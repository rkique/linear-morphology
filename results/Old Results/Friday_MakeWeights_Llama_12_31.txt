2024-07-26 17:12:33 root INFO     loading model + tokenizer
2024-07-26 17:12:37 root INFO     model + tokenizer loaded
2024-07-26 17:12:37 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+ment_irreg
2024-07-26 17:12:37 root INFO     building operator verb+ment_irreg
2024-07-26 17:12:38 root INFO     [order_1_approx] starting weight calculation for To acknowledge results in a acknowledgement
To infringe results in a infringement
To establish results in a establishment
To reinforce results in a reinforcement
To equip results in a equipment
To enhance results in a enhancement
To improve results in a improvement
To entertain results in a
2024-07-26 17:12:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 17:14:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1127,  0.1213, -0.5117,  ..., -0.0737, -0.2190, -0.0618],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5176, -2.2344,  1.3037,  ...,  1.5566, -1.0371, -1.4639],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0903,  0.0110,  0.0105,  ..., -0.0181, -0.0154,  0.0139],
        [-0.0158,  0.0749, -0.0094,  ...,  0.0262,  0.0071, -0.0118],
        [-0.0141, -0.0182,  0.0566,  ..., -0.0123,  0.0042,  0.0035],
        ...,
        [ 0.0017, -0.0068, -0.0173,  ...,  0.0663,  0.0102, -0.0017],
        [-0.0064,  0.0125,  0.0168,  ..., -0.0153,  0.0492, -0.0081],
        [ 0.0021, -0.0014,  0.0012,  ...,  0.0123, -0.0007,  0.0626]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5928, -2.1367,  1.1211,  ...,  2.1152, -1.5020, -1.5674]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 17:14:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To acknowledge results in a acknowledgement
To infringe results in a infringement
To establish results in a establishment
To reinforce results in a reinforcement
To equip results in a equipment
To enhance results in a enhancement
To improve results in a improvement
To entertain results in a
2024-07-26 17:14:58 root INFO     [order_1_approx] starting weight calculation for To improve results in a improvement
To infringe results in a infringement
To enhance results in a enhancement
To reinforce results in a reinforcement
To establish results in a establishment
To equip results in a equipment
To entertain results in a entertainment
To acknowledge results in a
2024-07-26 17:14:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 17:17:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2637,  0.5908, -0.9194,  ...,  0.2208, -0.3467, -0.1709],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7031, -2.3711,  0.3123,  ...,  0.9380, -2.8984,  1.0234],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0292, -0.0222, -0.0174,  ..., -0.0190, -0.0019,  0.0083],
        [ 0.0080,  0.0457,  0.0071,  ...,  0.0131,  0.0111,  0.0147],
        [-0.0018, -0.0097,  0.0206,  ..., -0.0080, -0.0035, -0.0156],
        ...,
        [ 0.0039,  0.0206,  0.0073,  ...,  0.0534, -0.0020,  0.0069],
        [ 0.0021,  0.0039,  0.0201,  ..., -0.0029,  0.0255,  0.0072],
        [ 0.0002, -0.0166,  0.0016,  ...,  0.0024, -0.0171,  0.0275]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4219, -2.2734,  0.3044,  ...,  1.2393, -2.7695,  0.7324]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 17:17:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To improve results in a improvement
To infringe results in a infringement
To enhance results in a enhancement
To reinforce results in a reinforcement
To establish results in a establishment
To equip results in a equipment
To entertain results in a entertainment
To acknowledge results in a
2024-07-26 17:17:17 root INFO     [order_1_approx] starting weight calculation for To equip results in a equipment
To infringe results in a infringement
To improve results in a improvement
To reinforce results in a reinforcement
To entertain results in a entertainment
To acknowledge results in a acknowledgement
To enhance results in a enhancement
To establish results in a
2024-07-26 17:17:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 17:19:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2385,  0.2749, -0.3926,  ...,  0.1555, -0.1630, -0.1053],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6582, -4.1289,  0.1865,  ...,  3.5742, -2.4141,  0.1772],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0488, -0.0008,  0.0038,  ..., -0.0176, -0.0053,  0.0274],
        [-0.0020,  0.0867,  0.0209,  ...,  0.0392,  0.0190,  0.0194],
        [ 0.0224, -0.0128,  0.0341,  ..., -0.0192,  0.0082, -0.0121],
        ...,
        [ 0.0008, -0.0063, -0.0088,  ...,  0.0652, -0.0049,  0.0250],
        [-0.0189,  0.0249, -0.0068,  ..., -0.0063,  0.0328, -0.0187],
        [ 0.0111, -0.0175,  0.0080,  ...,  0.0322, -0.0280,  0.0414]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6616, -3.8086,  0.5723,  ...,  3.6816, -2.7129, -0.1255]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 17:19:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To equip results in a equipment
To infringe results in a infringement
To improve results in a improvement
To reinforce results in a reinforcement
To entertain results in a entertainment
To acknowledge results in a acknowledgement
To enhance results in a enhancement
To establish results in a
2024-07-26 17:19:38 root INFO     [order_1_approx] starting weight calculation for To acknowledge results in a acknowledgement
To equip results in a equipment
To entertain results in a entertainment
To establish results in a establishment
To reinforce results in a reinforcement
To infringe results in a infringement
To enhance results in a enhancement
To improve results in a
2024-07-26 17:19:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 17:21:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1516, -0.0322, -0.0175,  ..., -0.2413, -0.2405,  0.0845],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5098, -2.5137,  1.3516,  ...,  4.5898, -2.9844, -2.5156],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0088, -0.0229, -0.0529,  ..., -0.0077,  0.0255,  0.0129],
        [ 0.0180,  0.0571,  0.0529,  ...,  0.0196, -0.0097,  0.0211],
        [-0.0169, -0.0133,  0.0235,  ..., -0.0009,  0.0154, -0.0043],
        ...,
        [ 0.0035, -0.0103, -0.0099,  ...,  0.0551, -0.0233,  0.0141],
        [-0.0002,  0.0065,  0.0356,  ..., -0.0037,  0.0287, -0.0273],
        [-0.0030, -0.0025,  0.0199,  ..., -0.0007, -0.0264,  0.0292]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7227, -2.0332,  1.3828,  ...,  4.2148, -2.9902, -2.6836]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 17:22:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To acknowledge results in a acknowledgement
To equip results in a equipment
To entertain results in a entertainment
To establish results in a establishment
To reinforce results in a reinforcement
To infringe results in a infringement
To enhance results in a enhancement
To improve results in a
2024-07-26 17:22:00 root INFO     [order_1_approx] starting weight calculation for To equip results in a equipment
To entertain results in a entertainment
To establish results in a establishment
To improve results in a improvement
To acknowledge results in a acknowledgement
To enhance results in a enhancement
To infringe results in a infringement
To reinforce results in a
2024-07-26 17:22:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 17:24:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2620,  0.0061, -0.3198,  ..., -0.2507, -0.1156,  0.0688],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5332, -2.9453,  2.8184,  ...,  3.7969, -2.1992, -3.6719],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.3599e-02, -2.2583e-02,  1.1528e-02,  ...,  7.3624e-03,
         -1.3199e-02,  2.1729e-02],
        [-1.1703e-02,  6.9763e-02,  1.6680e-03,  ...,  2.2659e-02,
          2.4689e-02, -4.2343e-03],
        [ 2.6360e-03, -1.3351e-05,  4.1290e-02,  ...,  3.2463e-03,
         -1.2703e-02,  3.0613e-03],
        ...,
        [ 2.1744e-03,  1.5259e-05, -2.4509e-03,  ...,  6.5491e-02,
          6.5804e-03,  1.0719e-02],
        [-1.3256e-03,  1.2100e-02, -1.6346e-03,  ..., -3.2616e-03,
          5.7404e-02, -1.6994e-03],
        [-1.6083e-02, -1.4679e-02,  7.8812e-03,  ...,  5.0926e-03,
         -1.8311e-02,  3.6530e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3184, -3.0547,  2.9883,  ...,  3.6543, -2.3594, -3.6191]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 17:24:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To equip results in a equipment
To entertain results in a entertainment
To establish results in a establishment
To improve results in a improvement
To acknowledge results in a acknowledgement
To enhance results in a enhancement
To infringe results in a infringement
To reinforce results in a
2024-07-26 17:24:22 root INFO     [order_1_approx] starting weight calculation for To acknowledge results in a acknowledgement
To enhance results in a enhancement
To equip results in a equipment
To reinforce results in a reinforcement
To establish results in a establishment
To entertain results in a entertainment
To improve results in a improvement
To infringe results in a
2024-07-26 17:24:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 17:26:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0571,  0.1956, -0.8052,  ...,  0.0585,  0.0284, -0.0087],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7705, -4.8750,  1.6582,  ...,  1.1074, -2.2305, -0.4346],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.9479e-02,  5.4932e-04, -7.0305e-03,  ..., -1.7990e-02,
         -9.3155e-03,  1.3863e-02],
        [-1.4046e-02,  8.4229e-02,  1.2634e-02,  ...,  1.3153e-02,
          3.8208e-02,  7.0381e-03],
        [-3.0899e-03, -6.2523e-03,  3.7811e-02,  ..., -1.7639e-02,
          1.9714e-02, -7.8087e-03],
        ...,
        [-1.3103e-03,  1.3779e-02,  3.2082e-03,  ...,  8.4106e-02,
         -1.2436e-03,  1.1658e-02],
        [-1.8127e-02, -7.9803e-03,  1.9135e-02,  ..., -6.7024e-03,
          5.3802e-02, -9.8724e-03],
        [ 2.1423e-02,  1.5259e-05,  2.3941e-02,  ...,  3.3386e-02,
         -2.5131e-02,  5.5817e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7363, -4.4414,  1.7256,  ...,  1.4189, -2.5215, -0.9077]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 17:26:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To acknowledge results in a acknowledgement
To enhance results in a enhancement
To equip results in a equipment
To reinforce results in a reinforcement
To establish results in a establishment
To entertain results in a entertainment
To improve results in a improvement
To infringe results in a
2024-07-26 17:26:43 root INFO     [order_1_approx] starting weight calculation for To equip results in a equipment
To reinforce results in a reinforcement
To entertain results in a entertainment
To acknowledge results in a acknowledgement
To establish results in a establishment
To improve results in a improvement
To infringe results in a infringement
To enhance results in a
2024-07-26 17:26:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 17:28:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0122, -0.2042, -0.1445,  ..., -0.0598, -0.0322, -0.0963],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8027, -0.6274,  0.5557,  ...,  4.4180, -5.5312, -2.6816],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0339,  0.0008, -0.0062,  ..., -0.0042, -0.0049,  0.0202],
        [-0.0007,  0.0477,  0.0085,  ...,  0.0322,  0.0019, -0.0048],
        [-0.0139, -0.0055,  0.0369,  ...,  0.0002, -0.0016, -0.0047],
        ...,
        [ 0.0065,  0.0035, -0.0068,  ...,  0.0419,  0.0091,  0.0087],
        [-0.0048,  0.0052,  0.0085,  ..., -0.0070,  0.0408, -0.0040],
        [-0.0039, -0.0011,  0.0122,  ...,  0.0040, -0.0163,  0.0297]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1309, -0.8062,  0.7271,  ...,  4.0117, -5.5586, -2.5879]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 17:28:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To equip results in a equipment
To reinforce results in a reinforcement
To entertain results in a entertainment
To acknowledge results in a acknowledgement
To establish results in a establishment
To improve results in a improvement
To infringe results in a infringement
To enhance results in a
2024-07-26 17:28:59 root INFO     [order_1_approx] starting weight calculation for To enhance results in a enhancement
To infringe results in a infringement
To establish results in a establishment
To reinforce results in a reinforcement
To improve results in a improvement
To acknowledge results in a acknowledgement
To entertain results in a entertainment
To equip results in a
2024-07-26 17:28:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 17:31:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1791,  0.2957, -0.4170,  ...,  0.0215, -0.1368, -0.0250],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8457, -1.8750, -0.3745,  ...,  3.3242, -2.5020, -2.4238],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.0720e-02,  1.3885e-02,  9.5139e-03,  ..., -3.3379e-05,
         -5.2071e-04,  9.5749e-03],
        [ 5.5084e-03,  7.4646e-02, -1.5354e-03,  ...,  2.8168e-02,
          2.0599e-02,  3.4084e-03],
        [ 1.4732e-02, -5.4054e-03,  4.3365e-02,  ..., -7.4005e-03,
         -8.2016e-04, -4.9782e-03],
        ...,
        [-2.7618e-03, -3.8185e-03,  2.0767e-02,  ...,  7.3425e-02,
         -8.0338e-03,  8.6212e-03],
        [-2.0081e-02,  1.7426e-02,  7.5989e-03,  ..., -1.3634e-02,
          4.0955e-02, -1.1002e-02],
        [-3.4332e-04, -2.8839e-03, -6.5269e-03,  ...,  1.7273e-02,
         -2.0409e-04,  6.1157e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5840, -1.6777, -0.5874,  ...,  3.4961, -2.3516, -2.3262]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 17:31:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To enhance results in a enhancement
To infringe results in a infringement
To establish results in a establishment
To reinforce results in a reinforcement
To improve results in a improvement
To acknowledge results in a acknowledgement
To entertain results in a entertainment
To equip results in a
2024-07-26 17:31:18 root INFO     total operator prediction time: 1121.3514273166656 seconds
2024-07-26 17:31:18 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun+less_reg
2024-07-26 17:31:18 root INFO     building operator noun+less_reg
2024-07-26 17:31:18 root INFO     [order_1_approx] starting weight calculation for Something without speech is speechless
Something without tact is tactless
Something without meat is meatless
Something without sensor is sensorless
Something without emotion is emotionless
Something without god is godless
Something without expression is expressionless
Something without goal is
2024-07-26 17:31:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 17:33:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2593,  0.0273, -0.2124,  ..., -0.4648, -0.1549,  0.2206],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0654, -2.1660, -1.0537,  ..., -2.3477, -1.5137, -1.7314],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0217, -0.0083, -0.0047,  ...,  0.0055,  0.0121,  0.0037],
        [ 0.0094,  0.0447, -0.0016,  ...,  0.0214, -0.0124,  0.0098],
        [ 0.0012, -0.0041,  0.0352,  ...,  0.0056, -0.0208,  0.0023],
        ...,
        [ 0.0173,  0.0306,  0.0030,  ...,  0.0266, -0.0050,  0.0100],
        [-0.0073,  0.0085, -0.0107,  ..., -0.0149,  0.0440, -0.0301],
        [ 0.0306,  0.0073,  0.0036,  ..., -0.0007, -0.0201,  0.0224]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9766, -2.3125, -1.3164,  ..., -2.5098, -1.4219, -1.7646]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 17:33:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without speech is speechless
Something without tact is tactless
Something without meat is meatless
Something without sensor is sensorless
Something without emotion is emotionless
Something without god is godless
Something without expression is expressionless
Something without goal is
2024-07-26 17:33:33 root INFO     [order_1_approx] starting weight calculation for Something without goal is goalless
Something without god is godless
Something without sensor is sensorless
Something without meat is meatless
Something without speech is speechless
Something without expression is expressionless
Something without emotion is emotionless
Something without tact is
2024-07-26 17:33:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 17:35:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2202,  0.1328,  0.4150,  ..., -0.0366, -0.0226,  0.0534],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7676,  0.3303,  1.5107,  ..., -0.4116, -6.0547, -3.8848],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0332, -0.0144,  0.0048,  ..., -0.0073, -0.0080,  0.0156],
        [ 0.0054,  0.0313,  0.0031,  ...,  0.0074, -0.0016, -0.0102],
        [-0.0015, -0.0052,  0.0197,  ...,  0.0150, -0.0222,  0.0036],
        ...,
        [ 0.0180,  0.0173,  0.0155,  ...,  0.0251, -0.0063,  0.0022],
        [ 0.0054, -0.0014,  0.0051,  ...,  0.0012,  0.0311, -0.0103],
        [ 0.0177,  0.0176,  0.0014,  ...,  0.0064, -0.0065,  0.0217]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4434,  0.2781,  1.3750,  ..., -0.5762, -5.6641, -4.1094]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 17:35:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without goal is goalless
Something without god is godless
Something without sensor is sensorless
Something without meat is meatless
Something without speech is speechless
Something without expression is expressionless
Something without emotion is emotionless
Something without tact is
2024-07-26 17:35:49 root INFO     [order_1_approx] starting weight calculation for Something without sensor is sensorless
Something without tact is tactless
Something without god is godless
Something without speech is speechless
Something without emotion is emotionless
Something without goal is goalless
Something without expression is expressionless
Something without meat is
2024-07-26 17:35:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 17:38:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1133, -0.5659,  0.1880,  ..., -0.0907, -0.2544,  0.2649],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6895, -3.5039, -0.6377,  ..., -3.3379, -6.2969, -2.7266],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0249, -0.0100,  0.0026,  ...,  0.0224,  0.0209,  0.0084],
        [ 0.0045,  0.0351, -0.0064,  ..., -0.0045,  0.0166,  0.0098],
        [ 0.0080, -0.0080,  0.0238,  ...,  0.0106, -0.0084, -0.0056],
        ...,
        [ 0.0247,  0.0197, -0.0001,  ...,  0.0060,  0.0061, -0.0155],
        [ 0.0115, -0.0133,  0.0038,  ...,  0.0201,  0.0415, -0.0450],
        [ 0.0193,  0.0195,  0.0045,  ..., -0.0027, -0.0086,  0.0257]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7500, -3.0801, -0.9810,  ..., -3.2109, -5.9297, -2.7383]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 17:38:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without sensor is sensorless
Something without tact is tactless
Something without god is godless
Something without speech is speechless
Something without emotion is emotionless
Something without goal is goalless
Something without expression is expressionless
Something without meat is
2024-07-26 17:38:11 root INFO     [order_1_approx] starting weight calculation for Something without speech is speechless
Something without goal is goalless
Something without expression is expressionless
Something without emotion is emotionless
Something without tact is tactless
Something without meat is meatless
Something without sensor is sensorless
Something without god is
2024-07-26 17:38:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 17:40:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3657,  0.1238, -0.1863,  ..., -0.2998, -0.1053, -0.1543],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2119, -3.0957,  1.7305,  ..., -3.5566, -2.2188, -0.1968],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0049,  0.0037,  0.0182,  ...,  0.0059,  0.0089,  0.0154],
        [ 0.0252,  0.0247, -0.0155,  ...,  0.0131,  0.0061, -0.0062],
        [-0.0225,  0.0065,  0.0248,  ...,  0.0025, -0.0085, -0.0011],
        ...,
        [ 0.0111,  0.0091, -0.0003,  ...,  0.0137,  0.0031,  0.0057],
        [-0.0007,  0.0062, -0.0029,  ..., -0.0009,  0.0302, -0.0133],
        [ 0.0184,  0.0191, -0.0045,  ...,  0.0100, -0.0252,  0.0164]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7222, -2.8418,  1.4023,  ..., -3.0625, -2.2988, -0.3784]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 17:40:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without speech is speechless
Something without goal is goalless
Something without expression is expressionless
Something without emotion is emotionless
Something without tact is tactless
Something without meat is meatless
Something without sensor is sensorless
Something without god is
2024-07-26 17:40:32 root INFO     [order_1_approx] starting weight calculation for Something without sensor is sensorless
Something without goal is goalless
Something without expression is expressionless
Something without tact is tactless
Something without emotion is emotionless
Something without meat is meatless
Something without god is godless
Something without speech is
2024-07-26 17:40:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 17:42:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0844, -0.2644,  0.1699,  ...,  0.2722,  0.2910,  0.2651],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5059, -2.4355,  0.4998,  ..., -0.1897, -1.1084, -0.6562],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.4342e-02, -3.8681e-03, -5.6839e-03,  ...,  3.0701e-02,
          8.3694e-03,  1.9379e-02],
        [-8.0795e-03,  5.7465e-02,  2.4261e-02,  ...,  5.6381e-03,
          1.7052e-03,  1.2138e-02],
        [ 2.3911e-02, -7.7400e-03,  3.1006e-02,  ...,  5.5161e-03,
         -2.5482e-02,  1.2985e-02],
        ...,
        [-4.8447e-03,  1.7044e-02,  9.5558e-04,  ...,  2.5818e-02,
          8.8882e-03, -1.0864e-02],
        [ 2.0981e-05,  3.0136e-04,  6.7863e-03,  ..., -2.4490e-02,
          4.3182e-02, -2.4460e-02],
        [ 2.3155e-03,  8.0414e-03, -1.4181e-03,  ..., -1.1879e-02,
         -1.4935e-03,  2.3010e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1777, -2.7168,  0.2373,  ..., -0.3169, -1.3232, -0.6992]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 17:42:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without sensor is sensorless
Something without goal is goalless
Something without expression is expressionless
Something without tact is tactless
Something without emotion is emotionless
Something without meat is meatless
Something without god is godless
Something without speech is
2024-07-26 17:42:51 root INFO     [order_1_approx] starting weight calculation for Something without speech is speechless
Something without meat is meatless
Something without goal is goalless
Something without expression is expressionless
Something without tact is tactless
Something without sensor is sensorless
Something without god is godless
Something without emotion is
2024-07-26 17:42:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 17:45:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0781, -0.4082, -0.0172,  ..., -0.0920, -0.0303,  0.3823],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7725, -1.6299, -0.0186,  ..., -3.4629, -1.8555, -4.4922],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.6764e-02, -3.5210e-03,  1.7426e-02,  ..., -8.3923e-04,
         -5.1918e-03,  1.0223e-02],
        [-5.0201e-03,  4.6143e-02,  4.4785e-03,  ...,  7.4615e-03,
         -3.3684e-03, -5.9128e-04],
        [-1.9569e-03, -4.7226e-03,  1.7029e-02,  ...,  9.4414e-05,
         -1.2466e-02, -1.7014e-03],
        ...,
        [ 1.8097e-02,  1.6602e-02, -4.4785e-03,  ...,  3.0579e-02,
          8.4915e-03,  1.1665e-02],
        [ 5.4016e-03,  1.1963e-02, -2.8305e-03,  ..., -1.9897e-02,
          3.8086e-02, -1.9226e-02],
        [ 2.7786e-02,  1.0002e-02, -2.2793e-03,  ...,  1.6296e-02,
         -5.9624e-03,  3.4698e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7988, -1.8672, -0.1792,  ..., -3.1504, -2.2285, -4.2461]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 17:45:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without speech is speechless
Something without meat is meatless
Something without goal is goalless
Something without expression is expressionless
Something without tact is tactless
Something without sensor is sensorless
Something without god is godless
Something without emotion is
2024-07-26 17:45:12 root INFO     [order_1_approx] starting weight calculation for Something without emotion is emotionless
Something without expression is expressionless
Something without meat is meatless
Something without tact is tactless
Something without goal is goalless
Something without speech is speechless
Something without god is godless
Something without sensor is
2024-07-26 17:45:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 17:47:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0820, -0.3765, -0.3701,  ..., -0.3345, -0.1517, -0.4072],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8145, -1.7637, -0.2793,  ..., -5.3281, -4.4805, -1.9453],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0474, -0.0132, -0.0084,  ...,  0.0092, -0.0114, -0.0068],
        [-0.0047,  0.0476,  0.0266,  ...,  0.0121,  0.0230,  0.0075],
        [-0.0010, -0.0092,  0.0059,  ..., -0.0072, -0.0323,  0.0072],
        ...,
        [ 0.0292,  0.0331,  0.0324,  ...,  0.0346,  0.0016,  0.0162],
        [-0.0063, -0.0104,  0.0050,  ...,  0.0010,  0.0367, -0.0166],
        [ 0.0325,  0.0230,  0.0082,  ...,  0.0279, -0.0188,  0.0293]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9395, -2.6055, -0.5342,  ..., -4.8945, -3.9668, -2.2812]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 17:47:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without emotion is emotionless
Something without expression is expressionless
Something without meat is meatless
Something without tact is tactless
Something without goal is goalless
Something without speech is speechless
Something without god is godless
Something without sensor is
2024-07-26 17:47:32 root INFO     [order_1_approx] starting weight calculation for Something without meat is meatless
Something without tact is tactless
Something without goal is goalless
Something without sensor is sensorless
Something without speech is speechless
Something without emotion is emotionless
Something without god is godless
Something without expression is
2024-07-26 17:47:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 17:49:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0187, -0.3652, -0.0385,  ...,  0.3892,  0.1832,  0.1171],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6226, -3.3984,  0.8970,  ..., -2.9453, -2.5273, -0.5859],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0341, -0.0007,  0.0011,  ..., -0.0013,  0.0085,  0.0168],
        [ 0.0126,  0.0619,  0.0032,  ...,  0.0307, -0.0029,  0.0198],
        [ 0.0183, -0.0091,  0.0393,  ...,  0.0179, -0.0191, -0.0148],
        ...,
        [ 0.0158,  0.0298, -0.0023,  ...,  0.0406,  0.0050, -0.0016],
        [-0.0113,  0.0169,  0.0028,  ..., -0.0165,  0.0525, -0.0204],
        [ 0.0277,  0.0133,  0.0090,  ...,  0.0309, -0.0071,  0.0340]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7539, -3.6328,  0.8516,  ..., -2.6211, -2.6016, -0.3174]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 17:49:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without meat is meatless
Something without tact is tactless
Something without goal is goalless
Something without sensor is sensorless
Something without speech is speechless
Something without emotion is emotionless
Something without god is godless
Something without expression is
2024-07-26 17:49:54 root INFO     total operator prediction time: 1115.6866796016693 seconds
2024-07-26 17:49:54 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj+ness_reg
2024-07-26 17:49:54 root INFO     building operator adj+ness_reg
2024-07-26 17:49:54 root INFO     [order_1_approx] starting weight calculation for The state of being obvious is obviousness
The state of being cheap is cheapness
The state of being broken is brokenness
The state of being reasonable is reasonableness
The state of being sad is sadness
The state of being random is randomness
The state of being related is relatedness
The state of being pure is
2024-07-26 17:49:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 17:52:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0228, -0.2373,  0.4565,  ..., -0.2267, -0.1133,  0.2900],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5312, -2.0000, -1.4912,  ..., -3.9473, -3.5234, -4.0742],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0695, -0.0108, -0.0207,  ..., -0.0098, -0.0100, -0.0082],
        [ 0.0195,  0.0620,  0.0355,  ...,  0.0233,  0.0083,  0.0052],
        [ 0.0290, -0.0093,  0.0523,  ...,  0.0162, -0.0144,  0.0106],
        ...,
        [ 0.0133,  0.0245,  0.0089,  ...,  0.0357,  0.0188, -0.0043],
        [-0.0179, -0.0075, -0.0165,  ..., -0.0078,  0.0650, -0.0193],
        [ 0.0006,  0.0151,  0.0008,  ..., -0.0045, -0.0059,  0.0745]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8301, -1.8262, -1.5146,  ..., -3.6895, -3.3418, -4.0820]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 17:52:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being obvious is obviousness
The state of being cheap is cheapness
The state of being broken is brokenness
The state of being reasonable is reasonableness
The state of being sad is sadness
The state of being random is randomness
The state of being related is relatedness
The state of being pure is
2024-07-26 17:52:14 root INFO     [order_1_approx] starting weight calculation for The state of being pure is pureness
The state of being sad is sadness
The state of being obvious is obviousness
The state of being broken is brokenness
The state of being cheap is cheapness
The state of being related is relatedness
The state of being reasonable is reasonableness
The state of being random is
2024-07-26 17:52:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 17:54:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3501,  0.3018, -0.3975,  ...,  0.2135,  0.0588, -0.1957],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.3506, -1.7803, -1.2949,  ..., -1.9072, -2.9434, -5.0859],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0652, -0.0072, -0.0066,  ...,  0.0062, -0.0107, -0.0083],
        [-0.0219,  0.0434,  0.0194,  ...,  0.0294,  0.0052,  0.0106],
        [ 0.0217, -0.0168,  0.0460,  ..., -0.0279,  0.0101, -0.0264],
        ...,
        [-0.0003,  0.0185,  0.0150,  ...,  0.0323, -0.0129,  0.0096],
        [ 0.0023,  0.0225,  0.0158,  ..., -0.0125,  0.0388, -0.0060],
        [ 0.0062,  0.0076, -0.0076,  ..., -0.0039, -0.0283,  0.0371]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.9766, -1.4170, -1.2725,  ..., -2.0781, -3.0723, -5.5078]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 17:54:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being pure is pureness
The state of being sad is sadness
The state of being obvious is obviousness
The state of being broken is brokenness
The state of being cheap is cheapness
The state of being related is relatedness
The state of being reasonable is reasonableness
The state of being random is
2024-07-26 17:54:36 root INFO     [order_1_approx] starting weight calculation for The state of being pure is pureness
The state of being random is randomness
The state of being reasonable is reasonableness
The state of being sad is sadness
The state of being obvious is obviousness
The state of being related is relatedness
The state of being cheap is cheapness
The state of being broken is
2024-07-26 17:54:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 17:56:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0995,  0.2128, -0.4509,  ..., -0.0211, -0.2539,  0.0684],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1562, -4.1367, -0.5098,  ..., -2.6562,  1.2275, -0.5566],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0442, -0.0020, -0.0115,  ...,  0.0057,  0.0018,  0.0197],
        [-0.0040,  0.0329,  0.0178,  ...,  0.0302,  0.0119, -0.0021],
        [ 0.0029, -0.0272,  0.0208,  ..., -0.0209,  0.0010, -0.0080],
        ...,
        [ 0.0134,  0.0213,  0.0002,  ...,  0.0310,  0.0075,  0.0031],
        [-0.0236,  0.0016, -0.0095,  ..., -0.0296,  0.0673, -0.0164],
        [ 0.0010,  0.0068, -0.0073,  ..., -0.0016, -0.0134,  0.0404]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0742, -3.8125, -0.2451,  ..., -2.2031,  1.0361, -0.3564]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 17:56:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being pure is pureness
The state of being random is randomness
The state of being reasonable is reasonableness
The state of being sad is sadness
The state of being obvious is obviousness
The state of being related is relatedness
The state of being cheap is cheapness
The state of being broken is
2024-07-26 17:56:57 root INFO     [order_1_approx] starting weight calculation for The state of being random is randomness
The state of being obvious is obviousness
The state of being pure is pureness
The state of being reasonable is reasonableness
The state of being broken is brokenness
The state of being related is relatedness
The state of being cheap is cheapness
The state of being sad is
2024-07-26 17:56:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 17:59:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0120, -0.1946, -0.1954,  ...,  0.1740, -0.6211,  0.2241],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5977, -4.6797, -1.8271,  ..., -7.2734, -2.9375, -3.2031],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0135,  0.0054, -0.0097,  ..., -0.0076,  0.0046, -0.0084],
        [ 0.0054,  0.0096,  0.0077,  ...,  0.0107,  0.0154,  0.0139],
        [ 0.0074, -0.0149,  0.0366,  ...,  0.0015, -0.0206, -0.0084],
        ...,
        [ 0.0128, -0.0024,  0.0053,  ...,  0.0218, -0.0078,  0.0141],
        [-0.0119,  0.0044, -0.0016,  ..., -0.0029,  0.0457, -0.0076],
        [ 0.0098, -0.0015,  0.0015,  ...,  0.0007, -0.0109,  0.0413]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5625, -4.7617, -2.1055,  ..., -7.1055, -2.8613, -3.1172]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 17:59:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being random is randomness
The state of being obvious is obviousness
The state of being pure is pureness
The state of being reasonable is reasonableness
The state of being broken is brokenness
The state of being related is relatedness
The state of being cheap is cheapness
The state of being sad is
2024-07-26 17:59:20 root INFO     [order_1_approx] starting weight calculation for The state of being reasonable is reasonableness
The state of being broken is brokenness
The state of being random is randomness
The state of being cheap is cheapness
The state of being sad is sadness
The state of being obvious is obviousness
The state of being pure is pureness
The state of being related is
2024-07-26 17:59:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 18:01:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0175, -0.0334, -0.3167,  ...,  0.0287, -0.2788,  0.2842],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1699, -2.3027, -1.3477,  ...,  0.7603, -3.0918, -2.6523],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0484,  0.0029, -0.0204,  ..., -0.0181,  0.0163, -0.0113],
        [ 0.0078,  0.0803,  0.0254,  ...,  0.0754, -0.0204,  0.0297],
        [ 0.0035, -0.0095,  0.0480,  ..., -0.0042, -0.0010, -0.0309],
        ...,
        [ 0.0097,  0.0199,  0.0075,  ...,  0.0629, -0.0082,  0.0246],
        [-0.0035,  0.0061,  0.0243,  ...,  0.0010,  0.0482, -0.0032],
        [-0.0031,  0.0182, -0.0068,  ...,  0.0164, -0.0335,  0.0693]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6240, -2.7207, -1.2578,  ...,  0.3718, -3.1016, -2.9004]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 18:01:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being reasonable is reasonableness
The state of being broken is brokenness
The state of being random is randomness
The state of being cheap is cheapness
The state of being sad is sadness
The state of being obvious is obviousness
The state of being pure is pureness
The state of being related is
2024-07-26 18:01:42 root INFO     [order_1_approx] starting weight calculation for The state of being pure is pureness
The state of being reasonable is reasonableness
The state of being cheap is cheapness
The state of being random is randomness
The state of being sad is sadness
The state of being related is relatedness
The state of being broken is brokenness
The state of being obvious is
2024-07-26 18:01:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 18:04:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1864,  0.3196, -0.0385,  ..., -0.0774, -0.4846,  0.1367],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3145, -3.8145, -1.0234,  ..., -2.6426, -4.3906,  1.7207],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0450,  0.0048, -0.0027,  ...,  0.0203,  0.0018,  0.0127],
        [-0.0146,  0.0429,  0.0191,  ...,  0.0095,  0.0200, -0.0239],
        [ 0.0186, -0.0028,  0.0181,  ..., -0.0215, -0.0353,  0.0034],
        ...,
        [ 0.0056,  0.0300,  0.0177,  ...,  0.0361, -0.0077,  0.0032],
        [ 0.0069,  0.0101, -0.0042,  ..., -0.0201,  0.0465, -0.0313],
        [ 0.0202,  0.0058, -0.0080,  ..., -0.0092, -0.0269,  0.0370]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6270, -3.4980, -0.9873,  ..., -2.5918, -4.4180,  1.6016]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 18:04:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being pure is pureness
The state of being reasonable is reasonableness
The state of being cheap is cheapness
The state of being random is randomness
The state of being sad is sadness
The state of being related is relatedness
The state of being broken is brokenness
The state of being obvious is
2024-07-26 18:04:03 root INFO     [order_1_approx] starting weight calculation for The state of being pure is pureness
The state of being related is relatedness
The state of being obvious is obviousness
The state of being broken is brokenness
The state of being random is randomness
The state of being reasonable is reasonableness
The state of being sad is sadness
The state of being cheap is
2024-07-26 18:04:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 18:06:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3179, -0.2351, -0.2598,  ...,  0.0728,  0.1625,  0.0652],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2749, -0.0156, -0.9404,  ..., -4.5000, -5.4453, -1.6211],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0347, -0.0176, -0.0099,  ..., -0.0128,  0.0003,  0.0078],
        [ 0.0141,  0.0372,  0.0348,  ...,  0.0145, -0.0064,  0.0334],
        [-0.0014,  0.0075,  0.0298,  ..., -0.0063, -0.0142,  0.0012],
        ...,
        [ 0.0016,  0.0231, -0.0093,  ...,  0.0446,  0.0318, -0.0121],
        [-0.0233,  0.0109, -0.0157,  ..., -0.0233,  0.0397, -0.0197],
        [ 0.0092,  0.0097, -0.0206,  ...,  0.0188,  0.0079,  0.0573]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1195, -0.3042, -0.9712,  ..., -4.2266, -5.2500, -1.6494]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 18:06:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being pure is pureness
The state of being related is relatedness
The state of being obvious is obviousness
The state of being broken is brokenness
The state of being random is randomness
The state of being reasonable is reasonableness
The state of being sad is sadness
The state of being cheap is
2024-07-26 18:06:21 root INFO     [order_1_approx] starting weight calculation for The state of being related is relatedness
The state of being pure is pureness
The state of being cheap is cheapness
The state of being random is randomness
The state of being obvious is obviousness
The state of being broken is brokenness
The state of being sad is sadness
The state of being reasonable is
2024-07-26 18:06:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 18:08:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1421,  0.0184, -0.0848,  ..., -0.4639,  0.0798, -0.1390],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8906, -2.2109, -1.3965,  ..., -3.3691, -6.1875, -3.5234],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0559,  0.0041, -0.0155,  ..., -0.0024, -0.0151,  0.0235],
        [-0.0051,  0.0407,  0.0169,  ...,  0.0055,  0.0196,  0.0013],
        [ 0.0179, -0.0147,  0.0573,  ..., -0.0110, -0.0141,  0.0107],
        ...,
        [ 0.0157,  0.0139,  0.0117,  ...,  0.0562, -0.0035,  0.0003],
        [ 0.0092,  0.0152,  0.0312,  ...,  0.0066,  0.0331, -0.0157],
        [ 0.0143,  0.0183,  0.0008,  ...,  0.0013, -0.0282,  0.0348]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5342, -2.1992, -1.0029,  ..., -2.9707, -6.2148, -3.5391]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 18:08:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being related is relatedness
The state of being pure is pureness
The state of being cheap is cheapness
The state of being random is randomness
The state of being obvious is obviousness
The state of being broken is brokenness
The state of being sad is sadness
The state of being reasonable is
2024-07-26 18:08:37 root INFO     total operator prediction time: 1123.4990665912628 seconds
2024-07-26 18:08:37 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on re+verb_reg
2024-07-26 18:08:37 root INFO     building operator re+verb_reg
2024-07-26 18:08:38 root INFO     [order_1_approx] starting weight calculation for To assess again is to reassess
To engage again is to reengage
To adjust again is to readjust
To cognize again is to recognize
To apply again is to reapply
To install again is to reinstall
To unite again is to reunite
To learn again is to
2024-07-26 18:08:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 18:10:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0512,  0.1017, -0.1580,  ..., -0.2827, -0.3462, -0.0200],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0273, -3.2188,  1.6855,  ...,  3.1602, -5.2422, -4.8984],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0360, -0.0079,  0.0053,  ..., -0.0128, -0.0084,  0.0106],
        [ 0.0043,  0.0250,  0.0024,  ..., -0.0048, -0.0096,  0.0067],
        [-0.0016, -0.0127,  0.0405,  ...,  0.0040,  0.0105, -0.0087],
        ...,
        [ 0.0312,  0.0026,  0.0014,  ...,  0.0376,  0.0003, -0.0001],
        [-0.0106,  0.0211, -0.0062,  ...,  0.0064,  0.0202, -0.0090],
        [ 0.0074,  0.0182,  0.0055,  ..., -0.0068, -0.0066,  0.0268]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.0078, -3.3945,  1.6318,  ...,  3.4609, -5.1094, -4.7266]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 18:10:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To assess again is to reassess
To engage again is to reengage
To adjust again is to readjust
To cognize again is to recognize
To apply again is to reapply
To install again is to reinstall
To unite again is to reunite
To learn again is to
2024-07-26 18:10:58 root INFO     [order_1_approx] starting weight calculation for To cognize again is to recognize
To apply again is to reapply
To assess again is to reassess
To learn again is to relearn
To engage again is to reengage
To unite again is to reunite
To adjust again is to readjust
To install again is to
2024-07-26 18:10:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 18:13:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2103, -0.2642, -0.1323,  ...,  0.1948, -0.0232, -0.1010],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2102, -3.1973,  1.6719,  ...,  2.7266, -4.7266, -3.9219],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0374, -0.0145,  0.0111,  ...,  0.0099, -0.0094,  0.0016],
        [ 0.0055,  0.0332,  0.0010,  ...,  0.0024, -0.0072,  0.0020],
        [ 0.0059, -0.0078,  0.0373,  ..., -0.0152, -0.0144,  0.0020],
        ...,
        [ 0.0096, -0.0046, -0.0125,  ...,  0.0381,  0.0098, -0.0019],
        [ 0.0033, -0.0033, -0.0068,  ..., -0.0027,  0.0232, -0.0027],
        [ 0.0004, -0.0043,  0.0017,  ..., -0.0033, -0.0081,  0.0270]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3389, -3.0566,  1.4824,  ...,  3.1172, -4.2930, -3.9043]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 18:13:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To cognize again is to recognize
To apply again is to reapply
To assess again is to reassess
To learn again is to relearn
To engage again is to reengage
To unite again is to reunite
To adjust again is to readjust
To install again is to
2024-07-26 18:13:20 root INFO     [order_1_approx] starting weight calculation for To apply again is to reapply
To unite again is to reunite
To assess again is to reassess
To install again is to reinstall
To adjust again is to readjust
To learn again is to relearn
To cognize again is to recognize
To engage again is to
2024-07-26 18:13:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 18:15:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0859,  0.4773, -0.1853,  ...,  0.6641, -0.3081,  0.0527],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.3320, -2.5918,  1.4180,  ...,  1.7871, -4.6328, -5.3984],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0634,  0.0105,  0.0044,  ...,  0.0068, -0.0028,  0.0056],
        [-0.0002,  0.0479,  0.0112,  ...,  0.0029, -0.0104,  0.0161],
        [ 0.0089,  0.0075,  0.0388,  ..., -0.0086,  0.0130, -0.0052],
        ...,
        [ 0.0174, -0.0163,  0.0084,  ...,  0.0656,  0.0084,  0.0004],
        [-0.0128,  0.0218, -0.0027,  ..., -0.0010,  0.0367, -0.0193],
        [-0.0041, -0.0079, -0.0079,  ..., -0.0060, -0.0116,  0.0415]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.2041, -2.9043,  1.6602,  ...,  1.9814, -4.9648, -5.2266]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 18:15:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To apply again is to reapply
To unite again is to reunite
To assess again is to reassess
To install again is to reinstall
To adjust again is to readjust
To learn again is to relearn
To cognize again is to recognize
To engage again is to
2024-07-26 18:15:42 root INFO     [order_1_approx] starting weight calculation for To learn again is to relearn
To adjust again is to readjust
To assess again is to reassess
To install again is to reinstall
To unite again is to reunite
To engage again is to reengage
To apply again is to reapply
To cognize again is to
2024-07-26 18:15:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 18:18:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0149,  0.2175, -0.6172,  ...,  0.0970, -0.0988,  0.0594],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.0195, -2.8945,  3.4609,  ...,  1.9629, -4.4102, -0.4727],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.4880e-02, -1.1261e-02,  1.3702e-02,  ...,  7.0915e-03,
         -9.8190e-03,  5.1575e-03],
        [ 7.7782e-03,  4.3945e-02,  7.1793e-03,  ...,  2.3212e-03,
         -1.3824e-02,  7.7820e-03],
        [-6.7520e-03, -1.8570e-02,  3.1281e-02,  ..., -7.0801e-03,
          5.9128e-05, -5.8403e-03],
        ...,
        [ 3.1616e-02,  9.2697e-03, -3.8834e-03,  ...,  4.3701e-02,
         -1.1337e-02,  5.5733e-03],
        [ 1.8768e-03,  5.7259e-03, -1.6212e-04,  ...,  1.5488e-03,
          2.9343e-02, -1.4206e-02],
        [-6.4373e-04,  6.4659e-04, -8.4381e-03,  ..., -1.7212e-02,
         -8.7814e-03,  3.5370e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.9199, -2.7988,  3.2695,  ...,  2.4355, -4.2852, -0.6533]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 18:18:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To learn again is to relearn
To adjust again is to readjust
To assess again is to reassess
To install again is to reinstall
To unite again is to reunite
To engage again is to reengage
To apply again is to reapply
To cognize again is to
2024-07-26 18:18:04 root INFO     [order_1_approx] starting weight calculation for To learn again is to relearn
To cognize again is to recognize
To install again is to reinstall
To assess again is to reassess
To unite again is to reunite
To adjust again is to readjust
To engage again is to reengage
To apply again is to
2024-07-26 18:18:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 18:20:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 1.2976e-01,  9.8633e-02,  2.1240e-01,  ...,  1.5015e-02,
        -3.2129e-01,  3.0518e-04], device='cuda:1', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3359, -2.2910,  0.0632,  ...,  2.9336, -5.6562, -4.1250],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0495, -0.0044,  0.0200,  ...,  0.0073, -0.0151,  0.0220],
        [ 0.0002,  0.0424,  0.0231,  ...,  0.0106, -0.0050,  0.0096],
        [-0.0054, -0.0034,  0.0560,  ..., -0.0099,  0.0157, -0.0029],
        ...,
        [ 0.0096, -0.0088,  0.0017,  ...,  0.0692,  0.0015,  0.0045],
        [-0.0198,  0.0120, -0.0135,  ..., -0.0067,  0.0448, -0.0227],
        [-0.0002, -0.0080,  0.0141,  ..., -0.0064, -0.0176,  0.0458]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1589, -2.6680,  0.1810,  ...,  3.1035, -5.6641, -3.9688]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 18:20:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To learn again is to relearn
To cognize again is to recognize
To install again is to reinstall
To assess again is to reassess
To unite again is to reunite
To adjust again is to readjust
To engage again is to reengage
To apply again is to
2024-07-26 18:20:26 root INFO     [order_1_approx] starting weight calculation for To assess again is to reassess
To engage again is to reengage
To apply again is to reapply
To cognize again is to recognize
To install again is to reinstall
To learn again is to relearn
To adjust again is to readjust
To unite again is to
2024-07-26 18:20:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 18:22:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3823,  0.1810, -0.2212,  ...,  0.4543, -0.0240,  0.1936],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4531, -3.0703,  2.7344,  ...,  3.1406, -4.4297, -1.9316],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0513,  0.0052,  0.0127,  ...,  0.0077,  0.0010,  0.0113],
        [ 0.0034,  0.0459,  0.0044,  ...,  0.0153, -0.0186,  0.0018],
        [-0.0012,  0.0009,  0.0352,  ..., -0.0030, -0.0045, -0.0027],
        ...,
        [ 0.0001,  0.0056, -0.0006,  ...,  0.0539, -0.0148, -0.0065],
        [-0.0002,  0.0189,  0.0069,  ..., -0.0146,  0.0435, -0.0168],
        [ 0.0082, -0.0184,  0.0132,  ...,  0.0026, -0.0163,  0.0503]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3418, -3.2910,  2.5977,  ...,  3.0820, -4.4219, -2.2422]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 18:22:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To assess again is to reassess
To engage again is to reengage
To apply again is to reapply
To cognize again is to recognize
To install again is to reinstall
To learn again is to relearn
To adjust again is to readjust
To unite again is to
2024-07-26 18:22:47 root INFO     [order_1_approx] starting weight calculation for To unite again is to reunite
To learn again is to relearn
To install again is to reinstall
To engage again is to reengage
To adjust again is to readjust
To cognize again is to recognize
To apply again is to reapply
To assess again is to
2024-07-26 18:22:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 18:25:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0608,  0.3752, -0.3818,  ...,  0.1804, -0.0202, -0.1641],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8838, -3.0195,  1.9453,  ...,  0.7686, -5.9062, -4.5234],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0505, -0.0116,  0.0084,  ..., -0.0099,  0.0051,  0.0078],
        [ 0.0132,  0.0418,  0.0132,  ...,  0.0261,  0.0012,  0.0107],
        [-0.0073,  0.0098,  0.0477,  ...,  0.0025,  0.0111, -0.0014],
        ...,
        [ 0.0178,  0.0004,  0.0012,  ...,  0.0629,  0.0068, -0.0056],
        [-0.0244,  0.0042,  0.0182,  ...,  0.0128,  0.0360, -0.0079],
        [ 0.0048,  0.0082, -0.0008,  ..., -0.0001, -0.0070,  0.0280]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8242, -3.2598,  1.8330,  ...,  1.2344, -6.1797, -3.9434]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 18:25:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To unite again is to reunite
To learn again is to relearn
To install again is to reinstall
To engage again is to reengage
To adjust again is to readjust
To cognize again is to recognize
To apply again is to reapply
To assess again is to
2024-07-26 18:25:06 root INFO     [order_1_approx] starting weight calculation for To unite again is to reunite
To learn again is to relearn
To assess again is to reassess
To install again is to reinstall
To engage again is to reengage
To apply again is to reapply
To cognize again is to recognize
To adjust again is to
2024-07-26 18:25:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 18:27:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1841,  0.0691, -0.5811,  ..., -0.1826, -0.1370,  0.1073],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8257, -3.1914, -1.9434,  ...,  1.7910, -5.6797, -2.5254],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0649,  0.0018,  0.0082,  ..., -0.0174,  0.0016,  0.0173],
        [ 0.0148,  0.0578,  0.0076,  ...,  0.0114, -0.0149,  0.0140],
        [ 0.0042,  0.0139,  0.0379,  ...,  0.0009,  0.0107,  0.0022],
        ...,
        [ 0.0021, -0.0051, -0.0084,  ...,  0.0690,  0.0043, -0.0049],
        [-0.0116,  0.0036, -0.0189,  ..., -0.0115,  0.0476, -0.0168],
        [ 0.0037,  0.0111, -0.0026,  ..., -0.0146, -0.0099,  0.0258]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4983, -3.2969, -1.7275,  ...,  1.9502, -5.3711, -2.0762]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 18:27:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To unite again is to reunite
To learn again is to relearn
To assess again is to reassess
To install again is to reinstall
To engage again is to reengage
To apply again is to reapply
To cognize again is to recognize
To adjust again is to
2024-07-26 18:27:28 root INFO     total operator prediction time: 1130.700091600418 seconds
2024-07-26 18:27:28 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on un+adj_reg
2024-07-26 18:27:28 root INFO     building operator un+adj_reg
2024-07-26 18:27:28 root INFO     [order_1_approx] starting weight calculation for The opposite of certain is uncertain
The opposite of lucky is unlucky
The opposite of veiled is unveiled
The opposite of comfortable is uncomfortable
The opposite of sustainable is unsustainable
The opposite of aware is unaware
The opposite of able is unable
The opposite of popular is
2024-07-26 18:27:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 18:29:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4058,  0.2162, -0.0056,  ...,  0.4106, -0.1995, -0.0800],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2363, -1.6387,  1.6650,  ..., -2.5898, -1.7422,  0.1562],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.4585e-02,  1.3733e-04,  2.4490e-02,  ...,  1.9958e-02,
         -1.4236e-02,  1.8829e-02],
        [ 2.9602e-03,  5.8289e-02, -3.4180e-03,  ...,  2.8397e-02,
         -1.3802e-02, -2.0111e-02],
        [-4.5280e-03, -1.7868e-02,  5.0507e-02,  ..., -2.4529e-03,
          1.4542e-02, -6.1531e-03],
        ...,
        [ 3.2257e-02,  2.6855e-02, -9.4070e-03,  ...,  5.8258e-02,
          4.6043e-03,  1.1063e-02],
        [-2.3071e-02, -5.5389e-03, -5.7220e-05,  ...,  1.7059e-02,
          4.0497e-02,  8.5373e-03],
        [ 2.9358e-02, -4.4513e-04, -2.3865e-02,  ..., -5.9700e-03,
          7.9155e-04,  4.3365e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4180, -1.8037,  1.3213,  ..., -2.3008, -1.7412, -0.0322]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 18:29:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of certain is uncertain
The opposite of lucky is unlucky
The opposite of veiled is unveiled
The opposite of comfortable is uncomfortable
The opposite of sustainable is unsustainable
The opposite of aware is unaware
The opposite of able is unable
The opposite of popular is
2024-07-26 18:29:48 root INFO     [order_1_approx] starting weight calculation for The opposite of lucky is unlucky
The opposite of sustainable is unsustainable
The opposite of aware is unaware
The opposite of able is unable
The opposite of comfortable is uncomfortable
The opposite of popular is unpopular
The opposite of veiled is unveiled
The opposite of certain is
2024-07-26 18:29:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 18:32:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1871,  0.1257, -0.1888,  ...,  0.0195, -0.1420, -0.2698],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6836, -2.1055,  2.1250,  ..., -0.5449, -0.6646, -3.5352],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0527,  0.0019,  0.0041,  ...,  0.0031, -0.0241,  0.0181],
        [-0.0079,  0.0660, -0.0003,  ...,  0.0539,  0.0167,  0.0233],
        [ 0.0148, -0.0013,  0.0516,  ...,  0.0170, -0.0135,  0.0199],
        ...,
        [ 0.0153,  0.0350,  0.0187,  ...,  0.0371,  0.0017,  0.0036],
        [-0.0109,  0.0087, -0.0005,  ...,  0.0240,  0.0572,  0.0032],
        [ 0.0165,  0.0203, -0.0172,  ...,  0.0117,  0.0035,  0.0560]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1953, -2.2910,  2.4141,  ..., -1.1250, -1.1484, -3.5996]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 18:32:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of lucky is unlucky
The opposite of sustainable is unsustainable
The opposite of aware is unaware
The opposite of able is unable
The opposite of comfortable is uncomfortable
The opposite of popular is unpopular
The opposite of veiled is unveiled
The opposite of certain is
2024-07-26 18:32:09 root INFO     [order_1_approx] starting weight calculation for The opposite of able is unable
The opposite of aware is unaware
The opposite of certain is uncertain
The opposite of lucky is unlucky
The opposite of sustainable is unsustainable
The opposite of veiled is unveiled
The opposite of popular is unpopular
The opposite of comfortable is
2024-07-26 18:32:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 18:34:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3806, -0.4314, -0.1782,  ..., -0.3281, -0.2122,  0.3191],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1484, -0.9922,  1.7764,  ..., -1.8320,  0.1777,  1.3398],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0773,  0.0007,  0.0115,  ..., -0.0133, -0.0093,  0.0170],
        [ 0.0004,  0.0922, -0.0131,  ...,  0.0003,  0.0166,  0.0144],
        [ 0.0077, -0.0114,  0.0544,  ...,  0.0201, -0.0108,  0.0068],
        ...,
        [ 0.0138,  0.0220, -0.0364,  ...,  0.0608,  0.0030, -0.0061],
        [-0.0201,  0.0015, -0.0055,  ..., -0.0140,  0.0520,  0.0065],
        [-0.0307, -0.0269, -0.0169,  ...,  0.0124, -0.0050,  0.0858]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9785, -1.0332,  1.3984,  ..., -1.4316, -0.2786,  1.0693]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 18:34:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of able is unable
The opposite of aware is unaware
The opposite of certain is uncertain
The opposite of lucky is unlucky
The opposite of sustainable is unsustainable
The opposite of veiled is unveiled
The opposite of popular is unpopular
The opposite of comfortable is
2024-07-26 18:34:29 root INFO     [order_1_approx] starting weight calculation for The opposite of popular is unpopular
The opposite of lucky is unlucky
The opposite of sustainable is unsustainable
The opposite of veiled is unveiled
The opposite of able is unable
The opposite of certain is uncertain
The opposite of comfortable is uncomfortable
The opposite of aware is
2024-07-26 18:34:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 18:36:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2922,  0.3730, -0.5542,  ..., -0.2527, -0.0288,  0.1765],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0312, -2.7090,  3.2695,  ..., -2.4375, -2.3535, -1.0762],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0751, -0.0094, -0.0030,  ...,  0.0116, -0.0253,  0.0248],
        [-0.0024,  0.0656, -0.0001,  ...,  0.0085,  0.0138,  0.0010],
        [ 0.0005, -0.0179,  0.0575,  ...,  0.0164, -0.0249,  0.0063],
        ...,
        [ 0.0204,  0.0167,  0.0019,  ...,  0.0418,  0.0001, -0.0144],
        [-0.0191,  0.0025,  0.0119,  ...,  0.0025,  0.0373, -0.0196],
        [ 0.0092,  0.0040, -0.0015,  ...,  0.0141, -0.0164,  0.0564]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0820, -2.6309,  2.6895,  ..., -1.9092, -2.5566, -0.8354]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 18:36:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of popular is unpopular
The opposite of lucky is unlucky
The opposite of sustainable is unsustainable
The opposite of veiled is unveiled
The opposite of able is unable
The opposite of certain is uncertain
The opposite of comfortable is uncomfortable
The opposite of aware is
2024-07-26 18:36:50 root INFO     [order_1_approx] starting weight calculation for The opposite of certain is uncertain
The opposite of aware is unaware
The opposite of popular is unpopular
The opposite of comfortable is uncomfortable
The opposite of lucky is unlucky
The opposite of sustainable is unsustainable
The opposite of able is unable
The opposite of veiled is
2024-07-26 18:36:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 18:39:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1301, -0.5376, -0.3701,  ...,  0.0267, -0.0263,  0.1913],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8901, -0.0093,  0.1660,  ...,  2.9961, -3.0273,  0.2559],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0593, -0.0040,  0.0095,  ...,  0.0229, -0.0035, -0.0046],
        [ 0.0013,  0.0779, -0.0184,  ...,  0.0259, -0.0047, -0.0070],
        [ 0.0183, -0.0026,  0.0616,  ...,  0.0086, -0.0290,  0.0048],
        ...,
        [ 0.0018,  0.0010,  0.0191,  ...,  0.0674,  0.0062,  0.0060],
        [ 0.0239, -0.0023,  0.0074,  ...,  0.0012,  0.0749,  0.0031],
        [-0.0080, -0.0130, -0.0005,  ...,  0.0051, -0.0028,  0.0850]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2920,  0.1105, -0.1160,  ...,  3.1836, -3.2754,  0.2131]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 18:39:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of certain is uncertain
The opposite of aware is unaware
The opposite of popular is unpopular
The opposite of comfortable is uncomfortable
The opposite of lucky is unlucky
The opposite of sustainable is unsustainable
The opposite of able is unable
The opposite of veiled is
2024-07-26 18:39:13 root INFO     [order_1_approx] starting weight calculation for The opposite of sustainable is unsustainable
The opposite of veiled is unveiled
The opposite of certain is uncertain
The opposite of aware is unaware
The opposite of able is unable
The opposite of popular is unpopular
The opposite of comfortable is uncomfortable
The opposite of lucky is
2024-07-26 18:39:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 18:41:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3115,  0.2942, -0.1619,  ..., -0.1576, -0.1919,  0.2363],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5781, -1.0449, -0.9336,  ..., -2.9668,  0.3818, -2.0508],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.7637e-02, -1.6876e-02, -8.2779e-03,  ...,  2.6932e-03,
         -3.3813e-02,  2.5616e-03],
        [ 4.6387e-03,  3.0365e-02,  9.7942e-04,  ...,  2.9343e-02,
         -1.6346e-03,  1.4206e-02],
        [ 9.4757e-03, -1.4130e-02,  2.6962e-02,  ..., -1.5411e-03,
         -2.1637e-02, -2.6413e-02],
        ...,
        [ 2.4605e-03,  2.1179e-02,  1.1978e-02,  ...,  2.7740e-02,
          2.1820e-02, -7.4387e-05],
        [ 1.0658e-02,  9.3079e-03,  8.7128e-03,  ...,  5.4932e-03,
          4.7485e-02, -4.3678e-03],
        [-1.7456e-02, -1.3969e-02,  5.6171e-04,  ...,  2.6855e-02,
          5.7449e-03,  5.1880e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5464, -0.8511, -0.8501,  ..., -2.9277,  0.4028, -2.0430]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 18:41:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of sustainable is unsustainable
The opposite of veiled is unveiled
The opposite of certain is uncertain
The opposite of aware is unaware
The opposite of able is unable
The opposite of popular is unpopular
The opposite of comfortable is uncomfortable
The opposite of lucky is
2024-07-26 18:41:33 root INFO     [order_1_approx] starting weight calculation for The opposite of veiled is unveiled
The opposite of able is unable
The opposite of comfortable is uncomfortable
The opposite of aware is unaware
The opposite of certain is uncertain
The opposite of popular is unpopular
The opposite of lucky is unlucky
The opposite of sustainable is
2024-07-26 18:41:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 18:43:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4558,  0.0864, -0.5078,  ..., -0.0969, -0.1467, -0.0335],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9932, -3.7109,  0.6650,  ..., -3.1289, -2.5098, -0.6289],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0395,  0.0176, -0.0020,  ...,  0.0013, -0.0279,  0.0029],
        [-0.0119,  0.0300,  0.0142,  ...,  0.0118,  0.0396,  0.0160],
        [-0.0026,  0.0003,  0.0242,  ...,  0.0025, -0.0290, -0.0022],
        ...,
        [ 0.0119,  0.0032, -0.0063,  ...,  0.0030,  0.0118, -0.0110],
        [-0.0164,  0.0289,  0.0278,  ..., -0.0074,  0.0352,  0.0006],
        [-0.0033, -0.0069, -0.0131,  ..., -0.0033,  0.0069,  0.0179]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0996, -3.5312,  1.1494,  ..., -2.7031, -2.1660, -0.5859]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 18:43:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of veiled is unveiled
The opposite of able is unable
The opposite of comfortable is uncomfortable
The opposite of aware is unaware
The opposite of certain is uncertain
The opposite of popular is unpopular
The opposite of lucky is unlucky
The opposite of sustainable is
2024-07-26 18:43:55 root INFO     [order_1_approx] starting weight calculation for The opposite of comfortable is uncomfortable
The opposite of sustainable is unsustainable
The opposite of lucky is unlucky
The opposite of veiled is unveiled
The opposite of aware is unaware
The opposite of popular is unpopular
The opposite of certain is uncertain
The opposite of able is
2024-07-26 18:43:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 18:46:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4573, -0.0739, -0.2234,  ..., -0.5557,  0.0495,  0.0558],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1846, -5.7422,  2.5020,  ...,  0.5806, -1.8164, -1.4785],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0690, -0.0003,  0.0201,  ...,  0.0064, -0.0464,  0.0165],
        [-0.0068,  0.0573, -0.0073,  ...,  0.0351,  0.0400,  0.0240],
        [ 0.0090,  0.0046,  0.0158,  ..., -0.0230, -0.0138, -0.0046],
        ...,
        [-0.0163,  0.0196, -0.0150,  ...,  0.0139,  0.0296, -0.0044],
        [-0.0380, -0.0045,  0.0144,  ...,  0.0099,  0.0186, -0.0150],
        [ 0.0289, -0.0189, -0.0160,  ..., -0.0240, -0.0135,  0.0475]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0566, -5.2031,  2.2930,  ...,  1.2734, -1.8633, -1.6797]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 18:46:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of comfortable is uncomfortable
The opposite of sustainable is unsustainable
The opposite of lucky is unlucky
The opposite of veiled is unveiled
The opposite of aware is unaware
The opposite of popular is unpopular
The opposite of certain is uncertain
The opposite of able is
2024-07-26 18:46:09 root INFO     total operator prediction time: 1120.8736577033997 seconds
2024-07-26 18:46:09 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+able_reg
2024-07-26 18:46:09 root INFO     building operator verb+able_reg
2024-07-26 18:46:09 root INFO     [order_1_approx] starting weight calculation for If you can discover something, that thing is discoverable
If you can dispose something, that thing is disposable
If you can afford something, that thing is affordable
If you can improve something, that thing is improvable
If you can recommend something, that thing is recommendable
If you can prefer something, that thing is preferable
If you can extend something, that thing is extendable
If you can manage something, that thing is
2024-07-26 18:46:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 18:48:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4839,  0.5303, -0.1326,  ...,  0.0287,  0.0049, -0.0811],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.1377, -0.6206, -0.6343,  ..., -3.6133, -5.9375, -2.9023],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0338,  0.0088,  0.0033,  ...,  0.0078, -0.0094,  0.0433],
        [-0.0142,  0.0439,  0.0170,  ...,  0.0086, -0.0139, -0.0074],
        [ 0.0148, -0.0186,  0.0258,  ..., -0.0141,  0.0028, -0.0206],
        ...,
        [ 0.0252,  0.0085,  0.0044,  ...,  0.0485,  0.0128, -0.0054],
        [ 0.0145,  0.0047,  0.0027,  ..., -0.0221,  0.0284, -0.0120],
        [-0.0135,  0.0074,  0.0033,  ..., -0.0235, -0.0130,  0.0081]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.5859, -0.7139, -0.8096,  ..., -3.6445, -6.0078, -2.9199]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 18:48:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can discover something, that thing is discoverable
If you can dispose something, that thing is disposable
If you can afford something, that thing is affordable
If you can improve something, that thing is improvable
If you can recommend something, that thing is recommendable
If you can prefer something, that thing is preferable
If you can extend something, that thing is extendable
If you can manage something, that thing is
2024-07-26 18:48:28 root INFO     [order_1_approx] starting weight calculation for If you can prefer something, that thing is preferable
If you can afford something, that thing is affordable
If you can recommend something, that thing is recommendable
If you can manage something, that thing is manageable
If you can extend something, that thing is extendable
If you can dispose something, that thing is disposable
If you can discover something, that thing is discoverable
If you can improve something, that thing is
2024-07-26 18:48:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 18:50:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1848, -0.1812, -0.0216,  ...,  0.0451, -0.0496,  0.3423],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1094, -1.5410, -0.7749,  ..., -1.7676, -7.6953, -2.4609],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.3579e-02, -5.7335e-03,  6.1035e-03,  ...,  2.8702e-02,
         -5.2338e-03,  4.3365e-02],
        [-4.6272e-03,  5.3864e-02,  2.1790e-02,  ...,  2.5467e-02,
         -1.8951e-02,  1.6510e-02],
        [-7.5073e-03, -7.1487e-03,  3.0716e-02,  ...,  4.5242e-03,
          1.5251e-02, -1.9012e-02],
        ...,
        [ 1.1673e-03, -2.6283e-03, -3.7613e-03,  ...,  4.7791e-02,
          4.7445e-05, -4.3411e-03],
        [-4.3488e-03, -9.3536e-03, -1.2199e-02,  ..., -2.6917e-02,
          2.0935e-02, -7.3509e-03],
        [-1.4267e-02, -4.4250e-03,  2.8992e-03,  ..., -2.0218e-02,
         -1.8219e-02, -6.8665e-04]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9189, -1.8525, -0.5767,  ..., -1.4746, -7.6602, -2.6680]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 18:50:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can prefer something, that thing is preferable
If you can afford something, that thing is affordable
If you can recommend something, that thing is recommendable
If you can manage something, that thing is manageable
If you can extend something, that thing is extendable
If you can dispose something, that thing is disposable
If you can discover something, that thing is discoverable
If you can improve something, that thing is
2024-07-26 18:50:48 root INFO     [order_1_approx] starting weight calculation for If you can recommend something, that thing is recommendable
If you can improve something, that thing is improvable
If you can extend something, that thing is extendable
If you can prefer something, that thing is preferable
If you can manage something, that thing is manageable
If you can dispose something, that thing is disposable
If you can afford something, that thing is affordable
If you can discover something, that thing is
2024-07-26 18:50:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 18:53:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2820,  0.1080, -0.1138,  ..., -0.1438, -0.2659,  0.0464],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2627, -2.6250,  0.2205,  ..., -1.5537, -7.1094,  0.2324],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0703, -0.0046,  0.0127,  ...,  0.0150, -0.0019,  0.0352],
        [-0.0081,  0.0558,  0.0233,  ...,  0.0259, -0.0148,  0.0066],
        [-0.0030, -0.0166,  0.0632,  ..., -0.0034, -0.0170, -0.0054],
        ...,
        [ 0.0024,  0.0264, -0.0059,  ...,  0.0703,  0.0149,  0.0002],
        [ 0.0165,  0.0167, -0.0144,  ..., -0.0278,  0.0532, -0.0107],
        [ 0.0175,  0.0036,  0.0142,  ..., -0.0051, -0.0284,  0.0486]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4888, -2.8281,  0.2422,  ..., -1.4062, -6.9297, -0.0503]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 18:53:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can recommend something, that thing is recommendable
If you can improve something, that thing is improvable
If you can extend something, that thing is extendable
If you can prefer something, that thing is preferable
If you can manage something, that thing is manageable
If you can dispose something, that thing is disposable
If you can afford something, that thing is affordable
If you can discover something, that thing is
2024-07-26 18:53:08 root INFO     [order_1_approx] starting weight calculation for If you can extend something, that thing is extendable
If you can manage something, that thing is manageable
If you can improve something, that thing is improvable
If you can recommend something, that thing is recommendable
If you can afford something, that thing is affordable
If you can discover something, that thing is discoverable
If you can dispose something, that thing is disposable
If you can prefer something, that thing is
2024-07-26 18:53:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 18:55:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0118, -0.0763, -0.2571,  ...,  0.0129, -0.1150,  0.2522],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7578,  0.6035, -2.0273,  ..., -0.5830, -6.6016, -4.1484],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.6335e-02,  1.1040e-02, -1.6289e-03,  ...,  6.2752e-03,
         -1.1375e-02,  4.5532e-02],
        [-6.6910e-03,  6.5857e-02,  2.7710e-02,  ...,  2.3041e-02,
         -3.6469e-03,  6.3400e-03],
        [-1.8682e-03, -1.8173e-02,  3.8544e-02,  ...,  1.4114e-02,
         -1.4969e-02,  2.2411e-04],
        ...,
        [ 3.7270e-03,  6.2866e-03, -1.2672e-02,  ...,  6.3599e-02,
          1.5926e-03,  8.8043e-03],
        [ 1.5366e-02, -2.5330e-03,  9.6893e-03,  ..., -3.4058e-02,
          4.1748e-02, -3.5095e-03],
        [-1.8806e-03, -1.9012e-02, -3.9558e-03,  ..., -1.9745e-02,
          5.1498e-05,  3.1586e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7695,  0.2385, -1.7627,  ..., -0.5244, -6.3164, -4.1562]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 18:55:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can extend something, that thing is extendable
If you can manage something, that thing is manageable
If you can improve something, that thing is improvable
If you can recommend something, that thing is recommendable
If you can afford something, that thing is affordable
If you can discover something, that thing is discoverable
If you can dispose something, that thing is disposable
If you can prefer something, that thing is
2024-07-26 18:55:29 root INFO     [order_1_approx] starting weight calculation for If you can extend something, that thing is extendable
If you can discover something, that thing is discoverable
If you can afford something, that thing is affordable
If you can prefer something, that thing is preferable
If you can dispose something, that thing is disposable
If you can improve something, that thing is improvable
If you can manage something, that thing is manageable
If you can recommend something, that thing is
2024-07-26 18:55:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 18:57:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1509,  0.3962,  0.0414,  ...,  0.4041,  0.0919, -0.3003],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1475,  0.5664, -1.2246,  ..., -1.2910, -7.3906, -4.4805],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0494,  0.0067,  0.0161,  ...,  0.0312, -0.0053,  0.0451],
        [-0.0065,  0.0510,  0.0058,  ...,  0.0297, -0.0158,  0.0226],
        [ 0.0107,  0.0079,  0.0354,  ..., -0.0035, -0.0110, -0.0117],
        ...,
        [ 0.0014,  0.0172, -0.0068,  ...,  0.0700,  0.0005,  0.0145],
        [ 0.0233, -0.0054,  0.0005,  ..., -0.0210,  0.0215, -0.0143],
        [-0.0168, -0.0056, -0.0025,  ..., -0.0131, -0.0064,  0.0144]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2312,  0.6377, -1.5762,  ..., -1.0293, -7.5273, -4.5312]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 18:57:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can extend something, that thing is extendable
If you can discover something, that thing is discoverable
If you can afford something, that thing is affordable
If you can prefer something, that thing is preferable
If you can dispose something, that thing is disposable
If you can improve something, that thing is improvable
If you can manage something, that thing is manageable
If you can recommend something, that thing is
2024-07-26 18:57:49 root INFO     [order_1_approx] starting weight calculation for If you can recommend something, that thing is recommendable
If you can extend something, that thing is extendable
If you can dispose something, that thing is disposable
If you can manage something, that thing is manageable
If you can prefer something, that thing is preferable
If you can improve something, that thing is improvable
If you can discover something, that thing is discoverable
If you can afford something, that thing is
2024-07-26 18:57:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 19:00:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1238,  0.0095, -0.2390,  ...,  0.4053,  0.5752,  0.0351],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.4727, -1.0059, -3.4883,  ..., -2.3711, -8.9531, -1.3066],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0404,  0.0046,  0.0194,  ...,  0.0102, -0.0033,  0.0184],
        [-0.0158,  0.0396,  0.0123,  ...,  0.0159, -0.0157, -0.0177],
        [-0.0004,  0.0004,  0.0428,  ..., -0.0020, -0.0158, -0.0129],
        ...,
        [ 0.0179,  0.0198, -0.0075,  ...,  0.0499,  0.0213,  0.0035],
        [ 0.0147, -0.0124,  0.0130,  ..., -0.0156,  0.0264, -0.0223],
        [-0.0125, -0.0116, -0.0068,  ..., -0.0131, -0.0098,  0.0253]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.8867, -0.9077, -3.7109,  ..., -2.1152, -8.5312, -1.1836]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 19:00:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can recommend something, that thing is recommendable
If you can extend something, that thing is extendable
If you can dispose something, that thing is disposable
If you can manage something, that thing is manageable
If you can prefer something, that thing is preferable
If you can improve something, that thing is improvable
If you can discover something, that thing is discoverable
If you can afford something, that thing is
2024-07-26 19:00:08 root INFO     [order_1_approx] starting weight calculation for If you can discover something, that thing is discoverable
If you can improve something, that thing is improvable
If you can extend something, that thing is extendable
If you can prefer something, that thing is preferable
If you can recommend something, that thing is recommendable
If you can manage something, that thing is manageable
If you can afford something, that thing is affordable
If you can dispose something, that thing is
2024-07-26 19:00:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 19:02:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1866,  0.2949, -0.3259,  ..., -0.0133, -0.3723,  0.6641],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0557, -2.0977, -1.1914,  ..., -3.9688, -5.6953, -2.1797],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.7485e-02,  1.1627e-02, -9.4681e-03,  ...,  6.4201e-03,
         -2.3689e-03,  3.0640e-02],
        [-6.6414e-03,  4.3457e-02,  3.2684e-02,  ...,  3.8696e-02,
          7.6942e-03, -5.3024e-03],
        [ 1.7223e-03, -1.1854e-03,  4.0131e-02,  ..., -8.1406e-03,
         -7.3471e-03, -1.8829e-02],
        ...,
        [-2.0660e-02,  1.0780e-02, -2.9160e-02,  ...,  6.1096e-02,
          2.4628e-02, -1.2810e-02],
        [ 1.4324e-03, -4.4250e-04, -1.8906e-02,  ..., -3.1555e-02,
          4.6600e-02, -1.5625e-02],
        [-3.3150e-03, -4.6349e-03, -1.9550e-05,  ..., -8.5297e-03,
         -8.7051e-03,  3.3600e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9277, -2.0195, -1.4268,  ..., -3.7402, -5.4258, -2.3145]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 19:02:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can discover something, that thing is discoverable
If you can improve something, that thing is improvable
If you can extend something, that thing is extendable
If you can prefer something, that thing is preferable
If you can recommend something, that thing is recommendable
If you can manage something, that thing is manageable
If you can afford something, that thing is affordable
If you can dispose something, that thing is
2024-07-26 19:02:23 root INFO     [order_1_approx] starting weight calculation for If you can discover something, that thing is discoverable
If you can dispose something, that thing is disposable
If you can manage something, that thing is manageable
If you can recommend something, that thing is recommendable
If you can improve something, that thing is improvable
If you can prefer something, that thing is preferable
If you can afford something, that thing is affordable
If you can extend something, that thing is
2024-07-26 19:02:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 19:04:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0282, -0.0389, -0.3699,  ..., -0.2091, -0.0482,  0.1792],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8281, -2.0527, -2.2930,  ..., -3.4746, -7.8984, -4.7461],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0399, -0.0183, -0.0183,  ...,  0.0275,  0.0075,  0.0600],
        [-0.0129,  0.0805,  0.0229,  ...,  0.0185, -0.0092,  0.0039],
        [ 0.0137, -0.0046,  0.0464,  ...,  0.0035,  0.0134, -0.0208],
        ...,
        [ 0.0066,  0.0230, -0.0031,  ...,  0.0588,  0.0197,  0.0230],
        [ 0.0157, -0.0041,  0.0090,  ..., -0.0162,  0.0422, -0.0178],
        [-0.0056, -0.0031, -0.0122,  ..., -0.0168, -0.0241,  0.0282]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.0381, -2.2207, -2.4004,  ..., -3.3516, -7.7070, -4.5781]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 19:04:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can discover something, that thing is discoverable
If you can dispose something, that thing is disposable
If you can manage something, that thing is manageable
If you can recommend something, that thing is recommendable
If you can improve something, that thing is improvable
If you can prefer something, that thing is preferable
If you can afford something, that thing is affordable
If you can extend something, that thing is
2024-07-26 19:04:44 root INFO     total operator prediction time: 1115.3153636455536 seconds
2024-07-26 19:04:44 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+tion_irreg
2024-07-26 19:04:44 root INFO     building operator verb+tion_irreg
2024-07-26 19:04:44 root INFO     [order_1_approx] starting weight calculation for To standardize results in standardization
To oblige results in obligation
To compile results in compilation
To admire results in admiration
To configure results in configuration
To consult results in consulation
To aspire results in aspiration
To utilize results in
2024-07-26 19:04:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 19:07:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4275,  0.0780, -0.0083,  ...,  0.1011, -0.4875, -0.0851],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9072, -3.7422,  1.3008,  ...,  0.4297, -4.5547, -1.9658],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0147, -0.0127, -0.0347,  ..., -0.0154,  0.0375, -0.0101],
        [ 0.0293,  0.0551,  0.0417,  ...,  0.0198, -0.0172,  0.0235],
        [-0.0049, -0.0128,  0.0331,  ..., -0.0068,  0.0052, -0.0061],
        ...,
        [ 0.0256,  0.0091,  0.0175,  ...,  0.0549, -0.0253,  0.0130],
        [ 0.0095,  0.0037,  0.0114,  ...,  0.0073,  0.0222, -0.0058],
        [ 0.0236,  0.0108,  0.0124,  ...,  0.0038, -0.0269,  0.0400]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8584, -3.7695,  1.2422,  ...,  0.5713, -4.3945, -1.7480]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 19:07:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To standardize results in standardization
To oblige results in obligation
To compile results in compilation
To admire results in admiration
To configure results in configuration
To consult results in consulation
To aspire results in aspiration
To utilize results in
2024-07-26 19:07:06 root INFO     [order_1_approx] starting weight calculation for To admire results in admiration
To standardize results in standardization
To configure results in configuration
To compile results in compilation
To utilize results in utilization
To aspire results in aspiration
To consult results in consulation
To oblige results in
2024-07-26 19:07:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 19:09:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1444,  1.1338, -0.5156,  ..., -0.0024, -0.2114, -0.0540],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5703, -6.9766,  2.4336,  ...,  2.5977, -2.4629, -1.3428],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0253,  0.0008,  0.0005,  ..., -0.0177,  0.0025, -0.0043],
        [ 0.0221,  0.0620,  0.0120,  ...,  0.0470,  0.0016,  0.0078],
        [-0.0154, -0.0166,  0.0286,  ..., -0.0051,  0.0176,  0.0102],
        ...,
        [ 0.0043,  0.0026,  0.0079,  ...,  0.0747, -0.0045,  0.0267],
        [ 0.0081, -0.0095, -0.0002,  ...,  0.0189,  0.0623, -0.0195],
        [ 0.0125, -0.0071,  0.0170,  ...,  0.0154, -0.0150,  0.0610]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3496, -6.8477,  2.6953,  ...,  2.0098, -2.3828, -1.7168]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 19:09:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To admire results in admiration
To standardize results in standardization
To configure results in configuration
To compile results in compilation
To utilize results in utilization
To aspire results in aspiration
To consult results in consulation
To oblige results in
2024-07-26 19:09:28 root INFO     [order_1_approx] starting weight calculation for To admire results in admiration
To utilize results in utilization
To configure results in configuration
To aspire results in aspiration
To oblige results in obligation
To standardize results in standardization
To compile results in compilation
To consult results in
2024-07-26 19:09:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 19:11:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1976,  0.3081, -0.5371,  ..., -0.1824, -0.4036, -0.1151],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3945, -2.8223,  2.0000,  ...,  1.2061, -1.1289, -1.4766],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0519,  0.0067,  0.0164,  ...,  0.0074, -0.0042,  0.0276],
        [ 0.0089,  0.0536,  0.0022,  ...,  0.0369, -0.0135,  0.0216],
        [ 0.0032, -0.0139,  0.0583,  ..., -0.0222,  0.0132, -0.0033],
        ...,
        [-0.0129,  0.0019, -0.0022,  ...,  0.0702,  0.0056,  0.0087],
        [-0.0158, -0.0227,  0.0166,  ..., -0.0012,  0.0506, -0.0003],
        [ 0.0214, -0.0048, -0.0148,  ...,  0.0120, -0.0130,  0.0558]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5527, -2.6973,  2.1152,  ...,  1.2744, -1.4521, -1.3594]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 19:11:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To admire results in admiration
To utilize results in utilization
To configure results in configuration
To aspire results in aspiration
To oblige results in obligation
To standardize results in standardization
To compile results in compilation
To consult results in
2024-07-26 19:11:50 root INFO     [order_1_approx] starting weight calculation for To admire results in admiration
To consult results in consulation
To oblige results in obligation
To standardize results in standardization
To utilize results in utilization
To compile results in compilation
To aspire results in aspiration
To configure results in
2024-07-26 19:11:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 19:14:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0368,  0.0027, -0.8247,  ...,  0.0908, -0.2400, -0.1068],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2588, -3.8613,  3.0703,  ...,  3.8320, -2.0762, -0.5029],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0677,  0.0061,  0.0138,  ...,  0.0192,  0.0219,  0.0421],
        [ 0.0074,  0.0619,  0.0309,  ...,  0.0261,  0.0192,  0.0118],
        [-0.0058, -0.0206,  0.0373,  ..., -0.0122,  0.0104, -0.0294],
        ...,
        [-0.0106,  0.0074, -0.0065,  ...,  0.0638, -0.0107, -0.0371],
        [ 0.0069,  0.0066, -0.0088,  ..., -0.0253,  0.0562, -0.0216],
        [-0.0075,  0.0030, -0.0228,  ..., -0.0024, -0.0279,  0.0626]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0865, -3.8652,  2.8496,  ...,  3.7031, -2.1855, -0.5742]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 19:14:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To admire results in admiration
To consult results in consulation
To oblige results in obligation
To standardize results in standardization
To utilize results in utilization
To compile results in compilation
To aspire results in aspiration
To configure results in
2024-07-26 19:14:12 root INFO     [order_1_approx] starting weight calculation for To standardize results in standardization
To oblige results in obligation
To consult results in consulation
To utilize results in utilization
To configure results in configuration
To aspire results in aspiration
To compile results in compilation
To admire results in
2024-07-26 19:14:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 19:16:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0570,  0.4121, -0.2979,  ...,  0.2354,  0.1890,  0.4634],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.9844, -3.0742, -0.0796,  ...,  0.6538, -1.8379, -0.2988],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0256, -0.0183, -0.0121,  ..., -0.0300, -0.0002,  0.0007],
        [ 0.0131,  0.0311,  0.0258,  ...,  0.0220, -0.0106,  0.0142],
        [ 0.0037, -0.0157,  0.0294,  ...,  0.0078,  0.0043, -0.0107],
        ...,
        [ 0.0079, -0.0041,  0.0081,  ...,  0.0213,  0.0204,  0.0087],
        [-0.0133,  0.0023,  0.0069,  ...,  0.0008,  0.0263,  0.0008],
        [ 0.0005,  0.0017, -0.0196,  ..., -0.0055, -0.0145,  0.0323]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.9180, -3.1387, -0.4236,  ...,  0.9897, -2.4277, -0.2223]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 19:16:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To standardize results in standardization
To oblige results in obligation
To consult results in consulation
To utilize results in utilization
To configure results in configuration
To aspire results in aspiration
To compile results in compilation
To admire results in
2024-07-26 19:16:31 root INFO     [order_1_approx] starting weight calculation for To compile results in compilation
To oblige results in obligation
To utilize results in utilization
To consult results in consulation
To admire results in admiration
To configure results in configuration
To aspire results in aspiration
To standardize results in
2024-07-26 19:16:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 19:18:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0750,  0.3103, -0.6929,  ..., -0.0599, -0.2642, -0.0949],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7734, -4.9648,  1.1621,  ...,  1.8115, -3.5254, -2.9609],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0399,  0.0060, -0.0061,  ..., -0.0242,  0.0112,  0.0013],
        [ 0.0130,  0.0657,  0.0177,  ...,  0.0199, -0.0119,  0.0223],
        [-0.0056, -0.0085,  0.0459,  ...,  0.0099,  0.0153, -0.0123],
        ...,
        [-0.0026,  0.0032,  0.0160,  ...,  0.0619, -0.0204,  0.0107],
        [-0.0156,  0.0085,  0.0084,  ...,  0.0175,  0.0467, -0.0023],
        [-0.0064, -0.0052,  0.0106,  ...,  0.0142, -0.0345,  0.0613]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7344, -4.8477,  1.4561,  ...,  2.5488, -3.5098, -2.9395]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 19:18:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To compile results in compilation
To oblige results in obligation
To utilize results in utilization
To consult results in consulation
To admire results in admiration
To configure results in configuration
To aspire results in aspiration
To standardize results in
2024-07-26 19:18:45 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To oblige results in obligation
To configure results in configuration
To standardize results in standardization
To admire results in admiration
To utilize results in utilization
To consult results in consulation
To compile results in
2024-07-26 19:18:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 19:21:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0229, -0.0237, -0.5776,  ..., -0.1768, -0.2258,  0.1721],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7534, -4.2891,  4.4805,  ...,  0.9282, -1.3975,  0.3896],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0753,  0.0091,  0.0194,  ...,  0.0018,  0.0086,  0.0157],
        [ 0.0187,  0.0852,  0.0151,  ...,  0.0430, -0.0174,  0.0268],
        [-0.0094, -0.0381,  0.0438,  ..., -0.0090,  0.0136, -0.0198],
        ...,
        [ 0.0050, -0.0101,  0.0154,  ...,  0.0745, -0.0034, -0.0096],
        [-0.0164,  0.0061,  0.0012,  ..., -0.0075,  0.0820, -0.0204],
        [ 0.0108,  0.0025,  0.0280,  ...,  0.0115, -0.0137,  0.0811]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7183, -4.1523,  4.4141,  ...,  0.8516, -1.4473,  0.0479]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 19:21:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To aspire results in aspiration
To oblige results in obligation
To configure results in configuration
To standardize results in standardization
To admire results in admiration
To utilize results in utilization
To consult results in consulation
To compile results in
2024-07-26 19:21:01 root INFO     [order_1_approx] starting weight calculation for To configure results in configuration
To oblige results in obligation
To compile results in compilation
To standardize results in standardization
To utilize results in utilization
To consult results in consulation
To admire results in admiration
To aspire results in
2024-07-26 19:21:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 19:23:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.6064,  0.2603, -0.5186,  ...,  0.2522, -0.2874,  0.4041],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5332, -4.2383,  0.3071,  ...,  1.3496, -4.2031, -1.6934],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0300, -0.0034,  0.0079,  ..., -0.0173, -0.0082, -0.0069],
        [ 0.0051,  0.0433,  0.0150,  ...,  0.0272,  0.0164,  0.0220],
        [ 0.0124, -0.0122,  0.0262,  ..., -0.0130,  0.0038,  0.0047],
        ...,
        [-0.0039, -0.0128, -0.0137,  ...,  0.0503,  0.0087,  0.0177],
        [ 0.0152,  0.0056,  0.0104,  ...,  0.0128,  0.0290, -0.0065],
        [ 0.0073, -0.0049, -0.0029,  ...,  0.0024, -0.0093,  0.0420]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3848, -3.9570,  0.5308,  ...,  1.5771, -4.3477, -1.8564]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 19:23:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To configure results in configuration
To oblige results in obligation
To compile results in compilation
To standardize results in standardization
To utilize results in utilization
To consult results in consulation
To admire results in admiration
To aspire results in
2024-07-26 19:23:18 root INFO     total operator prediction time: 1113.420167684555 seconds
2024-07-26 19:23:18 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj+ly_reg
2024-07-26 19:23:18 root INFO     building operator adj+ly_reg
2024-07-26 19:23:18 root INFO     [order_1_approx] starting weight calculation for The adjective form of serious is seriously
The adjective form of environmental is environmentally
The adjective form of interesting is interestingly
The adjective form of visual is visually
The adjective form of extensive is extensively
The adjective form of rare is rarely
The adjective form of digital is digitally
The adjective form of clinical is
2024-07-26 19:23:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 19:25:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3394, -0.1538, -0.4233,  ..., -0.5347, -0.7617, -0.2415],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7559, -0.5527, -0.5254,  ..., -1.1562,  2.1758, -0.2246],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0684, -0.0224,  0.0110,  ...,  0.0112, -0.0161,  0.0219],
        [-0.0116,  0.0567, -0.0016,  ...,  0.0255,  0.0222,  0.0248],
        [-0.0085, -0.0174,  0.0450,  ..., -0.0002,  0.0096,  0.0043],
        ...,
        [ 0.0219,  0.0349, -0.0058,  ...,  0.0601, -0.0061,  0.0117],
        [ 0.0094,  0.0282,  0.0095,  ...,  0.0004,  0.0451, -0.0122],
        [-0.0049,  0.0037,  0.0205,  ..., -0.0128,  0.0010,  0.0486]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6597, -0.9951, -0.5312,  ..., -1.2080,  2.0625, -0.2231]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 19:25:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of serious is seriously
The adjective form of environmental is environmentally
The adjective form of interesting is interestingly
The adjective form of visual is visually
The adjective form of extensive is extensively
The adjective form of rare is rarely
The adjective form of digital is digitally
The adjective form of clinical is
2024-07-26 19:25:39 root INFO     [order_1_approx] starting weight calculation for The adjective form of extensive is extensively
The adjective form of serious is seriously
The adjective form of visual is visually
The adjective form of clinical is clinically
The adjective form of interesting is interestingly
The adjective form of environmental is environmentally
The adjective form of digital is digitally
The adjective form of rare is
2024-07-26 19:25:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 19:27:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1080, -0.0592, -0.7827,  ..., -0.1337,  0.0596, -0.2385],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.2715, -3.3477, -0.5806,  ..., -4.3867, -3.6250, -4.1758],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0925, -0.0188,  0.0367,  ..., -0.0126, -0.0064,  0.0145],
        [ 0.0237,  0.0682,  0.0253,  ...,  0.0314,  0.0030, -0.0019],
        [ 0.0283, -0.0256,  0.0638,  ..., -0.0139,  0.0082,  0.0188],
        ...,
        [ 0.0193,  0.0471,  0.0077,  ...,  0.0854, -0.0049,  0.0081],
        [-0.0112,  0.0352,  0.0237,  ...,  0.0107,  0.0535, -0.0070],
        [ 0.0090,  0.0196,  0.0042,  ..., -0.0099, -0.0157,  0.0441]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.4395, -3.6797, -0.5947,  ..., -4.4023, -3.8262, -4.2031]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 19:28:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of extensive is extensively
The adjective form of serious is seriously
The adjective form of visual is visually
The adjective form of clinical is clinically
The adjective form of interesting is interestingly
The adjective form of environmental is environmentally
The adjective form of digital is digitally
The adjective form of rare is
2024-07-26 19:28:00 root INFO     [order_1_approx] starting weight calculation for The adjective form of interesting is interestingly
The adjective form of environmental is environmentally
The adjective form of digital is digitally
The adjective form of clinical is clinically
The adjective form of rare is rarely
The adjective form of visual is visually
The adjective form of extensive is extensively
The adjective form of serious is
2024-07-26 19:28:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 19:30:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4348,  0.0480, -0.4639,  ...,  0.0269, -0.7642,  0.2910],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6006, -2.5742, -0.6387,  ..., -2.7070, -0.5459, -4.5820],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1000, -0.0103,  0.0140,  ...,  0.0048,  0.0240,  0.0158],
        [ 0.0122,  0.0573,  0.0025,  ...,  0.0084,  0.0089, -0.0065],
        [ 0.0132, -0.0032,  0.0675,  ...,  0.0065, -0.0031, -0.0011],
        ...,
        [-0.0028,  0.0264,  0.0012,  ...,  0.0802, -0.0031,  0.0149],
        [-0.0269,  0.0195,  0.0055,  ..., -0.0055,  0.0640, -0.0133],
        [ 0.0156, -0.0085,  0.0140,  ...,  0.0033, -0.0430,  0.0499]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8906, -2.3379, -0.4800,  ..., -2.8750, -0.2463, -4.6328]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 19:30:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of interesting is interestingly
The adjective form of environmental is environmentally
The adjective form of digital is digitally
The adjective form of clinical is clinically
The adjective form of rare is rarely
The adjective form of visual is visually
The adjective form of extensive is extensively
The adjective form of serious is
2024-07-26 19:30:13 root INFO     [order_1_approx] starting weight calculation for The adjective form of rare is rarely
The adjective form of digital is digitally
The adjective form of clinical is clinically
The adjective form of interesting is interestingly
The adjective form of extensive is extensively
The adjective form of visual is visually
The adjective form of serious is seriously
The adjective form of environmental is
2024-07-26 19:30:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 19:32:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5269, -0.1211, -0.1520,  ..., -0.4099, -0.5747, -0.2688],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1768, -0.3940, -0.3989,  ..., -2.6309, -1.4736, -3.5156],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.0350e-02,  8.9359e-04,  1.3718e-02,  ..., -2.1400e-03,
          6.2866e-03,  2.1286e-02],
        [-8.4991e-03,  9.0637e-02,  2.0874e-02,  ...,  1.2932e-03,
          5.1498e-03, -1.5884e-02],
        [-7.6294e-05,  1.0109e-03,  5.0354e-02,  ...,  2.4353e-02,
          1.6403e-03,  1.0025e-02],
        ...,
        [ 6.1264e-03,  1.6724e-02, -3.3844e-02,  ...,  2.5757e-02,
         -3.0365e-03, -1.8930e-03],
        [ 4.2877e-03,  6.1188e-03, -2.1469e-02,  ..., -3.2440e-02,
          6.0364e-02, -1.0887e-02],
        [ 7.6447e-03,  8.0032e-03,  1.7776e-02,  ...,  2.3575e-02,
         -3.4241e-02,  4.2572e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1831, -0.5996, -0.4653,  ..., -2.2891, -1.4678, -3.8809]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 19:32:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of rare is rarely
The adjective form of digital is digitally
The adjective form of clinical is clinically
The adjective form of interesting is interestingly
The adjective form of extensive is extensively
The adjective form of visual is visually
The adjective form of serious is seriously
The adjective form of environmental is
2024-07-26 19:32:33 root INFO     [order_1_approx] starting weight calculation for The adjective form of environmental is environmentally
The adjective form of rare is rarely
The adjective form of serious is seriously
The adjective form of visual is visually
The adjective form of digital is digitally
The adjective form of interesting is interestingly
The adjective form of clinical is clinically
The adjective form of extensive is
2024-07-26 19:32:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 19:34:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3066, -0.0780, -0.5400,  ..., -0.2206, -0.3149, -0.0132],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4180, -1.5342, -1.8301,  ..., -1.9258, -1.0322, -4.2305],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0864, -0.0302, -0.0201,  ...,  0.0231,  0.0080,  0.0157],
        [ 0.0105,  0.0923,  0.0073,  ..., -0.0122,  0.0033,  0.0041],
        [ 0.0433, -0.0174,  0.0413,  ..., -0.0059, -0.0002,  0.0154],
        ...,
        [ 0.0330,  0.0070,  0.0251,  ...,  0.0858,  0.0158,  0.0095],
        [-0.0173,  0.0311,  0.0062,  ...,  0.0050,  0.0543,  0.0042],
        [ 0.0157,  0.0136,  0.0104,  ..., -0.0212,  0.0012,  0.0265]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2930, -2.1035, -1.9141,  ..., -2.2168, -0.6924, -4.0195]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 19:34:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of environmental is environmentally
The adjective form of rare is rarely
The adjective form of serious is seriously
The adjective form of visual is visually
The adjective form of digital is digitally
The adjective form of interesting is interestingly
The adjective form of clinical is clinically
The adjective form of extensive is
2024-07-26 19:34:52 root INFO     [order_1_approx] starting weight calculation for The adjective form of rare is rarely
The adjective form of serious is seriously
The adjective form of clinical is clinically
The adjective form of environmental is environmentally
The adjective form of extensive is extensively
The adjective form of visual is visually
The adjective form of interesting is interestingly
The adjective form of digital is
2024-07-26 19:34:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 19:37:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1143,  0.1986, -0.4624,  ..., -0.0602, -0.5698,  0.0043],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1855, -0.7036,  0.4294,  ..., -2.3711, -1.9023, -0.5996],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0729, -0.0320,  0.0010,  ...,  0.0190, -0.0036,  0.0013],
        [ 0.0134,  0.0650,  0.0287,  ...,  0.0193,  0.0013, -0.0030],
        [ 0.0181, -0.0169,  0.0500,  ...,  0.0158,  0.0328,  0.0082],
        ...,
        [-0.0091,  0.0291, -0.0080,  ...,  0.0334,  0.0082, -0.0055],
        [ 0.0009,  0.0194, -0.0045,  ..., -0.0178,  0.0526, -0.0046],
        [-0.0142,  0.0090, -0.0330,  ..., -0.0128, -0.0090,  0.0420]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0959, -1.3457,  0.3118,  ..., -1.7207, -1.6738, -0.5020]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 19:37:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of rare is rarely
The adjective form of serious is seriously
The adjective form of clinical is clinically
The adjective form of environmental is environmentally
The adjective form of extensive is extensively
The adjective form of visual is visually
The adjective form of interesting is interestingly
The adjective form of digital is
2024-07-26 19:37:14 root INFO     [order_1_approx] starting weight calculation for The adjective form of digital is digitally
The adjective form of extensive is extensively
The adjective form of rare is rarely
The adjective form of serious is seriously
The adjective form of visual is visually
The adjective form of environmental is environmentally
The adjective form of clinical is clinically
The adjective form of interesting is
2024-07-26 19:37:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 19:39:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0797,  0.0786, -0.1777,  ...,  0.0892, -0.5981, -0.4104],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9839, -1.9326,  1.2520,  ..., -1.8760, -1.7383, -2.0977],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.9774e-02, -1.4359e-02,  1.2268e-02,  ..., -3.3447e-02,
          2.3666e-02,  6.0387e-03],
        [-3.0518e-05,  6.9031e-02,  6.9275e-03,  ...,  3.0098e-03,
          1.1063e-02, -1.7151e-02],
        [ 3.9520e-02, -2.2907e-03,  6.6956e-02,  ...,  2.3468e-02,
          4.8447e-03,  2.8343e-03],
        ...,
        [ 1.7685e-02,  1.7075e-02, -1.8875e-02,  ...,  7.0435e-02,
         -4.9286e-03,  1.9073e-02],
        [ 1.5358e-02,  2.1957e-02,  2.1530e-02,  ...,  1.4023e-02,
          3.0472e-02,  2.6512e-04],
        [-6.6071e-03,  2.2369e-02,  7.3547e-03,  ..., -2.0721e-02,
         -1.9104e-02,  2.2720e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1777, -1.9590,  1.6797,  ..., -2.0410, -1.3711, -2.0859]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 19:39:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of digital is digitally
The adjective form of extensive is extensively
The adjective form of rare is rarely
The adjective form of serious is seriously
The adjective form of visual is visually
The adjective form of environmental is environmentally
The adjective form of clinical is clinically
The adjective form of interesting is
2024-07-26 19:39:36 root INFO     [order_1_approx] starting weight calculation for The adjective form of extensive is extensively
The adjective form of serious is seriously
The adjective form of clinical is clinically
The adjective form of environmental is environmentally
The adjective form of digital is digitally
The adjective form of rare is rarely
The adjective form of interesting is interestingly
The adjective form of visual is
2024-07-26 19:39:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 19:41:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3010,  0.0259, -0.1499,  ..., -0.3320, -0.4014, -0.2957],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1006, -2.9590,  1.1670,  ..., -2.4961, -0.8911, -1.5068],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0771, -0.0223, -0.0095,  ..., -0.0023, -0.0107,  0.0119],
        [ 0.0011,  0.0784,  0.0064,  ...,  0.0237, -0.0233, -0.0045],
        [ 0.0197, -0.0216,  0.0579,  ...,  0.0279, -0.0202,  0.0193],
        ...,
        [ 0.0338,  0.0295, -0.0146,  ...,  0.0547, -0.0112, -0.0142],
        [ 0.0220,  0.0226, -0.0238,  ..., -0.0219,  0.0708,  0.0009],
        [-0.0352,  0.0227, -0.0008,  ...,  0.0014,  0.0026,  0.0268]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6904, -3.1777,  0.7700,  ..., -2.3887, -0.7734, -1.2891]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 19:41:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of extensive is extensively
The adjective form of serious is seriously
The adjective form of clinical is clinically
The adjective form of environmental is environmentally
The adjective form of digital is digitally
The adjective form of rare is rarely
The adjective form of interesting is interestingly
The adjective form of visual is
2024-07-26 19:41:58 root INFO     total operator prediction time: 1119.9310998916626 seconds
2024-07-26 19:41:58 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on over+adj_reg
2024-07-26 19:41:58 root INFO     building operator over+adj_reg
2024-07-26 19:41:58 root INFO     [order_1_approx] starting weight calculation for If something is too confident, it is overconfident
If something is too booked, it is overbooked
If something is too paid, it is overpaid
If something is too laid, it is overlaid
If something is too sized, it is oversized
If something is too subscribed, it is oversubscribed
If something is too spent, it is overspent
If something is too heated, it is
2024-07-26 19:41:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 19:44:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2632, -0.6821, -0.4685,  ..., -0.0801, -0.3335,  0.2484],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7100, -2.3730,  0.5371,  ..., -0.3774, -2.4727, -1.1240],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0813, -0.0036, -0.0126,  ..., -0.0129,  0.0178,  0.0025],
        [ 0.0142,  0.0696,  0.0041,  ...,  0.0111, -0.0055, -0.0055],
        [-0.0112,  0.0109,  0.0448,  ...,  0.0128,  0.0027,  0.0109],
        ...,
        [-0.0035,  0.0175,  0.0043,  ...,  0.0693,  0.0216,  0.0196],
        [ 0.0065, -0.0067, -0.0083,  ...,  0.0027,  0.0587, -0.0242],
        [-0.0102,  0.0004,  0.0173,  ...,  0.0062, -0.0185,  0.0693]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2305, -2.3555,  0.2351,  ..., -0.3362, -2.4258, -1.0391]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 19:44:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too confident, it is overconfident
If something is too booked, it is overbooked
If something is too paid, it is overpaid
If something is too laid, it is overlaid
If something is too sized, it is oversized
If something is too subscribed, it is oversubscribed
If something is too spent, it is overspent
If something is too heated, it is
2024-07-26 19:44:16 root INFO     [order_1_approx] starting weight calculation for If something is too confident, it is overconfident
If something is too subscribed, it is oversubscribed
If something is too heated, it is overheated
If something is too laid, it is overlaid
If something is too sized, it is oversized
If something is too paid, it is overpaid
If something is too booked, it is overbooked
If something is too spent, it is
2024-07-26 19:44:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 19:46:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1807, -0.3359, -0.5635,  ..., -0.3320, -0.1501, -0.1437],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6250, -3.8203, -0.6924,  ..., -1.2100, -2.2051, -2.4258],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0684, -0.0061,  0.0034,  ...,  0.0013,  0.0119,  0.0221],
        [-0.0148,  0.0565, -0.0171,  ...,  0.0287, -0.0075,  0.0070],
        [ 0.0222,  0.0028,  0.0559,  ...,  0.0004, -0.0192, -0.0076],
        ...,
        [ 0.0135,  0.0009, -0.0226,  ...,  0.0759,  0.0105,  0.0044],
        [-0.0086,  0.0119, -0.0081,  ...,  0.0185,  0.0507, -0.0200],
        [-0.0209,  0.0126,  0.0050,  ...,  0.0010,  0.0017,  0.0726]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5547, -4.1680, -0.6602,  ..., -0.7520, -1.6621, -2.4258]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 19:46:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too confident, it is overconfident
If something is too subscribed, it is oversubscribed
If something is too heated, it is overheated
If something is too laid, it is overlaid
If something is too sized, it is oversized
If something is too paid, it is overpaid
If something is too booked, it is overbooked
If something is too spent, it is
2024-07-26 19:46:34 root INFO     [order_1_approx] starting weight calculation for If something is too sized, it is oversized
If something is too heated, it is overheated
If something is too laid, it is overlaid
If something is too spent, it is overspent
If something is too confident, it is overconfident
If something is too paid, it is overpaid
If something is too booked, it is overbooked
If something is too subscribed, it is
2024-07-26 19:46:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 19:48:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2285, -0.1772, -0.4619,  ..., -0.0708, -0.0504,  0.0408],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9160, -3.8711,  1.3779,  ...,  0.3923, -2.2539, -1.6475],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0367, -0.0323, -0.0043,  ..., -0.0045,  0.0036, -0.0007],
        [-0.0054,  0.0297,  0.0119,  ...,  0.0015, -0.0084, -0.0145],
        [ 0.0024,  0.0017,  0.0183,  ..., -0.0027, -0.0085,  0.0079],
        ...,
        [ 0.0048,  0.0071, -0.0067,  ...,  0.0323,  0.0219,  0.0048],
        [ 0.0020,  0.0209, -0.0019,  ...,  0.0017,  0.0334, -0.0167],
        [ 0.0014,  0.0078, -0.0006,  ..., -0.0172, -0.0062,  0.0504]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1045, -3.8027,  1.3779,  ...,  0.7153, -2.0488, -1.6143]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 19:48:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too sized, it is oversized
If something is too heated, it is overheated
If something is too laid, it is overlaid
If something is too spent, it is overspent
If something is too confident, it is overconfident
If something is too paid, it is overpaid
If something is too booked, it is overbooked
If something is too subscribed, it is
2024-07-26 19:48:55 root INFO     [order_1_approx] starting weight calculation for If something is too heated, it is overheated
If something is too subscribed, it is oversubscribed
If something is too confident, it is overconfident
If something is too spent, it is overspent
If something is too paid, it is overpaid
If something is too booked, it is overbooked
If something is too sized, it is oversized
If something is too laid, it is
2024-07-26 19:48:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 19:51:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3818,  0.2844, -0.5146,  ..., -0.4380, -0.3401,  0.2020],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2275, -2.3125,  0.6499,  ...,  0.9824, -2.3750, -1.5625],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0988, -0.0087, -0.0046,  ..., -0.0129, -0.0060,  0.0157],
        [ 0.0014,  0.0536,  0.0042,  ...,  0.0073, -0.0058, -0.0046],
        [ 0.0142, -0.0167,  0.0706,  ..., -0.0061, -0.0170, -0.0223],
        ...,
        [ 0.0045,  0.0339, -0.0166,  ...,  0.0877,  0.0245,  0.0101],
        [-0.0102, -0.0098, -0.0199,  ...,  0.0064,  0.0707, -0.0544],
        [-0.0129, -0.0038,  0.0013,  ...,  0.0077,  0.0110,  0.0824]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4561, -2.2617,  0.1377,  ...,  1.2373, -2.3125, -1.2930]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 19:51:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too heated, it is overheated
If something is too subscribed, it is oversubscribed
If something is too confident, it is overconfident
If something is too spent, it is overspent
If something is too paid, it is overpaid
If something is too booked, it is overbooked
If something is too sized, it is oversized
If something is too laid, it is
2024-07-26 19:51:14 root INFO     [order_1_approx] starting weight calculation for If something is too paid, it is overpaid
If something is too heated, it is overheated
If something is too subscribed, it is oversubscribed
If something is too sized, it is oversized
If something is too spent, it is overspent
If something is too laid, it is overlaid
If something is too booked, it is overbooked
If something is too confident, it is
2024-07-26 19:51:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 19:53:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0834, -0.0616, -0.4968,  ...,  0.4741,  0.0032,  0.0145],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9824, -4.0742,  2.5977,  ...,  2.0664, -2.5820, -0.6670],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.2551e-02, -1.3298e-02, -3.7270e-03,  ..., -1.0895e-02,
          7.6294e-05,  2.3514e-02],
        [ 2.1622e-02,  3.3478e-02,  1.2146e-02,  ...,  6.3515e-03,
          6.3858e-03,  8.0261e-03],
        [-1.6842e-03,  4.4556e-03,  3.3997e-02,  ...,  4.7112e-04,
         -2.9755e-03,  6.8703e-03],
        ...,
        [-4.0665e-03,  2.4376e-03,  8.3237e-03,  ...,  6.4514e-02,
          1.3359e-02,  3.8910e-04],
        [ 3.8853e-03,  1.2154e-02,  1.4938e-02,  ...,  1.6602e-02,
          3.5339e-02, -1.4656e-02],
        [-1.1311e-03, -4.6158e-03,  4.9782e-03,  ..., -1.7185e-03,
         -8.9340e-03,  3.8544e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4570, -3.7676,  2.4160,  ...,  1.9775, -2.6621, -0.9673]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 19:53:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too paid, it is overpaid
If something is too heated, it is overheated
If something is too subscribed, it is oversubscribed
If something is too sized, it is oversized
If something is too spent, it is overspent
If something is too laid, it is overlaid
If something is too booked, it is overbooked
If something is too confident, it is
2024-07-26 19:53:34 root INFO     [order_1_approx] starting weight calculation for If something is too subscribed, it is oversubscribed
If something is too booked, it is overbooked
If something is too sized, it is oversized
If something is too spent, it is overspent
If something is too confident, it is overconfident
If something is too laid, it is overlaid
If something is too heated, it is overheated
If something is too paid, it is
2024-07-26 19:53:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 19:55:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1926, -0.7441, -0.7930,  ..., -0.2241, -0.2423, -0.1270],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4219, -3.7734, -0.6201,  ..., -1.4141, -2.9023, -1.9736],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0630, -0.0092,  0.0130,  ..., -0.0138,  0.0011,  0.0410],
        [ 0.0108,  0.0327, -0.0043,  ...,  0.0323, -0.0055, -0.0034],
        [ 0.0373,  0.0079,  0.0480,  ...,  0.0258,  0.0117,  0.0145],
        ...,
        [ 0.0104, -0.0035, -0.0388,  ...,  0.0849,  0.0457,  0.0194],
        [-0.0093, -0.0028, -0.0100,  ...,  0.0063,  0.0805, -0.0414],
        [-0.0060, -0.0060, -0.0068,  ..., -0.0018, -0.0081,  0.0663]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4414, -3.6191, -0.2839,  ..., -1.0391, -2.9766, -1.9404]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 19:55:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too subscribed, it is oversubscribed
If something is too booked, it is overbooked
If something is too sized, it is oversized
If something is too spent, it is overspent
If something is too confident, it is overconfident
If something is too laid, it is overlaid
If something is too heated, it is overheated
If something is too paid, it is
2024-07-26 19:55:54 root INFO     [order_1_approx] starting weight calculation for If something is too booked, it is overbooked
If something is too laid, it is overlaid
If something is too confident, it is overconfident
If something is too spent, it is overspent
If something is too subscribed, it is oversubscribed
If something is too heated, it is overheated
If something is too paid, it is overpaid
If something is too sized, it is
2024-07-26 19:55:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 19:58:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0464, -0.7007, -0.7969,  ..., -0.3247, -0.1204, -0.0978],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1895, -3.9199, -1.3145,  ...,  0.3164, -3.6406,  0.4424],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 8.8013e-02, -2.1225e-02,  4.9362e-03,  ..., -1.2070e-02,
          1.8524e-02,  7.6065e-03],
        [ 4.8752e-03,  6.3477e-02,  2.6512e-03,  ..., -5.6610e-03,
         -2.3499e-02, -1.3931e-02],
        [ 2.4384e-02, -4.9019e-03,  6.2805e-02,  ..., -1.4359e-02,
          6.4278e-03,  1.7563e-02],
        ...,
        [ 1.3336e-02, -1.4343e-02,  1.0445e-02,  ...,  9.2407e-02,
         -1.0262e-02,  4.1008e-05],
        [ 9.6741e-03,  1.3557e-02, -2.2293e-02,  ...,  2.0111e-02,
          8.0872e-02, -2.9556e-02],
        [-1.4565e-02,  1.7960e-02,  1.9760e-02,  ..., -8.4839e-03,
         -2.7420e-02,  6.1615e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4434, -3.6367, -1.5117,  ...,  0.6011, -3.5137,  0.7100]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 19:58:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too booked, it is overbooked
If something is too laid, it is overlaid
If something is too confident, it is overconfident
If something is too spent, it is overspent
If something is too subscribed, it is oversubscribed
If something is too heated, it is overheated
If something is too paid, it is overpaid
If something is too sized, it is
2024-07-26 19:58:15 root INFO     [order_1_approx] starting weight calculation for If something is too subscribed, it is oversubscribed
If something is too paid, it is overpaid
If something is too sized, it is oversized
If something is too laid, it is overlaid
If something is too confident, it is overconfident
If something is too heated, it is overheated
If something is too spent, it is overspent
If something is too booked, it is
2024-07-26 19:58:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 20:00:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0090, -0.3240, -0.4924,  ..., -0.2244,  0.1029,  0.4180],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0986, -3.9082,  0.8374,  ...,  1.0645,  0.0620, -2.1504],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.2795e-02, -2.1637e-02,  6.8283e-04,  ...,  1.3672e-02,
          1.5518e-02,  1.3298e-02],
        [-1.0559e-02,  4.4739e-02,  6.1607e-04,  ...,  7.9727e-03,
          9.9640e-03, -2.2163e-03],
        [-4.5776e-05,  5.0659e-03,  3.9185e-02,  ...,  1.3123e-03,
         -1.1339e-03, -1.9577e-02],
        ...,
        [ 1.1139e-02,  1.9264e-03, -2.1000e-03,  ...,  5.6183e-02,
          1.5160e-02,  2.8763e-03],
        [-7.6332e-03,  6.6071e-03,  3.6354e-03,  ..., -5.0354e-03,
          2.8427e-02, -3.3436e-03],
        [-6.8665e-05, -2.7180e-04, -3.7441e-03,  ..., -7.1602e-03,
          1.7481e-03,  5.0018e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1282, -3.7109,  0.6113,  ...,  1.2500,  0.2993, -2.1328]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 20:00:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too subscribed, it is oversubscribed
If something is too paid, it is overpaid
If something is too sized, it is oversized
If something is too laid, it is overlaid
If something is too confident, it is overconfident
If something is too heated, it is overheated
If something is too spent, it is overspent
If something is too booked, it is
2024-07-26 20:00:36 root INFO     total operator prediction time: 1117.8922743797302 seconds
2024-07-26 20:00:36 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+er_irreg
2024-07-26 20:00:36 root INFO     building operator verb+er_irreg
2024-07-26 20:00:36 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you suffer something, you are a sufferer
If you examine something, you are a examiner
If you organise something, you are a organiser
If you observe something, you are a observer
If you contend something, you are a contender
If you advertise something, you are a advertiser
If you choreograph something, you are a
2024-07-26 20:00:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 20:02:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0568,  0.4551, -0.4243,  ..., -0.0271, -0.4211,  0.0141],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1765, -2.9961,  2.8750,  ..., -1.1426, -3.3359, -2.1562],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0735, -0.0025,  0.0175,  ...,  0.0022,  0.0249, -0.0032],
        [ 0.0151,  0.0662, -0.0025,  ...,  0.0244,  0.0208, -0.0050],
        [-0.0091,  0.0004,  0.0338,  ..., -0.0109,  0.0038,  0.0123],
        ...,
        [ 0.0282,  0.0150, -0.0009,  ...,  0.0594, -0.0033, -0.0154],
        [ 0.0085,  0.0085, -0.0130,  ..., -0.0238,  0.0509, -0.0032],
        [-0.0047, -0.0198,  0.0096,  ..., -0.0070, -0.0104,  0.0368]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0576, -2.9531,  2.4746,  ..., -0.6499, -3.3906, -2.1094]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 20:02:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you deliver something, you are a deliverer
If you suffer something, you are a sufferer
If you examine something, you are a examiner
If you organise something, you are a organiser
If you observe something, you are a observer
If you contend something, you are a contender
If you advertise something, you are a advertiser
If you choreograph something, you are a
2024-07-26 20:02:55 root INFO     [order_1_approx] starting weight calculation for If you choreograph something, you are a choreographer
If you suffer something, you are a sufferer
If you contend something, you are a contender
If you observe something, you are a observer
If you examine something, you are a examiner
If you advertise something, you are a advertiser
If you deliver something, you are a deliverer
If you organise something, you are a
2024-07-26 20:02:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 20:05:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3030,  0.4995, -0.3193,  ..., -0.1335,  0.1963, -0.1467],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2173, -3.0898,  0.3750,  ...,  0.8789, -3.2539, -5.6523],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0548,  0.0110,  0.0100,  ..., -0.0050,  0.0030,  0.0115],
        [-0.0031,  0.0367,  0.0095,  ...,  0.0248,  0.0153, -0.0133],
        [-0.0077,  0.0019,  0.0120,  ..., -0.0131,  0.0007,  0.0019],
        ...,
        [ 0.0166,  0.0159,  0.0037,  ...,  0.0408,  0.0047, -0.0036],
        [-0.0204,  0.0144, -0.0042,  ..., -0.0085,  0.0193, -0.0067],
        [-0.0018, -0.0030,  0.0112,  ..., -0.0043,  0.0007,  0.0226]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3560, -3.1094,  0.5605,  ...,  0.6670, -3.2363, -5.6602]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 20:05:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you choreograph something, you are a choreographer
If you suffer something, you are a sufferer
If you contend something, you are a contender
If you observe something, you are a observer
If you examine something, you are a examiner
If you advertise something, you are a advertiser
If you deliver something, you are a deliverer
If you organise something, you are a
2024-07-26 20:05:15 root INFO     [order_1_approx] starting weight calculation for If you suffer something, you are a sufferer
If you contend something, you are a contender
If you advertise something, you are a advertiser
If you organise something, you are a organiser
If you examine something, you are a examiner
If you observe something, you are a observer
If you choreograph something, you are a choreographer
If you deliver something, you are a
2024-07-26 20:05:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 20:07:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0167,  0.3677, -0.1044,  ...,  0.2234,  0.1228,  0.1595],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.7891, -4.5469,  1.1299,  ...,  0.7666, -3.9609, -2.2598],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0719,  0.0170,  0.0172,  ...,  0.0042, -0.0081,  0.0085],
        [-0.0032,  0.0585,  0.0012,  ...,  0.0152,  0.0077, -0.0049],
        [ 0.0321,  0.0013,  0.0444,  ...,  0.0190, -0.0225, -0.0064],
        ...,
        [ 0.0279,  0.0217,  0.0019,  ...,  0.0685,  0.0020,  0.0137],
        [ 0.0043,  0.0060,  0.0076,  ..., -0.0151,  0.0368, -0.0142],
        [ 0.0074, -0.0255, -0.0051,  ..., -0.0059, -0.0222,  0.0521]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 6.0742, -4.5273,  0.7256,  ...,  0.7354, -4.2109, -2.0898]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 20:07:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you suffer something, you are a sufferer
If you contend something, you are a contender
If you advertise something, you are a advertiser
If you organise something, you are a organiser
If you examine something, you are a examiner
If you observe something, you are a observer
If you choreograph something, you are a choreographer
If you deliver something, you are a
2024-07-26 20:07:36 root INFO     [order_1_approx] starting weight calculation for If you choreograph something, you are a choreographer
If you examine something, you are a examiner
If you suffer something, you are a sufferer
If you deliver something, you are a deliverer
If you advertise something, you are a advertiser
If you organise something, you are a organiser
If you observe something, you are a observer
If you contend something, you are a
2024-07-26 20:07:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 20:09:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3413,  0.3696, -0.3853,  ..., -0.1582, -0.0007, -0.2246],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8555, -5.5781,  1.6875,  ..., -1.8945, -1.2578, -2.7773],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0471,  0.0090,  0.0248,  ...,  0.0284,  0.0082,  0.0199],
        [ 0.0033,  0.0452, -0.0021,  ...,  0.0079,  0.0211,  0.0107],
        [-0.0024, -0.0020,  0.0326,  ..., -0.0066,  0.0145, -0.0045],
        ...,
        [ 0.0226,  0.0154,  0.0166,  ...,  0.0371,  0.0272, -0.0033],
        [-0.0261,  0.0251,  0.0185,  ..., -0.0129,  0.0604, -0.0371],
        [ 0.0057,  0.0035,  0.0009,  ..., -0.0040, -0.0006,  0.0179]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7471, -5.8164,  2.0312,  ..., -1.5957, -1.4316, -2.6738]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 20:09:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you choreograph something, you are a choreographer
If you examine something, you are a examiner
If you suffer something, you are a sufferer
If you deliver something, you are a deliverer
If you advertise something, you are a advertiser
If you organise something, you are a organiser
If you observe something, you are a observer
If you contend something, you are a
2024-07-26 20:09:55 root INFO     [order_1_approx] starting weight calculation for If you suffer something, you are a sufferer
If you choreograph something, you are a choreographer
If you advertise something, you are a advertiser
If you contend something, you are a contender
If you organise something, you are a organiser
If you observe something, you are a observer
If you deliver something, you are a deliverer
If you examine something, you are a
2024-07-26 20:09:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 20:12:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0909, -0.0873, -0.3196,  ..., -0.0215,  0.2012, -0.0236],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8008, -2.0312,  1.1055,  ..., -2.4980, -3.6797, -5.4766],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0669, -0.0206,  0.0034,  ...,  0.0196,  0.0017,  0.0062],
        [-0.0005,  0.0721,  0.0197,  ...,  0.0103,  0.0136, -0.0010],
        [ 0.0050,  0.0053,  0.0443,  ..., -0.0122,  0.0085, -0.0032],
        ...,
        [ 0.0229,  0.0182,  0.0028,  ...,  0.0622,  0.0071,  0.0030],
        [-0.0085,  0.0003, -0.0045,  ..., -0.0092,  0.0256, -0.0081],
        [ 0.0117, -0.0015,  0.0144,  ...,  0.0003, -0.0093,  0.0305]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1504, -2.2695,  1.0771,  ..., -2.1895, -3.8652, -5.4570]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 20:12:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you suffer something, you are a sufferer
If you choreograph something, you are a choreographer
If you advertise something, you are a advertiser
If you contend something, you are a contender
If you organise something, you are a organiser
If you observe something, you are a observer
If you deliver something, you are a deliverer
If you examine something, you are a
2024-07-26 20:12:12 root INFO     [order_1_approx] starting weight calculation for If you examine something, you are a examiner
If you choreograph something, you are a choreographer
If you organise something, you are a organiser
If you advertise something, you are a advertiser
If you observe something, you are a observer
If you deliver something, you are a deliverer
If you contend something, you are a contender
If you suffer something, you are a
2024-07-26 20:12:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 20:14:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2380,  0.1396, -0.1738,  ..., -0.5576,  0.0638,  0.0306],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.2852, -4.1914,  0.7222,  ..., -1.7100, -0.1797, -0.5049],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.2629e-02, -3.6743e-02,  2.6779e-02,  ..., -2.7008e-03,
          1.5402e-03,  2.0828e-02],
        [-5.6992e-03,  3.4088e-02,  2.0866e-03,  ...,  1.2070e-02,
          1.2009e-02, -4.2000e-03],
        [-2.5558e-04, -1.7792e-02,  3.8696e-02,  ..., -4.6082e-03,
         -4.1962e-05, -1.8066e-02],
        ...,
        [ 2.2705e-02,  1.8219e-02, -1.2131e-02,  ...,  3.0411e-02,
          2.1606e-02, -4.2686e-03],
        [-1.8044e-03,  2.7710e-02, -6.4621e-03,  ...,  6.9189e-04,
          2.0721e-02, -1.0612e-02],
        [ 1.0773e-02,  1.3742e-03,  2.0386e-02,  ..., -8.5220e-03,
         -1.5472e-02,  1.3710e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.1211, -3.9766,  0.7876,  ..., -1.1348, -0.4321, -0.7773]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 20:14:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you examine something, you are a examiner
If you choreograph something, you are a choreographer
If you organise something, you are a organiser
If you advertise something, you are a advertiser
If you observe something, you are a observer
If you deliver something, you are a deliverer
If you contend something, you are a contender
If you suffer something, you are a
2024-07-26 20:14:33 root INFO     [order_1_approx] starting weight calculation for If you organise something, you are a organiser
If you advertise something, you are a advertiser
If you choreograph something, you are a choreographer
If you deliver something, you are a deliverer
If you examine something, you are a examiner
If you contend something, you are a contender
If you suffer something, you are a sufferer
If you observe something, you are a
2024-07-26 20:14:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 20:16:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1870,  0.3501, -0.3625,  ..., -0.0774,  0.4502, -0.1094],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8960, -1.8809, -0.5928,  ..., -3.6328, -2.9277, -4.3672],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.1584e-02, -9.2888e-04,  6.9008e-03,  ...,  2.0157e-02,
          6.1493e-03,  2.5940e-02],
        [-4.8065e-03,  4.9133e-02,  7.7934e-03,  ...,  1.1467e-02,
          1.6479e-02, -5.5313e-03],
        [-8.4305e-03, -8.7509e-03,  4.6234e-02,  ..., -1.5778e-02,
         -8.1635e-03, -4.2686e-03],
        ...,
        [ 2.0813e-02,  1.7212e-02,  6.4671e-05,  ...,  4.3427e-02,
          1.5495e-02, -1.1086e-02],
        [-6.8321e-03,  8.3466e-03, -4.9362e-03,  ..., -2.6360e-03,
          1.3596e-02, -3.4409e-03],
        [ 3.5820e-03, -2.3651e-03, -2.9984e-03,  ..., -1.5358e-02,
         -4.6883e-03,  2.7740e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9272, -1.7363, -0.8447,  ..., -3.3555, -2.9805, -4.2070]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 20:16:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you organise something, you are a organiser
If you advertise something, you are a advertiser
If you choreograph something, you are a choreographer
If you deliver something, you are a deliverer
If you examine something, you are a examiner
If you contend something, you are a contender
If you suffer something, you are a sufferer
If you observe something, you are a
2024-07-26 20:16:53 root INFO     [order_1_approx] starting weight calculation for If you choreograph something, you are a choreographer
If you contend something, you are a contender
If you suffer something, you are a sufferer
If you observe something, you are a observer
If you examine something, you are a examiner
If you deliver something, you are a deliverer
If you organise something, you are a organiser
If you advertise something, you are a
2024-07-26 20:16:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 20:19:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2776,  0.2993, -0.4319,  ..., -0.0007,  0.3792, -0.4287],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.2891, -3.0957, -0.2107,  ...,  2.4141, -4.8516, -3.3574],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0352,  0.0069,  0.0051,  ...,  0.0099, -0.0077,  0.0114],
        [-0.0189,  0.0410,  0.0036,  ...,  0.0169,  0.0181, -0.0127],
        [ 0.0111,  0.0028,  0.0309,  ..., -0.0119, -0.0144,  0.0079],
        ...,
        [ 0.0097,  0.0159,  0.0048,  ...,  0.0253,  0.0103,  0.0095],
        [ 0.0045,  0.0084, -0.0052,  ..., -0.0049,  0.0201, -0.0147],
        [ 0.0052, -0.0020, -0.0065,  ..., -0.0023, -0.0089,  0.0179]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.2461, -3.0547, -0.3210,  ...,  2.4688, -5.1055, -3.4395]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 20:19:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you choreograph something, you are a choreographer
If you contend something, you are a contender
If you suffer something, you are a sufferer
If you observe something, you are a observer
If you examine something, you are a examiner
If you deliver something, you are a deliverer
If you organise something, you are a organiser
If you advertise something, you are a
2024-07-26 20:19:13 root INFO     total operator prediction time: 1117.510454416275 seconds
2024-07-26 20:19:13 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj - superlative
2024-07-26 20:19:13 root INFO     building operator adj - superlative
2024-07-26 20:19:13 root INFO     [order_1_approx] starting weight calculation for If something is the most tiny, it is tiniest
If something is the most nice, it is nicest
If something is the most ugly, it is ugliest
If something is the most cute, it is cutest
If something is the most noisy, it is noisiest
If something is the most weak, it is weakest
If something is the most tricky, it is trickiest
If something is the most strong, it is
2024-07-26 20:19:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 20:21:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0168, -0.2988, -0.1039,  ..., -0.3572, -0.0897, -0.2598],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0352, -6.3711, -3.0430,  ...,  0.1484, -1.8770, -2.2188],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0231, -0.0185, -0.0056,  ..., -0.0237, -0.0075,  0.0163],
        [-0.0099,  0.0213,  0.0014,  ..., -0.0012,  0.0107,  0.0117],
        [ 0.0131, -0.0113,  0.0099,  ..., -0.0029, -0.0136, -0.0107],
        ...,
        [ 0.0043,  0.0210,  0.0055,  ...,  0.0316,  0.0062,  0.0121],
        [-0.0203, -0.0174, -0.0005,  ...,  0.0018,  0.0256, -0.0256],
        [-0.0185,  0.0021,  0.0129,  ..., -0.0059, -0.0041,  0.0026]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8711, -6.0117, -2.9277,  ...,  0.0157, -2.3105, -2.5215]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 20:21:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most tiny, it is tiniest
If something is the most nice, it is nicest
If something is the most ugly, it is ugliest
If something is the most cute, it is cutest
If something is the most noisy, it is noisiest
If something is the most weak, it is weakest
If something is the most tricky, it is trickiest
If something is the most strong, it is
2024-07-26 20:21:32 root INFO     [order_1_approx] starting weight calculation for If something is the most noisy, it is noisiest
If something is the most weak, it is weakest
If something is the most nice, it is nicest
If something is the most tricky, it is trickiest
If something is the most strong, it is strongest
If something is the most cute, it is cutest
If something is the most ugly, it is ugliest
If something is the most tiny, it is
2024-07-26 20:21:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 20:23:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2410, -0.2532, -0.6113,  ..., -0.0828,  0.3750, -0.5068],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.4658, -0.1003, -0.4065,  ..., -4.6680, -2.0020, -1.2803],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0501, -0.0135, -0.0112,  ..., -0.0082,  0.0154,  0.0115],
        [ 0.0171,  0.0456,  0.0236,  ...,  0.0113,  0.0121, -0.0069],
        [ 0.0005,  0.0103,  0.0358,  ..., -0.0013, -0.0022,  0.0065],
        ...,
        [-0.0098,  0.0238, -0.0109,  ...,  0.0542,  0.0064,  0.0026],
        [ 0.0157, -0.0173,  0.0040,  ...,  0.0156,  0.0316, -0.0140],
        [ 0.0012, -0.0034,  0.0129,  ..., -0.0096, -0.0163,  0.0282]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.5840,  0.0220, -0.5112,  ..., -3.9023, -1.5586, -1.0303]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 20:23:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most noisy, it is noisiest
If something is the most weak, it is weakest
If something is the most nice, it is nicest
If something is the most tricky, it is trickiest
If something is the most strong, it is strongest
If something is the most cute, it is cutest
If something is the most ugly, it is ugliest
If something is the most tiny, it is
2024-07-26 20:23:51 root INFO     [order_1_approx] starting weight calculation for If something is the most noisy, it is noisiest
If something is the most tiny, it is tiniest
If something is the most strong, it is strongest
If something is the most tricky, it is trickiest
If something is the most nice, it is nicest
If something is the most weak, it is weakest
If something is the most ugly, it is ugliest
If something is the most cute, it is
2024-07-26 20:23:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 20:26:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1686, -0.0012,  0.1731,  ..., -0.4609, -0.4719,  0.0566],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.1621, -1.2969, -1.3135,  ..., -0.9062, -0.3242,  1.7949],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0360, -0.0148,  0.0049,  ..., -0.0133,  0.0079,  0.0165],
        [ 0.0019,  0.0443, -0.0082,  ...,  0.0071,  0.0031,  0.0095],
        [-0.0052, -0.0025,  0.0261,  ...,  0.0072, -0.0081, -0.0055],
        ...,
        [ 0.0025,  0.0206,  0.0181,  ...,  0.0534,  0.0191, -0.0059],
        [ 0.0044, -0.0085,  0.0091,  ..., -0.0290,  0.0131, -0.0145],
        [-0.0165, -0.0078,  0.0067,  ..., -0.0162, -0.0101,  0.0320]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.1367, -1.4307, -1.3838,  ..., -0.7783, -0.1704,  1.4297]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 20:26:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most noisy, it is noisiest
If something is the most tiny, it is tiniest
If something is the most strong, it is strongest
If something is the most tricky, it is trickiest
If something is the most nice, it is nicest
If something is the most weak, it is weakest
If something is the most ugly, it is ugliest
If something is the most cute, it is
2024-07-26 20:26:10 root INFO     [order_1_approx] starting weight calculation for If something is the most strong, it is strongest
If something is the most nice, it is nicest
If something is the most ugly, it is ugliest
If something is the most tricky, it is trickiest
If something is the most cute, it is cutest
If something is the most tiny, it is tiniest
If something is the most noisy, it is noisiest
If something is the most weak, it is
2024-07-26 20:26:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 20:28:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2556, -0.3501, -0.5981,  ..., -0.3823, -0.0873, -0.2384],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7598, -4.3906, -2.1914,  ..., -4.2695,  2.3672, -3.4629],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0330, -0.0099, -0.0015,  ..., -0.0234,  0.0041,  0.0059],
        [ 0.0013,  0.0336,  0.0172,  ...,  0.0009,  0.0010, -0.0103],
        [ 0.0042, -0.0008,  0.0120,  ...,  0.0113, -0.0096, -0.0068],
        ...,
        [ 0.0088,  0.0245,  0.0023,  ...,  0.0381,  0.0049, -0.0036],
        [-0.0140,  0.0051, -0.0117,  ...,  0.0120,  0.0269, -0.0093],
        [ 0.0017, -0.0144,  0.0006,  ..., -0.0108, -0.0120,  0.0095]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0498, -4.1328, -2.3340,  ..., -4.3008,  2.2344, -3.1680]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 20:28:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most strong, it is strongest
If something is the most nice, it is nicest
If something is the most ugly, it is ugliest
If something is the most tricky, it is trickiest
If something is the most cute, it is cutest
If something is the most tiny, it is tiniest
If something is the most noisy, it is noisiest
If something is the most weak, it is
2024-07-26 20:28:27 root INFO     [order_1_approx] starting weight calculation for If something is the most tiny, it is tiniest
If something is the most tricky, it is trickiest
If something is the most nice, it is nicest
If something is the most strong, it is strongest
If something is the most cute, it is cutest
If something is the most ugly, it is ugliest
If something is the most weak, it is weakest
If something is the most noisy, it is
2024-07-26 20:28:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 20:30:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2069,  0.0603, -0.0519,  ...,  0.0945, -0.1349,  0.0333],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-4.6055, -3.6230, -0.6904,  ..., -1.3594, -1.3730, -0.0381],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.0638e-02,  1.3847e-03, -7.6103e-03,  ...,  1.2985e-02,
          8.7643e-04,  7.7515e-03],
        [ 4.9210e-04,  4.9652e-02,  9.6359e-03,  ...,  1.0231e-02,
         -1.6165e-03,  1.1246e-02],
        [ 9.6817e-03, -5.3940e-03,  2.5848e-02,  ..., -2.8992e-04,
         -2.0050e-02,  5.5046e-03],
        ...,
        [ 1.4175e-02,  2.5665e-02,  1.1139e-02,  ...,  3.2623e-02,
         -4.6082e-03,  3.8147e-04],
        [-5.4836e-05,  1.0788e-02, -1.3641e-02,  ...,  5.4398e-03,
          3.9429e-02, -5.9471e-03],
        [-2.5215e-03,  9.6273e-04, -3.0351e-04,  ..., -1.8509e-02,
         -3.6583e-03,  1.5121e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-4.5703, -3.7344, -1.1699,  ..., -0.9785, -1.1914, -0.0588]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 20:30:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most tiny, it is tiniest
If something is the most tricky, it is trickiest
If something is the most nice, it is nicest
If something is the most strong, it is strongest
If something is the most cute, it is cutest
If something is the most ugly, it is ugliest
If something is the most weak, it is weakest
If something is the most noisy, it is
2024-07-26 20:30:46 root INFO     [order_1_approx] starting weight calculation for If something is the most strong, it is strongest
If something is the most weak, it is weakest
If something is the most noisy, it is noisiest
If something is the most tiny, it is tiniest
If something is the most tricky, it is trickiest
If something is the most nice, it is nicest
If something is the most cute, it is cutest
If something is the most ugly, it is
2024-07-26 20:30:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 20:33:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0006,  0.1004,  0.2471,  ..., -0.3967,  0.5732, -0.1217],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8193, -4.0078, -1.4707,  ..., -1.8613, -1.2783,  0.9658],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0349, -0.0121,  0.0013,  ...,  0.0023, -0.0061,  0.0182],
        [ 0.0017,  0.0310,  0.0211,  ..., -0.0046,  0.0129,  0.0008],
        [-0.0137,  0.0061,  0.0431,  ...,  0.0080, -0.0092, -0.0113],
        ...,
        [ 0.0141,  0.0300, -0.0054,  ...,  0.0365,  0.0060, -0.0113],
        [-0.0138,  0.0135,  0.0065,  ...,  0.0097,  0.0374, -0.0273],
        [-0.0087,  0.0069, -0.0005,  ..., -0.0165, -0.0140,  0.0141]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7451, -3.7539, -1.5039,  ..., -1.6709, -1.2236,  0.9414]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 20:33:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most strong, it is strongest
If something is the most weak, it is weakest
If something is the most noisy, it is noisiest
If something is the most tiny, it is tiniest
If something is the most tricky, it is trickiest
If something is the most nice, it is nicest
If something is the most cute, it is cutest
If something is the most ugly, it is
2024-07-26 20:33:04 root INFO     [order_1_approx] starting weight calculation for If something is the most strong, it is strongest
If something is the most tiny, it is tiniest
If something is the most ugly, it is ugliest
If something is the most weak, it is weakest
If something is the most nice, it is nicest
If something is the most noisy, it is noisiest
If something is the most cute, it is cutest
If something is the most tricky, it is
2024-07-26 20:33:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 20:35:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2849,  0.1530,  0.0909,  ...,  0.1672, -0.2830,  0.1096],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6387, -3.9082, -1.6602,  ..., -0.2510, -2.6211,  0.1406],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0628,  0.0025,  0.0023,  ...,  0.0159, -0.0018,  0.0034],
        [-0.0015,  0.0462,  0.0314,  ...,  0.0120, -0.0085,  0.0036],
        [ 0.0183, -0.0044,  0.0343,  ...,  0.0097, -0.0393,  0.0002],
        ...,
        [-0.0050,  0.0228,  0.0041,  ...,  0.0632,  0.0002, -0.0213],
        [ 0.0107, -0.0039,  0.0103,  ..., -0.0111,  0.0513, -0.0060],
        [ 0.0242,  0.0027,  0.0199,  ..., -0.0344, -0.0252,  0.0529]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 8.6719e-01, -4.0508e+00, -1.4814e+00,  ...,  2.4414e-03,
         -2.8066e+00,  3.3752e-02]], device='cuda:1', dtype=torch.float16,
       grad_fn=<SubBackward0>) 

                    
2024-07-26 20:35:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most strong, it is strongest
If something is the most tiny, it is tiniest
If something is the most ugly, it is ugliest
If something is the most weak, it is weakest
If something is the most nice, it is nicest
If something is the most noisy, it is noisiest
If something is the most cute, it is cutest
If something is the most tricky, it is
2024-07-26 20:35:25 root INFO     [order_1_approx] starting weight calculation for If something is the most ugly, it is ugliest
If something is the most cute, it is cutest
If something is the most weak, it is weakest
If something is the most tiny, it is tiniest
If something is the most strong, it is strongest
If something is the most tricky, it is trickiest
If something is the most noisy, it is noisiest
If something is the most nice, it is
2024-07-26 20:35:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 20:37:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2249, -0.1204, -0.2942,  ..., -0.2281, -0.2166, -0.4004],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2490, -0.5513, -4.2695,  ...,  0.3506, -4.2422, -0.9800],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0484, -0.0226, -0.0013,  ..., -0.0201,  0.0150,  0.0305],
        [-0.0020,  0.0228, -0.0006,  ..., -0.0009,  0.0141,  0.0056],
        [ 0.0038, -0.0239,  0.0443,  ...,  0.0034, -0.0252, -0.0205],
        ...,
        [-0.0033,  0.0203, -0.0072,  ...,  0.0541,  0.0098, -0.0071],
        [-0.0018, -0.0026,  0.0255,  ...,  0.0151,  0.0248, -0.0219],
        [-0.0118, -0.0002,  0.0107,  ..., -0.0075, -0.0221,  0.0287]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2123, -1.0293, -4.5547,  ...,  0.4514, -4.0977, -1.4102]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 20:37:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most ugly, it is ugliest
If something is the most cute, it is cutest
If something is the most weak, it is weakest
If something is the most tiny, it is tiniest
If something is the most strong, it is strongest
If something is the most tricky, it is trickiest
If something is the most noisy, it is noisiest
If something is the most nice, it is
2024-07-26 20:37:46 root INFO     total operator prediction time: 1112.5345079898834 seconds
2024-07-26 20:37:46 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_3pSg - Ved
2024-07-26 20:37:46 root INFO     building operator verb_3pSg - Ved
2024-07-26 20:37:46 root INFO     [order_1_approx] starting weight calculation for When he applies something, something has been applied
When he allows something, something has been allowed
When he agrees something, something has been agreed
When he fails something, something has been failed
When he replaces something, something has been replaced
When he tells something, something has been told
When he establishes something, something has been established
When he creates something, something has been
2024-07-26 20:37:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 20:40:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1708,  0.1479,  0.0411,  ..., -0.0340,  0.0104,  0.1110],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1445, -0.3599,  2.2461,  ..., -0.0684, -1.9961,  0.2461],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0357, -0.0210,  0.0165,  ...,  0.0047, -0.0006,  0.0209],
        [-0.0102,  0.0338,  0.0110,  ...,  0.0108, -0.0003,  0.0055],
        [ 0.0019,  0.0028,  0.0173,  ..., -0.0073, -0.0057, -0.0021],
        ...,
        [ 0.0070,  0.0006, -0.0023,  ...,  0.0192,  0.0033,  0.0033],
        [ 0.0122,  0.0289, -0.0054,  ...,  0.0060,  0.0244, -0.0173],
        [-0.0033,  0.0021,  0.0073,  ..., -0.0063,  0.0007,  0.0160]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0317, -0.3743,  2.0625,  ...,  0.1046, -2.0371,  0.4126]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 20:40:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he applies something, something has been applied
When he allows something, something has been allowed
When he agrees something, something has been agreed
When he fails something, something has been failed
When he replaces something, something has been replaced
When he tells something, something has been told
When he establishes something, something has been established
When he creates something, something has been
2024-07-26 20:40:08 root INFO     [order_1_approx] starting weight calculation for When he replaces something, something has been replaced
When he creates something, something has been created
When he allows something, something has been allowed
When he agrees something, something has been agreed
When he establishes something, something has been established
When he applies something, something has been applied
When he tells something, something has been told
When he fails something, something has been
2024-07-26 20:40:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 20:42:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4331,  0.2612, -0.3115,  ..., -0.0848,  0.2045, -0.2607],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0869,  0.6982,  4.1953,  ..., -1.3047, -1.1963, -1.0283],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.5854e-02,  4.5357e-03,  1.2283e-02,  ...,  2.2293e-02,
         -1.8372e-02,  1.3290e-02],
        [-6.7062e-03,  2.0233e-02,  4.5319e-03,  ..., -7.6294e-05,
          1.6388e-02, -1.3704e-03],
        [-1.8082e-03, -3.9368e-03, -8.9264e-03,  ..., -1.4763e-02,
         -2.9793e-03,  1.0094e-02],
        ...,
        [ 8.1253e-03, -1.1702e-03, -1.3191e-02,  ...,  1.8387e-02,
          2.0630e-02,  1.2070e-02],
        [ 9.9182e-03,  1.6632e-02, -8.0261e-03,  ..., -5.3139e-03,
          9.6359e-03, -1.7653e-03],
        [-4.3411e-03,  8.7128e-03,  2.1500e-02,  ..., -3.7842e-03,
         -7.8125e-03,  4.6387e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1680,  0.5688,  3.9805,  ..., -1.3330, -1.3848, -0.8428]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 20:42:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he replaces something, something has been replaced
When he creates something, something has been created
When he allows something, something has been allowed
When he agrees something, something has been agreed
When he establishes something, something has been established
When he applies something, something has been applied
When he tells something, something has been told
When he fails something, something has been
2024-07-26 20:42:30 root INFO     [order_1_approx] starting weight calculation for When he fails something, something has been failed
When he replaces something, something has been replaced
When he allows something, something has been allowed
When he applies something, something has been applied
When he agrees something, something has been agreed
When he establishes something, something has been established
When he creates something, something has been created
When he tells something, something has been
2024-07-26 20:42:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 20:44:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1141, -0.1290,  0.0181,  ...,  0.3542, -0.0696, -0.2720],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9668,  0.9023,  4.1875,  ...,  1.2998, -4.5586, -0.9375],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0380,  0.0051, -0.0037,  ...,  0.0013, -0.0053,  0.0229],
        [-0.0214,  0.0325,  0.0053,  ...,  0.0128, -0.0029, -0.0048],
        [ 0.0008, -0.0141,  0.0277,  ..., -0.0082, -0.0047,  0.0002],
        ...,
        [-0.0007,  0.0060, -0.0050,  ...,  0.0171,  0.0117,  0.0086],
        [ 0.0022,  0.0049,  0.0026,  ...,  0.0108,  0.0357, -0.0046],
        [-0.0034, -0.0059,  0.0175,  ..., -0.0146,  0.0150,  0.0198]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0586,  0.8550,  4.0078,  ...,  1.3008, -4.3984, -1.1328]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 20:44:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he fails something, something has been failed
When he replaces something, something has been replaced
When he allows something, something has been allowed
When he applies something, something has been applied
When he agrees something, something has been agreed
When he establishes something, something has been established
When he creates something, something has been created
When he tells something, something has been
2024-07-26 20:44:51 root INFO     [order_1_approx] starting weight calculation for When he fails something, something has been failed
When he replaces something, something has been replaced
When he tells something, something has been told
When he creates something, something has been created
When he establishes something, something has been established
When he allows something, something has been allowed
When he agrees something, something has been agreed
When he applies something, something has been
2024-07-26 20:44:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 20:47:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0114, -0.2881, -0.0366,  ...,  0.1794,  0.1559, -0.0815],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7217,  0.1409,  1.1230,  ..., -0.7490, -1.2207, -0.4980],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0401, -0.0014,  0.0048,  ...,  0.0092, -0.0093,  0.0132],
        [-0.0057,  0.0220,  0.0162,  ...,  0.0118,  0.0054,  0.0091],
        [-0.0048,  0.0056,  0.0145,  ..., -0.0160, -0.0055,  0.0069],
        ...,
        [ 0.0002,  0.0202, -0.0067,  ...,  0.0385,  0.0074,  0.0254],
        [ 0.0195,  0.0123, -0.0041,  ..., -0.0007,  0.0227, -0.0304],
        [-0.0077,  0.0061,  0.0022,  ..., -0.0069,  0.0109,  0.0088]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7104, -0.3494,  1.4082,  ..., -0.7114, -0.9346, -0.5933]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 20:47:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he fails something, something has been failed
When he replaces something, something has been replaced
When he tells something, something has been told
When he creates something, something has been created
When he establishes something, something has been established
When he allows something, something has been allowed
When he agrees something, something has been agreed
When he applies something, something has been
2024-07-26 20:47:13 root INFO     [order_1_approx] starting weight calculation for When he establishes something, something has been established
When he creates something, something has been created
When he agrees something, something has been agreed
When he replaces something, something has been replaced
When he applies something, something has been applied
When he tells something, something has been told
When he fails something, something has been failed
When he allows something, something has been
2024-07-26 20:47:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 20:49:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3472,  0.2157, -0.0170,  ..., -0.1970, -0.1371, -0.1675],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0332, -2.2715,  0.6074,  ...,  0.0254, -1.8818,  0.8965],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0498, -0.0135,  0.0109,  ..., -0.0010, -0.0013,  0.0173],
        [ 0.0005,  0.0135, -0.0118,  ...,  0.0265,  0.0172, -0.0078],
        [-0.0204, -0.0202,  0.0268,  ..., -0.0207, -0.0051, -0.0076],
        ...,
        [ 0.0072,  0.0211, -0.0188,  ...,  0.0205,  0.0251,  0.0136],
        [ 0.0101,  0.0149, -0.0108,  ..., -0.0030,  0.0241, -0.0196],
        [-0.0042,  0.0026,  0.0016,  ...,  0.0125,  0.0024,  0.0026]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2070, -2.2891,  0.5752,  ...,  0.4648, -2.0371,  1.1650]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 20:49:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he establishes something, something has been established
When he creates something, something has been created
When he agrees something, something has been agreed
When he replaces something, something has been replaced
When he applies something, something has been applied
When he tells something, something has been told
When he fails something, something has been failed
When he allows something, something has been
2024-07-26 20:49:35 root INFO     [order_1_approx] starting weight calculation for When he establishes something, something has been established
When he tells something, something has been told
When he fails something, something has been failed
When he allows something, something has been allowed
When he creates something, something has been created
When he agrees something, something has been agreed
When he applies something, something has been applied
When he replaces something, something has been
2024-07-26 20:49:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 20:51:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1282,  0.1877, -0.6367,  ...,  0.0660, -0.0397,  0.1807],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4675, -0.1758,  0.0635,  ..., -0.8687, -0.2373,  0.1602],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0235, -0.0079,  0.0049,  ...,  0.0131, -0.0158,  0.0364],
        [-0.0150,  0.0286,  0.0076,  ...,  0.0168, -0.0102,  0.0245],
        [ 0.0034, -0.0061, -0.0019,  ..., -0.0235,  0.0099, -0.0125],
        ...,
        [ 0.0029,  0.0072,  0.0033,  ...,  0.0185,  0.0025,  0.0341],
        [ 0.0128,  0.0117, -0.0090,  ..., -0.0151,  0.0276, -0.0093],
        [ 0.0126,  0.0037,  0.0083,  ..., -0.0032, -0.0041,  0.0120]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6025, -0.4165,  0.4587,  ..., -0.8403, -0.1550,  0.0592]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 20:51:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he establishes something, something has been established
When he tells something, something has been told
When he fails something, something has been failed
When he allows something, something has been allowed
When he creates something, something has been created
When he agrees something, something has been agreed
When he applies something, something has been applied
When he replaces something, something has been
2024-07-26 20:51:57 root INFO     [order_1_approx] starting weight calculation for When he tells something, something has been told
When he fails something, something has been failed
When he allows something, something has been allowed
When he replaces something, something has been replaced
When he applies something, something has been applied
When he creates something, something has been created
When he agrees something, something has been agreed
When he establishes something, something has been
2024-07-26 20:51:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 20:54:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2041,  0.0610, -0.4375,  ...,  0.1555, -0.1555,  0.1489],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3721, -0.7759,  1.2773,  ..., -0.7783, -0.7988, -1.6172],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0204, -0.0066,  0.0030,  ..., -0.0040, -0.0097,  0.0144],
        [-0.0165,  0.0182,  0.0075,  ...,  0.0077,  0.0132,  0.0024],
        [ 0.0071,  0.0006,  0.0107,  ..., -0.0123, -0.0023,  0.0001],
        ...,
        [ 0.0042, -0.0093,  0.0049,  ...,  0.0141,  0.0080,  0.0149],
        [ 0.0023,  0.0128,  0.0015,  ...,  0.0006,  0.0155, -0.0074],
        [-0.0042, -0.0051,  0.0155,  ...,  0.0141, -0.0065,  0.0011]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6318, -0.8052,  1.5156,  ..., -0.4065, -0.9541, -1.8809]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 20:54:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he tells something, something has been told
When he fails something, something has been failed
When he allows something, something has been allowed
When he replaces something, something has been replaced
When he applies something, something has been applied
When he creates something, something has been created
When he agrees something, something has been agreed
When he establishes something, something has been
2024-07-26 20:54:18 root INFO     [order_1_approx] starting weight calculation for When he allows something, something has been allowed
When he establishes something, something has been established
When he creates something, something has been created
When he fails something, something has been failed
When he applies something, something has been applied
When he tells something, something has been told
When he replaces something, something has been replaced
When he agrees something, something has been
2024-07-26 20:54:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 20:56:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2163,  0.1843, -0.3826,  ...,  0.2612, -0.2646, -0.0771],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9688, -1.3691,  1.3213,  ..., -0.1671, -1.3164,  0.7031],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0247, -0.0140,  0.0061,  ...,  0.0021,  0.0020,  0.0143],
        [-0.0113,  0.0275, -0.0009,  ...,  0.0138,  0.0066, -0.0131],
        [-0.0014, -0.0130,  0.0211,  ..., -0.0115, -0.0076, -0.0128],
        ...,
        [ 0.0156, -0.0004, -0.0115,  ...,  0.0103,  0.0076,  0.0081],
        [ 0.0101,  0.0168, -0.0038,  ...,  0.0029,  0.0197, -0.0164],
        [ 0.0014, -0.0039,  0.0180,  ..., -0.0005, -0.0069,  0.0202]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8672, -1.2568,  1.4004,  ..., -0.0387, -1.4092,  0.9805]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 20:56:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he allows something, something has been allowed
When he establishes something, something has been established
When he creates something, something has been created
When he fails something, something has been failed
When he applies something, something has been applied
When he tells something, something has been told
When he replaces something, something has been replaced
When he agrees something, something has been
2024-07-26 20:56:40 root INFO     total operator prediction time: 1134.6720385551453 seconds
2024-07-26 20:56:40 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun - plural_reg
2024-07-26 20:56:40 root INFO     building operator noun - plural_reg
2024-07-26 20:56:40 root INFO     [order_1_approx] starting weight calculation for The plural form of government is governments
The plural form of website is websites
The plural form of night is nights
The plural form of user is users
The plural form of song is songs
The plural form of office is offices
The plural form of population is populations
The plural form of street is
2024-07-26 20:56:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 20:59:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0885,  0.1268,  0.2996,  ..., -0.0098, -0.1265, -0.0470],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9834, -4.1797, -0.5229,  ...,  0.9727,  0.0046, -2.2129],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0521,  0.0124, -0.0289,  ..., -0.0005, -0.0121,  0.0051],
        [-0.0090,  0.0474, -0.0161,  ...,  0.0082,  0.0046, -0.0198],
        [-0.0104,  0.0205,  0.0693,  ..., -0.0083,  0.0085,  0.0378],
        ...,
        [-0.0125,  0.0031, -0.0126,  ...,  0.0505, -0.0103,  0.0218],
        [-0.0444,  0.0320, -0.0205,  ...,  0.0155,  0.0457,  0.0139],
        [ 0.0100,  0.0069, -0.0028,  ...,  0.0219, -0.0035,  0.0455]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5234, -4.5352, -0.1306,  ...,  1.5352, -0.1218, -2.1348]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 20:59:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of government is governments
The plural form of website is websites
The plural form of night is nights
The plural form of user is users
The plural form of song is songs
The plural form of office is offices
The plural form of population is populations
The plural form of street is
2024-07-26 20:59:02 root INFO     [order_1_approx] starting weight calculation for The plural form of song is songs
The plural form of street is streets
The plural form of government is governments
The plural form of night is nights
The plural form of population is populations
The plural form of office is offices
The plural form of website is websites
The plural form of user is
2024-07-26 20:59:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 21:01:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2068,  0.2458, -0.2000,  ...,  0.1416, -0.2321, -0.2878],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7520, -2.6348,  0.9092,  ..., -1.3145, -2.2344, -1.7441],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0499,  0.0061,  0.0056,  ...,  0.0071, -0.0040,  0.0003],
        [ 0.0155,  0.0454, -0.0175,  ...,  0.0045,  0.0066,  0.0125],
        [-0.0016, -0.0107,  0.0619,  ...,  0.0093,  0.0032,  0.0243],
        ...,
        [ 0.0080,  0.0157, -0.0198,  ...,  0.0414,  0.0054,  0.0246],
        [-0.0059, -0.0022, -0.0164,  ...,  0.0077,  0.0366, -0.0259],
        [ 0.0148,  0.0117, -0.0110,  ..., -0.0244, -0.0113,  0.0511]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9941, -2.8770,  0.8687,  ..., -0.6641, -2.0215, -1.2549]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 21:01:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of song is songs
The plural form of street is streets
The plural form of government is governments
The plural form of night is nights
The plural form of population is populations
The plural form of office is offices
The plural form of website is websites
The plural form of user is
2024-07-26 21:01:24 root INFO     [order_1_approx] starting weight calculation for The plural form of population is populations
The plural form of government is governments
The plural form of song is songs
The plural form of office is offices
The plural form of street is streets
The plural form of user is users
The plural form of night is nights
The plural form of website is
2024-07-26 21:01:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 21:03:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0329,  0.3621, -0.2063,  ...,  0.0312, -0.2234, -0.0997],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5293, -3.3887,  1.9102,  ...,  0.6909, -0.9678, -0.7520],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0400, -0.0035, -0.0016,  ...,  0.0139,  0.0122,  0.0010],
        [ 0.0065,  0.0950,  0.0110,  ...,  0.0038,  0.0077,  0.0033],
        [ 0.0251,  0.0064,  0.0652,  ...,  0.0177, -0.0085,  0.0341],
        ...,
        [-0.0073,  0.0126, -0.0003,  ...,  0.0362,  0.0118, -0.0233],
        [ 0.0001,  0.0238, -0.0133,  ...,  0.0174,  0.0602,  0.0036],
        [-0.0063,  0.0012, -0.0030,  ...,  0.0042, -0.0325,  0.0625]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7334, -3.8281,  1.3154,  ...,  1.1592, -1.1035, -0.4336]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 21:03:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of population is populations
The plural form of government is governments
The plural form of song is songs
The plural form of office is offices
The plural form of street is streets
The plural form of user is users
The plural form of night is nights
The plural form of website is
2024-07-26 21:03:46 root INFO     [order_1_approx] starting weight calculation for The plural form of website is websites
The plural form of user is users
The plural form of office is offices
The plural form of song is songs
The plural form of night is nights
The plural form of government is governments
The plural form of street is streets
The plural form of population is
2024-07-26 21:03:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 21:06:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5547,  0.4114, -0.1582,  ..., -0.2651, -0.1370,  0.0121],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5625, -3.7266,  1.2793,  ..., -1.4570, -2.9863, -1.6172],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0078,  0.0233, -0.0111,  ...,  0.0203,  0.0128,  0.0197],
        [ 0.0502,  0.0513,  0.0181,  ...,  0.0126, -0.0064,  0.0196],
        [ 0.0157,  0.0047,  0.0431,  ..., -0.0040, -0.0203,  0.0223],
        ...,
        [ 0.0321,  0.0019, -0.0053,  ...,  0.0390, -0.0130,  0.0244],
        [-0.0028, -0.0056, -0.0200,  ...,  0.0090,  0.0379, -0.0254],
        [ 0.0095,  0.0107,  0.0066,  ...,  0.0050, -0.0254,  0.0504]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0117, -4.3828,  0.8867,  ..., -1.6270, -2.5332, -1.8945]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 21:06:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of website is websites
The plural form of user is users
The plural form of office is offices
The plural form of song is songs
The plural form of night is nights
The plural form of government is governments
The plural form of street is streets
The plural form of population is
2024-07-26 21:06:07 root INFO     [order_1_approx] starting weight calculation for The plural form of government is governments
The plural form of population is populations
The plural form of user is users
The plural form of office is offices
The plural form of website is websites
The plural form of night is nights
The plural form of street is streets
The plural form of song is
2024-07-26 21:06:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 21:08:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0101,  0.2905,  0.2310,  ...,  0.1637, -0.5332, -0.3445],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5508, -4.3594,  2.2480,  ..., -2.5820, -1.2861, -2.2148],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.9641e-02, -3.0804e-04,  3.1204e-02,  ..., -3.8681e-03,
          2.1553e-03,  7.8430e-03],
        [ 2.2507e-04,  6.6833e-02,  6.1989e-04,  ..., -6.5613e-04,
          8.7051e-03, -2.2392e-03],
        [ 2.2793e-04, -5.3787e-03,  7.2266e-02,  ..., -2.5635e-03,
         -3.1616e-02,  4.0512e-03],
        ...,
        [ 8.3923e-03, -7.0763e-04, -1.6052e-02,  ...,  4.2786e-02,
         -1.0597e-02, -3.7193e-04],
        [-9.9335e-03,  6.4926e-03, -4.7516e-02,  ..., -1.3039e-02,
          3.3325e-02, -2.6703e-05],
        [ 4.0375e-02,  1.9150e-03,  4.3869e-03,  ..., -5.6992e-03,
         -4.6921e-03,  4.8401e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5908, -4.4141,  1.9424,  ..., -1.7480, -0.8311, -1.6260]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 21:08:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of government is governments
The plural form of population is populations
The plural form of user is users
The plural form of office is offices
The plural form of website is websites
The plural form of night is nights
The plural form of street is streets
The plural form of song is
2024-07-26 21:08:30 root INFO     [order_1_approx] starting weight calculation for The plural form of song is songs
The plural form of street is streets
The plural form of website is websites
The plural form of government is governments
The plural form of user is users
The plural form of night is nights
The plural form of population is populations
The plural form of office is
2024-07-26 21:08:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 21:10:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1863,  0.1687, -0.3572,  ..., -0.0529, -0.3074, -0.3301],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8008, -3.2617,  1.4121,  ..., -0.0950,  0.3809, -0.7959],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.6538e-02,  1.6754e-02,  8.5983e-03,  ..., -4.6463e-03,
         -6.7978e-03,  2.4170e-02],
        [ 8.6517e-03,  6.6284e-02, -1.2016e-02,  ...,  2.3499e-02,
          3.2139e-04, -3.1643e-03],
        [ 1.1063e-02,  2.6031e-02,  6.2439e-02,  ..., -3.3073e-03,
         -1.5175e-02,  5.9128e-03],
        ...,
        [-6.0120e-03,  1.7059e-02,  8.4114e-04,  ...,  4.8645e-02,
         -1.4404e-02,  2.6367e-02],
        [-3.0243e-02,  1.0468e-02, -1.2344e-02,  ...,  1.2970e-02,
          3.9490e-02,  9.5139e-03],
        [ 1.6785e-02, -1.7029e-02, -7.3204e-03,  ...,  7.6294e-06,
         -1.0246e-02,  4.4678e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7207, -3.4590,  1.2705,  ..., -0.3352,  0.3308, -0.5776]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 21:10:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of song is songs
The plural form of street is streets
The plural form of website is websites
The plural form of government is governments
The plural form of user is users
The plural form of night is nights
The plural form of population is populations
The plural form of office is
2024-07-26 21:10:51 root INFO     [order_1_approx] starting weight calculation for The plural form of office is offices
The plural form of website is websites
The plural form of user is users
The plural form of song is songs
The plural form of population is populations
The plural form of street is streets
The plural form of government is governments
The plural form of night is
2024-07-26 21:10:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 21:13:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0483,  0.2393,  0.0380,  ...,  0.1270, -0.3621, -0.0164],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4766, -3.8379,  0.4590,  ..., -0.7422, -0.4736, -1.9736],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0619,  0.0041, -0.0060,  ...,  0.0072,  0.0250,  0.0136],
        [ 0.0256,  0.0672, -0.0068,  ...,  0.0159,  0.0258, -0.0094],
        [ 0.0057,  0.0049,  0.0268,  ..., -0.0096, -0.0138,  0.0317],
        ...,
        [-0.0025,  0.0006, -0.0136,  ...,  0.0500, -0.0246,  0.0216],
        [ 0.0046,  0.0236,  0.0096,  ...,  0.0103,  0.0512, -0.0024],
        [-0.0071,  0.0112, -0.0157,  ..., -0.0216, -0.0321,  0.0539]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3301, -3.8066,  0.0767,  ..., -1.2695,  0.0225, -0.8115]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 21:13:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of office is offices
The plural form of website is websites
The plural form of user is users
The plural form of song is songs
The plural form of population is populations
The plural form of street is streets
The plural form of government is governments
The plural form of night is
2024-07-26 21:13:13 root INFO     [order_1_approx] starting weight calculation for The plural form of office is offices
The plural form of street is streets
The plural form of song is songs
The plural form of night is nights
The plural form of website is websites
The plural form of population is populations
The plural form of user is users
The plural form of government is
2024-07-26 21:13:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 21:15:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2695,  0.1985, -0.2510,  ..., -0.1451, -0.3936, -0.1733],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3828, -1.6943,  0.3083,  ..., -2.1738, -0.8994, -2.5703],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.8025e-02,  1.7578e-02, -1.1177e-03,  ...,  1.3191e-02,
         -2.1622e-02,  1.1436e-02],
        [ 1.0910e-02,  3.7079e-02,  1.4133e-03,  ...,  1.0147e-02,
          1.9424e-02,  4.0054e-03],
        [-7.3910e-05,  6.6490e-03,  4.9530e-02,  ...,  1.2695e-02,
          4.4708e-03,  1.9226e-02],
        ...,
        [ 7.6408e-03, -2.5387e-03, -2.6474e-02,  ...,  4.6265e-02,
          4.9782e-04,  6.1646e-03],
        [-2.4307e-02,  2.0691e-02, -1.8845e-02,  ..., -8.3008e-03,
          2.4445e-02,  7.6370e-03],
        [ 6.1188e-03,  1.1978e-02, -5.3253e-03,  ..., -3.2806e-03,
          5.9547e-03,  4.9164e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6250, -2.1133, -0.0088,  ..., -2.0938, -0.5400, -1.8457]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 21:15:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of office is offices
The plural form of street is streets
The plural form of song is songs
The plural form of night is nights
The plural form of website is websites
The plural form of population is populations
The plural form of user is users
The plural form of government is
2024-07-26 21:15:29 root INFO     total operator prediction time: 1128.6994886398315 seconds
2024-07-26 21:15:29 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_Ving - 3pSg
2024-07-26 21:15:29 root INFO     building operator verb_Ving - 3pSg
2024-07-26 21:15:29 root INFO     [order_1_approx] starting weight calculation for When something is occurring, it occurs
When something is referring, it refers
When something is allowing, it allows
When something is describing, it describes
When something is including, it includes
When something is publishing, it publishes
When something is requiring, it requires
When something is explaining, it
2024-07-26 21:15:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 21:17:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0394, -0.1289, -0.0211,  ..., -0.3699,  0.0918, -0.4802],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1016, -3.2656,  3.5996,  ...,  1.4629, -5.7852,  0.1250],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0302, -0.0049, -0.0041,  ...,  0.0042, -0.0027,  0.0243],
        [-0.0046,  0.0511,  0.0087,  ...,  0.0090, -0.0040,  0.0160],
        [-0.0055,  0.0010,  0.0362,  ..., -0.0068, -0.0060, -0.0116],
        ...,
        [ 0.0026,  0.0041,  0.0061,  ...,  0.0427, -0.0100,  0.0068],
        [-0.0026, -0.0054, -0.0207,  ..., -0.0002,  0.0300, -0.0232],
        [ 0.0065,  0.0053,  0.0227,  ...,  0.0075, -0.0067,  0.0350]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9629, -2.9629,  3.7227,  ...,  1.4854, -5.7227,  0.1174]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 21:17:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is occurring, it occurs
When something is referring, it refers
When something is allowing, it allows
When something is describing, it describes
When something is including, it includes
When something is publishing, it publishes
When something is requiring, it requires
When something is explaining, it
2024-07-26 21:17:51 root INFO     [order_1_approx] starting weight calculation for When something is including, it includes
When something is occurring, it occurs
When something is publishing, it publishes
When something is describing, it describes
When something is referring, it refers
When something is explaining, it explains
When something is requiring, it requires
When something is allowing, it
2024-07-26 21:17:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 21:20:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2268,  0.2163, -0.0828,  ..., -0.3826,  0.0370, -0.2839],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5312, -4.7891,  0.4688,  ..., -0.1406, -6.4727,  1.0137],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0546, -0.0146, -0.0032,  ..., -0.0136,  0.0071,  0.0154],
        [ 0.0120,  0.0413, -0.0153,  ...,  0.0318, -0.0140,  0.0022],
        [-0.0155, -0.0039,  0.0406,  ..., -0.0229, -0.0080, -0.0117],
        ...,
        [ 0.0068,  0.0135,  0.0042,  ...,  0.0422, -0.0061,  0.0040],
        [-0.0079,  0.0139, -0.0144,  ..., -0.0011,  0.0380, -0.0324],
        [-0.0151, -0.0052,  0.0056,  ...,  0.0019, -0.0116,  0.0166]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5703, -4.7930,  1.0996,  ...,  0.1851, -6.5000,  1.0859]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 21:20:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is including, it includes
When something is occurring, it occurs
When something is publishing, it publishes
When something is describing, it describes
When something is referring, it refers
When something is explaining, it explains
When something is requiring, it requires
When something is allowing, it
2024-07-26 21:20:09 root INFO     [order_1_approx] starting weight calculation for When something is including, it includes
When something is allowing, it allows
When something is describing, it describes
When something is referring, it refers
When something is publishing, it publishes
When something is explaining, it explains
When something is occurring, it occurs
When something is requiring, it
2024-07-26 21:20:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 21:22:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2590,  0.0312, -0.3069,  ..., -0.1311, -0.2383, -0.2935],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1650, -2.9844,  2.5703,  ..., -0.2979, -5.0977, -0.9453],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0664, -0.0062,  0.0033,  ..., -0.0102, -0.0190,  0.0162],
        [-0.0008,  0.0541, -0.0151,  ...,  0.0124,  0.0032,  0.0299],
        [ 0.0137, -0.0019,  0.0620,  ..., -0.0077, -0.0060,  0.0092],
        ...,
        [ 0.0041,  0.0021,  0.0163,  ...,  0.0531, -0.0046,  0.0175],
        [-0.0175, -0.0171,  0.0151,  ..., -0.0183,  0.0673, -0.0484],
        [-0.0219,  0.0011,  0.0107,  ..., -0.0013, -0.0227,  0.0251]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1740, -3.2598,  3.1133,  ..., -0.0261, -4.9180, -0.6875]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 21:22:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is including, it includes
When something is allowing, it allows
When something is describing, it describes
When something is referring, it refers
When something is publishing, it publishes
When something is explaining, it explains
When something is occurring, it occurs
When something is requiring, it
2024-07-26 21:22:30 root INFO     [order_1_approx] starting weight calculation for When something is including, it includes
When something is occurring, it occurs
When something is allowing, it allows
When something is explaining, it explains
When something is requiring, it requires
When something is referring, it refers
When something is publishing, it publishes
When something is describing, it
2024-07-26 21:22:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 21:24:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0649, -0.3481, -0.0872,  ..., -0.1628,  0.2458, -0.6177],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6035, -3.9688,  4.0156,  ...,  0.3125, -4.1367, -1.8633],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0568, -0.0155, -0.0078,  ...,  0.0002,  0.0022, -0.0073],
        [ 0.0047,  0.0486,  0.0155,  ...,  0.0062, -0.0004,  0.0166],
        [ 0.0018,  0.0002,  0.0240,  ..., -0.0008, -0.0075, -0.0151],
        ...,
        [ 0.0128,  0.0088,  0.0197,  ...,  0.0471, -0.0046,  0.0181],
        [-0.0143,  0.0015, -0.0269,  ..., -0.0007,  0.0350, -0.0133],
        [ 0.0155, -0.0031,  0.0127,  ..., -0.0141, -0.0204,  0.0315]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3574, -3.8770,  4.2969,  ...,  0.6592, -4.1836, -1.6562]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 21:24:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is including, it includes
When something is occurring, it occurs
When something is allowing, it allows
When something is explaining, it explains
When something is requiring, it requires
When something is referring, it refers
When something is publishing, it publishes
When something is describing, it
2024-07-26 21:24:52 root INFO     [order_1_approx] starting weight calculation for When something is including, it includes
When something is explaining, it explains
When something is referring, it refers
When something is publishing, it publishes
When something is requiring, it requires
When something is allowing, it allows
When something is describing, it describes
When something is occurring, it
2024-07-26 21:24:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 21:27:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0167, -0.0984, -0.3989,  ..., -0.1171,  0.1033, -0.6084],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7441, -4.9727,  1.4307,  ..., -0.7100, -3.0898, -0.1016],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0634,  0.0067, -0.0161,  ...,  0.0108, -0.0095,  0.0298],
        [ 0.0124,  0.0522, -0.0019,  ...,  0.0185, -0.0064, -0.0027],
        [ 0.0017, -0.0030,  0.0383,  ..., -0.0226,  0.0006, -0.0073],
        ...,
        [ 0.0253,  0.0004, -0.0083,  ...,  0.0345, -0.0076, -0.0024],
        [-0.0052, -0.0224, -0.0023,  ..., -0.0065,  0.0342, -0.0247],
        [ 0.0028, -0.0145,  0.0079,  ..., -0.0093, -0.0097,  0.0357]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7778, -4.5273,  1.4365,  ..., -0.3279, -3.3555, -0.2559]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 21:27:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is including, it includes
When something is explaining, it explains
When something is referring, it refers
When something is publishing, it publishes
When something is requiring, it requires
When something is allowing, it allows
When something is describing, it describes
When something is occurring, it
2024-07-26 21:27:11 root INFO     [order_1_approx] starting weight calculation for When something is describing, it describes
When something is including, it includes
When something is occurring, it occurs
When something is explaining, it explains
When something is requiring, it requires
When something is referring, it refers
When something is allowing, it allows
When something is publishing, it
2024-07-26 21:27:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 21:29:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1255,  0.0387,  0.0341,  ..., -0.0670,  0.0481,  0.1595],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3633, -4.2695,  0.8027,  ..., -1.2373, -5.1602, -0.0449],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0511,  0.0051,  0.0033,  ...,  0.0264,  0.0035,  0.0259],
        [ 0.0088,  0.0516, -0.0084,  ...,  0.0177,  0.0013,  0.0134],
        [ 0.0207, -0.0030,  0.0297,  ..., -0.0088, -0.0318,  0.0051],
        ...,
        [-0.0038, -0.0049, -0.0099,  ...,  0.0555,  0.0198,  0.0177],
        [-0.0020,  0.0160, -0.0263,  ..., -0.0086,  0.0458, -0.0416],
        [ 0.0014, -0.0089,  0.0177,  ..., -0.0096, -0.0205,  0.0233]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2188, -4.4023,  0.7578,  ..., -1.1533, -4.8711, -0.0189]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 21:29:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is describing, it describes
When something is including, it includes
When something is occurring, it occurs
When something is explaining, it explains
When something is requiring, it requires
When something is referring, it refers
When something is allowing, it allows
When something is publishing, it
2024-07-26 21:29:31 root INFO     [order_1_approx] starting weight calculation for When something is allowing, it allows
When something is describing, it describes
When something is explaining, it explains
When something is requiring, it requires
When something is referring, it refers
When something is publishing, it publishes
When something is occurring, it occurs
When something is including, it
2024-07-26 21:29:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 21:31:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0048, -0.1072, -0.1119,  ...,  0.1929, -0.0842, -0.3645],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7686, -2.2109,  2.2402,  ..., -0.6646, -4.7852, -2.6230],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0715, -0.0083,  0.0119,  ...,  0.0208, -0.0111,  0.0087],
        [ 0.0068,  0.0874,  0.0131,  ...,  0.0195, -0.0054,  0.0003],
        [-0.0021, -0.0055,  0.0489,  ..., -0.0117, -0.0260, -0.0144],
        ...,
        [ 0.0377,  0.0065, -0.0068,  ...,  0.0514, -0.0207,  0.0199],
        [-0.0182,  0.0041, -0.0191,  ..., -0.0126,  0.0540, -0.0374],
        [-0.0189, -0.0001,  0.0036,  ..., -0.0099, -0.0266,  0.0411]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8999, -2.3691,  2.6816,  ..., -0.7529, -4.4922, -2.4551]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 21:31:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is allowing, it allows
When something is describing, it describes
When something is explaining, it explains
When something is requiring, it requires
When something is referring, it refers
When something is publishing, it publishes
When something is occurring, it occurs
When something is including, it
2024-07-26 21:31:49 root INFO     [order_1_approx] starting weight calculation for When something is occurring, it occurs
When something is requiring, it requires
When something is allowing, it allows
When something is including, it includes
When something is describing, it describes
When something is explaining, it explains
When something is publishing, it publishes
When something is referring, it
2024-07-26 21:31:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 21:34:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3599,  0.0174, -0.4106,  ...,  0.0614, -0.1493, -0.3376],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1382, -4.1289,  2.4512,  ...,  2.2539, -5.7969, -1.2129],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0527, -0.0085,  0.0105,  ...,  0.0177,  0.0022,  0.0235],
        [-0.0276,  0.0629,  0.0074,  ...,  0.0109, -0.0045,  0.0030],
        [ 0.0044, -0.0190,  0.0506,  ..., -0.0096, -0.0062, -0.0013],
        ...,
        [ 0.0208,  0.0329,  0.0045,  ...,  0.0768,  0.0101,  0.0310],
        [ 0.0183, -0.0170, -0.0120,  ..., -0.0021,  0.0553, -0.0476],
        [ 0.0031,  0.0038,  0.0207,  ..., -0.0186, -0.0066,  0.0391]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0623, -4.1602,  3.1523,  ...,  2.0215, -5.1719, -1.2803]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 21:34:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is occurring, it occurs
When something is requiring, it requires
When something is allowing, it allows
When something is including, it includes
When something is describing, it describes
When something is explaining, it explains
When something is publishing, it publishes
When something is referring, it
2024-07-26 21:34:11 root INFO     total operator prediction time: 1121.6407787799835 seconds
2024-07-26 21:34:11 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_inf - 3pSg
2024-07-26 21:34:11 root INFO     building operator verb_inf - 3pSg
2024-07-26 21:34:11 root INFO     [order_1_approx] starting weight calculation for I provide, he provides
I describe, he describes
I suggest, he suggests
I ensure, he ensures
I understand, he understands
I remain, he remains
I apply, he applies
I improve, he
2024-07-26 21:34:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 21:36:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0114, -0.1062, -0.1802,  ..., -0.4641, -0.0565,  0.1188],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.9648, -3.2461, -1.7754,  ...,  0.5527, -6.5859,  1.0195],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.3640e-02, -1.1337e-02, -1.5545e-03,  ..., -8.0109e-03,
          1.6281e-02,  1.9684e-02],
        [ 1.7452e-03,  2.2720e-02, -7.2479e-05,  ..., -7.5455e-03,
          8.5907e-03,  2.2850e-03],
        [ 2.2697e-03,  1.3046e-03,  9.8419e-03,  ..., -6.1493e-03,
          4.9706e-03, -9.9564e-04],
        ...,
        [-4.7913e-03,  7.1564e-03, -1.2238e-02,  ...,  3.6072e-02,
          5.5351e-03,  3.3493e-03],
        [ 4.3106e-04, -9.1171e-03, -1.6678e-02,  ..., -4.0016e-03,
          1.6983e-02, -2.5146e-02],
        [-2.0233e-02, -7.5073e-03,  3.2387e-03,  ..., -1.9089e-02,
          6.1264e-03,  2.7847e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.8281, -3.2305, -1.6240,  ...,  0.9907, -6.6797,  0.8643]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 21:36:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I provide, he provides
I describe, he describes
I suggest, he suggests
I ensure, he ensures
I understand, he understands
I remain, he remains
I apply, he applies
I improve, he
2024-07-26 21:36:31 root INFO     [order_1_approx] starting weight calculation for I apply, he applies
I ensure, he ensures
I remain, he remains
I understand, he understands
I provide, he provides
I improve, he improves
I suggest, he suggests
I describe, he
2024-07-26 21:36:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 21:38:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0632, -0.2898,  0.2385,  ..., -0.2103, -0.0162, -0.2952],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0176, -3.7637,  3.8594,  ..., -0.1689, -4.9102, -0.7129],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0379,  0.0047, -0.0095,  ...,  0.0047,  0.0130,  0.0172],
        [-0.0016,  0.0497,  0.0105,  ...,  0.0029,  0.0155,  0.0318],
        [-0.0068,  0.0012,  0.0093,  ..., -0.0091,  0.0013, -0.0117],
        ...,
        [ 0.0044, -0.0011,  0.0085,  ...,  0.0347,  0.0048,  0.0130],
        [-0.0195,  0.0069, -0.0272,  ..., -0.0209,  0.0208, -0.0229],
        [-0.0030, -0.0021, -0.0012,  ..., -0.0198, -0.0128,  0.0247]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5117, -3.9277,  3.8125,  ...,  0.1277, -4.8906, -0.4614]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 21:38:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I apply, he applies
I ensure, he ensures
I remain, he remains
I understand, he understands
I provide, he provides
I improve, he improves
I suggest, he suggests
I describe, he
2024-07-26 21:38:51 root INFO     [order_1_approx] starting weight calculation for I describe, he describes
I understand, he understands
I improve, he improves
I ensure, he ensures
I apply, he applies
I provide, he provides
I suggest, he suggests
I remain, he
2024-07-26 21:38:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 21:41:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0468, -0.2045, -0.2578,  ..., -0.2169, -0.1272,  0.2583],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1172, -4.2383, -1.3301,  ..., -2.5410, -6.0859, -2.4141],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0335, -0.0145, -0.0033,  ...,  0.0158,  0.0082,  0.0243],
        [-0.0028,  0.0429, -0.0040,  ...,  0.0021,  0.0166, -0.0096],
        [-0.0090,  0.0038,  0.0451,  ..., -0.0170, -0.0087,  0.0118],
        ...,
        [ 0.0154,  0.0094, -0.0083,  ...,  0.0332, -0.0014,  0.0079],
        [-0.0267, -0.0097, -0.0096,  ..., -0.0276,  0.0165, -0.0563],
        [-0.0002,  0.0061, -0.0182,  ..., -0.0149, -0.0128,  0.0226]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7607, -3.7734, -1.3760,  ..., -1.7891, -5.7891, -1.9414]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 21:41:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I describe, he describes
I understand, he understands
I improve, he improves
I ensure, he ensures
I apply, he applies
I provide, he provides
I suggest, he suggests
I remain, he
2024-07-26 21:41:12 root INFO     [order_1_approx] starting weight calculation for I improve, he improves
I ensure, he ensures
I remain, he remains
I understand, he understands
I describe, he describes
I suggest, he suggests
I apply, he applies
I provide, he
2024-07-26 21:41:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 21:43:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4626, -0.2979, -0.2825,  ..., -0.5181, -0.1965, -0.0464],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7227, -4.7656,  0.8887,  ..., -0.9775, -8.2812, -0.0137],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.1727e-02,  2.2430e-03,  1.2039e-02,  ...,  1.7365e-02,
         -5.0812e-03,  3.7537e-02],
        [-1.4481e-02,  3.2104e-02,  5.0354e-03,  ...,  1.8120e-05,
          1.8478e-02,  1.2054e-02],
        [-7.2632e-03,  8.7128e-03,  2.7588e-02,  ..., -2.3331e-02,
         -6.2866e-03, -6.5613e-04],
        ...,
        [ 8.1406e-03,  8.6975e-03,  2.5501e-03,  ...,  3.5004e-02,
          2.0203e-02,  1.4748e-02],
        [-1.0773e-02, -6.1722e-03, -1.6815e-02,  ..., -3.6774e-02,
          1.4969e-02, -2.2751e-02],
        [-1.2093e-03,  6.4354e-03, -1.0284e-02,  ..., -3.0060e-02,
         -2.4071e-03,  3.0731e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4531, -4.5352,  0.9219,  ..., -0.5508, -7.7539,  0.3218]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 21:43:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I improve, he improves
I ensure, he ensures
I remain, he remains
I understand, he understands
I describe, he describes
I suggest, he suggests
I apply, he applies
I provide, he
2024-07-26 21:43:34 root INFO     [order_1_approx] starting weight calculation for I provide, he provides
I ensure, he ensures
I remain, he remains
I understand, he understands
I apply, he applies
I describe, he describes
I improve, he improves
I suggest, he
2024-07-26 21:43:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 21:45:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1704, -0.0480,  0.2622,  ...,  0.0652, -0.3652,  0.0078],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.8359, -3.3223, -1.1836,  ...,  1.7324, -5.6719,  2.0039],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0561, -0.0118,  0.0001,  ..., -0.0134, -0.0143,  0.0120],
        [-0.0241,  0.0348, -0.0047,  ..., -0.0009,  0.0211,  0.0237],
        [-0.0151,  0.0120,  0.0172,  ..., -0.0326,  0.0022, -0.0102],
        ...,
        [-0.0211,  0.0008, -0.0018,  ...,  0.0297,  0.0147,  0.0046],
        [-0.0312,  0.0162, -0.0264,  ..., -0.0297,  0.0259, -0.0482],
        [-0.0142,  0.0146,  0.0136,  ..., -0.0141, -0.0181,  0.0069]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.4688, -3.1445, -0.8687,  ...,  1.9844, -5.7109,  1.9111]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 21:45:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I provide, he provides
I ensure, he ensures
I remain, he remains
I understand, he understands
I apply, he applies
I describe, he describes
I improve, he improves
I suggest, he
2024-07-26 21:45:55 root INFO     [order_1_approx] starting weight calculation for I remain, he remains
I improve, he improves
I understand, he understands
I suggest, he suggests
I provide, he provides
I ensure, he ensures
I describe, he describes
I apply, he
2024-07-26 21:45:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 21:48:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1372, -0.0871,  0.2188,  ..., -0.1564, -0.0979, -0.0836],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0430, -2.7637, -1.2422,  ..., -0.3125, -8.0469, -0.7510],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0453,  0.0112,  0.0007,  ...,  0.0041, -0.0082,  0.0321],
        [-0.0213,  0.0511,  0.0145,  ..., -0.0205,  0.0099,  0.0062],
        [ 0.0018, -0.0021,  0.0154,  ..., -0.0270,  0.0066, -0.0101],
        ...,
        [ 0.0011,  0.0023, -0.0110,  ...,  0.0445,  0.0189,  0.0031],
        [-0.0283, -0.0102, -0.0051,  ..., -0.0182,  0.0279, -0.0350],
        [-0.0148,  0.0016,  0.0173,  ..., -0.0179, -0.0049,  0.0095]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4902, -3.4688, -0.4429,  ..., -0.1030, -7.5156, -0.3887]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 21:48:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I remain, he remains
I improve, he improves
I understand, he understands
I suggest, he suggests
I provide, he provides
I ensure, he ensures
I describe, he describes
I apply, he
2024-07-26 21:48:18 root INFO     [order_1_approx] starting weight calculation for I remain, he remains
I apply, he applies
I suggest, he suggests
I describe, he describes
I provide, he provides
I ensure, he ensures
I improve, he improves
I understand, he
2024-07-26 21:48:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 21:50:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1677,  0.0507,  0.0525,  ..., -0.1078, -0.0774, -0.1931],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6680, -2.8164, -1.0742,  ..., -0.7129, -5.3867,  2.3848],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0356, -0.0057, -0.0072,  ..., -0.0133, -0.0008,  0.0251],
        [-0.0023,  0.0334,  0.0025,  ...,  0.0009,  0.0110,  0.0149],
        [-0.0147, -0.0010,  0.0181,  ..., -0.0248,  0.0037, -0.0210],
        ...,
        [-0.0058, -0.0038, -0.0079,  ...,  0.0100,  0.0148,  0.0016],
        [-0.0197, -0.0066, -0.0078,  ..., -0.0266,  0.0309, -0.0232],
        [-0.0242, -0.0043,  0.0012,  ..., -0.0095, -0.0110, -0.0087]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4258, -3.0039, -0.8232,  ..., -0.5181, -5.5273,  2.1211]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 21:50:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I remain, he remains
I apply, he applies
I suggest, he suggests
I describe, he describes
I provide, he provides
I ensure, he ensures
I improve, he improves
I understand, he
2024-07-26 21:50:40 root INFO     [order_1_approx] starting weight calculation for I understand, he understands
I provide, he provides
I describe, he describes
I improve, he improves
I remain, he remains
I suggest, he suggests
I apply, he applies
I ensure, he
2024-07-26 21:50:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 21:53:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0209,  0.2007, -0.2705,  ..., -0.0352, -0.0469, -0.2313],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2344, -3.0273, -0.9355,  ..., -0.4128, -8.9219, -1.3818],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0276,  0.0012,  0.0099,  ...,  0.0013, -0.0004,  0.0374],
        [-0.0241,  0.0391,  0.0137,  ..., -0.0119,  0.0198, -0.0025],
        [ 0.0102,  0.0118,  0.0204,  ..., -0.0142, -0.0051,  0.0037],
        ...,
        [-0.0072, -0.0151, -0.0010,  ...,  0.0182,  0.0171,  0.0088],
        [ 0.0009,  0.0035, -0.0174,  ..., -0.0087,  0.0162, -0.0214],
        [ 0.0024, -0.0023,  0.0020,  ..., -0.0094, -0.0243,  0.0115]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3223, -3.3379, -0.7300,  ...,  0.0759, -8.6484, -1.0674]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 21:53:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I understand, he understands
I provide, he provides
I describe, he describes
I improve, he improves
I remain, he remains
I suggest, he suggests
I apply, he applies
I ensure, he
2024-07-26 21:53:01 root INFO     total operator prediction time: 1130.4310748577118 seconds
2024-07-26 21:53:01 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_inf - Ved
2024-07-26 21:53:01 root INFO     building operator verb_inf - Ved
2024-07-26 21:53:01 root INFO     [order_1_approx] starting weight calculation for If the present form is consider, the past form is considered
If the present form is achieve, the past form is achieved
If the present form is accept, the past form is accepted
If the present form is hear, the past form is heard
If the present form is add, the past form is added
If the present form is ask, the past form is asked
If the present form is publish, the past form is published
If the present form is discover, the past form is
2024-07-26 21:53:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 21:55:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0524,  0.1975, -0.0521,  ..., -0.4751, -0.6494,  0.0573],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2188, -1.7334,  2.3555,  ..., -0.7925, -0.9390,  0.2109],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0583, -0.0093,  0.0166,  ...,  0.0032,  0.0019,  0.0177],
        [-0.0059,  0.0532,  0.0223,  ...,  0.0151, -0.0056,  0.0038],
        [-0.0026,  0.0069,  0.0318,  ..., -0.0075, -0.0144, -0.0073],
        ...,
        [-0.0125,  0.0081,  0.0003,  ...,  0.0661,  0.0073, -0.0009],
        [ 0.0057,  0.0063, -0.0042,  ..., -0.0136,  0.0368, -0.0083],
        [-0.0060, -0.0199,  0.0211,  ..., -0.0250, -0.0152,  0.0294]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1191, -1.9043,  2.3320,  ..., -0.6235, -0.5693,  0.3276]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 21:55:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is consider, the past form is considered
If the present form is achieve, the past form is achieved
If the present form is accept, the past form is accepted
If the present form is hear, the past form is heard
If the present form is add, the past form is added
If the present form is ask, the past form is asked
If the present form is publish, the past form is published
If the present form is discover, the past form is
2024-07-26 21:55:22 root INFO     [order_1_approx] starting weight calculation for If the present form is hear, the past form is heard
If the present form is discover, the past form is discovered
If the present form is consider, the past form is considered
If the present form is accept, the past form is accepted
If the present form is ask, the past form is asked
If the present form is add, the past form is added
If the present form is publish, the past form is published
If the present form is achieve, the past form is
2024-07-26 21:55:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 21:57:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0354,  0.1448, -0.3403,  ..., -0.7183, -0.5029,  0.2856],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5732,  1.5361, -0.3999,  ..., -2.5312, -1.6387, -0.4639],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0496, -0.0042,  0.0145,  ...,  0.0080,  0.0162,  0.0395],
        [-0.0176,  0.0659,  0.0205,  ...,  0.0067,  0.0037, -0.0073],
        [ 0.0104,  0.0032,  0.0351,  ..., -0.0031, -0.0090,  0.0093],
        ...,
        [-0.0091,  0.0071, -0.0204,  ...,  0.0602,  0.0219,  0.0119],
        [ 0.0041, -0.0060,  0.0107,  ..., -0.0121,  0.0122, -0.0176],
        [ 0.0066, -0.0097,  0.0040,  ..., -0.0126, -0.0050,  0.0257]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6060,  1.2100, -0.6553,  ..., -2.2441, -1.7188, -0.1042]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 21:57:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is hear, the past form is heard
If the present form is discover, the past form is discovered
If the present form is consider, the past form is considered
If the present form is accept, the past form is accepted
If the present form is ask, the past form is asked
If the present form is add, the past form is added
If the present form is publish, the past form is published
If the present form is achieve, the past form is
2024-07-26 21:57:43 root INFO     [order_1_approx] starting weight calculation for If the present form is achieve, the past form is achieved
If the present form is ask, the past form is asked
If the present form is accept, the past form is accepted
If the present form is hear, the past form is heard
If the present form is publish, the past form is published
If the present form is consider, the past form is considered
If the present form is discover, the past form is discovered
If the present form is add, the past form is
2024-07-26 21:57:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 22:00:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0845, -0.2791,  0.0013,  ...,  0.0104, -0.0131, -0.0968],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5771, -0.1401, -1.2812,  ...,  0.4604, -3.5254, -0.3037],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0694, -0.0109, -0.0078,  ...,  0.0026, -0.0056, -0.0074],
        [-0.0039,  0.0720,  0.0226,  ...,  0.0159, -0.0039, -0.0145],
        [ 0.0214,  0.0138,  0.0402,  ..., -0.0017, -0.0165,  0.0099],
        ...,
        [ 0.0191, -0.0080,  0.0159,  ...,  0.0671, -0.0042,  0.0112],
        [ 0.0075, -0.0105,  0.0037,  ..., -0.0212,  0.0446, -0.0115],
        [-0.0328,  0.0150, -0.0088,  ..., -0.0308, -0.0367,  0.0452]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7500, -0.0518, -1.2490,  ...,  0.7388, -3.0527,  0.0632]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 22:00:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is achieve, the past form is achieved
If the present form is ask, the past form is asked
If the present form is accept, the past form is accepted
If the present form is hear, the past form is heard
If the present form is publish, the past form is published
If the present form is consider, the past form is considered
If the present form is discover, the past form is discovered
If the present form is add, the past form is
2024-07-26 22:00:01 root INFO     [order_1_approx] starting weight calculation for If the present form is ask, the past form is asked
If the present form is publish, the past form is published
If the present form is consider, the past form is considered
If the present form is discover, the past form is discovered
If the present form is accept, the past form is accepted
If the present form is achieve, the past form is achieved
If the present form is add, the past form is added
If the present form is hear, the past form is
2024-07-26 22:00:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 22:02:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0231, -0.0444,  0.0704,  ...,  0.2292, -0.3560, -0.0181],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.5420, -0.8628,  1.1543,  ..., -0.5767, -2.9062, -2.7734],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0864, -0.0171,  0.0090,  ..., -0.0007,  0.0188,  0.0344],
        [-0.0025,  0.0861, -0.0019,  ...,  0.0153,  0.0103, -0.0164],
        [-0.0044,  0.0138,  0.0656,  ..., -0.0175, -0.0298,  0.0092],
        ...,
        [ 0.0114,  0.0119, -0.0095,  ...,  0.0480,  0.0152, -0.0196],
        [ 0.0062,  0.0288,  0.0111,  ...,  0.0067,  0.0309, -0.0109],
        [-0.0113, -0.0027,  0.0117,  ..., -0.0104,  0.0155,  0.0440]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.4268, -1.0684,  0.9336,  ..., -0.2317, -2.7949, -2.7383]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 22:02:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is ask, the past form is asked
If the present form is publish, the past form is published
If the present form is consider, the past form is considered
If the present form is discover, the past form is discovered
If the present form is accept, the past form is accepted
If the present form is achieve, the past form is achieved
If the present form is add, the past form is added
If the present form is hear, the past form is
2024-07-26 22:02:21 root INFO     [order_1_approx] starting weight calculation for If the present form is publish, the past form is published
If the present form is hear, the past form is heard
If the present form is accept, the past form is accepted
If the present form is achieve, the past form is achieved
If the present form is discover, the past form is discovered
If the present form is add, the past form is added
If the present form is consider, the past form is considered
If the present form is ask, the past form is
2024-07-26 22:02:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 22:04:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1149, -0.1143, -0.0621,  ...,  0.0436, -0.2600, -0.5337],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4199, -2.5703, -0.7729,  ...,  1.0986, -2.3438, -0.4883],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0524, -0.0178,  0.0181,  ..., -0.0074,  0.0124,  0.0020],
        [-0.0065,  0.0379,  0.0066,  ...,  0.0045, -0.0016, -0.0144],
        [-0.0057,  0.0020,  0.0266,  ..., -0.0083, -0.0069, -0.0066],
        ...,
        [-0.0094,  0.0152,  0.0038,  ...,  0.0333,  0.0128, -0.0013],
        [ 0.0227,  0.0020, -0.0081,  ...,  0.0061,  0.0029,  0.0037],
        [-0.0116,  0.0143,  0.0024,  ..., -0.0031, -0.0055,  0.0117]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4185, -2.4199, -0.7866,  ...,  1.0049, -2.1738, -0.5322]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 22:04:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is publish, the past form is published
If the present form is hear, the past form is heard
If the present form is accept, the past form is accepted
If the present form is achieve, the past form is achieved
If the present form is discover, the past form is discovered
If the present form is add, the past form is added
If the present form is consider, the past form is considered
If the present form is ask, the past form is
2024-07-26 22:04:42 root INFO     [order_1_approx] starting weight calculation for If the present form is add, the past form is added
If the present form is ask, the past form is asked
If the present form is hear, the past form is heard
If the present form is consider, the past form is considered
If the present form is achieve, the past form is achieved
If the present form is discover, the past form is discovered
If the present form is accept, the past form is accepted
If the present form is publish, the past form is
2024-07-26 22:04:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 22:07:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1821,  0.0784,  0.2795,  ..., -0.0388,  0.0134,  0.4329],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7402, -2.0449,  0.6357,  ..., -2.4609, -1.5752,  1.5635],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0429, -0.0097,  0.0080,  ...,  0.0059,  0.0152,  0.0301],
        [-0.0200,  0.0447,  0.0111,  ...,  0.0015,  0.0075, -0.0169],
        [ 0.0223,  0.0038,  0.0206,  ..., -0.0151, -0.0252,  0.0130],
        ...,
        [-0.0025, -0.0015, -0.0138,  ...,  0.0458,  0.0224,  0.0113],
        [ 0.0028, -0.0188, -0.0059,  ..., -0.0105,  0.0095, -0.0111],
        [-0.0062, -0.0024,  0.0075,  ..., -0.0192, -0.0209,  0.0199]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6660, -2.3125,  0.5664,  ..., -2.3105, -0.7871,  1.5312]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 22:07:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is add, the past form is added
If the present form is ask, the past form is asked
If the present form is hear, the past form is heard
If the present form is consider, the past form is considered
If the present form is achieve, the past form is achieved
If the present form is discover, the past form is discovered
If the present form is accept, the past form is accepted
If the present form is publish, the past form is
2024-07-26 22:07:01 root INFO     [order_1_approx] starting weight calculation for If the present form is consider, the past form is considered
If the present form is ask, the past form is asked
If the present form is achieve, the past form is achieved
If the present form is hear, the past form is heard
If the present form is publish, the past form is published
If the present form is discover, the past form is discovered
If the present form is add, the past form is added
If the present form is accept, the past form is
2024-07-26 22:07:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 22:09:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2384,  0.3774, -0.2074,  ..., -0.0443, -0.1932,  0.1223],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6328,  1.1133, -1.2314,  ..., -0.9375, -2.5020,  0.7021],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.4739e-02, -3.0731e-02,  6.8474e-03,  ..., -1.2985e-02,
          3.5553e-03,  3.4729e-02],
        [-2.6810e-02,  5.5328e-02,  1.0643e-02,  ...,  3.9749e-03,
         -6.6528e-03, -2.2034e-02],
        [ 7.1487e-03,  1.3321e-02,  4.8279e-02,  ..., -7.1182e-03,
         -4.1870e-02, -7.3967e-03],
        ...,
        [-1.4305e-05, -1.0216e-02, -2.9099e-02,  ...,  6.1951e-02,
          2.5345e-02, -2.4078e-02],
        [ 6.6299e-03,  3.8471e-03, -1.0719e-03,  ..., -4.0512e-03,
          1.5579e-02, -9.0714e-03],
        [-2.0355e-02, -1.3885e-02, -7.7095e-03,  ..., -2.9938e-02,
         -1.9104e-02,  3.2562e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6255,  1.0098, -1.4443,  ..., -0.2285, -2.4004,  1.0146]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 22:09:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is consider, the past form is considered
If the present form is ask, the past form is asked
If the present form is achieve, the past form is achieved
If the present form is hear, the past form is heard
If the present form is publish, the past form is published
If the present form is discover, the past form is discovered
If the present form is add, the past form is added
If the present form is accept, the past form is
2024-07-26 22:09:19 root INFO     [order_1_approx] starting weight calculation for If the present form is add, the past form is added
If the present form is publish, the past form is published
If the present form is ask, the past form is asked
If the present form is achieve, the past form is achieved
If the present form is accept, the past form is accepted
If the present form is discover, the past form is discovered
If the present form is hear, the past form is heard
If the present form is consider, the past form is
2024-07-26 22:09:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 22:11:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0410, -0.1755,  0.0120,  ..., -0.1262,  0.0201,  0.0377],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2129, -0.3145,  2.0684,  ..., -2.4336, -0.5278,  0.1680],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0764, -0.0287,  0.0220,  ...,  0.0106, -0.0028,  0.0432],
        [-0.0234,  0.0449,  0.0154,  ...,  0.0038,  0.0081, -0.0069],
        [-0.0079,  0.0321,  0.0588,  ..., -0.0159, -0.0267,  0.0044],
        ...,
        [ 0.0002, -0.0034,  0.0131,  ...,  0.0648,  0.0068, -0.0030],
        [ 0.0130,  0.0148, -0.0009,  ..., -0.0060,  0.0106, -0.0112],
        [-0.0027,  0.0042,  0.0202,  ..., -0.0220, -0.0114,  0.0129]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2246, -0.3171,  1.6973,  ..., -2.1895, -0.6416,  0.6504]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 22:11:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is add, the past form is added
If the present form is publish, the past form is published
If the present form is ask, the past form is asked
If the present form is achieve, the past form is achieved
If the present form is accept, the past form is accepted
If the present form is discover, the past form is discovered
If the present form is hear, the past form is heard
If the present form is consider, the past form is
2024-07-26 22:11:39 root INFO     total operator prediction time: 1118.2593727111816 seconds
2024-07-26 22:11:39 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_Ving - Ved
2024-07-26 22:11:39 root INFO     building operator verb_Ving - Ved
2024-07-26 22:11:40 root INFO     [order_1_approx] starting weight calculation for After something is representing, it has represented
After something is following, it has followed
After something is improving, it has improved
After something is requiring, it has required
After something is failing, it has failed
After something is reducing, it has reduced
After something is describing, it has described
After something is managing, it has
2024-07-26 22:11:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 22:14:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0793,  0.2773, -0.1224,  ..., -0.0914, -0.0693, -0.2588],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2988, -0.9487,  2.2207,  ..., -1.9707, -1.7275, -2.4785],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0347,  0.0144, -0.0045,  ..., -0.0200, -0.0085,  0.0088],
        [-0.0187,  0.0340,  0.0147,  ...,  0.0134,  0.0187,  0.0060],
        [ 0.0003, -0.0025,  0.0316,  ..., -0.0073,  0.0043, -0.0163],
        ...,
        [ 0.0086,  0.0165,  0.0020,  ...,  0.0464, -0.0108,  0.0022],
        [ 0.0089,  0.0003, -0.0048,  ...,  0.0017,  0.0191, -0.0190],
        [-0.0159,  0.0120,  0.0031,  ..., -0.0165, -0.0017, -0.0034]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2031, -1.3457,  2.0000,  ..., -1.6729, -1.8467, -2.3828]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 22:14:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is representing, it has represented
After something is following, it has followed
After something is improving, it has improved
After something is requiring, it has required
After something is failing, it has failed
After something is reducing, it has reduced
After something is describing, it has described
After something is managing, it has
2024-07-26 22:14:01 root INFO     [order_1_approx] starting weight calculation for After something is managing, it has managed
After something is representing, it has represented
After something is following, it has followed
After something is describing, it has described
After something is reducing, it has reduced
After something is improving, it has improved
After something is failing, it has failed
After something is requiring, it has
2024-07-26 22:14:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 22:16:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3545, -0.0308, -0.4387,  ..., -0.3298, -0.1266, -0.1112],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3721,  0.7690,  1.6982,  ..., -2.4004, -2.8223, -1.9043],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0436, -0.0129,  0.0208,  ...,  0.0064, -0.0099, -0.0020],
        [-0.0550,  0.0522, -0.0191,  ..., -0.0009, -0.0051,  0.0222],
        [-0.0031, -0.0127,  0.0354,  ..., -0.0110,  0.0117, -0.0055],
        ...,
        [ 0.0074,  0.0304, -0.0017,  ...,  0.0590,  0.0061,  0.0087],
        [ 0.0118, -0.0009,  0.0229,  ..., -0.0070,  0.0372, -0.0370],
        [-0.0063,  0.0156,  0.0115,  ..., -0.0013, -0.0098,  0.0322]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4512,  0.4165,  2.0566,  ..., -2.0547, -2.1250, -1.6553]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 22:16:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is managing, it has managed
After something is representing, it has represented
After something is following, it has followed
After something is describing, it has described
After something is reducing, it has reduced
After something is improving, it has improved
After something is failing, it has failed
After something is requiring, it has
2024-07-26 22:16:23 root INFO     [order_1_approx] starting weight calculation for After something is representing, it has represented
After something is managing, it has managed
After something is describing, it has described
After something is improving, it has improved
After something is requiring, it has required
After something is failing, it has failed
After something is following, it has followed
After something is reducing, it has
2024-07-26 22:16:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 22:18:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0117, -0.1980, -0.5063,  ..., -0.2218,  0.3052, -0.4607],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.8926, -0.0234,  0.4512,  ..., -5.0000, -1.5771, -4.9453],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.7922e-02,  3.8147e-06, -5.8365e-03,  ...,  1.4435e-02,
          2.9869e-03,  2.3331e-02],
        [-3.2196e-02,  4.3274e-02,  2.2522e-02,  ...,  1.6220e-02,
          8.7280e-03,  1.7868e-02],
        [-7.6370e-03, -9.5901e-03,  2.1149e-02,  ..., -1.6708e-02,
         -3.9978e-03,  1.4496e-04],
        ...,
        [ 2.3148e-02, -2.0370e-03, -1.8433e-02,  ...,  4.8492e-02,
          1.3298e-02,  1.8951e-02],
        [ 1.1810e-02,  6.9733e-03, -1.8387e-02,  ...,  3.0823e-03,
          4.4098e-02, -1.5198e-02],
        [-2.8305e-03, -3.5715e-04,  1.4168e-02,  ..., -6.8512e-03,
         -1.2131e-02,  7.0610e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.1133, -0.4429,  0.4929,  ..., -4.0039, -1.9297, -4.8945]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 22:18:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is representing, it has represented
After something is managing, it has managed
After something is describing, it has described
After something is improving, it has improved
After something is requiring, it has required
After something is failing, it has failed
After something is following, it has followed
After something is reducing, it has
2024-07-26 22:18:44 root INFO     [order_1_approx] starting weight calculation for After something is failing, it has failed
After something is managing, it has managed
After something is improving, it has improved
After something is describing, it has described
After something is requiring, it has required
After something is representing, it has represented
After something is reducing, it has reduced
After something is following, it has
2024-07-26 22:18:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 22:21:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0127, -0.1895, -0.2188,  ..., -0.2405,  0.0497,  0.0039],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8516, -0.9287,  3.5996,  ..., -0.4214, -3.5996, -0.4316],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0862,  0.0169, -0.0031,  ..., -0.0025,  0.0249,  0.0149],
        [-0.0327,  0.0978,  0.0074,  ...,  0.0139, -0.0060, -0.0099],
        [-0.0079,  0.0115,  0.0587,  ...,  0.0082,  0.0040, -0.0144],
        ...,
        [ 0.0122,  0.0471, -0.0147,  ...,  0.0673, -0.0140, -0.0083],
        [ 0.0018,  0.0211, -0.0093,  ...,  0.0201,  0.0104, -0.0175],
        [-0.0098,  0.0284,  0.0038,  ..., -0.0265,  0.0019,  0.0388]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2480, -1.3691,  3.9375,  ..., -0.1099, -3.0898, -0.6074]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 22:21:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is failing, it has failed
After something is managing, it has managed
After something is improving, it has improved
After something is describing, it has described
After something is requiring, it has required
After something is representing, it has represented
After something is reducing, it has reduced
After something is following, it has
2024-07-26 22:21:07 root INFO     [order_1_approx] starting weight calculation for After something is describing, it has described
After something is improving, it has improved
After something is managing, it has managed
After something is reducing, it has reduced
After something is requiring, it has required
After something is following, it has followed
After something is failing, it has failed
After something is representing, it has
2024-07-26 22:21:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 22:23:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0725, -0.0781, -0.3823,  ..., -0.2766,  0.1055, -0.2957],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4961,  1.2812,  2.0820,  ..., -1.0010, -1.5156, -1.0557],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0854, -0.0022, -0.0004,  ...,  0.0095, -0.0012,  0.0173],
        [-0.0504,  0.0894,  0.0024,  ...,  0.0163,  0.0101, -0.0234],
        [ 0.0195,  0.0090,  0.0502,  ...,  0.0002, -0.0194, -0.0107],
        ...,
        [ 0.0235,  0.0313, -0.0372,  ...,  0.0988, -0.0228,  0.0087],
        [ 0.0059,  0.0152, -0.0127,  ..., -0.0157,  0.0612, -0.0339],
        [-0.0214,  0.0091,  0.0125,  ..., -0.0099, -0.0246,  0.0702]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2141,  1.1162,  2.2402,  ..., -0.9023, -1.4180, -1.2725]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 22:23:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is describing, it has described
After something is improving, it has improved
After something is managing, it has managed
After something is reducing, it has reduced
After something is requiring, it has required
After something is following, it has followed
After something is failing, it has failed
After something is representing, it has
2024-07-26 22:23:29 root INFO     [order_1_approx] starting weight calculation for After something is managing, it has managed
After something is requiring, it has required
After something is representing, it has represented
After something is following, it has followed
After something is failing, it has failed
After something is describing, it has described
After something is reducing, it has reduced
After something is improving, it has
2024-07-26 22:23:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 22:25:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2239, -0.3379, -0.1208,  ..., -0.4075,  0.2488,  0.2229],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0547, -0.8418,  1.2598,  ..., -1.7266, -1.0449, -1.8340],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0212, -0.0037,  0.0022,  ..., -0.0005, -0.0129,  0.0190],
        [-0.0060,  0.0318,  0.0111,  ...,  0.0214,  0.0083,  0.0191],
        [-0.0058, -0.0098,  0.0064,  ...,  0.0011,  0.0163, -0.0038],
        ...,
        [-0.0003,  0.0103, -0.0094,  ...,  0.0243,  0.0104,  0.0070],
        [ 0.0116,  0.0037, -0.0095,  ..., -0.0008,  0.0068, -0.0152],
        [-0.0072,  0.0133,  0.0186,  ..., -0.0042, -0.0094, -0.0083]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7988, -1.0410,  1.3096,  ..., -1.3838, -1.1846, -2.2734]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 22:25:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is managing, it has managed
After something is requiring, it has required
After something is representing, it has represented
After something is following, it has followed
After something is failing, it has failed
After something is describing, it has described
After something is reducing, it has reduced
After something is improving, it has
2024-07-26 22:25:52 root INFO     [order_1_approx] starting weight calculation for After something is reducing, it has reduced
After something is following, it has followed
After something is representing, it has represented
After something is failing, it has failed
After something is managing, it has managed
After something is improving, it has improved
After something is requiring, it has required
After something is describing, it has
2024-07-26 22:25:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 22:28:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1407, -0.3093,  0.0020,  ...,  0.1414,  0.1597, -0.6709],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5645,  0.3770,  4.3867,  ..., -0.4106, -0.1650, -1.9648],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0300, -0.0043, -0.0157,  ...,  0.0065,  0.0202,  0.0074],
        [-0.0183,  0.0482,  0.0097,  ...,  0.0045,  0.0080,  0.0082],
        [ 0.0020, -0.0112,  0.0217,  ...,  0.0119, -0.0039, -0.0155],
        ...,
        [ 0.0141,  0.0281,  0.0071,  ...,  0.0494,  0.0163,  0.0163],
        [ 0.0024,  0.0004, -0.0043,  ..., -0.0019,  0.0313,  0.0053],
        [ 0.0064,  0.0181,  0.0036,  ..., -0.0132, -0.0220,  0.0238]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5059,  0.4766,  4.3867,  ..., -0.1387, -0.1681, -1.7822]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 22:28:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is reducing, it has reduced
After something is following, it has followed
After something is representing, it has represented
After something is failing, it has failed
After something is managing, it has managed
After something is improving, it has improved
After something is requiring, it has required
After something is describing, it has
2024-07-26 22:28:13 root INFO     [order_1_approx] starting weight calculation for After something is describing, it has described
After something is representing, it has represented
After something is requiring, it has required
After something is managing, it has managed
After something is reducing, it has reduced
After something is improving, it has improved
After something is following, it has followed
After something is failing, it has
2024-07-26 22:28:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 22:30:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2725,  0.0495, -0.6602,  ..., -0.2756,  0.3838, -0.3865],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5996, -0.8486,  3.6934,  ..., -2.3242, -1.2383, -1.7559],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.5563e-02, -8.2550e-03,  2.3041e-03,  ...,  1.3962e-02,
         -2.9099e-02,  2.8931e-02],
        [-3.4393e-02,  4.7363e-02,  7.2250e-03,  ...,  9.7809e-03,
          1.8967e-02, -1.4343e-03],
        [-7.9498e-03, -4.0054e-05,  2.4231e-02,  ..., -2.9877e-02,
          1.8295e-02, -1.1063e-02],
        ...,
        [ 2.2278e-02,  8.5602e-03, -4.9286e-03,  ...,  2.5436e-02,
          5.7678e-03, -2.7351e-03],
        [ 1.2489e-02,  1.5388e-02,  2.6321e-04,  ...,  9.7046e-03,
          1.6479e-02, -2.5406e-02],
        [-1.7471e-03,  2.2659e-02,  2.2202e-03,  ..., -1.4503e-02,
         -2.1858e-03,  8.3160e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4253, -1.2168,  3.4551,  ..., -2.0547, -0.4883, -1.3613]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 22:30:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is describing, it has described
After something is representing, it has represented
After something is requiring, it has required
After something is managing, it has managed
After something is reducing, it has reduced
After something is improving, it has improved
After something is following, it has followed
After something is failing, it has
2024-07-26 22:30:36 root INFO     total operator prediction time: 1136.7036781311035 seconds
2024-07-26 22:30:36 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on Ving - verb_inf
2024-07-26 22:30:36 root INFO     building operator Ving - verb_inf
2024-07-26 22:30:36 root INFO     [order_1_approx] starting weight calculation for requiring is the active form of require
believing is the active form of believe
encouraging is the active form of encourage
asking is the active form of ask
spending is the active form of spend
providing is the active form of provide
including is the active form of include
attending is the active form of
2024-07-26 22:30:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 22:32:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2021, -0.1354, -0.3599,  ..., -0.3831, -0.1300,  0.0188],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2852, -2.6367, -1.8125,  ...,  1.9326, -2.8008, -3.2383],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.5195e-02,  6.2332e-03, -6.5231e-04,  ...,  1.2192e-02,
          6.4316e-03,  1.2238e-02],
        [-5.1975e-05,  6.9519e-02,  1.0330e-02,  ...,  7.4120e-03,
         -1.0548e-03, -8.7814e-03],
        [ 1.7517e-02, -3.1738e-03,  5.7098e-02,  ..., -4.2105e-04,
          2.9449e-03,  6.7253e-03],
        ...,
        [-3.0060e-03,  3.6240e-03, -5.2872e-03,  ...,  5.5786e-02,
         -6.5308e-03, -9.1743e-04],
        [-2.0020e-02, -1.3290e-02,  2.6798e-03,  ...,  9.2773e-03,
          4.8828e-02, -4.3221e-03],
        [ 3.6583e-03,  3.6373e-03, -1.7853e-02,  ..., -3.8147e-06,
         -1.4671e-02,  5.0720e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1875, -2.8652, -2.0801,  ...,  2.0000, -2.6055, -3.2910]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 22:32:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for requiring is the active form of require
believing is the active form of believe
encouraging is the active form of encourage
asking is the active form of ask
spending is the active form of spend
providing is the active form of provide
including is the active form of include
attending is the active form of
2024-07-26 22:32:56 root INFO     [order_1_approx] starting weight calculation for attending is the active form of attend
encouraging is the active form of encourage
including is the active form of include
spending is the active form of spend
asking is the active form of ask
requiring is the active form of require
believing is the active form of believe
providing is the active form of
2024-07-26 22:32:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 22:35:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2443, -0.3809, -0.2979,  ..., -0.1593,  0.1903, -0.0691],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1641, -6.0938,  0.0410,  ...,  2.3711, -2.2422, -1.1191],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0908, -0.0041,  0.0075,  ...,  0.0116, -0.0105,  0.0281],
        [ 0.0025,  0.0410,  0.0103,  ...,  0.0077, -0.0008,  0.0142],
        [ 0.0120, -0.0001,  0.0557,  ..., -0.0009,  0.0008,  0.0038],
        ...,
        [-0.0024,  0.0080, -0.0115,  ...,  0.0756, -0.0019,  0.0086],
        [-0.0021,  0.0146,  0.0062,  ...,  0.0044,  0.0501, -0.0235],
        [-0.0139,  0.0185, -0.0169,  ..., -0.0303, -0.0183,  0.0529]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7246, -6.2266, -0.0859,  ...,  2.4473, -1.7598, -1.1543]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 22:35:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for attending is the active form of attend
encouraging is the active form of encourage
including is the active form of include
spending is the active form of spend
asking is the active form of ask
requiring is the active form of require
believing is the active form of believe
providing is the active form of
2024-07-26 22:35:16 root INFO     [order_1_approx] starting weight calculation for including is the active form of include
attending is the active form of attend
believing is the active form of believe
encouraging is the active form of encourage
asking is the active form of ask
providing is the active form of provide
requiring is the active form of require
spending is the active form of
2024-07-26 22:35:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 22:37:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1088, -0.2192,  0.1464,  ..., -0.0207, -0.2087, -0.0751],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2480, -2.4961, -2.7012,  ...,  0.2246, -1.0938, -1.9688],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0658,  0.0022, -0.0168,  ...,  0.0135,  0.0071,  0.0286],
        [ 0.0068,  0.0460, -0.0011,  ...,  0.0171, -0.0106, -0.0039],
        [ 0.0276, -0.0108,  0.0399,  ...,  0.0057, -0.0083, -0.0093],
        ...,
        [ 0.0138,  0.0168, -0.0043,  ...,  0.0612, -0.0077,  0.0002],
        [-0.0055,  0.0023, -0.0078,  ...,  0.0021,  0.0338,  0.0002],
        [-0.0105,  0.0017, -0.0073,  ..., -0.0088, -0.0123,  0.0488]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1396, -2.7812, -2.6406,  ...,  0.3516, -1.0137, -2.1621]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 22:37:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for including is the active form of include
attending is the active form of attend
believing is the active form of believe
encouraging is the active form of encourage
asking is the active form of ask
providing is the active form of provide
requiring is the active form of require
spending is the active form of
2024-07-26 22:37:38 root INFO     [order_1_approx] starting weight calculation for requiring is the active form of require
asking is the active form of ask
encouraging is the active form of encourage
spending is the active form of spend
including is the active form of include
providing is the active form of provide
attending is the active form of attend
believing is the active form of
2024-07-26 22:37:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 22:39:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0328,  0.0072,  0.0267,  ..., -0.0169, -0.3723,  0.1718],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3301, -5.3555,  0.9380,  ...,  1.3242, -1.4121, -2.5059],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0356,  0.0019,  0.0029,  ...,  0.0089, -0.0185,  0.0142],
        [ 0.0019,  0.0295, -0.0001,  ...,  0.0207,  0.0068, -0.0034],
        [ 0.0066, -0.0051,  0.0313,  ..., -0.0051, -0.0049,  0.0143],
        ...,
        [ 0.0050, -0.0010, -0.0078,  ...,  0.0340, -0.0025,  0.0035],
        [ 0.0024,  0.0056,  0.0046,  ...,  0.0113,  0.0230, -0.0167],
        [ 0.0103,  0.0089, -0.0021,  ..., -0.0038, -0.0179,  0.0242]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9160, -5.4922,  0.6582,  ...,  1.6689, -1.3867, -2.6387]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 22:39:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for requiring is the active form of require
asking is the active form of ask
encouraging is the active form of encourage
spending is the active form of spend
including is the active form of include
providing is the active form of provide
attending is the active form of attend
believing is the active form of
2024-07-26 22:39:58 root INFO     [order_1_approx] starting weight calculation for attending is the active form of attend
spending is the active form of spend
requiring is the active form of require
asking is the active form of ask
providing is the active form of provide
encouraging is the active form of encourage
believing is the active form of believe
including is the active form of
2024-07-26 22:39:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 22:42:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0278, -0.4402, -0.0966,  ..., -0.0201,  0.0225, -0.3423],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1445, -1.5801,  0.5166,  ...,  0.8223, -2.0039, -3.1250],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0896, -0.0259, -0.0013,  ...,  0.0134, -0.0052, -0.0003],
        [ 0.0117,  0.0529, -0.0030,  ...,  0.0160, -0.0094, -0.0030],
        [ 0.0164, -0.0071,  0.0410,  ..., -0.0036, -0.0003, -0.0111],
        ...,
        [-0.0022,  0.0114, -0.0035,  ...,  0.0787, -0.0121,  0.0060],
        [-0.0189,  0.0086,  0.0082,  ..., -0.0084,  0.0363, -0.0076],
        [-0.0068,  0.0006, -0.0148,  ..., -0.0121, -0.0097,  0.0546]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0715, -1.6953,  0.4158,  ...,  0.5840, -1.7520, -2.7129]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 22:42:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for attending is the active form of attend
spending is the active form of spend
requiring is the active form of require
asking is the active form of ask
providing is the active form of provide
encouraging is the active form of encourage
believing is the active form of believe
including is the active form of
2024-07-26 22:42:21 root INFO     [order_1_approx] starting weight calculation for attending is the active form of attend
encouraging is the active form of encourage
believing is the active form of believe
spending is the active form of spend
including is the active form of include
requiring is the active form of require
providing is the active form of provide
asking is the active form of
2024-07-26 22:42:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 22:44:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1609, -0.2219, -0.2218,  ..., -0.1570, -0.2744, -0.1982],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3525, -4.1523, -0.9048,  ...,  3.0977, -2.2227, -2.1348],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.0405e-02, -5.6648e-03,  3.8853e-03,  ..., -1.0633e-03,
         -4.8904e-03,  7.2556e-03],
        [ 3.7041e-03,  4.4586e-02, -4.5776e-03,  ...,  1.8845e-02,
         -8.5602e-03,  5.9891e-03],
        [ 5.9166e-03, -9.5367e-03,  2.5467e-02,  ..., -1.4206e-02,
          4.4556e-03,  2.7351e-03],
        ...,
        [-7.0992e-03,  9.3002e-03, -3.5706e-03,  ...,  3.6255e-02,
         -5.2071e-04, -2.0599e-03],
        [ 6.6757e-05,  1.4114e-02,  7.5760e-03,  ...,  5.0468e-03,
          1.5121e-02, -3.2864e-03],
        [ 3.5114e-03,  2.5196e-03, -2.4185e-03,  ..., -4.7302e-04,
         -1.3931e-02,  3.2898e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3625, -4.4062, -1.1318,  ...,  3.0469, -2.1777, -2.0742]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 22:44:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for attending is the active form of attend
encouraging is the active form of encourage
believing is the active form of believe
spending is the active form of spend
including is the active form of include
requiring is the active form of require
providing is the active form of provide
asking is the active form of
2024-07-26 22:44:41 root INFO     [order_1_approx] starting weight calculation for believing is the active form of believe
providing is the active form of provide
including is the active form of include
encouraging is the active form of encourage
asking is the active form of ask
attending is the active form of attend
spending is the active form of spend
requiring is the active form of
2024-07-26 22:44:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 22:47:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2367, -0.1431, -0.2925,  ..., -0.3782, -0.2793, -0.0674],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.1055, -4.2188,  1.2373,  ...,  0.6313, -2.8770, -2.0703],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0627, -0.0181,  0.0113,  ...,  0.0007, -0.0071,  0.0056],
        [-0.0022,  0.0414,  0.0014,  ...,  0.0072, -0.0141,  0.0015],
        [ 0.0139,  0.0032,  0.0314,  ..., -0.0073,  0.0018,  0.0141],
        ...,
        [-0.0039,  0.0056, -0.0071,  ...,  0.0451,  0.0003, -0.0007],
        [-0.0063, -0.0010,  0.0091,  ..., -0.0088,  0.0371, -0.0073],
        [-0.0006,  0.0078, -0.0033,  ..., -0.0035, -0.0185,  0.0427]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1514, -4.2266,  0.9512,  ...,  0.8677, -2.7637, -2.1016]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 22:47:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for believing is the active form of believe
providing is the active form of provide
including is the active form of include
encouraging is the active form of encourage
asking is the active form of ask
attending is the active form of attend
spending is the active form of spend
requiring is the active form of
2024-07-26 22:47:02 root INFO     [order_1_approx] starting weight calculation for asking is the active form of ask
spending is the active form of spend
requiring is the active form of require
attending is the active form of attend
including is the active form of include
providing is the active form of provide
believing is the active form of believe
encouraging is the active form of
2024-07-26 22:47:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 22:49:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2019, -0.0137, -0.1130,  ...,  0.0403, -0.2318, -0.1241],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6738, -2.8359, -0.6475,  ...,  3.9219, -1.7676, -3.3750],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0470, -0.0046,  0.0023,  ...,  0.0022, -0.0117,  0.0094],
        [-0.0003,  0.0331, -0.0012,  ...,  0.0111,  0.0005, -0.0043],
        [ 0.0103, -0.0013,  0.0260,  ..., -0.0127, -0.0082,  0.0005],
        ...,
        [-0.0010,  0.0081,  0.0019,  ...,  0.0383, -0.0043, -0.0027],
        [ 0.0051,  0.0028, -0.0097,  ...,  0.0062,  0.0268, -0.0030],
        [ 0.0026,  0.0017, -0.0127,  ..., -0.0008, -0.0100,  0.0323]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7129, -2.9805, -0.7549,  ...,  3.7832, -1.6396, -3.1562]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 22:49:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for asking is the active form of ask
spending is the active form of spend
requiring is the active form of require
attending is the active form of attend
including is the active form of include
providing is the active form of provide
believing is the active form of believe
encouraging is the active form of
2024-07-26 22:49:22 root INFO     total operator prediction time: 1126.2181735038757 seconds
2024-07-26 22:49:22 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun - plural_irreg
2024-07-26 22:49:22 root INFO     building operator noun - plural_irreg
2024-07-26 22:49:23 root INFO     [order_1_approx] starting weight calculation for The plural form of datum is data
The plural form of child is children
The plural form of responsibility is responsibilities
The plural form of variety is varieties
The plural form of family is families
The plural form of ability is abilities
The plural form of facility is facilities
The plural form of economy is
2024-07-26 22:49:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 22:51:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5176,  0.3503, -0.3574,  ..., -0.5654,  0.0842,  0.0244],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9766,  0.2012, -1.1797,  ..., -2.3516, -2.7773, -2.6680],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.8125e-02,  1.0178e-02,  2.8351e-02,  ...,  4.2572e-03,
          2.3651e-04,  1.3275e-02],
        [ 1.8127e-02,  1.0687e-01,  1.4572e-03,  ...,  1.1971e-02,
          2.4796e-05,  3.1395e-03],
        [-1.1269e-02, -2.0599e-03,  7.6538e-02,  ..., -5.2681e-03,
          1.0231e-02, -2.0924e-03],
        ...,
        [ 1.9150e-02,  1.4526e-02, -4.8180e-03,  ...,  6.7139e-02,
          1.7757e-03,  2.6703e-03],
        [-5.2185e-02,  1.5411e-02, -1.3474e-02,  ...,  3.1769e-02,
          7.5806e-02, -6.3858e-03],
        [ 1.8250e-02,  7.6752e-03, -1.0551e-02,  ...,  2.1118e-02,
         -9.8724e-03,  6.2347e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6104,  0.0046, -1.3066,  ..., -1.8535, -2.4141, -2.7676]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 22:51:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of datum is data
The plural form of child is children
The plural form of responsibility is responsibilities
The plural form of variety is varieties
The plural form of family is families
The plural form of ability is abilities
The plural form of facility is facilities
The plural form of economy is
2024-07-26 22:51:44 root INFO     [order_1_approx] starting weight calculation for The plural form of family is families
The plural form of economy is economies
The plural form of responsibility is responsibilities
The plural form of datum is data
The plural form of variety is varieties
The plural form of child is children
The plural form of ability is abilities
The plural form of facility is
2024-07-26 22:51:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 22:54:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3198,  0.0382, -0.5596,  ..., -0.5234, -0.1069,  0.0344],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6797, -2.2031,  3.9531,  ...,  0.1763, -1.2568, -2.1758],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0780, -0.0216, -0.0026,  ..., -0.0009,  0.0049,  0.0206],
        [-0.0177,  0.0734, -0.0141,  ...,  0.0183,  0.0042, -0.0061],
        [ 0.0129,  0.0047,  0.0542,  ..., -0.0041, -0.0250,  0.0026],
        ...,
        [-0.0079,  0.0137, -0.0422,  ...,  0.1135,  0.0007,  0.0015],
        [ 0.0084,  0.0055,  0.0045,  ...,  0.0415,  0.0462,  0.0010],
        [ 0.0092,  0.0055, -0.0150,  ..., -0.0004, -0.0003,  0.0662]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9014, -2.4277,  4.0273,  ..., -0.1082, -1.1562, -2.0234]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 22:54:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of family is families
The plural form of economy is economies
The plural form of responsibility is responsibilities
The plural form of datum is data
The plural form of variety is varieties
The plural form of child is children
The plural form of ability is abilities
The plural form of facility is
2024-07-26 22:54:06 root INFO     [order_1_approx] starting weight calculation for The plural form of ability is abilities
The plural form of responsibility is responsibilities
The plural form of variety is varieties
The plural form of facility is facilities
The plural form of family is families
The plural form of child is children
The plural form of economy is economies
The plural form of datum is
2024-07-26 22:54:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 22:56:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4443,  0.3083, -0.5454,  ..., -0.1135, -0.4114,  0.1318],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5762, -2.1191,  2.4004,  ..., -1.3594, -3.5859, -1.6826],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.6965e-02, -4.2953e-03,  1.0803e-02,  ..., -3.9337e-02,
          4.2572e-02,  1.3657e-03],
        [ 2.5894e-02,  1.1426e-01,  6.0043e-03,  ...,  4.0131e-02,
         -4.0039e-02,  2.3712e-02],
        [ 9.9335e-03,  7.5684e-03,  8.0872e-02,  ..., -1.7405e-03,
          2.4277e-02, -7.0267e-03],
        ...,
        [ 2.8793e-02,  2.5604e-02,  4.5776e-03,  ...,  1.0925e-01,
         -4.9744e-02,  1.3603e-02],
        [ 9.1553e-05,  1.6586e-02, -1.2245e-03,  ...,  3.5057e-03,
          7.9163e-02, -1.9760e-02],
        [ 2.4155e-02,  3.5065e-02, -2.8114e-03,  ..., -3.5477e-03,
         -2.5757e-02,  9.2957e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.2188, -4.3867,  3.1875,  ..., -2.2500, -3.7578, -2.2070]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 22:56:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of ability is abilities
The plural form of responsibility is responsibilities
The plural form of variety is varieties
The plural form of facility is facilities
The plural form of family is families
The plural form of child is children
The plural form of economy is economies
The plural form of datum is
2024-07-26 22:56:29 root INFO     [order_1_approx] starting weight calculation for The plural form of variety is varieties
The plural form of economy is economies
The plural form of child is children
The plural form of facility is facilities
The plural form of responsibility is responsibilities
The plural form of datum is data
The plural form of family is families
The plural form of ability is
2024-07-26 22:56:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 22:58:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3218,  0.1962, -0.1570,  ..., -0.3127, -0.0597,  0.1340],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8604, -1.5195,  0.6401,  ..., -1.0488, -2.3242, -1.1865],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0549,  0.0050, -0.0049,  ..., -0.0106,  0.0119,  0.0146],
        [ 0.0210,  0.0782,  0.0302,  ...,  0.0281,  0.0095,  0.0018],
        [-0.0064,  0.0044,  0.0550,  ..., -0.0179,  0.0038,  0.0220],
        ...,
        [ 0.0133,  0.0386, -0.0164,  ...,  0.0617, -0.0024,  0.0135],
        [-0.0163,  0.0222,  0.0008,  ...,  0.0090,  0.0297, -0.0080],
        [ 0.0036, -0.0020,  0.0184,  ..., -0.0043,  0.0051,  0.0565]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0820, -1.5039,  0.4807,  ..., -1.2842, -2.1875, -1.3672]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 22:58:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of variety is varieties
The plural form of economy is economies
The plural form of child is children
The plural form of facility is facilities
The plural form of responsibility is responsibilities
The plural form of datum is data
The plural form of family is families
The plural form of ability is
2024-07-26 22:58:53 root INFO     [order_1_approx] starting weight calculation for The plural form of responsibility is responsibilities
The plural form of economy is economies
The plural form of ability is abilities
The plural form of family is families
The plural form of datum is data
The plural form of facility is facilities
The plural form of variety is varieties
The plural form of child is
2024-07-26 22:58:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 23:01:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1414,  0.1132, -0.1588,  ..., -0.2258, -0.8408, -0.0297],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9961, -2.5898,  1.3877,  ..., -1.4072, -0.6782, -2.2832],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0449, -0.0045, -0.0298,  ...,  0.0107,  0.0199, -0.0120],
        [ 0.0152,  0.0406,  0.0378,  ...,  0.0169,  0.0058,  0.0081],
        [ 0.0076,  0.0024,  0.0476,  ..., -0.0046,  0.0043,  0.0216],
        ...,
        [-0.0097,  0.0066,  0.0076,  ...,  0.0581, -0.0217,  0.0143],
        [ 0.0011,  0.0182, -0.0027,  ...,  0.0166,  0.0425, -0.0077],
        [ 0.0297, -0.0131,  0.0022,  ..., -0.0224, -0.0160,  0.0404]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3867, -2.5254,  1.2334,  ..., -1.4287, -0.6875, -2.0273]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 23:01:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of responsibility is responsibilities
The plural form of economy is economies
The plural form of ability is abilities
The plural form of family is families
The plural form of datum is data
The plural form of facility is facilities
The plural form of variety is varieties
The plural form of child is
2024-07-26 23:01:14 root INFO     [order_1_approx] starting weight calculation for The plural form of responsibility is responsibilities
The plural form of family is families
The plural form of economy is economies
The plural form of child is children
The plural form of facility is facilities
The plural form of ability is abilities
The plural form of datum is data
The plural form of variety is
2024-07-26 23:01:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 23:03:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3770,  0.1129, -0.4766,  ...,  0.0679, -0.1084,  0.1115],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8936, -2.2578,  0.7100,  ..., -3.0508, -3.4414, -2.3262],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0643,  0.0009,  0.0095,  ..., -0.0050,  0.0231,  0.0295],
        [ 0.0107,  0.0761,  0.0220,  ...,  0.0093, -0.0129,  0.0176],
        [ 0.0178,  0.0142,  0.0422,  ..., -0.0306, -0.0058,  0.0281],
        ...,
        [ 0.0286,  0.0160,  0.0043,  ...,  0.0691, -0.0002,  0.0095],
        [-0.0006, -0.0003, -0.0150,  ..., -0.0003,  0.0403, -0.0096],
        [ 0.0242,  0.0227,  0.0008,  ...,  0.0128, -0.0043,  0.0484]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8740, -2.4121,  0.3193,  ..., -3.0020, -3.2402, -1.9570]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 23:03:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of responsibility is responsibilities
The plural form of family is families
The plural form of economy is economies
The plural form of child is children
The plural form of facility is facilities
The plural form of ability is abilities
The plural form of datum is data
The plural form of variety is
2024-07-26 23:03:36 root INFO     [order_1_approx] starting weight calculation for The plural form of family is families
The plural form of economy is economies
The plural form of child is children
The plural form of ability is abilities
The plural form of variety is varieties
The plural form of datum is data
The plural form of facility is facilities
The plural form of responsibility is
2024-07-26 23:03:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 23:05:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0705,  0.7266, -0.6050,  ..., -0.1542, -0.1832, -0.1208],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9092, -1.8633,  1.7207,  ..., -2.6484, -1.2832, -3.2188],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0637,  0.0163,  0.0027,  ...,  0.0164, -0.0181, -0.0055],
        [ 0.0008,  0.0446,  0.0086,  ...,  0.0290, -0.0019,  0.0103],
        [-0.0003,  0.0161,  0.0497,  ...,  0.0001, -0.0051,  0.0081],
        ...,
        [ 0.0183,  0.0249,  0.0039,  ...,  0.0724, -0.0116, -0.0014],
        [-0.0132,  0.0079,  0.0098,  ...,  0.0019,  0.0343, -0.0145],
        [ 0.0183,  0.0005, -0.0099,  ...,  0.0066, -0.0183,  0.0390]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4141, -2.3340,  1.4609,  ..., -2.5742, -1.1992, -3.0840]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 23:05:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of family is families
The plural form of economy is economies
The plural form of child is children
The plural form of ability is abilities
The plural form of variety is varieties
The plural form of datum is data
The plural form of facility is facilities
The plural form of responsibility is
2024-07-26 23:06:00 root INFO     [order_1_approx] starting weight calculation for The plural form of ability is abilities
The plural form of economy is economies
The plural form of responsibility is responsibilities
The plural form of facility is facilities
The plural form of variety is varieties
The plural form of datum is data
The plural form of child is children
The plural form of family is
2024-07-26 23:06:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 23:08:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2393, -0.0567, -0.2061,  ..., -0.0831, -0.2203, -0.2688],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9648, -1.2246,  2.9473,  ..., -1.4023, -1.7686, -3.4609],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0557, -0.0008, -0.0047,  ..., -0.0096,  0.0101, -0.0196],
        [-0.0119,  0.0500,  0.0127,  ...,  0.0168,  0.0013, -0.0109],
        [-0.0117,  0.0110,  0.0452,  ..., -0.0019, -0.0016,  0.0085],
        ...,
        [ 0.0073,  0.0253, -0.0049,  ...,  0.0471, -0.0168,  0.0019],
        [-0.0191,  0.0292, -0.0179,  ..., -0.0098,  0.0271,  0.0102],
        [ 0.0249, -0.0037, -0.0020,  ...,  0.0054, -0.0187,  0.0341]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1328, -1.2969,  2.7988,  ..., -1.2227, -1.6582, -3.5742]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 23:08:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of ability is abilities
The plural form of economy is economies
The plural form of responsibility is responsibilities
The plural form of facility is facilities
The plural form of variety is varieties
The plural form of datum is data
The plural form of child is children
The plural form of family is
2024-07-26 23:08:21 root INFO     total operator prediction time: 1138.4391148090363 seconds
2024-07-26 23:08:21 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - member
2024-07-26 23:08:21 root INFO     building operator meronyms - member
2024-07-26 23:08:21 root INFO     [order_1_approx] starting weight calculation for A soldier is a member of a army
A musician is a member of a orchestra
A juror is a member of a jury
A photo is a member of a album
A galaxy is a member of a universe
A christian is a member of a congregation
A nomad is a member of a horde
A star is a member of a
2024-07-26 23:08:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 23:10:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1255,  0.0961, -0.1296,  ..., -0.2598, -0.0848, -0.2418],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.6270, -3.2031,  7.3828,  ..., -2.0547, -0.2402,  0.9902],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0710, -0.0202,  0.0107,  ..., -0.0003, -0.0078, -0.0047],
        [-0.0196,  0.0400,  0.0137,  ...,  0.0129, -0.0027, -0.0119],
        [ 0.0140,  0.0200,  0.0497,  ..., -0.0219,  0.0127, -0.0030],
        ...,
        [-0.0080,  0.0160, -0.0030,  ...,  0.1045,  0.0153, -0.0182],
        [ 0.0030,  0.0380, -0.0018,  ...,  0.0114,  0.0663, -0.0069],
        [ 0.0085,  0.0117, -0.0189,  ...,  0.0051, -0.0103,  0.0575]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1055, -3.5117,  7.1680,  ..., -2.1328, -0.1877,  0.9717]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 23:10:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A soldier is a member of a army
A musician is a member of a orchestra
A juror is a member of a jury
A photo is a member of a album
A galaxy is a member of a universe
A christian is a member of a congregation
A nomad is a member of a horde
A star is a member of a
2024-07-26 23:10:39 root INFO     [order_1_approx] starting weight calculation for A galaxy is a member of a universe
A musician is a member of a orchestra
A star is a member of a constellation
A christian is a member of a congregation
A photo is a member of a album
A juror is a member of a jury
A nomad is a member of a horde
A soldier is a member of a
2024-07-26 23:10:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 23:12:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1816,  0.4631, -0.2947,  ...,  0.0380, -0.6597,  0.0226],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3262, -6.6914,  3.4219,  ..., -2.2246,  1.8066, -3.4414],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0606,  0.0105,  0.0100,  ...,  0.0152, -0.0050, -0.0060],
        [-0.0030,  0.0607,  0.0126,  ..., -0.0087,  0.0025, -0.0024],
        [ 0.0125,  0.0024,  0.0498,  ..., -0.0119,  0.0217, -0.0119],
        ...,
        [-0.0070,  0.0249,  0.0015,  ...,  0.0381,  0.0175, -0.0014],
        [-0.0159,  0.0207, -0.0071,  ..., -0.0174,  0.0591,  0.0092],
        [ 0.0111, -0.0065, -0.0069,  ..., -0.0031, -0.0112,  0.0528]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5117, -6.7383,  3.2051,  ..., -2.2598,  1.7490, -3.2656]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 23:12:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A galaxy is a member of a universe
A musician is a member of a orchestra
A star is a member of a constellation
A christian is a member of a congregation
A photo is a member of a album
A juror is a member of a jury
A nomad is a member of a horde
A soldier is a member of a
2024-07-26 23:12:58 root INFO     [order_1_approx] starting weight calculation for A soldier is a member of a army
A star is a member of a constellation
A photo is a member of a album
A juror is a member of a jury
A musician is a member of a orchestra
A galaxy is a member of a universe
A nomad is a member of a horde
A christian is a member of a
2024-07-26 23:12:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 23:15:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3140,  0.1453,  0.0651,  ...,  0.1675, -0.0748,  0.0530],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.4258, -6.7891,  3.3379,  ..., -3.5195,  0.8115, -1.4785],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0234,  0.0063,  0.0139,  ...,  0.0319,  0.0063, -0.0019],
        [-0.0077,  0.0268,  0.0079,  ..., -0.0053,  0.0233, -0.0157],
        [ 0.0118, -0.0062,  0.0217,  ..., -0.0117, -0.0172,  0.0024],
        ...,
        [ 0.0021,  0.0108,  0.0093,  ...,  0.0410, -0.0086, -0.0133],
        [ 0.0055,  0.0132, -0.0035,  ..., -0.0043,  0.0191,  0.0097],
        [-0.0011, -0.0062, -0.0070,  ..., -0.0005, -0.0079,  0.0482]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.9141, -6.5117,  3.2109,  ..., -3.2363,  0.6538, -1.3096]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 23:15:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A soldier is a member of a army
A star is a member of a constellation
A photo is a member of a album
A juror is a member of a jury
A musician is a member of a orchestra
A galaxy is a member of a universe
A nomad is a member of a horde
A christian is a member of a
2024-07-26 23:15:19 root INFO     [order_1_approx] starting weight calculation for A soldier is a member of a army
A christian is a member of a congregation
A photo is a member of a album
A musician is a member of a orchestra
A nomad is a member of a horde
A galaxy is a member of a universe
A star is a member of a constellation
A juror is a member of a
2024-07-26 23:15:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 23:17:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6274, -0.1509,  0.0786,  ...,  0.3579, -0.3650, -0.0096],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.5156, -5.3203,  4.3477,  ..., -3.4570, -0.5825, -2.5137],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0553,  0.0042,  0.0223,  ...,  0.0304, -0.0021,  0.0123],
        [ 0.0120,  0.0311,  0.0205,  ...,  0.0219, -0.0055, -0.0042],
        [ 0.0012, -0.0055,  0.0292,  ..., -0.0211,  0.0013, -0.0014],
        ...,
        [ 0.0145,  0.0114,  0.0045,  ...,  0.0430,  0.0042, -0.0156],
        [-0.0001, -0.0032, -0.0190,  ...,  0.0034,  0.0337,  0.0018],
        [ 0.0142, -0.0095,  0.0057,  ...,  0.0122, -0.0021,  0.0540]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.1484, -5.3008,  4.5352,  ..., -3.3203, -0.4219, -2.6348]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 23:17:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A soldier is a member of a army
A christian is a member of a congregation
A photo is a member of a album
A musician is a member of a orchestra
A nomad is a member of a horde
A galaxy is a member of a universe
A star is a member of a constellation
A juror is a member of a
2024-07-26 23:17:42 root INFO     [order_1_approx] starting weight calculation for A galaxy is a member of a universe
A christian is a member of a congregation
A soldier is a member of a army
A nomad is a member of a horde
A juror is a member of a jury
A star is a member of a constellation
A photo is a member of a album
A musician is a member of a
2024-07-26 23:17:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 23:20:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3369,  0.3503,  0.3503,  ..., -0.1639, -0.2976, -0.0186],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9180, -6.6836,  4.0898,  ..., -3.2852, -1.6484, -2.8086],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0436,  0.0039,  0.0068,  ...,  0.0101,  0.0111,  0.0027],
        [-0.0034,  0.0390,  0.0101,  ..., -0.0085,  0.0085, -0.0222],
        [ 0.0102,  0.0057,  0.0324,  ..., -0.0007,  0.0107, -0.0007],
        ...,
        [ 0.0173,  0.0092, -0.0050,  ...,  0.0326,  0.0129, -0.0164],
        [ 0.0107,  0.0091, -0.0027,  ...,  0.0150,  0.0214, -0.0042],
        [ 0.0152, -0.0100, -0.0203,  ..., -0.0151, -0.0090,  0.0332]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9775, -6.8047,  4.1836,  ..., -3.0293, -1.8984, -2.6973]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 23:20:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A galaxy is a member of a universe
A christian is a member of a congregation
A soldier is a member of a army
A nomad is a member of a horde
A juror is a member of a jury
A star is a member of a constellation
A photo is a member of a album
A musician is a member of a
2024-07-26 23:20:06 root INFO     [order_1_approx] starting weight calculation for A galaxy is a member of a universe
A photo is a member of a album
A star is a member of a constellation
A musician is a member of a orchestra
A christian is a member of a congregation
A juror is a member of a jury
A soldier is a member of a army
A nomad is a member of a
2024-07-26 23:20:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 23:22:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1503,  0.3435, -0.3242,  ...,  0.1943, -0.1934,  0.2986],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0859, -3.8652,  0.9077,  ..., -2.3594, -1.2715, -0.0254],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0486, -0.0085,  0.0087,  ...,  0.0049, -0.0245, -0.0044],
        [ 0.0140,  0.0455, -0.0082,  ..., -0.0160,  0.0047, -0.0350],
        [ 0.0083, -0.0114,  0.0571,  ..., -0.0044,  0.0033, -0.0002],
        ...,
        [ 0.0127, -0.0012,  0.0048,  ...,  0.0835,  0.0153,  0.0022],
        [ 0.0079,  0.0076, -0.0037,  ..., -0.0008,  0.0518, -0.0206],
        [-0.0024, -0.0099, -0.0004,  ...,  0.0227, -0.0051,  0.0695]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0703, -3.8652,  0.9175,  ..., -2.4238, -0.8828, -0.0527]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 23:22:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A galaxy is a member of a universe
A photo is a member of a album
A star is a member of a constellation
A musician is a member of a orchestra
A christian is a member of a congregation
A juror is a member of a jury
A soldier is a member of a army
A nomad is a member of a
2024-07-26 23:22:24 root INFO     [order_1_approx] starting weight calculation for A juror is a member of a jury
A soldier is a member of a army
A christian is a member of a congregation
A galaxy is a member of a universe
A nomad is a member of a horde
A star is a member of a constellation
A musician is a member of a orchestra
A photo is a member of a
2024-07-26 23:22:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 23:24:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4453, -0.3047,  0.2612,  ...,  0.0416, -0.0775, -0.1543],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9385, -1.3438,  3.8633,  ..., -4.0156,  1.0762, -0.2520],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0581, -0.0008,  0.0081,  ...,  0.0164, -0.0285,  0.0196],
        [ 0.0030,  0.0582,  0.0187,  ...,  0.0413, -0.0293,  0.0234],
        [ 0.0035,  0.0009,  0.0557,  ..., -0.0117,  0.0102,  0.0101],
        ...,
        [ 0.0271,  0.0009, -0.0023,  ...,  0.0616, -0.0090, -0.0276],
        [-0.0142,  0.0311, -0.0374,  ..., -0.0241,  0.0606, -0.0141],
        [-0.0195, -0.0162,  0.0225,  ...,  0.0027, -0.0094,  0.0472]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3760, -1.4434,  4.2617,  ..., -4.1719,  1.0898, -0.4812]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 23:24:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A juror is a member of a jury
A soldier is a member of a army
A christian is a member of a congregation
A galaxy is a member of a universe
A nomad is a member of a horde
A star is a member of a constellation
A musician is a member of a orchestra
A photo is a member of a
2024-07-26 23:24:43 root INFO     [order_1_approx] starting weight calculation for A photo is a member of a album
A nomad is a member of a horde
A musician is a member of a orchestra
A christian is a member of a congregation
A soldier is a member of a army
A star is a member of a constellation
A juror is a member of a jury
A galaxy is a member of a
2024-07-26 23:24:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 23:27:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4343,  0.0269, -0.2703,  ..., -0.0648, -0.0671,  0.3445],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8174, -1.5137,  5.8789,  ..., -3.9688, -1.3340, -1.6270],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0312, -0.0090,  0.0036,  ..., -0.0097,  0.0015,  0.0036],
        [-0.0018,  0.0224,  0.0248,  ...,  0.0115,  0.0050,  0.0043],
        [-0.0034,  0.0153,  0.0287,  ..., -0.0044, -0.0077,  0.0039],
        ...,
        [-0.0017, -0.0011, -0.0002,  ...,  0.0351,  0.0081,  0.0097],
        [ 0.0055,  0.0102,  0.0012,  ..., -0.0118,  0.0244, -0.0072],
        [ 0.0058, -0.0026,  0.0044,  ..., -0.0152, -0.0007,  0.0079]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8643, -1.5332,  5.6523,  ..., -3.9570, -1.2637, -1.4922]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 23:27:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A photo is a member of a album
A nomad is a member of a horde
A musician is a member of a orchestra
A christian is a member of a congregation
A soldier is a member of a army
A star is a member of a constellation
A juror is a member of a jury
A galaxy is a member of a
2024-07-26 23:27:04 root INFO     total operator prediction time: 1123.2066180706024 seconds
2024-07-26 23:27:04 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on antonyms - binary
2024-07-26 23:27:04 root INFO     building operator antonyms - binary
2024-07-26 23:27:04 root INFO     [order_1_approx] starting weight calculation for The opposite of in is out
The opposite of forward is backward
The opposite of south is north
The opposite of front is back
The opposite of southeast is southwest
The opposite of anterior is posterior
The opposite of exit is entrance
The opposite of below is
2024-07-26 23:27:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 23:29:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2034, -0.1364, -0.0413,  ..., -0.1013, -0.1957, -0.0356],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9502, -2.0840,  1.4111,  ..., -0.3362,  2.9277, -1.0303],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0726, -0.0122,  0.0063,  ...,  0.0122,  0.0003, -0.0174],
        [-0.0042,  0.0679,  0.0187,  ...,  0.0135,  0.0155,  0.0132],
        [ 0.0119, -0.0052,  0.0022,  ..., -0.0223, -0.0316,  0.0061],
        ...,
        [ 0.0116,  0.0163, -0.0040,  ...,  0.0484,  0.0118, -0.0129],
        [ 0.0042, -0.0083,  0.0046,  ..., -0.0068,  0.0265, -0.0013],
        [-0.0142, -0.0189,  0.0254,  ..., -0.0054,  0.0049,  0.0424]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9971, -2.2285,  1.6260,  ..., -0.3643,  2.5352, -1.0615]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 23:29:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of in is out
The opposite of forward is backward
The opposite of south is north
The opposite of front is back
The opposite of southeast is southwest
The opposite of anterior is posterior
The opposite of exit is entrance
The opposite of below is
2024-07-26 23:29:26 root INFO     [order_1_approx] starting weight calculation for The opposite of front is back
The opposite of south is north
The opposite of southeast is southwest
The opposite of anterior is posterior
The opposite of in is out
The opposite of exit is entrance
The opposite of below is above
The opposite of forward is
2024-07-26 23:29:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 23:31:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4004,  0.3342, -0.4656,  ..., -0.1550,  0.1437,  0.5132],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1455, -2.6953,  0.4255,  ..., -1.3203, -1.5137, -1.6123],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1016,  0.0004,  0.0024,  ...,  0.0211, -0.0222, -0.0171],
        [ 0.0136,  0.0701,  0.0202,  ...,  0.0021, -0.0008,  0.0149],
        [ 0.0047, -0.0241,  0.0507,  ..., -0.0045, -0.0412, -0.0286],
        ...,
        [-0.0102,  0.0193, -0.0274,  ...,  0.0858,  0.0336, -0.0084],
        [-0.0218,  0.0091, -0.0082,  ..., -0.0059,  0.0764,  0.0029],
        [ 0.0106, -0.0235,  0.0106,  ...,  0.0052,  0.0060,  0.0236]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1357, -3.2812,  0.8013,  ..., -1.3809, -1.5273, -1.9082]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 23:31:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of front is back
The opposite of south is north
The opposite of southeast is southwest
The opposite of anterior is posterior
The opposite of in is out
The opposite of exit is entrance
The opposite of below is above
The opposite of forward is
2024-07-26 23:31:46 root INFO     [order_1_approx] starting weight calculation for The opposite of front is back
The opposite of anterior is posterior
The opposite of forward is backward
The opposite of below is above
The opposite of exit is entrance
The opposite of south is north
The opposite of in is out
The opposite of southeast is
2024-07-26 23:31:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 23:34:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1230,  0.1116,  0.0206,  ...,  0.1919,  0.2742, -0.5068],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7622, -2.0391,  2.3789,  ..., -0.7842, -0.6548, -1.0254],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0464, -0.0333,  0.0105,  ..., -0.0004, -0.0082, -0.0072],
        [ 0.0129,  0.0444,  0.0162,  ..., -0.0077, -0.0156, -0.0177],
        [-0.0310, -0.0232,  0.0197,  ...,  0.0141, -0.0190,  0.0081],
        ...,
        [ 0.0101, -0.0048,  0.0036,  ...,  0.0403,  0.0079, -0.0128],
        [ 0.0015, -0.0086,  0.0140,  ...,  0.0236,  0.0645, -0.0089],
        [-0.0082,  0.0197,  0.0152,  ...,  0.0065, -0.0031,  0.0341]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3489, -2.6250,  2.1562,  ..., -0.6406, -0.7285, -0.9937]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 23:34:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of front is back
The opposite of anterior is posterior
The opposite of forward is backward
The opposite of below is above
The opposite of exit is entrance
The opposite of south is north
The opposite of in is out
The opposite of southeast is
2024-07-26 23:34:04 root INFO     [order_1_approx] starting weight calculation for The opposite of southeast is southwest
The opposite of front is back
The opposite of forward is backward
The opposite of in is out
The opposite of below is above
The opposite of south is north
The opposite of anterior is posterior
The opposite of exit is
2024-07-26 23:34:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 23:36:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2793,  0.1710, -0.6333,  ...,  0.0973, -0.0103,  0.0110],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1611, -3.4961, -1.6318,  ...,  1.7148, -1.3984, -3.8203],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0309,  0.0294, -0.0046,  ...,  0.0060, -0.0479, -0.0031],
        [ 0.0035,  0.0826, -0.0251,  ...,  0.0040, -0.0210,  0.0164],
        [ 0.0083,  0.0157,  0.0131,  ..., -0.0142, -0.0649, -0.0149],
        ...,
        [ 0.0261,  0.0002,  0.0055,  ...,  0.0442,  0.0226, -0.0133],
        [-0.0073, -0.0222, -0.0031,  ...,  0.0189,  0.0292,  0.0067],
        [-0.0029,  0.0293, -0.0216,  ..., -0.0258, -0.0225,  0.0267]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5215, -3.4922, -1.7021,  ...,  1.5186, -1.3398, -3.2617]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 23:36:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of southeast is southwest
The opposite of front is back
The opposite of forward is backward
The opposite of in is out
The opposite of below is above
The opposite of south is north
The opposite of anterior is posterior
The opposite of exit is
2024-07-26 23:36:20 root INFO     [order_1_approx] starting weight calculation for The opposite of exit is entrance
The opposite of south is north
The opposite of in is out
The opposite of below is above
The opposite of southeast is southwest
The opposite of front is back
The opposite of forward is backward
The opposite of anterior is
2024-07-26 23:36:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 23:38:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0253,  0.3777, -0.1012,  ..., -0.4939, -0.4534,  0.0767],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9180, -2.7207,  3.4062,  ..., -3.7734, -2.3359, -4.1719],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.6530e-02, -1.3702e-02,  4.3526e-03,  ...,  1.1436e-02,
         -2.2751e-02, -2.2766e-02],
        [-7.1983e-03,  3.3142e-02, -4.1779e-02,  ...,  1.3618e-02,
         -3.1250e-02, -4.1656e-02],
        [ 2.1820e-02, -1.5038e-02,  1.7685e-02,  ..., -2.5024e-02,
         -2.2644e-02,  9.1248e-03],
        ...,
        [-2.7809e-03,  1.3412e-02, -9.5367e-03,  ...,  3.3020e-02,
          1.9653e-02, -3.7933e-02],
        [ 6.8665e-04, -1.6602e-02,  1.5015e-02,  ...,  3.4332e-05,
          4.7668e-02, -1.4053e-02],
        [-2.6321e-02,  1.0330e-02, -5.8380e-02,  ..., -1.4740e-02,
         -2.6672e-02,  4.7821e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0557, -2.4512,  2.8652,  ..., -2.5938, -1.7100, -3.1055]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 23:38:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of exit is entrance
The opposite of south is north
The opposite of in is out
The opposite of below is above
The opposite of southeast is southwest
The opposite of front is back
The opposite of forward is backward
The opposite of anterior is
2024-07-26 23:38:35 root INFO     [order_1_approx] starting weight calculation for The opposite of forward is backward
The opposite of southeast is southwest
The opposite of exit is entrance
The opposite of below is above
The opposite of anterior is posterior
The opposite of in is out
The opposite of south is north
The opposite of front is
2024-07-26 23:38:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 23:40:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3147,  0.0898, -0.0837,  ..., -0.3127, -0.1647, -0.0559],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4414, -2.2441,  1.3984,  ..., -1.0459,  0.0547, -1.2275],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0664, -0.0171,  0.0066,  ...,  0.0290, -0.0565, -0.0582],
        [ 0.0105,  0.0597, -0.0097,  ...,  0.0123, -0.0050, -0.0431],
        [-0.0155, -0.0186,  0.0469,  ..., -0.0049, -0.0247, -0.0197],
        ...,
        [-0.0095,  0.0005, -0.0125,  ...,  0.0558,  0.0177,  0.0120],
        [ 0.0018,  0.0200, -0.0003,  ..., -0.0054,  0.0703,  0.0209],
        [ 0.0029, -0.0271,  0.0068,  ...,  0.0098,  0.0054,  0.0110]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2534, -1.7744,  1.3438,  ..., -0.8345, -0.1107, -0.8643]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 23:40:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of forward is backward
The opposite of southeast is southwest
The opposite of exit is entrance
The opposite of below is above
The opposite of anterior is posterior
The opposite of in is out
The opposite of south is north
The opposite of front is
2024-07-26 23:40:55 root INFO     [order_1_approx] starting weight calculation for The opposite of southeast is southwest
The opposite of in is out
The opposite of below is above
The opposite of forward is backward
The opposite of anterior is posterior
The opposite of exit is entrance
The opposite of front is back
The opposite of south is
2024-07-26 23:40:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 23:43:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1099, -0.0327,  0.0527,  ..., -0.1274, -0.2017, -0.0271],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9702, -3.2031,  0.7886,  ..., -0.8018,  0.0836, -2.9688],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0256, -0.0387,  0.0051,  ..., -0.0012,  0.0163,  0.0018],
        [ 0.0049,  0.0092,  0.0042,  ...,  0.0249,  0.0134, -0.0138],
        [-0.0251,  0.0023,  0.0116,  ..., -0.0060, -0.0127,  0.0130],
        ...,
        [ 0.0199, -0.0028,  0.0175,  ...,  0.0248,  0.0015, -0.0341],
        [ 0.0070, -0.0149, -0.0010,  ...,  0.0142,  0.0215, -0.0065],
        [-0.0038, -0.0019, -0.0055,  ..., -0.0019, -0.0012,  0.0068]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1406, -3.4355,  0.7017,  ..., -0.4055,  0.2153, -2.6797]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 23:43:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of southeast is southwest
The opposite of in is out
The opposite of below is above
The opposite of forward is backward
The opposite of anterior is posterior
The opposite of exit is entrance
The opposite of front is back
The opposite of south is
2024-07-26 23:43:16 root INFO     [order_1_approx] starting weight calculation for The opposite of exit is entrance
The opposite of anterior is posterior
The opposite of front is back
The opposite of southeast is southwest
The opposite of south is north
The opposite of below is above
The opposite of forward is backward
The opposite of in is
2024-07-26 23:43:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 23:45:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2815,  0.2827, -0.1208,  ..., -0.0706, -0.1705, -0.2402],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7266, -4.3945,  1.9980,  ..., -3.1602,  0.6025, -5.1953],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0785,  0.0201, -0.0311,  ...,  0.0174, -0.0341, -0.0075],
        [ 0.0230,  0.0584,  0.0037,  ...,  0.0247,  0.0224,  0.0358],
        [-0.0022,  0.0135,  0.0011,  ..., -0.0110, -0.0228, -0.0119],
        ...,
        [ 0.0070,  0.0134,  0.0007,  ...,  0.0437,  0.0332,  0.0012],
        [-0.0334, -0.0226,  0.0216,  ...,  0.0044,  0.0540,  0.0078],
        [ 0.0629,  0.0183, -0.0069,  ..., -0.0108, -0.0072,  0.0074]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1152, -4.5781,  2.2578,  ..., -3.4570, -0.1250, -4.4570]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 23:45:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of exit is entrance
The opposite of anterior is posterior
The opposite of front is back
The opposite of southeast is southwest
The opposite of south is north
The opposite of below is above
The opposite of forward is backward
The opposite of in is
2024-07-26 23:45:34 root INFO     total operator prediction time: 1109.598109960556 seconds
2024-07-26 23:45:34 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hyponyms - misc
2024-07-26 23:45:34 root INFO     building operator hyponyms - misc
2024-07-26 23:45:34 root INFO     [order_1_approx] starting weight calculation for A more specific term for a sofa is divan
A more specific term for a jewelry is bracelet
A more specific term for a bag is pouch
A more specific term for a boat is ferry
A more specific term for a weapon is gun
A more specific term for a spice is pepper
A more specific term for a toy is doll
A more specific term for a car is
2024-07-26 23:45:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 23:47:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3965, -0.1748, -0.0620,  ...,  0.0767, -0.0651, -0.4004],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0530, -7.3516,  0.5278,  ...,  1.7822, -2.6738, -2.0430],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0439, -0.0120,  0.0083,  ..., -0.0019, -0.0014,  0.0162],
        [-0.0096,  0.0409,  0.0133,  ...,  0.0151,  0.0169, -0.0271],
        [ 0.0127, -0.0139,  0.0605,  ..., -0.0045, -0.0211,  0.0192],
        ...,
        [-0.0004,  0.0188, -0.0129,  ...,  0.0342,  0.0136,  0.0090],
        [-0.0074, -0.0041,  0.0047,  ..., -0.0053,  0.0473, -0.0077],
        [ 0.0176,  0.0049, -0.0096,  ..., -0.0241,  0.0076,  0.0569]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0432, -7.3203,  0.6504,  ...,  1.5596, -2.6543, -1.6660]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 23:47:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a sofa is divan
A more specific term for a jewelry is bracelet
A more specific term for a bag is pouch
A more specific term for a boat is ferry
A more specific term for a weapon is gun
A more specific term for a spice is pepper
A more specific term for a toy is doll
A more specific term for a car is
2024-07-26 23:47:51 root INFO     [order_1_approx] starting weight calculation for A more specific term for a jewelry is bracelet
A more specific term for a weapon is gun
A more specific term for a sofa is divan
A more specific term for a bag is pouch
A more specific term for a boat is ferry
A more specific term for a toy is doll
A more specific term for a car is limousine
A more specific term for a spice is
2024-07-26 23:47:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 23:50:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1422,  0.1357, -0.0988,  ...,  0.2299,  0.1013, -0.3750],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9004, -4.7266, -1.0059,  ..., -0.7285, -2.7695, -0.9990],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.4382e-02, -7.9803e-03,  3.9864e-04,  ..., -4.5319e-03,
          1.9699e-02,  9.4223e-04],
        [-2.6901e-02,  4.9927e-02, -1.5381e-02,  ...,  7.7171e-03,
          3.3997e-02, -3.4695e-03],
        [-7.2136e-03, -1.5236e-02,  5.1483e-02,  ...,  1.0475e-02,
         -1.7776e-02,  5.1689e-03],
        ...,
        [ 3.2063e-03,  4.1992e-02,  1.0513e-02,  ...,  5.5237e-02,
          1.2680e-02, -1.8954e-04],
        [-6.8665e-05,  1.5678e-03, -7.0992e-03,  ..., -1.5823e-02,
          5.6335e-02, -2.4460e-02],
        [ 2.3712e-02, -1.4687e-02,  4.0131e-03,  ..., -3.2898e-02,
          1.3214e-02,  3.3508e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5488, -4.6250, -1.0000,  ..., -0.7627, -2.9805, -0.9932]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 23:50:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a jewelry is bracelet
A more specific term for a weapon is gun
A more specific term for a sofa is divan
A more specific term for a bag is pouch
A more specific term for a boat is ferry
A more specific term for a toy is doll
A more specific term for a car is limousine
A more specific term for a spice is
2024-07-26 23:50:12 root INFO     [order_1_approx] starting weight calculation for A more specific term for a weapon is gun
A more specific term for a toy is doll
A more specific term for a car is limousine
A more specific term for a bag is pouch
A more specific term for a jewelry is bracelet
A more specific term for a spice is pepper
A more specific term for a boat is ferry
A more specific term for a sofa is
2024-07-26 23:50:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 23:52:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3015, -0.2800,  0.2610,  ...,  0.2375, -0.6294, -0.0455],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3931, -5.8242,  4.0977,  ...,  1.1221, -4.4492, -1.0596],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0881,  0.0072,  0.0029,  ...,  0.0242,  0.0158,  0.0018],
        [ 0.0038,  0.0546,  0.0037,  ...,  0.0194,  0.0089, -0.0292],
        [-0.0244, -0.0168,  0.0812,  ..., -0.0167, -0.0236, -0.0041],
        ...,
        [ 0.0369,  0.0166, -0.0249,  ...,  0.0924,  0.0049, -0.0126],
        [ 0.0206,  0.0064, -0.0123,  ..., -0.0090,  0.0505,  0.0054],
        [-0.0089,  0.0184, -0.0050,  ..., -0.0442, -0.0041,  0.0621]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3335, -5.3828,  3.7168,  ...,  1.1621, -3.7812, -0.7734]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 23:52:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a weapon is gun
A more specific term for a toy is doll
A more specific term for a car is limousine
A more specific term for a bag is pouch
A more specific term for a jewelry is bracelet
A more specific term for a spice is pepper
A more specific term for a boat is ferry
A more specific term for a sofa is
2024-07-26 23:52:33 root INFO     [order_1_approx] starting weight calculation for A more specific term for a toy is doll
A more specific term for a bag is pouch
A more specific term for a car is limousine
A more specific term for a weapon is gun
A more specific term for a spice is pepper
A more specific term for a sofa is divan
A more specific term for a boat is ferry
A more specific term for a jewelry is
2024-07-26 23:52:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 23:54:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2384, -0.3677, -0.0632,  ..., -0.1680, -0.2207, -0.1299],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4912, -3.0195, -5.0352,  ..., -0.3027, -3.1016,  1.6055],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0219, -0.0057,  0.0078,  ..., -0.0067, -0.0038,  0.0088],
        [-0.0077,  0.0260,  0.0023,  ..., -0.0053,  0.0140, -0.0112],
        [ 0.0023,  0.0031,  0.0238,  ...,  0.0047, -0.0027,  0.0087],
        ...,
        [ 0.0014,  0.0001, -0.0054,  ...,  0.0159,  0.0082, -0.0114],
        [-0.0082, -0.0030, -0.0051,  ...,  0.0065, -0.0027, -0.0016],
        [ 0.0009,  0.0091,  0.0053,  ..., -0.0208,  0.0103,  0.0193]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4561, -2.8086, -5.0000,  ..., -0.1912, -2.8926,  1.4600]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 23:54:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a toy is doll
A more specific term for a bag is pouch
A more specific term for a car is limousine
A more specific term for a weapon is gun
A more specific term for a spice is pepper
A more specific term for a sofa is divan
A more specific term for a boat is ferry
A more specific term for a jewelry is
2024-07-26 23:54:54 root INFO     [order_1_approx] starting weight calculation for A more specific term for a boat is ferry
A more specific term for a car is limousine
A more specific term for a toy is doll
A more specific term for a jewelry is bracelet
A more specific term for a spice is pepper
A more specific term for a weapon is gun
A more specific term for a sofa is divan
A more specific term for a bag is
2024-07-26 23:54:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 23:57:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3262,  0.0424, -0.1581,  ...,  0.4153, -0.5234, -0.6592],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.1914, -3.7480, -2.5020,  ...,  0.6963,  0.2314,  1.1777],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0583, -0.0187, -0.0085,  ...,  0.0272, -0.0120,  0.0122],
        [-0.0267,  0.0554, -0.0140,  ..., -0.0150,  0.0098, -0.0084],
        [ 0.0208,  0.0009,  0.0527,  ...,  0.0235, -0.0217, -0.0073],
        ...,
        [ 0.0110,  0.0192, -0.0045,  ...,  0.0296, -0.0021, -0.0178],
        [-0.0214,  0.0065,  0.0059,  ..., -0.0140,  0.0380, -0.0030],
        [-0.0305,  0.0157,  0.0108,  ..., -0.0128,  0.0168,  0.0544]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.0312, -3.6133, -2.3027,  ...,  0.7656,  0.2345,  1.0059]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 23:57:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a boat is ferry
A more specific term for a car is limousine
A more specific term for a toy is doll
A more specific term for a jewelry is bracelet
A more specific term for a spice is pepper
A more specific term for a weapon is gun
A more specific term for a sofa is divan
A more specific term for a bag is
2024-07-26 23:57:10 root INFO     [order_1_approx] starting weight calculation for A more specific term for a sofa is divan
A more specific term for a car is limousine
A more specific term for a bag is pouch
A more specific term for a weapon is gun
A more specific term for a boat is ferry
A more specific term for a jewelry is bracelet
A more specific term for a spice is pepper
A more specific term for a toy is
2024-07-26 23:57:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-26 23:59:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1907,  0.1421,  0.2954,  ..., -0.2764, -0.1575, -0.2211],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-4.0625, -4.3320,  0.3018,  ...,  2.8477, -1.8672,  0.5713],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0639,  0.0051,  0.0071,  ...,  0.0111, -0.0215, -0.0031],
        [ 0.0001,  0.0409, -0.0144,  ..., -0.0101,  0.0189, -0.0159],
        [ 0.0051, -0.0292,  0.0608,  ...,  0.0010, -0.0207,  0.0093],
        ...,
        [ 0.0111,  0.0042, -0.0104,  ...,  0.0373,  0.0075, -0.0064],
        [-0.0035,  0.0121, -0.0094,  ..., -0.0053,  0.0235, -0.0049],
        [ 0.0075,  0.0144,  0.0086,  ..., -0.0130,  0.0060,  0.0643]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-3.5508, -4.2109,  0.3958,  ...,  2.8281, -1.9316,  0.2690]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 23:59:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a sofa is divan
A more specific term for a car is limousine
A more specific term for a bag is pouch
A more specific term for a weapon is gun
A more specific term for a boat is ferry
A more specific term for a jewelry is bracelet
A more specific term for a spice is pepper
A more specific term for a toy is
2024-07-26 23:59:29 root INFO     [order_1_approx] starting weight calculation for A more specific term for a toy is doll
A more specific term for a jewelry is bracelet
A more specific term for a boat is ferry
A more specific term for a sofa is divan
A more specific term for a spice is pepper
A more specific term for a bag is pouch
A more specific term for a car is limousine
A more specific term for a weapon is
2024-07-26 23:59:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 00:01:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1128, -0.0244,  0.2297,  ..., -0.0988, -0.3398, -0.2822],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.7979, -6.3125,  0.0186,  ...,  2.1641, -3.5488, -0.1445],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.5807e-02,  3.7575e-03,  8.3065e-04,  ..., -1.4854e-02,
         -1.9821e-02,  7.3318e-03],
        [-1.0422e-02,  3.3936e-02,  1.1215e-02,  ...,  1.7166e-03,
          3.9551e-02, -3.3295e-02],
        [-1.5621e-03,  1.2985e-02,  6.1920e-02,  ..., -9.0599e-04,
         -8.9645e-03,  6.9809e-03],
        ...,
        [ 1.2352e-02, -9.9640e-03, -1.2711e-02,  ...,  5.8136e-02,
          1.3542e-02,  7.9041e-03],
        [-1.3489e-02, -1.1581e-02, -1.8349e-03,  ...,  1.4526e-02,
          5.7129e-02, -3.2990e-02],
        [ 1.6525e-02, -7.1716e-04,  2.0416e-02,  ..., -6.7558e-03,
          8.5831e-06,  4.2755e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.7012, -6.1953, -0.0131,  ...,  2.4961, -3.6367,  0.0438]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 00:01:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a toy is doll
A more specific term for a jewelry is bracelet
A more specific term for a boat is ferry
A more specific term for a sofa is divan
A more specific term for a spice is pepper
A more specific term for a bag is pouch
A more specific term for a car is limousine
A more specific term for a weapon is
2024-07-27 00:01:48 root INFO     [order_1_approx] starting weight calculation for A more specific term for a car is limousine
A more specific term for a weapon is gun
A more specific term for a bag is pouch
A more specific term for a jewelry is bracelet
A more specific term for a spice is pepper
A more specific term for a toy is doll
A more specific term for a sofa is divan
A more specific term for a boat is
2024-07-27 00:01:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 00:04:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4373, -0.1509,  0.1018,  ..., -0.0845, -0.4028,  0.0258],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2334e+00, -4.4453e+00, -1.1426e-01,  ...,  9.4482e-01,
        -4.3945e-03, -9.3408e-01], device='cuda:1', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.8716e-02, -2.2888e-05,  3.4218e-03,  ...,  1.1299e-02,
          2.9343e-02,  8.4991e-03],
        [-1.6632e-02,  4.8706e-02, -3.3760e-03,  ...,  1.4267e-02,
          8.5754e-03, -2.4872e-03],
        [-7.6637e-03,  1.5430e-03,  7.9224e-02,  ..., -6.9618e-03,
         -2.5879e-02,  1.1963e-02],
        ...,
        [ 2.1179e-02,  2.5497e-02,  5.5923e-03,  ...,  4.0649e-02,
          2.0981e-02, -1.2772e-02],
        [-8.9340e-03, -7.6485e-04,  6.3705e-04,  ..., -9.3842e-03,
          2.0645e-02, -1.5450e-02],
        [ 8.9798e-03,  8.3466e-03, -1.3115e-02,  ..., -9.8877e-03,
         -1.1284e-02,  4.3549e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0908e+00, -4.3945e+00,  4.3335e-03,  ...,  1.3965e+00,
          4.5013e-02, -9.6582e-01]], device='cuda:1', dtype=torch.float16,
       grad_fn=<SubBackward0>) 

                    
2024-07-27 00:04:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a car is limousine
A more specific term for a weapon is gun
A more specific term for a bag is pouch
A more specific term for a jewelry is bracelet
A more specific term for a spice is pepper
A more specific term for a toy is doll
A more specific term for a sofa is divan
A more specific term for a boat is
2024-07-27 00:04:08 root INFO     total operator prediction time: 1114.683675289154 seconds
2024-07-27 00:04:08 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hypernyms - animals
2024-07-27 00:04:08 root INFO     building operator hypernyms - animals
2024-07-27 00:04:08 root INFO     [order_1_approx] starting weight calculation for The fox falls into the category of canine
The ant falls into the category of insect
The leopard falls into the category of feline
The duck falls into the category of fowl
The beetle falls into the category of insect
The coyote falls into the category of canine
The cobra falls into the category of snake
The triceratops falls into the category of
2024-07-27 00:04:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 00:06:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4534, -0.0954, -0.3022,  ...,  0.3481, -0.6338,  0.6626],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2715, -4.9922,  1.5430,  ..., -0.5312, -5.1719, -0.9839],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0429, -0.0097, -0.0223,  ...,  0.0132, -0.0152, -0.0087],
        [-0.0011,  0.0282, -0.0032,  ...,  0.0081,  0.0154, -0.0217],
        [ 0.0059,  0.0040,  0.0506,  ..., -0.0188, -0.0236,  0.0127],
        ...,
        [ 0.0045, -0.0063,  0.0148,  ...,  0.0651,  0.0015,  0.0029],
        [-0.0138,  0.0012,  0.0160,  ...,  0.0050,  0.0476,  0.0033],
        [ 0.0033, -0.0186, -0.0094,  ...,  0.0121, -0.0229,  0.0414]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1738, -4.9180,  1.0039,  ..., -0.2666, -5.4414, -0.7119]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 00:06:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The fox falls into the category of canine
The ant falls into the category of insect
The leopard falls into the category of feline
The duck falls into the category of fowl
The beetle falls into the category of insect
The coyote falls into the category of canine
The cobra falls into the category of snake
The triceratops falls into the category of
2024-07-27 00:06:29 root INFO     [order_1_approx] starting weight calculation for The coyote falls into the category of canine
The triceratops falls into the category of dinosaur
The duck falls into the category of fowl
The beetle falls into the category of insect
The cobra falls into the category of snake
The leopard falls into the category of feline
The fox falls into the category of canine
The ant falls into the category of
2024-07-27 00:06:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 00:08:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1165, -0.4055, -0.2333,  ...,  0.0702, -0.1545, -0.0141],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3008, -4.1797,  2.1289,  ..., -3.1914, -3.9883, -1.1074],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.0171e-02,  6.2637e-03, -1.3382e-02,  ...,  3.5629e-03,
         -1.4679e-02, -7.2556e-03],
        [ 1.7151e-02,  3.7445e-02,  8.8196e-03,  ...,  2.2568e-02,
          9.2850e-03, -2.9343e-02],
        [ 4.6844e-03,  9.7198e-03,  6.4087e-02,  ..., -1.7731e-02,
         -1.5404e-02,  2.0447e-02],
        ...,
        [ 2.1606e-02,  1.0452e-02,  1.4198e-02,  ...,  6.6711e-02,
          2.6035e-03,  7.0114e-03],
        [-2.5482e-02,  1.9073e-06,  3.3588e-03,  ..., -9.4833e-03,
          3.2867e-02,  1.1398e-02],
        [-7.8812e-03, -1.8158e-02, -8.3389e-03,  ..., -1.8936e-02,
         -5.1384e-03,  4.0680e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3279, -4.4414,  1.3848,  ..., -2.7793, -4.2734, -0.7300]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 00:08:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The coyote falls into the category of canine
The triceratops falls into the category of dinosaur
The duck falls into the category of fowl
The beetle falls into the category of insect
The cobra falls into the category of snake
The leopard falls into the category of feline
The fox falls into the category of canine
The ant falls into the category of
2024-07-27 00:08:50 root INFO     [order_1_approx] starting weight calculation for The beetle falls into the category of insect
The duck falls into the category of fowl
The cobra falls into the category of snake
The fox falls into the category of canine
The triceratops falls into the category of dinosaur
The coyote falls into the category of canine
The ant falls into the category of insect
The leopard falls into the category of
2024-07-27 00:08:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 00:11:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2042, -0.2734, -0.1647,  ...,  0.5059, -0.1289, -0.0869],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6279, -7.1250, -0.6406,  ..., -4.3281, -6.1484,  0.3232],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0370,  0.0008, -0.0068,  ..., -0.0114, -0.0138,  0.0046],
        [ 0.0163,  0.0126,  0.0086,  ..., -0.0057,  0.0199,  0.0051],
        [-0.0009,  0.0061,  0.0356,  ...,  0.0063, -0.0072, -0.0078],
        ...,
        [-0.0084,  0.0061,  0.0088,  ...,  0.0307,  0.0158,  0.0050],
        [ 0.0068, -0.0162, -0.0125,  ...,  0.0059,  0.0263,  0.0022],
        [-0.0085, -0.0006, -0.0089,  ..., -0.0097, -0.0043,  0.0261]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6895, -6.9414, -0.6938,  ..., -4.3164, -6.1836,  0.3813]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 00:11:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The beetle falls into the category of insect
The duck falls into the category of fowl
The cobra falls into the category of snake
The fox falls into the category of canine
The triceratops falls into the category of dinosaur
The coyote falls into the category of canine
The ant falls into the category of insect
The leopard falls into the category of
2024-07-27 00:11:10 root INFO     [order_1_approx] starting weight calculation for The triceratops falls into the category of dinosaur
The fox falls into the category of canine
The duck falls into the category of fowl
The ant falls into the category of insect
The cobra falls into the category of snake
The beetle falls into the category of insect
The leopard falls into the category of feline
The coyote falls into the category of
2024-07-27 00:11:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 00:13:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0351, -0.0991, -0.3062,  ...,  0.4587, -0.4458, -0.1868],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4390, -6.6953,  1.8291,  ..., -4.0977, -4.6797,  1.7148],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.8309e-02,  1.2115e-02, -1.1322e-02,  ...,  1.7529e-03,
         -2.5803e-02, -2.1362e-03],
        [ 1.9669e-02,  1.1650e-02,  1.6373e-02,  ...,  4.1809e-03,
          2.4414e-03, -4.3678e-03],
        [-7.7248e-05,  7.6828e-03,  4.8096e-02,  ..., -2.7374e-02,
         -6.3210e-03, -1.1864e-02],
        ...,
        [ 5.4264e-04,  1.5137e-02,  1.5421e-03,  ...,  8.2169e-03,
          2.8564e-02,  3.8929e-03],
        [-6.1798e-04, -1.5594e-02, -2.8496e-03,  ...,  2.0065e-03,
          3.1830e-02,  3.7003e-04],
        [-2.7695e-03, -1.6800e-02,  7.6065e-03,  ...,  6.2485e-03,
         -2.5482e-02,  2.6520e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4565, -6.7578,  1.4736,  ..., -4.0781, -5.1562,  1.6084]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 00:13:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The triceratops falls into the category of dinosaur
The fox falls into the category of canine
The duck falls into the category of fowl
The ant falls into the category of insect
The cobra falls into the category of snake
The beetle falls into the category of insect
The leopard falls into the category of feline
The coyote falls into the category of
2024-07-27 00:13:31 root INFO     [order_1_approx] starting weight calculation for The triceratops falls into the category of dinosaur
The duck falls into the category of fowl
The fox falls into the category of canine
The beetle falls into the category of insect
The ant falls into the category of insect
The coyote falls into the category of canine
The leopard falls into the category of feline
The cobra falls into the category of
2024-07-27 00:13:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 00:15:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0790,  0.1421,  0.0157,  ...,  0.3491, -0.0177,  0.1031],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2510, -5.2812,  2.4492,  ..., -2.6953, -3.4941, -0.0488],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.7791e-02, -2.4414e-04, -4.7874e-03,  ..., -2.0294e-02,
         -2.9373e-04,  6.5613e-03],
        [-7.8278e-03,  6.3354e-02,  2.4834e-03,  ..., -1.0406e-02,
          1.2115e-02, -5.7526e-03],
        [-1.4629e-03, -8.3923e-05,  6.9031e-02,  ..., -2.3773e-02,
          9.1553e-05, -1.3390e-02],
        ...,
        [ 1.2924e-02,  7.7286e-03,  1.5137e-02,  ...,  6.5186e-02,
          2.0660e-02,  4.2953e-03],
        [-8.1711e-03,  1.0643e-02,  4.3678e-03,  ..., -6.9237e-03,
          4.2023e-02, -1.0345e-02],
        [ 5.1613e-03, -2.0691e-02, -5.2567e-03,  ..., -9.6054e-03,
          3.1662e-04,  5.1483e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3987, -5.4180,  1.9131,  ..., -2.1797, -4.0742,  0.6294]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 00:15:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The triceratops falls into the category of dinosaur
The duck falls into the category of fowl
The fox falls into the category of canine
The beetle falls into the category of insect
The ant falls into the category of insect
The coyote falls into the category of canine
The leopard falls into the category of feline
The cobra falls into the category of
2024-07-27 00:15:51 root INFO     [order_1_approx] starting weight calculation for The leopard falls into the category of feline
The cobra falls into the category of snake
The ant falls into the category of insect
The duck falls into the category of fowl
The triceratops falls into the category of dinosaur
The coyote falls into the category of canine
The fox falls into the category of canine
The beetle falls into the category of
2024-07-27 00:15:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 00:18:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1187, -0.2041,  0.0807,  ...,  0.4927, -0.2314, -0.3003],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7109, -3.6094,  2.6836,  ..., -1.5234, -1.5410, -2.1172],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0517,  0.0039, -0.0021,  ..., -0.0031, -0.0143,  0.0033],
        [ 0.0290,  0.0132,  0.0108,  ...,  0.0307,  0.0068, -0.0086],
        [-0.0137,  0.0004,  0.0517,  ..., -0.0103, -0.0180, -0.0006],
        ...,
        [ 0.0177,  0.0095, -0.0038,  ...,  0.0622,  0.0098,  0.0059],
        [-0.0062,  0.0158,  0.0106,  ...,  0.0189,  0.0320,  0.0074],
        [ 0.0027, -0.0150, -0.0060,  ..., -0.0125, -0.0058,  0.0331]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5840, -4.0664,  2.6562,  ..., -1.5820, -1.8408, -1.8457]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 00:18:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The leopard falls into the category of feline
The cobra falls into the category of snake
The ant falls into the category of insect
The duck falls into the category of fowl
The triceratops falls into the category of dinosaur
The coyote falls into the category of canine
The fox falls into the category of canine
The beetle falls into the category of
2024-07-27 00:18:12 root INFO     [order_1_approx] starting weight calculation for The fox falls into the category of canine
The leopard falls into the category of feline
The coyote falls into the category of canine
The triceratops falls into the category of dinosaur
The beetle falls into the category of insect
The ant falls into the category of insect
The cobra falls into the category of snake
The duck falls into the category of
2024-07-27 00:18:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 00:20:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2213, -0.2734,  0.2166,  ...,  0.2290, -0.4971,  0.3301],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1504, -3.3516,  4.8125,  ..., -1.3799, -7.4883,  1.7891],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0460,  0.0049, -0.0196,  ...,  0.0035, -0.0100, -0.0017],
        [ 0.0099,  0.0368,  0.0101,  ...,  0.0038,  0.0046, -0.0172],
        [-0.0058, -0.0061,  0.0465,  ..., -0.0112, -0.0147,  0.0016],
        ...,
        [ 0.0087, -0.0073,  0.0188,  ...,  0.0368, -0.0059,  0.0069],
        [-0.0068, -0.0010, -0.0026,  ..., -0.0044,  0.0315, -0.0011],
        [ 0.0104, -0.0146, -0.0049,  ...,  0.0012, -0.0063,  0.0421]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5781, -3.0957,  3.8516,  ..., -1.2236, -7.6602,  2.0879]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 00:20:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The fox falls into the category of canine
The leopard falls into the category of feline
The coyote falls into the category of canine
The triceratops falls into the category of dinosaur
The beetle falls into the category of insect
The ant falls into the category of insect
The cobra falls into the category of snake
The duck falls into the category of
2024-07-27 00:20:31 root INFO     [order_1_approx] starting weight calculation for The leopard falls into the category of feline
The duck falls into the category of fowl
The beetle falls into the category of insect
The ant falls into the category of insect
The triceratops falls into the category of dinosaur
The coyote falls into the category of canine
The cobra falls into the category of snake
The fox falls into the category of
2024-07-27 00:20:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 00:22:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3484,  0.0384,  0.0558,  ...,  0.2162, -0.2131, -0.2203],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1945, -6.7539,  2.3691,  ..., -3.6074, -6.6016,  1.9727],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0351,  0.0112, -0.0037,  ..., -0.0012, -0.0178,  0.0037],
        [ 0.0266,  0.0226,  0.0187,  ...,  0.0016,  0.0060, -0.0301],
        [ 0.0019,  0.0050,  0.0473,  ..., -0.0261,  0.0089, -0.0105],
        ...,
        [ 0.0074,  0.0019,  0.0117,  ...,  0.0131,  0.0305, -0.0002],
        [-0.0096, -0.0120, -0.0112,  ...,  0.0076,  0.0335,  0.0050],
        [ 0.0145, -0.0134, -0.0102,  ..., -0.0058, -0.0076,  0.0311]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2917, -6.9492,  1.9414,  ..., -3.3105, -6.5977,  1.8076]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 00:22:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The leopard falls into the category of feline
The duck falls into the category of fowl
The beetle falls into the category of insect
The ant falls into the category of insect
The triceratops falls into the category of dinosaur
The coyote falls into the category of canine
The cobra falls into the category of snake
The fox falls into the category of
2024-07-27 00:22:52 root INFO     total operator prediction time: 1123.2602047920227 seconds
2024-07-27 00:22:52 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on synonyms - intensity
2024-07-27 00:22:52 root INFO     building operator synonyms - intensity
2024-07-27 00:22:52 root INFO     [order_1_approx] starting weight calculation for A more intense word for necessary is essential
A more intense word for angry is furious
A more intense word for tired is exhausted
A more intense word for unfortunate is tragic
A more intense word for chuckle is laugh
A more intense word for snack is meal
A more intense word for indulge is pamper
A more intense word for sea is
2024-07-27 00:22:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 00:25:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1296, -0.0417, -0.1851,  ..., -0.3052,  0.0812, -0.0756],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7969, -4.8320,  0.2002,  ..., -2.2285, -1.0674,  0.7930],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0690,  0.0119, -0.0006,  ..., -0.0104,  0.0258,  0.0276],
        [-0.0267,  0.0523, -0.0244,  ..., -0.0163,  0.0141, -0.0365],
        [-0.0162,  0.0005,  0.0833,  ...,  0.0030, -0.0283,  0.0269],
        ...,
        [-0.0144,  0.0511, -0.0199,  ...,  0.0475,  0.0306, -0.0098],
        [-0.0232,  0.0083,  0.0322,  ...,  0.0201,  0.0688,  0.0016],
        [ 0.0101, -0.0143, -0.0233,  ...,  0.0239,  0.0066,  0.0551]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4561, -4.3398,  0.0750,  ..., -1.5820, -1.4863,  0.2354]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 00:25:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for necessary is essential
A more intense word for angry is furious
A more intense word for tired is exhausted
A more intense word for unfortunate is tragic
A more intense word for chuckle is laugh
A more intense word for snack is meal
A more intense word for indulge is pamper
A more intense word for sea is
2024-07-27 00:25:13 root INFO     [order_1_approx] starting weight calculation for A more intense word for tired is exhausted
A more intense word for sea is ocean
A more intense word for indulge is pamper
A more intense word for snack is meal
A more intense word for necessary is essential
A more intense word for unfortunate is tragic
A more intense word for angry is furious
A more intense word for chuckle is
2024-07-27 00:25:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 00:27:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0743, -0.2313, -0.3298,  ...,  0.0747, -0.4629,  0.1667],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5000, -1.7178,  4.7422,  ...,  3.4805, -0.5117,  0.0781],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0874,  0.0097,  0.0184,  ..., -0.0103, -0.0116,  0.0273],
        [-0.0260,  0.0583, -0.0065,  ...,  0.0107,  0.0340,  0.0015],
        [ 0.0087, -0.0168,  0.0441,  ..., -0.0068, -0.0086, -0.0176],
        ...,
        [-0.0073, -0.0061,  0.0053,  ...,  0.0413,  0.0026, -0.0082],
        [-0.0072, -0.0130,  0.0073,  ...,  0.0004,  0.0298,  0.0072],
        [-0.0117,  0.0034, -0.0154,  ..., -0.0035,  0.0036,  0.0381]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5137, -2.2090,  5.1250,  ...,  3.2734, -0.3447, -0.2104]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 00:27:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for tired is exhausted
A more intense word for sea is ocean
A more intense word for indulge is pamper
A more intense word for snack is meal
A more intense word for necessary is essential
A more intense word for unfortunate is tragic
A more intense word for angry is furious
A more intense word for chuckle is
2024-07-27 00:27:34 root INFO     [order_1_approx] starting weight calculation for A more intense word for sea is ocean
A more intense word for snack is meal
A more intense word for chuckle is laugh
A more intense word for indulge is pamper
A more intense word for necessary is essential
A more intense word for tired is exhausted
A more intense word for angry is furious
A more intense word for unfortunate is
2024-07-27 00:27:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 00:29:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4443,  0.5449, -0.5527,  ..., -0.1151, -0.5044,  0.0396],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.5078, -2.0000,  2.4258,  ..., -0.9219, -0.2773, -3.5898],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0131,  0.0081,  0.0008,  ...,  0.0086, -0.0278, -0.0085],
        [ 0.0196,  0.0308,  0.0038,  ...,  0.0010,  0.0157,  0.0075],
        [ 0.0023, -0.0207,  0.0445,  ...,  0.0035, -0.0101,  0.0034],
        ...,
        [ 0.0028,  0.0064, -0.0052,  ...,  0.0477, -0.0187, -0.0129],
        [ 0.0226, -0.0090,  0.0080,  ...,  0.0020,  0.0457, -0.0051],
        [ 0.0051, -0.0135, -0.0009,  ..., -0.0030, -0.0169,  0.0677]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.7344, -1.9395,  2.4688,  ..., -1.2393, -0.4697, -3.6934]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 00:29:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for sea is ocean
A more intense word for snack is meal
A more intense word for chuckle is laugh
A more intense word for indulge is pamper
A more intense word for necessary is essential
A more intense word for tired is exhausted
A more intense word for angry is furious
A more intense word for unfortunate is
2024-07-27 00:29:55 root INFO     [order_1_approx] starting weight calculation for A more intense word for tired is exhausted
A more intense word for indulge is pamper
A more intense word for chuckle is laugh
A more intense word for sea is ocean
A more intense word for necessary is essential
A more intense word for unfortunate is tragic
A more intense word for snack is meal
A more intense word for angry is
2024-07-27 00:29:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 00:32:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1086,  0.2260, -0.5068,  ..., -0.2500, -0.2529,  0.3315],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0195, -6.0430, -0.7354,  ..., -2.4922, -1.5332,  0.3027],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0775,  0.0204,  0.0120,  ..., -0.0084,  0.0010,  0.0017],
        [ 0.0045,  0.0420, -0.0135,  ...,  0.0063,  0.0093, -0.0013],
        [ 0.0168,  0.0133,  0.0679,  ..., -0.0085,  0.0044, -0.0090],
        ...,
        [ 0.0062,  0.0172, -0.0071,  ...,  0.0426,  0.0026, -0.0212],
        [-0.0008,  0.0090,  0.0028,  ...,  0.0201,  0.0567, -0.0237],
        [-0.0023, -0.0158, -0.0035,  ..., -0.0025, -0.0183,  0.0508]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9082, -5.9648, -0.5479,  ..., -2.4180, -1.4873, -0.0112]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 00:32:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for tired is exhausted
A more intense word for indulge is pamper
A more intense word for chuckle is laugh
A more intense word for sea is ocean
A more intense word for necessary is essential
A more intense word for unfortunate is tragic
A more intense word for snack is meal
A more intense word for angry is
2024-07-27 00:32:16 root INFO     [order_1_approx] starting weight calculation for A more intense word for tired is exhausted
A more intense word for unfortunate is tragic
A more intense word for chuckle is laugh
A more intense word for sea is ocean
A more intense word for indulge is pamper
A more intense word for angry is furious
A more intense word for snack is meal
A more intense word for necessary is
2024-07-27 00:32:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 00:34:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2935, -0.0217, -0.4888,  ..., -0.3848, -0.4487, -0.0875],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.9531,  0.0526, -0.8013,  ..., -0.3870, -5.7969, -0.5244],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0412, -0.0092,  0.0168,  ...,  0.0179,  0.0157,  0.0054],
        [-0.0062,  0.0572, -0.0078,  ...,  0.0186,  0.0293, -0.0081],
        [-0.0042,  0.0090,  0.0746,  ..., -0.0086, -0.0022, -0.0117],
        ...,
        [ 0.0114,  0.0410,  0.0154,  ...,  0.0757,  0.0065, -0.0194],
        [ 0.0185, -0.0014,  0.0071,  ..., -0.0375,  0.0458, -0.0107],
        [-0.0034, -0.0073, -0.0161,  ..., -0.0332, -0.0266,  0.0737]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.8633,  0.2949, -0.9575,  ..., -0.5176, -5.9961, -0.6572]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 00:34:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for tired is exhausted
A more intense word for unfortunate is tragic
A more intense word for chuckle is laugh
A more intense word for sea is ocean
A more intense word for indulge is pamper
A more intense word for angry is furious
A more intense word for snack is meal
A more intense word for necessary is
2024-07-27 00:34:37 root INFO     [order_1_approx] starting weight calculation for A more intense word for angry is furious
A more intense word for unfortunate is tragic
A more intense word for indulge is pamper
A more intense word for snack is meal
A more intense word for sea is ocean
A more intense word for chuckle is laugh
A more intense word for necessary is essential
A more intense word for tired is
2024-07-27 00:34:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 00:36:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2218, -0.3899, -0.4043,  ..., -0.0496, -0.2544,  0.5918],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0039e+00, -6.5039e+00,  3.7988e+00,  ..., -2.5293e+00,
        -6.2695e-01, -1.9531e-03], device='cuda:1', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0743,  0.0124,  0.0086,  ...,  0.0257,  0.0316,  0.0198],
        [ 0.0036,  0.0561, -0.0028,  ...,  0.0201,  0.0269, -0.0036],
        [ 0.0091,  0.0000,  0.0535,  ..., -0.0009, -0.0232, -0.0196],
        ...,
        [ 0.0201,  0.0049,  0.0074,  ...,  0.0369,  0.0084, -0.0242],
        [-0.0259,  0.0051, -0.0003,  ...,  0.0155,  0.0418,  0.0081],
        [ 0.0001,  0.0044, -0.0113,  ..., -0.0129, -0.0083,  0.0444]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3535, -6.2773,  3.8359,  ..., -2.3027, -0.6909, -0.5479]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 00:36:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for angry is furious
A more intense word for unfortunate is tragic
A more intense word for indulge is pamper
A more intense word for snack is meal
A more intense word for sea is ocean
A more intense word for chuckle is laugh
A more intense word for necessary is essential
A more intense word for tired is
2024-07-27 00:36:58 root INFO     [order_1_approx] starting weight calculation for A more intense word for necessary is essential
A more intense word for chuckle is laugh
A more intense word for unfortunate is tragic
A more intense word for snack is meal
A more intense word for tired is exhausted
A more intense word for angry is furious
A more intense word for sea is ocean
A more intense word for indulge is
2024-07-27 00:36:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 00:39:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2378,  0.1194, -0.5972,  ..., -0.2057, -0.7207,  0.4895],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5508, -1.9580, -3.0488,  ...,  0.9092, -4.6562,  1.8213],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0608, -0.0055,  0.0196,  ...,  0.0129, -0.0107,  0.0126],
        [ 0.0258,  0.0681, -0.0068,  ...,  0.0051, -0.0038, -0.0025],
        [-0.0191, -0.0090,  0.0336,  ..., -0.0051, -0.0117, -0.0113],
        ...,
        [ 0.0182, -0.0113, -0.0027,  ...,  0.0567, -0.0035, -0.0023],
        [-0.0292,  0.0324,  0.0156,  ..., -0.0110,  0.0319,  0.0052],
        [-0.0038, -0.0107, -0.0033,  ..., -0.0262, -0.0224,  0.0423]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6270, -1.9736, -3.0625,  ...,  1.1250, -4.5430,  1.9629]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 00:39:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for necessary is essential
A more intense word for chuckle is laugh
A more intense word for unfortunate is tragic
A more intense word for snack is meal
A more intense word for tired is exhausted
A more intense word for angry is furious
A more intense word for sea is ocean
A more intense word for indulge is
2024-07-27 00:39:17 root INFO     [order_1_approx] starting weight calculation for A more intense word for chuckle is laugh
A more intense word for indulge is pamper
A more intense word for angry is furious
A more intense word for sea is ocean
A more intense word for unfortunate is tragic
A more intense word for necessary is essential
A more intense word for tired is exhausted
A more intense word for snack is
2024-07-27 00:39:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 00:41:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0903, -0.2261, -0.5283,  ...,  0.0657, -0.6978, -0.3447],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6562, -2.0117, -0.5620,  ...,  1.2178, -4.8320,  0.0527],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0635, -0.0148,  0.0284,  ...,  0.0040, -0.0170,  0.0526],
        [ 0.0002,  0.0773,  0.0064,  ..., -0.0215, -0.0023, -0.0271],
        [ 0.0028, -0.0194,  0.0745,  ..., -0.0107, -0.0499,  0.0073],
        ...,
        [ 0.0166,  0.0076,  0.0155,  ...,  0.0645, -0.0070,  0.0049],
        [ 0.0012,  0.0180,  0.0298,  ...,  0.0104,  0.0299, -0.0128],
        [-0.0414,  0.0072, -0.0334,  ...,  0.0127,  0.0168,  0.0614]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1719, -1.5986, -0.3579,  ...,  1.2441, -5.1094,  0.2057]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 00:41:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for chuckle is laugh
A more intense word for indulge is pamper
A more intense word for angry is furious
A more intense word for sea is ocean
A more intense word for unfortunate is tragic
A more intense word for necessary is essential
A more intense word for tired is exhausted
A more intense word for snack is
2024-07-27 00:41:36 root INFO     total operator prediction time: 1124.339260339737 seconds
2024-07-27 00:41:36 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - substance
2024-07-27 00:41:36 root INFO     building operator meronyms - substance
2024-07-27 00:41:36 root INFO     [order_1_approx] starting weight calculation for A lawn is made up of grass
A water is made up of oxygen
A icicle is made up of ice
A bottle is made up of glass
A doorknob is made up of metal
A wine is made up of grapes
A candy is made up of sugar
A beard is made up of
2024-07-27 00:41:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 00:43:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1873, -0.0054, -0.1208,  ..., -0.0071, -0.0082,  0.0619],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5938, -4.9961, -3.0742,  ..., -2.6250,  1.6650, -0.7500],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0498,  0.0012, -0.0088,  ...,  0.0224, -0.0163,  0.0085],
        [-0.0070,  0.0336,  0.0139,  ..., -0.0270, -0.0005, -0.0033],
        [-0.0124, -0.0066,  0.0418,  ..., -0.0011, -0.0214, -0.0303],
        ...,
        [ 0.0145,  0.0036,  0.0208,  ...,  0.0491,  0.0038, -0.0134],
        [-0.0166,  0.0161, -0.0399,  ...,  0.0139,  0.0276, -0.0022],
        [ 0.0059,  0.0002,  0.0087,  ..., -0.0218, -0.0007,  0.0339]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7051, -4.8086, -2.9727,  ..., -2.2988,  1.4385, -0.7651]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 00:43:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A lawn is made up of grass
A water is made up of oxygen
A icicle is made up of ice
A bottle is made up of glass
A doorknob is made up of metal
A wine is made up of grapes
A candy is made up of sugar
A beard is made up of
2024-07-27 00:43:58 root INFO     [order_1_approx] starting weight calculation for A doorknob is made up of metal
A wine is made up of grapes
A beard is made up of hair
A candy is made up of sugar
A water is made up of oxygen
A icicle is made up of ice
A bottle is made up of glass
A lawn is made up of
2024-07-27 00:43:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 00:46:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2288,  0.3276, -0.3621,  ...,  0.1274, -0.0513, -0.2119],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.2969, -5.5469, -2.8672,  ..., -3.1270,  3.0449, -0.8301],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0368,  0.0056,  0.0062,  ...,  0.0121, -0.0257, -0.0103],
        [ 0.0095,  0.0167,  0.0187,  ...,  0.0022,  0.0074, -0.0096],
        [-0.0034,  0.0021,  0.0395,  ..., -0.0175, -0.0007,  0.0006],
        ...,
        [ 0.0157,  0.0060,  0.0169,  ...,  0.0486, -0.0075,  0.0011],
        [-0.0163,  0.0269, -0.0192,  ...,  0.0029,  0.0201,  0.0221],
        [-0.0019, -0.0202, -0.0062,  ..., -0.0063,  0.0039,  0.0271]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.0117, -5.2344, -3.0352,  ..., -2.8223,  2.7422, -0.8267]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 00:46:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A doorknob is made up of metal
A wine is made up of grapes
A beard is made up of hair
A candy is made up of sugar
A water is made up of oxygen
A icicle is made up of ice
A bottle is made up of glass
A lawn is made up of
2024-07-27 00:46:22 root INFO     [order_1_approx] starting weight calculation for A bottle is made up of glass
A candy is made up of sugar
A water is made up of oxygen
A wine is made up of grapes
A beard is made up of hair
A icicle is made up of ice
A lawn is made up of grass
A doorknob is made up of
2024-07-27 00:46:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 00:48:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2834, -0.2981, -0.2690,  ...,  0.3325, -0.1421, -0.2164],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1523, -3.6152, -1.7188,  ..., -2.4766, -0.2148, -0.2773],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.0760e-02, -6.7902e-03, -2.3895e-02,  ...,  3.8757e-02,
         -1.4183e-02, -8.3847e-03],
        [-1.4999e-02,  5.9784e-02,  8.8882e-03,  ..., -2.9202e-03,
         -1.0513e-02, -8.3923e-04],
        [ 1.8967e-02, -2.1362e-04,  6.1188e-02,  ...,  2.5768e-03,
         -6.0158e-03,  5.7697e-04],
        ...,
        [ 3.6957e-02,  4.1504e-03,  2.0370e-02,  ...,  7.0801e-02,
         -2.3773e-02, -3.2654e-03],
        [ 5.0125e-03,  9.3231e-03, -5.2452e-03,  ...,  1.8036e-02,
          4.5837e-02, -1.2253e-02],
        [ 6.6280e-04, -1.1124e-02,  3.3142e-02,  ..., -1.1475e-02,
         -7.0572e-05,  3.3813e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0078, -3.2852, -1.8926,  ..., -2.4961, -0.3147, -0.2625]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 00:48:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A bottle is made up of glass
A candy is made up of sugar
A water is made up of oxygen
A wine is made up of grapes
A beard is made up of hair
A icicle is made up of ice
A lawn is made up of grass
A doorknob is made up of
2024-07-27 00:48:44 root INFO     [order_1_approx] starting weight calculation for A wine is made up of grapes
A water is made up of oxygen
A icicle is made up of ice
A bottle is made up of glass
A doorknob is made up of metal
A beard is made up of hair
A lawn is made up of grass
A candy is made up of
2024-07-27 00:48:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 00:51:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2153, -0.0936, -0.2549,  ..., -0.0857,  0.1088, -0.1357],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4775, -6.3438, -0.0898,  ..., -2.8242, -1.0088,  5.4570],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0392,  0.0002, -0.0022,  ...,  0.0076, -0.0290,  0.0044],
        [-0.0172,  0.0468,  0.0163,  ...,  0.0161,  0.0226, -0.0118],
        [ 0.0009,  0.0177,  0.0195,  ...,  0.0033,  0.0047, -0.0018],
        ...,
        [ 0.0117, -0.0071,  0.0150,  ...,  0.0528, -0.0067,  0.0014],
        [-0.0057,  0.0219, -0.0128,  ...,  0.0317,  0.0511,  0.0184],
        [ 0.0021, -0.0009, -0.0064,  ..., -0.0120,  0.0190,  0.0492]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2725, -6.8438, -0.1749,  ..., -2.9355, -0.8213,  5.6016]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 00:51:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A wine is made up of grapes
A water is made up of oxygen
A icicle is made up of ice
A bottle is made up of glass
A doorknob is made up of metal
A beard is made up of hair
A lawn is made up of grass
A candy is made up of
2024-07-27 00:51:07 root INFO     [order_1_approx] starting weight calculation for A bottle is made up of glass
A candy is made up of sugar
A water is made up of oxygen
A doorknob is made up of metal
A beard is made up of hair
A icicle is made up of ice
A lawn is made up of grass
A wine is made up of
2024-07-27 00:51:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 00:53:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1178, -0.0247, -0.1899,  ..., -0.1256,  0.1582, -0.3994],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8271, -6.3594, -1.3320,  ..., -3.5508,  0.8145, -2.6094],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0372,  0.0079, -0.0180,  ..., -0.0075,  0.0001,  0.0012],
        [-0.0221,  0.0394,  0.0194,  ...,  0.0124,  0.0006, -0.0096],
        [ 0.0317, -0.0174,  0.0427,  ...,  0.0205,  0.0294, -0.0072],
        ...,
        [-0.0153,  0.0003,  0.0160,  ...,  0.0431,  0.0018, -0.0257],
        [ 0.0214,  0.0428, -0.0413,  ...,  0.0248,  0.0287,  0.0220],
        [-0.0071, -0.0105,  0.0167,  ..., -0.0160,  0.0056,  0.0425]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7646, -6.6953, -1.5127,  ..., -3.2227,  0.6533, -2.4824]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 00:53:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A bottle is made up of glass
A candy is made up of sugar
A water is made up of oxygen
A doorknob is made up of metal
A beard is made up of hair
A icicle is made up of ice
A lawn is made up of grass
A wine is made up of
2024-07-27 00:53:28 root INFO     [order_1_approx] starting weight calculation for A wine is made up of grapes
A doorknob is made up of metal
A beard is made up of hair
A water is made up of oxygen
A lawn is made up of grass
A bottle is made up of glass
A candy is made up of sugar
A icicle is made up of
2024-07-27 00:53:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 00:55:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2878, -0.0488, -0.5010,  ...,  0.1421, -0.3672, -0.1700],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1670, -4.2969,  0.6279,  ..., -4.2383,  0.6606,  0.6895],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0729, -0.0170, -0.0047,  ..., -0.0064, -0.0028, -0.0196],
        [-0.0066,  0.0371,  0.0203,  ..., -0.0031,  0.0011, -0.0392],
        [ 0.0042,  0.0212,  0.0274,  ...,  0.0210,  0.0074, -0.0092],
        ...,
        [ 0.0136,  0.0194,  0.0227,  ...,  0.0864,  0.0056,  0.0020],
        [-0.0294,  0.0194,  0.0040,  ...,  0.0409,  0.0272,  0.0314],
        [ 0.0111, -0.0243, -0.0011,  ...,  0.0125, -0.0013,  0.0251]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1738, -4.4102,  0.7852,  ..., -3.9648,  0.6899,  1.0801]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 00:55:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A wine is made up of grapes
A doorknob is made up of metal
A beard is made up of hair
A water is made up of oxygen
A lawn is made up of grass
A bottle is made up of glass
A candy is made up of sugar
A icicle is made up of
2024-07-27 00:55:44 root INFO     [order_1_approx] starting weight calculation for A icicle is made up of ice
A candy is made up of sugar
A beard is made up of hair
A wine is made up of grapes
A doorknob is made up of metal
A water is made up of oxygen
A lawn is made up of grass
A bottle is made up of
2024-07-27 00:55:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 00:58:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2659, -0.3389, -0.5483,  ...,  0.3147, -0.0698, -0.0542],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9844, -5.6719,  0.6372,  ..., -2.1426,  1.3652,  1.9873],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0240, -0.0017, -0.0054,  ...,  0.0133, -0.0127, -0.0048],
        [ 0.0025,  0.0247, -0.0034,  ...,  0.0157, -0.0042, -0.0051],
        [ 0.0141, -0.0029,  0.0157,  ...,  0.0128,  0.0076, -0.0040],
        ...,
        [ 0.0082,  0.0115,  0.0142,  ...,  0.0316, -0.0059, -0.0056],
        [-0.0053,  0.0035, -0.0068,  ...,  0.0069,  0.0157,  0.0023],
        [ 0.0061, -0.0014,  0.0065,  ...,  0.0128,  0.0032,  0.0240]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8281, -5.7695,  0.6489,  ..., -2.2520,  1.2480,  1.8223]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 00:58:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A icicle is made up of ice
A candy is made up of sugar
A beard is made up of hair
A wine is made up of grapes
A doorknob is made up of metal
A water is made up of oxygen
A lawn is made up of grass
A bottle is made up of
2024-07-27 00:58:02 root INFO     [order_1_approx] starting weight calculation for A bottle is made up of glass
A candy is made up of sugar
A doorknob is made up of metal
A wine is made up of grapes
A lawn is made up of grass
A icicle is made up of ice
A beard is made up of hair
A water is made up of
2024-07-27 00:58:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 01:00:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0072, -0.1608, -0.3599,  ...,  0.0331, -0.0544, -0.1602],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1699, -3.8398,  1.5127,  ..., -3.9355,  2.0781,  0.6006],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0389,  0.0110, -0.0173,  ..., -0.0140, -0.0066, -0.0088],
        [-0.0139,  0.0394,  0.0138,  ...,  0.0062,  0.0052, -0.0034],
        [ 0.0130,  0.0115,  0.0124,  ...,  0.0013,  0.0077, -0.0036],
        ...,
        [-0.0027,  0.0059,  0.0156,  ...,  0.0300, -0.0063,  0.0020],
        [-0.0087,  0.0028, -0.0102,  ...,  0.0209,  0.0243,  0.0142],
        [ 0.0098, -0.0051,  0.0147,  ..., -0.0089,  0.0023,  0.0270]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1273, -4.0820,  1.6963,  ..., -4.0977,  2.0957,  0.5669]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 01:00:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A bottle is made up of glass
A candy is made up of sugar
A doorknob is made up of metal
A wine is made up of grapes
A lawn is made up of grass
A icicle is made up of ice
A beard is made up of hair
A water is made up of
2024-07-27 01:00:24 root INFO     total operator prediction time: 1128.0367624759674 seconds
2024-07-27 01:00:24 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hypernyms - misc
2024-07-27 01:00:24 root INFO     building operator hypernyms - misc
2024-07-27 01:00:24 root INFO     [order_1_approx] starting weight calculation for The toaster falls into the category of appliance
The photo falls into the category of picture
The jeans falls into the category of trousers
The lemon falls into the category of citrus
The desk falls into the category of furniture
The dishwasher falls into the category of appliance
The toothbrush falls into the category of brush
The blender falls into the category of
2024-07-27 01:00:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 01:02:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0347, -0.1879,  0.2167,  ...,  0.7031, -0.0876, -0.4250],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9263, -3.3535, -1.0938,  ..., -2.5293, -3.4219, -0.5000],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0677, -0.0029, -0.0290,  ..., -0.0098, -0.0129,  0.0058],
        [ 0.0283,  0.0848,  0.0186,  ..., -0.0142, -0.0011,  0.0048],
        [-0.0053,  0.0026,  0.0682,  ..., -0.0079, -0.0095,  0.0041],
        ...,
        [-0.0038,  0.0133,  0.0165,  ...,  0.0804,  0.0194,  0.0115],
        [-0.0107, -0.0075,  0.0009,  ...,  0.0282,  0.0714, -0.0421],
        [ 0.0027,  0.0022,  0.0149,  ..., -0.0074,  0.0072,  0.0571]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8096, -3.4141, -1.4180,  ..., -2.5840, -3.2383, -0.3811]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 01:02:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The toaster falls into the category of appliance
The photo falls into the category of picture
The jeans falls into the category of trousers
The lemon falls into the category of citrus
The desk falls into the category of furniture
The dishwasher falls into the category of appliance
The toothbrush falls into the category of brush
The blender falls into the category of
2024-07-27 01:02:40 root INFO     [order_1_approx] starting weight calculation for The desk falls into the category of furniture
The blender falls into the category of appliance
The photo falls into the category of picture
The jeans falls into the category of trousers
The dishwasher falls into the category of appliance
The toothbrush falls into the category of brush
The toaster falls into the category of appliance
The lemon falls into the category of
2024-07-27 01:02:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 01:04:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4717, -0.2961, -0.4185,  ...,  0.0355,  0.1515, -0.3083],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0430, -4.8047, -0.9688,  ..., -4.7695, -2.4277, -1.6006],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0452, -0.0057, -0.0144,  ...,  0.0411,  0.0015,  0.0086],
        [ 0.0125,  0.0374,  0.0079,  ..., -0.0058, -0.0051,  0.0192],
        [-0.0048, -0.0073,  0.0424,  ...,  0.0047, -0.0073, -0.0004],
        ...,
        [ 0.0063,  0.0149,  0.0023,  ...,  0.0404,  0.0014, -0.0073],
        [ 0.0146, -0.0159, -0.0061,  ...,  0.0096,  0.0320, -0.0115],
        [-0.0056,  0.0019,  0.0037,  ..., -0.0247, -0.0153,  0.0537]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8379, -4.9570, -1.2832,  ..., -4.5703, -2.2090, -1.5254]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 01:04:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The desk falls into the category of furniture
The blender falls into the category of appliance
The photo falls into the category of picture
The jeans falls into the category of trousers
The dishwasher falls into the category of appliance
The toothbrush falls into the category of brush
The toaster falls into the category of appliance
The lemon falls into the category of
2024-07-27 01:04:58 root INFO     [order_1_approx] starting weight calculation for The toaster falls into the category of appliance
The lemon falls into the category of citrus
The dishwasher falls into the category of appliance
The toothbrush falls into the category of brush
The blender falls into the category of appliance
The jeans falls into the category of trousers
The photo falls into the category of picture
The desk falls into the category of
2024-07-27 01:04:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 01:07:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0989, -0.2732, -0.1611,  ...,  0.1868, -0.3896, -0.3394],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1240, -5.0703,  3.6719,  ..., -2.4551, -2.4824, -0.8135],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0331,  0.0052, -0.0130,  ...,  0.0123,  0.0047,  0.0079],
        [ 0.0110,  0.0278,  0.0161,  ..., -0.0099,  0.0212, -0.0118],
        [-0.0117, -0.0089,  0.0330,  ..., -0.0013, -0.0103,  0.0102],
        ...,
        [ 0.0114,  0.0011,  0.0334,  ...,  0.0478,  0.0004, -0.0230],
        [ 0.0092,  0.0111, -0.0055,  ...,  0.0137,  0.0406, -0.0028],
        [ 0.0034, -0.0042,  0.0086,  ..., -0.0152, -0.0118,  0.0222]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2090, -5.1328,  3.3867,  ..., -2.2305, -2.5488, -0.6611]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 01:07:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The toaster falls into the category of appliance
The lemon falls into the category of citrus
The dishwasher falls into the category of appliance
The toothbrush falls into the category of brush
The blender falls into the category of appliance
The jeans falls into the category of trousers
The photo falls into the category of picture
The desk falls into the category of
2024-07-27 01:07:19 root INFO     [order_1_approx] starting weight calculation for The toaster falls into the category of appliance
The blender falls into the category of appliance
The dishwasher falls into the category of appliance
The desk falls into the category of furniture
The toothbrush falls into the category of brush
The photo falls into the category of picture
The lemon falls into the category of citrus
The jeans falls into the category of
2024-07-27 01:07:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 01:09:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3735,  0.0142, -0.2852,  ...,  0.6841, -0.2224, -0.2761],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.5938, -8.1328, -0.4324,  ...,  0.1489, -3.2578,  0.4150],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0457,  0.0068,  0.0003,  ...,  0.0167,  0.0023,  0.0083],
        [ 0.0169,  0.0396,  0.0120,  ..., -0.0069, -0.0017,  0.0017],
        [-0.0117, -0.0131,  0.0333,  ..., -0.0018, -0.0039,  0.0063],
        ...,
        [ 0.0122,  0.0018,  0.0107,  ...,  0.0529, -0.0006, -0.0003],
        [ 0.0043,  0.0016,  0.0037,  ...,  0.0105,  0.0285, -0.0208],
        [ 0.0155, -0.0082,  0.0142,  ..., -0.0054, -0.0071,  0.0411]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.1445, -8.2109, -0.6777,  ...,  0.3430, -3.0879,  0.6748]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 01:09:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The toaster falls into the category of appliance
The blender falls into the category of appliance
The dishwasher falls into the category of appliance
The desk falls into the category of furniture
The toothbrush falls into the category of brush
The photo falls into the category of picture
The lemon falls into the category of citrus
The jeans falls into the category of
2024-07-27 01:09:39 root INFO     [order_1_approx] starting weight calculation for The jeans falls into the category of trousers
The lemon falls into the category of citrus
The toothbrush falls into the category of brush
The blender falls into the category of appliance
The dishwasher falls into the category of appliance
The toaster falls into the category of appliance
The desk falls into the category of furniture
The photo falls into the category of
2024-07-27 01:09:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 01:11:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4094, -0.3298,  0.2192,  ...,  0.1020,  0.0170, -0.0149],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1367, -4.2812,  0.2163,  ..., -1.6777, -0.5127, -0.0215],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0586,  0.0011, -0.0035,  ..., -0.0067,  0.0044,  0.0030],
        [-0.0174,  0.0237, -0.0120,  ...,  0.0189, -0.0091,  0.0290],
        [ 0.0100,  0.0035,  0.0356,  ...,  0.0159,  0.0070,  0.0073],
        ...,
        [ 0.0041,  0.0016,  0.0110,  ...,  0.0486, -0.0106,  0.0036],
        [-0.0131,  0.0092, -0.0053,  ...,  0.0161,  0.0486,  0.0153],
        [-0.0012,  0.0056, -0.0027,  ..., -0.0021, -0.0096,  0.0356]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3262, -4.6875,  0.4729,  ..., -1.6211, -0.4695, -0.4353]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 01:11:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The jeans falls into the category of trousers
The lemon falls into the category of citrus
The toothbrush falls into the category of brush
The blender falls into the category of appliance
The dishwasher falls into the category of appliance
The toaster falls into the category of appliance
The desk falls into the category of furniture
The photo falls into the category of
2024-07-27 01:11:58 root INFO     [order_1_approx] starting weight calculation for The lemon falls into the category of citrus
The blender falls into the category of appliance
The desk falls into the category of furniture
The jeans falls into the category of trousers
The toaster falls into the category of appliance
The toothbrush falls into the category of brush
The photo falls into the category of picture
The dishwasher falls into the category of
2024-07-27 01:11:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 01:14:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2708, -0.2296, -0.3616,  ...,  0.1004, -0.4963, -0.5977],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9609, -2.4902,  1.0137,  ..., -1.0293, -3.0449,  0.4531],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0231,  0.0045,  0.0004,  ..., -0.0014, -0.0110,  0.0103],
        [ 0.0157,  0.0279,  0.0175,  ...,  0.0129,  0.0070, -0.0047],
        [ 0.0012,  0.0020,  0.0284,  ...,  0.0016, -0.0159,  0.0075],
        ...,
        [ 0.0073,  0.0145, -0.0006,  ...,  0.0354,  0.0027,  0.0053],
        [ 0.0001,  0.0017,  0.0025,  ...,  0.0058,  0.0312, -0.0184],
        [ 0.0093, -0.0089,  0.0061,  ..., -0.0004,  0.0002,  0.0206]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6904, -2.1484,  0.9341,  ..., -1.0264, -2.9512,  0.6963]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 01:14:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The lemon falls into the category of citrus
The blender falls into the category of appliance
The desk falls into the category of furniture
The jeans falls into the category of trousers
The toaster falls into the category of appliance
The toothbrush falls into the category of brush
The photo falls into the category of picture
The dishwasher falls into the category of
2024-07-27 01:14:17 root INFO     [order_1_approx] starting weight calculation for The dishwasher falls into the category of appliance
The photo falls into the category of picture
The lemon falls into the category of citrus
The jeans falls into the category of trousers
The blender falls into the category of appliance
The toothbrush falls into the category of brush
The desk falls into the category of furniture
The toaster falls into the category of
2024-07-27 01:14:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 01:16:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.5225,  0.1298,  0.0403,  ...,  0.0167, -0.1714, -0.0623],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0234, -1.7256, -0.3350,  ..., -1.3125, -2.9688,  2.8906],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0876, -0.0143, -0.0118,  ..., -0.0068, -0.0372,  0.0065],
        [ 0.0379,  0.1024,  0.0281,  ...,  0.0084, -0.0040,  0.0035],
        [ 0.0024, -0.0184,  0.0515,  ..., -0.0206, -0.0337, -0.0023],
        ...,
        [ 0.0189,  0.0350,  0.0100,  ...,  0.0917, -0.0028,  0.0023],
        [-0.0166, -0.0081,  0.0184,  ...,  0.0133,  0.0852, -0.0230],
        [ 0.0140,  0.0010, -0.0122,  ..., -0.0111, -0.0163,  0.0823]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2754, -1.7871, -0.4775,  ..., -1.7842, -2.4688,  2.7168]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 01:16:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The dishwasher falls into the category of appliance
The photo falls into the category of picture
The lemon falls into the category of citrus
The jeans falls into the category of trousers
The blender falls into the category of appliance
The toothbrush falls into the category of brush
The desk falls into the category of furniture
The toaster falls into the category of
2024-07-27 01:16:37 root INFO     [order_1_approx] starting weight calculation for The dishwasher falls into the category of appliance
The toaster falls into the category of appliance
The desk falls into the category of furniture
The photo falls into the category of picture
The blender falls into the category of appliance
The jeans falls into the category of trousers
The lemon falls into the category of citrus
The toothbrush falls into the category of
2024-07-27 01:16:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 01:18:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1217, -0.2172, -0.0701,  ..., -0.0010, -0.4517, -0.2808],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2539, -2.8848, -1.6191,  ..., -3.2207, -3.5742,  1.2129],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.2480e-02, -1.3031e-02,  1.0900e-03,  ...,  8.2550e-03,
         -8.7509e-03,  1.3489e-02],
        [ 1.0513e-02,  2.5818e-02,  7.0190e-03,  ...,  4.7302e-03,
         -6.0959e-03,  1.6689e-03],
        [-9.5978e-03,  4.5013e-03,  2.8152e-02,  ...,  4.4861e-03,
         -8.2703e-03,  2.7504e-03],
        ...,
        [ 1.3412e-02, -5.0697e-03,  6.7329e-04,  ...,  2.8336e-02,
          6.2065e-03, -8.9417e-03],
        [ 5.5809e-03, -5.4550e-03,  6.9885e-03,  ...,  5.3215e-04,
          2.8076e-02, -7.2784e-03],
        [ 5.3673e-03,  6.2103e-03, -5.2719e-03,  ...,  1.9073e-05,
         -9.6588e-03,  2.6245e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1230, -3.1895, -1.5381,  ..., -2.9922, -3.7812,  0.9277]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 01:18:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The dishwasher falls into the category of appliance
The toaster falls into the category of appliance
The desk falls into the category of furniture
The photo falls into the category of picture
The blender falls into the category of appliance
The jeans falls into the category of trousers
The lemon falls into the category of citrus
The toothbrush falls into the category of
2024-07-27 01:18:55 root INFO     total operator prediction time: 1111.3380830287933 seconds
2024-07-27 01:18:55 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on synonyms - exact
2024-07-27 01:18:55 root INFO     building operator synonyms - exact
2024-07-27 01:18:55 root INFO     [order_1_approx] starting weight calculation for Another word for spouse is partner
Another word for murder is slaying
Another word for loyal is faithful
Another word for sofa is couch
Another word for villain is scoundrel
Another word for dollars is bucks
Another word for new is modern
Another word for airplane is
2024-07-27 01:18:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 01:21:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3914, -0.2820, -0.0618,  ...,  0.0855, -0.2864, -0.0944],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2114, -3.2871,  3.1621,  ..., -1.2959, -2.1523,  1.2578],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0854, -0.0092,  0.0199,  ...,  0.0211,  0.0122,  0.0168],
        [ 0.0331,  0.0611, -0.0142,  ...,  0.0358,  0.0106, -0.0306],
        [-0.0132,  0.0068,  0.0885,  ...,  0.0033, -0.0157,  0.0191],
        ...,
        [ 0.0174,  0.0257, -0.0198,  ...,  0.0633,  0.0163, -0.0119],
        [-0.0327,  0.0011, -0.0125,  ...,  0.0213,  0.0470,  0.0123],
        [-0.0060,  0.0166, -0.0084,  ..., -0.0244,  0.0043,  0.0460]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5791, -3.0410,  2.7227,  ..., -1.3164, -2.1680,  1.2725]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 01:21:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for spouse is partner
Another word for murder is slaying
Another word for loyal is faithful
Another word for sofa is couch
Another word for villain is scoundrel
Another word for dollars is bucks
Another word for new is modern
Another word for airplane is
2024-07-27 01:21:18 root INFO     [order_1_approx] starting weight calculation for Another word for new is modern
Another word for loyal is faithful
Another word for sofa is couch
Another word for dollars is bucks
Another word for villain is scoundrel
Another word for murder is slaying
Another word for airplane is aeroplane
Another word for spouse is
2024-07-27 01:21:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 01:23:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0574,  0.4519,  0.0601,  ...,  0.0875, -0.0946, -0.1310],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.9570, -1.6699,  1.6191,  ...,  0.9946, -0.6455,  2.0039],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0679, -0.0144,  0.0356,  ...,  0.0033,  0.0083, -0.0184],
        [-0.0010,  0.0522,  0.0382,  ...,  0.0031,  0.0182,  0.0012],
        [ 0.0092,  0.0040,  0.0936,  ..., -0.0219, -0.0108, -0.0170],
        ...,
        [ 0.0069,  0.0202, -0.0028,  ...,  0.0656, -0.0073,  0.0158],
        [-0.0401,  0.0326,  0.0041,  ...,  0.0240,  0.0376, -0.0120],
        [-0.0169, -0.0023, -0.0114,  ..., -0.0313, -0.0029,  0.0808]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.9404, -1.4336,  1.2324,  ...,  1.5156, -0.8096,  1.5693]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 01:23:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for new is modern
Another word for loyal is faithful
Another word for sofa is couch
Another word for dollars is bucks
Another word for villain is scoundrel
Another word for murder is slaying
Another word for airplane is aeroplane
Another word for spouse is
2024-07-27 01:23:36 root INFO     [order_1_approx] starting weight calculation for Another word for dollars is bucks
Another word for spouse is partner
Another word for airplane is aeroplane
Another word for murder is slaying
Another word for new is modern
Another word for sofa is couch
Another word for villain is scoundrel
Another word for loyal is
2024-07-27 01:23:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 01:25:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2761, -0.0760, -0.0815,  ..., -0.4731,  0.6006,  0.3967],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1406, -5.2812,  0.0566,  ..., -1.4932, -7.0859, -0.8594],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0715, -0.0092,  0.0196,  ..., -0.0026,  0.0043, -0.0081],
        [ 0.0353,  0.0896, -0.0154,  ...,  0.0105, -0.0079, -0.0314],
        [-0.0087, -0.0033,  0.0890,  ..., -0.0097, -0.0055, -0.0231],
        ...,
        [-0.0024,  0.0051,  0.0064,  ...,  0.0837,  0.0203,  0.0010],
        [ 0.0225,  0.0026, -0.0041,  ...,  0.0020,  0.0474, -0.0248],
        [ 0.0087, -0.0264, -0.0009,  ..., -0.0260, -0.0254,  0.0720]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9971, -4.7734,  0.2178,  ..., -1.3447, -6.6797, -1.2812]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 01:25:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for dollars is bucks
Another word for spouse is partner
Another word for airplane is aeroplane
Another word for murder is slaying
Another word for new is modern
Another word for sofa is couch
Another word for villain is scoundrel
Another word for loyal is
2024-07-27 01:25:57 root INFO     [order_1_approx] starting weight calculation for Another word for villain is scoundrel
Another word for dollars is bucks
Another word for airplane is aeroplane
Another word for loyal is faithful
Another word for murder is slaying
Another word for sofa is couch
Another word for spouse is partner
Another word for new is
2024-07-27 01:25:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 01:28:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0316, -0.0576, -0.2822,  ...,  0.0593,  0.1740,  0.0464],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0879, -2.8105,  0.1348,  ...,  3.0566, -4.2422, -0.2744],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0666, -0.0128, -0.0139,  ...,  0.0134,  0.0038,  0.0054],
        [-0.0221,  0.0519,  0.0101,  ...,  0.0276,  0.0150, -0.0106],
        [ 0.0198,  0.0165,  0.0532,  ...,  0.0055,  0.0146, -0.0231],
        ...,
        [-0.0273,  0.0004, -0.0042,  ...,  0.0500, -0.0171,  0.0112],
        [ 0.0065, -0.0082, -0.0126,  ..., -0.0026,  0.0467, -0.0044],
        [-0.0186, -0.0247,  0.0060,  ..., -0.0072, -0.0162,  0.0374]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7432, -2.3594,  0.4705,  ...,  2.7539, -3.7617, -0.3132]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 01:28:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for villain is scoundrel
Another word for dollars is bucks
Another word for airplane is aeroplane
Another word for loyal is faithful
Another word for murder is slaying
Another word for sofa is couch
Another word for spouse is partner
Another word for new is
2024-07-27 01:28:17 root INFO     [order_1_approx] starting weight calculation for Another word for loyal is faithful
Another word for airplane is aeroplane
Another word for villain is scoundrel
Another word for spouse is partner
Another word for new is modern
Another word for sofa is couch
Another word for dollars is bucks
Another word for murder is
2024-07-27 01:28:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 01:30:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0681,  0.3533,  0.4421,  ..., -0.1560, -0.0963, -0.0419],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4648, -5.8828, -1.9600,  ...,  0.2998, -1.4277, -3.8750],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0750, -0.0058,  0.0233,  ...,  0.0148, -0.0102,  0.0244],
        [-0.0108,  0.0692, -0.0028,  ..., -0.0241,  0.0281, -0.0254],
        [-0.0227,  0.0030,  0.0619,  ..., -0.0317,  0.0056, -0.0004],
        ...,
        [ 0.0111, -0.0079,  0.0019,  ...,  0.0482, -0.0057, -0.0033],
        [ 0.0046,  0.0103,  0.0164,  ..., -0.0260,  0.0418, -0.0148],
        [ 0.0342, -0.0082,  0.0056,  ..., -0.0191,  0.0106,  0.0396]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3218, -5.5234, -1.7236,  ..., -0.1089, -1.6123, -3.7695]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 01:30:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for loyal is faithful
Another word for airplane is aeroplane
Another word for villain is scoundrel
Another word for spouse is partner
Another word for new is modern
Another word for sofa is couch
Another word for dollars is bucks
Another word for murder is
2024-07-27 01:30:37 root INFO     [order_1_approx] starting weight calculation for Another word for dollars is bucks
Another word for sofa is couch
Another word for murder is slaying
Another word for new is modern
Another word for airplane is aeroplane
Another word for loyal is faithful
Another word for spouse is partner
Another word for villain is
2024-07-27 01:30:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 01:32:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3850,  0.4487, -0.0676,  ..., -0.1338, -0.1450, -0.2156],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2197, -3.1797,  0.9751,  ..., -0.4932, -2.9531,  0.2935],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.7087e-02,  1.5068e-03,  3.2135e-02,  ..., -8.0776e-04,
          1.0834e-02, -6.1264e-03],
        [ 3.7323e-02,  6.2622e-02,  9.2392e-03,  ...,  9.1629e-03,
          1.7365e-02, -1.6296e-02],
        [-5.7220e-06, -2.2964e-03,  8.4595e-02,  ..., -2.7023e-02,
          5.4626e-03,  8.4686e-03],
        ...,
        [ 8.1100e-03,  4.7188e-03, -2.5024e-02,  ...,  7.5134e-02,
          1.2672e-02, -2.9964e-03],
        [-2.3636e-02, -7.4921e-03,  1.5099e-02,  ...,  1.7334e-02,
          5.0873e-02, -2.3880e-02],
        [ 2.7512e-02, -1.0574e-02, -1.0040e-02,  ..., -1.7609e-02,
         -2.6215e-02,  4.0619e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2532, -3.0352,  0.6240,  ..., -0.1140, -2.8477,  0.1588]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 01:32:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for dollars is bucks
Another word for sofa is couch
Another word for murder is slaying
Another word for new is modern
Another word for airplane is aeroplane
Another word for loyal is faithful
Another word for spouse is partner
Another word for villain is
2024-07-27 01:32:58 root INFO     [order_1_approx] starting weight calculation for Another word for villain is scoundrel
Another word for loyal is faithful
Another word for airplane is aeroplane
Another word for spouse is partner
Another word for murder is slaying
Another word for dollars is bucks
Another word for new is modern
Another word for sofa is
2024-07-27 01:32:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 01:35:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2913, -0.2479,  0.1335,  ...,  0.3311, -0.1519, -0.0308],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.7236, -3.4961,  4.5000,  ..., -1.1309, -2.9512, -2.3281],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1089,  0.0157,  0.0232,  ...,  0.0344, -0.0091, -0.0072],
        [-0.0023,  0.0782, -0.0043,  ...,  0.0013,  0.0206, -0.0016],
        [-0.0270, -0.0175,  0.0978,  ..., -0.0082, -0.0253, -0.0157],
        ...,
        [ 0.0402,  0.0009, -0.0293,  ...,  0.1140, -0.0003, -0.0176],
        [ 0.0188,  0.0021, -0.0132,  ...,  0.0023,  0.0546,  0.0219],
        [-0.0014,  0.0293, -0.0184,  ..., -0.0549,  0.0078,  0.0489]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.0195, -2.9023,  3.9082,  ..., -0.9932, -2.3984, -2.2812]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 01:35:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for villain is scoundrel
Another word for loyal is faithful
Another word for airplane is aeroplane
Another word for spouse is partner
Another word for murder is slaying
Another word for dollars is bucks
Another word for new is modern
Another word for sofa is
2024-07-27 01:35:20 root INFO     [order_1_approx] starting weight calculation for Another word for murder is slaying
Another word for loyal is faithful
Another word for airplane is aeroplane
Another word for spouse is partner
Another word for villain is scoundrel
Another word for new is modern
Another word for sofa is couch
Another word for dollars is
2024-07-27 01:35:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 01:37:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3564, -0.3730, -0.3960,  ..., -0.0882,  0.0289, -0.0437],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7241, -2.0840,  1.5449,  ..., -3.0117,  1.1270, -2.4023],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1155, -0.0113, -0.0215,  ...,  0.0171, -0.0115,  0.0116],
        [-0.0045,  0.0591,  0.0316,  ..., -0.0047,  0.0219, -0.0234],
        [-0.0213,  0.0043,  0.0810,  ..., -0.0026, -0.0060,  0.0224],
        ...,
        [ 0.0016,  0.0016, -0.0282,  ...,  0.0651,  0.0091, -0.0347],
        [-0.0149, -0.0377,  0.0063,  ...,  0.0256,  0.0509,  0.0161],
        [ 0.0064,  0.0118, -0.0099,  ..., -0.0075,  0.0019,  0.0683]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3811, -1.7090,  1.7725,  ..., -2.5488,  1.3525, -2.3340]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 01:37:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for murder is slaying
Another word for loyal is faithful
Another word for airplane is aeroplane
Another word for spouse is partner
Another word for villain is scoundrel
Another word for new is modern
Another word for sofa is couch
Another word for dollars is
2024-07-27 01:37:43 root INFO     total operator prediction time: 1128.1137990951538 seconds
2024-07-27 01:37:43 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - youth
2024-07-27 01:37:43 root INFO     building operator animal - youth
2024-07-27 01:37:44 root INFO     [order_1_approx] starting weight calculation for The offspring of a tiger is referred to as a cub
The offspring of a bear is referred to as a cub
The offspring of a shark is referred to as a cub
The offspring of a monkey is referred to as a infant
The offspring of a weasel is referred to as a kit
The offspring of a skunk is referred to as a kit
The offspring of a panda is referred to as a cub
The offspring of a cricket is referred to as a
2024-07-27 01:37:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 01:40:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0309,  0.0615,  0.1340,  ...,  0.2340, -0.0632, -0.1067],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7793, -3.1211, -0.6602,  ..., -1.0156, -2.3613,  0.1211],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0728, -0.0244, -0.0010,  ...,  0.0214, -0.0073, -0.0235],
        [ 0.0061,  0.0565,  0.0058,  ..., -0.0118,  0.0109, -0.0107],
        [-0.0099,  0.0074,  0.0658,  ...,  0.0019, -0.0186, -0.0209],
        ...,
        [ 0.0134, -0.0250,  0.0070,  ...,  0.0453,  0.0025,  0.0165],
        [ 0.0036, -0.0217,  0.0307,  ...,  0.0503,  0.0350, -0.0070],
        [ 0.0083, -0.0065, -0.0213,  ..., -0.0195,  0.0056,  0.0442]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9443, -3.0176, -0.9639,  ..., -0.8687, -1.9785,  0.0139]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 01:40:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a tiger is referred to as a cub
The offspring of a bear is referred to as a cub
The offspring of a shark is referred to as a cub
The offspring of a monkey is referred to as a infant
The offspring of a weasel is referred to as a kit
The offspring of a skunk is referred to as a kit
The offspring of a panda is referred to as a cub
The offspring of a cricket is referred to as a
2024-07-27 01:40:02 root INFO     [order_1_approx] starting weight calculation for The offspring of a shark is referred to as a cub
The offspring of a skunk is referred to as a kit
The offspring of a cricket is referred to as a larva
The offspring of a monkey is referred to as a infant
The offspring of a panda is referred to as a cub
The offspring of a tiger is referred to as a cub
The offspring of a weasel is referred to as a kit
The offspring of a bear is referred to as a
2024-07-27 01:40:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 01:42:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.8604,  0.0966,  0.0600,  ..., -0.0186, -0.5615,  0.0688],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3164, -4.9844, -1.9590,  ..., -1.0479, -2.7715,  2.2637],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0447, -0.0221, -0.0201,  ...,  0.0115, -0.0051, -0.0175],
        [-0.0021,  0.0534,  0.0101,  ...,  0.0075,  0.0054, -0.0328],
        [-0.0229,  0.0158,  0.0412,  ...,  0.0184,  0.0022, -0.0258],
        ...,
        [ 0.0167,  0.0003, -0.0003,  ...,  0.0395,  0.0199, -0.0076],
        [ 0.0064,  0.0021,  0.0312,  ...,  0.0184,  0.0235,  0.0004],
        [-0.0041, -0.0177, -0.0116,  ..., -0.0243, -0.0190,  0.0338]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6016, -4.9219, -1.7500,  ..., -0.8486, -3.0078,  2.3145]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 01:42:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a shark is referred to as a cub
The offspring of a skunk is referred to as a kit
The offspring of a cricket is referred to as a larva
The offspring of a monkey is referred to as a infant
The offspring of a panda is referred to as a cub
The offspring of a tiger is referred to as a cub
The offspring of a weasel is referred to as a kit
The offspring of a bear is referred to as a
2024-07-27 01:42:22 root INFO     [order_1_approx] starting weight calculation for The offspring of a panda is referred to as a cub
The offspring of a shark is referred to as a cub
The offspring of a cricket is referred to as a larva
The offspring of a weasel is referred to as a kit
The offspring of a monkey is referred to as a infant
The offspring of a bear is referred to as a cub
The offspring of a skunk is referred to as a kit
The offspring of a tiger is referred to as a
2024-07-27 01:42:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 01:44:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2625,  0.2271, -0.1263,  ...,  0.2162, -0.2988, -0.2338],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7969, -5.8086, -2.3496,  ..., -0.6875, -2.0977,  1.2500],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0547, -0.0172, -0.0270,  ...,  0.0133, -0.0164, -0.0139],
        [-0.0025,  0.0410,  0.0115,  ..., -0.0139,  0.0025, -0.0193],
        [-0.0032,  0.0230,  0.0534,  ...,  0.0025,  0.0095, -0.0070],
        ...,
        [ 0.0069, -0.0015,  0.0326,  ...,  0.0497,  0.0206, -0.0094],
        [ 0.0074, -0.0228,  0.0152,  ...,  0.0146,  0.0159,  0.0013],
        [-0.0038, -0.0085, -0.0218,  ..., -0.0352, -0.0123,  0.0335]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0879, -5.3359, -2.3496,  ..., -0.6240, -2.2422,  1.3623]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 01:44:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a panda is referred to as a cub
The offspring of a shark is referred to as a cub
The offspring of a cricket is referred to as a larva
The offspring of a weasel is referred to as a kit
The offspring of a monkey is referred to as a infant
The offspring of a bear is referred to as a cub
The offspring of a skunk is referred to as a kit
The offspring of a tiger is referred to as a
2024-07-27 01:44:43 root INFO     [order_1_approx] starting weight calculation for The offspring of a panda is referred to as a cub
The offspring of a monkey is referred to as a infant
The offspring of a tiger is referred to as a cub
The offspring of a skunk is referred to as a kit
The offspring of a cricket is referred to as a larva
The offspring of a weasel is referred to as a kit
The offspring of a bear is referred to as a cub
The offspring of a shark is referred to as a
2024-07-27 01:44:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 01:47:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6128,  0.3860, -0.4807,  ...,  0.3003, -0.4856, -0.0867],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6880, -3.7109, -2.9141,  ..., -1.7344, -3.8984,  1.1621],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.5481e-02, -9.3842e-03, -5.4092e-03,  ...,  1.3390e-02,
          7.0572e-05, -1.5366e-02],
        [-9.8114e-03,  6.8298e-02,  5.6610e-03,  ..., -9.8572e-03,
         -3.9215e-03, -8.3160e-03],
        [ 1.5900e-02,  1.3008e-02,  4.5990e-02,  ...,  5.8899e-03,
         -4.0741e-03, -2.9404e-02],
        ...,
        [-1.3382e-02,  1.1780e-02,  1.0254e-02,  ...,  3.9093e-02,
          4.9667e-03, -2.0733e-03],
        [ 3.4752e-03,  2.2068e-03,  1.9852e-02,  ...,  1.8051e-02,
          7.4577e-04, -8.9569e-03],
        [ 2.5444e-03, -1.8951e-02, -4.3411e-03,  ..., -1.6266e-02,
         -9.5367e-03,  3.4882e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7266, -3.5938, -3.2715,  ..., -1.9346, -4.0195,  0.9795]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 01:47:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a panda is referred to as a cub
The offspring of a monkey is referred to as a infant
The offspring of a tiger is referred to as a cub
The offspring of a skunk is referred to as a kit
The offspring of a cricket is referred to as a larva
The offspring of a weasel is referred to as a kit
The offspring of a bear is referred to as a cub
The offspring of a shark is referred to as a
2024-07-27 01:47:01 root INFO     [order_1_approx] starting weight calculation for The offspring of a monkey is referred to as a infant
The offspring of a tiger is referred to as a cub
The offspring of a shark is referred to as a cub
The offspring of a cricket is referred to as a larva
The offspring of a bear is referred to as a cub
The offspring of a skunk is referred to as a kit
The offspring of a panda is referred to as a cub
The offspring of a weasel is referred to as a
2024-07-27 01:47:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 01:49:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1864,  0.0179,  0.1494,  ..., -0.0360, -0.6206, -0.4363],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8750, -3.2441, -0.9175,  ...,  0.0186, -2.2109,  1.4619],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.1042e-02,  4.0627e-03, -3.8490e-03,  ..., -6.3705e-04,
          8.4305e-04,  3.9940e-03],
        [ 1.3542e-03,  2.0111e-02,  5.6419e-03,  ..., -8.4686e-03,
          8.4457e-03, -5.5885e-03],
        [-1.1673e-03, -1.4915e-03,  1.7273e-02,  ...,  2.3727e-03,
         -8.2321e-03, -1.1665e-02],
        ...,
        [ 3.9787e-03, -1.0610e-04,  6.6223e-03,  ...,  1.4130e-02,
          1.3794e-02, -1.2810e-02],
        [-6.1989e-05, -2.1973e-03,  6.8932e-03,  ...,  1.3824e-02,
          2.1038e-03, -4.5815e-03],
        [-2.6321e-03, -6.3972e-03, -1.9665e-03,  ..., -4.1351e-03,
         -9.6817e-03,  8.4763e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9551, -3.4336, -0.9595,  ...,  0.0245, -2.2422,  1.4189]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 01:49:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a monkey is referred to as a infant
The offspring of a tiger is referred to as a cub
The offspring of a shark is referred to as a cub
The offspring of a cricket is referred to as a larva
The offspring of a bear is referred to as a cub
The offspring of a skunk is referred to as a kit
The offspring of a panda is referred to as a cub
The offspring of a weasel is referred to as a
2024-07-27 01:49:20 root INFO     [order_1_approx] starting weight calculation for The offspring of a monkey is referred to as a infant
The offspring of a tiger is referred to as a cub
The offspring of a cricket is referred to as a larva
The offspring of a weasel is referred to as a kit
The offspring of a shark is referred to as a cub
The offspring of a skunk is referred to as a kit
The offspring of a bear is referred to as a cub
The offspring of a panda is referred to as a
2024-07-27 01:49:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 01:51:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2173, -0.1698, -0.1984,  ...,  0.2479, -0.5664,  0.5107],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0020, -4.9297, -0.6934,  ..., -2.2539, -3.8047,  3.0977],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0689, -0.0160, -0.0148,  ...,  0.0215, -0.0049, -0.0146],
        [-0.0019,  0.0559,  0.0073,  ...,  0.0086, -0.0060, -0.0502],
        [-0.0212,  0.0135,  0.0669,  ...,  0.0115, -0.0072, -0.0220],
        ...,
        [ 0.0121, -0.0195, -0.0099,  ...,  0.0767,  0.0095, -0.0094],
        [ 0.0273, -0.0143,  0.0158,  ...,  0.0009,  0.0362,  0.0029],
        [-0.0127, -0.0265, -0.0242,  ..., -0.0334,  0.0160,  0.0233]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0488, -4.5469, -0.5376,  ..., -1.9863, -3.9004,  2.8438]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 01:51:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a monkey is referred to as a infant
The offspring of a tiger is referred to as a cub
The offspring of a cricket is referred to as a larva
The offspring of a weasel is referred to as a kit
The offspring of a shark is referred to as a cub
The offspring of a skunk is referred to as a kit
The offspring of a bear is referred to as a cub
The offspring of a panda is referred to as a
2024-07-27 01:51:41 root INFO     [order_1_approx] starting weight calculation for The offspring of a skunk is referred to as a kit
The offspring of a bear is referred to as a cub
The offspring of a panda is referred to as a cub
The offspring of a cricket is referred to as a larva
The offspring of a tiger is referred to as a cub
The offspring of a shark is referred to as a cub
The offspring of a weasel is referred to as a kit
The offspring of a monkey is referred to as a
2024-07-27 01:51:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 01:54:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4783, -0.1133,  0.0287,  ...,  0.1545, -0.6870,  0.1172],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5176, -4.0234, -1.4258,  ..., -1.7227, -4.5195,  3.3125],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0502, -0.0166, -0.0147,  ...,  0.0164,  0.0067, -0.0125],
        [-0.0139,  0.0667,  0.0053,  ..., -0.0076,  0.0059, -0.0221],
        [ 0.0028,  0.0154,  0.0410,  ...,  0.0117, -0.0122, -0.0002],
        ...,
        [ 0.0082, -0.0003, -0.0024,  ...,  0.0376,  0.0129, -0.0090],
        [ 0.0128, -0.0009,  0.0199,  ...,  0.0009, -0.0005,  0.0060],
        [-0.0139, -0.0176, -0.0074,  ..., -0.0249,  0.0054,  0.0196]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7871, -4.0273, -1.8252,  ..., -1.4482, -4.7656,  3.5391]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 01:54:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a skunk is referred to as a kit
The offspring of a bear is referred to as a cub
The offspring of a panda is referred to as a cub
The offspring of a cricket is referred to as a larva
The offspring of a tiger is referred to as a cub
The offspring of a shark is referred to as a cub
The offspring of a weasel is referred to as a kit
The offspring of a monkey is referred to as a
2024-07-27 01:54:02 root INFO     [order_1_approx] starting weight calculation for The offspring of a weasel is referred to as a kit
The offspring of a cricket is referred to as a larva
The offspring of a shark is referred to as a cub
The offspring of a tiger is referred to as a cub
The offspring of a panda is referred to as a cub
The offspring of a monkey is referred to as a infant
The offspring of a bear is referred to as a cub
The offspring of a skunk is referred to as a
2024-07-27 01:54:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 01:56:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0193,  0.0776,  0.1736,  ...,  0.2605, -0.5698, -0.0062],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8984, -2.6250, -1.8359,  ..., -0.0625, -3.9766,  1.4199],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0636, -0.0304, -0.0350,  ...,  0.0264,  0.0002, -0.0089],
        [-0.0039,  0.0635,  0.0074,  ...,  0.0058, -0.0078,  0.0094],
        [ 0.0002, -0.0089,  0.0604,  ...,  0.0429, -0.0249,  0.0026],
        ...,
        [ 0.0106,  0.0068,  0.0243,  ...,  0.0560,  0.0239, -0.0018],
        [ 0.0125, -0.0183,  0.0212,  ...,  0.0064,  0.0077, -0.0114],
        [-0.0023,  0.0186,  0.0049,  ..., -0.0228, -0.0019,  0.0494]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1992, -2.6621, -2.2109,  ..., -0.0940, -3.9824,  1.1611]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 01:56:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a weasel is referred to as a kit
The offspring of a cricket is referred to as a larva
The offspring of a shark is referred to as a cub
The offspring of a tiger is referred to as a cub
The offspring of a panda is referred to as a cub
The offspring of a monkey is referred to as a infant
The offspring of a bear is referred to as a cub
The offspring of a skunk is referred to as a
2024-07-27 01:56:20 root INFO     total operator prediction time: 1116.9251363277435 seconds
2024-07-27 01:56:20 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - sound
2024-07-27 01:56:20 root INFO     building operator animal - sound
2024-07-27 01:56:21 root INFO     [order_1_approx] starting weight calculation for The sound that a seal makes is called a bark
The sound that a pig makes is called a oink
The sound that a frog makes is called a ribbit
The sound that a rat makes is called a squeak
The sound that a chicken makes is called a cluck
The sound that a tiger makes is called a growl
The sound that a chimpanzee makes is called a scream
The sound that a mallard makes is called a
2024-07-27 01:56:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 01:58:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0985,  0.2263, -0.2090,  ...,  0.3298, -0.5156, -0.0027],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1245, -5.8164,  1.8037,  ...,  0.0654, -4.6367,  1.0215],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0238, -0.0025, -0.0028,  ...,  0.0030, -0.0167,  0.0060],
        [ 0.0075,  0.0300,  0.0249,  ...,  0.0264,  0.0055, -0.0146],
        [ 0.0021,  0.0145,  0.0302,  ..., -0.0044, -0.0435,  0.0074],
        ...,
        [-0.0038, -0.0002,  0.0103,  ...,  0.0553,  0.0014, -0.0059],
        [ 0.0012,  0.0241,  0.0037,  ...,  0.0061,  0.0566, -0.0100],
        [-0.0013, -0.0190, -0.0092,  ..., -0.0219, -0.0117,  0.0228]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0542, -5.5742,  1.5371,  ..., -0.1198, -4.7812,  0.9072]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 01:58:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a seal makes is called a bark
The sound that a pig makes is called a oink
The sound that a frog makes is called a ribbit
The sound that a rat makes is called a squeak
The sound that a chicken makes is called a cluck
The sound that a tiger makes is called a growl
The sound that a chimpanzee makes is called a scream
The sound that a mallard makes is called a
2024-07-27 01:58:41 root INFO     [order_1_approx] starting weight calculation for The sound that a seal makes is called a bark
The sound that a frog makes is called a ribbit
The sound that a rat makes is called a squeak
The sound that a tiger makes is called a growl
The sound that a chimpanzee makes is called a scream
The sound that a pig makes is called a oink
The sound that a mallard makes is called a quack
The sound that a chicken makes is called a
2024-07-27 01:58:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 02:01:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2175,  0.2705,  0.2096,  ..., -0.0345, -0.0254,  0.0796],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5879, -5.1328,  3.3242,  ...,  0.4136,  0.6260,  0.9277],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0388, -0.0193, -0.0061,  ..., -0.0047, -0.0138,  0.0056],
        [-0.0086,  0.0480,  0.0018,  ...,  0.0041,  0.0191, -0.0155],
        [-0.0040,  0.0040,  0.0331,  ..., -0.0098, -0.0096, -0.0046],
        ...,
        [ 0.0154,  0.0059,  0.0045,  ...,  0.0385,  0.0029,  0.0041],
        [-0.0048,  0.0019, -0.0162,  ...,  0.0118,  0.0352,  0.0035],
        [ 0.0091, -0.0157,  0.0034,  ..., -0.0105, -0.0005,  0.0165]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5586, -4.7773,  3.1152,  ..., -0.1201,  0.7832,  1.0059]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 02:01:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a seal makes is called a bark
The sound that a frog makes is called a ribbit
The sound that a rat makes is called a squeak
The sound that a tiger makes is called a growl
The sound that a chimpanzee makes is called a scream
The sound that a pig makes is called a oink
The sound that a mallard makes is called a quack
The sound that a chicken makes is called a
2024-07-27 02:01:02 root INFO     [order_1_approx] starting weight calculation for The sound that a mallard makes is called a quack
The sound that a chicken makes is called a cluck
The sound that a tiger makes is called a growl
The sound that a pig makes is called a oink
The sound that a chimpanzee makes is called a scream
The sound that a frog makes is called a ribbit
The sound that a rat makes is called a squeak
The sound that a seal makes is called a
2024-07-27 02:01:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 02:03:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7764, -0.3022,  0.2986,  ...,  0.2542, -0.5444,  0.1364],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.9844, -0.9204, -0.3389,  ..., -0.8213, -0.2422,  1.8701],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0634, -0.0254, -0.0237,  ..., -0.0168, -0.0202, -0.0177],
        [ 0.0152,  0.0726, -0.0213,  ..., -0.0204, -0.0258, -0.0302],
        [ 0.0305,  0.0179,  0.0589,  ..., -0.0461, -0.0235, -0.0075],
        ...,
        [ 0.0126,  0.0160,  0.0214,  ...,  0.0461,  0.0140, -0.0154],
        [-0.0074, -0.0021,  0.0094,  ...,  0.0180,  0.0484, -0.0283],
        [-0.0143, -0.0177, -0.0226,  ...,  0.0042, -0.0065,  0.0467]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7227, -1.1279, -0.2554,  ..., -0.9634, -0.5088,  1.6943]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 02:03:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a mallard makes is called a quack
The sound that a chicken makes is called a cluck
The sound that a tiger makes is called a growl
The sound that a pig makes is called a oink
The sound that a chimpanzee makes is called a scream
The sound that a frog makes is called a ribbit
The sound that a rat makes is called a squeak
The sound that a seal makes is called a
2024-07-27 02:03:21 root INFO     [order_1_approx] starting weight calculation for The sound that a pig makes is called a oink
The sound that a tiger makes is called a growl
The sound that a chimpanzee makes is called a scream
The sound that a chicken makes is called a cluck
The sound that a rat makes is called a squeak
The sound that a mallard makes is called a quack
The sound that a seal makes is called a bark
The sound that a frog makes is called a
2024-07-27 02:03:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 02:05:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4563,  0.1653,  0.2786,  ..., -0.3381, -0.1714, -0.1995],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8970, -1.6328,  0.4111,  ...,  2.7832, -0.6914,  4.3984],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0607, -0.0171,  0.0176,  ...,  0.0055, -0.0281, -0.0218],
        [ 0.0064,  0.0429, -0.0168,  ..., -0.0280,  0.0110, -0.0277],
        [ 0.0044, -0.0130,  0.0616,  ..., -0.0223,  0.0030, -0.0023],
        ...,
        [ 0.0068,  0.0229,  0.0021,  ...,  0.0386,  0.0040, -0.0212],
        [-0.0060,  0.0133,  0.0022,  ..., -0.0047,  0.0174, -0.0108],
        [ 0.0153,  0.0042, -0.0011,  ..., -0.0259, -0.0103,  0.0460]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8804, -1.8398,  0.6650,  ...,  2.7988, -0.9951,  4.2266]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 02:05:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a pig makes is called a oink
The sound that a tiger makes is called a growl
The sound that a chimpanzee makes is called a scream
The sound that a chicken makes is called a cluck
The sound that a rat makes is called a squeak
The sound that a mallard makes is called a quack
The sound that a seal makes is called a bark
The sound that a frog makes is called a
2024-07-27 02:05:40 root INFO     [order_1_approx] starting weight calculation for The sound that a frog makes is called a ribbit
The sound that a chimpanzee makes is called a scream
The sound that a pig makes is called a oink
The sound that a chicken makes is called a cluck
The sound that a mallard makes is called a quack
The sound that a rat makes is called a squeak
The sound that a seal makes is called a bark
The sound that a tiger makes is called a
2024-07-27 02:05:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 02:08:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0745,  0.4011,  0.0791,  ...,  0.2015, -0.2505, -0.1137],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9492, -5.9219, -0.4734,  ..., -2.6328,  0.5303,  1.2559],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0523, -0.0055,  0.0041,  ...,  0.0006, -0.0350, -0.0153],
        [ 0.0025,  0.0359,  0.0002,  ..., -0.0078,  0.0084, -0.0228],
        [-0.0211,  0.0360,  0.0467,  ..., -0.0182,  0.0129,  0.0107],
        ...,
        [ 0.0104,  0.0119,  0.0166,  ...,  0.0493,  0.0089, -0.0192],
        [ 0.0177, -0.0150, -0.0011,  ..., -0.0250,  0.0312,  0.0234],
        [-0.0055, -0.0055, -0.0351,  ..., -0.0239, -0.0032,  0.0070]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7227, -5.7695, -0.2134,  ..., -2.5723,  0.1943,  0.9526]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 02:08:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a frog makes is called a ribbit
The sound that a chimpanzee makes is called a scream
The sound that a pig makes is called a oink
The sound that a chicken makes is called a cluck
The sound that a mallard makes is called a quack
The sound that a rat makes is called a squeak
The sound that a seal makes is called a bark
The sound that a tiger makes is called a
2024-07-27 02:08:01 root INFO     [order_1_approx] starting weight calculation for The sound that a seal makes is called a bark
The sound that a chicken makes is called a cluck
The sound that a tiger makes is called a growl
The sound that a rat makes is called a squeak
The sound that a mallard makes is called a quack
The sound that a chimpanzee makes is called a scream
The sound that a frog makes is called a ribbit
The sound that a pig makes is called a
2024-07-27 02:08:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 02:10:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0908,  0.0950,  0.1965,  ...,  0.0383, -0.2603,  0.0117],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8848, -2.1758,  3.2617,  ..., -2.0527,  0.4292,  1.9932],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0538, -0.0068, -0.0023,  ..., -0.0155, -0.0141, -0.0324],
        [ 0.0057,  0.0237,  0.0066,  ..., -0.0183,  0.0008, -0.0104],
        [ 0.0150,  0.0031,  0.0696,  ..., -0.0133, -0.0244, -0.0190],
        ...,
        [ 0.0201,  0.0015,  0.0124,  ...,  0.0185, -0.0072, -0.0065],
        [ 0.0042,  0.0198,  0.0081,  ...,  0.0178,  0.0201,  0.0043],
        [ 0.0037, -0.0263,  0.0016,  ..., -0.0261,  0.0176,  0.0233]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9082, -2.2910,  2.9863,  ..., -2.1406,  0.2588,  1.7939]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 02:10:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a seal makes is called a bark
The sound that a chicken makes is called a cluck
The sound that a tiger makes is called a growl
The sound that a rat makes is called a squeak
The sound that a mallard makes is called a quack
The sound that a chimpanzee makes is called a scream
The sound that a frog makes is called a ribbit
The sound that a pig makes is called a
2024-07-27 02:10:20 root INFO     [order_1_approx] starting weight calculation for The sound that a mallard makes is called a quack
The sound that a chicken makes is called a cluck
The sound that a tiger makes is called a growl
The sound that a rat makes is called a squeak
The sound that a frog makes is called a ribbit
The sound that a pig makes is called a oink
The sound that a seal makes is called a bark
The sound that a chimpanzee makes is called a
2024-07-27 02:10:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 02:12:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1036,  0.0220,  0.0168,  ..., -0.1553, -0.3477, -0.1224],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9023, -1.6562,  0.5137,  ..., -0.7471, -2.2090,  0.3525],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0069,  0.0007, -0.0024,  ...,  0.0021, -0.0092, -0.0023],
        [-0.0008,  0.0065,  0.0032,  ...,  0.0046,  0.0043, -0.0079],
        [-0.0044,  0.0020,  0.0088,  ..., -0.0097,  0.0014, -0.0060],
        ...,
        [ 0.0058,  0.0067,  0.0015,  ...,  0.0112, -0.0009, -0.0006],
        [ 0.0047, -0.0038,  0.0006,  ...,  0.0034,  0.0129,  0.0062],
        [-0.0067, -0.0046, -0.0046,  ..., -0.0079,  0.0003,  0.0107]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8418, -1.6650,  0.5107,  ..., -0.7529, -2.2812,  0.2710]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 02:12:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a mallard makes is called a quack
The sound that a chicken makes is called a cluck
The sound that a tiger makes is called a growl
The sound that a rat makes is called a squeak
The sound that a frog makes is called a ribbit
The sound that a pig makes is called a oink
The sound that a seal makes is called a bark
The sound that a chimpanzee makes is called a
2024-07-27 02:12:43 root INFO     [order_1_approx] starting weight calculation for The sound that a mallard makes is called a quack
The sound that a chimpanzee makes is called a scream
The sound that a tiger makes is called a growl
The sound that a seal makes is called a bark
The sound that a pig makes is called a oink
The sound that a chicken makes is called a cluck
The sound that a frog makes is called a ribbit
The sound that a rat makes is called a
2024-07-27 02:12:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 02:15:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0930, -0.1849,  0.1824,  ..., -0.2458, -0.1945, -0.0681],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0176, -1.1738,  0.7500,  ..., -2.3730,  0.3945,  2.4277],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0645, -0.0143,  0.0065,  ..., -0.0148, -0.0318, -0.0183],
        [ 0.0123,  0.0764,  0.0001,  ...,  0.0050,  0.0063, -0.0251],
        [-0.0050,  0.0144,  0.0701,  ..., -0.0155, -0.0154, -0.0217],
        ...,
        [ 0.0082, -0.0123, -0.0011,  ...,  0.0450, -0.0009, -0.0159],
        [ 0.0004, -0.0092,  0.0134,  ..., -0.0060,  0.0267,  0.0087],
        [ 0.0259, -0.0010, -0.0146,  ..., -0.0357, -0.0132,  0.0438]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5664, -1.1729,  0.4556,  ..., -2.5078,  0.3811,  2.4023]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 02:15:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a mallard makes is called a quack
The sound that a chimpanzee makes is called a scream
The sound that a tiger makes is called a growl
The sound that a seal makes is called a bark
The sound that a pig makes is called a oink
The sound that a chicken makes is called a cluck
The sound that a frog makes is called a ribbit
The sound that a rat makes is called a
2024-07-27 02:15:01 root INFO     total operator prediction time: 1120.1952466964722 seconds
2024-07-27 02:15:01 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on things - color
2024-07-27 02:15:01 root INFO     building operator things - color
2024-07-27 02:15:01 root INFO     [order_1_approx] starting weight calculation for The ruby is colored red
The sugar is colored white
The coffee is colored black
The sky is colored blue
The frog is colored green
The cream is colored white
The pepper is colored black
The parsley is colored
2024-07-27 02:15:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 02:17:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2217,  0.0151, -0.6470,  ..., -0.2637, -0.4285, -0.1152],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5479, -5.6250, -2.2383,  ..., -0.5381, -0.2227, -3.1758],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0751,  0.0082,  0.0091,  ...,  0.0047, -0.0067,  0.0260],
        [ 0.0100,  0.0499,  0.0128,  ...,  0.0137,  0.0118, -0.0202],
        [-0.0163, -0.0248,  0.0660,  ..., -0.0017, -0.0121, -0.0002],
        ...,
        [ 0.0098, -0.0135,  0.0135,  ...,  0.0747, -0.0065,  0.0054],
        [ 0.0163,  0.0049, -0.0121,  ...,  0.0114,  0.0679, -0.0080],
        [-0.0042, -0.0018,  0.0057,  ..., -0.0235, -0.0063,  0.0350]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2266, -5.5195, -2.2051,  ..., -0.4280, -0.4985, -2.3066]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 02:17:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The ruby is colored red
The sugar is colored white
The coffee is colored black
The sky is colored blue
The frog is colored green
The cream is colored white
The pepper is colored black
The parsley is colored
2024-07-27 02:17:21 root INFO     [order_1_approx] starting weight calculation for The sky is colored blue
The ruby is colored red
The cream is colored white
The coffee is colored black
The pepper is colored black
The frog is colored green
The parsley is colored green
The sugar is colored
2024-07-27 02:17:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 02:19:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2720, -0.2394, -0.2274,  ...,  0.1324, -0.1600, -0.3550],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8496, -6.1680,  1.1016,  ..., -2.4434, -1.7998, -0.7188],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.7922e-02,  1.1330e-03,  1.1841e-02,  ...,  1.5869e-02,
          2.0027e-03,  6.2227e-05],
        [-2.4414e-03,  9.1003e-02,  2.7649e-02,  ...,  9.9182e-03,
          5.0598e-02, -1.0956e-02],
        [ 1.5442e-02, -6.8703e-03,  5.2429e-02,  ...,  2.4567e-02,
         -2.6505e-02,  1.6129e-02],
        ...,
        [ 1.2878e-02, -3.5461e-02, -1.1234e-03,  ...,  5.3009e-02,
          1.7105e-02, -5.9052e-03],
        [-1.7471e-03,  1.3596e-02, -1.1101e-02,  ...,  2.3407e-02,
          5.6488e-02, -1.6663e-02],
        [-6.6948e-03, -4.2206e-02,  3.9291e-03,  ..., -3.5172e-03,
         -1.6968e-02,  2.5970e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6343, -5.9531,  0.8936,  ..., -2.2871, -1.7705, -0.2830]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 02:19:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sky is colored blue
The ruby is colored red
The cream is colored white
The coffee is colored black
The pepper is colored black
The frog is colored green
The parsley is colored green
The sugar is colored
2024-07-27 02:19:41 root INFO     [order_1_approx] starting weight calculation for The coffee is colored black
The sky is colored blue
The pepper is colored black
The frog is colored green
The ruby is colored red
The parsley is colored green
The sugar is colored white
The cream is colored
2024-07-27 02:19:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 02:22:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2024, -0.3247,  0.2925,  ...,  0.0604, -0.4355,  0.1250],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.1162, -4.7109,  1.6475,  ..., -2.5352, -0.2712, -0.6543],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0587,  0.0069,  0.0123,  ...,  0.0023, -0.0053,  0.0237],
        [ 0.0008,  0.0655,  0.0226,  ...,  0.0079, -0.0112, -0.0169],
        [-0.0008,  0.0007,  0.0547,  ...,  0.0245,  0.0088,  0.0129],
        ...,
        [ 0.0086,  0.0209, -0.0071,  ...,  0.0778, -0.0090, -0.0133],
        [ 0.0204, -0.0013, -0.0104,  ...,  0.0151,  0.0626,  0.0039],
        [-0.0106, -0.0054, -0.0025,  ..., -0.0070, -0.0086,  0.0312]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8896, -4.9336,  1.7607,  ..., -2.6445, -0.6064, -0.5942]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 02:22:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The coffee is colored black
The sky is colored blue
The pepper is colored black
The frog is colored green
The ruby is colored red
The parsley is colored green
The sugar is colored white
The cream is colored
2024-07-27 02:22:03 root INFO     [order_1_approx] starting weight calculation for The coffee is colored black
The cream is colored white
The frog is colored green
The parsley is colored green
The pepper is colored black
The sugar is colored white
The ruby is colored red
The sky is colored
2024-07-27 02:22:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 02:24:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1165, -0.3938, -0.1064,  ...,  0.0255,  0.0063,  0.0158],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.2266, -6.4844,  2.9277,  ..., -1.2822,  0.1770, -1.2188],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0524,  0.0069, -0.0135,  ..., -0.0026,  0.0121, -0.0128],
        [ 0.0015,  0.0500,  0.0078,  ..., -0.0069, -0.0117, -0.0136],
        [ 0.0007, -0.0108,  0.0410,  ...,  0.0170, -0.0163,  0.0220],
        ...,
        [-0.0103,  0.0112,  0.0162,  ...,  0.0525,  0.0103, -0.0165],
        [-0.0041, -0.0231,  0.0042,  ...,  0.0438,  0.0530,  0.0034],
        [-0.0110, -0.0152,  0.0095,  ..., -0.0146, -0.0099,  0.0336]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.4043, -6.3672,  2.8203,  ..., -0.9243,  0.3340, -1.2285]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 02:24:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The coffee is colored black
The cream is colored white
The frog is colored green
The parsley is colored green
The pepper is colored black
The sugar is colored white
The ruby is colored red
The sky is colored
2024-07-27 02:24:24 root INFO     [order_1_approx] starting weight calculation for The frog is colored green
The cream is colored white
The sugar is colored white
The sky is colored blue
The parsley is colored green
The coffee is colored black
The ruby is colored red
The pepper is colored
2024-07-27 02:24:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 02:26:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.5225, -0.0354, -0.1699,  ..., -0.1025, -0.2435, -0.0685],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.2627, -6.3203, -1.5703,  ..., -2.2090, -1.1387, -2.6777],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0956,  0.0199,  0.0078,  ..., -0.0415,  0.0201,  0.0058],
        [ 0.0315,  0.0726,  0.0258,  ..., -0.0022,  0.0206, -0.0084],
        [-0.0352, -0.0301,  0.0738,  ...,  0.0257, -0.0200,  0.0098],
        ...,
        [ 0.0226,  0.0159,  0.0220,  ...,  0.0743, -0.0009, -0.0135],
        [ 0.0297,  0.0110, -0.0279,  ...,  0.0203,  0.0709, -0.0094],
        [ 0.0093,  0.0012, -0.0011,  ..., -0.0150, -0.0048,  0.0221]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.9131, -6.6562, -1.9189,  ..., -2.5508, -1.0947, -2.2891]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 02:26:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The frog is colored green
The cream is colored white
The sugar is colored white
The sky is colored blue
The parsley is colored green
The coffee is colored black
The ruby is colored red
The pepper is colored
2024-07-27 02:26:45 root INFO     [order_1_approx] starting weight calculation for The coffee is colored black
The frog is colored green
The sugar is colored white
The sky is colored blue
The parsley is colored green
The cream is colored white
The pepper is colored black
The ruby is colored
2024-07-27 02:26:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 02:29:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1721, -0.3682, -0.2327,  ..., -0.0480, -0.1294,  0.3030],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.4941, -4.6992, -0.6201,  ..., -2.0879, -0.1816,  0.9487],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.2927e-02, -2.5986e-02,  1.2482e-02,  ..., -1.6739e-02,
          2.2552e-02,  1.2543e-02],
        [ 1.9760e-02,  5.4565e-02,  7.9956e-03,  ...,  2.1011e-02,
         -3.3569e-03, -4.0359e-03],
        [ 1.9257e-02, -1.1261e-02,  4.6478e-02,  ...,  7.6752e-03,
         -6.4697e-03,  8.1253e-03],
        ...,
        [-1.0040e-02, -9.6512e-03,  1.6327e-02,  ...,  6.9641e-02,
          6.3629e-03, -3.0556e-03],
        [ 2.0742e-05, -1.1856e-02, -1.9547e-02,  ...,  5.1544e-02,
          5.4749e-02, -2.3117e-03],
        [-1.0704e-02, -3.1036e-02,  1.3718e-02,  ..., -4.4441e-03,
         -6.6376e-03,  4.0924e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.3125, -4.4688, -0.4932,  ..., -1.8398, -0.0155,  1.3193]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 02:29:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The coffee is colored black
The frog is colored green
The sugar is colored white
The sky is colored blue
The parsley is colored green
The cream is colored white
The pepper is colored black
The ruby is colored
2024-07-27 02:29:06 root INFO     [order_1_approx] starting weight calculation for The sky is colored blue
The frog is colored green
The pepper is colored black
The ruby is colored red
The parsley is colored green
The sugar is colored white
The cream is colored white
The coffee is colored
2024-07-27 02:29:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 02:31:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0073, -0.0477, -0.1470,  ...,  0.1030, -0.3281, -0.1621],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0996, -4.6562, -1.2969,  ..., -2.5254, -0.9380, -2.0195],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.8167e-02,  4.1656e-03,  2.4033e-02,  ..., -1.5076e-02,
         -1.2329e-02,  5.9128e-04],
        [-7.4863e-04,  5.3955e-02,  8.0109e-03,  ...,  1.1505e-02,
          7.4043e-03, -2.8133e-03],
        [ 4.2343e-03,  3.4447e-03,  4.3884e-02,  ...,  2.1393e-02,
         -6.0501e-03,  1.0963e-02],
        ...,
        [ 7.7438e-03,  8.9035e-03, -8.7166e-04,  ...,  5.4352e-02,
         -3.8834e-03, -1.6724e-02],
        [ 1.3451e-02, -2.7580e-03, -2.3895e-02,  ...,  2.4475e-02,
          4.5410e-02,  3.8147e-05],
        [-1.1253e-02, -1.2131e-02,  1.1772e-02,  ..., -1.3092e-02,
         -9.4833e-03,  4.1595e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0972, -4.8203, -1.3584,  ..., -2.5566, -1.0439, -1.8750]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 02:31:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sky is colored blue
The frog is colored green
The pepper is colored black
The ruby is colored red
The parsley is colored green
The sugar is colored white
The cream is colored white
The coffee is colored
2024-07-27 02:31:27 root INFO     [order_1_approx] starting weight calculation for The sky is colored blue
The cream is colored white
The parsley is colored green
The sugar is colored white
The ruby is colored red
The pepper is colored black
The coffee is colored black
The frog is colored
2024-07-27 02:31:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 02:33:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3945, -0.0718,  0.0960,  ..., -0.0922, -0.2722,  0.1882],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8535, -2.5469,  1.0381,  ...,  0.6792, -0.2744,  1.4990],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0825, -0.0100,  0.0112,  ...,  0.0028,  0.0059,  0.0007],
        [-0.0097,  0.0589, -0.0130,  ...,  0.0044,  0.0015, -0.0167],
        [-0.0157,  0.0035,  0.0537,  ..., -0.0016, -0.0137,  0.0281],
        ...,
        [ 0.0046,  0.0105,  0.0034,  ...,  0.1075,  0.0102,  0.0043],
        [ 0.0080, -0.0124, -0.0028,  ...,  0.0395,  0.0317,  0.0082],
        [ 0.0025, -0.0079,  0.0034,  ...,  0.0069, -0.0115,  0.0605]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7817, -2.6660,  0.9482,  ...,  0.6416, -0.7056,  1.3936]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 02:33:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sky is colored blue
The cream is colored white
The parsley is colored green
The sugar is colored white
The ruby is colored red
The pepper is colored black
The coffee is colored black
The frog is colored
2024-07-27 02:33:48 root INFO     total operator prediction time: 1127.4671099185944 seconds
2024-07-27 02:33:48 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on country - capital
2024-07-27 02:33:48 root INFO     building operator country - capital
2024-07-27 02:33:48 root INFO     [order_1_approx] starting weight calculation for The country with tokyo as its capital is known as japan
The country with dublin as its capital is known as ireland
The country with kiev as its capital is known as ukraine
The country with santiago as its capital is known as chile
The country with nairobi as its capital is known as kenya
The country with rome as its capital is known as italy
The country with canberra as its capital is known as australia
The country with taipei as its capital is known as
2024-07-27 02:33:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 02:36:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3940, -0.0983, -0.2012,  ...,  0.3950,  0.1232,  0.3792],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8867, -3.2676,  0.6465,  ..., -0.7295, -1.9941, -1.3320],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0151,  0.0019, -0.0087,  ...,  0.0019, -0.0083, -0.0008],
        [ 0.0025,  0.0179,  0.0110,  ..., -0.0003, -0.0005, -0.0040],
        [ 0.0064,  0.0088,  0.0291,  ...,  0.0186, -0.0019, -0.0119],
        ...,
        [-0.0006, -0.0027,  0.0057,  ...,  0.0293,  0.0101, -0.0088],
        [ 0.0080,  0.0036, -0.0005,  ..., -0.0034,  0.0042,  0.0054],
        [-0.0044, -0.0015, -0.0138,  ..., -0.0056, -0.0023,  0.0079]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5430, -3.2363,  0.1741,  ..., -0.9097, -1.9346, -1.4629]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 02:36:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with tokyo as its capital is known as japan
The country with dublin as its capital is known as ireland
The country with kiev as its capital is known as ukraine
The country with santiago as its capital is known as chile
The country with nairobi as its capital is known as kenya
The country with rome as its capital is known as italy
The country with canberra as its capital is known as australia
The country with taipei as its capital is known as
2024-07-27 02:36:07 root INFO     [order_1_approx] starting weight calculation for The country with santiago as its capital is known as chile
The country with nairobi as its capital is known as kenya
The country with rome as its capital is known as italy
The country with taipei as its capital is known as taiwan
The country with canberra as its capital is known as australia
The country with tokyo as its capital is known as japan
The country with dublin as its capital is known as ireland
The country with kiev as its capital is known as
2024-07-27 02:36:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 02:38:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6382, -0.2666, -0.3201,  ...,  0.4873, -0.0698, -0.1219],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7344, -3.9883, -1.3350,  ...,  0.5073, -0.5605, -3.5078],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0296, -0.0069, -0.0148,  ...,  0.0110, -0.0148,  0.0042],
        [-0.0012,  0.0399,  0.0203,  ...,  0.0127,  0.0097,  0.0022],
        [ 0.0089,  0.0206,  0.0419,  ...,  0.0117, -0.0082, -0.0117],
        ...,
        [-0.0130,  0.0208,  0.0121,  ...,  0.0575,  0.0078, -0.0186],
        [ 0.0107, -0.0030, -0.0003,  ...,  0.0026,  0.0276, -0.0121],
        [-0.0119, -0.0051,  0.0042,  ..., -0.0005, -0.0060,  0.0183]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5566, -3.9199, -1.5537,  ...,  0.7295, -0.6641, -3.2305]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 02:38:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with santiago as its capital is known as chile
The country with nairobi as its capital is known as kenya
The country with rome as its capital is known as italy
The country with taipei as its capital is known as taiwan
The country with canberra as its capital is known as australia
The country with tokyo as its capital is known as japan
The country with dublin as its capital is known as ireland
The country with kiev as its capital is known as
2024-07-27 02:38:26 root INFO     [order_1_approx] starting weight calculation for The country with kiev as its capital is known as ukraine
The country with santiago as its capital is known as chile
The country with dublin as its capital is known as ireland
The country with taipei as its capital is known as taiwan
The country with rome as its capital is known as italy
The country with tokyo as its capital is known as japan
The country with nairobi as its capital is known as kenya
The country with canberra as its capital is known as
2024-07-27 02:38:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 02:40:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2720, -0.1711, -0.5630,  ...,  0.3965,  0.0997, -0.0841],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1562, -3.9551,  2.0332,  ..., -2.0469, -2.2715, -1.8945],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0216, -0.0064, -0.0095,  ...,  0.0144, -0.0096, -0.0007],
        [-0.0029,  0.0215, -0.0004,  ..., -0.0083, -0.0013, -0.0097],
        [-0.0051,  0.0064,  0.0294,  ...,  0.0142,  0.0010, -0.0033],
        ...,
        [-0.0021,  0.0051,  0.0087,  ...,  0.0227,  0.0084, -0.0120],
        [-0.0088,  0.0061, -0.0024,  ..., -0.0036,  0.0074, -0.0009],
        [-0.0101,  0.0022, -0.0036,  ..., -0.0032, -0.0065,  0.0203]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0195, -3.9941,  1.8584,  ..., -2.1230, -2.3984, -1.8809]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 02:40:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with kiev as its capital is known as ukraine
The country with santiago as its capital is known as chile
The country with dublin as its capital is known as ireland
The country with taipei as its capital is known as taiwan
The country with rome as its capital is known as italy
The country with tokyo as its capital is known as japan
The country with nairobi as its capital is known as kenya
The country with canberra as its capital is known as
2024-07-27 02:40:47 root INFO     [order_1_approx] starting weight calculation for The country with dublin as its capital is known as ireland
The country with tokyo as its capital is known as japan
The country with rome as its capital is known as italy
The country with taipei as its capital is known as taiwan
The country with santiago as its capital is known as chile
The country with canberra as its capital is known as australia
The country with kiev as its capital is known as ukraine
The country with nairobi as its capital is known as
2024-07-27 02:40:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 02:43:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2340, -0.1504, -0.4622,  ...,  0.5322, -0.1467, -0.1642],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.6406, -3.8945, -2.4648,  ...,  0.0623, -0.9355, -2.8262],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0257, -0.0132,  0.0010,  ...,  0.0165, -0.0059,  0.0064],
        [ 0.0002,  0.0385, -0.0080,  ..., -0.0028,  0.0073, -0.0010],
        [ 0.0009,  0.0022,  0.0417,  ...,  0.0191, -0.0041, -0.0061],
        ...,
        [-0.0037,  0.0126,  0.0027,  ...,  0.0334, -0.0032, -0.0007],
        [-0.0099,  0.0090, -0.0003,  ...,  0.0013,  0.0120, -0.0023],
        [-0.0046, -0.0013, -0.0140,  ...,  0.0079,  0.0035,  0.0240]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.5547, -3.7559, -2.6387,  ..., -0.0934, -0.7529, -3.1973]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 02:43:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with dublin as its capital is known as ireland
The country with tokyo as its capital is known as japan
The country with rome as its capital is known as italy
The country with taipei as its capital is known as taiwan
The country with santiago as its capital is known as chile
The country with canberra as its capital is known as australia
The country with kiev as its capital is known as ukraine
The country with nairobi as its capital is known as
2024-07-27 02:43:05 root INFO     [order_1_approx] starting weight calculation for The country with canberra as its capital is known as australia
The country with dublin as its capital is known as ireland
The country with taipei as its capital is known as taiwan
The country with rome as its capital is known as italy
The country with nairobi as its capital is known as kenya
The country with kiev as its capital is known as ukraine
The country with santiago as its capital is known as chile
The country with tokyo as its capital is known as
2024-07-27 02:43:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 02:45:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3101, -0.0533,  0.0121,  ...,  0.3318,  0.1732,  0.0704],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9863, -4.6328, -0.1752,  ...,  0.4902,  0.5693, -2.3320],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0094, -0.0005, -0.0098,  ...,  0.0023, -0.0066,  0.0029],
        [-0.0019,  0.0145,  0.0029,  ..., -0.0016,  0.0050, -0.0038],
        [ 0.0045,  0.0139,  0.0279,  ...,  0.0169,  0.0014, -0.0074],
        ...,
        [-0.0033,  0.0108,  0.0059,  ...,  0.0261,  0.0079, -0.0193],
        [ 0.0061, -0.0083, -0.0068,  ...,  0.0007,  0.0069, -0.0003],
        [-0.0055, -0.0038,  0.0019,  ..., -0.0024, -0.0062,  0.0063]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8555, -4.4609, -0.4009,  ...,  0.4097,  0.5933, -2.2441]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 02:45:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with canberra as its capital is known as australia
The country with dublin as its capital is known as ireland
The country with taipei as its capital is known as taiwan
The country with rome as its capital is known as italy
The country with nairobi as its capital is known as kenya
The country with kiev as its capital is known as ukraine
The country with santiago as its capital is known as chile
The country with tokyo as its capital is known as
2024-07-27 02:45:18 root INFO     [order_1_approx] starting weight calculation for The country with tokyo as its capital is known as japan
The country with rome as its capital is known as italy
The country with nairobi as its capital is known as kenya
The country with taipei as its capital is known as taiwan
The country with kiev as its capital is known as ukraine
The country with canberra as its capital is known as australia
The country with dublin as its capital is known as ireland
The country with santiago as its capital is known as
2024-07-27 02:45:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 02:47:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4700, -0.0832, -0.5542,  ...,  0.3169,  0.0477,  0.2220],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8633, -0.9355, -0.1011,  ...,  0.5977, -0.4102, -2.8418],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0310, -0.0025, -0.0084,  ...,  0.0111, -0.0183,  0.0043],
        [-0.0022,  0.0171,  0.0129,  ..., -0.0141, -0.0033,  0.0093],
        [ 0.0118,  0.0359,  0.0081,  ..., -0.0091,  0.0016, -0.0208],
        ...,
        [-0.0044,  0.0146, -0.0106,  ...,  0.0298,  0.0182, -0.0263],
        [ 0.0092, -0.0137, -0.0115,  ...,  0.0095,  0.0159, -0.0146],
        [-0.0141,  0.0144, -0.0079,  ..., -0.0073,  0.0033,  0.0086]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5430, -0.5264, -0.4697,  ...,  0.5679, -0.4912, -2.5742]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 02:47:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with tokyo as its capital is known as japan
The country with rome as its capital is known as italy
The country with nairobi as its capital is known as kenya
The country with taipei as its capital is known as taiwan
The country with kiev as its capital is known as ukraine
The country with canberra as its capital is known as australia
The country with dublin as its capital is known as ireland
The country with santiago as its capital is known as
2024-07-27 02:47:39 root INFO     [order_1_approx] starting weight calculation for The country with kiev as its capital is known as ukraine
The country with nairobi as its capital is known as kenya
The country with taipei as its capital is known as taiwan
The country with santiago as its capital is known as chile
The country with tokyo as its capital is known as japan
The country with canberra as its capital is known as australia
The country with rome as its capital is known as italy
The country with dublin as its capital is known as
2024-07-27 02:47:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 02:49:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4121, -0.0986, -0.4812,  ...,  0.6880,  0.0955,  0.0036],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5938, -5.5000, -1.4414,  ...,  1.9580, -1.4180, -6.6406],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0420, -0.0205, -0.0111,  ...,  0.0085,  0.0004, -0.0013],
        [-0.0048,  0.0249, -0.0161,  ...,  0.0015, -0.0077, -0.0115],
        [-0.0058,  0.0159,  0.0471,  ...,  0.0130, -0.0092, -0.0108],
        ...,
        [-0.0144,  0.0047,  0.0118,  ...,  0.0237,  0.0109, -0.0118],
        [ 0.0020, -0.0062, -0.0039,  ...,  0.0095,  0.0220,  0.0005],
        [-0.0041, -0.0091,  0.0027,  ..., -0.0009,  0.0063,  0.0151]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3516, -5.6719, -1.5635,  ...,  1.5742, -1.3301, -6.1367]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 02:49:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with kiev as its capital is known as ukraine
The country with nairobi as its capital is known as kenya
The country with taipei as its capital is known as taiwan
The country with santiago as its capital is known as chile
The country with tokyo as its capital is known as japan
The country with canberra as its capital is known as australia
The country with rome as its capital is known as italy
The country with dublin as its capital is known as
2024-07-27 02:49:58 root INFO     [order_1_approx] starting weight calculation for The country with tokyo as its capital is known as japan
The country with taipei as its capital is known as taiwan
The country with santiago as its capital is known as chile
The country with canberra as its capital is known as australia
The country with nairobi as its capital is known as kenya
The country with kiev as its capital is known as ukraine
The country with dublin as its capital is known as ireland
The country with rome as its capital is known as
2024-07-27 02:49:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 02:52:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3733, -0.1388, -0.3325,  ...,  0.3977,  0.0993, -0.1050],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5430, -5.3398, -1.5996,  ..., -1.5508,  2.3477, -3.4023],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0293, -0.0009, -0.0135,  ...,  0.0099, -0.0062,  0.0081],
        [ 0.0057,  0.0144,  0.0148,  ...,  0.0007, -0.0106, -0.0150],
        [-0.0107,  0.0068,  0.0602,  ...,  0.0221,  0.0023, -0.0054],
        ...,
        [-0.0060, -0.0009,  0.0109,  ...,  0.0237,  0.0191, -0.0046],
        [ 0.0144,  0.0027, -0.0005,  ...,  0.0010,  0.0077, -0.0053],
        [-0.0056,  0.0048, -0.0183,  ...,  0.0084, -0.0090,  0.0207]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4648, -5.2227, -1.9688,  ..., -1.7617,  2.3652, -3.2266]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 02:52:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with tokyo as its capital is known as japan
The country with taipei as its capital is known as taiwan
The country with santiago as its capital is known as chile
The country with canberra as its capital is known as australia
The country with nairobi as its capital is known as kenya
The country with kiev as its capital is known as ukraine
The country with dublin as its capital is known as ireland
The country with rome as its capital is known as
2024-07-27 02:52:14 root INFO     total operator prediction time: 1105.5338101387024 seconds
2024-07-27 02:52:14 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on name - occupation
2024-07-27 02:52:14 root INFO     building operator name - occupation
2024-07-27 02:52:14 root INFO     [order_1_approx] starting weight calculation for andersen was known for their work as a  writer
kant was known for their work as a  philosopher
rousseau was known for their work as a  writer
locke was known for their work as a  philosopher
picasso was known for their work as a  painter
dante was known for their work as a  poet
confucius was known for their work as a  philosopher
darwin was known for their work as a 
2024-07-27 02:52:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 02:54:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2788, -0.2363, -0.1094,  ...,  0.0366, -0.0236,  0.0362],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9688, -5.7305,  2.2871,  ..., -5.6328, -0.3521, -1.9785],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0385, -0.0160,  0.0017,  ..., -0.0150, -0.0004,  0.0088],
        [-0.0108,  0.0476, -0.0065,  ...,  0.0027, -0.0021, -0.0082],
        [ 0.0112, -0.0038,  0.0534,  ..., -0.0125,  0.0100,  0.0088],
        ...,
        [ 0.0105, -0.0007,  0.0054,  ...,  0.0420,  0.0089, -0.0080],
        [-0.0105,  0.0023,  0.0024,  ...,  0.0017,  0.0351, -0.0047],
        [ 0.0008, -0.0090, -0.0014,  ..., -0.0141,  0.0022,  0.0378]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8867, -5.8516,  2.2207,  ..., -5.6367, -0.1675, -1.4463]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 02:54:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for andersen was known for their work as a  writer
kant was known for their work as a  philosopher
rousseau was known for their work as a  writer
locke was known for their work as a  philosopher
picasso was known for their work as a  painter
dante was known for their work as a  poet
confucius was known for their work as a  philosopher
darwin was known for their work as a 
2024-07-27 02:54:27 root INFO     [order_1_approx] starting weight calculation for confucius was known for their work as a  philosopher
rousseau was known for their work as a  writer
kant was known for their work as a  philosopher
andersen was known for their work as a  writer
dante was known for their work as a  poet
darwin was known for their work as a  naturalist
picasso was known for their work as a  painter
locke was known for their work as a 
2024-07-27 02:54:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 02:56:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1648, -0.2849, -0.5107,  ...,  0.0895, -0.1812,  0.1118],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0469, -4.5312,  1.7881,  ..., -6.5664,  1.6426, -2.3906],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.0060e-02, -6.9427e-03,  8.7118e-04,  ...,  5.4245e-03,
          1.9493e-03,  3.5744e-03],
        [ 8.7433e-03,  2.9953e-02, -8.5144e-03,  ...,  1.0696e-02,
         -4.5776e-03,  2.1019e-03],
        [ 6.6833e-03, -5.9357e-03,  3.9490e-02,  ..., -4.6234e-03,
          1.0727e-02,  7.6447e-03],
        ...,
        [ 1.1482e-02,  1.3504e-03, -8.3733e-04,  ...,  4.8187e-02,
         -9.7275e-05, -5.2071e-04],
        [-6.3286e-03,  1.0696e-02,  5.0201e-03,  ...,  8.4991e-03,
          2.7435e-02, -2.4586e-03],
        [-6.8512e-03, -8.4686e-04, -3.7212e-03,  ..., -9.9792e-03,
         -3.3035e-03,  3.9673e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8066, -4.6328,  1.7461,  ..., -6.2578,  1.7383, -2.3379]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 02:56:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for confucius was known for their work as a  philosopher
rousseau was known for their work as a  writer
kant was known for their work as a  philosopher
andersen was known for their work as a  writer
dante was known for their work as a  poet
darwin was known for their work as a  naturalist
picasso was known for their work as a  painter
locke was known for their work as a 
2024-07-27 02:56:44 root INFO     [order_1_approx] starting weight calculation for confucius was known for their work as a  philosopher
locke was known for their work as a  philosopher
andersen was known for their work as a  writer
darwin was known for their work as a  naturalist
rousseau was known for their work as a  writer
picasso was known for their work as a  painter
kant was known for their work as a  philosopher
dante was known for their work as a 
2024-07-27 02:56:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 02:59:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1991, -0.3181, -0.4241,  ...,  0.4814, -0.0857,  0.1528],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3340, -7.9062,  2.2539,  ..., -4.5078, -0.3560,  0.3379],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0509, -0.0155,  0.0051,  ..., -0.0060, -0.0090,  0.0168],
        [ 0.0066,  0.0431, -0.0124,  ..., -0.0200,  0.0003, -0.0112],
        [ 0.0079, -0.0102,  0.0555,  ..., -0.0124, -0.0063,  0.0030],
        ...,
        [ 0.0139,  0.0261, -0.0085,  ...,  0.0645,  0.0099, -0.0109],
        [ 0.0021,  0.0009,  0.0012,  ...,  0.0023,  0.0214,  0.0074],
        [-0.0084,  0.0087, -0.0071,  ..., -0.0033, -0.0063,  0.0474]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3008, -7.4609,  2.2539,  ..., -4.3359, -0.1055,  0.2661]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 02:59:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for confucius was known for their work as a  philosopher
locke was known for their work as a  philosopher
andersen was known for their work as a  writer
darwin was known for their work as a  naturalist
rousseau was known for their work as a  writer
picasso was known for their work as a  painter
kant was known for their work as a  philosopher
dante was known for their work as a 
2024-07-27 02:59:03 root INFO     [order_1_approx] starting weight calculation for kant was known for their work as a  philosopher
locke was known for their work as a  philosopher
picasso was known for their work as a  painter
dante was known for their work as a  poet
andersen was known for their work as a  writer
darwin was known for their work as a  naturalist
confucius was known for their work as a  philosopher
rousseau was known for their work as a 
2024-07-27 02:59:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 03:01:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2156, -0.3296, -0.6133,  ..., -0.1210, -0.5493,  0.2742],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9062, -6.3242,  3.4785,  ..., -6.6211,  0.7490,  0.7422],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0733, -0.0182,  0.0202,  ...,  0.0075, -0.0028, -0.0098],
        [-0.0008,  0.0778, -0.0003,  ...,  0.0068, -0.0108, -0.0162],
        [ 0.0148, -0.0094,  0.0820,  ..., -0.0178,  0.0155,  0.0060],
        ...,
        [ 0.0224,  0.0174, -0.0058,  ...,  0.0935,  0.0124, -0.0029],
        [-0.0078,  0.0181,  0.0022,  ...,  0.0099,  0.0319,  0.0029],
        [-0.0051,  0.0192,  0.0011,  ...,  0.0013, -0.0148,  0.0688]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8740, -6.1602,  3.3125,  ..., -6.6172,  0.7227,  0.8208]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 03:01:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for kant was known for their work as a  philosopher
locke was known for their work as a  philosopher
picasso was known for their work as a  painter
dante was known for their work as a  poet
andersen was known for their work as a  writer
darwin was known for their work as a  naturalist
confucius was known for their work as a  philosopher
rousseau was known for their work as a 
2024-07-27 03:01:26 root INFO     [order_1_approx] starting weight calculation for locke was known for their work as a  philosopher
dante was known for their work as a  poet
picasso was known for their work as a  painter
rousseau was known for their work as a  writer
kant was known for their work as a  philosopher
darwin was known for their work as a  naturalist
confucius was known for their work as a  philosopher
andersen was known for their work as a 
2024-07-27 03:01:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 03:03:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0770,  0.1993, -0.5107,  ...,  0.0078, -0.1692,  0.0520],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4688, -3.8340,  1.7402,  ..., -4.8750, -2.0410,  1.5576],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0657, -0.0115,  0.0115,  ..., -0.0100, -0.0006,  0.0170],
        [ 0.0086,  0.0417, -0.0092,  ...,  0.0036, -0.0168,  0.0006],
        [ 0.0077,  0.0038,  0.0548,  ..., -0.0058,  0.0023,  0.0028],
        ...,
        [ 0.0265,  0.0008, -0.0079,  ...,  0.0573,  0.0028, -0.0021],
        [-0.0038,  0.0128,  0.0105,  ...,  0.0023,  0.0336,  0.0042],
        [-0.0018, -0.0079, -0.0238,  ...,  0.0092, -0.0021,  0.0558]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4688, -3.9297,  1.6348,  ..., -4.5312, -1.9502,  1.6865]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 03:03:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for locke was known for their work as a  philosopher
dante was known for their work as a  poet
picasso was known for their work as a  painter
rousseau was known for their work as a  writer
kant was known for their work as a  philosopher
darwin was known for their work as a  naturalist
confucius was known for their work as a  philosopher
andersen was known for their work as a 
2024-07-27 03:03:45 root INFO     [order_1_approx] starting weight calculation for confucius was known for their work as a  philosopher
rousseau was known for their work as a  writer
darwin was known for their work as a  naturalist
locke was known for their work as a  philosopher
andersen was known for their work as a  writer
dante was known for their work as a  poet
picasso was known for their work as a  painter
kant was known for their work as a 
2024-07-27 03:03:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 03:05:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1946, -0.4453, -0.1243,  ...,  0.4917,  0.0246,  0.2194],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2676, -6.8828,  2.8184,  ..., -6.5859, -0.6436, -2.6992],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0271, -0.0122,  0.0089,  ..., -0.0055, -0.0023,  0.0069],
        [ 0.0027,  0.0197, -0.0046,  ..., -0.0029, -0.0036,  0.0070],
        [ 0.0110, -0.0043,  0.0270,  ..., -0.0106,  0.0039,  0.0020],
        ...,
        [ 0.0071, -0.0027,  0.0094,  ...,  0.0333,  0.0020,  0.0004],
        [-0.0019,  0.0050,  0.0042,  ...,  0.0077,  0.0209,  0.0024],
        [-0.0106,  0.0004, -0.0021,  ..., -0.0014, -0.0088,  0.0359]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0820, -6.9297,  2.6719,  ..., -6.4062, -0.4741, -2.6270]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 03:05:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for confucius was known for their work as a  philosopher
rousseau was known for their work as a  writer
darwin was known for their work as a  naturalist
locke was known for their work as a  philosopher
andersen was known for their work as a  writer
dante was known for their work as a  poet
picasso was known for their work as a  painter
kant was known for their work as a 
2024-07-27 03:05:59 root INFO     [order_1_approx] starting weight calculation for andersen was known for their work as a  writer
confucius was known for their work as a  philosopher
darwin was known for their work as a  naturalist
dante was known for their work as a  poet
locke was known for their work as a  philosopher
rousseau was known for their work as a  writer
kant was known for their work as a  philosopher
picasso was known for their work as a 
2024-07-27 03:05:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 03:08:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1412, -0.3374, -0.3022,  ...,  0.6455, -0.2993, -0.1012],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5332, -7.7578,  0.4409,  ..., -4.1641,  0.3091, -1.6816],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.8818e-02, -1.8015e-03,  2.4815e-03,  ..., -9.1553e-05,
         -8.6975e-03, -1.5221e-03],
        [-1.3260e-02,  3.1128e-02, -4.9210e-03,  ..., -1.0643e-02,
          6.8521e-04, -9.8572e-03],
        [ 3.0670e-02, -7.2403e-03,  4.8401e-02,  ..., -8.3923e-03,
          3.2253e-03,  9.0332e-03],
        ...,
        [-5.3825e-03, -1.5707e-03, -4.3945e-03,  ...,  4.3243e-02,
          5.9052e-03, -3.4447e-03],
        [-4.9362e-03, -7.3624e-04, -1.1749e-03,  ...,  9.8953e-03,
          2.2415e-02, -2.7752e-04],
        [ 7.7896e-03,  1.6708e-03,  4.7207e-04,  ..., -1.1002e-02,
          4.8904e-03,  3.4760e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3496, -7.6641,  0.7129,  ..., -4.1289,  0.2502, -1.5254]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 03:08:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for andersen was known for their work as a  writer
confucius was known for their work as a  philosopher
darwin was known for their work as a  naturalist
dante was known for their work as a  poet
locke was known for their work as a  philosopher
rousseau was known for their work as a  writer
kant was known for their work as a  philosopher
picasso was known for their work as a 
2024-07-27 03:08:17 root INFO     [order_1_approx] starting weight calculation for dante was known for their work as a  poet
rousseau was known for their work as a  writer
kant was known for their work as a  philosopher
darwin was known for their work as a  naturalist
picasso was known for their work as a  painter
andersen was known for their work as a  writer
locke was known for their work as a  philosopher
confucius was known for their work as a 
2024-07-27 03:08:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 03:10:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0684, -0.3201, -0.8706,  ...,  0.3235, -0.2563,  0.1998],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1777, -5.6172,  3.8594,  ..., -8.1094,  0.1697,  0.8096],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0342,  0.0006,  0.0053,  ...,  0.0024, -0.0141,  0.0012],
        [-0.0037,  0.0355, -0.0087,  ..., -0.0136, -0.0090, -0.0026],
        [ 0.0113, -0.0112,  0.0292,  ...,  0.0026, -0.0055,  0.0095],
        ...,
        [ 0.0088,  0.0103, -0.0101,  ...,  0.0323,  0.0042, -0.0135],
        [-0.0085,  0.0072, -0.0077,  ..., -0.0003,  0.0077,  0.0007],
        [-0.0177,  0.0078,  0.0031,  ...,  0.0042,  0.0067,  0.0256]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2329, -5.7461,  3.6680,  ..., -7.8750,  0.2297,  0.9189]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 03:10:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for dante was known for their work as a  poet
rousseau was known for their work as a  writer
kant was known for their work as a  philosopher
darwin was known for their work as a  naturalist
picasso was known for their work as a  painter
andersen was known for their work as a  writer
locke was known for their work as a  philosopher
confucius was known for their work as a 
2024-07-27 03:10:34 root INFO     total operator prediction time: 1100.5061676502228 seconds
2024-07-27 03:10:34 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on male - female
2024-07-27 03:10:34 root INFO     building operator male - female
2024-07-27 03:10:34 root INFO     [order_1_approx] starting weight calculation for A female stallion is known as a mare
A female boy is known as a girl
A female mister is known as a miss
A female superman is known as a superwoman
A female dad is known as a mom
A female businessman is known as a businesswoman
A female stepfather is known as a stepmother
A female uncle is known as a
2024-07-27 03:10:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 03:12:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1305,  0.5698,  0.3887,  ..., -0.0631, -0.0549, -0.1029],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9092, -0.8076, -1.7617,  ...,  0.5146, -3.8359, -1.3203],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0553,  0.0048,  0.0399,  ...,  0.0356, -0.0220,  0.0365],
        [ 0.0359,  0.0294,  0.0024,  ...,  0.0119,  0.0123, -0.0050],
        [ 0.0192, -0.0181,  0.0398,  ..., -0.0319,  0.0264, -0.0430],
        ...,
        [ 0.0017,  0.0214,  0.0008,  ...,  0.0547,  0.0108, -0.0150],
        [-0.0143,  0.0037,  0.0069,  ...,  0.0365,  0.0125,  0.0010],
        [ 0.0003,  0.0030,  0.0100,  ...,  0.0237,  0.0206,  0.0369]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9365, -0.1074, -1.5166,  ...,  0.4692, -4.4531, -1.4414]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 03:12:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female stallion is known as a mare
A female boy is known as a girl
A female mister is known as a miss
A female superman is known as a superwoman
A female dad is known as a mom
A female businessman is known as a businesswoman
A female stepfather is known as a stepmother
A female uncle is known as a
2024-07-27 03:12:55 root INFO     [order_1_approx] starting weight calculation for A female uncle is known as a aunt
A female superman is known as a superwoman
A female boy is known as a girl
A female mister is known as a miss
A female stallion is known as a mare
A female stepfather is known as a stepmother
A female dad is known as a mom
A female businessman is known as a
2024-07-27 03:12:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 03:15:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7383,  0.3623, -0.1528,  ...,  0.1448, -0.3625,  0.2158],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.4766, -2.4219, -0.0205,  ...,  1.2559, -0.8379, -2.7734],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0413, -0.0273, -0.0013,  ..., -0.0037, -0.0131, -0.0003],
        [ 0.0052,  0.0471,  0.0063,  ...,  0.0281, -0.0050, -0.0049],
        [-0.0011,  0.0083,  0.0576,  ..., -0.0036,  0.0036,  0.0044],
        ...,
        [-0.0198,  0.0051, -0.0042,  ...,  0.0690, -0.0229, -0.0115],
        [-0.0068,  0.0175,  0.0006,  ...,  0.0018,  0.0264, -0.0002],
        [-0.0080, -0.0075, -0.0085,  ..., -0.0084, -0.0012,  0.0444]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.6406, -2.4199, -0.0573,  ...,  1.0908, -0.7354, -2.6992]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 03:15:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female uncle is known as a aunt
A female superman is known as a superwoman
A female boy is known as a girl
A female mister is known as a miss
A female stallion is known as a mare
A female stepfather is known as a stepmother
A female dad is known as a mom
A female businessman is known as a
2024-07-27 03:15:15 root INFO     [order_1_approx] starting weight calculation for A female dad is known as a mom
A female superman is known as a superwoman
A female boy is known as a girl
A female mister is known as a miss
A female businessman is known as a businesswoman
A female uncle is known as a aunt
A female stepfather is known as a stepmother
A female stallion is known as a
2024-07-27 03:15:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 03:17:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6421, -0.0924, -0.0928,  ...,  0.2174, -0.2800,  0.4888],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.3672, -5.9062, -2.5879,  ...,  0.8140, -1.5762,  2.4688],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0838, -0.0057,  0.0086,  ...,  0.0071, -0.0168,  0.0132],
        [-0.0054,  0.0701,  0.0105,  ...,  0.0150,  0.0316, -0.0347],
        [ 0.0036, -0.0122,  0.0498,  ..., -0.0156, -0.0321, -0.0264],
        ...,
        [-0.0180, -0.0051, -0.0305,  ...,  0.0660, -0.0022, -0.0157],
        [-0.0241,  0.0246,  0.0072,  ...,  0.0113,  0.0340,  0.0085],
        [ 0.0417, -0.0168,  0.0083,  ..., -0.0130,  0.0022,  0.0561]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9688, -5.2617, -2.9414,  ...,  0.9819, -1.4727,  2.4258]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 03:17:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female dad is known as a mom
A female superman is known as a superwoman
A female boy is known as a girl
A female mister is known as a miss
A female businessman is known as a businesswoman
A female uncle is known as a aunt
A female stepfather is known as a stepmother
A female stallion is known as a
2024-07-27 03:17:35 root INFO     [order_1_approx] starting weight calculation for A female stallion is known as a mare
A female stepfather is known as a stepmother
A female uncle is known as a aunt
A female businessman is known as a businesswoman
A female dad is known as a mom
A female boy is known as a girl
A female superman is known as a superwoman
A female mister is known as a
2024-07-27 03:17:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 03:19:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.8721,  0.8252, -0.1599,  ...,  0.3645, -0.1205,  0.0344],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.9844, -2.6855, -0.6836,  ...,  0.6045, -5.0391, -2.4824],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0880, -0.0373,  0.0513,  ...,  0.0537,  0.0136,  0.0055],
        [ 0.0019,  0.0572,  0.0357,  ...,  0.0077,  0.0078, -0.0061],
        [ 0.0284, -0.0096,  0.0905,  ..., -0.0365,  0.0039,  0.0442],
        ...,
        [ 0.0112,  0.0188,  0.0357,  ...,  0.0975, -0.0290,  0.0050],
        [-0.0049, -0.0080,  0.0029,  ...,  0.0480,  0.0479,  0.0099],
        [ 0.0291,  0.0036, -0.0267,  ...,  0.0090,  0.0055,  0.0317]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.6055, -2.5742, -0.6943,  ...,  0.8916, -4.3281, -2.1953]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 03:19:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female stallion is known as a mare
A female stepfather is known as a stepmother
A female uncle is known as a aunt
A female businessman is known as a businesswoman
A female dad is known as a mom
A female boy is known as a girl
A female superman is known as a superwoman
A female mister is known as a
2024-07-27 03:19:55 root INFO     [order_1_approx] starting weight calculation for A female stepfather is known as a stepmother
A female uncle is known as a aunt
A female superman is known as a superwoman
A female stallion is known as a mare
A female businessman is known as a businesswoman
A female mister is known as a miss
A female boy is known as a girl
A female dad is known as a
2024-07-27 03:19:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 03:22:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5010,  0.3254,  0.0952,  ...,  0.1362, -0.6382,  0.1479],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.0391, -2.7734, -3.6719,  ...,  1.4307, -4.8203, -2.5488],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0710, -0.0112,  0.0109,  ...,  0.0143, -0.0095,  0.0162],
        [ 0.0206,  0.0430, -0.0021,  ...,  0.0074,  0.0122, -0.0072],
        [ 0.0011, -0.0109,  0.0781,  ...,  0.0087, -0.0038, -0.0102],
        ...,
        [ 0.0071,  0.0102, -0.0133,  ...,  0.0547, -0.0126, -0.0105],
        [ 0.0163, -0.0157,  0.0057,  ...,  0.0192,  0.0167, -0.0148],
        [ 0.0244, -0.0017, -0.0182,  ..., -0.0198,  0.0013,  0.0244]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.9023, -2.5957, -3.9023,  ...,  1.8633, -4.6133, -1.7803]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 03:22:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female stepfather is known as a stepmother
A female uncle is known as a aunt
A female superman is known as a superwoman
A female stallion is known as a mare
A female businessman is known as a businesswoman
A female mister is known as a miss
A female boy is known as a girl
A female dad is known as a
2024-07-27 03:22:15 root INFO     [order_1_approx] starting weight calculation for A female superman is known as a superwoman
A female uncle is known as a aunt
A female stepfather is known as a stepmother
A female mister is known as a miss
A female dad is known as a mom
A female stallion is known as a mare
A female businessman is known as a businesswoman
A female boy is known as a
2024-07-27 03:22:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 03:24:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4587,  0.2881, -0.3079,  ..., -0.0178, -0.5869, -0.0228],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.4922, -0.5977, -3.6719,  ...,  3.6602, -1.1660,  1.0332],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0394, -0.0329,  0.0160,  ...,  0.0129, -0.0088,  0.0206],
        [ 0.0166,  0.0464,  0.0210,  ...,  0.0200,  0.0139, -0.0092],
        [-0.0045, -0.0033,  0.0245,  ..., -0.0170, -0.0109, -0.0098],
        ...,
        [-0.0099,  0.0118,  0.0169,  ...,  0.0535, -0.0187, -0.0121],
        [-0.0151,  0.0011,  0.0334,  ...,  0.0047,  0.0121,  0.0038],
        [ 0.0243,  0.0170, -0.0049,  ..., -0.0019,  0.0073,  0.0424]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.2109, -0.5703, -3.8418,  ...,  3.6406, -1.7656,  0.8809]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 03:24:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female superman is known as a superwoman
A female uncle is known as a aunt
A female stepfather is known as a stepmother
A female mister is known as a miss
A female dad is known as a mom
A female stallion is known as a mare
A female businessman is known as a businesswoman
A female boy is known as a
2024-07-27 03:24:36 root INFO     [order_1_approx] starting weight calculation for A female stallion is known as a mare
A female businessman is known as a businesswoman
A female mister is known as a miss
A female dad is known as a mom
A female stepfather is known as a stepmother
A female uncle is known as a aunt
A female boy is known as a girl
A female superman is known as a
2024-07-27 03:24:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 03:26:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7354,  0.4961,  0.2109,  ...,  0.2229, -0.3269,  0.2245],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 7.1875, -4.2461,  0.9097,  ...,  0.7217, -2.1641,  1.9990],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0565, -0.0298,  0.0310,  ...,  0.0266, -0.0242,  0.0128],
        [-0.0119,  0.0537,  0.0068,  ...,  0.0237,  0.0202, -0.0191],
        [ 0.0153,  0.0019,  0.0544,  ..., -0.0166, -0.0013, -0.0093],
        ...,
        [ 0.0149,  0.0098, -0.0242,  ...,  0.0747, -0.0184,  0.0058],
        [ 0.0004, -0.0077, -0.0079,  ...,  0.0007,  0.0332,  0.0119],
        [-0.0082, -0.0217, -0.0034,  ...,  0.0034,  0.0193,  0.0302]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 6.9766, -4.1484,  0.8125,  ...,  1.0537, -1.8057,  1.7539]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 03:26:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female stallion is known as a mare
A female businessman is known as a businesswoman
A female mister is known as a miss
A female dad is known as a mom
A female stepfather is known as a stepmother
A female uncle is known as a aunt
A female boy is known as a girl
A female superman is known as a
2024-07-27 03:26:56 root INFO     [order_1_approx] starting weight calculation for A female dad is known as a mom
A female mister is known as a miss
A female uncle is known as a aunt
A female stallion is known as a mare
A female boy is known as a girl
A female businessman is known as a businesswoman
A female superman is known as a superwoman
A female stepfather is known as a
2024-07-27 03:26:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 03:29:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5488,  0.4165,  0.2025,  ...,  0.0417, -0.6104, -0.0314],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.1758, -0.5723, -2.3027,  ...,  1.8086, -2.6094, -0.3164],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0336, -0.0026, -0.0047,  ...,  0.0321, -0.0069,  0.0278],
        [ 0.0095,  0.0383,  0.0080,  ...,  0.0046,  0.0135,  0.0154],
        [-0.0041, -0.0035,  0.0614,  ..., -0.0069, -0.0033,  0.0046],
        ...,
        [-0.0035,  0.0005, -0.0071,  ...,  0.0371,  0.0094, -0.0065],
        [ 0.0019,  0.0066,  0.0108,  ...,  0.0006,  0.0344, -0.0056],
        [-0.0154, -0.0063, -0.0017,  ..., -0.0065,  0.0165,  0.0422]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.0273, -0.3228, -2.4453,  ...,  2.1133, -2.6895, -0.3013]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 03:29:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female dad is known as a mom
A female mister is known as a miss
A female uncle is known as a aunt
A female stallion is known as a mare
A female boy is known as a girl
A female businessman is known as a businesswoman
A female superman is known as a superwoman
A female stepfather is known as a
2024-07-27 03:29:16 root INFO     total operator prediction time: 1122.215022802353 seconds
2024-07-27 03:29:16 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - shelter
2024-07-27 03:29:16 root INFO     building operator animal - shelter
2024-07-27 03:29:17 root INFO     [order_1_approx] starting weight calculation for The place fox lives in is called den
The place mole lives in is called hole
The place ant lives in is called anthill
The place snake lives in is called nest
The place hedgehog lives in is called nest
The place rat lives in is called nest
The place wasp lives in is called nest
The place baboon lives in is called
2024-07-27 03:29:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 03:31:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5947, -0.3237,  0.1577,  ...,  0.7710, -0.8945,  0.0591],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.3359, -7.7422, -1.9395,  ..., -1.2314, -1.0566, -0.6738],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0098,  0.0155, -0.0378,  ...,  0.0186,  0.0105,  0.0110],
        [-0.0297,  0.0632,  0.0168,  ...,  0.0334, -0.0024, -0.0242],
        [-0.0050,  0.0157,  0.0404,  ..., -0.0072, -0.0190, -0.0011],
        ...,
        [-0.0037,  0.0162,  0.0209,  ...,  0.0711,  0.0243,  0.0151],
        [ 0.0153, -0.0090,  0.0050,  ..., -0.0007,  0.0233,  0.0012],
        [-0.0009,  0.0144, -0.0239,  ..., -0.0155, -0.0098,  0.0541]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 6.2305, -7.5195, -2.6406,  ..., -0.9785, -1.1348, -0.7661]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 03:31:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place fox lives in is called den
The place mole lives in is called hole
The place ant lives in is called anthill
The place snake lives in is called nest
The place hedgehog lives in is called nest
The place rat lives in is called nest
The place wasp lives in is called nest
The place baboon lives in is called
2024-07-27 03:31:39 root INFO     [order_1_approx] starting weight calculation for The place hedgehog lives in is called nest
The place ant lives in is called anthill
The place mole lives in is called hole
The place fox lives in is called den
The place baboon lives in is called grove
The place rat lives in is called nest
The place snake lives in is called nest
The place wasp lives in is called
2024-07-27 03:31:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 03:34:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2305, -0.6118,  0.1838,  ...,  0.8262, -0.1243, -0.0514],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.0508, -5.6484,  1.9102,  ..., -2.8047,  0.3584,  0.1621],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0453, -0.0071, -0.0152,  ...,  0.0323, -0.0188,  0.0107],
        [-0.0159,  0.0577,  0.0312,  ...,  0.0142, -0.0101, -0.0079],
        [ 0.0054,  0.0303,  0.0657,  ...,  0.0273, -0.0363,  0.0040],
        ...,
        [ 0.0043,  0.0038,  0.0204,  ...,  0.0620,  0.0203, -0.0104],
        [ 0.0020,  0.0082, -0.0146,  ...,  0.0257,  0.0034, -0.0008],
        [-0.0151, -0.0212, -0.0262,  ...,  0.0199, -0.0292,  0.0491]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.6250, -5.7070,  1.7559,  ..., -2.8867,  0.5703,  0.7285]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 03:34:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place hedgehog lives in is called nest
The place ant lives in is called anthill
The place mole lives in is called hole
The place fox lives in is called den
The place baboon lives in is called grove
The place rat lives in is called nest
The place snake lives in is called nest
The place wasp lives in is called
2024-07-27 03:34:01 root INFO     [order_1_approx] starting weight calculation for The place fox lives in is called den
The place snake lives in is called nest
The place mole lives in is called hole
The place rat lives in is called nest
The place wasp lives in is called nest
The place baboon lives in is called grove
The place hedgehog lives in is called nest
The place ant lives in is called
2024-07-27 03:34:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 03:36:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2593, -0.4111,  0.0013,  ...,  0.2661, -0.0191, -0.2330],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8105, -5.0234,  0.9912,  ..., -3.5371,  0.1509, -2.3770],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.0476e-02, -7.2937e-03, -3.3379e-04,  ...,  2.8381e-02,
         -1.2901e-02,  5.4779e-03],
        [-1.5579e-02,  5.1117e-02,  1.8188e-02,  ...,  3.8147e-05,
          1.2993e-02, -1.8597e-03],
        [ 8.3923e-03,  3.9673e-02,  5.7007e-02,  ...,  5.5542e-03,
         -2.2766e-02,  1.2383e-02],
        ...,
        [ 4.4823e-03, -2.3575e-03,  8.5602e-03,  ...,  5.1086e-02,
          1.2047e-02, -8.3542e-03],
        [-3.0403e-03, -7.2708e-03,  3.3512e-03,  ...,  1.2962e-02,
          2.5284e-02,  2.8931e-02],
        [-1.5381e-02,  1.3916e-02, -6.6071e-03,  ..., -7.8278e-03,
         -3.3295e-02,  4.4678e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4121, -5.1719,  1.0000,  ..., -3.5762,  0.3528, -1.7754]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 03:36:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place fox lives in is called den
The place snake lives in is called nest
The place mole lives in is called hole
The place rat lives in is called nest
The place wasp lives in is called nest
The place baboon lives in is called grove
The place hedgehog lives in is called nest
The place ant lives in is called
2024-07-27 03:36:23 root INFO     [order_1_approx] starting weight calculation for The place rat lives in is called nest
The place hedgehog lives in is called nest
The place baboon lives in is called grove
The place ant lives in is called anthill
The place wasp lives in is called nest
The place fox lives in is called den
The place mole lives in is called hole
The place snake lives in is called
2024-07-27 03:36:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 03:38:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5444, -0.2917,  0.1061,  ...,  0.1032,  0.0142, -0.0161],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8848, -4.5156,  0.4707,  ..., -0.7183, -1.2207, -0.8599],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.6143e-02, -8.8501e-03, -1.5259e-04,  ...,  1.0063e-02,
         -1.2405e-02,  2.5749e-04],
        [-4.3221e-03,  5.4321e-02,  2.8290e-02,  ..., -8.4839e-03,
         -1.5259e-05, -1.6663e-02],
        [-1.9043e-02,  2.1713e-02,  5.9113e-02,  ..., -3.8666e-02,
         -1.0567e-02,  4.4327e-03],
        ...,
        [-6.4964e-03,  7.3929e-03,  2.9087e-05,  ...,  5.3986e-02,
          2.6947e-02, -2.9984e-02],
        [ 1.2520e-02, -4.7798e-03, -5.2414e-03,  ...,  1.0513e-02,
          1.1780e-02,  1.0315e-02],
        [-8.1177e-03,  2.6474e-03, -1.7557e-03,  ..., -1.4908e-02,
         -7.6294e-03,  4.5013e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3672, -4.5078,  0.6230,  ..., -0.9727, -1.1270, -0.9248]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 03:38:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place rat lives in is called nest
The place hedgehog lives in is called nest
The place baboon lives in is called grove
The place ant lives in is called anthill
The place wasp lives in is called nest
The place fox lives in is called den
The place mole lives in is called hole
The place snake lives in is called
2024-07-27 03:38:44 root INFO     [order_1_approx] starting weight calculation for The place rat lives in is called nest
The place wasp lives in is called nest
The place snake lives in is called nest
The place ant lives in is called anthill
The place fox lives in is called den
The place mole lives in is called hole
The place baboon lives in is called grove
The place hedgehog lives in is called
2024-07-27 03:38:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 03:41:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2710, -0.5508,  0.2524,  ...,  0.0508, -0.1880, -0.4250],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2344, -2.4727, -0.0518,  ..., -1.2402,  0.1963,  0.7056],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.3321e-02, -3.8357e-03, -1.4336e-02,  ..., -9.2010e-03,
         -1.2489e-02,  3.6526e-03],
        [-4.7722e-03,  3.2166e-02,  5.2528e-03,  ...,  1.5068e-02,
          1.4877e-02, -1.4286e-03],
        [-1.6212e-04,  1.1169e-02,  2.1210e-02,  ...,  1.0208e-02,
         -4.2458e-03,  1.5469e-03],
        ...,
        [ 6.1226e-03,  9.7275e-05,  1.1009e-02,  ...,  2.7847e-02,
          9.1705e-03,  3.4027e-03],
        [ 4.5929e-03,  7.0877e-03, -2.0943e-03,  ...,  3.2597e-03,
          1.0208e-02, -1.1124e-02],
        [ 1.2184e-02, -6.1131e-04, -8.5831e-03,  ...,  6.7444e-03,
         -4.7417e-03,  2.5635e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2715, -2.4336, -0.1826,  ..., -1.3682,  0.2554,  0.3494]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 03:41:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place rat lives in is called nest
The place wasp lives in is called nest
The place snake lives in is called nest
The place ant lives in is called anthill
The place fox lives in is called den
The place mole lives in is called hole
The place baboon lives in is called grove
The place hedgehog lives in is called
2024-07-27 03:41:06 root INFO     [order_1_approx] starting weight calculation for The place snake lives in is called nest
The place fox lives in is called den
The place baboon lives in is called grove
The place rat lives in is called nest
The place wasp lives in is called nest
The place ant lives in is called anthill
The place hedgehog lives in is called nest
The place mole lives in is called
2024-07-27 03:41:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 03:43:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.8408, -0.2932,  0.2717,  ...,  0.1429, -0.5566, -0.1672],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4297, -1.9902,  0.9238,  ..., -2.2773, -0.8472,  0.7109],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0712, -0.0183, -0.0045,  ...,  0.0353, -0.0065,  0.0059],
        [ 0.0064,  0.0790,  0.0199,  ...,  0.0190,  0.0071, -0.0200],
        [-0.0083,  0.0022,  0.0792,  ..., -0.0023,  0.0004, -0.0013],
        ...,
        [ 0.0084,  0.0212, -0.0026,  ...,  0.0727,  0.0220,  0.0166],
        [ 0.0063, -0.0086,  0.0043,  ...,  0.0226,  0.0395,  0.0138],
        [ 0.0051,  0.0152, -0.0093,  ..., -0.0161, -0.0299,  0.0777]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3496, -2.1641,  0.4543,  ..., -2.8359, -0.5996,  0.2886]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 03:43:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place snake lives in is called nest
The place fox lives in is called den
The place baboon lives in is called grove
The place rat lives in is called nest
The place wasp lives in is called nest
The place ant lives in is called anthill
The place hedgehog lives in is called nest
The place mole lives in is called
2024-07-27 03:43:28 root INFO     [order_1_approx] starting weight calculation for The place snake lives in is called nest
The place baboon lives in is called grove
The place fox lives in is called den
The place wasp lives in is called nest
The place hedgehog lives in is called nest
The place ant lives in is called anthill
The place mole lives in is called hole
The place rat lives in is called
2024-07-27 03:43:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 03:45:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2021, -0.6807,  0.1746,  ..., -0.0781, -0.2729, -0.2406],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7207, -3.9434,  2.6621,  ..., -1.6875, -0.7290, -0.3428],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0714, -0.0162, -0.0063,  ...,  0.0200, -0.0223,  0.0038],
        [-0.0301,  0.0790,  0.0007,  ..., -0.0122, -0.0117, -0.0321],
        [-0.0140,  0.0249,  0.0699,  ..., -0.0090,  0.0090,  0.0195],
        ...,
        [-0.0121,  0.0017, -0.0007,  ...,  0.0500,  0.0071, -0.0178],
        [ 0.0169,  0.0029, -0.0118,  ...,  0.0139,  0.0553,  0.0083],
        [ 0.0005,  0.0158, -0.0148,  ..., -0.0089, -0.0310,  0.0504]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9258, -3.2812,  2.1641,  ..., -1.5352, -0.8599, -0.1775]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 03:45:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place snake lives in is called nest
The place baboon lives in is called grove
The place fox lives in is called den
The place wasp lives in is called nest
The place hedgehog lives in is called nest
The place ant lives in is called anthill
The place mole lives in is called hole
The place rat lives in is called
2024-07-27 03:45:51 root INFO     [order_1_approx] starting weight calculation for The place wasp lives in is called nest
The place ant lives in is called anthill
The place snake lives in is called nest
The place mole lives in is called hole
The place rat lives in is called nest
The place hedgehog lives in is called nest
The place baboon lives in is called grove
The place fox lives in is called
2024-07-27 03:45:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 03:48:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6270,  0.0143,  0.0710,  ...,  0.4395, -0.0655, -0.5688],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.2422, -9.2344, -0.5713,  ..., -2.9766, -0.1123,  2.3086],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0325, -0.0028, -0.0110,  ...,  0.0204, -0.0242,  0.0137],
        [-0.0126,  0.0487,  0.0126,  ..., -0.0172, -0.0305, -0.0322],
        [-0.0013,  0.0176,  0.0547,  ..., -0.0034,  0.0121,  0.0017],
        ...,
        [-0.0101, -0.0005,  0.0244,  ...,  0.0406,  0.0342, -0.0086],
        [ 0.0123,  0.0048, -0.0165,  ...,  0.0022,  0.0440, -0.0194],
        [ 0.0019, -0.0128, -0.0041,  ..., -0.0063, -0.0320,  0.0473]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.7109, -9.1797, -0.5576,  ..., -3.1387, -0.0908,  2.1387]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 03:48:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place wasp lives in is called nest
The place ant lives in is called anthill
The place snake lives in is called nest
The place mole lives in is called hole
The place rat lives in is called nest
The place hedgehog lives in is called nest
The place baboon lives in is called grove
The place fox lives in is called
2024-07-27 03:48:12 root INFO     total operator prediction time: 1135.3642501831055 seconds
2024-07-27 03:48:12 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on country - language
2024-07-27 03:48:12 root INFO     building operator country - language
2024-07-27 03:48:12 root INFO     [order_1_approx] starting weight calculation for The country of syria primarily speaks the language of arabic
The country of egypt primarily speaks the language of arabic
The country of netherlands primarily speaks the language of dutch
The country of taiwan primarily speaks the language of chinese
The country of andorra primarily speaks the language of catalan
The country of cuba primarily speaks the language of spanish
The country of guyana primarily speaks the language of english
The country of peru primarily speaks the language of
2024-07-27 03:48:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 03:50:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2327,  0.2097,  0.4062,  ...,  0.1833, -0.5220,  0.3281],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2883, -2.9590,  2.1582,  ...,  0.7715, -0.5176, -0.2749],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0141, -0.0018,  0.0008,  ..., -0.0044, -0.0056, -0.0015],
        [ 0.0008,  0.0313,  0.0020,  ..., -0.0016, -0.0088, -0.0052],
        [ 0.0015,  0.0004,  0.0502,  ...,  0.0104,  0.0050,  0.0132],
        ...,
        [-0.0036,  0.0230,  0.0087,  ...,  0.0288,  0.0106,  0.0085],
        [ 0.0117,  0.0029, -0.0083,  ..., -0.0037,  0.0161, -0.0079],
        [ 0.0036,  0.0029,  0.0068,  ...,  0.0100, -0.0051,  0.0229]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3789, -2.9766,  1.7627,  ...,  0.3506, -0.3770, -0.1733]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 03:50:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of syria primarily speaks the language of arabic
The country of egypt primarily speaks the language of arabic
The country of netherlands primarily speaks the language of dutch
The country of taiwan primarily speaks the language of chinese
The country of andorra primarily speaks the language of catalan
The country of cuba primarily speaks the language of spanish
The country of guyana primarily speaks the language of english
The country of peru primarily speaks the language of
2024-07-27 03:50:33 root INFO     [order_1_approx] starting weight calculation for The country of syria primarily speaks the language of arabic
The country of andorra primarily speaks the language of catalan
The country of netherlands primarily speaks the language of dutch
The country of egypt primarily speaks the language of arabic
The country of taiwan primarily speaks the language of chinese
The country of peru primarily speaks the language of spanish
The country of cuba primarily speaks the language of spanish
The country of guyana primarily speaks the language of
2024-07-27 03:50:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 03:52:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0388, -0.0502,  0.3975,  ...,  0.2444, -0.7021,  0.0963],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0059,  0.0986,  1.3848,  ...,  0.9316,  0.5000, -3.0430],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0196,  0.0085, -0.0173,  ...,  0.0010, -0.0076, -0.0113],
        [ 0.0042,  0.0327,  0.0055,  ..., -0.0014, -0.0062, -0.0173],
        [-0.0089, -0.0047,  0.0430,  ...,  0.0143,  0.0064,  0.0165],
        ...,
        [-0.0058, -0.0171, -0.0028,  ...,  0.0322,  0.0042,  0.0124],
        [ 0.0059,  0.0100, -0.0098,  ..., -0.0074,  0.0254, -0.0120],
        [ 0.0154, -0.0004, -0.0046,  ..., -0.0046,  0.0032,  0.0226]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7734,  0.1349,  1.2510,  ...,  0.6943,  0.4343, -2.6211]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 03:52:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of syria primarily speaks the language of arabic
The country of andorra primarily speaks the language of catalan
The country of netherlands primarily speaks the language of dutch
The country of egypt primarily speaks the language of arabic
The country of taiwan primarily speaks the language of chinese
The country of peru primarily speaks the language of spanish
The country of cuba primarily speaks the language of spanish
The country of guyana primarily speaks the language of
2024-07-27 03:52:53 root INFO     [order_1_approx] starting weight calculation for The country of peru primarily speaks the language of spanish
The country of syria primarily speaks the language of arabic
The country of guyana primarily speaks the language of english
The country of netherlands primarily speaks the language of dutch
The country of egypt primarily speaks the language of arabic
The country of cuba primarily speaks the language of spanish
The country of taiwan primarily speaks the language of chinese
The country of andorra primarily speaks the language of
2024-07-27 03:52:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 03:55:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5991, -0.1857, -0.0576,  ...,  0.3752, -0.2622,  0.1597],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.1475, -5.0391,  0.7461,  ..., -1.1934, -1.1221,  0.9985],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0327, -0.0067, -0.0189,  ...,  0.0126,  0.0051, -0.0102],
        [ 0.0126,  0.0359,  0.0244,  ..., -0.0007,  0.0090, -0.0225],
        [-0.0204,  0.0177,  0.0537,  ...,  0.0089,  0.0030,  0.0120],
        ...,
        [-0.0196,  0.0169, -0.0031,  ...,  0.0409,  0.0218,  0.0011],
        [ 0.0046, -0.0043, -0.0014,  ..., -0.0028,  0.0332, -0.0149],
        [-0.0047, -0.0009, -0.0136,  ...,  0.0126, -0.0146,  0.0329]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.3135, -4.8594,  0.5005,  ..., -1.3564, -1.0459,  0.8154]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 03:55:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of peru primarily speaks the language of spanish
The country of syria primarily speaks the language of arabic
The country of guyana primarily speaks the language of english
The country of netherlands primarily speaks the language of dutch
The country of egypt primarily speaks the language of arabic
The country of cuba primarily speaks the language of spanish
The country of taiwan primarily speaks the language of chinese
The country of andorra primarily speaks the language of
2024-07-27 03:55:12 root INFO     [order_1_approx] starting weight calculation for The country of taiwan primarily speaks the language of chinese
The country of egypt primarily speaks the language of arabic
The country of netherlands primarily speaks the language of dutch
The country of peru primarily speaks the language of spanish
The country of andorra primarily speaks the language of catalan
The country of cuba primarily speaks the language of spanish
The country of guyana primarily speaks the language of english
The country of syria primarily speaks the language of
2024-07-27 03:55:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 03:57:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0851, -0.2910, -0.2224,  ...,  0.3445, -0.5098,  0.3948],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.8516, -3.6094,  0.3162,  ..., -0.9033,  0.9824, -1.4805],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0407, -0.0126,  0.0025,  ...,  0.0037, -0.0119, -0.0196],
        [-0.0017,  0.0280,  0.0067,  ..., -0.0072, -0.0033, -0.0169],
        [-0.0216,  0.0050,  0.0574,  ...,  0.0090,  0.0049,  0.0088],
        ...,
        [-0.0146,  0.0127, -0.0046,  ...,  0.0554,  0.0071,  0.0106],
        [ 0.0172, -0.0069,  0.0056,  ...,  0.0028,  0.0212, -0.0121],
        [-0.0006,  0.0056,  0.0059,  ...,  0.0107, -0.0055,  0.0120]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.4648, -3.3730,  0.2424,  ..., -0.9287,  1.1758, -1.3975]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 03:57:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of taiwan primarily speaks the language of chinese
The country of egypt primarily speaks the language of arabic
The country of netherlands primarily speaks the language of dutch
The country of peru primarily speaks the language of spanish
The country of andorra primarily speaks the language of catalan
The country of cuba primarily speaks the language of spanish
The country of guyana primarily speaks the language of english
The country of syria primarily speaks the language of
2024-07-27 03:57:31 root INFO     [order_1_approx] starting weight calculation for The country of netherlands primarily speaks the language of dutch
The country of peru primarily speaks the language of spanish
The country of taiwan primarily speaks the language of chinese
The country of andorra primarily speaks the language of catalan
The country of guyana primarily speaks the language of english
The country of egypt primarily speaks the language of arabic
The country of syria primarily speaks the language of arabic
The country of cuba primarily speaks the language of
2024-07-27 03:57:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 03:59:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0533, -0.1216,  0.4033,  ..., -0.0244, -0.0081,  0.1257],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9639, -2.0176,  0.8438,  ...,  1.1914, -0.1465, -2.2773],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0309,  0.0015,  0.0113,  ...,  0.0131,  0.0096, -0.0204],
        [-0.0010,  0.0362, -0.0006,  ..., -0.0038, -0.0097,  0.0065],
        [-0.0150,  0.0118,  0.0564,  ...,  0.0212,  0.0180,  0.0158],
        ...,
        [-0.0291,  0.0029,  0.0062,  ...,  0.0475,  0.0135,  0.0133],
        [ 0.0075, -0.0011, -0.0089,  ..., -0.0082,  0.0216, -0.0021],
        [ 0.0032,  0.0003,  0.0063,  ...,  0.0051,  0.0078,  0.0195]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9414, -1.8359,  0.5596,  ...,  0.5815, -0.0076, -2.2344]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 03:59:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of netherlands primarily speaks the language of dutch
The country of peru primarily speaks the language of spanish
The country of taiwan primarily speaks the language of chinese
The country of andorra primarily speaks the language of catalan
The country of guyana primarily speaks the language of english
The country of egypt primarily speaks the language of arabic
The country of syria primarily speaks the language of arabic
The country of cuba primarily speaks the language of
2024-07-27 03:59:42 root INFO     [order_1_approx] starting weight calculation for The country of guyana primarily speaks the language of english
The country of peru primarily speaks the language of spanish
The country of syria primarily speaks the language of arabic
The country of cuba primarily speaks the language of spanish
The country of egypt primarily speaks the language of arabic
The country of andorra primarily speaks the language of catalan
The country of taiwan primarily speaks the language of chinese
The country of netherlands primarily speaks the language of
2024-07-27 03:59:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 04:01:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([0.2561, 0.0475, 0.0763,  ..., 0.2964, 0.0310, 0.0084], device='cuda:1',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6211, -2.9414,  1.5352,  ..., -0.7412, -1.3223, -3.1133],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0260,  0.0003, -0.0035,  ...,  0.0045,  0.0008, -0.0184],
        [-0.0009,  0.0226,  0.0163,  ...,  0.0073,  0.0041, -0.0145],
        [-0.0113, -0.0033,  0.0340,  ...,  0.0160,  0.0154,  0.0085],
        ...,
        [-0.0240, -0.0149, -0.0010,  ...,  0.0278,  0.0129, -0.0009],
        [ 0.0014, -0.0106,  0.0060,  ...,  0.0055,  0.0188, -0.0121],
        [-0.0049, -0.0073, -0.0039,  ...,  0.0070, -0.0013,  0.0212]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5894, -2.8926,  1.6055,  ..., -0.8057, -1.2607, -3.0645]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 04:01:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of guyana primarily speaks the language of english
The country of peru primarily speaks the language of spanish
The country of syria primarily speaks the language of arabic
The country of cuba primarily speaks the language of spanish
The country of egypt primarily speaks the language of arabic
The country of andorra primarily speaks the language of catalan
The country of taiwan primarily speaks the language of chinese
The country of netherlands primarily speaks the language of
2024-07-27 04:01:58 root INFO     [order_1_approx] starting weight calculation for The country of syria primarily speaks the language of arabic
The country of cuba primarily speaks the language of spanish
The country of egypt primarily speaks the language of arabic
The country of guyana primarily speaks the language of english
The country of andorra primarily speaks the language of catalan
The country of netherlands primarily speaks the language of dutch
The country of peru primarily speaks the language of spanish
The country of taiwan primarily speaks the language of
2024-07-27 04:01:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 04:04:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2167, -0.1658,  0.2476,  ...,  0.6924,  0.0052,  0.3479],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.7031, -1.8340,  2.2188,  ..., -0.2029, -3.1992,  0.1504],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0255, -0.0080, -0.0085,  ...,  0.0049,  0.0113, -0.0158],
        [-0.0042,  0.0222,  0.0027,  ...,  0.0051, -0.0059, -0.0043],
        [-0.0080,  0.0024,  0.0523,  ...,  0.0015, -0.0069,  0.0193],
        ...,
        [ 0.0012,  0.0095,  0.0066,  ...,  0.0324,  0.0027, -0.0029],
        [ 0.0188, -0.0068, -0.0069,  ...,  0.0050,  0.0129, -0.0209],
        [ 0.0152, -0.0057, -0.0186,  ...,  0.0069, -0.0034,  0.0262]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.4082, -1.8271,  1.5771,  ..., -0.2253, -3.1074,  0.2534]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 04:04:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of syria primarily speaks the language of arabic
The country of cuba primarily speaks the language of spanish
The country of egypt primarily speaks the language of arabic
The country of guyana primarily speaks the language of english
The country of andorra primarily speaks the language of catalan
The country of netherlands primarily speaks the language of dutch
The country of peru primarily speaks the language of spanish
The country of taiwan primarily speaks the language of
2024-07-27 04:04:11 root INFO     [order_1_approx] starting weight calculation for The country of taiwan primarily speaks the language of chinese
The country of guyana primarily speaks the language of english
The country of peru primarily speaks the language of spanish
The country of andorra primarily speaks the language of catalan
The country of syria primarily speaks the language of arabic
The country of cuba primarily speaks the language of spanish
The country of netherlands primarily speaks the language of dutch
The country of egypt primarily speaks the language of
2024-07-27 04:04:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 04:06:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1201, -0.0648,  0.1031,  ...,  0.0022, -0.3762,  0.0713],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.6602, -4.3555,  1.9111,  ..., -1.4766,  0.5293,  0.2568],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0229, -0.0257, -0.0035,  ...,  0.0025, -0.0060, -0.0054],
        [-0.0064,  0.0226,  0.0121,  ..., -0.0074,  0.0017, -0.0075],
        [-0.0054,  0.0035,  0.0577,  ...,  0.0264,  0.0028,  0.0061],
        ...,
        [-0.0155,  0.0135, -0.0031,  ...,  0.0373,  0.0120,  0.0002],
        [ 0.0105, -0.0156, -0.0024,  ..., -0.0071,  0.0153, -0.0097],
        [ 0.0011, -0.0104,  0.0039,  ...,  0.0164, -0.0003,  0.0108]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.5410, -4.0547,  1.7656,  ..., -1.6152,  0.5596,  0.2732]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 04:06:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of taiwan primarily speaks the language of chinese
The country of guyana primarily speaks the language of english
The country of peru primarily speaks the language of spanish
The country of andorra primarily speaks the language of catalan
The country of syria primarily speaks the language of arabic
The country of cuba primarily speaks the language of spanish
The country of netherlands primarily speaks the language of dutch
The country of egypt primarily speaks the language of
2024-07-27 04:06:31 root INFO     total operator prediction time: 1099.4349131584167 seconds
2024-07-27 04:06:31 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on name - nationality
2024-07-27 04:06:31 root INFO     building operator name - nationality
2024-07-27 04:06:31 root INFO     [order_1_approx] starting weight calculation for balzac was french
caesar was roman
edison was american
descartes was french
tchaikovsky was russian
hume was scottish
wagner was german
stalin was
2024-07-27 04:06:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 04:08:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0885, -0.5059, -0.3496,  ...,  0.4304, -0.1880,  0.2194],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2090, -2.5176, -0.6011,  ..., -4.4727,  0.2617, -0.5264],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.6255e-02,  1.7262e-03, -8.4839e-03,  ..., -1.5503e-02,
          6.2370e-03,  2.3575e-03],
        [ 1.1284e-02,  1.9409e-02,  3.4576e-02,  ...,  2.1057e-02,
         -4.0054e-03, -1.6281e-02],
        [ 1.3077e-02, -7.1793e-03,  7.0984e-02,  ...,  1.5154e-03,
          1.3382e-02,  2.1011e-02],
        ...,
        [ 2.3972e-02, -1.0986e-02, -2.0065e-02,  ...,  1.0120e-01,
         -2.1515e-02,  1.4175e-02],
        [-1.7502e-02,  1.1276e-02,  9.0599e-06,  ...,  3.1013e-03,
          5.0598e-02, -1.2253e-02],
        [ 2.8038e-03,  8.5144e-03,  3.6583e-03,  ...,  3.1708e-02,
         -2.7359e-02,  5.7587e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3516, -2.7070, -0.7842,  ..., -4.6953,  0.5410, -0.2378]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 04:08:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for balzac was french
caesar was roman
edison was american
descartes was french
tchaikovsky was russian
hume was scottish
wagner was german
stalin was
2024-07-27 04:08:52 root INFO     [order_1_approx] starting weight calculation for edison was american
hume was scottish
caesar was roman
wagner was german
tchaikovsky was russian
descartes was french
stalin was soviet
balzac was
2024-07-27 04:08:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 04:11:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1951, -0.0869, -0.4226,  ...,  0.0569, -0.2065, -0.2477],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9473, -3.3359,  1.9521,  ..., -4.0234, -0.3027,  1.1787],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1329, -0.0104, -0.0023,  ..., -0.0598,  0.0325, -0.0498],
        [ 0.0016,  0.0798, -0.0004,  ...,  0.0450, -0.0147,  0.0200],
        [ 0.0149, -0.0203,  0.0912,  ...,  0.0161,  0.0046,  0.0372],
        ...,
        [ 0.0012,  0.0258, -0.0271,  ...,  0.1227, -0.0062,  0.0035],
        [ 0.0294,  0.0067,  0.0224,  ..., -0.0080,  0.0802, -0.0125],
        [-0.0261,  0.0227, -0.0035,  ...,  0.0373, -0.0378,  0.1083]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.5117, -3.5625,  1.6992,  ..., -4.4609, -0.4207,  0.6172]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 04:11:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for edison was american
hume was scottish
caesar was roman
wagner was german
tchaikovsky was russian
descartes was french
stalin was soviet
balzac was
2024-07-27 04:11:10 root INFO     [order_1_approx] starting weight calculation for edison was american
balzac was french
tchaikovsky was russian
stalin was soviet
caesar was roman
descartes was french
hume was scottish
wagner was
2024-07-27 04:11:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 04:13:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4268,  0.1565,  0.2083,  ...,  0.3669, -0.0439, -0.1107],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1230, -6.1289,  0.5200,  ..., -2.3066, -2.1328, -1.0020],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0558, -0.0261, -0.0101,  ..., -0.0171, -0.0118, -0.0117],
        [ 0.0249,  0.0551,  0.0009,  ...,  0.0109, -0.0075, -0.0175],
        [ 0.0197,  0.0123,  0.0882,  ...,  0.0181,  0.0086,  0.0089],
        ...,
        [ 0.0083,  0.0146,  0.0194,  ...,  0.0620, -0.0181,  0.0073],
        [ 0.0209,  0.0285,  0.0098,  ..., -0.0186,  0.0601, -0.0055],
        [ 0.0026,  0.0140,  0.0132,  ...,  0.0145, -0.0220,  0.0767]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9785, -6.4141, -0.0342,  ..., -2.1719, -2.1484, -0.6133]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 04:13:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for edison was american
balzac was french
tchaikovsky was russian
stalin was soviet
caesar was roman
descartes was french
hume was scottish
wagner was
2024-07-27 04:13:31 root INFO     [order_1_approx] starting weight calculation for descartes was french
balzac was french
wagner was german
caesar was roman
stalin was soviet
tchaikovsky was russian
hume was scottish
edison was
2024-07-27 04:13:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 04:15:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0795,  0.2451, -0.3323,  ...,  0.1520, -0.0837,  0.1837],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7344, -4.4688,  0.4365,  ..., -3.4297,  1.5391, -2.2773],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0504,  0.0070,  0.0069,  ..., -0.0172, -0.0026, -0.0246],
        [ 0.0296,  0.0681,  0.0438,  ...,  0.0254,  0.0056, -0.0127],
        [-0.0099, -0.0021,  0.0492,  ...,  0.0188,  0.0097,  0.0347],
        ...,
        [ 0.0096,  0.0236, -0.0184,  ...,  0.0687,  0.0014, -0.0061],
        [ 0.0062, -0.0052, -0.0154,  ...,  0.0063,  0.0573,  0.0114],
        [ 0.0070,  0.0104,  0.0075,  ...,  0.0081, -0.0299,  0.0897]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3574, -4.8633,  0.0417,  ..., -2.9883,  1.9814, -2.1582]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 04:15:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for descartes was french
balzac was french
wagner was german
caesar was roman
stalin was soviet
tchaikovsky was russian
hume was scottish
edison was
2024-07-27 04:15:49 root INFO     [order_1_approx] starting weight calculation for stalin was soviet
hume was scottish
tchaikovsky was russian
balzac was french
edison was american
caesar was roman
wagner was german
descartes was
2024-07-27 04:15:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 04:18:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2932, -0.2935, -0.2744,  ...,  0.2266, -0.3115,  0.4478],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1875, -2.7324,  2.1016,  ..., -5.1602, -1.2432, -0.1572],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0790,  0.0069, -0.0074,  ..., -0.0501,  0.0186, -0.0247],
        [ 0.0172,  0.0574,  0.0311,  ...,  0.0189,  0.0001, -0.0014],
        [ 0.0139, -0.0061,  0.1077,  ...,  0.0139,  0.0177,  0.0244],
        ...,
        [ 0.0002,  0.0059, -0.0153,  ...,  0.0904, -0.0120, -0.0167],
        [-0.0001,  0.0227, -0.0051,  ...,  0.0138,  0.0704, -0.0146],
        [-0.0005, -0.0011, -0.0016,  ...,  0.0168, -0.0104,  0.0991]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0391, -2.8438,  1.6562,  ..., -4.7812, -0.9805, -0.1761]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 04:18:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for stalin was soviet
hume was scottish
tchaikovsky was russian
balzac was french
edison was american
caesar was roman
wagner was german
descartes was
2024-07-27 04:18:10 root INFO     [order_1_approx] starting weight calculation for descartes was french
tchaikovsky was russian
balzac was french
hume was scottish
wagner was german
stalin was soviet
edison was american
caesar was
2024-07-27 04:18:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 04:20:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1221,  0.0710, -0.4473,  ...,  0.3662, -0.5400,  0.2515],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2070, -3.7656,  0.2400,  ..., -2.6016,  1.8652, -1.3955],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0582,  0.0104, -0.0086,  ..., -0.0413,  0.0377, -0.0186],
        [ 0.0070,  0.0548,  0.0320,  ...,  0.0013, -0.0338,  0.0226],
        [ 0.0173, -0.0013,  0.0762,  ...,  0.0077,  0.0161,  0.0199],
        ...,
        [ 0.0331,  0.0081, -0.0087,  ...,  0.1018, -0.0302, -0.0078],
        [ 0.0057,  0.0132,  0.0209,  ..., -0.0045,  0.0701, -0.0015],
        [ 0.0010,  0.0068,  0.0117,  ..., -0.0104, -0.0498,  0.0917]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8857, -4.4023,  0.3911,  ..., -3.3828,  2.4043, -1.9971]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 04:20:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for descartes was french
tchaikovsky was russian
balzac was french
hume was scottish
wagner was german
stalin was soviet
edison was american
caesar was
2024-07-27 04:20:31 root INFO     [order_1_approx] starting weight calculation for tchaikovsky was russian
balzac was french
wagner was german
stalin was soviet
caesar was roman
edison was american
descartes was french
hume was
2024-07-27 04:20:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 04:22:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3203,  0.3965, -0.0392,  ..., -0.0151,  0.0664,  0.2302],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5381, -2.3711,  1.9326,  ..., -3.4844, -1.2285, -1.3750],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0592,  0.0157, -0.0234,  ..., -0.0018,  0.0006, -0.0075],
        [-0.0015,  0.0445,  0.0164,  ...,  0.0372, -0.0011,  0.0036],
        [ 0.0064, -0.0082,  0.0596,  ...,  0.0045,  0.0222,  0.0167],
        ...,
        [-0.0005, -0.0036, -0.0057,  ...,  0.0827,  0.0099,  0.0061],
        [ 0.0234,  0.0101,  0.0093,  ..., -0.0026,  0.0665, -0.0107],
        [-0.0005,  0.0236, -0.0112,  ...,  0.0115, -0.0237,  0.0717]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6826, -2.6582,  1.3965,  ..., -3.7969, -0.7959, -1.2812]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 04:22:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for tchaikovsky was russian
balzac was french
wagner was german
stalin was soviet
caesar was roman
edison was american
descartes was french
hume was
2024-07-27 04:22:51 root INFO     [order_1_approx] starting weight calculation for balzac was french
caesar was roman
wagner was german
hume was scottish
descartes was french
stalin was soviet
edison was american
tchaikovsky was
2024-07-27 04:22:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 04:25:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1201, -0.4629, -0.6216,  ...,  0.1995, -0.2360, -0.1129],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9331, -2.9648, -0.8389,  ..., -5.6875, -0.6689, -2.3438],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0473, -0.0066,  0.0079,  ..., -0.0244,  0.0033, -0.0151],
        [ 0.0169,  0.0417,  0.0203,  ...,  0.0002,  0.0099, -0.0116],
        [ 0.0043,  0.0016,  0.0440,  ...,  0.0086, -0.0029,  0.0127],
        ...,
        [ 0.0168, -0.0014, -0.0152,  ...,  0.0354, -0.0040, -0.0050],
        [ 0.0182,  0.0077,  0.0056,  ..., -0.0143,  0.0300, -0.0016],
        [-0.0067, -0.0017, -0.0032,  ...,  0.0055, -0.0052,  0.0292]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2119, -2.8281, -0.9150,  ..., -5.4414, -0.8066, -2.2129]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 04:25:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for balzac was french
caesar was roman
wagner was german
hume was scottish
descartes was french
stalin was soviet
edison was american
tchaikovsky was
2024-07-27 04:25:12 root INFO     total operator prediction time: 1121.2497613430023 seconds
2024-07-27 04:25:12 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on UK_city - county
2024-07-27 04:25:12 root INFO     building operator UK_city - county
2024-07-27 04:25:13 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of winchester is in the county of hampshire
In the United Kingdom, the city of chester is in the county of cheshire
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of cambridge is in the county of cambridgeshire
In the United Kingdom, the city of norwich is in the county of norfolk
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of wolverhampton is in the county of midlands
In the United Kingdom, the city of lancaster is in the county of
2024-07-27 04:25:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 04:27:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4966,  0.0227, -0.4229,  ...,  0.4258, -0.6421,  0.2888],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0293, -4.4297,  2.7852,  ..., -5.0664,  2.7852,  1.0117],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0214,  0.0051,  0.0032,  ..., -0.0107, -0.0009, -0.0126],
        [ 0.0026,  0.0139,  0.0047,  ...,  0.0008, -0.0051,  0.0008],
        [-0.0109,  0.0143,  0.0298,  ...,  0.0164, -0.0031, -0.0151],
        ...,
        [ 0.0013,  0.0010, -0.0071,  ...,  0.0231,  0.0131,  0.0009],
        [-0.0015, -0.0022,  0.0044,  ...,  0.0160,  0.0043, -0.0131],
        [-0.0019, -0.0147, -0.0097,  ..., -0.0087, -0.0118,  0.0105]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8965, -4.5273,  2.6641,  ..., -4.9062,  2.8320,  0.9482]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 04:27:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of winchester is in the county of hampshire
In the United Kingdom, the city of chester is in the county of cheshire
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of cambridge is in the county of cambridgeshire
In the United Kingdom, the city of norwich is in the county of norfolk
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of wolverhampton is in the county of midlands
In the United Kingdom, the city of lancaster is in the county of
2024-07-27 04:27:38 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of cambridge is in the county of cambridgeshire
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of norwich is in the county of norfolk
In the United Kingdom, the city of chester is in the county of cheshire
In the United Kingdom, the city of wolverhampton is in the county of midlands
In the United Kingdom, the city of lancaster is in the county of lancashire
In the United Kingdom, the city of winchester is in the county of
2024-07-27 04:27:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 04:30:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3862, -0.2404, -0.3027,  ...,  0.1122, -0.3408,  0.1747],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0664, -6.4141,  0.7891,  ..., -5.0625,  0.6523,  0.3633],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.1606e-02,  1.7792e-02,  1.3748e-02,  ...,  4.6158e-03,
         -1.1070e-02, -1.6693e-02],
        [-2.3422e-02,  2.5253e-02,  1.7258e-02,  ...,  2.4399e-02,
         -1.8112e-02, -1.1925e-02],
        [-1.0559e-02, -9.3460e-04,  2.7283e-02,  ...,  1.1948e-02,
          1.4210e-03, -2.7954e-02],
        ...,
        [ 1.8143e-02,  4.8904e-03, -2.4277e-02,  ...,  1.9257e-02,
          2.2995e-02, -9.9335e-03],
        [ 2.0046e-03, -2.0676e-02,  2.2469e-03,  ...,  2.0905e-02,
          1.0483e-02,  4.6272e-03],
        [-1.1536e-02,  2.6340e-03, -3.9291e-04,  ...,  4.6730e-05,
          1.4015e-02,  4.6768e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0625, -6.3086,  0.6377,  ..., -5.0859,  1.0488,  0.2827]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 04:30:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of cambridge is in the county of cambridgeshire
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of norwich is in the county of norfolk
In the United Kingdom, the city of chester is in the county of cheshire
In the United Kingdom, the city of wolverhampton is in the county of midlands
In the United Kingdom, the city of lancaster is in the county of lancashire
In the United Kingdom, the city of winchester is in the county of
2024-07-27 04:30:02 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of chester is in the county of cheshire
In the United Kingdom, the city of norwich is in the county of norfolk
In the United Kingdom, the city of cambridge is in the county of cambridgeshire
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of lancaster is in the county of lancashire
In the United Kingdom, the city of winchester is in the county of hampshire
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of wolverhampton is in the county of
2024-07-27 04:30:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 04:32:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7485, -0.0640, -0.0902,  ...,  1.0693, -0.4343,  0.4756],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1250, -1.7041, -0.1890,  ..., -2.6797,  3.7949, -0.2480],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-2.0599e-04,  7.3090e-03,  1.9943e-02,  ..., -4.2725e-03,
         -4.3716e-03, -4.4746e-03],
        [-7.0648e-03,  1.1322e-02,  8.7814e-03,  ..., -8.5678e-03,
         -2.1347e-02, -1.6022e-02],
        [ 3.9024e-03, -5.1880e-04,  3.3508e-02,  ...,  9.6054e-03,
          2.3499e-03, -1.0406e-02],
        ...,
        [ 1.3092e-02,  4.4823e-03, -4.4060e-03,  ...,  2.1835e-02,
          5.3120e-04, -6.5308e-03],
        [-1.8954e-05,  4.2801e-03,  1.2512e-02,  ...,  1.4565e-02,
          1.9875e-03, -8.2703e-03],
        [-1.2350e-03,  2.7370e-04, -6.4888e-03,  ..., -7.8201e-03,
         -1.6586e-02,  9.0485e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.2031, -1.5732, -0.4683,  ..., -2.6953,  3.8164, -0.5459]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 04:32:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of chester is in the county of cheshire
In the United Kingdom, the city of norwich is in the county of norfolk
In the United Kingdom, the city of cambridge is in the county of cambridgeshire
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of lancaster is in the county of lancashire
In the United Kingdom, the city of winchester is in the county of hampshire
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of wolverhampton is in the county of
2024-07-27 04:32:27 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of chester is in the county of cheshire
In the United Kingdom, the city of lancaster is in the county of lancashire
In the United Kingdom, the city of cambridge is in the county of cambridgeshire
In the United Kingdom, the city of wolverhampton is in the county of midlands
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of norwich is in the county of norfolk
In the United Kingdom, the city of winchester is in the county of hampshire
In the United Kingdom, the city of aberdeen is in the county of
2024-07-27 04:32:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 04:34:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4888, -0.1826, -0.3733,  ...,  0.3254, -0.0322,  0.2686],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2539, -5.7969,  0.9722,  ..., -5.4609, -1.3125, -1.7930],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 8.7585e-03, -4.7188e-03,  9.4223e-03,  ...,  9.3079e-04,
          5.4359e-05,  3.6812e-04],
        [-6.9809e-03,  1.1665e-02,  3.7384e-03,  ..., -4.0817e-04,
          1.0357e-03, -4.1695e-03],
        [-1.3351e-03,  7.7820e-03,  2.9510e-02,  ...,  1.6678e-02,
          2.0504e-03,  6.8188e-04],
        ...,
        [ 4.1580e-03,  1.3742e-03, -1.1742e-02,  ...,  2.0508e-02,
          1.0025e-02, -7.8888e-03],
        [ 2.8362e-03, -1.8478e-02,  5.9738e-03,  ...,  1.7262e-03,
         -1.0595e-03,  3.0727e-03],
        [ 1.6336e-03,  2.0065e-03, -9.9945e-03,  ..., -1.8349e-03,
          4.1962e-04,  1.8738e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3643, -6.0820,  0.8472,  ..., -5.2383, -1.1270, -1.8047]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 04:34:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of chester is in the county of cheshire
In the United Kingdom, the city of lancaster is in the county of lancashire
In the United Kingdom, the city of cambridge is in the county of cambridgeshire
In the United Kingdom, the city of wolverhampton is in the county of midlands
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of norwich is in the county of norfolk
In the United Kingdom, the city of winchester is in the county of hampshire
In the United Kingdom, the city of aberdeen is in the county of
2024-07-27 04:34:52 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of wolverhampton is in the county of midlands
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of winchester is in the county of hampshire
In the United Kingdom, the city of lancaster is in the county of lancashire
In the United Kingdom, the city of chester is in the county of cheshire
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of cambridge is in the county of cambridgeshire
In the United Kingdom, the city of norwich is in the county of
2024-07-27 04:34:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 04:37:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5010, -0.2944, -0.1357,  ...,  0.1971, -0.0473,  0.1331],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1621, -0.9873,  1.5391,  ..., -3.8555, -1.1875, -1.1299],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-7.4959e-04,  8.2245e-03,  1.4381e-02,  ..., -1.0765e-02,
          3.1776e-03,  2.5330e-03],
        [-8.4381e-03,  3.3203e-02, -4.1542e-03,  ...,  5.8174e-05,
          8.9493e-03, -6.8474e-03],
        [-3.9825e-03,  9.2621e-03,  3.3417e-02,  ...,  2.0599e-02,
          3.9101e-03, -7.0267e-03],
        ...,
        [ 2.0584e-02,  1.5991e-02, -1.3321e-02,  ...,  3.2898e-02,
          5.4817e-03,  4.9629e-03],
        [-1.8616e-03, -2.0340e-02,  2.1477e-03,  ...,  1.0704e-02,
          3.3684e-03, -6.9427e-03],
        [-1.9073e-02,  4.7073e-03, -6.0730e-03,  ..., -1.4801e-02,
          3.5248e-03,  1.1414e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2207, -1.0469,  1.1426,  ..., -3.9766, -1.1084, -0.6958]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 04:37:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of wolverhampton is in the county of midlands
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of winchester is in the county of hampshire
In the United Kingdom, the city of lancaster is in the county of lancashire
In the United Kingdom, the city of chester is in the county of cheshire
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of cambridge is in the county of cambridgeshire
In the United Kingdom, the city of norwich is in the county of
2024-07-27 04:37:17 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of norwich is in the county of norfolk
In the United Kingdom, the city of winchester is in the county of hampshire
In the United Kingdom, the city of chester is in the county of cheshire
In the United Kingdom, the city of wolverhampton is in the county of midlands
In the United Kingdom, the city of cambridge is in the county of cambridgeshire
In the United Kingdom, the city of lancaster is in the county of lancashire
In the United Kingdom, the city of newcastle is in the county of
2024-07-27 04:37:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 04:39:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5879,  0.2876, -0.2021,  ...,  0.4941, -0.2554,  0.3843],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.2461, -3.7734,  1.9229,  ..., -3.0508, -2.3477, -0.8218],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0370, -0.0070,  0.0101,  ...,  0.0023, -0.0079, -0.0190],
        [ 0.0004,  0.0159,  0.0188,  ...,  0.0027,  0.0110, -0.0102],
        [-0.0086, -0.0015,  0.0353,  ...,  0.0270,  0.0045, -0.0178],
        ...,
        [ 0.0005, -0.0117, -0.0144,  ...,  0.0264,  0.0006, -0.0025],
        [ 0.0266, -0.0139, -0.0189,  ...,  0.0061,  0.0141, -0.0009],
        [ 0.0070, -0.0068, -0.0212,  ..., -0.0217, -0.0227,  0.0225]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.6836, -3.7695,  1.4082,  ..., -3.1270, -1.7656, -0.9077]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 04:39:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of norwich is in the county of norfolk
In the United Kingdom, the city of winchester is in the county of hampshire
In the United Kingdom, the city of chester is in the county of cheshire
In the United Kingdom, the city of wolverhampton is in the county of midlands
In the United Kingdom, the city of cambridge is in the county of cambridgeshire
In the United Kingdom, the city of lancaster is in the county of lancashire
In the United Kingdom, the city of newcastle is in the county of
2024-07-27 04:39:41 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of chester is in the county of cheshire
In the United Kingdom, the city of winchester is in the county of hampshire
In the United Kingdom, the city of lancaster is in the county of lancashire
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of norwich is in the county of norfolk
In the United Kingdom, the city of wolverhampton is in the county of midlands
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of cambridge is in the county of
2024-07-27 04:39:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 04:42:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4702, -0.3477, -0.4431,  ...,  0.1465, -0.2769,  0.4023],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2344, -5.0469, -0.0807,  ..., -5.5703, -2.0176,  1.8496],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.3496e-02, -2.0538e-02,  4.2076e-03,  ..., -1.0918e-02,
         -2.2888e-02, -4.3716e-03],
        [-1.3306e-02,  1.5259e-02,  1.0773e-02,  ...,  6.1035e-05,
          9.7504e-03, -1.7136e-02],
        [-1.7242e-02,  2.2278e-02,  2.7252e-02,  ...,  1.3702e-02,
          6.9046e-03,  1.2619e-02],
        ...,
        [ 9.7504e-03, -2.8305e-03, -7.9041e-03,  ...,  3.4973e-02,
          1.3489e-02, -1.4091e-02],
        [-1.2451e-02,  3.5229e-03, -1.5915e-02,  ...,  1.0674e-02,
          1.1086e-02,  7.9956e-03],
        [-1.0872e-03, -9.7275e-03,  1.4067e-03,  ..., -3.2978e-03,
         -1.4984e-02,  1.4763e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1641, -5.0391, -0.3804,  ..., -5.3906, -2.0020,  1.9004]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 04:42:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of chester is in the county of cheshire
In the United Kingdom, the city of winchester is in the county of hampshire
In the United Kingdom, the city of lancaster is in the county of lancashire
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of norwich is in the county of norfolk
In the United Kingdom, the city of wolverhampton is in the county of midlands
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of cambridge is in the county of
2024-07-27 04:42:06 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of norwich is in the county of norfolk
In the United Kingdom, the city of winchester is in the county of hampshire
In the United Kingdom, the city of lancaster is in the county of lancashire
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of cambridge is in the county of cambridgeshire
In the United Kingdom, the city of wolverhampton is in the county of midlands
In the United Kingdom, the city of chester is in the county of
2024-07-27 04:42:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 04:44:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3269, -0.0360,  0.0339,  ...,  0.3667, -0.1765,  0.3662],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.5625, -4.6641,  0.9497,  ..., -3.4258,  1.0781, -0.9878],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0260,  0.0016, -0.0038,  ..., -0.0086, -0.0200, -0.0082],
        [ 0.0026,  0.0421,  0.0093,  ...,  0.0255, -0.0186, -0.0093],
        [-0.0263, -0.0120,  0.0486,  ...,  0.0265,  0.0004, -0.0278],
        ...,
        [ 0.0205, -0.0126, -0.0129,  ...,  0.0390,  0.0175, -0.0101],
        [-0.0386, -0.0052, -0.0026,  ...,  0.0102, -0.0071,  0.0057],
        [ 0.0124, -0.0043, -0.0108,  ..., -0.0121, -0.0250,  0.0039]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.6289, -4.6680,  0.7236,  ..., -3.3125,  1.2852, -0.5928]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 04:44:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of norwich is in the county of norfolk
In the United Kingdom, the city of winchester is in the county of hampshire
In the United Kingdom, the city of lancaster is in the county of lancashire
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of cambridge is in the county of cambridgeshire
In the United Kingdom, the city of wolverhampton is in the county of midlands
In the United Kingdom, the city of chester is in the county of
2024-07-27 04:44:31 root INFO     total operator prediction time: 1158.3382184505463 seconds
2024-07-27 04:44:31 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+ment_irreg
2024-07-27 04:44:31 root INFO     building operator verb+ment_irreg
2024-07-27 04:44:31 root INFO     [order_1_approx] starting weight calculation for To reinforce results in a reinforcement
To appoint results in a appointment
To require results in a requirement
To advertise results in a advertisement
To assess results in a assessment
To enlighten results in a enlightenment
To announce results in a announcement
To redevelop results in a
2024-07-27 04:44:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 04:46:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1709,  0.2163, -0.8599,  ...,  0.1390, -0.0056, -0.3560],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5879, -4.4844,  1.5596,  ...,  2.4766, -1.9287, -3.2422],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0692,  0.0152,  0.0092,  ...,  0.0031,  0.0069,  0.0218],
        [ 0.0130,  0.0977,  0.0326,  ...,  0.0230,  0.0353, -0.0039],
        [ 0.0046, -0.0039,  0.0491,  ..., -0.0043,  0.0121, -0.0105],
        ...,
        [-0.0083, -0.0100,  0.0075,  ...,  0.0926,  0.0022,  0.0165],
        [-0.0097, -0.0003,  0.0256,  ...,  0.0146,  0.0507, -0.0004],
        [ 0.0057, -0.0013, -0.0032,  ...,  0.0057, -0.0097,  0.0688]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7607, -4.0742,  1.4805,  ...,  2.8535, -1.8271, -3.1719]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 04:46:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To reinforce results in a reinforcement
To appoint results in a appointment
To require results in a requirement
To advertise results in a advertisement
To assess results in a assessment
To enlighten results in a enlightenment
To announce results in a announcement
To redevelop results in a
2024-07-27 04:46:49 root INFO     [order_1_approx] starting weight calculation for To announce results in a announcement
To enlighten results in a enlightenment
To require results in a requirement
To assess results in a assessment
To redevelop results in a redevelopment
To reinforce results in a reinforcement
To advertise results in a advertisement
To appoint results in a
2024-07-27 04:46:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 04:49:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2117,  0.7236, -0.3091,  ...,  0.1862, -0.3198, -0.2181],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4531, -3.6348,  1.0000,  ...,  4.2812, -2.7754, -2.2051],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0342, -0.0164, -0.0117,  ..., -0.0315,  0.0151,  0.0015],
        [ 0.0258,  0.0720,  0.0222,  ...,  0.0692,  0.0056,  0.0016],
        [ 0.0096, -0.0140,  0.0302,  ..., -0.0086, -0.0096, -0.0181],
        ...,
        [-0.0160,  0.0148, -0.0030,  ...,  0.0415,  0.0003,  0.0242],
        [ 0.0054, -0.0018,  0.0180,  ...,  0.0015,  0.0262, -0.0182],
        [ 0.0109,  0.0077,  0.0012,  ...,  0.0185, -0.0194,  0.0566]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4395, -2.9785,  1.1602,  ...,  3.6797, -2.8418, -2.8887]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 04:49:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To announce results in a announcement
To enlighten results in a enlightenment
To require results in a requirement
To assess results in a assessment
To redevelop results in a redevelopment
To reinforce results in a reinforcement
To advertise results in a advertisement
To appoint results in a
2024-07-27 04:49:07 root INFO     [order_1_approx] starting weight calculation for To assess results in a assessment
To announce results in a announcement
To reinforce results in a reinforcement
To require results in a requirement
To enlighten results in a enlightenment
To appoint results in a appointment
To redevelop results in a redevelopment
To advertise results in a
2024-07-27 04:49:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 04:51:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2450,  0.2490, -0.1271,  ...,  0.0527, -0.1543, -0.4927],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2051, -2.4180,  1.6826,  ...,  3.9414, -2.5801, -1.5938],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0379,  0.0044, -0.0052,  ..., -0.0024, -0.0182,  0.0091],
        [-0.0019,  0.0267,  0.0011,  ...,  0.0260,  0.0166,  0.0103],
        [ 0.0035, -0.0097,  0.0177,  ..., -0.0063, -0.0063, -0.0124],
        ...,
        [-0.0099, -0.0087,  0.0077,  ...,  0.0289,  0.0107,  0.0119],
        [-0.0010,  0.0143,  0.0205,  ..., -0.0015,  0.0220, -0.0067],
        [-0.0072, -0.0052, -0.0066,  ...,  0.0062, -0.0133,  0.0238]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9590, -2.1074,  1.6670,  ...,  3.5703, -2.4336, -1.8076]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 04:51:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To assess results in a assessment
To announce results in a announcement
To reinforce results in a reinforcement
To require results in a requirement
To enlighten results in a enlightenment
To appoint results in a appointment
To redevelop results in a redevelopment
To advertise results in a
2024-07-27 04:51:30 root INFO     [order_1_approx] starting weight calculation for To enlighten results in a enlightenment
To advertise results in a advertisement
To reinforce results in a reinforcement
To announce results in a announcement
To assess results in a assessment
To redevelop results in a redevelopment
To appoint results in a appointment
To require results in a
2024-07-27 04:51:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 04:53:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4954,  0.1552, -0.2917,  ..., -0.0698, -0.0511, -0.1644],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7656, -4.0547, -0.1445,  ...,  1.1367, -3.3125, -2.2988],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0355, -0.0826, -0.0309,  ..., -0.0819, -0.0160, -0.0151],
        [ 0.0558,  0.1266,  0.0321,  ...,  0.1070, -0.0148,  0.0420],
        [-0.0242, -0.0301,  0.0156,  ..., -0.0360,  0.0005,  0.0018],
        ...,
        [ 0.0463,  0.0555,  0.0344,  ...,  0.0983,  0.0136,  0.0330],
        [ 0.0138, -0.0070,  0.0295,  ..., -0.0006,  0.0295, -0.0391],
        [ 0.0367,  0.0208,  0.0304,  ...,  0.0343, -0.0221,  0.0603]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1465, -3.9004, -0.4097,  ...,  1.6719, -3.2012, -2.1855]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 04:53:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To enlighten results in a enlightenment
To advertise results in a advertisement
To reinforce results in a reinforcement
To announce results in a announcement
To assess results in a assessment
To redevelop results in a redevelopment
To appoint results in a appointment
To require results in a
2024-07-27 04:53:52 root INFO     [order_1_approx] starting weight calculation for To assess results in a assessment
To appoint results in a appointment
To require results in a requirement
To reinforce results in a reinforcement
To redevelop results in a redevelopment
To enlighten results in a enlightenment
To advertise results in a advertisement
To announce results in a
2024-07-27 04:53:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 04:56:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0910,  0.4812, -0.3005,  ..., -0.0716, -0.5259, -0.0898],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3008, -3.7617,  1.4951,  ...,  3.8398, -3.0000, -0.1084],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0555,  0.0178,  0.0101,  ..., -0.0068, -0.0334,  0.0062],
        [-0.0138,  0.0148, -0.0218,  ...,  0.0415,  0.0186, -0.0008],
        [ 0.0014, -0.0152,  0.0115,  ..., -0.0040, -0.0066, -0.0157],
        ...,
        [-0.0103, -0.0078, -0.0118,  ...,  0.0351, -0.0023,  0.0078],
        [-0.0027,  0.0132,  0.0298,  ..., -0.0027,  0.0253, -0.0115],
        [ 0.0034, -0.0141, -0.0180,  ...,  0.0012, -0.0230,  0.0422]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9219, -3.3105,  1.6602,  ...,  3.7871, -2.8145, -0.6001]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 04:56:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To assess results in a assessment
To appoint results in a appointment
To require results in a requirement
To reinforce results in a reinforcement
To redevelop results in a redevelopment
To enlighten results in a enlightenment
To advertise results in a advertisement
To announce results in a
2024-07-27 04:56:12 root INFO     [order_1_approx] starting weight calculation for To redevelop results in a redevelopment
To require results in a requirement
To assess results in a assessment
To appoint results in a appointment
To announce results in a announcement
To advertise results in a advertisement
To enlighten results in a enlightenment
To reinforce results in a
2024-07-27 04:56:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 04:58:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2090,  0.2852, -0.0912,  ...,  0.2847, -0.0796,  0.0707],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5117, -3.3750,  3.0957,  ...,  4.0781, -2.2090, -4.2422],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0804,  0.0025,  0.0057,  ...,  0.0055, -0.0145,  0.0188],
        [-0.0053,  0.0905,  0.0113,  ...,  0.0234,  0.0181, -0.0030],
        [ 0.0069, -0.0031,  0.0433,  ...,  0.0107,  0.0040,  0.0052],
        ...,
        [ 0.0005, -0.0009, -0.0017,  ...,  0.0696,  0.0046,  0.0077],
        [-0.0072,  0.0059,  0.0076,  ..., -0.0131,  0.0584, -0.0072],
        [-0.0150, -0.0069,  0.0093,  ...,  0.0153, -0.0141,  0.0518]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1758, -3.3613,  3.3047,  ...,  3.6621, -2.1172, -4.1836]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 04:58:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To redevelop results in a redevelopment
To require results in a requirement
To assess results in a assessment
To appoint results in a appointment
To announce results in a announcement
To advertise results in a advertisement
To enlighten results in a enlightenment
To reinforce results in a
2024-07-27 04:58:36 root INFO     [order_1_approx] starting weight calculation for To reinforce results in a reinforcement
To advertise results in a advertisement
To redevelop results in a redevelopment
To announce results in a announcement
To enlighten results in a enlightenment
To require results in a requirement
To appoint results in a appointment
To assess results in a
2024-07-27 04:58:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 05:00:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3379,  0.2598, -0.4004,  ..., -0.0235, -0.2168, -0.2424],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4121, -2.6602,  0.6348,  ...,  3.0664, -2.9727, -1.7656],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0422,  0.0029,  0.0052,  ..., -0.0084, -0.0113, -0.0017],
        [ 0.0303,  0.0735,  0.0271,  ...,  0.0396,  0.0226,  0.0152],
        [ 0.0125, -0.0150,  0.0464,  ..., -0.0066,  0.0141, -0.0148],
        ...,
        [ 0.0059,  0.0067,  0.0020,  ...,  0.0674,  0.0208,  0.0057],
        [-0.0384, -0.0025,  0.0180,  ...,  0.0215,  0.0341, -0.0133],
        [ 0.0061, -0.0119,  0.0031,  ..., -0.0044, -0.0108,  0.0463]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8477, -2.6465,  0.4385,  ...,  3.8438, -3.5215, -1.2861]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 05:00:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To reinforce results in a reinforcement
To advertise results in a advertisement
To redevelop results in a redevelopment
To announce results in a announcement
To enlighten results in a enlightenment
To require results in a requirement
To appoint results in a appointment
To assess results in a
2024-07-27 05:00:59 root INFO     [order_1_approx] starting weight calculation for To redevelop results in a redevelopment
To require results in a requirement
To reinforce results in a reinforcement
To assess results in a assessment
To advertise results in a advertisement
To appoint results in a appointment
To announce results in a announcement
To enlighten results in a
2024-07-27 05:00:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 05:03:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0171,  0.5762, -0.3457,  ...,  0.1707, -0.4788,  0.1401],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7227, -1.0508,  2.4805,  ...,  5.1562, -2.7559, -2.1777],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0432,  0.0115, -0.0042,  ..., -0.0087, -0.0113,  0.0034],
        [-0.0079,  0.0317,  0.0094,  ...,  0.0307,  0.0083,  0.0022],
        [ 0.0045, -0.0145,  0.0370,  ..., -0.0038,  0.0108, -0.0043],
        ...,
        [-0.0090, -0.0101, -0.0137,  ...,  0.0524,  0.0090,  0.0105],
        [ 0.0053,  0.0031,  0.0149,  ..., -0.0035,  0.0218,  0.0005],
        [-0.0063, -0.0057, -0.0021,  ...,  0.0123, -0.0084,  0.0305]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5889, -1.1406,  2.2793,  ...,  4.8594, -2.7109, -2.3184]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 05:03:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To redevelop results in a redevelopment
To require results in a requirement
To reinforce results in a reinforcement
To assess results in a assessment
To advertise results in a advertisement
To appoint results in a appointment
To announce results in a announcement
To enlighten results in a
2024-07-27 05:03:21 root INFO     total operator prediction time: 1129.906596660614 seconds
2024-07-27 05:03:21 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun+less_reg
2024-07-27 05:03:21 root INFO     building operator noun+less_reg
2024-07-27 05:03:21 root INFO     [order_1_approx] starting weight calculation for Something without bone is boneless
Something without speech is speechless
Something without emotion is emotionless
Something without heir is heirless
Something without god is godless
Something without window is windowless
Something without ego is egoless
Something without error is
2024-07-27 05:03:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 05:05:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0319, -0.2505, -0.0527,  ...,  0.1145,  0.1945,  0.0069],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4893, -2.4355, -3.0391,  ..., -0.1577, -4.1445, -2.3750],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0056, -0.0045,  0.0070,  ..., -0.0090,  0.0090,  0.0284],
        [ 0.0302,  0.0302,  0.0154,  ...,  0.0491, -0.0030,  0.0095],
        [ 0.0196, -0.0137,  0.0397,  ..., -0.0056, -0.0095, -0.0050],
        ...,
        [ 0.0125,  0.0136, -0.0039,  ...,  0.0276,  0.0155,  0.0015],
        [-0.0144,  0.0146, -0.0003,  ..., -0.0269,  0.0279, -0.0112],
        [ 0.0451, -0.0050, -0.0012,  ...,  0.0245, -0.0255,  0.0308]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3862, -2.2832, -2.6348,  ...,  0.0189, -4.1914, -2.1777]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 05:05:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without bone is boneless
Something without speech is speechless
Something without emotion is emotionless
Something without heir is heirless
Something without god is godless
Something without window is windowless
Something without ego is egoless
Something without error is
2024-07-27 05:05:43 root INFO     [order_1_approx] starting weight calculation for Something without god is godless
Something without ego is egoless
Something without emotion is emotionless
Something without window is windowless
Something without heir is heirless
Something without bone is boneless
Something without error is errorless
Something without speech is
2024-07-27 05:05:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 05:07:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0299, -0.1790,  0.3301,  ...,  0.2620,  0.1130,  0.2898],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2891, -2.7578, -1.5693,  ..., -0.2080, -1.3623, -0.0703],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0276, -0.0047, -0.0011,  ...,  0.0181,  0.0230,  0.0169],
        [ 0.0023,  0.0633,  0.0219,  ...,  0.0082, -0.0041,  0.0073],
        [ 0.0332, -0.0141,  0.0260,  ..., -0.0028, -0.0252,  0.0045],
        ...,
        [-0.0064,  0.0118, -0.0049,  ...,  0.0240, -0.0009, -0.0085],
        [ 0.0030,  0.0017, -0.0010,  ..., -0.0265,  0.0256, -0.0220],
        [-0.0051,  0.0054, -0.0010,  ..., -0.0072, -0.0065,  0.0242]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1812, -2.7598, -2.1133,  ..., -0.2155, -1.5850, -0.1572]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 05:07:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without god is godless
Something without ego is egoless
Something without emotion is emotionless
Something without window is windowless
Something without heir is heirless
Something without bone is boneless
Something without error is errorless
Something without speech is
2024-07-27 05:07:59 root INFO     [order_1_approx] starting weight calculation for Something without window is windowless
Something without speech is speechless
Something without bone is boneless
Something without error is errorless
Something without god is godless
Something without emotion is emotionless
Something without heir is heirless
Something without ego is
2024-07-27 05:07:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 05:10:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1764, -0.2871, -0.0856,  ...,  0.0151,  0.2964,  0.2310],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.6543, -2.7598, -0.5327,  ..., -2.4336, -1.4336, -4.0039],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0216, -0.0101, -0.0096,  ..., -0.0002, -0.0028, -0.0048],
        [ 0.0146,  0.0594, -0.0108,  ...,  0.0286, -0.0020,  0.0040],
        [ 0.0368,  0.0022,  0.0568,  ...,  0.0012, -0.0292,  0.0274],
        ...,
        [-0.0064,  0.0113, -0.0130,  ...,  0.0442,  0.0254, -0.0055],
        [-0.0006,  0.0016,  0.0092,  ..., -0.0090,  0.0705, -0.0033],
        [ 0.0304,  0.0110, -0.0008,  ...,  0.0254, -0.0291,  0.0496]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.9004, -2.6797, -1.1484,  ..., -1.9180, -1.1719, -4.1641]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 05:10:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without window is windowless
Something without speech is speechless
Something without bone is boneless
Something without error is errorless
Something without god is godless
Something without emotion is emotionless
Something without heir is heirless
Something without ego is
2024-07-27 05:10:20 root INFO     [order_1_approx] starting weight calculation for Something without error is errorless
Something without god is godless
Something without bone is boneless
Something without window is windowless
Something without speech is speechless
Something without heir is heirless
Something without ego is egoless
Something without emotion is
2024-07-27 05:10:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 05:12:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1836, -0.4280, -0.0997,  ..., -0.1543,  0.0389,  0.3833],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4062, -1.1934, -1.2217,  ..., -3.8926, -1.5889, -3.1172],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0183, -0.0068,  0.0134,  ..., -0.0003,  0.0075,  0.0185],
        [ 0.0067,  0.0440,  0.0092,  ...,  0.0080, -0.0101,  0.0044],
        [-0.0040, -0.0086,  0.0060,  ..., -0.0032, -0.0131, -0.0012],
        ...,
        [ 0.0038,  0.0054, -0.0021,  ...,  0.0218,  0.0165,  0.0022],
        [ 0.0084,  0.0160, -0.0031,  ..., -0.0180,  0.0368, -0.0059],
        [ 0.0145,  0.0086, -0.0069,  ...,  0.0171, -0.0024,  0.0206]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7100, -1.5674, -1.5176,  ..., -3.5586, -1.9707, -2.9023]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 05:12:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without error is errorless
Something without god is godless
Something without bone is boneless
Something without window is windowless
Something without speech is speechless
Something without heir is heirless
Something without ego is egoless
Something without emotion is
2024-07-27 05:12:40 root INFO     [order_1_approx] starting weight calculation for Something without ego is egoless
Something without heir is heirless
Something without error is errorless
Something without window is windowless
Something without speech is speechless
Something without emotion is emotionless
Something without god is godless
Something without bone is
2024-07-27 05:12:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 05:15:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4563, -0.1310, -0.4287,  ...,  0.0823, -0.5903,  0.2634],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5713, -2.1035,  0.3101,  ..., -1.4102, -2.5312, -2.0898],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0504, -0.0003, -0.0133,  ...,  0.0168,  0.0073,  0.0012],
        [ 0.0166,  0.0514,  0.0141,  ...,  0.0080,  0.0154,  0.0078],
        [-0.0087, -0.0145,  0.0261,  ..., -0.0050, -0.0109, -0.0066],
        ...,
        [ 0.0045,  0.0290, -0.0003,  ...,  0.0537,  0.0015, -0.0125],
        [-0.0168, -0.0010,  0.0059,  ..., -0.0134,  0.0608, -0.0313],
        [ 0.0397,  0.0211,  0.0039,  ...,  0.0092, -0.0067,  0.0305]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7803, -1.9453, -0.1699,  ..., -1.3994, -2.6680, -1.7207]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 05:15:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without ego is egoless
Something without heir is heirless
Something without error is errorless
Something without window is windowless
Something without speech is speechless
Something without emotion is emotionless
Something without god is godless
Something without bone is
2024-07-27 05:15:01 root INFO     [order_1_approx] starting weight calculation for Something without error is errorless
Something without ego is egoless
Something without bone is boneless
Something without speech is speechless
Something without heir is heirless
Something without emotion is emotionless
Something without window is windowless
Something without god is
2024-07-27 05:15:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 05:17:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2976,  0.0339, -0.1448,  ..., -0.3545, -0.1343, -0.2244],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0402, -2.8008,  1.3447,  ..., -2.9844, -2.1758,  0.2817],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.0490e-02,  1.6651e-03,  1.7426e-02,  ...,  1.3084e-02,
          8.9417e-03,  8.4305e-03],
        [ 2.3438e-02,  2.8442e-02, -2.2949e-02,  ...,  1.1459e-02,
          3.8242e-03,  4.6921e-03],
        [-2.0004e-02,  1.6041e-03,  3.0182e-02,  ..., -3.5934e-03,
         -2.1572e-03,  1.9054e-03],
        ...,
        [ 1.3329e-02,  9.6436e-03, -5.5771e-03,  ...,  7.0686e-03,
          9.2621e-03,  3.4332e-05],
        [-1.1971e-02,  1.4744e-03,  1.0056e-02,  ..., -6.0539e-03,
          2.2598e-02, -2.1790e-02],
        [ 1.1520e-02,  2.7252e-02, -4.4060e-03,  ...,  4.4174e-03,
         -1.8600e-02,  2.3651e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4429, -2.5371,  0.7158,  ..., -2.0996, -2.6562,  0.3572]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 05:17:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without error is errorless
Something without ego is egoless
Something without bone is boneless
Something without speech is speechless
Something without heir is heirless
Something without emotion is emotionless
Something without window is windowless
Something without god is
2024-07-27 05:17:23 root INFO     [order_1_approx] starting weight calculation for Something without ego is egoless
Something without speech is speechless
Something without emotion is emotionless
Something without god is godless
Something without error is errorless
Something without bone is boneless
Something without heir is heirless
Something without window is
2024-07-27 05:17:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 05:19:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0797, -0.6611, -0.3491,  ...,  0.3894,  0.0172, -0.0020],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7637, -4.2188,  0.3315,  ..., -1.9922, -4.3750,  1.6768],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0222,  0.0042,  0.0038,  ...,  0.0060, -0.0001,  0.0070],
        [ 0.0078,  0.0231,  0.0049,  ...,  0.0045, -0.0048, -0.0176],
        [ 0.0199, -0.0061,  0.0329,  ..., -0.0066, -0.0052,  0.0120],
        ...,
        [-0.0053,  0.0167,  0.0012,  ...,  0.0288,  0.0051,  0.0027],
        [-0.0093,  0.0048, -0.0013,  ..., -0.0139,  0.0482,  0.0069],
        [ 0.0205,  0.0112, -0.0015,  ...,  0.0151, -0.0076,  0.0259]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0752, -4.4688, -0.1418,  ..., -2.2051, -4.5234,  1.3633]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 05:19:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without ego is egoless
Something without speech is speechless
Something without emotion is emotionless
Something without god is godless
Something without error is errorless
Something without bone is boneless
Something without heir is heirless
Something without window is
2024-07-27 05:19:44 root INFO     [order_1_approx] starting weight calculation for Something without ego is egoless
Something without god is godless
Something without window is windowless
Something without bone is boneless
Something without speech is speechless
Something without error is errorless
Something without emotion is emotionless
Something without heir is
2024-07-27 05:19:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 05:22:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1301, -0.1621, -0.3950,  ..., -0.0349,  0.1729, -0.2209],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3340, -1.7100, -0.3923,  ..., -2.2852, -4.6094, -2.8125],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0130, -0.0060,  0.0054,  ..., -0.0037,  0.0083, -0.0098],
        [-0.0021,  0.0247, -0.0288,  ..., -0.0021,  0.0071, -0.0016],
        [-0.0040,  0.0043,  0.0264,  ...,  0.0130,  0.0002,  0.0069],
        ...,
        [ 0.0100, -0.0020, -0.0127,  ...,  0.0211, -0.0019,  0.0016],
        [-0.0102,  0.0097,  0.0059,  ...,  0.0019,  0.0206, -0.0093],
        [ 0.0129,  0.0194,  0.0005,  ...,  0.0060, -0.0098,  0.0249]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5244, -1.6299, -0.4355,  ..., -2.3203, -4.8555, -2.9863]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 05:22:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without ego is egoless
Something without god is godless
Something without window is windowless
Something without bone is boneless
Something without speech is speechless
Something without error is errorless
Something without emotion is emotionless
Something without heir is
2024-07-27 05:22:05 root INFO     total operator prediction time: 1124.0190379619598 seconds
2024-07-27 05:22:05 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj+ness_reg
2024-07-27 05:22:05 root INFO     building operator adj+ness_reg
2024-07-27 05:22:05 root INFO     [order_1_approx] starting weight calculation for The state of being foreign is foreignness
The state of being nice is niceness
The state of being massive is massiveness
The state of being happy is happiness
The state of being cheap is cheapness
The state of being fixed is fixedness
The state of being weak is weakness
The state of being distinctive is
2024-07-27 05:22:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 05:24:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0463,  0.0093, -0.3391,  ...,  0.5020, -0.1072,  0.0753],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9287, -3.2930, -1.0391,  ..., -3.2852, -4.4062, -1.3252],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0475, -0.0161, -0.0031,  ..., -0.0041,  0.0196, -0.0058],
        [-0.0204,  0.0541,  0.0084,  ...,  0.0114,  0.0150, -0.0026],
        [ 0.0111, -0.0123,  0.0392,  ..., -0.0153, -0.0070,  0.0005],
        ...,
        [ 0.0110,  0.0089,  0.0024,  ...,  0.0359,  0.0010, -0.0055],
        [ 0.0117,  0.0101,  0.0153,  ...,  0.0107,  0.0423, -0.0012],
        [ 0.0100,  0.0073, -0.0089,  ...,  0.0104, -0.0290,  0.0315]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0488, -3.0957, -0.8716,  ..., -3.0859, -4.6758, -1.4248]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 05:24:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being foreign is foreignness
The state of being nice is niceness
The state of being massive is massiveness
The state of being happy is happiness
The state of being cheap is cheapness
The state of being fixed is fixedness
The state of being weak is weakness
The state of being distinctive is
2024-07-27 05:24:26 root INFO     [order_1_approx] starting weight calculation for The state of being distinctive is distinctiveness
The state of being massive is massiveness
The state of being nice is niceness
The state of being foreign is foreignness
The state of being weak is weakness
The state of being cheap is cheapness
The state of being happy is happiness
The state of being fixed is
2024-07-27 05:24:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 05:26:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0943, -0.1079, -0.8003,  ...,  0.0341, -0.0168,  0.5073],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8555, -4.1172, -0.5156,  ..., -0.7471, -5.3750, -2.8867],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0724, -0.0063, -0.0036,  ..., -0.0052,  0.0094,  0.0340],
        [-0.0017,  0.0758,  0.0042,  ...,  0.0356,  0.0122,  0.0041],
        [-0.0159, -0.0251,  0.0461,  ..., -0.0102,  0.0003,  0.0150],
        ...,
        [ 0.0163,  0.0047, -0.0137,  ...,  0.0793, -0.0027, -0.0125],
        [ 0.0016,  0.0017, -0.0107,  ..., -0.0073,  0.0771, -0.0292],
        [ 0.0119,  0.0167, -0.0112,  ...,  0.0106, -0.0167,  0.0571]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0391, -3.9492, -0.4709,  ..., -0.5752, -5.2891, -2.9590]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 05:26:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being distinctive is distinctiveness
The state of being massive is massiveness
The state of being nice is niceness
The state of being foreign is foreignness
The state of being weak is weakness
The state of being cheap is cheapness
The state of being happy is happiness
The state of being fixed is
2024-07-27 05:26:48 root INFO     [order_1_approx] starting weight calculation for The state of being massive is massiveness
The state of being happy is happiness
The state of being weak is weakness
The state of being foreign is foreignness
The state of being distinctive is distinctiveness
The state of being cheap is cheapness
The state of being fixed is fixedness
The state of being nice is
2024-07-27 05:26:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 05:29:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1611, -0.0950, -0.2124,  ...,  0.2028, -0.2357, -0.1399],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4297, -1.5176, -3.5898,  ..., -1.7129, -6.8984, -2.0957],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0627, -0.0117, -0.0075,  ..., -0.0133,  0.0035,  0.0326],
        [-0.0054,  0.0314,  0.0103,  ...,  0.0137,  0.0355,  0.0123],
        [ 0.0196, -0.0334,  0.0192,  ...,  0.0043, -0.0020, -0.0071],
        ...,
        [ 0.0149, -0.0052, -0.0111,  ...,  0.0292,  0.0257,  0.0012],
        [-0.0096,  0.0093,  0.0138,  ...,  0.0116,  0.0359, -0.0030],
        [-0.0049,  0.0019, -0.0089,  ..., -0.0021, -0.0308,  0.0255]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6504, -1.7266, -3.8613,  ..., -1.5811, -6.8125, -1.9492]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 05:29:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being massive is massiveness
The state of being happy is happiness
The state of being weak is weakness
The state of being foreign is foreignness
The state of being distinctive is distinctiveness
The state of being cheap is cheapness
The state of being fixed is fixedness
The state of being nice is
2024-07-27 05:29:09 root INFO     [order_1_approx] starting weight calculation for The state of being foreign is foreignness
The state of being happy is happiness
The state of being nice is niceness
The state of being fixed is fixedness
The state of being weak is weakness
The state of being cheap is cheapness
The state of being distinctive is distinctiveness
The state of being massive is
2024-07-27 05:29:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 05:31:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2993,  0.2605, -0.1506,  ...,  0.3708, -0.1553, -0.2351],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6758, -5.1836, -3.4766,  ..., -4.5195, -5.7617, -4.7344],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.1086e-02,  1.5764e-03, -6.7444e-03,  ...,  1.8509e-02,
          5.5695e-04,  1.2138e-02],
        [-5.9853e-03,  5.9784e-02,  2.9068e-03,  ...,  4.9553e-03,
         -2.8133e-05,  6.7444e-03],
        [ 1.6647e-02, -1.1726e-02,  4.9011e-02,  ..., -6.6490e-03,
         -2.3071e-02,  2.5223e-02],
        ...,
        [ 1.0529e-03,  1.3290e-02,  1.6556e-02,  ...,  6.5308e-02,
         -1.0765e-02, -1.2558e-02],
        [ 1.3321e-02,  7.4234e-03, -3.4332e-04,  ...,  3.9673e-04,
          5.3833e-02, -1.9287e-02],
        [ 6.6299e-03,  2.1683e-02, -9.8267e-03,  ...,  4.0550e-03,
         -1.1261e-02,  2.5513e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4424, -5.0820, -3.5098,  ..., -4.3203, -5.6367, -4.7461]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 05:31:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being foreign is foreignness
The state of being happy is happiness
The state of being nice is niceness
The state of being fixed is fixedness
The state of being weak is weakness
The state of being cheap is cheapness
The state of being distinctive is distinctiveness
The state of being massive is
2024-07-27 05:31:29 root INFO     [order_1_approx] starting weight calculation for The state of being cheap is cheapness
The state of being fixed is fixedness
The state of being happy is happiness
The state of being distinctive is distinctiveness
The state of being nice is niceness
The state of being massive is massiveness
The state of being weak is weakness
The state of being foreign is
2024-07-27 05:31:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 05:33:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0244,  0.3484, -0.0338,  ...,  0.0751,  0.2280,  0.0585],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6387, -4.3320,  0.5869,  ..., -3.0742, -3.1094, -1.6973],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0509,  0.0034,  0.0046,  ...,  0.0080,  0.0137,  0.0183],
        [ 0.0133,  0.0440,  0.0005,  ...,  0.0111,  0.0077,  0.0038],
        [-0.0051,  0.0057,  0.0305,  ..., -0.0009,  0.0046,  0.0060],
        ...,
        [-0.0032,  0.0153, -0.0139,  ...,  0.0225,  0.0005, -0.0197],
        [ 0.0021, -0.0016,  0.0013,  ..., -0.0068,  0.0519, -0.0214],
        [ 0.0074,  0.0226, -0.0003,  ..., -0.0012, -0.0187,  0.0403]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9136, -4.2070,  0.5054,  ..., -2.9668, -2.9980, -2.0078]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 05:33:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being cheap is cheapness
The state of being fixed is fixedness
The state of being happy is happiness
The state of being distinctive is distinctiveness
The state of being nice is niceness
The state of being massive is massiveness
The state of being weak is weakness
The state of being foreign is
2024-07-27 05:33:49 root INFO     [order_1_approx] starting weight calculation for The state of being distinctive is distinctiveness
The state of being fixed is fixedness
The state of being nice is niceness
The state of being weak is weakness
The state of being massive is massiveness
The state of being foreign is foreignness
The state of being happy is happiness
The state of being cheap is
2024-07-27 05:33:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 05:36:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0141, -0.1299, -0.3076,  ...,  0.2737, -0.0411, -0.1173],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.1943,  0.1787, -1.7461,  ..., -4.7812, -6.4766, -2.0020],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0530, -0.0130, -0.0129,  ...,  0.0028,  0.0059,  0.0126],
        [ 0.0033,  0.0362,  0.0297,  ...,  0.0048, -0.0034,  0.0205],
        [-0.0006,  0.0086,  0.0356,  ..., -0.0056, -0.0081,  0.0117],
        ...,
        [-0.0025,  0.0173, -0.0006,  ...,  0.0348,  0.0271, -0.0169],
        [-0.0261,  0.0105, -0.0117,  ..., -0.0299,  0.0514, -0.0201],
        [ 0.0125,  0.0111, -0.0231,  ...,  0.0127,  0.0005,  0.0523]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.0977,  0.0132, -1.7402,  ..., -4.4883, -6.1055, -2.1230]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 05:36:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being distinctive is distinctiveness
The state of being fixed is fixedness
The state of being nice is niceness
The state of being weak is weakness
The state of being massive is massiveness
The state of being foreign is foreignness
The state of being happy is happiness
The state of being cheap is
2024-07-27 05:36:12 root INFO     [order_1_approx] starting weight calculation for The state of being happy is happiness
The state of being fixed is fixedness
The state of being massive is massiveness
The state of being nice is niceness
The state of being foreign is foreignness
The state of being distinctive is distinctiveness
The state of being cheap is cheapness
The state of being weak is
2024-07-27 05:36:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 05:38:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2371,  0.0709, -0.1665,  ..., -0.0079, -0.0854,  0.1328],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2871, -4.1641, -1.6934,  ..., -6.1445, -0.7676, -4.0312],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0294,  0.0145,  0.0081,  ..., -0.0086,  0.0030,  0.0218],
        [-0.0016,  0.0171, -0.0087,  ...,  0.0212,  0.0031,  0.0105],
        [ 0.0054, -0.0063,  0.0216,  ..., -0.0008, -0.0111,  0.0073],
        ...,
        [ 0.0095,  0.0128, -0.0046,  ...,  0.0126,  0.0150, -0.0130],
        [-0.0058, -0.0071, -0.0060,  ..., -0.0053,  0.0363, -0.0140],
        [-0.0003,  0.0023, -0.0135,  ..., -0.0068, -0.0094,  0.0081]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9375, -3.8633, -1.6660,  ..., -5.9023, -0.8208, -3.4961]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 05:38:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being happy is happiness
The state of being fixed is fixedness
The state of being massive is massiveness
The state of being nice is niceness
The state of being foreign is foreignness
The state of being distinctive is distinctiveness
The state of being cheap is cheapness
The state of being weak is
2024-07-27 05:38:35 root INFO     [order_1_approx] starting weight calculation for The state of being weak is weakness
The state of being distinctive is distinctiveness
The state of being foreign is foreignness
The state of being cheap is cheapness
The state of being massive is massiveness
The state of being nice is niceness
The state of being fixed is fixedness
The state of being happy is
2024-07-27 05:38:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 05:40:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0533, -0.4585, -0.4380,  ..., -0.0761, -0.2861,  0.0070],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3438, -0.1479,  0.7705,  ..., -2.0293, -4.4297, -2.2617],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0584,  0.0056,  0.0013,  ...,  0.0096, -0.0139,  0.0182],
        [ 0.0071,  0.0410, -0.0047,  ...,  0.0226,  0.0079,  0.0112],
        [-0.0031, -0.0048,  0.0558,  ..., -0.0111, -0.0172, -0.0040],
        ...,
        [ 0.0032, -0.0096,  0.0054,  ...,  0.0239, -0.0118,  0.0103],
        [-0.0110,  0.0111,  0.0122,  ..., -0.0202,  0.0468, -0.0271],
        [ 0.0042, -0.0043, -0.0060,  ...,  0.0018, -0.0189,  0.0630]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3271, -0.5879,  0.3069,  ..., -1.6260, -4.2734, -2.5430]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 05:40:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being weak is weakness
The state of being distinctive is distinctiveness
The state of being foreign is foreignness
The state of being cheap is cheapness
The state of being massive is massiveness
The state of being nice is niceness
The state of being fixed is fixedness
The state of being happy is
2024-07-27 05:40:58 root INFO     total operator prediction time: 1133.0237383842468 seconds
2024-07-27 05:40:58 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on re+verb_reg
2024-07-27 05:40:58 root INFO     building operator re+verb_reg
2024-07-27 05:40:58 root INFO     [order_1_approx] starting weight calculation for To apply again is to reapply
To develop again is to redevelop
To acquire again is to reacquire
To define again is to redefine
To occur again is to reoccur
To upload again is to reupload
To marry again is to remarry
To write again is to
2024-07-27 05:40:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 05:43:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1107, -0.1063, -0.1062,  ..., -0.1087, -0.1797, -0.0704],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8931, -2.7578, -0.3711,  ...,  1.8184, -3.1992, -2.8477],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0385, -0.0133,  0.0170,  ...,  0.0092, -0.0134,  0.0116],
        [ 0.0011,  0.0315, -0.0042,  ...,  0.0022, -0.0172, -0.0110],
        [ 0.0076, -0.0088,  0.0535,  ..., -0.0032, -0.0033,  0.0012],
        ...,
        [ 0.0211,  0.0014,  0.0016,  ...,  0.0558, -0.0084,  0.0016],
        [ 0.0035,  0.0086,  0.0132,  ..., -0.0056,  0.0233, -0.0012],
        [ 0.0022,  0.0171,  0.0011,  ...,  0.0076, -0.0140,  0.0370]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.9907, -3.1074, -0.6323,  ...,  1.8262, -3.2129, -2.7930]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 05:43:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To apply again is to reapply
To develop again is to redevelop
To acquire again is to reacquire
To define again is to redefine
To occur again is to reoccur
To upload again is to reupload
To marry again is to remarry
To write again is to
2024-07-27 05:43:20 root INFO     [order_1_approx] starting weight calculation for To marry again is to remarry
To occur again is to reoccur
To define again is to redefine
To apply again is to reapply
To develop again is to redevelop
To acquire again is to reacquire
To write again is to rewrite
To upload again is to
2024-07-27 05:43:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 05:45:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0993, -0.0250, -0.1393,  ...,  0.2825, -0.0978, -0.1511],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2842, -3.7188,  1.0576,  ...,  2.2285, -3.3711, -2.2578],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0403,  0.0011,  0.0089,  ..., -0.0071,  0.0036,  0.0111],
        [ 0.0078,  0.0325,  0.0052,  ...,  0.0097, -0.0142,  0.0211],
        [ 0.0085, -0.0114,  0.0367,  ..., -0.0094, -0.0101, -0.0125],
        ...,
        [ 0.0170, -0.0228, -0.0074,  ...,  0.0341,  0.0165, -0.0100],
        [-0.0059,  0.0188, -0.0117,  ..., -0.0074,  0.0243, -0.0084],
        [ 0.0048, -0.0090,  0.0024,  ..., -0.0006, -0.0158,  0.0490]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1592, -3.1133,  1.4004,  ...,  3.1953, -3.6367, -2.5645]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 05:45:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To marry again is to remarry
To occur again is to reoccur
To define again is to redefine
To apply again is to reapply
To develop again is to redevelop
To acquire again is to reacquire
To write again is to rewrite
To upload again is to
2024-07-27 05:45:43 root INFO     [order_1_approx] starting weight calculation for To marry again is to remarry
To develop again is to redevelop
To acquire again is to reacquire
To write again is to rewrite
To occur again is to reoccur
To apply again is to reapply
To upload again is to reupload
To define again is to
2024-07-27 05:45:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 05:48:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1224, -0.0806, -0.1089,  ...,  0.2441, -0.0325, -0.1981],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.6895, -2.6445,  0.9097,  ...,  2.4102, -3.1797, -4.0156],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0321, -0.0119,  0.0043,  ..., -0.0161,  0.0020,  0.0071],
        [ 0.0077,  0.0320,  0.0006,  ...,  0.0083, -0.0051,  0.0082],
        [-0.0157, -0.0044,  0.0389,  ...,  0.0053, -0.0060,  0.0019],
        ...,
        [ 0.0162, -0.0157, -0.0012,  ...,  0.0424,  0.0095,  0.0011],
        [-0.0018, -0.0018,  0.0081,  ..., -0.0006,  0.0407, -0.0063],
        [ 0.0030, -0.0013,  0.0027,  ..., -0.0068, -0.0232,  0.0452]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.8955, -2.4277,  0.8350,  ...,  2.7324, -3.1914, -3.6094]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 05:48:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To marry again is to remarry
To develop again is to redevelop
To acquire again is to reacquire
To write again is to rewrite
To occur again is to reoccur
To apply again is to reapply
To upload again is to reupload
To define again is to
2024-07-27 05:48:04 root INFO     [order_1_approx] starting weight calculation for To marry again is to remarry
To write again is to rewrite
To acquire again is to reacquire
To upload again is to reupload
To occur again is to reoccur
To define again is to redefine
To apply again is to reapply
To develop again is to
2024-07-27 05:48:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 05:50:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4292,  0.1183, -0.1174,  ..., -0.1414, -0.1039,  0.0029],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0659, -3.1875,  0.1365,  ...,  2.1211, -4.3984, -4.7031],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0433, -0.0135,  0.0068,  ..., -0.0043, -0.0136,  0.0194],
        [ 0.0111,  0.0643,  0.0055,  ...,  0.0101,  0.0049,  0.0143],
        [ 0.0099, -0.0056,  0.0325,  ..., -0.0065, -0.0048, -0.0068],
        ...,
        [ 0.0118, -0.0088, -0.0047,  ...,  0.0409, -0.0086,  0.0087],
        [-0.0090,  0.0060, -0.0009,  ...,  0.0050,  0.0448, -0.0056],
        [ 0.0092, -0.0007, -0.0031,  ..., -0.0068, -0.0214,  0.0388]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0967, -3.1309,  0.1498,  ...,  2.1172, -4.3633, -4.3438]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 05:50:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To marry again is to remarry
To write again is to rewrite
To acquire again is to reacquire
To upload again is to reupload
To occur again is to reoccur
To define again is to redefine
To apply again is to reapply
To develop again is to
2024-07-27 05:50:26 root INFO     [order_1_approx] starting weight calculation for To apply again is to reapply
To acquire again is to reacquire
To upload again is to reupload
To develop again is to redevelop
To define again is to redefine
To marry again is to remarry
To write again is to rewrite
To occur again is to
2024-07-27 05:50:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 05:52:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2444,  0.0688, -0.4661,  ..., -0.1720, -0.0079, -0.5605],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-3.0352, -2.3125,  0.7993,  ...,  0.5107, -1.8291, -0.7627],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0745,  0.0008,  0.0140,  ..., -0.0002, -0.0003,  0.0218],
        [-0.0152,  0.0496,  0.0056,  ...,  0.0110, -0.0056, -0.0007],
        [ 0.0067,  0.0018,  0.0429,  ..., -0.0233,  0.0042, -0.0178],
        ...,
        [ 0.0135,  0.0029,  0.0010,  ...,  0.0609,  0.0033, -0.0044],
        [-0.0108, -0.0014,  0.0204,  ..., -0.0208,  0.0526, -0.0292],
        [ 0.0025,  0.0011, -0.0162,  ..., -0.0217, -0.0202,  0.0576]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-3.4238, -2.5488,  1.1309,  ...,  0.9893, -2.0820, -0.9248]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 05:52:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To apply again is to reapply
To acquire again is to reacquire
To upload again is to reupload
To develop again is to redevelop
To define again is to redefine
To marry again is to remarry
To write again is to rewrite
To occur again is to
2024-07-27 05:52:47 root INFO     [order_1_approx] starting weight calculation for To define again is to redefine
To write again is to rewrite
To occur again is to reoccur
To marry again is to remarry
To upload again is to reupload
To develop again is to redevelop
To apply again is to reapply
To acquire again is to
2024-07-27 05:52:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 05:55:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1963,  0.4429, -0.5928,  ...,  0.3186,  0.0161,  0.0732],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.1484, -1.9775, -1.5508,  ...,  2.1875, -4.2695, -2.9766],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0490, -0.0008,  0.0117,  ...,  0.0031, -0.0035,  0.0215],
        [ 0.0053,  0.0389, -0.0109,  ...,  0.0085,  0.0015, -0.0008],
        [ 0.0145,  0.0035,  0.0406,  ..., -0.0037, -0.0032,  0.0062],
        ...,
        [ 0.0119, -0.0045, -0.0091,  ...,  0.0464,  0.0206, -0.0168],
        [-0.0098,  0.0152,  0.0039,  ..., -0.0022,  0.0429, -0.0170],
        [ 0.0016,  0.0033,  0.0009,  ..., -0.0102, -0.0104,  0.0363]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.0557, -2.1152, -1.4590,  ...,  2.3828, -4.1289, -2.9844]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 05:55:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To define again is to redefine
To write again is to rewrite
To occur again is to reoccur
To marry again is to remarry
To upload again is to reupload
To develop again is to redevelop
To apply again is to reapply
To acquire again is to
2024-07-27 05:55:07 root INFO     [order_1_approx] starting weight calculation for To write again is to rewrite
To apply again is to reapply
To define again is to redefine
To develop again is to redevelop
To upload again is to reupload
To acquire again is to reacquire
To occur again is to reoccur
To marry again is to
2024-07-27 05:55:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 05:57:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1812,  0.1852, -0.1521,  ..., -0.1238, -0.4414,  0.2217],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9897, -1.8672,  0.3374,  ..., -0.8091, -1.7119, -3.8945],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.0457e-02,  2.8667e-03,  2.0294e-02,  ...,  3.3989e-03,
         -1.5945e-02,  3.2921e-03],
        [ 4.7684e-05,  3.3234e-02, -1.0712e-02,  ...,  1.0445e-02,
          2.6321e-03,  1.2817e-03],
        [ 1.9379e-02,  1.4896e-03,  3.0396e-02,  ..., -1.4473e-02,
         -2.3819e-02,  2.3804e-02],
        ...,
        [ 3.1929e-03,  7.5378e-03, -3.0613e-03,  ...,  3.9429e-02,
          7.2212e-03, -6.9580e-03],
        [ 1.3817e-02,  7.9346e-03,  7.1945e-03,  ..., -5.0201e-03,
          1.9424e-02,  3.4180e-03],
        [ 3.5782e-03, -3.2253e-03, -1.0284e-02,  ..., -3.1242e-03,
         -1.5671e-02,  3.7842e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8633, -1.8633, -0.1226,  ..., -0.4268, -1.6768, -3.8652]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 05:57:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To write again is to rewrite
To apply again is to reapply
To define again is to redefine
To develop again is to redevelop
To upload again is to reupload
To acquire again is to reacquire
To occur again is to reoccur
To marry again is to
2024-07-27 05:57:30 root INFO     [order_1_approx] starting weight calculation for To upload again is to reupload
To develop again is to redevelop
To marry again is to remarry
To acquire again is to reacquire
To define again is to redefine
To occur again is to reoccur
To write again is to rewrite
To apply again is to
2024-07-27 05:57:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 05:59:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3135, -0.2324,  0.0454,  ...,  0.1292, -0.2271, -0.0630],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0469, -2.3730, -0.8799,  ...,  3.2734, -3.8965, -4.0078],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0760, -0.0245,  0.0328,  ...,  0.0181, -0.0287,  0.0230],
        [-0.0016,  0.0391,  0.0146,  ...,  0.0119, -0.0207,  0.0185],
        [ 0.0037, -0.0045,  0.0623,  ..., -0.0134,  0.0214,  0.0190],
        ...,
        [ 0.0188, -0.0163, -0.0132,  ...,  0.0807,  0.0136, -0.0013],
        [-0.0199, -0.0006, -0.0192,  ..., -0.0236,  0.0425, -0.0457],
        [-0.0107,  0.0034, -0.0046,  ..., -0.0092, -0.0276,  0.0583]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.6914, -2.8418, -0.4614,  ...,  3.2109, -3.3457, -3.8867]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 05:59:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To upload again is to reupload
To develop again is to redevelop
To marry again is to remarry
To acquire again is to reacquire
To define again is to redefine
To occur again is to reoccur
To write again is to rewrite
To apply again is to
2024-07-27 05:59:50 root INFO     total operator prediction time: 1131.8858058452606 seconds
2024-07-27 05:59:50 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on un+adj_reg
2024-07-27 05:59:50 root INFO     building operator un+adj_reg
2024-07-27 05:59:50 root INFO     [order_1_approx] starting weight calculation for The opposite of avoidable is unavoidable
The opposite of intended is unintended
The opposite of available is unavailable
The opposite of expected is unexpected
The opposite of reasonable is unreasonable
The opposite of usual is unusual
The opposite of related is unrelated
The opposite of comfortable is
2024-07-27 05:59:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 06:02:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2365, -0.1760, -0.1086,  ..., -0.3110, -0.2109,  0.4087],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7051, -0.2188,  1.6426,  ..., -0.9980,  0.6943,  1.0127],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0738,  0.0018, -0.0033,  ..., -0.0013, -0.0061,  0.0189],
        [ 0.0008,  0.0811, -0.0132,  ...,  0.0118,  0.0202, -0.0009],
        [-0.0019, -0.0086,  0.0469,  ...,  0.0165, -0.0146,  0.0179],
        ...,
        [ 0.0198,  0.0283, -0.0273,  ...,  0.0564,  0.0061, -0.0137],
        [-0.0258, -0.0023,  0.0177,  ..., -0.0144,  0.0539,  0.0032],
        [-0.0289, -0.0185, -0.0179,  ...,  0.0220, -0.0056,  0.0735]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4277, -0.4087,  1.1621,  ..., -0.6807,  0.2468,  0.9375]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 06:02:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of avoidable is unavoidable
The opposite of intended is unintended
The opposite of available is unavailable
The opposite of expected is unexpected
The opposite of reasonable is unreasonable
The opposite of usual is unusual
The opposite of related is unrelated
The opposite of comfortable is
2024-07-27 06:02:14 root INFO     [order_1_approx] starting weight calculation for The opposite of intended is unintended
The opposite of related is unrelated
The opposite of avoidable is unavoidable
The opposite of usual is unusual
The opposite of comfortable is uncomfortable
The opposite of expected is unexpected
The opposite of available is unavailable
The opposite of reasonable is
2024-07-27 06:02:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 06:04:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0536,  0.1516, -0.1309,  ..., -0.5381, -0.0623, -0.0059],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8438, -1.4883,  0.2251,  ..., -1.4951, -3.6660, -4.4688],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0605,  0.0203,  0.0051,  ..., -0.0014, -0.0142,  0.0115],
        [ 0.0153,  0.0410, -0.0148,  ...,  0.0085,  0.0282,  0.0053],
        [-0.0024,  0.0018,  0.0403,  ...,  0.0034, -0.0356,  0.0060],
        ...,
        [ 0.0064,  0.0100,  0.0101,  ...,  0.0452,  0.0167,  0.0066],
        [-0.0106,  0.0233,  0.0203,  ..., -0.0065,  0.0692, -0.0136],
        [ 0.0206,  0.0003, -0.0129,  ..., -0.0188, -0.0256,  0.0388]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5840, -1.6709,  0.0306,  ..., -1.0098, -3.5215, -4.3008]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 06:04:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of intended is unintended
The opposite of related is unrelated
The opposite of avoidable is unavoidable
The opposite of usual is unusual
The opposite of comfortable is uncomfortable
The opposite of expected is unexpected
The opposite of available is unavailable
The opposite of reasonable is
2024-07-27 06:04:36 root INFO     [order_1_approx] starting weight calculation for The opposite of related is unrelated
The opposite of comfortable is uncomfortable
The opposite of usual is unusual
The opposite of reasonable is unreasonable
The opposite of avoidable is unavoidable
The opposite of intended is unintended
The opposite of available is unavailable
The opposite of expected is
2024-07-27 06:04:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 06:06:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0157,  0.0255, -0.3296,  ..., -0.5117,  0.0493, -0.1990],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.2344,  0.1089, -1.6895,  ..., -0.6826, -0.5127, -3.5684],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0393, -0.0049,  0.0101,  ...,  0.0158, -0.0147,  0.0339],
        [-0.0032,  0.0565, -0.0071,  ...,  0.0093,  0.0187,  0.0037],
        [ 0.0184, -0.0060,  0.0315,  ...,  0.0124, -0.0049,  0.0082],
        ...,
        [-0.0012,  0.0255, -0.0080,  ...,  0.0353, -0.0024, -0.0103],
        [ 0.0011, -0.0053,  0.0107,  ...,  0.0034,  0.0547,  0.0080],
        [ 0.0294,  0.0085, -0.0165,  ...,  0.0032, -0.0071,  0.0668]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.0547, -0.0231, -1.7832,  ..., -0.1975, -0.6641, -3.7910]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 06:06:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of related is unrelated
The opposite of comfortable is uncomfortable
The opposite of usual is unusual
The opposite of reasonable is unreasonable
The opposite of avoidable is unavoidable
The opposite of intended is unintended
The opposite of available is unavailable
The opposite of expected is
2024-07-27 06:06:57 root INFO     [order_1_approx] starting weight calculation for The opposite of expected is unexpected
The opposite of available is unavailable
The opposite of related is unrelated
The opposite of usual is unusual
The opposite of intended is unintended
The opposite of comfortable is uncomfortable
The opposite of reasonable is unreasonable
The opposite of avoidable is
2024-07-27 06:06:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 06:09:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3748,  0.1604, -0.2219,  ..., -0.5898,  0.0310,  0.0658],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2100, -1.6895, -1.0078,  ..., -0.4519, -4.1367, -4.5664],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0701,  0.0244, -0.0015,  ...,  0.0229, -0.0518,  0.0100],
        [-0.0021,  0.0621, -0.0020,  ...,  0.0295,  0.0195, -0.0048],
        [-0.0037, -0.0024,  0.0284,  ..., -0.0217, -0.0100, -0.0011],
        ...,
        [ 0.0065,  0.0224, -0.0059,  ...,  0.0062,  0.0150, -0.0147],
        [-0.0007,  0.0185,  0.0229,  ..., -0.0221,  0.0475, -0.0120],
        [ 0.0129,  0.0008, -0.0084,  ..., -0.0133,  0.0115,  0.0289]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9727, -1.3877, -1.3457,  ..., -0.0959, -4.2500, -4.4141]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 06:09:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of expected is unexpected
The opposite of available is unavailable
The opposite of related is unrelated
The opposite of usual is unusual
The opposite of intended is unintended
The opposite of comfortable is uncomfortable
The opposite of reasonable is unreasonable
The opposite of avoidable is
2024-07-27 06:09:19 root INFO     [order_1_approx] starting weight calculation for The opposite of comfortable is uncomfortable
The opposite of related is unrelated
The opposite of intended is unintended
The opposite of expected is unexpected
The opposite of usual is unusual
The opposite of avoidable is unavoidable
The opposite of reasonable is unreasonable
The opposite of available is
2024-07-27 06:09:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 06:11:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2585, -0.2656, -0.3882,  ..., -0.2742,  0.3394, -0.3672],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7529, -2.6875,  1.3125,  ..., -1.1240, -2.1133, -0.7969],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0773,  0.0023, -0.0035,  ...,  0.0153, -0.0279,  0.0074],
        [ 0.0245,  0.0656, -0.0011,  ...,  0.0266,  0.0159, -0.0002],
        [-0.0051,  0.0121,  0.0386,  ..., -0.0196, -0.0111, -0.0128],
        ...,
        [-0.0283,  0.0137,  0.0049,  ...,  0.0564,  0.0253, -0.0173],
        [-0.0553,  0.0195,  0.0394,  ...,  0.0343,  0.0546,  0.0137],
        [-0.0108, -0.0117, -0.0265,  ..., -0.0118, -0.0133,  0.0792]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2695, -2.1777,  1.1934,  ..., -1.0850, -2.2539, -1.0762]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 06:11:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of comfortable is uncomfortable
The opposite of related is unrelated
The opposite of intended is unintended
The opposite of expected is unexpected
The opposite of usual is unusual
The opposite of avoidable is unavoidable
The opposite of reasonable is unreasonable
The opposite of available is
2024-07-27 06:11:42 root INFO     [order_1_approx] starting weight calculation for The opposite of related is unrelated
The opposite of expected is unexpected
The opposite of available is unavailable
The opposite of comfortable is uncomfortable
The opposite of intended is unintended
The opposite of reasonable is unreasonable
The opposite of avoidable is unavoidable
The opposite of usual is
2024-07-27 06:11:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 06:14:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2820, -0.1638, -0.1598,  ..., -0.4189, -0.4512, -0.2393],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2451, -1.3271,  1.1514,  ..., -1.6094, -1.7295, -2.2129],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0471,  0.0083,  0.0163,  ..., -0.0065, -0.0055, -0.0006],
        [-0.0261,  0.0994, -0.0174,  ...,  0.0267,  0.0113, -0.0137],
        [ 0.0246,  0.0040,  0.0287,  ..., -0.0098, -0.0043,  0.0109],
        ...,
        [ 0.0330,  0.0245,  0.0121,  ...,  0.0797,  0.0251, -0.0110],
        [ 0.0023,  0.0077, -0.0035,  ...,  0.0121,  0.0401,  0.0124],
        [ 0.0320, -0.0039, -0.0244,  ...,  0.0150, -0.0266,  0.0432]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1592, -1.3545,  0.9292,  ..., -1.1270, -2.1504, -2.1641]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 06:14:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of related is unrelated
The opposite of expected is unexpected
The opposite of available is unavailable
The opposite of comfortable is uncomfortable
The opposite of intended is unintended
The opposite of reasonable is unreasonable
The opposite of avoidable is unavoidable
The opposite of usual is
2024-07-27 06:14:05 root INFO     [order_1_approx] starting weight calculation for The opposite of usual is unusual
The opposite of avoidable is unavoidable
The opposite of reasonable is unreasonable
The opposite of intended is unintended
The opposite of comfortable is uncomfortable
The opposite of available is unavailable
The opposite of expected is unexpected
The opposite of related is
2024-07-27 06:14:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 06:16:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0756, -0.1515, -0.4250,  ..., -0.3506, -0.0169,  0.0611],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4688,  0.3477,  0.2041,  ..., -0.6357,  0.0977, -3.2227],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0415,  0.0352,  0.0246,  ...,  0.0306,  0.0352,  0.0052],
        [-0.0219,  0.0413,  0.0155,  ...,  0.0116, -0.0131,  0.0073],
        [-0.0126, -0.0043,  0.0207,  ...,  0.0282,  0.0040, -0.0138],
        ...,
        [ 0.0154,  0.0089, -0.0235,  ...,  0.0255,  0.0043, -0.0208],
        [ 0.0186, -0.0170,  0.0164,  ...,  0.0255,  0.0376,  0.0218],
        [ 0.0262,  0.0079, -0.0076,  ..., -0.0081, -0.0170,  0.0605]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0142,  0.1588,  0.1515,  ..., -0.6133, -0.4346, -3.2559]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 06:16:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of usual is unusual
The opposite of avoidable is unavoidable
The opposite of reasonable is unreasonable
The opposite of intended is unintended
The opposite of comfortable is uncomfortable
The opposite of available is unavailable
The opposite of expected is unexpected
The opposite of related is
2024-07-27 06:16:25 root INFO     [order_1_approx] starting weight calculation for The opposite of expected is unexpected
The opposite of comfortable is uncomfortable
The opposite of related is unrelated
The opposite of reasonable is unreasonable
The opposite of avoidable is unavoidable
The opposite of available is unavailable
The opposite of usual is unusual
The opposite of intended is
2024-07-27 06:16:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 06:18:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1353,  0.1816, -0.3008,  ..., -0.0324,  0.2435, -0.0587],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3594, -0.9180, -0.0254,  ...,  0.7871,  0.4385, -4.8047],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0388,  0.0158,  0.0077,  ...,  0.0035, -0.0058,  0.0021],
        [-0.0178,  0.0634, -0.0188,  ...,  0.0123,  0.0293, -0.0185],
        [-0.0045, -0.0113,  0.0514,  ...,  0.0200, -0.0003,  0.0004],
        ...,
        [-0.0140, -0.0130,  0.0213,  ...,  0.0364, -0.0054, -0.0064],
        [-0.0015, -0.0098,  0.0038,  ...,  0.0172,  0.0750,  0.0056],
        [-0.0098,  0.0119,  0.0118,  ..., -0.0032, -0.0059,  0.0602]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7686, -0.5015, -0.3479,  ...,  0.3691,  0.2915, -4.9727]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 06:18:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of expected is unexpected
The opposite of comfortable is uncomfortable
The opposite of related is unrelated
The opposite of reasonable is unreasonable
The opposite of avoidable is unavoidable
The opposite of available is unavailable
The opposite of usual is unusual
The opposite of intended is
2024-07-27 06:18:47 root INFO     total operator prediction time: 1137.2957518100739 seconds
2024-07-27 06:18:47 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+able_reg
2024-07-27 06:18:47 root INFO     building operator verb+able_reg
2024-07-27 06:18:47 root INFO     [order_1_approx] starting weight calculation for If you can deliver something, that thing is deliverable
If you can rely something, that thing is reliable
If you can discover something, that thing is discoverable
If you can learn something, that thing is learnable
If you can imagine something, that thing is imaginable
If you can believe something, that thing is believeable
If you can execute something, that thing is executable
If you can observe something, that thing is
2024-07-27 06:18:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 06:21:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0468,  0.4666, -0.3254,  ...,  0.0922,  0.1094, -0.0649],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.7812, -1.6611, -0.3657,  ..., -4.4492, -6.5273, -0.9121],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.5624e-02, -1.4282e-02, -4.9438e-03,  ...,  2.3209e-02,
          1.2932e-03,  1.6098e-02],
        [-8.7204e-03,  6.8237e-02,  1.7624e-02,  ...,  4.9629e-03,
         -1.6037e-02,  7.1030e-03],
        [-1.9150e-03, -1.0574e-02,  4.7882e-02,  ..., -1.2760e-03,
         -1.6785e-04, -3.7327e-03],
        ...,
        [ 1.0185e-03, -5.3978e-03, -2.0950e-02,  ...,  5.8441e-02,
          1.8646e-02, -3.2825e-03],
        [ 5.2309e-04,  3.9215e-03, -1.2863e-02,  ..., -2.7344e-02,
          4.7302e-02, -2.3285e-02],
        [-7.4387e-05, -9.6054e-03,  8.8348e-03,  ..., -8.8043e-03,
         -1.5327e-02,  2.2720e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.9512, -1.5605, -0.7363,  ..., -4.1914, -6.3203, -0.8433]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 06:21:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can deliver something, that thing is deliverable
If you can rely something, that thing is reliable
If you can discover something, that thing is discoverable
If you can learn something, that thing is learnable
If you can imagine something, that thing is imaginable
If you can believe something, that thing is believeable
If you can execute something, that thing is executable
If you can observe something, that thing is
2024-07-27 06:21:08 root INFO     [order_1_approx] starting weight calculation for If you can execute something, that thing is executable
If you can deliver something, that thing is deliverable
If you can discover something, that thing is discoverable
If you can rely something, that thing is reliable
If you can believe something, that thing is believeable
If you can observe something, that thing is observable
If you can imagine something, that thing is imaginable
If you can learn something, that thing is
2024-07-27 06:21:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 06:23:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0070,  0.1105, -0.0717,  ..., -0.3625, -0.0005, -0.0371],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.4941, -1.1074,  1.2568,  ..., -0.4443, -8.3906, -5.4492],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.2501e-02, -1.8021e-02,  3.9787e-03,  ...,  1.0239e-02,
         -4.4861e-03,  2.5177e-02],
        [-1.8570e-02,  4.5563e-02, -2.1973e-03,  ...,  3.8719e-03,
         -3.9940e-03,  1.5991e-02],
        [ 4.5357e-03, -2.6215e-02,  3.8422e-02,  ...,  5.0621e-03,
          4.3488e-03,  3.4084e-03],
        ...,
        [ 3.2471e-02,  1.9932e-03, -1.0330e-02,  ...,  2.5742e-02,
          5.9814e-03, -2.2568e-02],
        [ 1.5593e-03, -2.8610e-03,  1.0544e-02,  ..., -2.4734e-02,
          2.7115e-02, -1.5854e-02],
        [-5.7106e-03, -3.0518e-05,  3.9787e-03,  ..., -1.1475e-02,
         -9.0485e-03, -3.6945e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.7051, -0.8105,  1.2080,  ..., -0.2400, -8.2188, -5.4414]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 06:23:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can execute something, that thing is executable
If you can deliver something, that thing is deliverable
If you can discover something, that thing is discoverable
If you can rely something, that thing is reliable
If you can believe something, that thing is believeable
If you can observe something, that thing is observable
If you can imagine something, that thing is imaginable
If you can learn something, that thing is
2024-07-27 06:23:29 root INFO     [order_1_approx] starting weight calculation for If you can believe something, that thing is believeable
If you can deliver something, that thing is deliverable
If you can discover something, that thing is discoverable
If you can observe something, that thing is observable
If you can learn something, that thing is learnable
If you can imagine something, that thing is imaginable
If you can execute something, that thing is executable
If you can rely something, that thing is
2024-07-27 06:23:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 06:25:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0155,  0.1721, -0.3499,  ..., -0.0648, -0.3989,  0.0801],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.2246, -0.3828, -0.5293,  ..., -3.4375, -7.6914, -2.3340],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0324,  0.0007, -0.0019,  ...,  0.0246, -0.0095,  0.0175],
        [-0.0268,  0.0432,  0.0214,  ...,  0.0184,  0.0059,  0.0018],
        [ 0.0200, -0.0035,  0.0365,  ..., -0.0036, -0.0072, -0.0141],
        ...,
        [ 0.0157,  0.0219,  0.0051,  ...,  0.0322,  0.0023,  0.0049],
        [ 0.0289,  0.0016,  0.0100,  ..., -0.0267,  0.0403, -0.0267],
        [-0.0114, -0.0030,  0.0253,  ..., -0.0319, -0.0115,  0.0102]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.6494, -0.4697, -0.4502,  ..., -3.7656, -7.4336, -2.3105]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 06:25:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can believe something, that thing is believeable
If you can deliver something, that thing is deliverable
If you can discover something, that thing is discoverable
If you can observe something, that thing is observable
If you can learn something, that thing is learnable
If you can imagine something, that thing is imaginable
If you can execute something, that thing is executable
If you can rely something, that thing is
2024-07-27 06:25:50 root INFO     [order_1_approx] starting weight calculation for If you can learn something, that thing is learnable
If you can rely something, that thing is reliable
If you can discover something, that thing is discoverable
If you can believe something, that thing is believeable
If you can observe something, that thing is observable
If you can deliver something, that thing is deliverable
If you can execute something, that thing is executable
If you can imagine something, that thing is
2024-07-27 06:25:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 06:28:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2866,  0.1156,  0.7573,  ...,  0.0906,  0.3059, -0.0720],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9546,  0.5757,  1.7402,  ..., -3.3262, -7.2656, -2.2656],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.8920e-02, -7.9498e-03,  6.8665e-03,  ...,  1.1169e-02,
         -1.8799e-02,  3.2959e-02],
        [ 8.5449e-03,  6.9641e-02,  1.5900e-02,  ...,  1.1124e-02,
         -3.5339e-02,  1.1887e-02],
        [-3.8147e-06,  7.0572e-05,  3.5858e-02,  ...,  2.0618e-03,
         -1.8158e-02, -7.3586e-03],
        ...,
        [-1.1009e-02, -3.9864e-03, -1.7151e-02,  ...,  5.6915e-02,
          5.7983e-03, -7.7782e-03],
        [ 1.8326e-02,  3.3798e-03, -1.1780e-02,  ..., -5.1636e-02,
          3.7079e-02, -1.4687e-02],
        [-8.2932e-03, -6.3858e-03, -9.1171e-03,  ..., -2.2217e-02,
         -3.3691e-02,  3.1555e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7866,  0.5542,  1.4160,  ..., -2.7949, -6.9492, -2.4258]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 06:28:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can learn something, that thing is learnable
If you can rely something, that thing is reliable
If you can discover something, that thing is discoverable
If you can believe something, that thing is believeable
If you can observe something, that thing is observable
If you can deliver something, that thing is deliverable
If you can execute something, that thing is executable
If you can imagine something, that thing is
2024-07-27 06:28:09 root INFO     [order_1_approx] starting weight calculation for If you can deliver something, that thing is deliverable
If you can discover something, that thing is discoverable
If you can believe something, that thing is believeable
If you can learn something, that thing is learnable
If you can observe something, that thing is observable
If you can imagine something, that thing is imaginable
If you can rely something, that thing is reliable
If you can execute something, that thing is
2024-07-27 06:28:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 06:30:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1519,  0.2079, -0.4097,  ...,  0.1628,  0.0038,  0.0825],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1367, -0.7656,  1.3125,  ..., -2.1152, -7.8906, -5.5391],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0367, -0.0186,  0.0099,  ...,  0.0190, -0.0018,  0.0361],
        [-0.0069,  0.0699,  0.0034,  ...,  0.0163, -0.0178, -0.0129],
        [ 0.0121, -0.0098,  0.0402,  ..., -0.0147, -0.0023,  0.0092],
        ...,
        [ 0.0024,  0.0121, -0.0231,  ...,  0.0475,  0.0046, -0.0262],
        [ 0.0144,  0.0044,  0.0089,  ..., -0.0330,  0.0239, -0.0240],
        [ 0.0202, -0.0226,  0.0122,  ..., -0.0244, -0.0187,  0.0194]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4958, -0.4138,  1.0088,  ..., -2.1836, -7.8008, -5.1367]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 06:30:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can deliver something, that thing is deliverable
If you can discover something, that thing is discoverable
If you can believe something, that thing is believeable
If you can learn something, that thing is learnable
If you can observe something, that thing is observable
If you can imagine something, that thing is imaginable
If you can rely something, that thing is reliable
If you can execute something, that thing is
2024-07-27 06:30:30 root INFO     [order_1_approx] starting weight calculation for If you can rely something, that thing is reliable
If you can discover something, that thing is discoverable
If you can observe something, that thing is observable
If you can learn something, that thing is learnable
If you can believe something, that thing is believeable
If you can execute something, that thing is executable
If you can imagine something, that thing is imaginable
If you can deliver something, that thing is
2024-07-27 06:30:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 06:32:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3337,  0.2356, -0.2759,  ...,  0.1338,  0.1079,  0.0395],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7422, -1.6523, -0.3452,  ..., -3.5156, -8.2188, -3.5234],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0415, -0.0001,  0.0034,  ...,  0.0067, -0.0021,  0.0396],
        [-0.0082,  0.0530,  0.0053,  ...,  0.0054, -0.0210,  0.0070],
        [ 0.0111, -0.0003,  0.0284,  ...,  0.0036,  0.0169, -0.0279],
        ...,
        [ 0.0104, -0.0036, -0.0085,  ...,  0.0353,  0.0045, -0.0020],
        [ 0.0102, -0.0251, -0.0033,  ..., -0.0393,  0.0479, -0.0587],
        [ 0.0171, -0.0086, -0.0137,  ..., -0.0120, -0.0250,  0.0215]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5938, -1.4736, -0.3040,  ..., -3.4629, -8.1328, -3.6172]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 06:32:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can rely something, that thing is reliable
If you can discover something, that thing is discoverable
If you can observe something, that thing is observable
If you can learn something, that thing is learnable
If you can believe something, that thing is believeable
If you can execute something, that thing is executable
If you can imagine something, that thing is imaginable
If you can deliver something, that thing is
2024-07-27 06:32:50 root INFO     [order_1_approx] starting weight calculation for If you can imagine something, that thing is imaginable
If you can observe something, that thing is observable
If you can rely something, that thing is reliable
If you can learn something, that thing is learnable
If you can believe something, that thing is believeable
If you can deliver something, that thing is deliverable
If you can execute something, that thing is executable
If you can discover something, that thing is
2024-07-27 06:32:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 06:35:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4319,  0.2476, -0.1736,  ...,  0.0156, -0.1509, -0.0607],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0269, -2.4180,  1.0312,  ..., -1.8379, -6.7500,  0.5234],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.1626e-02, -1.0605e-03,  1.9348e-02,  ...,  2.6825e-02,
         -9.7132e-04,  2.6642e-02],
        [-1.0864e-02,  6.5491e-02,  2.4368e-02,  ...,  1.5358e-02,
         -3.2990e-02,  8.5754e-03],
        [ 4.6692e-03, -3.8319e-03,  5.3711e-02,  ...,  9.7427e-03,
         -1.1887e-02, -5.5199e-03],
        ...,
        [-6.5994e-03,  8.5754e-03,  4.5776e-05,  ...,  5.3772e-02,
          1.4381e-02, -9.3384e-03],
        [ 5.9814e-03,  1.3969e-02,  2.1458e-03,  ..., -3.0197e-02,
          5.6305e-02, -1.0078e-02],
        [ 2.2034e-02,  5.4550e-03,  1.2657e-02,  ..., -2.8625e-02,
         -2.9648e-02,  4.0009e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0193, -2.6992,  1.0342,  ..., -1.8115, -6.7617,  0.2183]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 06:35:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can imagine something, that thing is imaginable
If you can observe something, that thing is observable
If you can rely something, that thing is reliable
If you can learn something, that thing is learnable
If you can believe something, that thing is believeable
If you can deliver something, that thing is deliverable
If you can execute something, that thing is executable
If you can discover something, that thing is
2024-07-27 06:35:12 root INFO     [order_1_approx] starting weight calculation for If you can execute something, that thing is executable
If you can rely something, that thing is reliable
If you can observe something, that thing is observable
If you can learn something, that thing is learnable
If you can deliver something, that thing is deliverable
If you can imagine something, that thing is imaginable
If you can discover something, that thing is discoverable
If you can believe something, that thing is
2024-07-27 06:35:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 06:37:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3013,  0.2925,  0.0592,  ...,  0.0331, -0.1405,  0.4155],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8691, -1.1123, -0.0801,  ..., -3.1250, -6.7578, -2.5898],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0157, -0.0038, -0.0022,  ...,  0.0137, -0.0137,  0.0232],
        [-0.0092,  0.0437,  0.0165,  ...,  0.0154, -0.0052,  0.0131],
        [ 0.0063, -0.0008,  0.0276,  ...,  0.0002, -0.0096,  0.0073],
        ...,
        [-0.0049, -0.0016, -0.0120,  ...,  0.0185, -0.0077, -0.0035],
        [ 0.0077,  0.0008, -0.0008,  ..., -0.0369,  0.0306, -0.0253],
        [ 0.0055, -0.0102, -0.0027,  ..., -0.0168, -0.0110,  0.0099]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9077, -1.1992, -0.1639,  ..., -2.6152, -6.9102, -2.6699]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 06:37:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can execute something, that thing is executable
If you can rely something, that thing is reliable
If you can observe something, that thing is observable
If you can learn something, that thing is learnable
If you can deliver something, that thing is deliverable
If you can imagine something, that thing is imaginable
If you can discover something, that thing is discoverable
If you can believe something, that thing is
2024-07-27 06:37:33 root INFO     total operator prediction time: 1126.2083868980408 seconds
2024-07-27 06:37:33 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+tion_irreg
2024-07-27 06:37:33 root INFO     building operator verb+tion_irreg
2024-07-27 06:37:33 root INFO     [order_1_approx] starting weight calculation for To perspire results in perspiration
To privatize results in privatization
To observe results in observation
To visualize results in visualization
To expire results in expiration
To accuse results in accusation
To consult results in consulation
To modernize results in
2024-07-27 06:37:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 06:39:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3435,  0.4780, -0.8535,  ..., -0.3528, -0.2800, -0.1230],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0576, -5.0859,  0.6411,  ..., -0.5239, -2.7578, -0.7559],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0363, -0.0057,  0.0077,  ..., -0.0018,  0.0108,  0.0029],
        [ 0.0043,  0.0521,  0.0168,  ...,  0.0249, -0.0081,  0.0210],
        [ 0.0009, -0.0061,  0.0270,  ...,  0.0154,  0.0033, -0.0064],
        ...,
        [ 0.0078,  0.0064,  0.0176,  ...,  0.0512, -0.0111,  0.0016],
        [ 0.0080,  0.0111,  0.0036,  ...,  0.0042,  0.0466, -0.0131],
        [ 0.0041,  0.0086, -0.0022,  ...,  0.0042, -0.0226,  0.0461]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.0352, -5.2031,  0.7100,  ..., -0.4480, -2.8867, -0.7935]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 06:39:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To perspire results in perspiration
To privatize results in privatization
To observe results in observation
To visualize results in visualization
To expire results in expiration
To accuse results in accusation
To consult results in consulation
To modernize results in
2024-07-27 06:39:55 root INFO     [order_1_approx] starting weight calculation for To perspire results in perspiration
To privatize results in privatization
To expire results in expiration
To visualize results in visualization
To modernize results in modernization
To consult results in consulation
To accuse results in accusation
To observe results in
2024-07-27 06:39:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 06:42:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1700,  0.3723, -0.2314,  ..., -0.0657, -0.3479, -0.0806],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.1572, -5.6328,  3.1074,  ..., -0.3911, -1.0898, -1.1035],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0218, -0.0143, -0.0296,  ..., -0.0369, -0.0200, -0.0068],
        [ 0.0500,  0.0971,  0.0342,  ...,  0.0499,  0.0144,  0.0294],
        [-0.0005, -0.0089,  0.0732,  ..., -0.0183,  0.0111, -0.0039],
        ...,
        [ 0.0221,  0.0054,  0.0192,  ...,  0.0955,  0.0005,  0.0060],
        [-0.0033,  0.0245,  0.0214,  ...,  0.0326,  0.0499, -0.0012],
        [ 0.0290,  0.0222,  0.0019,  ...,  0.0230, -0.0026,  0.0804]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.6738, -5.1875,  3.2578,  ..., -0.1406, -1.4922, -1.1064]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 06:42:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To perspire results in perspiration
To privatize results in privatization
To expire results in expiration
To visualize results in visualization
To modernize results in modernization
To consult results in consulation
To accuse results in accusation
To observe results in
2024-07-27 06:42:10 root INFO     [order_1_approx] starting weight calculation for To perspire results in perspiration
To modernize results in modernization
To accuse results in accusation
To observe results in observation
To privatize results in privatization
To expire results in expiration
To visualize results in visualization
To consult results in
2024-07-27 06:42:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 06:44:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0023,  0.3860, -0.4905,  ..., -0.2146, -0.4731, -0.3132],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1787, -3.9805,  2.6055,  ...,  1.0791, -0.0449, -0.8906],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0463,  0.0070,  0.0098,  ...,  0.0051, -0.0028,  0.0225],
        [ 0.0239,  0.0641,  0.0128,  ...,  0.0245, -0.0039,  0.0128],
        [ 0.0206, -0.0046,  0.0565,  ..., -0.0139,  0.0096,  0.0001],
        ...,
        [ 0.0013, -0.0017,  0.0040,  ...,  0.0681, -0.0039,  0.0031],
        [-0.0541, -0.0572, -0.0002,  ...,  0.0108,  0.0543, -0.0051],
        [ 0.0375,  0.0009, -0.0098,  ...,  0.0116, -0.0079,  0.0508]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2380, -3.3984,  2.7520,  ...,  1.0449, -0.6675, -0.5645]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 06:44:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To perspire results in perspiration
To modernize results in modernization
To accuse results in accusation
To observe results in observation
To privatize results in privatization
To expire results in expiration
To visualize results in visualization
To consult results in
2024-07-27 06:44:32 root INFO     [order_1_approx] starting weight calculation for To observe results in observation
To expire results in expiration
To modernize results in modernization
To consult results in consulation
To privatize results in privatization
To accuse results in accusation
To perspire results in perspiration
To visualize results in
2024-07-27 06:44:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 06:46:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0381,  0.0261, -0.2217,  ..., -0.0861,  0.0593, -0.0062],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4580, -5.7969,  5.7383,  ..., -0.0459, -2.1680, -0.1514],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.5125e-02, -1.5373e-03, -8.2016e-05,  ..., -3.6583e-03,
          4.1246e-04,  1.1528e-02],
        [ 1.5839e-02,  9.3140e-02,  2.9861e-02,  ...,  3.5248e-02,
         -4.1466e-03,  2.4353e-02],
        [-5.4741e-03, -2.7191e-02,  7.2388e-02,  ..., -2.0874e-02,
         -7.8201e-03,  5.0163e-04],
        ...,
        [ 3.5057e-03,  3.2463e-03, -1.0338e-02,  ...,  7.7454e-02,
         -1.2579e-03, -1.0300e-04],
        [ 3.3646e-03,  2.0580e-03,  6.6376e-04,  ...,  2.1576e-02,
          5.5573e-02, -1.0483e-02],
        [ 1.2680e-02,  1.5991e-02,  2.3071e-02,  ...,  1.6479e-02,
         -2.8793e-02,  7.1289e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3398, -5.8789,  5.5820,  ..., -0.0424, -2.2754, -0.3999]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 06:46:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To observe results in observation
To expire results in expiration
To modernize results in modernization
To consult results in consulation
To privatize results in privatization
To accuse results in accusation
To perspire results in perspiration
To visualize results in
2024-07-27 06:46:53 root INFO     [order_1_approx] starting weight calculation for To modernize results in modernization
To perspire results in perspiration
To privatize results in privatization
To consult results in consulation
To visualize results in visualization
To accuse results in accusation
To observe results in observation
To expire results in
2024-07-27 06:46:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 06:49:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1812,  0.0612, -0.7598,  ..., -0.4463,  0.0175, -0.2756],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4531, -4.7578,  1.0830,  ..., -0.9297, -1.3008, -2.6895],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0557, -0.0105, -0.0054,  ..., -0.0092,  0.0079, -0.0017],
        [ 0.0232,  0.0753,  0.0115,  ...,  0.0276, -0.0013,  0.0195],
        [ 0.0044, -0.0064,  0.0576,  ...,  0.0029, -0.0188, -0.0118],
        ...,
        [ 0.0196,  0.0243,  0.0112,  ...,  0.0753, -0.0039, -0.0079],
        [ 0.0105, -0.0276,  0.0123,  ...,  0.0343,  0.0501,  0.0051],
        [ 0.0381, -0.0036,  0.0004,  ...,  0.0199, -0.0252,  0.0907]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9980, -4.0039,  0.6699,  ..., -0.8779, -1.7324, -2.6289]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 06:49:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To modernize results in modernization
To perspire results in perspiration
To privatize results in privatization
To consult results in consulation
To visualize results in visualization
To accuse results in accusation
To observe results in observation
To expire results in
2024-07-27 06:49:13 root INFO     [order_1_approx] starting weight calculation for To accuse results in accusation
To visualize results in visualization
To modernize results in modernization
To expire results in expiration
To perspire results in perspiration
To consult results in consulation
To observe results in observation
To privatize results in
2024-07-27 06:49:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 06:51:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3909,  0.1057, -0.6919,  ...,  0.0057, -0.4219,  0.0267],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0781, -5.9688,  3.3203,  ..., -1.7969, -0.1982, -2.3496],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.1178e-02,  2.0782e-02, -1.2985e-02,  ..., -1.6388e-02,
          1.1349e-03, -2.9030e-03],
        [ 8.0414e-03,  6.2988e-02,  1.2299e-02,  ...,  2.9480e-02,
         -2.9793e-03,  9.7351e-03],
        [-6.3286e-03, -5.8289e-03,  3.7567e-02,  ..., -1.2398e-05,
         -4.6349e-04,  2.8915e-03],
        ...,
        [ 1.1185e-02,  3.1433e-03, -4.9591e-03,  ...,  5.0903e-02,
          1.0109e-04, -6.1760e-03],
        [-3.8967e-03, -5.1117e-03, -6.8665e-04,  ...,  1.7517e-02,
          5.5939e-02, -3.2654e-03],
        [ 8.6365e-03, -5.3930e-04,  5.0850e-03,  ...,  8.7738e-03,
         -1.7700e-02,  4.9561e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1582, -5.7773,  3.2383,  ..., -1.2363, -0.3450, -1.9326]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 06:51:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To accuse results in accusation
To visualize results in visualization
To modernize results in modernization
To expire results in expiration
To perspire results in perspiration
To consult results in consulation
To observe results in observation
To privatize results in
2024-07-27 06:51:28 root INFO     [order_1_approx] starting weight calculation for To visualize results in visualization
To consult results in consulation
To observe results in observation
To privatize results in privatization
To modernize results in modernization
To expire results in expiration
To accuse results in accusation
To perspire results in
2024-07-27 06:51:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 06:53:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0026, -0.3477, -0.7603,  ..., -0.2494,  0.1313, -0.2036],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4023, -5.3789,  2.7227,  ..., -1.7021, -1.2725, -1.0840],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0012,  0.0102, -0.0054,  ..., -0.0270,  0.0317, -0.0225],
        [ 0.0461,  0.0408,  0.0016,  ...,  0.0303, -0.0311,  0.0355],
        [ 0.0035, -0.0037,  0.0652,  ...,  0.0064, -0.0130,  0.0018],
        ...,
        [ 0.0330, -0.0082, -0.0147,  ...,  0.0630, -0.0085,  0.0155],
        [-0.0057, -0.0021,  0.0146,  ...,  0.0089,  0.0413,  0.0058],
        [ 0.0287, -0.0232, -0.0032,  ...,  0.0136, -0.0205,  0.0696]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8457, -5.6406,  2.5488,  ..., -1.9893, -1.2334, -1.4531]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 06:53:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To visualize results in visualization
To consult results in consulation
To observe results in observation
To privatize results in privatization
To modernize results in modernization
To expire results in expiration
To accuse results in accusation
To perspire results in
2024-07-27 06:53:46 root INFO     [order_1_approx] starting weight calculation for To privatize results in privatization
To visualize results in visualization
To expire results in expiration
To perspire results in perspiration
To observe results in observation
To consult results in consulation
To modernize results in modernization
To accuse results in
2024-07-27 06:53:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 06:55:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1389,  0.3979, -0.6719,  ...,  0.3777, -0.3455, -0.2167],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.9395, -5.3828,  1.3184,  ...,  4.6367, -0.7515, -0.2344],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0031,  0.0066,  0.0001,  ..., -0.0219, -0.0105, -0.0386],
        [ 0.0679,  0.0534, -0.0097,  ...,  0.0436, -0.0156,  0.0442],
        [-0.0140, -0.0204,  0.0568,  ..., -0.0088, -0.0019, -0.0229],
        ...,
        [ 0.0092, -0.0003, -0.0087,  ...,  0.0756, -0.0003,  0.0152],
        [-0.0037, -0.0007,  0.0098,  ...,  0.0076,  0.0452,  0.0111],
        [ 0.0359, -0.0017, -0.0023,  ...,  0.0152, -0.0082,  0.0709]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.2617, -4.3750,  1.1777,  ...,  4.2344, -1.4199, -0.6768]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 06:55:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To privatize results in privatization
To visualize results in visualization
To expire results in expiration
To perspire results in perspiration
To observe results in observation
To consult results in consulation
To modernize results in modernization
To accuse results in
2024-07-27 06:55:59 root INFO     total operator prediction time: 1105.4309751987457 seconds
2024-07-27 06:55:59 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj+ly_reg
2024-07-27 06:55:59 root INFO     building operator adj+ly_reg
2024-07-27 06:55:59 root INFO     [order_1_approx] starting weight calculation for The adjective form of physical is physically
The adjective form of nice is nicely
The adjective form of serious is seriously
The adjective form of similar is similarly
The adjective form of successful is successfully
The adjective form of historical is historically
The adjective form of digital is digitally
The adjective form of immediate is
2024-07-27 06:55:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 06:58:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2507,  0.1486, -0.5151,  ..., -0.2749, -0.7764,  0.1896],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7148, -1.6172, -1.3652,  ..., -1.3730, -1.1895, -3.7305],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 8.4229e-02, -8.8043e-03,  1.1909e-02,  ...,  3.9459e-02,
         -9.9716e-03,  1.8204e-02],
        [ 2.9419e-02,  6.3293e-02,  2.8534e-02,  ...,  5.2094e-02,
         -8.8959e-03, -7.4959e-04],
        [ 2.0126e-02, -1.1978e-02,  3.3661e-02,  ..., -7.3471e-03,
          4.8752e-03,  9.3994e-03],
        ...,
        [ 4.9515e-03,  3.1830e-02,  3.8815e-03,  ...,  8.6182e-02,
          9.1553e-05,  5.7602e-03],
        [ 1.8707e-02,  2.6581e-02,  7.7820e-04,  ..., -4.2610e-03,
          6.6223e-02, -4.4174e-03],
        [-2.4719e-03,  1.6136e-03,  1.5778e-02,  ..., -2.9144e-02,
         -3.3722e-02,  6.2103e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4102, -2.0508, -1.6172,  ..., -1.1934, -1.0762, -3.8086]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 06:58:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of physical is physically
The adjective form of nice is nicely
The adjective form of serious is seriously
The adjective form of similar is similarly
The adjective form of successful is successfully
The adjective form of historical is historically
The adjective form of digital is digitally
The adjective form of immediate is
2024-07-27 06:58:22 root INFO     [order_1_approx] starting weight calculation for The adjective form of nice is nicely
The adjective form of digital is digitally
The adjective form of physical is physically
The adjective form of successful is successfully
The adjective form of similar is similarly
The adjective form of serious is seriously
The adjective form of immediate is immediately
The adjective form of historical is
2024-07-27 06:58:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 07:00:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2323, -0.0548, -0.4924,  ..., -0.6123, -0.3594, -0.0851],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1877, -1.5352,  0.8491,  ..., -3.4668, -3.1211, -1.4043],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0933, -0.0225,  0.0119,  ...,  0.0236,  0.0026,  0.0200],
        [ 0.0192,  0.0858,  0.0181,  ...,  0.0349, -0.0053,  0.0012],
        [ 0.0117,  0.0042,  0.0576,  ...,  0.0238, -0.0062, -0.0068],
        ...,
        [ 0.0236,  0.0127, -0.0325,  ...,  0.0699, -0.0085,  0.0027],
        [-0.0224,  0.0359,  0.0136,  ..., -0.0143,  0.0729, -0.0121],
        [ 0.0173,  0.0064,  0.0035,  ...,  0.0093, -0.0198,  0.0472]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3037, -2.0723,  0.4463,  ..., -3.2109, -3.0488, -1.9141]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 07:00:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of nice is nicely
The adjective form of digital is digitally
The adjective form of physical is physically
The adjective form of successful is successfully
The adjective form of similar is similarly
The adjective form of serious is seriously
The adjective form of immediate is immediately
The adjective form of historical is
2024-07-27 07:00:44 root INFO     [order_1_approx] starting weight calculation for The adjective form of physical is physically
The adjective form of historical is historically
The adjective form of serious is seriously
The adjective form of similar is similarly
The adjective form of successful is successfully
The adjective form of immediate is immediately
The adjective form of digital is digitally
The adjective form of nice is
2024-07-27 07:00:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 07:03:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3784,  0.2111, -0.5239,  ..., -0.1029, -0.3516, -0.2554],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4717, -2.1328, -1.8828,  ..., -0.1113, -6.1875, -1.4932],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0488, -0.0148,  0.0375,  ..., -0.0072,  0.0168,  0.0237],
        [ 0.0409,  0.0462, -0.0256,  ...,  0.0328,  0.0040, -0.0069],
        [ 0.0234, -0.0214,  0.0519,  ...,  0.0298, -0.0031, -0.0155],
        ...,
        [ 0.0177, -0.0134, -0.0177,  ...,  0.0812,  0.0086,  0.0082],
        [-0.0060,  0.0385,  0.0296,  ...,  0.0249,  0.0267, -0.0183],
        [ 0.0130, -0.0050, -0.0030,  ..., -0.0036, -0.0287,  0.0472]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4170, -2.7109, -1.9443,  ..., -0.2415, -6.1797, -1.1621]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 07:03:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of physical is physically
The adjective form of historical is historically
The adjective form of serious is seriously
The adjective form of similar is similarly
The adjective form of successful is successfully
The adjective form of immediate is immediately
The adjective form of digital is digitally
The adjective form of nice is
2024-07-27 07:03:05 root INFO     [order_1_approx] starting weight calculation for The adjective form of historical is historically
The adjective form of digital is digitally
The adjective form of serious is seriously
The adjective form of immediate is immediately
The adjective form of nice is nicely
The adjective form of similar is similarly
The adjective form of successful is successfully
The adjective form of physical is
2024-07-27 07:03:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 07:05:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4434, -0.3157, -0.4773,  ..., -0.4929, -0.3550,  0.0569],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9941, -3.1445,  1.0762,  ..., -3.0508, -2.9258, -2.4102],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0690, -0.0168,  0.0044,  ..., -0.0071,  0.0106,  0.0061],
        [ 0.0375,  0.0764, -0.0142,  ...,  0.0040, -0.0002, -0.0119],
        [-0.0040, -0.0361,  0.0748,  ...,  0.0273,  0.0047, -0.0028],
        ...,
        [ 0.0197,  0.0102, -0.0334,  ...,  0.0896,  0.0090, -0.0069],
        [-0.0004, -0.0217,  0.0234,  ..., -0.0053,  0.0484,  0.0006],
        [ 0.0044, -0.0224,  0.0039,  ...,  0.0018, -0.0206,  0.0438]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6992, -2.5449,  1.0518,  ..., -2.3750, -2.9902, -2.4219]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 07:05:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of historical is historically
The adjective form of digital is digitally
The adjective form of serious is seriously
The adjective form of immediate is immediately
The adjective form of nice is nicely
The adjective form of similar is similarly
The adjective form of successful is successfully
The adjective form of physical is
2024-07-27 07:05:27 root INFO     [order_1_approx] starting weight calculation for The adjective form of physical is physically
The adjective form of similar is similarly
The adjective form of immediate is immediately
The adjective form of nice is nicely
The adjective form of historical is historically
The adjective form of digital is digitally
The adjective form of successful is successfully
The adjective form of serious is
2024-07-27 07:05:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 07:07:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2610, -0.0209, -0.5713,  ...,  0.0162, -0.5801,  0.2203],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2510, -1.9492, -0.9805,  ..., -2.3594,  0.1533, -4.2969],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1252, -0.0118,  0.0210,  ...,  0.0018,  0.0055,  0.0233],
        [ 0.0127,  0.0681,  0.0139,  ...,  0.0125,  0.0003, -0.0086],
        [ 0.0223, -0.0061,  0.0773,  ...,  0.0081, -0.0107,  0.0112],
        ...,
        [ 0.0025,  0.0359, -0.0069,  ...,  0.0850, -0.0032,  0.0259],
        [-0.0398,  0.0227,  0.0034,  ...,  0.0099,  0.0788, -0.0061],
        [ 0.0319, -0.0171,  0.0214,  ...,  0.0105, -0.0535,  0.0595]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6489, -1.8281, -1.1611,  ..., -2.3730,  0.3040, -4.2422]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 07:07:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of physical is physically
The adjective form of similar is similarly
The adjective form of immediate is immediately
The adjective form of nice is nicely
The adjective form of historical is historically
The adjective form of digital is digitally
The adjective form of successful is successfully
The adjective form of serious is
2024-07-27 07:07:51 root INFO     [order_1_approx] starting weight calculation for The adjective form of serious is seriously
The adjective form of nice is nicely
The adjective form of digital is digitally
The adjective form of historical is historically
The adjective form of physical is physically
The adjective form of successful is successfully
The adjective form of immediate is immediately
The adjective form of similar is
2024-07-27 07:07:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 07:10:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0439, -0.3320, -0.2739,  ...,  0.1010, -0.1506,  0.0833],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7744, -1.2900,  1.0049,  ..., -1.5527,  0.7002, -0.8096],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0956,  0.0053,  0.0184,  ...,  0.0124,  0.0299,  0.0307],
        [ 0.0295,  0.0694,  0.0201,  ...,  0.0269,  0.0233, -0.0221],
        [ 0.0188,  0.0110,  0.0682,  ...,  0.0094, -0.0188, -0.0074],
        ...,
        [ 0.0069,  0.0075,  0.0069,  ...,  0.1047,  0.0024, -0.0014],
        [-0.0254,  0.0188,  0.0146,  ..., -0.0139,  0.0272, -0.0204],
        [ 0.0116,  0.0057, -0.0052,  ...,  0.0134, -0.0435,  0.0316]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2354, -0.9404,  1.0098,  ..., -1.8604,  0.4680, -1.1016]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 07:10:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of serious is seriously
The adjective form of nice is nicely
The adjective form of digital is digitally
The adjective form of historical is historically
The adjective form of physical is physically
The adjective form of successful is successfully
The adjective form of immediate is immediately
The adjective form of similar is
2024-07-27 07:10:14 root INFO     [order_1_approx] starting weight calculation for The adjective form of serious is seriously
The adjective form of physical is physically
The adjective form of similar is similarly
The adjective form of nice is nicely
The adjective form of historical is historically
The adjective form of immediate is immediately
The adjective form of digital is digitally
The adjective form of successful is
2024-07-27 07:10:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 07:12:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3218,  0.1548, -0.2881,  ..., -0.1517, -0.5410,  0.0269],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7090, -1.0430,  0.6475,  ...,  0.4634, -1.1445, -2.0859],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0631,  0.0034,  0.0052,  ...,  0.0178,  0.0028,  0.0305],
        [ 0.0139,  0.0594, -0.0032,  ...,  0.0350, -0.0032, -0.0105],
        [ 0.0104, -0.0145,  0.0455,  ...,  0.0023, -0.0132, -0.0024],
        ...,
        [-0.0144, -0.0102, -0.0136,  ...,  0.0730,  0.0100,  0.0014],
        [-0.0190,  0.0085,  0.0027,  ...,  0.0022,  0.0403, -0.0275],
        [ 0.0008, -0.0159, -0.0035,  ...,  0.0123, -0.0159,  0.0199]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2695, -1.1562,  1.0449,  ...,  0.4756, -0.7432, -1.9688]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 07:12:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of serious is seriously
The adjective form of physical is physically
The adjective form of similar is similarly
The adjective form of nice is nicely
The adjective form of historical is historically
The adjective form of immediate is immediately
The adjective form of digital is digitally
The adjective form of successful is
2024-07-27 07:12:37 root INFO     [order_1_approx] starting weight calculation for The adjective form of successful is successfully
The adjective form of historical is historically
The adjective form of nice is nicely
The adjective form of similar is similarly
The adjective form of immediate is immediately
The adjective form of serious is seriously
The adjective form of physical is physically
The adjective form of digital is
2024-07-27 07:12:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 07:14:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0187,  0.2808, -0.4834,  ..., -0.0930, -0.3596,  0.0546],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1011, -0.6182,  0.9053,  ..., -2.1719, -2.0801, -0.1133],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0704, -0.0330,  0.0051,  ...,  0.0135, -0.0061,  0.0033],
        [ 0.0207,  0.0559,  0.0392,  ...,  0.0224, -0.0024, -0.0078],
        [ 0.0095, -0.0216,  0.0518,  ...,  0.0106,  0.0301, -0.0054],
        ...,
        [-0.0213,  0.0289, -0.0022,  ...,  0.0477,  0.0026, -0.0147],
        [ 0.0037,  0.0182, -0.0003,  ..., -0.0183,  0.0622,  0.0020],
        [-0.0114,  0.0044, -0.0267,  ..., -0.0080, -0.0157,  0.0492]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4067, -1.2090,  1.1035,  ..., -1.6426, -1.8486, -0.3359]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 07:15:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of successful is successfully
The adjective form of historical is historically
The adjective form of nice is nicely
The adjective form of similar is similarly
The adjective form of immediate is immediately
The adjective form of serious is seriously
The adjective form of physical is physically
The adjective form of digital is
2024-07-27 07:15:00 root INFO     total operator prediction time: 1141.3340728282928 seconds
2024-07-27 07:15:00 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on over+adj_reg
2024-07-27 07:15:00 root INFO     building operator over+adj_reg
2024-07-27 07:15:00 root INFO     [order_1_approx] starting weight calculation for If something is too sized, it is oversized
If something is too protected, it is overprotected
If something is too optimistic, it is overoptimistic
If something is too excited, it is overexcited
If something is too dressed, it is overdressed
If something is too stretched, it is overstretched
If something is too played, it is overplayed
If something is too zealous, it is
2024-07-27 07:15:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 07:17:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4863, -0.6025, -0.5264,  ...,  0.0623, -0.6621,  0.0737],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2021, -5.0742,  0.1821,  ..., -0.2300, -0.8193, -1.7910],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0564,  0.0063,  0.0186,  ...,  0.0105, -0.0032,  0.0191],
        [-0.0079,  0.0382,  0.0079,  ...,  0.0094, -0.0048,  0.0089],
        [ 0.0241, -0.0106,  0.0498,  ..., -0.0075,  0.0023,  0.0113],
        ...,
        [ 0.0083,  0.0095, -0.0063,  ...,  0.0704,  0.0145, -0.0028],
        [ 0.0137,  0.0087, -0.0082,  ..., -0.0045,  0.0611, -0.0255],
        [ 0.0036,  0.0023, -0.0021,  ..., -0.0014, -0.0287,  0.0549]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4072, -4.8125,  0.4517,  ...,  0.0562, -0.6919, -1.6123]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 07:17:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too sized, it is oversized
If something is too protected, it is overprotected
If something is too optimistic, it is overoptimistic
If something is too excited, it is overexcited
If something is too dressed, it is overdressed
If something is too stretched, it is overstretched
If something is too played, it is overplayed
If something is too zealous, it is
2024-07-27 07:17:21 root INFO     [order_1_approx] starting weight calculation for If something is too optimistic, it is overoptimistic
If something is too sized, it is oversized
If something is too played, it is overplayed
If something is too stretched, it is overstretched
If something is too protected, it is overprotected
If something is too zealous, it is overzealous
If something is too excited, it is overexcited
If something is too dressed, it is
2024-07-27 07:17:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 07:19:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1200, -0.4915, -0.2876,  ..., -0.3108, -0.3081,  0.1942],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5889, -4.3281, -0.7686,  ...,  2.0898, -4.2930, -2.4258],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0482, -0.0122, -0.0070,  ..., -0.0124,  0.0036,  0.0037],
        [-0.0006,  0.0403,  0.0008,  ..., -0.0109, -0.0162, -0.0014],
        [ 0.0104, -0.0151,  0.0227,  ..., -0.0105,  0.0032,  0.0145],
        ...,
        [ 0.0048,  0.0033,  0.0152,  ...,  0.0644,  0.0110, -0.0052],
        [-0.0035,  0.0010, -0.0009,  ...,  0.0104,  0.0280, -0.0098],
        [ 0.0024,  0.0037,  0.0172,  ...,  0.0259, -0.0073,  0.0292]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8291, -4.1914, -0.9575,  ...,  2.3477, -3.8789, -2.3848]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 07:19:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too optimistic, it is overoptimistic
If something is too sized, it is oversized
If something is too played, it is overplayed
If something is too stretched, it is overstretched
If something is too protected, it is overprotected
If something is too zealous, it is overzealous
If something is too excited, it is overexcited
If something is too dressed, it is
2024-07-27 07:19:41 root INFO     [order_1_approx] starting weight calculation for If something is too zealous, it is overzealous
If something is too protected, it is overprotected
If something is too stretched, it is overstretched
If something is too sized, it is oversized
If something is too optimistic, it is overoptimistic
If something is too dressed, it is overdressed
If something is too played, it is overplayed
If something is too excited, it is
2024-07-27 07:19:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 07:22:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0106, -0.3809, -0.8184,  ..., -0.0744, -0.7129,  0.1898],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2773, -4.3594, -0.5117,  ...,  0.3621, -1.1738, -3.5488],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0525, -0.0076, -0.0151,  ..., -0.0131,  0.0191,  0.0140],
        [ 0.0116,  0.0603, -0.0006,  ...,  0.0024, -0.0119, -0.0116],
        [ 0.0305, -0.0005,  0.0364,  ...,  0.0099, -0.0102,  0.0013],
        ...,
        [ 0.0013,  0.0237, -0.0023,  ...,  0.0716,  0.0105,  0.0071],
        [ 0.0046,  0.0105, -0.0091,  ..., -0.0004,  0.0454, -0.0202],
        [ 0.0030, -0.0031,  0.0101,  ...,  0.0110, -0.0251,  0.0461]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0801, -4.5312, -0.4480,  ...,  0.4534, -1.0596, -3.6953]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 07:22:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too zealous, it is overzealous
If something is too protected, it is overprotected
If something is too stretched, it is overstretched
If something is too sized, it is oversized
If something is too optimistic, it is overoptimistic
If something is too dressed, it is overdressed
If something is too played, it is overplayed
If something is too excited, it is
2024-07-27 07:22:03 root INFO     [order_1_approx] starting weight calculation for If something is too sized, it is oversized
If something is too protected, it is overprotected
If something is too dressed, it is overdressed
If something is too optimistic, it is overoptimistic
If something is too zealous, it is overzealous
If something is too excited, it is overexcited
If something is too played, it is overplayed
If something is too stretched, it is
2024-07-27 07:22:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 07:24:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3801, -0.7129, -0.0526,  ..., -0.2827,  0.0578,  0.4563],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9980, -3.8203,  1.0039,  ..., -0.4751,  0.1899, -2.5352],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0416,  0.0064, -0.0078,  ...,  0.0029,  0.0191,  0.0163],
        [-0.0010,  0.0415,  0.0003,  ...,  0.0040, -0.0052, -0.0097],
        [ 0.0144,  0.0183,  0.0277,  ...,  0.0111, -0.0011, -0.0040],
        ...,
        [ 0.0165,  0.0050, -0.0044,  ...,  0.0657,  0.0084,  0.0022],
        [ 0.0028,  0.0153, -0.0077,  ...,  0.0032,  0.0427, -0.0320],
        [-0.0009, -0.0039, -0.0072,  ..., -0.0120, -0.0032,  0.0581]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7412, -3.8262,  0.7041,  ..., -0.3936,  0.1404, -2.3320]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 07:24:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too sized, it is oversized
If something is too protected, it is overprotected
If something is too dressed, it is overdressed
If something is too optimistic, it is overoptimistic
If something is too zealous, it is overzealous
If something is too excited, it is overexcited
If something is too played, it is overplayed
If something is too stretched, it is
2024-07-27 07:24:23 root INFO     [order_1_approx] starting weight calculation for If something is too played, it is overplayed
If something is too sized, it is oversized
If something is too excited, it is overexcited
If something is too optimistic, it is overoptimistic
If something is too stretched, it is overstretched
If something is too dressed, it is overdressed
If something is too zealous, it is overzealous
If something is too protected, it is
2024-07-27 07:24:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 07:26:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2238, -0.3013, -0.5078,  ..., -0.2720, -0.1796,  0.2793],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0645, -3.9922,  1.6318,  ...,  0.4741, -1.1191, -3.1230],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0509, -0.0094,  0.0093,  ...,  0.0147,  0.0065,  0.0293],
        [ 0.0021,  0.0613,  0.0120,  ...,  0.0080, -0.0008, -0.0072],
        [-0.0158,  0.0017,  0.0474,  ...,  0.0270, -0.0232,  0.0195],
        ...,
        [ 0.0067,  0.0082, -0.0073,  ...,  0.0673,  0.0053,  0.0128],
        [ 0.0005,  0.0090, -0.0136,  ..., -0.0047,  0.0688, -0.0268],
        [ 0.0057,  0.0084, -0.0096,  ...,  0.0177, -0.0216,  0.0627]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0830, -3.9102,  1.2490,  ...,  0.7173, -1.1729, -3.3359]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 07:26:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too played, it is overplayed
If something is too sized, it is oversized
If something is too excited, it is overexcited
If something is too optimistic, it is overoptimistic
If something is too stretched, it is overstretched
If something is too dressed, it is overdressed
If something is too zealous, it is overzealous
If something is too protected, it is
2024-07-27 07:26:44 root INFO     [order_1_approx] starting weight calculation for If something is too dressed, it is overdressed
If something is too optimistic, it is overoptimistic
If something is too excited, it is overexcited
If something is too zealous, it is overzealous
If something is too sized, it is oversized
If something is too protected, it is overprotected
If something is too stretched, it is overstretched
If something is too played, it is
2024-07-27 07:26:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 07:28:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0880, -0.4126, -0.2322,  ..., -0.4075, -0.5742,  0.1877],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7725, -3.4355,  1.0078,  ..., -0.1208, -1.0215, -3.3848],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0690, -0.0022,  0.0052,  ...,  0.0133,  0.0141,  0.0344],
        [-0.0152,  0.0690,  0.0041,  ...,  0.0073, -0.0059, -0.0136],
        [ 0.0263, -0.0048,  0.0463,  ...,  0.0127, -0.0156,  0.0099],
        ...,
        [ 0.0006,  0.0016, -0.0251,  ...,  0.0794,  0.0089, -0.0026],
        [-0.0108,  0.0143,  0.0039,  ..., -0.0065,  0.0548, -0.0453],
        [-0.0160,  0.0111,  0.0049,  ..., -0.0058, -0.0049,  0.0660]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2070, -3.5156,  1.3105,  ...,  0.3521, -0.6953, -3.7793]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 07:29:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too dressed, it is overdressed
If something is too optimistic, it is overoptimistic
If something is too excited, it is overexcited
If something is too zealous, it is overzealous
If something is too sized, it is oversized
If something is too protected, it is overprotected
If something is too stretched, it is overstretched
If something is too played, it is
2024-07-27 07:29:00 root INFO     [order_1_approx] starting weight calculation for If something is too dressed, it is overdressed
If something is too played, it is overplayed
If something is too zealous, it is overzealous
If something is too stretched, it is overstretched
If something is too excited, it is overexcited
If something is too protected, it is overprotected
If something is too optimistic, it is overoptimistic
If something is too sized, it is
2024-07-27 07:29:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 07:31:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0224, -0.9131, -0.6279,  ..., -0.3828, -0.3599, -0.2192],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9746, -2.9961, -1.5791,  ...,  0.4248, -3.3574, -0.0684],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0817, -0.0246, -0.0079,  ..., -0.0070,  0.0061,  0.0195],
        [ 0.0066,  0.0645,  0.0054,  ...,  0.0016, -0.0130,  0.0012],
        [ 0.0141, -0.0090,  0.0544,  ..., -0.0246, -0.0074,  0.0219],
        ...,
        [ 0.0152, -0.0038,  0.0094,  ...,  0.0914, -0.0044,  0.0003],
        [ 0.0069, -0.0068, -0.0179,  ...,  0.0084,  0.0636, -0.0270],
        [-0.0160,  0.0187,  0.0192,  ...,  0.0036, -0.0250,  0.0538]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1709, -2.7891, -1.5830,  ...,  0.6772, -2.9238, -0.0970]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 07:31:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too dressed, it is overdressed
If something is too played, it is overplayed
If something is too zealous, it is overzealous
If something is too stretched, it is overstretched
If something is too excited, it is overexcited
If something is too protected, it is overprotected
If something is too optimistic, it is overoptimistic
If something is too sized, it is
2024-07-27 07:31:16 root INFO     [order_1_approx] starting weight calculation for If something is too excited, it is overexcited
If something is too dressed, it is overdressed
If something is too zealous, it is overzealous
If something is too stretched, it is overstretched
If something is too sized, it is oversized
If something is too played, it is overplayed
If something is too protected, it is overprotected
If something is too optimistic, it is
2024-07-27 07:31:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 07:33:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2512, -0.2155, -0.3379,  ..., -0.2454, -0.2632, -0.0088],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6328e+00, -3.4902e+00,  1.1035e+00,  ...,  4.8828e-04,
        -8.0615e-01, -1.7207e+00], device='cuda:1', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0524,  0.0024, -0.0076,  ...,  0.0025,  0.0008,  0.0039],
        [ 0.0075,  0.0541,  0.0019,  ..., -0.0027,  0.0016,  0.0008],
        [ 0.0070, -0.0113,  0.0457,  ...,  0.0051,  0.0033,  0.0029],
        ...,
        [-0.0076,  0.0006, -0.0015,  ...,  0.0750,  0.0031,  0.0006],
        [-0.0033,  0.0177,  0.0114,  ..., -0.0119,  0.0513, -0.0174],
        [-0.0036, -0.0055, -0.0006,  ...,  0.0071, -0.0078,  0.0418]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7812, -3.6758,  0.7568,  ...,  0.0154, -0.7666, -1.8379]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 07:33:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too excited, it is overexcited
If something is too dressed, it is overdressed
If something is too zealous, it is overzealous
If something is too stretched, it is overstretched
If something is too sized, it is oversized
If something is too played, it is overplayed
If something is too protected, it is overprotected
If something is too optimistic, it is
2024-07-27 07:33:38 root INFO     total operator prediction time: 1117.619247674942 seconds
2024-07-27 07:33:38 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+er_irreg
2024-07-27 07:33:38 root INFO     building operator verb+er_irreg
2024-07-27 07:33:38 root INFO     [order_1_approx] starting weight calculation for If you lose something, you are a loser
If you suffer something, you are a sufferer
If you send something, you are a sender
If you entertain something, you are a entertainer
If you preach something, you are a preacher
If you achieve something, you are a achiever
If you slay something, you are a slayer
If you skydive something, you are a
2024-07-27 07:33:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 07:35:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0843,  0.0684, -0.3203,  ..., -0.1088, -0.4763, -0.2505],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.0195, -1.6387,  0.4883,  ...,  0.4282, -3.4102,  1.2207],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0423, -0.0014,  0.0243,  ...,  0.0206, -0.0061, -0.0027],
        [ 0.0039,  0.0352,  0.0078,  ...,  0.0169,  0.0118, -0.0014],
        [ 0.0044, -0.0024,  0.0361,  ..., -0.0056,  0.0039, -0.0034],
        ...,
        [ 0.0068,  0.0124, -0.0120,  ...,  0.0437, -0.0119,  0.0030],
        [-0.0029, -0.0016, -0.0035,  ...,  0.0054,  0.0262,  0.0005],
        [-0.0005, -0.0004,  0.0173,  ..., -0.0091, -0.0088,  0.0222]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.8945, -1.4951,  0.4531,  ...,  0.7451, -3.5059,  0.9336]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 07:35:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you lose something, you are a loser
If you suffer something, you are a sufferer
If you send something, you are a sender
If you entertain something, you are a entertainer
If you preach something, you are a preacher
If you achieve something, you are a achiever
If you slay something, you are a slayer
If you skydive something, you are a
2024-07-27 07:35:59 root INFO     [order_1_approx] starting weight calculation for If you slay something, you are a slayer
If you skydive something, you are a skydiver
If you achieve something, you are a achiever
If you suffer something, you are a sufferer
If you entertain something, you are a entertainer
If you send something, you are a sender
If you lose something, you are a loser
If you preach something, you are a
2024-07-27 07:35:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 07:38:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3457,  0.3516,  0.0477,  ...,  0.0237, -0.1956,  0.1411],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.9844, -4.1289,  2.3945,  ...,  0.4941, -3.0781, -1.3975],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0864, -0.0150,  0.0247,  ...,  0.0128, -0.0129, -0.0057],
        [-0.0027,  0.0876,  0.0140,  ...,  0.0367,  0.0271, -0.0088],
        [-0.0053, -0.0031,  0.0543,  ...,  0.0212, -0.0468,  0.0029],
        ...,
        [ 0.0129,  0.0259,  0.0007,  ...,  0.0732,  0.0346, -0.0072],
        [-0.0083,  0.0023, -0.0100,  ..., -0.0066,  0.0417, -0.0212],
        [ 0.0012, -0.0026, -0.0003,  ..., -0.0009, -0.0194,  0.0627]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 6.2070, -4.2266,  2.3750,  ...,  1.0977, -3.3633, -1.0898]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 07:38:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you slay something, you are a slayer
If you skydive something, you are a skydiver
If you achieve something, you are a achiever
If you suffer something, you are a sufferer
If you entertain something, you are a entertainer
If you send something, you are a sender
If you lose something, you are a loser
If you preach something, you are a
2024-07-27 07:38:22 root INFO     [order_1_approx] starting weight calculation for If you suffer something, you are a sufferer
If you lose something, you are a loser
If you achieve something, you are a achiever
If you skydive something, you are a skydiver
If you entertain something, you are a entertainer
If you slay something, you are a slayer
If you preach something, you are a preacher
If you send something, you are a
2024-07-27 07:38:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 07:40:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0864,  0.1840,  0.3862,  ...,  0.0840,  0.3682, -0.2009],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3008, -2.5938, -3.2695,  ..., -0.6919, -1.2441, -2.7871],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.3538e-02, -7.3471e-03,  2.1553e-03,  ..., -2.7866e-03,
          2.5604e-02,  1.8978e-03],
        [ 7.1335e-03,  5.6366e-02,  7.2937e-03,  ...,  5.2109e-03,
         -1.4786e-02, -2.9144e-02],
        [ 6.7253e-03, -9.0790e-03,  3.0167e-02,  ..., -8.5526e-03,
         -1.4763e-02,  1.8341e-02],
        ...,
        [ 9.1629e-03,  1.0559e-02, -3.4523e-04,  ...,  4.1046e-02,
          7.0343e-03,  1.1475e-02],
        [-2.7100e-02,  1.8616e-02, -1.3710e-02,  ..., -2.1530e-02,
          2.9724e-02, -5.3406e-03],
        [ 5.6000e-03, -4.6768e-03,  8.9340e-03,  ..., -3.9101e-05,
         -1.1940e-02,  3.2318e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5264, -2.7285, -3.3008,  ..., -0.3896, -1.3203, -2.7246]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 07:40:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you suffer something, you are a sufferer
If you lose something, you are a loser
If you achieve something, you are a achiever
If you skydive something, you are a skydiver
If you entertain something, you are a entertainer
If you slay something, you are a slayer
If you preach something, you are a preacher
If you send something, you are a
2024-07-27 07:40:43 root INFO     [order_1_approx] starting weight calculation for If you slay something, you are a slayer
If you preach something, you are a preacher
If you achieve something, you are a achiever
If you lose something, you are a loser
If you send something, you are a sender
If you skydive something, you are a skydiver
If you entertain something, you are a entertainer
If you suffer something, you are a
2024-07-27 07:40:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 07:43:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0787,  0.1559, -0.1621,  ..., -0.6143,  0.0191,  0.0167],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.8594, -2.9395,  1.0020,  ..., -2.1328,  0.1123,  0.7715],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0421, -0.0398,  0.0279,  ..., -0.0009,  0.0030,  0.0134],
        [-0.0105,  0.0436,  0.0137,  ...,  0.0090,  0.0300, -0.0098],
        [ 0.0142, -0.0141,  0.0352,  ...,  0.0029,  0.0002, -0.0139],
        ...,
        [ 0.0121,  0.0031, -0.0042,  ...,  0.0242,  0.0193, -0.0009],
        [-0.0078,  0.0304, -0.0113,  ...,  0.0117,  0.0130, -0.0349],
        [ 0.0125, -0.0003,  0.0053,  ..., -0.0130, -0.0198,  0.0231]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.0195, -2.9609,  1.1719,  ..., -1.6328, -0.2605,  0.4775]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 07:43:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you slay something, you are a slayer
If you preach something, you are a preacher
If you achieve something, you are a achiever
If you lose something, you are a loser
If you send something, you are a sender
If you skydive something, you are a skydiver
If you entertain something, you are a entertainer
If you suffer something, you are a
2024-07-27 07:43:04 root INFO     [order_1_approx] starting weight calculation for If you achieve something, you are a achiever
If you skydive something, you are a skydiver
If you slay something, you are a slayer
If you preach something, you are a preacher
If you lose something, you are a loser
If you send something, you are a sender
If you suffer something, you are a sufferer
If you entertain something, you are a
2024-07-27 07:43:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 07:45:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3447,  0.3008, -0.1846,  ..., -0.0223, -0.0526, -0.2700],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2070, -2.1309, -0.3162,  ...,  0.1250, -1.9814, -4.5742],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1038, -0.0072,  0.0240,  ...,  0.0008,  0.0011,  0.0030],
        [-0.0147,  0.0837, -0.0265,  ...,  0.0166,  0.0253, -0.0068],
        [ 0.0049, -0.0135,  0.0832,  ...,  0.0089, -0.0271,  0.0009],
        ...,
        [ 0.0188,  0.0226, -0.0224,  ...,  0.0438,  0.0070,  0.0080],
        [ 0.0192,  0.0209,  0.0054,  ..., -0.0195,  0.0134,  0.0017],
        [ 0.0053, -0.0048,  0.0052,  ..., -0.0031, -0.0307,  0.0634]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3340, -1.8467, -0.8330,  ...,  0.2568, -1.9482, -4.8008]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 07:45:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you achieve something, you are a achiever
If you skydive something, you are a skydiver
If you slay something, you are a slayer
If you preach something, you are a preacher
If you lose something, you are a loser
If you send something, you are a sender
If you suffer something, you are a sufferer
If you entertain something, you are a
2024-07-27 07:45:21 root INFO     [order_1_approx] starting weight calculation for If you suffer something, you are a sufferer
If you entertain something, you are a entertainer
If you send something, you are a sender
If you slay something, you are a slayer
If you skydive something, you are a skydiver
If you preach something, you are a preacher
If you achieve something, you are a achiever
If you lose something, you are a
2024-07-27 07:45:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 07:47:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0696,  0.3525,  0.1709,  ..., -0.1873,  0.5747, -0.3369],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2695, -1.5420, -0.9951,  ..., -0.3975, -2.4824,  0.6211],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0138, -0.0171,  0.0165,  ...,  0.0169, -0.0157,  0.0196],
        [ 0.0014,  0.0278, -0.0003,  ...,  0.0239,  0.0088,  0.0009],
        [ 0.0066,  0.0021,  0.0316,  ..., -0.0035,  0.0033, -0.0135],
        ...,
        [ 0.0202,  0.0052, -0.0114,  ...,  0.0073,  0.0072,  0.0048],
        [-0.0143,  0.0279, -0.0029,  ..., -0.0184,  0.0108, -0.0139],
        [ 0.0061,  0.0084,  0.0041,  ..., -0.0212, -0.0088,  0.0004]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2578, -1.4521, -1.0293,  ...,  0.1533, -2.7324,  0.3347]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 07:47:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you suffer something, you are a sufferer
If you entertain something, you are a entertainer
If you send something, you are a sender
If you slay something, you are a slayer
If you skydive something, you are a skydiver
If you preach something, you are a preacher
If you achieve something, you are a achiever
If you lose something, you are a
2024-07-27 07:47:39 root INFO     [order_1_approx] starting weight calculation for If you slay something, you are a slayer
If you send something, you are a sender
If you entertain something, you are a entertainer
If you lose something, you are a loser
If you suffer something, you are a sufferer
If you skydive something, you are a skydiver
If you preach something, you are a preacher
If you achieve something, you are a
2024-07-27 07:47:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 07:49:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4119,  0.2932, -0.3462,  ...,  0.0228, -0.1625, -0.1780],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7715,  0.2549, -1.5254,  ...,  0.4219, -5.7266, -2.5039],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.5319e-02,  1.0891e-03,  1.1986e-02,  ...,  2.3834e-02,
         -4.6635e-04,  4.3060e-02],
        [-1.4175e-02,  4.0894e-02,  8.8806e-03,  ...,  1.1322e-02,
          1.6785e-02, -8.4991e-03],
        [ 1.9592e-02, -8.4534e-03,  1.9150e-02,  ...,  1.2794e-02,
         -4.2953e-03,  1.3245e-02],
        ...,
        [ 8.6212e-03,  1.2268e-02, -2.8198e-02,  ...,  1.8204e-02,
          2.2491e-02,  3.4370e-03],
        [ 3.3531e-03,  2.2141e-02,  1.0117e-02,  ..., -6.6757e-03,
         -5.8746e-04,  4.8637e-03],
        [ 1.3680e-02, -1.7715e-02, -1.6113e-02,  ...,  9.5725e-05,
          4.8561e-03,  9.1553e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0723, -0.2410, -1.3936,  ...,  0.9976, -6.1797, -2.4590]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 07:49:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you slay something, you are a slayer
If you send something, you are a sender
If you entertain something, you are a entertainer
If you lose something, you are a loser
If you suffer something, you are a sufferer
If you skydive something, you are a skydiver
If you preach something, you are a preacher
If you achieve something, you are a
2024-07-27 07:49:57 root INFO     [order_1_approx] starting weight calculation for If you achieve something, you are a achiever
If you send something, you are a sender
If you suffer something, you are a sufferer
If you preach something, you are a preacher
If you entertain something, you are a entertainer
If you skydive something, you are a skydiver
If you lose something, you are a loser
If you slay something, you are a
2024-07-27 07:49:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 07:52:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4058,  0.1410, -0.5820,  ...,  0.0184,  0.0253, -0.0634],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5098, -3.1797, -2.3398,  ..., -4.5352, -2.4551, -2.1172],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0873, -0.0206,  0.0136,  ...,  0.0018, -0.0046,  0.0193],
        [ 0.0172,  0.0641,  0.0224,  ..., -0.0039,  0.0243, -0.0105],
        [-0.0123, -0.0350,  0.0668,  ...,  0.0514, -0.0192, -0.0115],
        ...,
        [ 0.0046,  0.0282,  0.0258,  ...,  0.0618,  0.0418,  0.0020],
        [-0.0152,  0.0198, -0.0190,  ...,  0.0013,  0.0552, -0.0051],
        [ 0.0142,  0.0117, -0.0150,  ..., -0.0246,  0.0221,  0.0628]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6328, -3.0957, -1.8135,  ..., -4.2422, -2.3691, -2.3301]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 07:52:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you achieve something, you are a achiever
If you send something, you are a sender
If you suffer something, you are a sufferer
If you preach something, you are a preacher
If you entertain something, you are a entertainer
If you skydive something, you are a skydiver
If you lose something, you are a loser
If you slay something, you are a
2024-07-27 07:52:08 root INFO     total operator prediction time: 1110.5491342544556 seconds
2024-07-27 07:52:08 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj - superlative
2024-07-27 07:52:08 root INFO     building operator adj - superlative
2024-07-27 07:52:08 root INFO     [order_1_approx] starting weight calculation for If something is the most lengthy, it is lengthiest
If something is the most merry, it is merriest
If something is the most shiny, it is shiniest
If something is the most cruel, it is cruelest
If something is the most hungry, it is hungriest
If something is the most strong, it is strongest
If something is the most sad, it is saddest
If something is the most healthy, it is
2024-07-27 07:52:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 07:54:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1493, -0.1970, -0.2603,  ..., -0.3000, -0.0888, -0.1594],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9644, -6.4727, -0.5762,  ..., -0.2783, -2.1523, -2.2734],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0259, -0.0048,  0.0156,  ..., -0.0025, -0.0045,  0.0055],
        [ 0.0053,  0.0356,  0.0110,  ..., -0.0079,  0.0193,  0.0007],
        [ 0.0056, -0.0101,  0.0329,  ...,  0.0023, -0.0086,  0.0017],
        ...,
        [ 0.0062,  0.0185,  0.0006,  ...,  0.0391,  0.0071,  0.0054],
        [-0.0008, -0.0057, -0.0037,  ..., -0.0051,  0.0268, -0.0221],
        [-0.0044, -0.0120, -0.0028,  ..., -0.0004,  0.0006,  0.0159]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4614, -6.4023, -0.8452,  ..., -0.1597, -1.7803, -2.0039]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 07:54:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most lengthy, it is lengthiest
If something is the most merry, it is merriest
If something is the most shiny, it is shiniest
If something is the most cruel, it is cruelest
If something is the most hungry, it is hungriest
If something is the most strong, it is strongest
If something is the most sad, it is saddest
If something is the most healthy, it is
2024-07-27 07:54:25 root INFO     [order_1_approx] starting weight calculation for If something is the most cruel, it is cruelest
If something is the most strong, it is strongest
If something is the most healthy, it is healthiest
If something is the most sad, it is saddest
If something is the most hungry, it is hungriest
If something is the most lengthy, it is lengthiest
If something is the most shiny, it is shiniest
If something is the most merry, it is
2024-07-27 07:54:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 07:56:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0116,  0.1974, -0.4912,  ..., -0.4026, -0.8970, -0.2218],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.7773, -3.5156, -2.0273,  ...,  1.3457, -1.6699, -1.3447],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0440, -0.0064,  0.0167,  ..., -0.0078,  0.0081,  0.0278],
        [ 0.0127,  0.0135, -0.0016,  ...,  0.0069,  0.0006,  0.0067],
        [-0.0005, -0.0033,  0.0319,  ..., -0.0114, -0.0325, -0.0067],
        ...,
        [ 0.0082,  0.0029,  0.0040,  ...,  0.0448,  0.0117, -0.0056],
        [ 0.0023, -0.0021, -0.0098,  ...,  0.0077,  0.0305, -0.0142],
        [ 0.0088, -0.0147,  0.0053,  ..., -0.0088,  0.0030,  0.0225]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.1055, -3.3633, -1.9209,  ...,  1.6680, -1.5938, -1.5762]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 07:56:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most cruel, it is cruelest
If something is the most strong, it is strongest
If something is the most healthy, it is healthiest
If something is the most sad, it is saddest
If something is the most hungry, it is hungriest
If something is the most lengthy, it is lengthiest
If something is the most shiny, it is shiniest
If something is the most merry, it is
2024-07-27 07:56:43 root INFO     [order_1_approx] starting weight calculation for If something is the most healthy, it is healthiest
If something is the most shiny, it is shiniest
If something is the most strong, it is strongest
If something is the most sad, it is saddest
If something is the most merry, it is merriest
If something is the most lengthy, it is lengthiest
If something is the most hungry, it is hungriest
If something is the most cruel, it is
2024-07-27 07:56:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 07:59:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2350,  0.1277,  0.2407,  ..., -0.3555,  0.0101,  0.0761],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3496, -3.5762, -2.1602,  ..., -0.6284, -0.0156,  0.1338],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0551, -0.0080,  0.0240,  ...,  0.0046, -0.0110,  0.0115],
        [ 0.0069,  0.0272,  0.0244,  ..., -0.0092,  0.0273,  0.0140],
        [ 0.0076,  0.0156,  0.0231,  ..., -0.0005, -0.0127, -0.0003],
        ...,
        [-0.0010,  0.0318,  0.0059,  ...,  0.0228,  0.0285, -0.0072],
        [-0.0028, -0.0033,  0.0235,  ..., -0.0038,  0.0466, -0.0106],
        [-0.0158, -0.0104, -0.0007,  ..., -0.0124, -0.0107,  0.0141]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.9702, -3.8379, -2.2754,  ..., -0.8892, -0.2932,  0.3643]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 07:59:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most healthy, it is healthiest
If something is the most shiny, it is shiniest
If something is the most strong, it is strongest
If something is the most sad, it is saddest
If something is the most merry, it is merriest
If something is the most lengthy, it is lengthiest
If something is the most hungry, it is hungriest
If something is the most cruel, it is
2024-07-27 07:59:05 root INFO     [order_1_approx] starting weight calculation for If something is the most sad, it is saddest
If something is the most shiny, it is shiniest
If something is the most cruel, it is cruelest
If something is the most strong, it is strongest
If something is the most healthy, it is healthiest
If something is the most merry, it is merriest
If something is the most lengthy, it is lengthiest
If something is the most hungry, it is
2024-07-27 07:59:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 08:01:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0311, -0.1650, -0.4817,  ...,  0.0376, -0.2494,  0.2507],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7559, -5.0391,  1.1826,  ..., -1.7266, -4.4453, -1.4336],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0426,  0.0027,  0.0202,  ..., -0.0042, -0.0098,  0.0022],
        [ 0.0049,  0.0418, -0.0041,  ...,  0.0017, -0.0078, -0.0153],
        [ 0.0281,  0.0181,  0.0205,  ...,  0.0021,  0.0020, -0.0065],
        ...,
        [ 0.0259,  0.0069,  0.0060,  ...,  0.0432, -0.0100, -0.0151],
        [-0.0096,  0.0143,  0.0098,  ..., -0.0052,  0.0497, -0.0073],
        [-0.0127, -0.0292,  0.0232,  ..., -0.0226, -0.0243,  0.0247]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.9229, -4.6328,  1.1611,  ..., -1.6846, -4.3984, -1.1104]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 08:01:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most sad, it is saddest
If something is the most shiny, it is shiniest
If something is the most cruel, it is cruelest
If something is the most strong, it is strongest
If something is the most healthy, it is healthiest
If something is the most merry, it is merriest
If something is the most lengthy, it is lengthiest
If something is the most hungry, it is
2024-07-27 08:01:24 root INFO     [order_1_approx] starting weight calculation for If something is the most healthy, it is healthiest
If something is the most strong, it is strongest
If something is the most hungry, it is hungriest
If something is the most cruel, it is cruelest
If something is the most merry, it is merriest
If something is the most lengthy, it is lengthiest
If something is the most shiny, it is shiniest
If something is the most sad, it is
2024-07-27 08:01:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 08:03:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2751, -0.0421, -0.2798,  ..., -0.1594, -0.3604,  0.1105],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.9297e-03, -5.8359e+00, -2.9902e+00,  ..., -4.6211e+00,
         1.5723e-01, -2.6250e+00], device='cuda:1', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0193, -0.0062, -0.0078,  ..., -0.0070, -0.0070, -0.0096],
        [ 0.0172,  0.0018,  0.0170,  ..., -0.0036,  0.0163,  0.0034],
        [ 0.0028, -0.0009,  0.0073,  ...,  0.0109, -0.0169, -0.0013],
        ...,
        [-0.0086,  0.0210,  0.0018,  ...,  0.0224,  0.0019,  0.0160],
        [-0.0147, -0.0088,  0.0144,  ...,  0.0123,  0.0397, -0.0135],
        [-0.0016, -0.0020, -0.0094,  ..., -0.0244,  0.0018,  0.0128]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0125, -5.7344, -3.0898,  ..., -4.5078,  0.2147, -2.3438]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 08:03:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most healthy, it is healthiest
If something is the most strong, it is strongest
If something is the most hungry, it is hungriest
If something is the most cruel, it is cruelest
If something is the most merry, it is merriest
If something is the most lengthy, it is lengthiest
If something is the most shiny, it is shiniest
If something is the most sad, it is
2024-07-27 08:03:42 root INFO     [order_1_approx] starting weight calculation for If something is the most sad, it is saddest
If something is the most shiny, it is shiniest
If something is the most cruel, it is cruelest
If something is the most lengthy, it is lengthiest
If something is the most hungry, it is hungriest
If something is the most healthy, it is healthiest
If something is the most merry, it is merriest
If something is the most strong, it is
2024-07-27 08:03:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 08:05:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0706, -0.4268, -0.2524,  ..., -0.1904, -0.1541, -0.2964],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2686, -6.7891, -3.0898,  ...,  0.3081, -2.2773, -1.9531],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0342, -0.0186,  0.0016,  ..., -0.0262, -0.0023,  0.0111],
        [-0.0107,  0.0304,  0.0029,  ..., -0.0023,  0.0108,  0.0151],
        [ 0.0174, -0.0104,  0.0198,  ..., -0.0086, -0.0224, -0.0041],
        ...,
        [-0.0036,  0.0149,  0.0034,  ...,  0.0368, -0.0032,  0.0033],
        [-0.0144, -0.0130, -0.0051,  ..., -0.0088,  0.0253, -0.0294],
        [-0.0127,  0.0020,  0.0021,  ..., -0.0012, -0.0082,  0.0144]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1152, -6.6484, -3.0801,  ...,  0.1169, -2.5469, -1.9141]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 08:05:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most sad, it is saddest
If something is the most shiny, it is shiniest
If something is the most cruel, it is cruelest
If something is the most lengthy, it is lengthiest
If something is the most hungry, it is hungriest
If something is the most healthy, it is healthiest
If something is the most merry, it is merriest
If something is the most strong, it is
2024-07-27 08:05:58 root INFO     [order_1_approx] starting weight calculation for If something is the most hungry, it is hungriest
If something is the most healthy, it is healthiest
If something is the most cruel, it is cruelest
If something is the most sad, it is saddest
If something is the most shiny, it is shiniest
If something is the most merry, it is merriest
If something is the most strong, it is strongest
If something is the most lengthy, it is
2024-07-27 08:05:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 08:08:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0682, -0.1832, -0.3711,  ..., -0.2842, -0.4700,  0.1267],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.1719, -4.5820, -1.1719,  ..., -2.4023, -2.3555, -3.5547],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0396, -0.0043,  0.0034,  ...,  0.0050,  0.0047,  0.0050],
        [-0.0104,  0.0367,  0.0085,  ..., -0.0007,  0.0068,  0.0039],
        [-0.0042, -0.0003,  0.0341,  ..., -0.0069,  0.0005, -0.0005],
        ...,
        [ 0.0015,  0.0271,  0.0221,  ...,  0.0438,  0.0069,  0.0049],
        [ 0.0097, -0.0004,  0.0135,  ...,  0.0066,  0.0302, -0.0170],
        [-0.0035, -0.0014, -0.0054,  ..., -0.0209, -0.0192,  0.0074]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.2559, -4.6875, -1.3154,  ..., -2.3496, -2.0820, -3.3691]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 08:08:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most hungry, it is hungriest
If something is the most healthy, it is healthiest
If something is the most cruel, it is cruelest
If something is the most sad, it is saddest
If something is the most shiny, it is shiniest
If something is the most merry, it is merriest
If something is the most strong, it is strongest
If something is the most lengthy, it is
2024-07-27 08:08:18 root INFO     [order_1_approx] starting weight calculation for If something is the most strong, it is strongest
If something is the most sad, it is saddest
If something is the most lengthy, it is lengthiest
If something is the most merry, it is merriest
If something is the most hungry, it is hungriest
If something is the most cruel, it is cruelest
If something is the most healthy, it is healthiest
If something is the most shiny, it is
2024-07-27 08:08:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 08:10:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1801, -0.1265, -0.2981,  ...,  0.3430,  0.4170, -0.4038],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.7285, -1.3096, -2.9688,  ...,  1.5176, -1.7412,  1.5703],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0659, -0.0176,  0.0084,  ...,  0.0060, -0.0042,  0.0109],
        [-0.0148,  0.0510,  0.0164,  ..., -0.0036, -0.0032,  0.0124],
        [-0.0064, -0.0064,  0.0399,  ..., -0.0144, -0.0294, -0.0017],
        ...,
        [ 0.0054,  0.0336, -0.0044,  ...,  0.0498, -0.0088, -0.0047],
        [ 0.0037,  0.0259, -0.0102,  ...,  0.0101,  0.0425, -0.0125],
        [-0.0135,  0.0023,  0.0195,  ..., -0.0375, -0.0102,  0.0301]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.6621, -1.4678, -2.9141,  ...,  1.7344, -1.3965,  1.5020]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 08:10:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most strong, it is strongest
If something is the most sad, it is saddest
If something is the most lengthy, it is lengthiest
If something is the most merry, it is merriest
If something is the most hungry, it is hungriest
If something is the most cruel, it is cruelest
If something is the most healthy, it is healthiest
If something is the most shiny, it is
2024-07-27 08:10:36 root INFO     total operator prediction time: 1107.7810366153717 seconds
2024-07-27 08:10:36 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_3pSg - Ved
2024-07-27 08:10:36 root INFO     building operator verb_3pSg - Ved
2024-07-27 08:10:36 root INFO     [order_1_approx] starting weight calculation for When he performs something, something has been performed
When he refers something, something has been referred
When he occurs something, something has been occurred
When he suggests something, something has been suggested
When he describes something, something has been described
When he appears something, something has been appeared
When he loses something, something has been lost
When he decides something, something has been
2024-07-27 08:10:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 08:12:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1702,  0.0200, -0.1782,  ...,  0.2275, -0.1461, -0.0895],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6914, -1.3750,  2.4922,  ...,  0.1130, -2.3340,  0.2734],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0255, -0.0176,  0.0010,  ..., -0.0087,  0.0011,  0.0191],
        [-0.0177,  0.0252,  0.0160,  ...,  0.0225,  0.0049, -0.0101],
        [-0.0042,  0.0255,  0.0101,  ...,  0.0042, -0.0111, -0.0038],
        ...,
        [ 0.0010,  0.0210,  0.0010,  ...,  0.0324,  0.0120,  0.0143],
        [ 0.0003,  0.0140, -0.0039,  ..., -0.0012,  0.0110, -0.0249],
        [ 0.0039, -0.0079,  0.0163,  ..., -0.0067, -0.0115,  0.0052]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7656, -1.5312,  2.4219,  ...,  0.3306, -2.2695,  0.4175]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 08:12:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he performs something, something has been performed
When he refers something, something has been referred
When he occurs something, something has been occurred
When he suggests something, something has been suggested
When he describes something, something has been described
When he appears something, something has been appeared
When he loses something, something has been lost
When he decides something, something has been
2024-07-27 08:12:58 root INFO     [order_1_approx] starting weight calculation for When he appears something, something has been appeared
When he occurs something, something has been occurred
When he loses something, something has been lost
When he describes something, something has been described
When he refers something, something has been referred
When he decides something, something has been decided
When he suggests something, something has been suggested
When he performs something, something has been
2024-07-27 08:12:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 08:15:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3652,  0.0511, -0.1836,  ...,  0.0429,  0.0486,  0.0061],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2539, -0.2871,  5.3047,  ..., -1.1846, -2.2480, -1.4668],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0367,  0.0006,  0.0044,  ...,  0.0073, -0.0157,  0.0159],
        [-0.0105,  0.0439,  0.0175,  ...,  0.0151,  0.0125,  0.0094],
        [ 0.0051,  0.0030,  0.0221,  ..., -0.0161, -0.0006,  0.0230],
        ...,
        [ 0.0086,  0.0020, -0.0132,  ...,  0.0220,  0.0098, -0.0002],
        [ 0.0122, -0.0139,  0.0044,  ..., -0.0050,  0.0154, -0.0240],
        [ 0.0099,  0.0029,  0.0079,  ..., -0.0079,  0.0073,  0.0094]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7773, -0.6475,  5.0977,  ..., -0.7896, -1.6221, -1.0293]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 08:15:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he appears something, something has been appeared
When he occurs something, something has been occurred
When he loses something, something has been lost
When he describes something, something has been described
When he refers something, something has been referred
When he decides something, something has been decided
When he suggests something, something has been suggested
When he performs something, something has been
2024-07-27 08:15:20 root INFO     [order_1_approx] starting weight calculation for When he occurs something, something has been occurred
When he appears something, something has been appeared
When he decides something, something has been decided
When he refers something, something has been referred
When he describes something, something has been described
When he performs something, something has been performed
When he suggests something, something has been suggested
When he loses something, something has been
2024-07-27 08:15:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 08:17:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0336,  0.0470,  0.0155,  ...,  0.1650,  0.4023, -0.1215],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6914, -1.0879,  0.9150,  ..., -1.0703, -0.6685, -1.8906],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.0161e-02,  1.2264e-03,  1.0292e-02,  ..., -5.3215e-03,
         -1.8280e-02,  2.2903e-02],
        [ 9.1553e-05,  2.7649e-02,  2.9388e-02,  ...,  1.3184e-02,
          3.6659e-03, -6.8626e-03],
        [ 5.3215e-03, -2.6321e-03,  2.7786e-02,  ..., -1.6983e-02,
         -2.2507e-04, -1.2390e-02],
        ...,
        [-1.4053e-02,  2.4719e-02, -1.7227e-02,  ...,  2.0248e-02,
          1.7609e-02, -2.7084e-04],
        [-1.0490e-03,  1.1673e-02, -1.5945e-02,  ..., -3.1319e-03,
          3.4576e-02, -3.4485e-02],
        [-1.6670e-03,  1.3756e-02,  2.1286e-02,  ..., -1.6037e-02,
         -6.0883e-03, -2.7122e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6709, -1.3066,  0.7915,  ..., -0.4702, -0.4282, -1.6855]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 08:17:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he occurs something, something has been occurred
When he appears something, something has been appeared
When he decides something, something has been decided
When he refers something, something has been referred
When he describes something, something has been described
When he performs something, something has been performed
When he suggests something, something has been suggested
When he loses something, something has been
2024-07-27 08:17:39 root INFO     [order_1_approx] starting weight calculation for When he refers something, something has been referred
When he describes something, something has been described
When he decides something, something has been decided
When he occurs something, something has been occurred
When he loses something, something has been lost
When he performs something, something has been performed
When he suggests something, something has been suggested
When he appears something, something has been
2024-07-27 08:17:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 08:19:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2261, -0.1019, -0.4792,  ...,  0.2292, -0.0100, -0.3965],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7168,  1.2812,  1.9873,  ...,  1.6934, -2.0215, -0.3867],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0409, -0.0119,  0.0180,  ..., -0.0078, -0.0024,  0.0161],
        [ 0.0037,  0.0249,  0.0142,  ...,  0.0257,  0.0041,  0.0042],
        [ 0.0042, -0.0054,  0.0356,  ..., -0.0090, -0.0078, -0.0070],
        ...,
        [-0.0054,  0.0014, -0.0043,  ...,  0.0304,  0.0116,  0.0153],
        [ 0.0097,  0.0020, -0.0009,  ..., -0.0187,  0.0464, -0.0268],
        [-0.0175, -0.0062,  0.0182,  ..., -0.0035, -0.0006,  0.0215]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9297,  1.1162,  1.6855,  ...,  1.4805, -2.0508, -0.3262]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 08:19:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he refers something, something has been referred
When he describes something, something has been described
When he decides something, something has been decided
When he occurs something, something has been occurred
When he loses something, something has been lost
When he performs something, something has been performed
When he suggests something, something has been suggested
When he appears something, something has been
2024-07-27 08:19:56 root INFO     [order_1_approx] starting weight calculation for When he appears something, something has been appeared
When he performs something, something has been performed
When he decides something, something has been decided
When he suggests something, something has been suggested
When he loses something, something has been lost
When he describes something, something has been described
When he refers something, something has been referred
When he occurs something, something has been
2024-07-27 08:19:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 08:22:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2651, -0.0316, -0.5967,  ..., -0.1840, -0.1759, -1.0010],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3311,  1.5781,  2.5664,  ..., -0.7910, -0.3027,  1.2188],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.6234e-02,  4.3640e-03,  2.0859e-02,  ...,  1.1566e-02,
         -1.0895e-02,  3.1097e-02],
        [-2.0447e-02,  3.4973e-02,  3.2776e-02,  ...,  2.2919e-02,
          8.4076e-03, -7.5607e-03],
        [ 1.6891e-02, -1.1452e-02,  3.1097e-02,  ..., -3.8666e-02,
         -2.2888e-05, -2.4796e-03],
        ...,
        [ 6.0921e-03,  1.6510e-02,  8.2550e-03,  ...,  2.1408e-02,
          1.4210e-03,  2.2827e-02],
        [ 8.1940e-03,  6.8779e-03,  2.9583e-03,  ..., -1.7300e-03,
          3.6713e-02, -2.2842e-02],
        [ 4.1924e-03, -2.7237e-03,  1.7609e-02,  ..., -1.3954e-02,
          1.2802e-02,  2.8717e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0867,  1.6357,  2.7500,  ..., -0.5503, -0.2268,  1.6172]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 08:22:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he appears something, something has been appeared
When he performs something, something has been performed
When he decides something, something has been decided
When he suggests something, something has been suggested
When he loses something, something has been lost
When he describes something, something has been described
When he refers something, something has been referred
When he occurs something, something has been
2024-07-27 08:22:15 root INFO     [order_1_approx] starting weight calculation for When he decides something, something has been decided
When he performs something, something has been performed
When he describes something, something has been described
When he suggests something, something has been suggested
When he occurs something, something has been occurred
When he appears something, something has been appeared
When he loses something, something has been lost
When he refers something, something has been
2024-07-27 08:22:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 08:24:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4810, -0.2358, -0.1646,  ...,  0.2737, -0.1234, -0.3315],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5806, -0.2981,  1.7871,  ...,  2.1875, -1.4521, -3.0039],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0389, -0.0113,  0.0039,  ...,  0.0021,  0.0028,  0.0238],
        [-0.0291,  0.0307,  0.0226,  ...,  0.0128, -0.0024,  0.0067],
        [-0.0024, -0.0165,  0.0181,  ..., -0.0083, -0.0076, -0.0142],
        ...,
        [ 0.0167,  0.0184, -0.0179,  ...,  0.0344,  0.0145,  0.0277],
        [-0.0003,  0.0040, -0.0047,  ..., -0.0090,  0.0212, -0.0326],
        [-0.0017, -0.0023,  0.0226,  ..., -0.0083, -0.0046,  0.0141]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9468, -0.6709,  1.9375,  ...,  1.9932, -1.4805, -2.8027]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 08:24:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he decides something, something has been decided
When he performs something, something has been performed
When he describes something, something has been described
When he suggests something, something has been suggested
When he occurs something, something has been occurred
When he appears something, something has been appeared
When he loses something, something has been lost
When he refers something, something has been
2024-07-27 08:24:37 root INFO     [order_1_approx] starting weight calculation for When he refers something, something has been referred
When he appears something, something has been appeared
When he performs something, something has been performed
When he loses something, something has been lost
When he suggests something, something has been suggested
When he occurs something, something has been occurred
When he decides something, something has been decided
When he describes something, something has been
2024-07-27 08:24:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 08:26:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3210, -0.4597,  0.0758,  ...,  0.3159,  0.2391, -0.5796],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1113, -0.0242,  5.0234,  ...,  0.3071, -0.2700, -2.6582],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.6102e-02, -1.7838e-02, -8.8978e-04,  ..., -2.3422e-03,
          8.8425e-03,  1.7807e-02],
        [-7.5760e-03,  2.8992e-02,  2.2354e-02,  ...,  9.6512e-04,
         -2.6779e-03,  1.7456e-02],
        [ 1.2131e-02, -1.8707e-02,  2.1973e-02,  ..., -7.6485e-03,
         -1.2047e-02, -1.6693e-02],
        ...,
        [ 9.4604e-03,  1.9363e-02,  7.4539e-03,  ...,  2.4719e-02,
          1.5732e-02,  1.3649e-02],
        [-7.9441e-04,  5.2261e-03, -1.5808e-02,  ..., -2.0409e-03,
          2.5757e-02, -8.0185e-03],
        [-3.4828e-03,  2.1815e-05,  2.6722e-03,  ..., -1.3832e-02,
         -7.2632e-03,  2.1713e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9707, -0.0139,  5.1523,  ...,  0.5464, -0.5459, -2.2559]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 08:26:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he refers something, something has been referred
When he appears something, something has been appeared
When he performs something, something has been performed
When he loses something, something has been lost
When he suggests something, something has been suggested
When he occurs something, something has been occurred
When he decides something, something has been decided
When he describes something, something has been
2024-07-27 08:26:59 root INFO     [order_1_approx] starting weight calculation for When he occurs something, something has been occurred
When he appears something, something has been appeared
When he refers something, something has been referred
When he loses something, something has been lost
When he decides something, something has been decided
When he describes something, something has been described
When he performs something, something has been performed
When he suggests something, something has been
2024-07-27 08:26:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 08:29:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1218,  0.0754,  0.0511,  ...,  0.5044, -0.1227, -0.1494],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.5195,  0.0176, -0.2881,  ...,  1.7939,  0.2368,  0.2344],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0582, -0.0124,  0.0042,  ..., -0.0135, -0.0193,  0.0161],
        [-0.0114,  0.0387,  0.0011,  ...,  0.0213, -0.0137,  0.0162],
        [ 0.0021, -0.0145,  0.0346,  ..., -0.0189, -0.0104, -0.0092],
        ...,
        [-0.0204, -0.0007, -0.0105,  ...,  0.0213,  0.0068,  0.0276],
        [ 0.0111,  0.0162,  0.0017,  ..., -0.0134,  0.0344, -0.0507],
        [ 0.0049,  0.0051,  0.0211,  ..., -0.0100,  0.0125,  0.0040]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.1719, -0.1238, -0.0934,  ...,  1.6953,  0.0071,  0.3716]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 08:29:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he occurs something, something has been occurred
When he appears something, something has been appeared
When he refers something, something has been referred
When he loses something, something has been lost
When he decides something, something has been decided
When he describes something, something has been described
When he performs something, something has been performed
When he suggests something, something has been
2024-07-27 08:29:20 root INFO     total operator prediction time: 1124.2489235401154 seconds
2024-07-27 08:29:20 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun - plural_reg
2024-07-27 08:29:20 root INFO     building operator noun - plural_reg
2024-07-27 08:29:20 root INFO     [order_1_approx] starting weight calculation for The plural form of version is versions
The plural form of population is populations
The plural form of month is months
The plural form of road is roads
The plural form of town is towns
The plural form of hour is hours
The plural form of office is offices
The plural form of website is
2024-07-27 08:29:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 08:31:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0455,  0.2837, -0.2534,  ...,  0.0471, -0.1899, -0.0797],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5000, -3.3223,  1.4609,  ...,  0.6333, -0.9268, -0.5352],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0351, -0.0033,  0.0055,  ...,  0.0085,  0.0177,  0.0016],
        [ 0.0039,  0.0825,  0.0102,  ...,  0.0016, -0.0023,  0.0045],
        [ 0.0191,  0.0070,  0.0630,  ...,  0.0157, -0.0138,  0.0243],
        ...,
        [ 0.0005,  0.0237,  0.0072,  ...,  0.0341,  0.0116, -0.0105],
        [-0.0050,  0.0366, -0.0116,  ...,  0.0187,  0.0509,  0.0066],
        [ 0.0013, -0.0024,  0.0055,  ...,  0.0022, -0.0313,  0.0586]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9551, -3.7090,  0.9126,  ...,  1.1797, -1.0830, -0.2515]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 08:31:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of version is versions
The plural form of population is populations
The plural form of month is months
The plural form of road is roads
The plural form of town is towns
The plural form of hour is hours
The plural form of office is offices
The plural form of website is
2024-07-27 08:31:42 root INFO     [order_1_approx] starting weight calculation for The plural form of population is populations
The plural form of version is versions
The plural form of town is towns
The plural form of hour is hours
The plural form of road is roads
The plural form of website is websites
The plural form of office is offices
The plural form of month is
2024-07-27 08:31:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 08:34:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2964, -0.2771, -0.2070,  ..., -0.0217, -0.3718, -0.0215],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6768, -4.0312,  0.6421,  ..., -1.3789,  0.8457, -1.1904],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0409,  0.0142, -0.0134,  ...,  0.0009, -0.0043,  0.0023],
        [ 0.0014,  0.0673, -0.0069,  ...,  0.0132,  0.0169, -0.0191],
        [-0.0016,  0.0118,  0.0337,  ..., -0.0082, -0.0348,  0.0150],
        ...,
        [-0.0007,  0.0193,  0.0027,  ...,  0.0540, -0.0065,  0.0268],
        [-0.0190,  0.0167, -0.0082,  ...,  0.0047,  0.0321,  0.0070],
        [-0.0131,  0.0107, -0.0227,  ...,  0.0043, -0.0103,  0.0325]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7852, -3.8867,  0.3083,  ..., -1.4248,  0.2852, -0.6245]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 08:34:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of population is populations
The plural form of version is versions
The plural form of town is towns
The plural form of hour is hours
The plural form of road is roads
The plural form of website is websites
The plural form of office is offices
The plural form of month is
2024-07-27 08:34:04 root INFO     [order_1_approx] starting weight calculation for The plural form of website is websites
The plural form of population is populations
The plural form of road is roads
The plural form of hour is hours
The plural form of office is offices
The plural form of version is versions
The plural form of month is months
The plural form of town is
2024-07-27 08:34:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 08:36:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2927,  0.3054,  0.1716,  ..., -0.1794, -0.1371, -0.3159],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.5566, -3.9141, -0.0457,  ..., -0.4473,  0.4678, -1.1621],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0651,  0.0099,  0.0097,  ...,  0.0013, -0.0077,  0.0114],
        [ 0.0134,  0.0539, -0.0243,  ...,  0.0055,  0.0152, -0.0029],
        [ 0.0022,  0.0003,  0.0525,  ...,  0.0025, -0.0238,  0.0267],
        ...,
        [-0.0013,  0.0034, -0.0080,  ...,  0.0569,  0.0136, -0.0035],
        [-0.0074,  0.0065, -0.0062,  ...,  0.0121,  0.0438, -0.0071],
        [ 0.0079,  0.0068,  0.0014,  ..., -0.0069,  0.0090,  0.0260]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.3848, -3.7383, -0.1990,  ..., -0.3198,  0.8789, -1.1719]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 08:36:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of website is websites
The plural form of population is populations
The plural form of road is roads
The plural form of hour is hours
The plural form of office is offices
The plural form of version is versions
The plural form of month is months
The plural form of town is
2024-07-27 08:36:26 root INFO     [order_1_approx] starting weight calculation for The plural form of road is roads
The plural form of month is months
The plural form of population is populations
The plural form of town is towns
The plural form of website is websites
The plural form of hour is hours
The plural form of office is offices
The plural form of version is
2024-07-27 08:36:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 08:38:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3022, -0.0015, -0.3147,  ...,  0.1909,  0.1115,  0.2065],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9121, -4.1133, -0.7725,  ..., -1.5713, -1.8760, -1.3594],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0654, -0.0091, -0.0359,  ...,  0.0022,  0.0120, -0.0278],
        [ 0.0077,  0.0852,  0.0203,  ...,  0.0131, -0.0110,  0.0194],
        [ 0.0044, -0.0004,  0.0632,  ..., -0.0321, -0.0169,  0.0057],
        ...,
        [ 0.0095,  0.0304,  0.0144,  ...,  0.0538, -0.0319,  0.0272],
        [-0.0178, -0.0188, -0.0222,  ..., -0.0173,  0.0666, -0.0224],
        [ 0.0120,  0.0129,  0.0114,  ..., -0.0070, -0.0326,  0.0762]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4863, -4.4844, -0.5479,  ..., -1.9404, -0.9678, -1.9180]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 08:38:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of road is roads
The plural form of month is months
The plural form of population is populations
The plural form of town is towns
The plural form of website is websites
The plural form of hour is hours
The plural form of office is offices
The plural form of version is
2024-07-27 08:38:47 root INFO     [order_1_approx] starting weight calculation for The plural form of month is months
The plural form of version is versions
The plural form of town is towns
The plural form of office is offices
The plural form of hour is hours
The plural form of website is websites
The plural form of road is roads
The plural form of population is
2024-07-27 08:38:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 08:41:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5435,  0.4272, -0.0115,  ..., -0.1841, -0.0410,  0.0308],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2422, -3.7227,  1.5195,  ..., -1.6064, -2.7109, -2.0078],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0178, -0.0007, -0.0849,  ...,  0.0224,  0.0692, -0.0491],
        [ 0.0453,  0.0618,  0.0579,  ...,  0.0206, -0.0309,  0.0535],
        [ 0.0094,  0.0100,  0.0489,  ...,  0.0015, -0.0217,  0.0247],
        ...,
        [ 0.0331,  0.0141,  0.0356,  ...,  0.0528, -0.0399,  0.0530],
        [ 0.0151, -0.0064, -0.0089,  ...,  0.0023,  0.0358, -0.0120],
        [-0.0037,  0.0108,  0.0150,  ...,  0.0075, -0.0271,  0.0653]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.3125, -5.2656,  0.8330,  ..., -2.4551, -2.6699, -2.5352]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 08:41:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of month is months
The plural form of version is versions
The plural form of town is towns
The plural form of office is offices
The plural form of hour is hours
The plural form of website is websites
The plural form of road is roads
The plural form of population is
2024-07-27 08:41:10 root INFO     [order_1_approx] starting weight calculation for The plural form of office is offices
The plural form of month is months
The plural form of website is websites
The plural form of version is versions
The plural form of hour is hours
The plural form of population is populations
The plural form of town is towns
The plural form of road is
2024-07-27 08:41:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 08:43:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0051,  0.1353,  0.2206,  ...,  0.1942,  0.0751, -0.2012],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.2393, -5.2734, -1.5498,  ..., -0.1460, -0.7856, -2.2266],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.0052e-01,  6.2103e-03,  7.9498e-03,  ...,  5.3177e-03,
         -1.3618e-03,  2.9182e-03],
        [ 4.6043e-03,  5.3833e-02,  1.8845e-02,  ..., -1.7433e-03,
          1.4259e-02,  1.2608e-03],
        [ 1.8346e-04,  9.3231e-03,  6.0211e-02,  ..., -9.2316e-03,
          6.7711e-04,  3.1891e-02],
        ...,
        [ 1.2741e-02, -3.3836e-03,  1.8356e-02,  ...,  6.7017e-02,
          7.0572e-05,  2.4124e-02],
        [-2.1088e-02,  1.5518e-02, -1.5495e-02,  ...,  1.7967e-03,
          7.2815e-02,  6.3629e-03],
        [-3.6812e-03, -2.5940e-03,  3.7880e-03,  ..., -8.4076e-03,
         -2.8687e-03,  4.0466e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1299, -5.8281, -1.4102,  ..., -0.0737, -0.4790, -2.0918]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 08:43:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of office is offices
The plural form of month is months
The plural form of website is websites
The plural form of version is versions
The plural form of hour is hours
The plural form of population is populations
The plural form of town is towns
The plural form of road is
2024-07-27 08:43:32 root INFO     [order_1_approx] starting weight calculation for The plural form of population is populations
The plural form of website is websites
The plural form of hour is hours
The plural form of month is months
The plural form of road is roads
The plural form of town is towns
The plural form of version is versions
The plural form of office is
2024-07-27 08:43:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 08:45:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1168,  0.0599, -0.5269,  ..., -0.0798, -0.1912, -0.3340],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9824, -3.3281,  1.3057,  ..., -0.5732,  0.3115, -0.8970],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0486,  0.0056, -0.0016,  ..., -0.0031, -0.0132,  0.0230],
        [ 0.0199,  0.0516,  0.0011,  ...,  0.0226, -0.0063,  0.0135],
        [ 0.0095,  0.0256,  0.0412,  ..., -0.0054, -0.0096, -0.0036],
        ...,
        [ 0.0014,  0.0100,  0.0090,  ...,  0.0403, -0.0089,  0.0222],
        [-0.0344,  0.0099, -0.0151,  ...,  0.0162,  0.0420,  0.0047],
        [ 0.0246, -0.0035, -0.0083,  ...,  0.0014, -0.0171,  0.0397]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1133, -3.7441,  1.1201,  ..., -0.6079,  0.1624, -0.5923]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 08:45:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of population is populations
The plural form of website is websites
The plural form of hour is hours
The plural form of month is months
The plural form of road is roads
The plural form of town is towns
The plural form of version is versions
The plural form of office is
2024-07-27 08:45:55 root INFO     [order_1_approx] starting weight calculation for The plural form of road is roads
The plural form of month is months
The plural form of office is offices
The plural form of town is towns
The plural form of website is websites
The plural form of version is versions
The plural form of population is populations
The plural form of hour is
2024-07-27 08:45:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 08:48:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2096, -0.0757,  0.0974,  ...,  0.1553, -0.1301, -0.1168],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0767, -2.8164,  1.2256,  ..., -1.6367,  0.4897, -2.3281],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0877,  0.0130, -0.0046,  ...,  0.0043, -0.0144,  0.0103],
        [ 0.0105,  0.0763, -0.0033,  ...,  0.0160,  0.0167, -0.0021],
        [ 0.0067,  0.0045,  0.0527,  ..., -0.0040, -0.0128,  0.0200],
        ...,
        [ 0.0031,  0.0134,  0.0031,  ...,  0.0696, -0.0150,  0.0150],
        [-0.0192, -0.0122, -0.0039,  ...,  0.0140,  0.0407, -0.0145],
        [ 0.0008, -0.0032, -0.0080,  ...,  0.0034, -0.0012,  0.0584]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0524, -3.0352,  0.4028,  ..., -1.7266,  0.4536, -1.6357]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 08:48:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of road is roads
The plural form of month is months
The plural form of office is offices
The plural form of town is towns
The plural form of website is websites
The plural form of version is versions
The plural form of population is populations
The plural form of hour is
2024-07-27 08:48:17 root INFO     total operator prediction time: 1136.778344154358 seconds
2024-07-27 08:48:17 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_Ving - 3pSg
2024-07-27 08:48:17 root INFO     building operator verb_Ving - 3pSg
2024-07-27 08:48:17 root INFO     [order_1_approx] starting weight calculation for When something is learning, it learns
When something is operating, it operates
When something is enabling, it enables
When something is allowing, it allows
When something is improving, it improves
When something is occurring, it occurs
When something is hearing, it hears
When something is requiring, it
2024-07-27 08:48:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 08:50:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3511,  0.1599, -0.3740,  ..., -0.1680, -0.4292, -0.0928],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7319, -2.9648,  1.2539,  ..., -1.3799, -6.5039, -1.0195],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.0913e-02,  7.2479e-05, -1.7853e-03,  ..., -3.1223e-03,
         -2.7008e-02,  1.1642e-02],
        [-6.5155e-03,  5.8899e-02, -1.2924e-02,  ...,  8.3771e-03,
         -6.9809e-03,  3.1647e-02],
        [-2.3422e-03, -1.1742e-02,  4.5471e-02,  ..., -1.1429e-02,
          4.2343e-03,  2.3994e-03],
        ...,
        [-1.0490e-02,  9.2316e-03,  1.3626e-02,  ...,  6.3538e-02,
         -6.9962e-03,  2.5055e-02],
        [-2.3621e-02, -2.9343e-02,  1.6937e-02,  ..., -3.1464e-02,
          5.0049e-02, -5.4810e-02],
        [-1.7593e-02, -3.2024e-03,  1.5518e-02,  ..., -6.4583e-03,
         -2.2873e-02,  2.8336e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6211, -3.5000,  1.6172,  ..., -1.1768, -6.1211, -0.7910]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 08:50:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is learning, it learns
When something is operating, it operates
When something is enabling, it enables
When something is allowing, it allows
When something is improving, it improves
When something is occurring, it occurs
When something is hearing, it hears
When something is requiring, it
2024-07-27 08:50:40 root INFO     [order_1_approx] starting weight calculation for When something is requiring, it requires
When something is operating, it operates
When something is improving, it improves
When something is hearing, it hears
When something is enabling, it enables
When something is learning, it learns
When something is allowing, it allows
When something is occurring, it
2024-07-27 08:50:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 08:53:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1003, -0.1489, -0.6055,  ..., -0.1467, -0.1514, -0.8101],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5366, -4.5273,  0.0137,  ..., -1.5869, -2.9961,  0.7070],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.5134e-02,  7.7362e-03, -1.5480e-02,  ...,  1.3565e-02,
         -1.1787e-02,  3.3691e-02],
        [ 3.5915e-03,  5.4871e-02, -3.1509e-03,  ...,  2.2842e-02,
         -6.8817e-03, -4.6310e-03],
        [-1.8120e-05, -1.4811e-03,  3.8757e-02,  ..., -2.9785e-02,
         -2.7084e-04, -1.3382e-02],
        ...,
        [ 2.0020e-02, -2.9316e-03, -3.5496e-03,  ...,  3.3081e-02,
         -1.0658e-02,  9.1171e-04],
        [-1.5259e-04, -9.1400e-03, -6.4926e-03,  ..., -2.9526e-03,
          4.3427e-02, -2.8931e-02],
        [-4.9591e-04, -1.2253e-02,  7.1564e-03,  ..., -9.1400e-03,
         -5.4550e-03,  3.5248e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2920, -4.1562, -0.1122,  ..., -1.1670, -3.4238,  0.7646]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 08:53:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is requiring, it requires
When something is operating, it operates
When something is improving, it improves
When something is hearing, it hears
When something is enabling, it enables
When something is learning, it learns
When something is allowing, it allows
When something is occurring, it
2024-07-27 08:53:02 root INFO     [order_1_approx] starting weight calculation for When something is enabling, it enables
When something is occurring, it occurs
When something is improving, it improves
When something is hearing, it hears
When something is allowing, it allows
When something is learning, it learns
When something is requiring, it requires
When something is operating, it
2024-07-27 08:53:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 08:55:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2908, -0.1964, -0.4077,  ..., -0.2133, -0.1185, -0.4641],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8398, -4.6758, -0.5488,  ..., -2.5625, -4.9688, -1.0576],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0526, -0.0107,  0.0002,  ..., -0.0093, -0.0098,  0.0182],
        [ 0.0094,  0.0464, -0.0053,  ...,  0.0100, -0.0053,  0.0085],
        [ 0.0033,  0.0235,  0.0372,  ..., -0.0149, -0.0057,  0.0050],
        ...,
        [ 0.0094,  0.0042, -0.0185,  ...,  0.0626, -0.0049,  0.0056],
        [ 0.0103, -0.0005, -0.0099,  ..., -0.0040,  0.0335, -0.0259],
        [ 0.0118, -0.0179,  0.0070,  ..., -0.0143, -0.0157,  0.0332]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7324, -4.4609, -0.2251,  ..., -2.1973, -5.2383, -0.8379]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 08:55:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is enabling, it enables
When something is occurring, it occurs
When something is improving, it improves
When something is hearing, it hears
When something is allowing, it allows
When something is learning, it learns
When something is requiring, it requires
When something is operating, it
2024-07-27 08:55:25 root INFO     [order_1_approx] starting weight calculation for When something is learning, it learns
When something is enabling, it enables
When something is hearing, it hears
When something is operating, it operates
When something is allowing, it allows
When something is requiring, it requires
When something is occurring, it occurs
When something is improving, it
2024-07-27 08:55:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 08:57:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1545, -0.4380, -0.3689,  ..., -0.1750,  0.0492,  0.3303],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.0078, -3.9805, -1.9043,  ...,  0.4302, -6.3555, -0.7734],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.7821e-02, -1.9817e-03,  4.3259e-03,  ...,  2.6035e-03,
         -2.0370e-03,  1.5335e-02],
        [ 1.6174e-02,  2.2217e-02, -1.1131e-02,  ...,  1.8524e-02,
          5.6686e-03,  2.2766e-02],
        [ 3.0441e-03,  7.2670e-03,  1.5457e-02,  ...,  8.4763e-03,
          1.8906e-02, -7.3624e-03],
        ...,
        [-1.0815e-03, -7.6294e-05, -5.6152e-03,  ...,  3.2501e-02,
          5.9090e-03,  1.0582e-02],
        [ 4.7970e-04, -8.3160e-03, -2.3697e-02,  ...,  5.6763e-03,
          3.1433e-02, -5.2765e-02],
        [-1.9760e-02, -6.1798e-04,  7.7057e-03,  ..., -8.7662e-03,
         -1.7281e-03,  8.7128e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.8516, -3.9844, -1.7598,  ...,  0.5537, -6.2031, -1.1387]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 08:57:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is learning, it learns
When something is enabling, it enables
When something is hearing, it hears
When something is operating, it operates
When something is allowing, it allows
When something is requiring, it requires
When something is occurring, it occurs
When something is improving, it
2024-07-27 08:57:47 root INFO     [order_1_approx] starting weight calculation for When something is operating, it operates
When something is occurring, it occurs
When something is learning, it learns
When something is hearing, it hears
When something is enabling, it enables
When something is improving, it improves
When something is requiring, it requires
When something is allowing, it
2024-07-27 08:57:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 09:00:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2681,  0.1769, -0.2888,  ..., -0.4678,  0.0664, -0.4727],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5508, -4.7773, -0.2285,  ..., -0.9917, -7.5586,  1.6074],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0531, -0.0120, -0.0016,  ..., -0.0080,  0.0022,  0.0023],
        [ 0.0099,  0.0352, -0.0168,  ...,  0.0281, -0.0076,  0.0041],
        [-0.0164, -0.0054,  0.0365,  ..., -0.0273,  0.0005, -0.0171],
        ...,
        [ 0.0092,  0.0096, -0.0030,  ...,  0.0385, -0.0002,  0.0008],
        [-0.0012,  0.0107, -0.0209,  ..., -0.0156,  0.0438, -0.0477],
        [-0.0167, -0.0039,  0.0044,  ...,  0.0019, -0.0095,  0.0160]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5371, -4.7852,  0.4609,  ..., -0.8545, -7.7852,  1.5850]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 09:00:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is operating, it operates
When something is occurring, it occurs
When something is learning, it learns
When something is hearing, it hears
When something is enabling, it enables
When something is improving, it improves
When something is requiring, it requires
When something is allowing, it
2024-07-27 09:00:10 root INFO     [order_1_approx] starting weight calculation for When something is enabling, it enables
When something is improving, it improves
When something is learning, it learns
When something is occurring, it occurs
When something is requiring, it requires
When something is operating, it operates
When something is allowing, it allows
When something is hearing, it
2024-07-27 09:00:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 09:02:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0916, -0.0267, -0.0115,  ...,  0.0436, -0.0645, -0.0698],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4121, -3.2656, -0.4297,  ..., -2.3770, -7.2930, -3.8750],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.9143e-02, -1.1635e-04,  1.6251e-02,  ..., -2.9030e-03,
         -3.9940e-03,  7.9956e-03],
        [ 4.7607e-03,  4.9255e-02,  5.3406e-05,  ...,  1.8845e-02,
          2.3594e-03, -1.6460e-03],
        [-3.1281e-03, -1.3115e-02,  4.8981e-02,  ..., -2.1500e-02,
          3.0937e-03, -4.4365e-03],
        ...,
        [ 2.9495e-02, -1.0063e-02, -7.6447e-03,  ...,  4.0192e-02,
          1.1711e-02,  8.5373e-03],
        [ 3.0746e-03,  7.4100e-04, -7.3433e-03,  ..., -4.4365e-03,
          2.7176e-02, -4.4800e-02],
        [-1.3275e-02, -1.1574e-02,  1.3130e-02,  ...,  6.3553e-03,
          1.7490e-03,  2.5436e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3296, -3.4062, -0.5776,  ..., -1.8711, -7.5508, -3.8906]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 09:02:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is enabling, it enables
When something is improving, it improves
When something is learning, it learns
When something is occurring, it occurs
When something is requiring, it requires
When something is operating, it operates
When something is allowing, it allows
When something is hearing, it
2024-07-27 09:02:32 root INFO     [order_1_approx] starting weight calculation for When something is operating, it operates
When something is improving, it improves
When something is learning, it learns
When something is allowing, it allows
When something is hearing, it hears
When something is occurring, it occurs
When something is requiring, it requires
When something is enabling, it
2024-07-27 09:02:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 09:04:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3044, -0.0545, -0.2822,  ..., -0.4373, -0.0308, -0.1567],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5518, -2.2344, -0.7402,  ..., -1.2031, -9.2812, -1.6855],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0454, -0.0020,  0.0236,  ..., -0.0047, -0.0126,  0.0078],
        [ 0.0052,  0.0354, -0.0096,  ...,  0.0154,  0.0006, -0.0082],
        [ 0.0008, -0.0155,  0.0380,  ..., -0.0207, -0.0008,  0.0018],
        ...,
        [ 0.0046,  0.0121, -0.0143,  ...,  0.0388, -0.0011,  0.0038],
        [ 0.0145, -0.0120, -0.0326,  ..., -0.0083,  0.0516, -0.0369],
        [-0.0148, -0.0199,  0.0138,  ..., -0.0171, -0.0147,  0.0338]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0801, -1.9580, -0.4744,  ..., -1.2236, -9.5625, -1.5957]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 09:04:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is operating, it operates
When something is improving, it improves
When something is learning, it learns
When something is allowing, it allows
When something is hearing, it hears
When something is occurring, it occurs
When something is requiring, it requires
When something is enabling, it
2024-07-27 09:04:54 root INFO     [order_1_approx] starting weight calculation for When something is occurring, it occurs
When something is improving, it improves
When something is allowing, it allows
When something is enabling, it enables
When something is operating, it operates
When something is hearing, it hears
When something is requiring, it requires
When something is learning, it
2024-07-27 09:04:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 09:07:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0387, -0.0702, -0.1001,  ..., -0.4912, -0.1543, -0.1467],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1816, -3.2578,  0.6875,  ...,  1.2139, -5.6562, -4.3516],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.7607e-02, -4.0588e-03,  1.1368e-02,  ...,  3.8853e-03,
         -1.0376e-02,  5.9700e-03],
        [ 1.0849e-02,  3.5767e-02, -1.6174e-02,  ...,  1.1917e-02,
         -8.7433e-03,  1.6937e-02],
        [-1.0109e-03, -2.4445e-02,  4.4128e-02,  ..., -7.8888e-03,
          1.6724e-02,  1.6174e-03],
        ...,
        [ 1.4809e-02,  8.9722e-03,  2.9373e-04,  ...,  3.9520e-02,
          4.0016e-03, -3.7842e-03],
        [ 8.0109e-05,  1.6998e-02, -1.6281e-02,  ..., -4.9591e-03,
          2.7573e-02, -4.1138e-02],
        [-1.0529e-02, -3.1624e-03,  1.0254e-02,  ..., -1.2550e-02,
         -1.0824e-03,  2.4765e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2188, -3.0859,  0.7197,  ...,  1.1494, -5.4844, -4.1094]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 09:07:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is occurring, it occurs
When something is improving, it improves
When something is allowing, it allows
When something is enabling, it enables
When something is operating, it operates
When something is hearing, it hears
When something is requiring, it requires
When something is learning, it
2024-07-27 09:07:15 root INFO     total operator prediction time: 1138.3194942474365 seconds
2024-07-27 09:07:15 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_inf - 3pSg
2024-07-27 09:07:15 root INFO     building operator verb_inf - 3pSg
2024-07-27 09:07:15 root INFO     [order_1_approx] starting weight calculation for I exist, he exists
I happen, he happens
I include, he includes
I provide, he provides
I enable, he enables
I appear, he appears
I describe, he describes
I protect, he
2024-07-27 09:07:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 09:09:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2440, -0.0643, -0.4199,  ..., -0.1068,  0.0486,  0.1193],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8906, -4.1562, -2.1113,  ..., -0.9731, -6.3359,  0.9375],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.3203e-02,  4.7302e-03,  1.4107e-02,  ...,  5.6267e-03,
         -1.2405e-02,  3.6713e-02],
        [-2.8168e-02,  1.9958e-02,  1.3252e-02,  ...,  5.7869e-03,
          1.2115e-02,  1.6479e-02],
        [-3.0689e-03,  1.9836e-02,  1.6083e-02,  ..., -1.3275e-02,
         -8.5449e-03, -4.2801e-03],
        ...,
        [-1.2978e-02, -7.3051e-03,  1.1124e-02,  ...,  1.9485e-02,
          1.6098e-02,  9.9792e-03],
        [-1.2619e-02, -1.3229e-02, -1.4328e-02,  ..., -1.4587e-02,
          3.1372e-02, -3.6346e-02],
        [ 1.0214e-03, -9.0179e-03,  7.2479e-05,  ..., -1.4992e-02,
         -8.8882e-03,  2.0203e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6592, -4.3906, -1.9717,  ..., -0.6211, -6.3711,  0.8979]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 09:09:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I exist, he exists
I happen, he happens
I include, he includes
I provide, he provides
I enable, he enables
I appear, he appears
I describe, he describes
I protect, he
2024-07-27 09:09:38 root INFO     [order_1_approx] starting weight calculation for I exist, he exists
I protect, he protects
I happen, he happens
I include, he includes
I describe, he describes
I provide, he provides
I enable, he enables
I appear, he
2024-07-27 09:09:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 09:11:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2952,  0.1003, -0.3914,  ...,  0.0008, -0.2217,  0.0390],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3125, -2.4746, -1.9707,  ...,  1.0547, -6.1133,  2.2871],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0270, -0.0017,  0.0076,  ..., -0.0031, -0.0095,  0.0153],
        [-0.0040,  0.0235, -0.0012,  ...,  0.0037, -0.0010, -0.0013],
        [-0.0124,  0.0052,  0.0266,  ..., -0.0074,  0.0043, -0.0157],
        ...,
        [-0.0213,  0.0131,  0.0024,  ...,  0.0286,  0.0026, -0.0043],
        [-0.0374, -0.0081,  0.0144,  ..., -0.0250,  0.0295, -0.0076],
        [-0.0233, -0.0094,  0.0205,  ..., -0.0108, -0.0132,  0.0170]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2395, -2.4844, -1.6582,  ...,  1.1396, -6.2891,  2.3535]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 09:11:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I exist, he exists
I protect, he protects
I happen, he happens
I include, he includes
I describe, he describes
I provide, he provides
I enable, he enables
I appear, he
2024-07-27 09:11:55 root INFO     [order_1_approx] starting weight calculation for I provide, he provides
I describe, he describes
I appear, he appears
I happen, he happens
I include, he includes
I enable, he enables
I protect, he protects
I exist, he
2024-07-27 09:11:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 09:14:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1898, -0.1052, -0.4583,  ..., -0.2849,  0.0012, -0.0295],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4746, -3.2090, -1.9473,  ..., -1.6318, -5.0078,  0.6279],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0149,  0.0020,  0.0010,  ...,  0.0030, -0.0150,  0.0252],
        [ 0.0010,  0.0320,  0.0045,  ...,  0.0143,  0.0157, -0.0066],
        [-0.0150,  0.0127,  0.0069,  ..., -0.0157, -0.0115, -0.0174],
        ...,
        [-0.0213,  0.0021, -0.0037,  ...,  0.0291,  0.0115, -0.0131],
        [-0.0361, -0.0188,  0.0112,  ..., -0.0204,  0.0282, -0.0118],
        [-0.0147, -0.0017,  0.0051,  ..., -0.0091, -0.0173,  0.0007]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4609, -3.0195, -1.8184,  ..., -1.3008, -5.1055,  1.1543]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 09:14:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I provide, he provides
I describe, he describes
I appear, he appears
I happen, he happens
I include, he includes
I enable, he enables
I protect, he protects
I exist, he
2024-07-27 09:14:16 root INFO     [order_1_approx] starting weight calculation for I appear, he appears
I exist, he exists
I include, he includes
I protect, he protects
I enable, he enables
I describe, he describes
I happen, he happens
I provide, he
2024-07-27 09:14:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 09:16:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3140, -0.1965, -0.3630,  ..., -0.1603, -0.3567, -0.2394],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6602, -3.0742, -1.0000,  ..., -2.1406, -7.6406,  0.8086],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0332, -0.0030,  0.0091,  ...,  0.0014, -0.0074,  0.0286],
        [-0.0045,  0.0152,  0.0137,  ..., -0.0042,  0.0154,  0.0190],
        [-0.0163,  0.0004,  0.0090,  ..., -0.0150,  0.0099,  0.0010],
        ...,
        [-0.0063, -0.0078,  0.0047,  ...,  0.0209,  0.0161,  0.0118],
        [-0.0112, -0.0084, -0.0088,  ..., -0.0176,  0.0071, -0.0223],
        [-0.0043,  0.0029, -0.0035,  ..., -0.0208, -0.0078,  0.0135]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4629, -2.9258, -0.5669,  ..., -1.6406, -7.6797,  0.9458]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 09:16:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I appear, he appears
I exist, he exists
I include, he includes
I protect, he protects
I enable, he enables
I describe, he describes
I happen, he happens
I provide, he
2024-07-27 09:16:34 root INFO     [order_1_approx] starting weight calculation for I appear, he appears
I happen, he happens
I provide, he provides
I exist, he exists
I describe, he describes
I enable, he enables
I protect, he protects
I include, he
2024-07-27 09:16:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 09:18:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0689,  0.0772, -0.1138,  ..., -0.0087, -0.3064, -0.0503],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9492, -0.6924, -0.2246,  ..., -0.6885, -6.7266, -0.5527],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0402, -0.0146, -0.0002,  ...,  0.0266, -0.0314,  0.0043],
        [-0.0025,  0.0319, -0.0029,  ...,  0.0205,  0.0010, -0.0040],
        [-0.0111, -0.0012,  0.0285,  ..., -0.0197,  0.0082, -0.0112],
        ...,
        [-0.0027, -0.0158, -0.0008,  ...,  0.0214,  0.0047,  0.0075],
        [-0.0315, -0.0006, -0.0099,  ..., -0.0307,  0.0439, -0.0243],
        [-0.0006,  0.0125, -0.0008,  ..., -0.0026, -0.0109,  0.0124]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9473, -0.6890, -0.1211,  ..., -0.6260, -6.5586,  0.1802]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 09:18:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I appear, he appears
I happen, he happens
I provide, he provides
I exist, he exists
I describe, he describes
I enable, he enables
I protect, he protects
I include, he
2024-07-27 09:18:56 root INFO     [order_1_approx] starting weight calculation for I protect, he protects
I appear, he appears
I describe, he describes
I include, he includes
I exist, he exists
I enable, he enables
I provide, he provides
I happen, he
2024-07-27 09:18:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 09:21:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.6162, -0.2196, -0.4004,  ..., -0.2062, -0.0781, -0.2430],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4941, -0.8691, -1.4395,  ..., -1.0908, -8.4531,  0.5723],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0180,  0.0063, -0.0169,  ..., -0.0076, -0.0032,  0.0222],
        [ 0.0004,  0.0218, -0.0110,  ..., -0.0036,  0.0039,  0.0082],
        [-0.0030,  0.0057,  0.0098,  ..., -0.0146, -0.0082, -0.0042],
        ...,
        [-0.0092, -0.0075, -0.0033,  ...,  0.0369, -0.0039, -0.0046],
        [-0.0215, -0.0078,  0.0104,  ..., -0.0019,  0.0126, -0.0340],
        [-0.0086, -0.0205, -0.0003,  ...,  0.0003, -0.0129, -0.0075]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1650, -1.0527, -1.2344,  ..., -0.8389, -8.6406,  1.0303]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 09:21:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I protect, he protects
I appear, he appears
I describe, he describes
I include, he includes
I exist, he exists
I enable, he enables
I provide, he provides
I happen, he
2024-07-27 09:21:17 root INFO     [order_1_approx] starting weight calculation for I enable, he enables
I include, he includes
I protect, he protects
I provide, he provides
I exist, he exists
I happen, he happens
I appear, he appears
I describe, he
2024-07-27 09:21:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 09:23:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1621, -0.1350, -0.0786,  ...,  0.0488,  0.0911, -0.3936],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0898, -2.7324,  2.6836,  ..., -0.1924, -5.7773, -0.4609],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0209,  0.0076, -0.0073,  ...,  0.0180,  0.0116,  0.0108],
        [-0.0091,  0.0111,  0.0024,  ...,  0.0011,  0.0180, -0.0024],
        [-0.0014,  0.0016, -0.0020,  ..., -0.0026, -0.0081, -0.0132],
        ...,
        [ 0.0113,  0.0048,  0.0066,  ...,  0.0159,  0.0013, -0.0053],
        [-0.0244, -0.0050, -0.0052,  ..., -0.0121,  0.0231, -0.0219],
        [ 0.0032,  0.0069,  0.0090,  ...,  0.0032, -0.0274,  0.0148]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3164, -2.7930,  2.6562,  ..., -0.1333, -5.9531, -0.3018]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 09:23:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I enable, he enables
I include, he includes
I protect, he protects
I provide, he provides
I exist, he exists
I happen, he happens
I appear, he appears
I describe, he
2024-07-27 09:23:37 root INFO     [order_1_approx] starting weight calculation for I provide, he provides
I describe, he describes
I happen, he happens
I include, he includes
I appear, he appears
I protect, he protects
I exist, he exists
I enable, he
2024-07-27 09:23:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 09:25:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0444, -0.0583, -0.2188,  ..., -0.2981, -0.2103,  0.0670],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0283, -2.8242, -0.7070,  ..., -1.3896, -8.3438, -1.3809],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0409, -0.0012,  0.0017,  ..., -0.0003, -0.0182,  0.0250],
        [-0.0030,  0.0152,  0.0082,  ...,  0.0046,  0.0149, -0.0146],
        [-0.0163,  0.0055,  0.0229,  ..., -0.0256,  0.0029,  0.0177],
        ...,
        [-0.0047, -0.0012,  0.0054,  ...,  0.0274,  0.0105,  0.0048],
        [-0.0285, -0.0106, -0.0102,  ..., -0.0068,  0.0314, -0.0145],
        [-0.0174, -0.0111,  0.0109,  ..., -0.0020, -0.0139,  0.0158]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0342, -2.5176, -0.5576,  ..., -1.0508, -7.6289, -0.7749]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 09:25:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I provide, he provides
I describe, he describes
I happen, he happens
I include, he includes
I appear, he appears
I protect, he protects
I exist, he exists
I enable, he
2024-07-27 09:25:58 root INFO     total operator prediction time: 1122.7552254199982 seconds
2024-07-27 09:25:58 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_inf - Ved
2024-07-27 09:25:58 root INFO     building operator verb_inf - Ved
2024-07-27 09:25:58 root INFO     [order_1_approx] starting weight calculation for If the present form is tell, the past form is told
If the present form is unite, the past form is united
If the present form is discover, the past form is discovered
If the present form is ask, the past form is asked
If the present form is require, the past form is required
If the present form is apply, the past form is applied
If the present form is agree, the past form is agreed
If the present form is continue, the past form is
2024-07-27 09:25:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 09:28:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3665, -0.4255, -0.2622,  ..., -0.2053, -0.2939,  0.3774],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2031, -1.9795,  2.4648,  ..., -0.9180,  1.4844, -1.4160],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0765, -0.0111, -0.0144,  ...,  0.0117,  0.0053,  0.0142],
        [-0.0154,  0.0543, -0.0004,  ...,  0.0071,  0.0038, -0.0311],
        [ 0.0044,  0.0302,  0.0388,  ..., -0.0089, -0.0131,  0.0198],
        ...,
        [ 0.0058,  0.0017,  0.0244,  ...,  0.0780,  0.0068,  0.0155],
        [ 0.0074,  0.0107,  0.0135,  ..., -0.0060,  0.0286,  0.0209],
        [-0.0144,  0.0096, -0.0097,  ..., -0.0060, -0.0352,  0.0287]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3809, -2.0273,  1.7988,  ..., -1.0684,  1.3369, -1.0186]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 09:28:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is tell, the past form is told
If the present form is unite, the past form is united
If the present form is discover, the past form is discovered
If the present form is ask, the past form is asked
If the present form is require, the past form is required
If the present form is apply, the past form is applied
If the present form is agree, the past form is agreed
If the present form is continue, the past form is
2024-07-27 09:28:19 root INFO     [order_1_approx] starting weight calculation for If the present form is agree, the past form is agreed
If the present form is tell, the past form is told
If the present form is unite, the past form is united
If the present form is ask, the past form is asked
If the present form is apply, the past form is applied
If the present form is require, the past form is required
If the present form is continue, the past form is continued
If the present form is discover, the past form is
2024-07-27 09:28:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 09:30:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0299,  0.0954, -0.0349,  ..., -0.2341, -0.4941,  0.0875],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8467, -1.3027,  2.4590,  ..., -0.2700, -0.3774,  0.5469],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0616, -0.0117,  0.0148,  ..., -0.0030,  0.0110,  0.0202],
        [-0.0089,  0.0610,  0.0176,  ...,  0.0222, -0.0072,  0.0114],
        [ 0.0005,  0.0017,  0.0246,  ..., -0.0079, -0.0021, -0.0151],
        ...,
        [-0.0093,  0.0178, -0.0086,  ...,  0.0630,  0.0052, -0.0009],
        [ 0.0055,  0.0141, -0.0152,  ..., -0.0134,  0.0451, -0.0152],
        [-0.0056, -0.0144,  0.0266,  ..., -0.0216, -0.0187,  0.0388]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8267, -1.6650,  2.5645,  ..., -0.0505,  0.1948,  0.4424]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 09:30:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is agree, the past form is agreed
If the present form is tell, the past form is told
If the present form is unite, the past form is united
If the present form is ask, the past form is asked
If the present form is apply, the past form is applied
If the present form is require, the past form is required
If the present form is continue, the past form is continued
If the present form is discover, the past form is
2024-07-27 09:30:39 root INFO     [order_1_approx] starting weight calculation for If the present form is require, the past form is required
If the present form is continue, the past form is continued
If the present form is unite, the past form is united
If the present form is tell, the past form is told
If the present form is apply, the past form is applied
If the present form is discover, the past form is discovered
If the present form is ask, the past form is asked
If the present form is agree, the past form is
2024-07-27 09:30:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 09:32:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3477,  0.0380, -0.2299,  ...,  0.0686, -0.2124, -0.1086],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9453, -1.4199,  0.4326,  ..., -1.0684, -2.3027, -0.0039],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0707, -0.0109,  0.0116,  ..., -0.0021,  0.0035,  0.0351],
        [-0.0254,  0.0506,  0.0250,  ...,  0.0101, -0.0053, -0.0247],
        [ 0.0036, -0.0058,  0.0333,  ...,  0.0069, -0.0200, -0.0191],
        ...,
        [-0.0118, -0.0033, -0.0006,  ...,  0.0482,  0.0159,  0.0087],
        [ 0.0087, -0.0179, -0.0177,  ..., -0.0071,  0.0082, -0.0266],
        [-0.0027, -0.0045,  0.0331,  ..., -0.0109, -0.0377,  0.0345]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9023, -1.3154,  0.3892,  ..., -1.0566, -1.9434,  0.1019]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 09:32:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is require, the past form is required
If the present form is continue, the past form is continued
If the present form is unite, the past form is united
If the present form is tell, the past form is told
If the present form is apply, the past form is applied
If the present form is discover, the past form is discovered
If the present form is ask, the past form is asked
If the present form is agree, the past form is
2024-07-27 09:32:59 root INFO     [order_1_approx] starting weight calculation for If the present form is apply, the past form is applied
If the present form is continue, the past form is continued
If the present form is agree, the past form is agreed
If the present form is discover, the past form is discovered
If the present form is tell, the past form is told
If the present form is ask, the past form is asked
If the present form is unite, the past form is united
If the present form is require, the past form is
2024-07-27 09:32:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 09:35:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4253,  0.0405, -0.3284,  ..., -0.2522, -0.1226, -0.0579],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.6113,  0.3826,  1.1592,  ..., -1.3213, -2.8242, -1.7676],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0479, -0.0204,  0.0220,  ..., -0.0014, -0.0064, -0.0006],
        [-0.0329,  0.0477,  0.0106,  ..., -0.0071, -0.0069, -0.0051],
        [-0.0040,  0.0040,  0.0182,  ..., -0.0127, -0.0184,  0.0139],
        ...,
        [-0.0218,  0.0105, -0.0018,  ...,  0.0691,  0.0203, -0.0002],
        [ 0.0192, -0.0248, -0.0040,  ..., -0.0185,  0.0255, -0.0058],
        [-0.0243, -0.0060,  0.0182,  ..., -0.0071, -0.0096,  0.0316]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.8438,  0.1223,  1.2559,  ..., -1.0391, -2.1289, -1.3906]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 09:35:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is apply, the past form is applied
If the present form is continue, the past form is continued
If the present form is agree, the past form is agreed
If the present form is discover, the past form is discovered
If the present form is tell, the past form is told
If the present form is ask, the past form is asked
If the present form is unite, the past form is united
If the present form is require, the past form is
2024-07-27 09:35:14 root INFO     [order_1_approx] starting weight calculation for If the present form is discover, the past form is discovered
If the present form is apply, the past form is applied
If the present form is agree, the past form is agreed
If the present form is require, the past form is required
If the present form is unite, the past form is united
If the present form is continue, the past form is continued
If the present form is ask, the past form is asked
If the present form is tell, the past form is
2024-07-27 09:35:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 09:37:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0869, -0.0122, -0.0029,  ..., -0.1349, -0.2600,  0.1074],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1992,  0.8218,  1.9648,  ...,  2.5430, -4.1641, -1.8516],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0648, -0.0047, -0.0066,  ...,  0.0037, -0.0032,  0.0316],
        [-0.0142,  0.0531, -0.0030,  ..., -0.0003, -0.0032,  0.0069],
        [-0.0012, -0.0166,  0.0204,  ..., -0.0040, -0.0121,  0.0149],
        ...,
        [ 0.0163,  0.0034, -0.0226,  ...,  0.0488,  0.0032, -0.0016],
        [-0.0073, -0.0044, -0.0080,  ...,  0.0046,  0.0464, -0.0079],
        [-0.0002,  0.0019,  0.0294,  ..., -0.0214, -0.0112,  0.0344]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1035,  0.7744,  2.0723,  ...,  2.4785, -3.2559, -1.8008]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 09:37:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is discover, the past form is discovered
If the present form is apply, the past form is applied
If the present form is agree, the past form is agreed
If the present form is require, the past form is required
If the present form is unite, the past form is united
If the present form is continue, the past form is continued
If the present form is ask, the past form is asked
If the present form is tell, the past form is
2024-07-27 09:37:33 root INFO     [order_1_approx] starting weight calculation for If the present form is apply, the past form is applied
If the present form is require, the past form is required
If the present form is unite, the past form is united
If the present form is continue, the past form is continued
If the present form is discover, the past form is discovered
If the present form is tell, the past form is told
If the present form is agree, the past form is agreed
If the present form is ask, the past form is
2024-07-27 09:37:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 09:39:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0412,  0.0247, -0.0669,  ...,  0.0886, -0.1108, -0.5713],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7607, -2.1641, -0.7427,  ...,  1.2236, -1.8467, -1.0176],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0574, -0.0201,  0.0101,  ..., -0.0050,  0.0128, -0.0028],
        [-0.0175,  0.0387,  0.0189,  ...,  0.0070,  0.0027, -0.0110],
        [-0.0132, -0.0014,  0.0266,  ..., -0.0096, -0.0090, -0.0092],
        ...,
        [-0.0096,  0.0159,  0.0016,  ...,  0.0374,  0.0073, -0.0033],
        [ 0.0154, -0.0050, -0.0080,  ..., -0.0019,  0.0045, -0.0065],
        [-0.0127,  0.0208,  0.0111,  ..., -0.0077, -0.0150,  0.0132]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6333, -2.0000, -0.5605,  ...,  1.2471, -1.3506, -0.9116]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 09:39:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is apply, the past form is applied
If the present form is require, the past form is required
If the present form is unite, the past form is united
If the present form is continue, the past form is continued
If the present form is discover, the past form is discovered
If the present form is tell, the past form is told
If the present form is agree, the past form is agreed
If the present form is ask, the past form is
2024-07-27 09:39:50 root INFO     [order_1_approx] starting weight calculation for If the present form is continue, the past form is continued
If the present form is unite, the past form is united
If the present form is agree, the past form is agreed
If the present form is discover, the past form is discovered
If the present form is require, the past form is required
If the present form is ask, the past form is asked
If the present form is tell, the past form is told
If the present form is apply, the past form is
2024-07-27 09:39:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 09:42:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0182, -0.4070,  0.1302,  ...,  0.0049, -0.1285, -0.1382],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7109, -0.6255, -1.2988,  ..., -0.3635, -2.5059, -1.3848],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0825, -0.0213,  0.0149,  ..., -0.0004,  0.0031,  0.0087],
        [-0.0166,  0.0495,  0.0204,  ..., -0.0043, -0.0141, -0.0024],
        [ 0.0022, -0.0172,  0.0307,  ..., -0.0058, -0.0049, -0.0061],
        ...,
        [-0.0048,  0.0008, -0.0108,  ...,  0.0837,  0.0115,  0.0018],
        [ 0.0047, -0.0165, -0.0158,  ..., -0.0058,  0.0176, -0.0291],
        [-0.0403, -0.0006, -0.0187,  ..., -0.0381, -0.0291,  0.0170]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.9951, -0.7397, -1.0625,  ..., -0.1130, -2.0703, -0.9990]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 09:42:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is continue, the past form is continued
If the present form is unite, the past form is united
If the present form is agree, the past form is agreed
If the present form is discover, the past form is discovered
If the present form is require, the past form is required
If the present form is ask, the past form is asked
If the present form is tell, the past form is told
If the present form is apply, the past form is
2024-07-27 09:42:11 root INFO     [order_1_approx] starting weight calculation for If the present form is discover, the past form is discovered
If the present form is require, the past form is required
If the present form is agree, the past form is agreed
If the present form is apply, the past form is applied
If the present form is ask, the past form is asked
If the present form is tell, the past form is told
If the present form is continue, the past form is continued
If the present form is unite, the past form is
2024-07-27 09:42:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 09:44:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1152, -0.0524, -0.1217,  ...,  0.0637, -0.0254,  0.0880],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5938, -0.1187,  2.3301,  ...,  0.0824, -0.4102,  0.3525],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0464, -0.0064,  0.0035,  ...,  0.0283,  0.0016,  0.0108],
        [-0.0095,  0.0595, -0.0048,  ...,  0.0251, -0.0267,  0.0110],
        [ 0.0012,  0.0014, -0.0085,  ..., -0.0087, -0.0075,  0.0057],
        ...,
        [-0.0128,  0.0135,  0.0004,  ...,  0.0606, -0.0043, -0.0076],
        [-0.0048, -0.0072, -0.0115,  ..., -0.0377,  0.0201, -0.0191],
        [ 0.0039, -0.0216, -0.0072,  ..., -0.0261, -0.0211,  0.0547]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[0.2915, 0.1125, 2.2402,  ..., 0.1891, 0.0583, 0.4929]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 09:44:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is discover, the past form is discovered
If the present form is require, the past form is required
If the present form is agree, the past form is agreed
If the present form is apply, the past form is applied
If the present form is ask, the past form is asked
If the present form is tell, the past form is told
If the present form is continue, the past form is continued
If the present form is unite, the past form is
2024-07-27 09:44:29 root INFO     total operator prediction time: 1110.88076877594 seconds
2024-07-27 09:44:29 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_Ving - Ved
2024-07-27 09:44:29 root INFO     building operator verb_Ving - Ved
2024-07-27 09:44:29 root INFO     [order_1_approx] starting weight calculation for After something is announcing, it has announced
After something is applying, it has applied
After something is performing, it has performed
After something is establishing, it has established
After something is proposing, it has proposed
After something is remaining, it has remained
After something is publishing, it has published
After something is teaching, it has
2024-07-27 09:44:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 09:46:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3054,  0.1537,  0.0341,  ..., -0.3159, -0.2803, -0.1846],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4727,  0.3784,  4.6406,  ..., -1.0859, -2.7148, -3.7012],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0257,  0.0049, -0.0002,  ...,  0.0047, -0.0115,  0.0143],
        [-0.0263,  0.0526, -0.0150,  ...,  0.0177, -0.0008, -0.0008],
        [-0.0061, -0.0027,  0.0205,  ...,  0.0024,  0.0062,  0.0106],
        ...,
        [ 0.0144,  0.0177, -0.0244,  ...,  0.0305,  0.0048, -0.0003],
        [ 0.0205,  0.0019, -0.0129,  ...,  0.0010,  0.0186, -0.0077],
        [ 0.0003,  0.0050,  0.0156,  ..., -0.0075, -0.0014,  0.0045]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5391,  0.3601,  4.2891,  ..., -1.1367, -2.6445, -3.4160]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 09:46:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is announcing, it has announced
After something is applying, it has applied
After something is performing, it has performed
After something is establishing, it has established
After something is proposing, it has proposed
After something is remaining, it has remained
After something is publishing, it has published
After something is teaching, it has
2024-07-27 09:46:51 root INFO     [order_1_approx] starting weight calculation for After something is announcing, it has announced
After something is teaching, it has taught
After something is remaining, it has remained
After something is establishing, it has established
After something is publishing, it has published
After something is applying, it has applied
After something is proposing, it has proposed
After something is performing, it has
2024-07-27 09:46:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 09:49:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3611, -0.3098, -0.0200,  ..., -0.3318,  0.0217, -0.0725],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7969, -0.6758,  3.7617,  ..., -2.6953, -2.8711, -0.8438],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0435, -0.0053, -0.0050,  ...,  0.0198, -0.0201,  0.0317],
        [-0.0214,  0.0568,  0.0082,  ...,  0.0094,  0.0108,  0.0002],
        [ 0.0108,  0.0011,  0.0262,  ...,  0.0238,  0.0055,  0.0160],
        ...,
        [-0.0001,  0.0094, -0.0282,  ...,  0.0467,  0.0147,  0.0071],
        [ 0.0133, -0.0072,  0.0133,  ...,  0.0048,  0.0106, -0.0146],
        [-0.0013, -0.0028,  0.0166,  ..., -0.0305,  0.0011,  0.0081]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6445, -1.0898,  3.7090,  ..., -2.4453, -2.6211, -0.3860]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 09:49:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is announcing, it has announced
After something is teaching, it has taught
After something is remaining, it has remained
After something is establishing, it has established
After something is publishing, it has published
After something is applying, it has applied
After something is proposing, it has proposed
After something is performing, it has
2024-07-27 09:49:16 root INFO     [order_1_approx] starting weight calculation for After something is publishing, it has published
After something is performing, it has performed
After something is announcing, it has announced
After something is remaining, it has remained
After something is proposing, it has proposed
After something is establishing, it has established
After something is teaching, it has taught
After something is applying, it has
2024-07-27 09:49:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 09:51:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0050, -0.5327,  0.0959,  ...,  0.0741, -0.0913, -0.4331],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4453,  0.5479,  1.0107,  ..., -1.3320, -1.6641, -0.2480],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0444, -0.0113,  0.0242,  ...,  0.0280, -0.0245,  0.0260],
        [-0.0170,  0.0578,  0.0054,  ...,  0.0079,  0.0061,  0.0051],
        [ 0.0070, -0.0021,  0.0282,  ...,  0.0069,  0.0018,  0.0133],
        ...,
        [ 0.0069,  0.0297, -0.0254,  ...,  0.0535,  0.0159,  0.0049],
        [ 0.0241, -0.0049, -0.0224,  ...,  0.0034,  0.0406, -0.0175],
        [-0.0088,  0.0163, -0.0011,  ..., -0.0241, -0.0038,  0.0058]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1064,  0.2444,  1.2246,  ..., -1.0605, -1.5303, -0.1399]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 09:51:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is publishing, it has published
After something is performing, it has performed
After something is announcing, it has announced
After something is remaining, it has remained
After something is proposing, it has proposed
After something is establishing, it has established
After something is teaching, it has taught
After something is applying, it has
2024-07-27 09:51:39 root INFO     [order_1_approx] starting weight calculation for After something is performing, it has performed
After something is establishing, it has established
After something is teaching, it has taught
After something is announcing, it has announced
After something is proposing, it has proposed
After something is publishing, it has published
After something is applying, it has applied
After something is remaining, it has
2024-07-27 09:51:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 09:53:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1171, -0.1790, -0.1294,  ..., -0.3408, -0.1697,  0.0927],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2773, -0.4104,  1.6836,  ..., -2.7715, -0.2881, -1.9102],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0761, -0.0032,  0.0016,  ...,  0.0198,  0.0044,  0.0250],
        [-0.0259,  0.0541,  0.0017,  ...,  0.0199,  0.0233, -0.0109],
        [ 0.0009,  0.0055,  0.0730,  ...,  0.0195, -0.0199, -0.0329],
        ...,
        [ 0.0139,  0.0311,  0.0064,  ...,  0.0502,  0.0091,  0.0309],
        [ 0.0164,  0.0057, -0.0143,  ...,  0.0106,  0.0286, -0.0164],
        [-0.0207,  0.0267,  0.0242,  ..., -0.0130, -0.0100,  0.0062]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1328, -0.2642,  2.2441,  ..., -2.3496,  0.0173, -1.3262]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 09:54:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is performing, it has performed
After something is establishing, it has established
After something is teaching, it has taught
After something is announcing, it has announced
After something is proposing, it has proposed
After something is publishing, it has published
After something is applying, it has applied
After something is remaining, it has
2024-07-27 09:54:00 root INFO     [order_1_approx] starting weight calculation for After something is remaining, it has remained
After something is performing, it has performed
After something is applying, it has applied
After something is teaching, it has taught
After something is publishing, it has published
After something is establishing, it has established
After something is announcing, it has announced
After something is proposing, it has
2024-07-27 09:54:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 09:56:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3457, -0.1372,  0.0170,  ..., -0.0435, -0.1399, -0.0629],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9131, -2.3945,  2.2227,  ..., -1.4688, -1.0781,  0.7578],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0312, -0.0091,  0.0048,  ...,  0.0060, -0.0025,  0.0203],
        [-0.0290,  0.0155,  0.0144,  ...,  0.0160, -0.0025,  0.0024],
        [-0.0065, -0.0016,  0.0315,  ..., -0.0131,  0.0012,  0.0129],
        ...,
        [-0.0052, -0.0030,  0.0023,  ...,  0.0120,  0.0189,  0.0100],
        [ 0.0046,  0.0141, -0.0030,  ..., -0.0119,  0.0024, -0.0170],
        [-0.0057,  0.0109, -0.0007,  ...,  0.0060, -0.0162, -0.0003]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7080, -2.7852,  2.3242,  ..., -1.3916, -1.0029,  0.6021]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 09:56:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is remaining, it has remained
After something is performing, it has performed
After something is applying, it has applied
After something is teaching, it has taught
After something is publishing, it has published
After something is establishing, it has established
After something is announcing, it has announced
After something is proposing, it has
2024-07-27 09:56:23 root INFO     [order_1_approx] starting weight calculation for After something is applying, it has applied
After something is remaining, it has remained
After something is performing, it has performed
After something is announcing, it has announced
After something is proposing, it has proposed
After something is teaching, it has taught
After something is publishing, it has published
After something is establishing, it has
2024-07-27 09:56:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 09:58:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3455, -0.3069, -0.3213,  ..., -0.0389, -0.1272, -0.2385],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2793,  0.1133,  0.8105,  ..., -1.3926, -0.5049, -1.3730],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0181,  0.0020,  0.0007,  ..., -0.0011, -0.0048,  0.0185],
        [-0.0266,  0.0199,  0.0027,  ..., -0.0020,  0.0123,  0.0021],
        [ 0.0245, -0.0061,  0.0209,  ..., -0.0018,  0.0052,  0.0021],
        ...,
        [ 0.0044,  0.0026,  0.0033,  ...,  0.0162, -0.0041,  0.0071],
        [-0.0047,  0.0149, -0.0097,  ...,  0.0041,  0.0177, -0.0081],
        [-0.0251,  0.0137,  0.0106,  ..., -0.0018, -0.0016, -0.0051]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5762,  0.0236,  1.0117,  ..., -1.2773, -0.7104, -1.5117]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 09:58:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is applying, it has applied
After something is remaining, it has remained
After something is performing, it has performed
After something is announcing, it has announced
After something is proposing, it has proposed
After something is teaching, it has taught
After something is publishing, it has published
After something is establishing, it has
2024-07-27 09:58:45 root INFO     [order_1_approx] starting weight calculation for After something is applying, it has applied
After something is teaching, it has taught
After something is publishing, it has published
After something is establishing, it has established
After something is performing, it has performed
After something is remaining, it has remained
After something is proposing, it has proposed
After something is announcing, it has
2024-07-27 09:58:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 10:01:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1958,  0.1041, -0.1223,  ...,  0.1047,  0.1531, -0.3367],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3828, -1.5059,  2.8789,  ..., -0.8184, -1.6670,  0.9668],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0391, -0.0143,  0.0037,  ...,  0.0012, -0.0127,  0.0250],
        [-0.0211,  0.0250,  0.0047,  ...,  0.0094,  0.0155, -0.0064],
        [ 0.0195, -0.0285,  0.0026,  ..., -0.0037, -0.0082, -0.0012],
        ...,
        [ 0.0073,  0.0031, -0.0204,  ...,  0.0098, -0.0022,  0.0160],
        [ 0.0217,  0.0029, -0.0091,  ..., -0.0041,  0.0103, -0.0056],
        [-0.0071,  0.0195,  0.0134,  ..., -0.0045, -0.0016, -0.0018]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4346, -1.6660,  3.3242,  ..., -0.5410, -1.7432,  0.8252]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 10:01:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is applying, it has applied
After something is teaching, it has taught
After something is publishing, it has published
After something is establishing, it has established
After something is performing, it has performed
After something is remaining, it has remained
After something is proposing, it has proposed
After something is announcing, it has
2024-07-27 10:01:07 root INFO     [order_1_approx] starting weight calculation for After something is establishing, it has established
After something is proposing, it has proposed
After something is announcing, it has announced
After something is remaining, it has remained
After something is teaching, it has taught
After something is applying, it has applied
After something is performing, it has performed
After something is publishing, it has
2024-07-27 10:01:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 10:03:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2059, -0.2216,  0.2042,  ...,  0.1628,  0.2258,  0.0042],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1348, -2.1328,  1.2207,  ..., -2.9648, -1.6787,  0.6562],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0386, -0.0043,  0.0059,  ...,  0.0017,  0.0021,  0.0290],
        [-0.0366,  0.0440, -0.0005,  ..., -0.0088, -0.0004, -0.0025],
        [ 0.0179, -0.0184,  0.0369,  ...,  0.0008, -0.0026, -0.0025],
        ...,
        [-0.0021,  0.0099, -0.0138,  ...,  0.0472,  0.0213,  0.0033],
        [ 0.0200,  0.0005, -0.0246,  ...,  0.0025,  0.0209, -0.0188],
        [-0.0034,  0.0225,  0.0279,  ..., -0.0148, -0.0191,  0.0074]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1270, -2.3066,  1.3369,  ..., -2.6152, -1.3174,  0.8379]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 10:03:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is establishing, it has established
After something is proposing, it has proposed
After something is announcing, it has announced
After something is remaining, it has remained
After something is teaching, it has taught
After something is applying, it has applied
After something is performing, it has performed
After something is publishing, it has
2024-07-27 10:03:28 root INFO     total operator prediction time: 1139.4892642498016 seconds
2024-07-27 10:03:28 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on Ving - verb_inf
2024-07-27 10:03:28 root INFO     building operator Ving - verb_inf
2024-07-27 10:03:29 root INFO     [order_1_approx] starting weight calculation for avoiding is the active form of avoid
losing is the active form of lose
requiring is the active form of require
ensuring is the active form of ensure
representing is the active form of represent
applying is the active form of apply
receiving is the active form of receive
following is the active form of
2024-07-27 10:03:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 10:05:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2382, -0.3062, -0.3179,  ..., -0.2115, -0.2568,  0.0674],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9785, -3.7051,  2.0430,  ...,  2.1094, -1.9844, -2.2656],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0675,  0.0038,  0.0035,  ...,  0.0041,  0.0050,  0.0105],
        [-0.0030,  0.0627,  0.0105,  ...,  0.0127, -0.0180, -0.0091],
        [ 0.0060, -0.0038,  0.0246,  ..., -0.0190, -0.0063, -0.0137],
        ...,
        [ 0.0072, -0.0002, -0.0136,  ...,  0.0572, -0.0206,  0.0023],
        [-0.0071,  0.0009,  0.0065,  ...,  0.0080,  0.0302, -0.0067],
        [ 0.0003,  0.0072, -0.0076,  ...,  0.0052, -0.0040,  0.0310]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6416, -4.1055,  1.9180,  ...,  2.1660, -1.9150, -2.2383]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 10:05:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for avoiding is the active form of avoid
losing is the active form of lose
requiring is the active form of require
ensuring is the active form of ensure
representing is the active form of represent
applying is the active form of apply
receiving is the active form of receive
following is the active form of
2024-07-27 10:05:50 root INFO     [order_1_approx] starting weight calculation for requiring is the active form of require
following is the active form of follow
losing is the active form of lose
applying is the active form of apply
representing is the active form of represent
avoiding is the active form of avoid
ensuring is the active form of ensure
receiving is the active form of
2024-07-27 10:05:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 10:08:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3418, -0.1121, -0.2384,  ..., -0.4912,  0.2307,  0.1130],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8408, -3.4805, -2.0293,  ...,  0.1436,  0.1094, -3.5332],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0931, -0.0179,  0.0043,  ...,  0.0095,  0.0030,  0.0254],
        [-0.0114,  0.0580,  0.0011,  ...,  0.0106,  0.0023, -0.0009],
        [ 0.0056,  0.0006,  0.0338,  ..., -0.0170, -0.0041, -0.0022],
        ...,
        [ 0.0091,  0.0170, -0.0089,  ...,  0.0578, -0.0022, -0.0154],
        [-0.0207,  0.0095,  0.0037,  ..., -0.0066,  0.0314, -0.0067],
        [ 0.0009,  0.0113, -0.0080,  ..., -0.0102, -0.0242,  0.0506]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.9810, -3.7363, -1.9219,  ...,  0.2620,  0.0513, -3.4863]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 10:08:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for requiring is the active form of require
following is the active form of follow
losing is the active form of lose
applying is the active form of apply
representing is the active form of represent
avoiding is the active form of avoid
ensuring is the active form of ensure
receiving is the active form of
2024-07-27 10:08:11 root INFO     [order_1_approx] starting weight calculation for requiring is the active form of require
following is the active form of follow
representing is the active form of represent
ensuring is the active form of ensure
receiving is the active form of receive
applying is the active form of apply
avoiding is the active form of avoid
losing is the active form of
2024-07-27 10:08:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 10:10:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2388, -0.3030, -0.0425,  ..., -0.6621,  0.3381,  0.0253],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3799, -3.1445, -1.2852,  ...,  1.1895,  1.4492, -2.0840],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0635,  0.0062,  0.0068,  ...,  0.0045, -0.0095,  0.0205],
        [ 0.0046,  0.0484,  0.0143,  ...,  0.0128, -0.0026, -0.0135],
        [-0.0005, -0.0058,  0.0340,  ..., -0.0060,  0.0052, -0.0160],
        ...,
        [ 0.0105, -0.0034, -0.0235,  ...,  0.0507,  0.0120,  0.0060],
        [-0.0141,  0.0214,  0.0052,  ...,  0.0055,  0.0191, -0.0065],
        [ 0.0010,  0.0081,  0.0066,  ..., -0.0031, -0.0096,  0.0405]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0676, -3.4375, -1.1387,  ...,  1.8564,  1.1738, -2.1406]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 10:10:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for requiring is the active form of require
following is the active form of follow
representing is the active form of represent
ensuring is the active form of ensure
receiving is the active form of receive
applying is the active form of apply
avoiding is the active form of avoid
losing is the active form of
2024-07-27 10:10:32 root INFO     [order_1_approx] starting weight calculation for applying is the active form of apply
following is the active form of follow
avoiding is the active form of avoid
requiring is the active form of require
losing is the active form of lose
ensuring is the active form of ensure
receiving is the active form of receive
representing is the active form of
2024-07-27 10:10:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 10:12:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1996, -0.1224, -0.5356,  ..., -0.2529, -0.1552,  0.0743],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.2695, -3.3555,  1.5605,  ...,  1.8750, -2.1230, -2.9766],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 8.0627e-02, -1.8501e-04,  1.2833e-02,  ...,  1.0857e-02,
          3.3836e-03,  7.6790e-03],
        [-5.7220e-05,  6.4392e-02,  1.3504e-02,  ...,  2.4014e-03,
          9.2773e-03, -1.1871e-02],
        [ 2.1286e-02, -6.1607e-03,  4.9072e-02,  ..., -2.2278e-03,
         -8.4610e-03,  2.2964e-03],
        ...,
        [-8.5678e-03,  4.3335e-03, -2.4139e-02,  ...,  6.1707e-02,
         -5.3787e-03,  6.7139e-03],
        [-2.9564e-03,  1.0582e-02,  2.5158e-03,  ...,  6.2218e-03,
          4.7058e-02, -1.9638e-02],
        [ 7.3433e-03,  1.8320e-03, -1.1864e-02,  ...,  4.3221e-03,
         -9.3155e-03,  5.3772e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.2471, -3.4629,  1.2451,  ...,  1.6982, -2.1309, -2.9121]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 10:12:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for applying is the active form of apply
following is the active form of follow
avoiding is the active form of avoid
requiring is the active form of require
losing is the active form of lose
ensuring is the active form of ensure
receiving is the active form of receive
representing is the active form of
2024-07-27 10:12:54 root INFO     [order_1_approx] starting weight calculation for representing is the active form of represent
applying is the active form of apply
following is the active form of follow
avoiding is the active form of avoid
losing is the active form of lose
receiving is the active form of receive
ensuring is the active form of ensure
requiring is the active form of
2024-07-27 10:12:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 10:15:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2576, -0.0431, -0.2690,  ..., -0.4534, -0.0073, -0.0126],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.5020, -3.8613,  1.1641,  ...,  0.7671, -2.5078, -2.2930],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0488, -0.0107,  0.0111,  ..., -0.0022,  0.0054,  0.0020],
        [-0.0133,  0.0501,  0.0052,  ...,  0.0054, -0.0009,  0.0067],
        [ 0.0079, -0.0006,  0.0389,  ..., -0.0075,  0.0053,  0.0146],
        ...,
        [-0.0040,  0.0029, -0.0067,  ...,  0.0461, -0.0059,  0.0019],
        [ 0.0073,  0.0020,  0.0033,  ..., -0.0021,  0.0314, -0.0121],
        [ 0.0070,  0.0064, -0.0061,  ...,  0.0037, -0.0178,  0.0447]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.4678, -3.9395,  0.9629,  ...,  0.9512, -2.3750, -2.2578]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 10:15:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for representing is the active form of represent
applying is the active form of apply
following is the active form of follow
avoiding is the active form of avoid
losing is the active form of lose
receiving is the active form of receive
ensuring is the active form of ensure
requiring is the active form of
2024-07-27 10:15:17 root INFO     [order_1_approx] starting weight calculation for applying is the active form of apply
following is the active form of follow
representing is the active form of represent
receiving is the active form of receive
requiring is the active form of require
losing is the active form of lose
avoiding is the active form of avoid
ensuring is the active form of
2024-07-27 10:15:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 10:17:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2023, -0.1833, -0.2308,  ...,  0.0333,  0.2578, -0.2505],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6660, -3.6133, -0.3086,  ...,  1.7412, -1.9844, -3.8164],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.7200e-02, -5.3406e-05, -1.2159e-03,  ...,  1.2264e-03,
          2.9697e-03,  1.4320e-02],
        [-3.1452e-03,  5.9631e-02,  3.5877e-03,  ...,  1.5976e-02,
          5.5809e-03,  4.4394e-04],
        [-2.1877e-03, -8.3771e-03,  5.0110e-02,  ..., -4.2000e-03,
          2.3079e-03, -5.4626e-03],
        ...,
        [ 3.4370e-03, -1.9894e-03, -3.5839e-03,  ...,  6.8176e-02,
         -8.2016e-03,  7.5035e-03],
        [ 1.5244e-02,  8.5754e-03,  3.4027e-03,  ...,  5.9319e-03,
          4.2114e-02, -5.4131e-03],
        [-1.1606e-03, -4.5166e-03, -2.1347e-02,  ...,  2.1400e-03,
         -1.7502e-02,  4.4800e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7861, -3.7422, -0.2106,  ...,  1.7129, -2.1152, -3.6895]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 10:17:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for applying is the active form of apply
following is the active form of follow
representing is the active form of represent
receiving is the active form of receive
requiring is the active form of require
losing is the active form of lose
avoiding is the active form of avoid
ensuring is the active form of
2024-07-27 10:17:38 root INFO     [order_1_approx] starting weight calculation for following is the active form of follow
receiving is the active form of receive
applying is the active form of apply
ensuring is the active form of ensure
losing is the active form of lose
requiring is the active form of require
representing is the active form of represent
avoiding is the active form of
2024-07-27 10:17:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 10:19:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2952, -0.3896, -0.4104,  ..., -0.4165,  0.2576,  0.4382],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5986, -3.5586, -2.2773,  ...,  3.1133, -1.2539, -2.5625],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.2866e-02,  7.9155e-05,  1.6922e-02,  ...,  2.6512e-03,
         -1.4038e-02,  2.2003e-02],
        [-5.6610e-03,  5.8990e-02, -3.8834e-03,  ...,  9.1782e-03,
          1.4334e-03, -2.1805e-02],
        [ 2.5375e-02, -1.3023e-02,  3.7079e-02,  ..., -8.8425e-03,
         -4.0169e-03,  9.5444e-03],
        ...,
        [ 3.9444e-03,  8.2092e-03, -1.6556e-02,  ...,  4.9927e-02,
         -1.2291e-02,  4.3564e-03],
        [-4.8218e-03,  8.4839e-03,  5.9090e-03,  ..., -2.0161e-03,
          3.7964e-02, -6.1378e-03],
        [ 4.6463e-03, -3.4790e-03, -8.3542e-03,  ...,  5.8174e-04,
         -2.8076e-03,  3.8513e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4209, -3.5938, -2.2949,  ...,  3.1992, -1.5703, -2.4961]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 10:20:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for following is the active form of follow
receiving is the active form of receive
applying is the active form of apply
ensuring is the active form of ensure
losing is the active form of lose
requiring is the active form of require
representing is the active form of represent
avoiding is the active form of
2024-07-27 10:20:00 root INFO     [order_1_approx] starting weight calculation for receiving is the active form of receive
ensuring is the active form of ensure
following is the active form of follow
representing is the active form of represent
losing is the active form of lose
requiring is the active form of require
avoiding is the active form of avoid
applying is the active form of
2024-07-27 10:20:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 10:22:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2173, -0.4641,  0.0771,  ..., -0.1138,  0.0341,  0.0129],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4824, -3.6133, -0.9004,  ...,  2.8457, -2.6250, -3.0742],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0908, -0.0124, -0.0006,  ...,  0.0111, -0.0175,  0.0097],
        [-0.0054,  0.0677,  0.0129,  ...,  0.0023, -0.0122,  0.0060],
        [ 0.0052, -0.0035,  0.0564,  ..., -0.0026,  0.0090,  0.0121],
        ...,
        [-0.0044,  0.0050, -0.0124,  ...,  0.0723, -0.0041, -0.0050],
        [-0.0025, -0.0179, -0.0037,  ...,  0.0019,  0.0419, -0.0070],
        [ 0.0082,  0.0138, -0.0001,  ...,  0.0002, -0.0202,  0.0589]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0308, -4.2031, -0.9888,  ...,  3.1504, -2.4297, -3.0723]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 10:22:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for receiving is the active form of receive
ensuring is the active form of ensure
following is the active form of follow
representing is the active form of represent
losing is the active form of lose
requiring is the active form of require
avoiding is the active form of avoid
applying is the active form of
2024-07-27 10:22:22 root INFO     total operator prediction time: 1133.9375615119934 seconds
2024-07-27 10:22:22 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun - plural_irreg
2024-07-27 10:22:22 root INFO     building operator noun - plural_irreg
2024-07-27 10:22:23 root INFO     [order_1_approx] starting weight calculation for The plural form of memory is memories
The plural form of life is lives
The plural form of facility is facilities
The plural form of activity is activities
The plural form of category is categories
The plural form of species is species
The plural form of ability is abilities
The plural form of safety is
2024-07-27 10:22:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 10:24:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2407, -0.0889, -0.3286,  ...,  0.0122, -0.1003,  0.0309],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0625, -1.0566,  0.1625,  ..., -0.6006, -3.6133, -2.8398],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0825,  0.0027,  0.0090,  ...,  0.0042, -0.0204,  0.0117],
        [-0.0259,  0.0537,  0.0191,  ...,  0.0232,  0.0119,  0.0043],
        [ 0.0058,  0.0150,  0.0578,  ...,  0.0139, -0.0181, -0.0090],
        ...,
        [ 0.0005,  0.0174, -0.0103,  ...,  0.0651, -0.0250,  0.0015],
        [-0.0277, -0.0006,  0.0018,  ...,  0.0031,  0.0353, -0.0038],
        [ 0.0077, -0.0073, -0.0035,  ...,  0.0159, -0.0077,  0.0614]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8984, -1.1631,  0.1844,  ..., -0.5190, -3.5312, -2.7578]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 10:24:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of memory is memories
The plural form of life is lives
The plural form of facility is facilities
The plural form of activity is activities
The plural form of category is categories
The plural form of species is species
The plural form of ability is abilities
The plural form of safety is
2024-07-27 10:24:44 root INFO     [order_1_approx] starting weight calculation for The plural form of life is lives
The plural form of ability is abilities
The plural form of memory is memories
The plural form of facility is facilities
The plural form of category is categories
The plural form of species is species
The plural form of safety is safeties
The plural form of activity is
2024-07-27 10:24:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 10:27:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1851,  0.1429, -0.2805,  ..., -0.3274, -0.2559, -0.2747],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3521, -1.2520,  1.5625,  ...,  0.0737,  0.0806, -2.4375],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.6233e-02,  1.2131e-02,  3.2227e-02,  ..., -1.8921e-03,
         -2.5940e-04,  1.1497e-02],
        [ 9.4147e-03,  6.2683e-02,  9.6436e-03,  ...,  2.9083e-02,
          6.0043e-03,  1.9699e-02],
        [-1.6434e-02, -1.2207e-02,  4.7028e-02,  ...,  2.4700e-03,
         -7.7438e-03,  2.0409e-04],
        ...,
        [-1.7719e-03,  1.7502e-02, -2.3315e-02,  ...,  6.6650e-02,
         -1.3901e-02, -5.9128e-05],
        [-3.3936e-02,  2.7313e-02, -2.3132e-02,  ...,  1.9684e-03,
          4.7150e-02,  7.5455e-03],
        [ 1.9287e-02,  3.9024e-03, -8.4229e-03,  ...,  1.3000e-02,
         -1.6235e-02,  7.0496e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1741, -1.4482,  1.9355,  ...,  0.3042, -0.2073, -2.3320]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 10:27:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of life is lives
The plural form of ability is abilities
The plural form of memory is memories
The plural form of facility is facilities
The plural form of category is categories
The plural form of species is species
The plural form of safety is safeties
The plural form of activity is
2024-07-27 10:27:08 root INFO     [order_1_approx] starting weight calculation for The plural form of life is lives
The plural form of activity is activities
The plural form of ability is abilities
The plural form of species is species
The plural form of memory is memories
The plural form of category is categories
The plural form of safety is safeties
The plural form of facility is
2024-07-27 10:27:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 10:29:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3130,  0.1404, -0.5059,  ..., -0.6030, -0.2026,  0.0314],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9453, -2.5625,  3.8633,  ...,  0.3545, -1.3730, -2.1133],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0751, -0.0153, -0.0108,  ...,  0.0100,  0.0038,  0.0197],
        [-0.0097,  0.0733, -0.0008,  ...,  0.0276,  0.0024, -0.0036],
        [ 0.0091, -0.0083,  0.0498,  ..., -0.0066, -0.0200,  0.0032],
        ...,
        [-0.0082,  0.0155, -0.0434,  ...,  0.1013, -0.0005,  0.0086],
        [ 0.0023,  0.0039,  0.0034,  ...,  0.0375,  0.0480, -0.0061],
        [ 0.0145, -0.0074, -0.0146,  ...,  0.0135, -0.0041,  0.0631]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3652, -2.5312,  3.8809,  ..., -0.0044, -1.4277, -2.1543]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 10:29:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of life is lives
The plural form of activity is activities
The plural form of ability is abilities
The plural form of species is species
The plural form of memory is memories
The plural form of category is categories
The plural form of safety is safeties
The plural form of facility is
2024-07-27 10:29:32 root INFO     [order_1_approx] starting weight calculation for The plural form of activity is activities
The plural form of ability is abilities
The plural form of memory is memories
The plural form of category is categories
The plural form of life is lives
The plural form of safety is safeties
The plural form of facility is facilities
The plural form of species is
2024-07-27 10:29:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 10:31:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4900, -0.2791, -0.3279,  ...,  0.0008, -0.0402,  0.1675],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0137, -3.4707, -0.1294,  ..., -0.5029, -3.4414, -3.2891],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0573,  0.0027,  0.0055,  ...,  0.0070,  0.0061, -0.0002],
        [ 0.0400,  0.0589,  0.0202,  ...,  0.0119,  0.0006,  0.0007],
        [ 0.0062, -0.0173,  0.0394,  ..., -0.0123, -0.0201,  0.0228],
        ...,
        [-0.0113, -0.0028, -0.0019,  ...,  0.0467,  0.0169,  0.0146],
        [-0.0188,  0.0258, -0.0171,  ..., -0.0011,  0.0396,  0.0063],
        [ 0.0178,  0.0051,  0.0013,  ..., -0.0126, -0.0266,  0.0289]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1602, -3.8848,  0.0247,  ..., -0.1345, -3.2812, -3.2500]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 10:31:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of activity is activities
The plural form of ability is abilities
The plural form of memory is memories
The plural form of category is categories
The plural form of life is lives
The plural form of safety is safeties
The plural form of facility is facilities
The plural form of species is
2024-07-27 10:31:55 root INFO     [order_1_approx] starting weight calculation for The plural form of life is lives
The plural form of species is species
The plural form of category is categories
The plural form of memory is memories
The plural form of activity is activities
The plural form of safety is safeties
The plural form of facility is facilities
The plural form of ability is
2024-07-27 10:31:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 10:34:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2303,  0.0985, -0.0184,  ..., -0.3921, -0.0814,  0.1045],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0801, -2.0684,  0.9121,  ..., -0.6533, -2.2383, -1.1602],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0507, -0.0087,  0.0010,  ..., -0.0044,  0.0157,  0.0316],
        [ 0.0182,  0.0563,  0.0188,  ...,  0.0361,  0.0158,  0.0037],
        [-0.0038, -0.0120,  0.0422,  ..., -0.0105, -0.0060,  0.0175],
        ...,
        [ 0.0109,  0.0389, -0.0165,  ...,  0.0387, -0.0043,  0.0143],
        [-0.0052,  0.0310,  0.0131,  ..., -0.0010,  0.0207, -0.0130],
        [ 0.0000, -0.0089, -0.0034,  ...,  0.0061, -0.0011,  0.0332]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8066, -2.1348,  0.8296,  ..., -0.3538, -1.9980, -1.5391]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 10:34:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of life is lives
The plural form of species is species
The plural form of category is categories
The plural form of memory is memories
The plural form of activity is activities
The plural form of safety is safeties
The plural form of facility is facilities
The plural form of ability is
2024-07-27 10:34:18 root INFO     [order_1_approx] starting weight calculation for The plural form of category is categories
The plural form of activity is activities
The plural form of ability is abilities
The plural form of species is species
The plural form of memory is memories
The plural form of safety is safeties
The plural form of facility is facilities
The plural form of life is
2024-07-27 10:34:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 10:36:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4429,  0.0970, -0.2947,  ..., -0.1686, -0.3801,  0.0754],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0820, -3.1895,  0.3572,  ..., -2.2109, -3.1250, -2.6289],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0434,  0.0175, -0.0134,  ..., -0.0059, -0.0022,  0.0071],
        [ 0.0075,  0.0810,  0.0367,  ...,  0.0164,  0.0092,  0.0129],
        [ 0.0065, -0.0141,  0.0631,  ..., -0.0297, -0.0127,  0.0240],
        ...,
        [ 0.0295,  0.0251, -0.0093,  ...,  0.0585, -0.0044,  0.0266],
        [-0.0020,  0.0036,  0.0077,  ..., -0.0067,  0.0342,  0.0057],
        [ 0.0023,  0.0031, -0.0019,  ..., -0.0009, -0.0116,  0.0539]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2930, -3.8223,  0.3618,  ..., -2.1621, -3.3418, -2.6523]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 10:36:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of category is categories
The plural form of activity is activities
The plural form of ability is abilities
The plural form of species is species
The plural form of memory is memories
The plural form of safety is safeties
The plural form of facility is facilities
The plural form of life is
2024-07-27 10:36:41 root INFO     [order_1_approx] starting weight calculation for The plural form of ability is abilities
The plural form of safety is safeties
The plural form of species is species
The plural form of life is lives
The plural form of facility is facilities
The plural form of activity is activities
The plural form of category is categories
The plural form of memory is
2024-07-27 10:36:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 10:39:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0801,  0.0046, -0.2952,  ..., -0.1309,  0.1152,  0.0807],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7324, -0.8281,  0.7183,  ..., -2.0098, -4.8047, -4.5664],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0378,  0.0088, -0.0411,  ..., -0.0393, -0.0029,  0.0058],
        [ 0.0186,  0.0666,  0.0403,  ...,  0.0594, -0.0128,  0.0030],
        [-0.0040, -0.0063,  0.0728,  ..., -0.0194, -0.0140,  0.0111],
        ...,
        [ 0.0261,  0.0020,  0.0323,  ...,  0.1112, -0.0343,  0.0167],
        [ 0.0064,  0.0111, -0.0080,  ..., -0.0184,  0.0376,  0.0078],
        [ 0.0111,  0.0052,  0.0390,  ...,  0.0150, -0.0339,  0.0649]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2949, -1.5400,  0.6177,  ..., -2.0020, -3.9023, -4.5625]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 10:39:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of ability is abilities
The plural form of safety is safeties
The plural form of species is species
The plural form of life is lives
The plural form of facility is facilities
The plural form of activity is activities
The plural form of category is categories
The plural form of memory is
2024-07-27 10:39:03 root INFO     [order_1_approx] starting weight calculation for The plural form of activity is activities
The plural form of safety is safeties
The plural form of memory is memories
The plural form of life is lives
The plural form of facility is facilities
The plural form of species is species
The plural form of ability is abilities
The plural form of category is
2024-07-27 10:39:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 10:41:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3772,  0.0071, -0.2343,  ...,  0.1943, -0.3755,  0.0168],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7773, -2.7148,  1.8301,  ..., -1.0049, -0.1868, -2.7324],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0512,  0.0088, -0.0074,  ..., -0.0122,  0.0059, -0.0173],
        [ 0.0138,  0.0724,  0.0378,  ...,  0.0246, -0.0055,  0.0180],
        [-0.0016, -0.0095,  0.0396,  ..., -0.0164, -0.0173,  0.0068],
        ...,
        [ 0.0224,  0.0159,  0.0257,  ...,  0.0578, -0.0108,  0.0354],
        [-0.0317,  0.0039, -0.0171,  ...,  0.0040,  0.0561,  0.0059],
        [ 0.0256,  0.0055,  0.0216,  ...,  0.0164, -0.0183,  0.0710]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4963, -3.3242,  2.2520,  ..., -1.1729, -0.2976, -3.0703]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 10:41:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of activity is activities
The plural form of safety is safeties
The plural form of memory is memories
The plural form of life is lives
The plural form of facility is facilities
The plural form of species is species
The plural form of ability is abilities
The plural form of category is
2024-07-27 10:41:24 root INFO     total operator prediction time: 1141.9467272758484 seconds
2024-07-27 10:41:24 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - member
2024-07-27 10:41:24 root INFO     building operator meronyms - member
2024-07-27 10:41:25 root INFO     [order_1_approx] starting weight calculation for A cattle is a member of a herd
A sheep is a member of a flock
A county is a member of a state
A shrub is a member of a shrubbery
A student is a member of a class
A calf is a member of a cattle
A player is a member of a team
A college is a member of a
2024-07-27 10:41:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 10:43:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3335, -0.1052, -0.2939,  ..., -0.0082, -0.2610, -0.0077],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0820, -5.9141,  4.1562,  ..., -2.7383,  0.3179, -1.4590],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0342, -0.0018,  0.0249,  ...,  0.0121, -0.0188, -0.0168],
        [-0.0008,  0.0431,  0.0016,  ...,  0.0016,  0.0062, -0.0096],
        [ 0.0013, -0.0063,  0.0479,  ..., -0.0223, -0.0009,  0.0168],
        ...,
        [ 0.0123,  0.0107, -0.0218,  ...,  0.0433,  0.0038, -0.0211],
        [-0.0058,  0.0109, -0.0019,  ..., -0.0128,  0.0154,  0.0112],
        [ 0.0007,  0.0016,  0.0090,  ...,  0.0080, -0.0121,  0.0382]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1114, -5.7266,  3.9395,  ..., -2.4395,  0.5537, -1.5107]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 10:43:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A cattle is a member of a herd
A sheep is a member of a flock
A county is a member of a state
A shrub is a member of a shrubbery
A student is a member of a class
A calf is a member of a cattle
A player is a member of a team
A college is a member of a
2024-07-27 10:43:47 root INFO     [order_1_approx] starting weight calculation for A county is a member of a state
A player is a member of a team
A calf is a member of a cattle
A student is a member of a class
A sheep is a member of a flock
A shrub is a member of a shrubbery
A college is a member of a university
A cattle is a member of a
2024-07-27 10:43:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 10:46:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2090, -0.2839,  0.1543,  ..., -0.3416, -0.0506, -0.0665],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.7578, -3.5430,  4.2812,  ..., -3.9844, -0.2607, -1.1758],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.2603e-02, -4.9248e-03,  2.2095e-02,  ...,  7.2975e-03,
         -1.8173e-02,  4.8218e-03],
        [ 7.0076e-03,  4.3335e-02,  9.7275e-04,  ...,  1.1139e-02,
         -1.3533e-03, -1.0391e-02],
        [ 2.9707e-04, -1.5440e-03,  3.3539e-02,  ...,  5.0545e-03,
         -1.5137e-02, -4.9667e-03],
        ...,
        [ 2.0294e-03, -6.4316e-03,  8.8654e-03,  ...,  3.9978e-02,
          1.2985e-02, -2.1088e-02],
        [-7.0610e-03,  9.2392e-03, -1.4847e-02,  ..., -1.8272e-03,
          4.1992e-02,  7.3509e-03],
        [-5.7220e-06,  8.0967e-04, -3.5667e-03,  ..., -1.2154e-02,
         -1.1292e-03,  2.6764e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.3867, -4.0000,  4.2305,  ..., -3.8125, -0.4297, -0.7856]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 10:46:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A county is a member of a state
A player is a member of a team
A calf is a member of a cattle
A student is a member of a class
A sheep is a member of a flock
A shrub is a member of a shrubbery
A college is a member of a university
A cattle is a member of a
2024-07-27 10:46:08 root INFO     [order_1_approx] starting weight calculation for A player is a member of a team
A sheep is a member of a flock
A county is a member of a state
A cattle is a member of a herd
A calf is a member of a cattle
A college is a member of a university
A shrub is a member of a shrubbery
A student is a member of a
2024-07-27 10:46:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 10:48:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2803,  0.0781, -0.4485,  ...,  0.3247, -0.3264, -0.0090],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9678, -4.4336,  3.0234,  ..., -0.5938, -1.0898, -2.4355],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0405, -0.0063,  0.0127,  ...,  0.0260, -0.0148,  0.0003],
        [-0.0046,  0.0426,  0.0058,  ..., -0.0019, -0.0035, -0.0096],
        [ 0.0169, -0.0187,  0.0304,  ..., -0.0013,  0.0153,  0.0080],
        ...,
        [ 0.0051,  0.0160,  0.0051,  ...,  0.0465, -0.0190,  0.0041],
        [ 0.0087,  0.0161, -0.0048,  ..., -0.0011,  0.0457, -0.0019],
        [ 0.0099, -0.0098, -0.0091,  ..., -0.0083, -0.0167,  0.0453]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0703, -4.4961,  2.6523,  ..., -0.5566, -0.9902, -1.9980]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 10:48:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A player is a member of a team
A sheep is a member of a flock
A county is a member of a state
A cattle is a member of a herd
A calf is a member of a cattle
A college is a member of a university
A shrub is a member of a shrubbery
A student is a member of a
2024-07-27 10:48:29 root INFO     [order_1_approx] starting weight calculation for A player is a member of a team
A calf is a member of a cattle
A college is a member of a university
A sheep is a member of a flock
A student is a member of a class
A cattle is a member of a herd
A shrub is a member of a shrubbery
A county is a member of a
2024-07-27 10:48:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 10:50:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2583, -0.0362, -0.2178,  ...,  0.0621, -0.0400,  0.1565],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0449, -5.4688,  3.5879,  ..., -5.1797,  0.9365, -2.6738],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0222, -0.0182,  0.0240,  ...,  0.0036, -0.0162, -0.0021],
        [-0.0076,  0.0411,  0.0076,  ...,  0.0058,  0.0205, -0.0077],
        [ 0.0056,  0.0157,  0.0441,  ..., -0.0122, -0.0214, -0.0078],
        ...,
        [ 0.0042,  0.0154, -0.0185,  ...,  0.0342,  0.0286, -0.0165],
        [ 0.0137,  0.0070, -0.0162,  ..., -0.0030,  0.0408,  0.0051],
        [-0.0158, -0.0054,  0.0032,  ..., -0.0036,  0.0161,  0.0396]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2822, -5.1406,  3.3926,  ..., -4.9336,  0.6133, -2.8242]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 10:50:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A player is a member of a team
A calf is a member of a cattle
A college is a member of a university
A sheep is a member of a flock
A student is a member of a class
A cattle is a member of a herd
A shrub is a member of a shrubbery
A county is a member of a
2024-07-27 10:50:51 root INFO     [order_1_approx] starting weight calculation for A county is a member of a state
A sheep is a member of a flock
A college is a member of a university
A shrub is a member of a shrubbery
A student is a member of a class
A calf is a member of a cattle
A cattle is a member of a herd
A player is a member of a
2024-07-27 10:50:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 10:53:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0107,  0.1102,  0.0964,  ...,  0.1318, -0.2988, -0.2954],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7559, -7.4062,  1.1758,  ..., -1.0117, -0.8096, -4.1406],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0461, -0.0083,  0.0078,  ...,  0.0274, -0.0189,  0.0028],
        [-0.0030,  0.0532,  0.0112,  ...,  0.0249, -0.0042,  0.0166],
        [ 0.0214, -0.0096,  0.0404,  ..., -0.0253,  0.0105,  0.0066],
        ...,
        [-0.0046,  0.0281,  0.0068,  ...,  0.0691,  0.0063, -0.0066],
        [ 0.0056,  0.0006,  0.0009,  ..., -0.0042,  0.0621, -0.0013],
        [ 0.0115, -0.0071, -0.0112,  ...,  0.0031, -0.0089,  0.0353]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0684, -7.6367,  1.2188,  ..., -0.9858, -0.7656, -3.7930]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 10:53:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A county is a member of a state
A sheep is a member of a flock
A college is a member of a university
A shrub is a member of a shrubbery
A student is a member of a class
A calf is a member of a cattle
A cattle is a member of a herd
A player is a member of a
2024-07-27 10:53:13 root INFO     [order_1_approx] starting weight calculation for A college is a member of a university
A student is a member of a class
A county is a member of a state
A player is a member of a team
A calf is a member of a cattle
A cattle is a member of a herd
A shrub is a member of a shrubbery
A sheep is a member of a
2024-07-27 10:53:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 10:55:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 3.5767e-01, -4.8828e-04, -2.0471e-01,  ...,  5.7373e-02,
        -6.9275e-02,  5.0928e-01], device='cuda:1', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7461, -0.1162,  3.7812,  ..., -1.4746, -2.6992, -0.3047],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0520, -0.0089,  0.0053,  ..., -0.0046, -0.0284, -0.0105],
        [ 0.0041,  0.0724, -0.0044,  ...,  0.0262, -0.0106, -0.0095],
        [ 0.0093, -0.0085,  0.0515,  ...,  0.0001, -0.0097, -0.0154],
        ...,
        [ 0.0127,  0.0306, -0.0036,  ...,  0.0660, -0.0026, -0.0141],
        [ 0.0018,  0.0182,  0.0012,  ..., -0.0088,  0.0533,  0.0165],
        [-0.0162, -0.0160, -0.0086,  ..., -0.0282,  0.0049,  0.0375]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8848,  0.0442,  3.5430,  ..., -1.5049, -3.1055, -0.4128]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 10:55:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A college is a member of a university
A student is a member of a class
A county is a member of a state
A player is a member of a team
A calf is a member of a cattle
A cattle is a member of a herd
A shrub is a member of a shrubbery
A sheep is a member of a
2024-07-27 10:55:35 root INFO     [order_1_approx] starting weight calculation for A player is a member of a team
A shrub is a member of a shrubbery
A county is a member of a state
A college is a member of a university
A cattle is a member of a herd
A sheep is a member of a flock
A student is a member of a class
A calf is a member of a
2024-07-27 10:55:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 10:57:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5088, -0.1633,  0.3008,  ..., -0.0226, -0.4163,  0.4702],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.9844, -1.7598,  1.4678,  ..., -1.5801, -0.4248, -0.7441],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.4302e-02,  6.5346e-03,  1.2741e-02,  ...,  7.2021e-03,
         -2.3041e-02, -1.4771e-02],
        [ 1.2573e-02,  6.2622e-02, -1.4938e-02,  ...,  1.6266e-02,
          7.2861e-03, -1.7792e-02],
        [ 3.9406e-03, -2.3804e-02,  4.5898e-02,  ..., -4.7073e-03,
         -2.4002e-02, -6.2714e-03],
        ...,
        [ 1.3245e-02,  8.4686e-03,  4.2057e-04,  ...,  5.9814e-02,
          1.9608e-02, -1.5488e-02],
        [-4.5776e-05,  7.0000e-03, -6.7520e-03,  ...,  1.9470e-02,
          4.1290e-02, -7.0610e-03],
        [ 9.6893e-03,  1.1902e-03, -1.0368e-02,  ..., -2.3514e-02,
          1.0521e-02,  5.7678e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.0234, -1.8301,  1.7812,  ..., -1.5615, -0.5513, -1.1338]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 10:57:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A player is a member of a team
A shrub is a member of a shrubbery
A county is a member of a state
A college is a member of a university
A cattle is a member of a herd
A sheep is a member of a flock
A student is a member of a class
A calf is a member of a
2024-07-27 10:57:56 root INFO     [order_1_approx] starting weight calculation for A student is a member of a class
A player is a member of a team
A calf is a member of a cattle
A college is a member of a university
A sheep is a member of a flock
A county is a member of a state
A cattle is a member of a herd
A shrub is a member of a
2024-07-27 10:57:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 11:00:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3120, -0.0505,  0.1711,  ..., -0.0945, -0.3098, -0.3489],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0547, -4.2148,  1.6094,  ..., -2.9844, -2.6016, -2.3652],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.0457e-02, -1.8448e-02, -4.8065e-03,  ...,  1.1124e-02,
         -1.5686e-02, -2.0528e-04],
        [ 8.6517e-03,  2.1713e-02,  2.4166e-03,  ...,  1.8555e-02,
          1.3031e-02, -8.1177e-03],
        [-1.9470e-02, -2.6283e-03,  6.0242e-02,  ..., -3.1708e-02,
          2.3079e-03, -4.3411e-03],
        ...,
        [ 3.8147e-03,  9.9030e-03,  4.7607e-03,  ...,  8.0200e-02,
          1.2642e-02, -4.6005e-03],
        [ 3.9444e-03,  1.6270e-03, -1.7166e-05,  ...,  3.7003e-03,
          3.0914e-02,  1.1726e-02],
        [-2.4414e-02, -2.1408e-02, -7.8812e-03,  ..., -2.7039e-02,
         -2.6398e-02,  5.9601e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1211, -3.9824,  1.7031,  ..., -2.8379, -2.8594, -1.8574]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 11:00:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A student is a member of a class
A player is a member of a team
A calf is a member of a cattle
A college is a member of a university
A sheep is a member of a flock
A county is a member of a state
A cattle is a member of a herd
A shrub is a member of a
2024-07-27 11:00:19 root INFO     total operator prediction time: 1134.4135143756866 seconds
2024-07-27 11:00:19 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on antonyms - binary
2024-07-27 11:00:19 root INFO     building operator antonyms - binary
2024-07-27 11:00:19 root INFO     [order_1_approx] starting weight calculation for The opposite of in is out
The opposite of inside is outside
The opposite of out is in
The opposite of front is back
The opposite of under is over
The opposite of previously is subsequently
The opposite of submerge is emerge
The opposite of dead is
2024-07-27 11:00:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 11:02:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0309, -0.0491, -0.0370,  ..., -0.4927, -0.0900, -0.0751],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4854, -2.9570,  0.8555,  ..., -3.7676, -2.8867, -3.0547],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0288,  0.0051,  0.0130,  ...,  0.0190, -0.0149, -0.0023],
        [ 0.0074,  0.0586, -0.0084,  ...,  0.0115,  0.0178, -0.0088],
        [ 0.0179,  0.0098,  0.0556,  ..., -0.0178, -0.0486, -0.0193],
        ...,
        [-0.0139,  0.0244, -0.0028,  ...,  0.0271,  0.0182, -0.0299],
        [-0.0031, -0.0245,  0.0378,  ...,  0.0029,  0.0414, -0.0004],
        [ 0.0108,  0.0070, -0.0107,  ..., -0.0231, -0.0119,  0.0421]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6387, -2.5859,  0.2886,  ..., -3.0117, -2.8691, -3.3359]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 11:02:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of in is out
The opposite of inside is outside
The opposite of out is in
The opposite of front is back
The opposite of under is over
The opposite of previously is subsequently
The opposite of submerge is emerge
The opposite of dead is
2024-07-27 11:02:41 root INFO     [order_1_approx] starting weight calculation for The opposite of out is in
The opposite of previously is subsequently
The opposite of inside is outside
The opposite of under is over
The opposite of front is back
The opposite of submerge is emerge
The opposite of dead is alive
The opposite of in is
2024-07-27 11:02:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 11:05:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4150, -0.0957, -0.1539,  ..., -0.4341, -0.0192, -0.1560],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1406, -4.1875,  1.1914,  ..., -3.5469,  0.6489, -5.0820],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 8.3069e-02, -1.3931e-02, -5.2551e-02,  ...,  4.9477e-03,
          3.8147e-06, -2.0447e-02],
        [ 1.9241e-02,  4.9408e-02,  9.9030e-03,  ...,  2.0325e-02,
          9.5673e-03,  3.6793e-03],
        [-1.4671e-02,  5.5389e-03,  9.7752e-04,  ...,  1.3596e-02,
         -9.2697e-03,  1.2970e-04],
        ...,
        [-5.6076e-03, -2.6550e-03,  1.7670e-02,  ...,  1.5640e-02,
          5.4245e-03, -1.8387e-02],
        [ 3.2272e-03, -9.7656e-03,  4.2694e-02,  ..., -5.2948e-03,
          6.7444e-02,  4.7668e-02],
        [ 3.9276e-02,  7.3280e-03, -1.5579e-02,  ..., -1.8433e-02,
         -1.7181e-02,  5.4474e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2419, -4.1172,  1.6963,  ..., -3.5781,  0.0278, -5.0703]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 11:05:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of out is in
The opposite of previously is subsequently
The opposite of inside is outside
The opposite of under is over
The opposite of front is back
The opposite of submerge is emerge
The opposite of dead is alive
The opposite of in is
2024-07-27 11:05:03 root INFO     [order_1_approx] starting weight calculation for The opposite of under is over
The opposite of submerge is emerge
The opposite of in is out
The opposite of dead is alive
The opposite of previously is subsequently
The opposite of inside is outside
The opposite of front is back
The opposite of out is
2024-07-27 11:05:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 11:07:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0494,  0.0378, -0.1077,  ..., -0.2896,  0.1243, -0.1545],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8555, -3.6680,  0.2445,  ..., -1.0049, -0.2793, -3.9395],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0291,  0.0078, -0.0113,  ..., -0.0075, -0.0116, -0.0042],
        [ 0.0235,  0.0572, -0.0305,  ...,  0.0366,  0.0432, -0.0035],
        [-0.0289,  0.0054,  0.0095,  ..., -0.0069, -0.0347, -0.0147],
        ...,
        [ 0.0280, -0.0104, -0.0442,  ...,  0.0737,  0.0190, -0.0221],
        [ 0.0153, -0.0224,  0.0233,  ...,  0.0153,  0.0447, -0.0080],
        [ 0.0261,  0.0115, -0.0107,  ...,  0.0072,  0.0221,  0.0401]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2607, -3.7734, -0.5889,  ..., -1.4980, -0.1201, -3.8164]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 11:07:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of under is over
The opposite of submerge is emerge
The opposite of in is out
The opposite of dead is alive
The opposite of previously is subsequently
The opposite of inside is outside
The opposite of front is back
The opposite of out is
2024-07-27 11:07:24 root INFO     [order_1_approx] starting weight calculation for The opposite of dead is alive
The opposite of submerge is emerge
The opposite of front is back
The opposite of out is in
The opposite of previously is subsequently
The opposite of inside is outside
The opposite of in is out
The opposite of under is
2024-07-27 11:07:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 11:09:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2969,  0.0814, -0.0513,  ..., -0.3613, -0.0256, -0.1533],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1719, -4.5156,  2.1680,  ..., -0.7627,  1.7168, -1.8516],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0409, -0.0238,  0.0104,  ...,  0.0211, -0.0089, -0.0096],
        [ 0.0027,  0.0501, -0.0160,  ...,  0.0093, -0.0099, -0.0168],
        [-0.0181, -0.0137,  0.0150,  ..., -0.0038, -0.0121,  0.0237],
        ...,
        [-0.0022,  0.0059,  0.0054,  ...,  0.0185,  0.0153, -0.0269],
        [-0.0003,  0.0189,  0.0186,  ..., -0.0015,  0.0345, -0.0041],
        [-0.0007,  0.0080, -0.0114,  ..., -0.0083, -0.0032,  0.0263]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.2461, -4.1836,  1.9453,  ..., -0.6885,  0.9541, -1.9238]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 11:09:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of dead is alive
The opposite of submerge is emerge
The opposite of front is back
The opposite of out is in
The opposite of previously is subsequently
The opposite of inside is outside
The opposite of in is out
The opposite of under is
2024-07-27 11:09:44 root INFO     [order_1_approx] starting weight calculation for The opposite of out is in
The opposite of in is out
The opposite of previously is subsequently
The opposite of submerge is emerge
The opposite of front is back
The opposite of under is over
The opposite of dead is alive
The opposite of inside is
2024-07-27 11:09:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 11:12:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2263, -0.3164, -0.1689,  ..., -0.2217,  0.1151,  0.0734],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1445, -3.6445,  2.2207,  ..., -1.3652,  3.4492, -2.1367],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0473, -0.0196,  0.0009,  ...,  0.0256, -0.0098, -0.0327],
        [-0.0018,  0.0498, -0.0053,  ...,  0.0272,  0.0085,  0.0082],
        [-0.0089,  0.0004,  0.0145,  ..., -0.0187, -0.0248,  0.0074],
        ...,
        [ 0.0008,  0.0006,  0.0054,  ...,  0.0515,  0.0221, -0.0088],
        [-0.0334,  0.0256,  0.0102,  ...,  0.0219,  0.0483,  0.0173],
        [-0.0113, -0.0398,  0.0149,  ..., -0.0033, -0.0146,  0.0582]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5723, -3.3477,  2.1523,  ..., -1.6943,  2.7578, -2.3203]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 11:12:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of out is in
The opposite of in is out
The opposite of previously is subsequently
The opposite of submerge is emerge
The opposite of front is back
The opposite of under is over
The opposite of dead is alive
The opposite of inside is
2024-07-27 11:12:07 root INFO     [order_1_approx] starting weight calculation for The opposite of out is in
The opposite of front is back
The opposite of submerge is emerge
The opposite of under is over
The opposite of in is out
The opposite of inside is outside
The opposite of dead is alive
The opposite of previously is
2024-07-27 11:12:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 11:14:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0723,  0.0939, -0.2510,  ..., -0.3201, -0.3811,  0.2130],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0996, -3.2793, -0.7148,  ..., -1.6631, -1.7256, -5.6289],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0525, -0.0030, -0.0036,  ...,  0.0175, -0.0244, -0.0021],
        [-0.0300,  0.0656, -0.0439,  ...,  0.0164, -0.0208,  0.0026],
        [ 0.0035, -0.0025,  0.0213,  ...,  0.0085, -0.0170, -0.0148],
        ...,
        [-0.0138,  0.0173, -0.0354,  ...,  0.0354, -0.0031, -0.0266],
        [ 0.0280, -0.0382,  0.0402,  ...,  0.0212,  0.0458,  0.0219],
        [ 0.0053,  0.0491, -0.0385,  ..., -0.0513, -0.0465,  0.0088]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2852, -2.7227, -0.2195,  ..., -0.7549, -1.9941, -5.0000]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 11:14:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of out is in
The opposite of front is back
The opposite of submerge is emerge
The opposite of under is over
The opposite of in is out
The opposite of inside is outside
The opposite of dead is alive
The opposite of previously is
2024-07-27 11:14:29 root INFO     [order_1_approx] starting weight calculation for The opposite of inside is outside
The opposite of out is in
The opposite of previously is subsequently
The opposite of under is over
The opposite of front is back
The opposite of in is out
The opposite of dead is alive
The opposite of submerge is
2024-07-27 11:14:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 11:16:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1943,  0.5239,  0.1260,  ...,  0.1093, -0.7549,  0.1482],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3008, -0.8506, -0.1519,  ...,  3.5156, -2.3281,  0.1152],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0626,  0.0008, -0.0201,  ..., -0.0275,  0.0419,  0.0006],
        [ 0.0089,  0.0578,  0.0246,  ...,  0.0474, -0.0179, -0.0143],
        [-0.0059,  0.0280,  0.0409,  ..., -0.0279,  0.0078,  0.0060],
        ...,
        [-0.0211,  0.0252,  0.0180,  ...,  0.0670,  0.0107, -0.0094],
        [ 0.0094,  0.0306,  0.0224,  ..., -0.0184,  0.0368, -0.0029],
        [-0.0060,  0.0107,  0.0119,  ..., -0.0184, -0.0110,  0.0444]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8359, -0.9141, -0.4077,  ...,  3.0273, -2.7031, -0.6084]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 11:16:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of inside is outside
The opposite of out is in
The opposite of previously is subsequently
The opposite of under is over
The opposite of front is back
The opposite of in is out
The opposite of dead is alive
The opposite of submerge is
2024-07-27 11:16:51 root INFO     [order_1_approx] starting weight calculation for The opposite of submerge is emerge
The opposite of previously is subsequently
The opposite of inside is outside
The opposite of under is over
The opposite of dead is alive
The opposite of out is in
The opposite of in is out
The opposite of front is
2024-07-27 11:16:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 11:19:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3921,  0.0916, -0.3120,  ..., -0.0967, -0.0164, -0.2042],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.9766, -2.6211,  1.2441,  ..., -0.6548, -0.0898, -1.6602],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0671, -0.0227,  0.0169,  ...,  0.0339, -0.0546, -0.0249],
        [-0.0007,  0.0735, -0.0053,  ...,  0.0045,  0.0383, -0.0299],
        [ 0.0076, -0.0317,  0.0375,  ..., -0.0014, -0.0533, -0.0040],
        ...,
        [-0.0028,  0.0082, -0.0143,  ...,  0.0614,  0.0220,  0.0029],
        [-0.0085,  0.0205, -0.0061,  ...,  0.0035,  0.0549,  0.0120],
        [ 0.0065, -0.0141,  0.0040,  ...,  0.0045,  0.0259,  0.0577]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4873, -2.4277,  1.3223,  ..., -0.4763,  0.1532, -1.6953]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 11:19:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of submerge is emerge
The opposite of previously is subsequently
The opposite of inside is outside
The opposite of under is over
The opposite of dead is alive
The opposite of out is in
The opposite of in is out
The opposite of front is
2024-07-27 11:19:13 root INFO     total operator prediction time: 1133.9746191501617 seconds
2024-07-27 11:19:13 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hyponyms - misc
2024-07-27 11:19:13 root INFO     building operator hyponyms - misc
2024-07-27 11:19:13 root INFO     [order_1_approx] starting weight calculation for A more specific term for a cloud is thundercloud
A more specific term for a shirt is polo
A more specific term for a dessert is cake
A more specific term for a jewelry is bracelet
A more specific term for a oven is broiler
A more specific term for a month is january
A more specific term for a shelf is bookshelf
A more specific term for a seat is
2024-07-27 11:19:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 11:21:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3728, -0.0762, -0.2333,  ...,  0.4749, -0.2045,  0.0325],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1074, -4.3359,  4.6602,  ...,  2.4805, -2.5547,  1.2988],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0928, -0.0155, -0.0059,  ...,  0.0076, -0.0250, -0.0206],
        [ 0.0040,  0.0907, -0.0086,  ...,  0.0111,  0.0417, -0.0044],
        [-0.0082, -0.0130,  0.0779,  ..., -0.0006, -0.0232,  0.0013],
        ...,
        [ 0.0121,  0.0235,  0.0077,  ...,  0.0977,  0.0159, -0.0073],
        [-0.0117, -0.0041, -0.0336,  ...,  0.0200, -0.0253, -0.0215],
        [ 0.0113,  0.0140,  0.0065,  ..., -0.0089,  0.0027,  0.0589]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3555, -4.5039,  4.3398,  ...,  2.6523, -2.1270,  0.7393]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 11:21:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a cloud is thundercloud
A more specific term for a shirt is polo
A more specific term for a dessert is cake
A more specific term for a jewelry is bracelet
A more specific term for a oven is broiler
A more specific term for a month is january
A more specific term for a shelf is bookshelf
A more specific term for a seat is
2024-07-27 11:21:34 root INFO     [order_1_approx] starting weight calculation for A more specific term for a shelf is bookshelf
A more specific term for a cloud is thundercloud
A more specific term for a oven is broiler
A more specific term for a month is january
A more specific term for a seat is chair
A more specific term for a shirt is polo
A more specific term for a dessert is cake
A more specific term for a jewelry is
2024-07-27 11:21:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 11:23:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2654, -0.3398,  0.0379,  ..., -0.1434, -0.3130, -0.2000],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9648, -3.3730, -4.6289,  ...,  0.1777, -3.5430,  1.3447],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0279, -0.0082,  0.0075,  ..., -0.0088, -0.0049,  0.0129],
        [-0.0074,  0.0416,  0.0049,  ..., -0.0075,  0.0183, -0.0143],
        [ 0.0094,  0.0082,  0.0301,  ...,  0.0071, -0.0010,  0.0095],
        ...,
        [-0.0052,  0.0017, -0.0108,  ...,  0.0255,  0.0061, -0.0123],
        [-0.0112, -0.0080, -0.0091,  ...,  0.0019,  0.0004, -0.0025],
        [ 0.0019,  0.0138,  0.0045,  ..., -0.0212,  0.0086,  0.0250]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9346, -3.1992, -4.5430,  ...,  0.2549, -3.3496,  1.2266]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 11:23:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a shelf is bookshelf
A more specific term for a cloud is thundercloud
A more specific term for a oven is broiler
A more specific term for a month is january
A more specific term for a seat is chair
A more specific term for a shirt is polo
A more specific term for a dessert is cake
A more specific term for a jewelry is
2024-07-27 11:23:54 root INFO     [order_1_approx] starting weight calculation for A more specific term for a oven is broiler
A more specific term for a month is january
A more specific term for a shelf is bookshelf
A more specific term for a seat is chair
A more specific term for a cloud is thundercloud
A more specific term for a dessert is cake
A more specific term for a jewelry is bracelet
A more specific term for a shirt is
2024-07-27 11:23:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 11:26:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0390,  0.0097, -0.2329,  ...,  0.5332, -0.5073,  0.0820],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9688e+00, -2.5762e+00,  9.7656e-04,  ...,  2.9922e+00,
        -1.1367e+00, -4.5996e-01], device='cuda:1', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0486,  0.0105,  0.0031,  ...,  0.0106,  0.0063, -0.0149],
        [-0.0033,  0.0362, -0.0060,  ...,  0.0081,  0.0019, -0.0110],
        [ 0.0218, -0.0278,  0.0527,  ...,  0.0004, -0.0222, -0.0102],
        ...,
        [ 0.0126,  0.0182, -0.0040,  ...,  0.0604,  0.0148, -0.0097],
        [-0.0015, -0.0027, -0.0104,  ...,  0.0057,  0.0614, -0.0192],
        [ 0.0010,  0.0036,  0.0211,  ..., -0.0072,  0.0018,  0.0419]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9746, -2.7090, -0.5825,  ...,  2.8770, -1.1123, -0.4448]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 11:26:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a oven is broiler
A more specific term for a month is january
A more specific term for a shelf is bookshelf
A more specific term for a seat is chair
A more specific term for a cloud is thundercloud
A more specific term for a dessert is cake
A more specific term for a jewelry is bracelet
A more specific term for a shirt is
2024-07-27 11:26:14 root INFO     [order_1_approx] starting weight calculation for A more specific term for a shelf is bookshelf
A more specific term for a dessert is cake
A more specific term for a seat is chair
A more specific term for a shirt is polo
A more specific term for a jewelry is bracelet
A more specific term for a oven is broiler
A more specific term for a cloud is thundercloud
A more specific term for a month is
2024-07-27 11:26:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 11:28:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2910, -0.2974, -0.2966,  ...,  0.2452, -0.0896,  0.0895],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0508, -5.4453,  5.6953,  ..., -0.8887,  0.7598, -0.7314],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0026,  0.0196, -0.0326,  ..., -0.0237, -0.0030,  0.0092],
        [ 0.0024,  0.0635, -0.0054,  ...,  0.0110, -0.0014, -0.0224],
        [-0.0382,  0.0032,  0.0426,  ..., -0.0115, -0.0164,  0.0231],
        ...,
        [ 0.0105,  0.0248, -0.0028,  ...,  0.0910, -0.0144, -0.0185],
        [-0.0505,  0.0159, -0.0003,  ..., -0.0149,  0.0604,  0.0145],
        [-0.0013,  0.0267, -0.0111,  ...,  0.0196,  0.0133,  0.0565]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5938, -5.0469,  5.2930,  ..., -1.1562,  0.5010, -0.6172]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 11:28:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a shelf is bookshelf
A more specific term for a dessert is cake
A more specific term for a seat is chair
A more specific term for a shirt is polo
A more specific term for a jewelry is bracelet
A more specific term for a oven is broiler
A more specific term for a cloud is thundercloud
A more specific term for a month is
2024-07-27 11:28:34 root INFO     [order_1_approx] starting weight calculation for A more specific term for a seat is chair
A more specific term for a cloud is thundercloud
A more specific term for a dessert is cake
A more specific term for a jewelry is bracelet
A more specific term for a shelf is bookshelf
A more specific term for a shirt is polo
A more specific term for a month is january
A more specific term for a oven is
2024-07-27 11:28:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 11:30:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0908, -0.4292, -0.1178,  ...,  0.1764, -0.3625, -0.2783],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7578, -5.4531,  4.0156,  ..., -3.1602, -3.7891,  1.5742],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0545, -0.0021, -0.0190,  ...,  0.0246, -0.0145,  0.0080],
        [ 0.0051,  0.0635,  0.0086,  ..., -0.0009,  0.0139, -0.0134],
        [-0.0300, -0.0194,  0.0611,  ..., -0.0022,  0.0034, -0.0030],
        ...,
        [ 0.0004,  0.0122,  0.0075,  ...,  0.0580,  0.0012,  0.0017],
        [-0.0255, -0.0039,  0.0059,  ...,  0.0059,  0.0917, -0.0200],
        [-0.0203,  0.0091,  0.0132,  ..., -0.0222, -0.0043,  0.0386]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6445, -5.8281,  4.0703,  ..., -2.9512, -2.9727,  1.6172]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 11:30:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a seat is chair
A more specific term for a cloud is thundercloud
A more specific term for a dessert is cake
A more specific term for a jewelry is bracelet
A more specific term for a shelf is bookshelf
A more specific term for a shirt is polo
A more specific term for a month is january
A more specific term for a oven is
2024-07-27 11:30:56 root INFO     [order_1_approx] starting weight calculation for A more specific term for a seat is chair
A more specific term for a shirt is polo
A more specific term for a dessert is cake
A more specific term for a shelf is bookshelf
A more specific term for a month is january
A more specific term for a jewelry is bracelet
A more specific term for a oven is broiler
A more specific term for a cloud is
2024-07-27 11:30:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 11:33:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1628, -0.1771, -0.1550,  ..., -0.0855, -0.0983,  0.0335],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6875, -3.2520,  4.5508,  ..., -0.3750, -1.0361,  0.8906],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0915,  0.0112,  0.0013,  ..., -0.0147,  0.0007,  0.0063],
        [ 0.0161,  0.0669, -0.0249,  ...,  0.0218, -0.0152, -0.0145],
        [ 0.0071, -0.0104,  0.0681,  ...,  0.0103, -0.0302,  0.0184],
        ...,
        [ 0.0049,  0.0065,  0.0014,  ...,  0.0657, -0.0127, -0.0034],
        [-0.0232, -0.0002,  0.0022,  ...,  0.0015,  0.0776, -0.0114],
        [ 0.0041,  0.0125, -0.0176,  ..., -0.0144,  0.0047,  0.0627]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1055, -4.0078,  3.9688,  ..., -0.3826, -0.8784,  0.9341]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 11:33:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a seat is chair
A more specific term for a shirt is polo
A more specific term for a dessert is cake
A more specific term for a shelf is bookshelf
A more specific term for a month is january
A more specific term for a jewelry is bracelet
A more specific term for a oven is broiler
A more specific term for a cloud is
2024-07-27 11:33:17 root INFO     [order_1_approx] starting weight calculation for A more specific term for a seat is chair
A more specific term for a jewelry is bracelet
A more specific term for a dessert is cake
A more specific term for a cloud is thundercloud
A more specific term for a month is january
A more specific term for a shirt is polo
A more specific term for a oven is broiler
A more specific term for a shelf is
2024-07-27 11:33:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 11:35:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0936, -0.5327, -0.5693,  ...,  0.3191, -0.2222,  0.0367],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.8477, -3.7910,  1.3438,  ...,  3.8281, -2.8711,  2.0918],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0634, -0.0003,  0.0151,  ...,  0.0183, -0.0152, -0.0024],
        [ 0.0043,  0.0773, -0.0171,  ...,  0.0191,  0.0066, -0.0077],
        [ 0.0237, -0.0134,  0.0592,  ..., -0.0162, -0.0110,  0.0158],
        ...,
        [ 0.0120,  0.0261, -0.0050,  ...,  0.0657,  0.0020,  0.0028],
        [-0.0123,  0.0120, -0.0285,  ..., -0.0044,  0.0417, -0.0014],
        [-0.0133,  0.0333, -0.0134,  ..., -0.0128, -0.0127,  0.0563]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.0117, -4.1133,  1.7676,  ...,  3.9746, -2.4199,  2.0273]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 11:35:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a seat is chair
A more specific term for a jewelry is bracelet
A more specific term for a dessert is cake
A more specific term for a cloud is thundercloud
A more specific term for a month is january
A more specific term for a shirt is polo
A more specific term for a oven is broiler
A more specific term for a shelf is
2024-07-27 11:35:38 root INFO     [order_1_approx] starting weight calculation for A more specific term for a cloud is thundercloud
A more specific term for a seat is chair
A more specific term for a shirt is polo
A more specific term for a oven is broiler
A more specific term for a month is january
A more specific term for a shelf is bookshelf
A more specific term for a jewelry is bracelet
A more specific term for a dessert is
2024-07-27 11:35:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 11:37:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1658, -0.2498,  0.0500,  ..., -0.0966, -0.4565, -0.5703],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([  2.7852, -11.1797,   1.3691,  ...,  -0.6191,  -1.1719,   1.5156],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0511, -0.0078,  0.0103,  ...,  0.0086, -0.0102,  0.0036],
        [-0.0035,  0.0308,  0.0305,  ..., -0.0068,  0.0068, -0.0051],
        [-0.0227, -0.0138,  0.0295,  ...,  0.0031, -0.0107,  0.0056],
        ...,
        [ 0.0051,  0.0079, -0.0138,  ...,  0.0373, -0.0061, -0.0028],
        [-0.0042,  0.0036, -0.0051,  ..., -0.0035,  0.0266,  0.0089],
        [-0.0103,  0.0076,  0.0084,  ..., -0.0141,  0.0170,  0.0248]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[  2.6621, -11.1406,   1.4912,  ...,  -0.4297,  -1.2178,   1.6211]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 11:37:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a cloud is thundercloud
A more specific term for a seat is chair
A more specific term for a shirt is polo
A more specific term for a oven is broiler
A more specific term for a month is january
A more specific term for a shelf is bookshelf
A more specific term for a jewelry is bracelet
A more specific term for a dessert is
2024-07-27 11:37:59 root INFO     total operator prediction time: 1125.7265062332153 seconds
2024-07-27 11:37:59 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hypernyms - animals
2024-07-27 11:37:59 root INFO     building operator hypernyms - animals
2024-07-27 11:37:59 root INFO     [order_1_approx] starting weight calculation for The cat falls into the category of feline
The hawk falls into the category of raptor
The tiger falls into the category of feline
The goat falls into the category of bovid
The triceratops falls into the category of dinosaur
The beetle falls into the category of insect
The gibbon falls into the category of primate
The wolf falls into the category of
2024-07-27 11:37:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 11:40:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5513, -0.2140,  0.1602,  ...,  0.4792, -0.2808, -0.1455],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.2598, -5.5820,  0.9912,  ..., -4.0156, -5.7109,  0.6123],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0310,  0.0109, -0.0061,  ..., -0.0257, -0.0118,  0.0092],
        [ 0.0075,  0.0207,  0.0165,  ..., -0.0078,  0.0056, -0.0020],
        [-0.0002,  0.0110,  0.0536,  ..., -0.0120, -0.0104, -0.0112],
        ...,
        [ 0.0041,  0.0162,  0.0065,  ...,  0.0170,  0.0327,  0.0158],
        [ 0.0075, -0.0269,  0.0021,  ...,  0.0195,  0.0291, -0.0060],
        [ 0.0059, -0.0103, -0.0156,  ..., -0.0081, -0.0164,  0.0165]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.0908, -5.8398,  0.6094,  ..., -3.5332, -6.5703,  0.9380]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 11:40:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The cat falls into the category of feline
The hawk falls into the category of raptor
The tiger falls into the category of feline
The goat falls into the category of bovid
The triceratops falls into the category of dinosaur
The beetle falls into the category of insect
The gibbon falls into the category of primate
The wolf falls into the category of
2024-07-27 11:40:20 root INFO     [order_1_approx] starting weight calculation for The cat falls into the category of feline
The beetle falls into the category of insect
The gibbon falls into the category of primate
The hawk falls into the category of raptor
The tiger falls into the category of feline
The triceratops falls into the category of dinosaur
The wolf falls into the category of canine
The goat falls into the category of
2024-07-27 11:40:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 11:42:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0813, -0.2683,  0.2390,  ...,  0.3535, -0.2532,  0.4458],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6963, -4.6680,  2.5840,  ..., -1.3242, -7.7734, -1.6113],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0383,  0.0143, -0.0269,  ..., -0.0155, -0.0276, -0.0112],
        [ 0.0129,  0.0619, -0.0003,  ...,  0.0140, -0.0056, -0.0231],
        [-0.0072,  0.0144,  0.0330,  ..., -0.0146,  0.0105, -0.0103],
        ...,
        [ 0.0005,  0.0093, -0.0090,  ...,  0.0384,  0.0227, -0.0017],
        [-0.0027,  0.0180, -0.0088,  ..., -0.0168,  0.0607,  0.0014],
        [ 0.0054,  0.0048, -0.0130,  ..., -0.0265, -0.0098,  0.0660]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7632, -4.6953,  1.9307,  ..., -1.3613, -8.0547, -1.4746]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 11:42:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The cat falls into the category of feline
The beetle falls into the category of insect
The gibbon falls into the category of primate
The hawk falls into the category of raptor
The tiger falls into the category of feline
The triceratops falls into the category of dinosaur
The wolf falls into the category of canine
The goat falls into the category of
2024-07-27 11:42:41 root INFO     [order_1_approx] starting weight calculation for The wolf falls into the category of canine
The gibbon falls into the category of primate
The cat falls into the category of feline
The hawk falls into the category of raptor
The tiger falls into the category of feline
The triceratops falls into the category of dinosaur
The goat falls into the category of bovid
The beetle falls into the category of
2024-07-27 11:42:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 11:45:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1632,  0.0474,  0.1007,  ...,  0.5049, -0.2688, -0.3074],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2798, -2.3203,  2.7305,  ..., -0.5801, -3.3086, -2.3496],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0483, -0.0007, -0.0035,  ..., -0.0187, -0.0178, -0.0085],
        [ 0.0186, -0.0033,  0.0070,  ...,  0.0329,  0.0045, -0.0077],
        [-0.0090,  0.0036,  0.0389,  ..., -0.0154, -0.0051, -0.0049],
        ...,
        [ 0.0160,  0.0020, -0.0091,  ...,  0.0541,  0.0158,  0.0056],
        [-0.0141,  0.0091,  0.0093,  ...,  0.0083,  0.0296,  0.0096],
        [ 0.0035, -0.0050, -0.0020,  ..., -0.0098, -0.0096,  0.0239]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3240, -2.6152,  2.4688,  ..., -0.4189, -3.4688, -1.9160]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 11:45:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The wolf falls into the category of canine
The gibbon falls into the category of primate
The cat falls into the category of feline
The hawk falls into the category of raptor
The tiger falls into the category of feline
The triceratops falls into the category of dinosaur
The goat falls into the category of bovid
The beetle falls into the category of
2024-07-27 11:45:02 root INFO     [order_1_approx] starting weight calculation for The tiger falls into the category of feline
The goat falls into the category of bovid
The wolf falls into the category of canine
The triceratops falls into the category of dinosaur
The beetle falls into the category of insect
The cat falls into the category of feline
The gibbon falls into the category of primate
The hawk falls into the category of
2024-07-27 11:45:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 11:47:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2581, -0.1880, -0.1482,  ...,  0.5503, -0.0667, -0.1421],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6582, -2.9492,  2.3086,  ..., -1.0771, -5.9180,  0.4453],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0418,  0.0085, -0.0103,  ..., -0.0075, -0.0111, -0.0019],
        [ 0.0111,  0.0264,  0.0146,  ...,  0.0071,  0.0162, -0.0027],
        [ 0.0008,  0.0012,  0.0444,  ..., -0.0038, -0.0105, -0.0083],
        ...,
        [ 0.0086, -0.0011,  0.0142,  ...,  0.0302,  0.0026,  0.0058],
        [ 0.0016,  0.0023, -0.0048,  ...,  0.0019,  0.0289, -0.0026],
        [ 0.0041, -0.0166,  0.0009,  ..., -0.0124, -0.0155,  0.0316]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7812, -3.1348,  1.9170,  ..., -0.9673, -5.8672,  0.6646]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 11:47:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The tiger falls into the category of feline
The goat falls into the category of bovid
The wolf falls into the category of canine
The triceratops falls into the category of dinosaur
The beetle falls into the category of insect
The cat falls into the category of feline
The gibbon falls into the category of primate
The hawk falls into the category of
2024-07-27 11:47:23 root INFO     [order_1_approx] starting weight calculation for The goat falls into the category of bovid
The hawk falls into the category of raptor
The wolf falls into the category of canine
The tiger falls into the category of feline
The triceratops falls into the category of dinosaur
The beetle falls into the category of insect
The gibbon falls into the category of primate
The cat falls into the category of
2024-07-27 11:47:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 11:49:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2068, -0.2507,  0.3242,  ...,  0.0903,  0.0900,  0.2681],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3281, -4.8008,  1.4170,  ..., -4.0703, -6.7422, -1.3301],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0196,  0.0025, -0.0024,  ..., -0.0025,  0.0066, -0.0020],
        [ 0.0162, -0.0034,  0.0024,  ..., -0.0075,  0.0194, -0.0066],
        [-0.0097, -0.0015,  0.0185,  ...,  0.0007, -0.0009, -0.0023],
        ...,
        [-0.0004, -0.0037,  0.0042,  ...,  0.0190,  0.0113, -0.0042],
        [ 0.0025, -0.0069, -0.0106,  ...,  0.0008,  0.0141, -0.0040],
        [ 0.0114, -0.0120, -0.0080,  ...,  0.0116,  0.0152,  0.0151]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3550, -4.7344,  1.3770,  ..., -4.0547, -6.7031, -1.2979]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 11:49:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The goat falls into the category of bovid
The hawk falls into the category of raptor
The wolf falls into the category of canine
The tiger falls into the category of feline
The triceratops falls into the category of dinosaur
The beetle falls into the category of insect
The gibbon falls into the category of primate
The cat falls into the category of
2024-07-27 11:49:44 root INFO     [order_1_approx] starting weight calculation for The tiger falls into the category of feline
The hawk falls into the category of raptor
The cat falls into the category of feline
The wolf falls into the category of canine
The goat falls into the category of bovid
The triceratops falls into the category of dinosaur
The beetle falls into the category of insect
The gibbon falls into the category of
2024-07-27 11:49:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 11:52:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3782, -0.5195,  0.4756,  ...,  0.4568, -0.8794,  0.6938],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0870, -2.5859,  1.0508,  ..., -3.0742, -6.7109,  0.7427],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0460,  0.0006, -0.0252,  ..., -0.0099, -0.0092, -0.0034],
        [-0.0050,  0.0206, -0.0067,  ..., -0.0012,  0.0274, -0.0034],
        [-0.0077,  0.0063,  0.0386,  ..., -0.0005, -0.0056, -0.0197],
        ...,
        [ 0.0192,  0.0323,  0.0004,  ...,  0.0411,  0.0106,  0.0054],
        [-0.0020, -0.0172,  0.0170,  ...,  0.0049,  0.0347, -0.0129],
        [-0.0108, -0.0042, -0.0187,  ..., -0.0024,  0.0008,  0.0467]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2072, -2.6465,  0.6475,  ..., -2.6699, -7.2070,  0.6152]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 11:52:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The tiger falls into the category of feline
The hawk falls into the category of raptor
The cat falls into the category of feline
The wolf falls into the category of canine
The goat falls into the category of bovid
The triceratops falls into the category of dinosaur
The beetle falls into the category of insect
The gibbon falls into the category of
2024-07-27 11:52:01 root INFO     [order_1_approx] starting weight calculation for The goat falls into the category of bovid
The gibbon falls into the category of primate
The cat falls into the category of feline
The triceratops falls into the category of dinosaur
The beetle falls into the category of insect
The wolf falls into the category of canine
The hawk falls into the category of raptor
The tiger falls into the category of
2024-07-27 11:52:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 11:54:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1151, -0.1071,  0.1180,  ...,  0.4155, -0.1786, -0.0529],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-3.4180e-03, -6.2305e+00, -5.9570e-01,  ..., -2.8652e+00,
        -8.1094e+00, -1.3359e+00], device='cuda:1', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0387, -0.0074, -0.0233,  ...,  0.0027, -0.0129, -0.0176],
        [ 0.0091,  0.0158,  0.0076,  ..., -0.0122,  0.0222, -0.0070],
        [-0.0084,  0.0128,  0.0758,  ..., -0.0010, -0.0218, -0.0055],
        ...,
        [ 0.0050,  0.0026,  0.0133,  ...,  0.0417,  0.0222, -0.0025],
        [-0.0030, -0.0170, -0.0025,  ...,  0.0055,  0.0343, -0.0049],
        [-0.0028,  0.0064, -0.0157,  ..., -0.0086, -0.0123,  0.0356]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0279, -6.1719, -0.6387,  ..., -2.5859, -8.4531, -1.0469]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 11:54:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The goat falls into the category of bovid
The gibbon falls into the category of primate
The cat falls into the category of feline
The triceratops falls into the category of dinosaur
The beetle falls into the category of insect
The wolf falls into the category of canine
The hawk falls into the category of raptor
The tiger falls into the category of
2024-07-27 11:54:22 root INFO     [order_1_approx] starting weight calculation for The goat falls into the category of bovid
The gibbon falls into the category of primate
The beetle falls into the category of insect
The hawk falls into the category of raptor
The tiger falls into the category of feline
The wolf falls into the category of canine
The cat falls into the category of feline
The triceratops falls into the category of
2024-07-27 11:54:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 11:56:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3403, -0.1182, -0.3599,  ...,  0.2717, -0.6997,  0.5840],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3320, -3.8945,  1.1543,  ..., -0.6582, -5.4609, -1.8135],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0372, -0.0007, -0.0179,  ...,  0.0129, -0.0219, -0.0055],
        [-0.0003,  0.0345,  0.0009,  ...,  0.0091,  0.0082, -0.0253],
        [ 0.0111,  0.0064,  0.0356,  ..., -0.0143, -0.0113,  0.0181],
        ...,
        [ 0.0038, -0.0090,  0.0133,  ...,  0.0572,  0.0028,  0.0031],
        [-0.0151,  0.0019,  0.0160,  ...,  0.0095,  0.0529, -0.0025],
        [ 0.0085, -0.0113, -0.0054,  ..., -0.0039, -0.0199,  0.0348]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0664, -3.8184,  0.6328,  ..., -0.3787, -5.7148, -1.6074]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 11:56:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The goat falls into the category of bovid
The gibbon falls into the category of primate
The beetle falls into the category of insect
The hawk falls into the category of raptor
The tiger falls into the category of feline
The wolf falls into the category of canine
The cat falls into the category of feline
The triceratops falls into the category of
2024-07-27 11:56:42 root INFO     total operator prediction time: 1123.9155201911926 seconds
2024-07-27 11:56:43 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on synonyms - intensity
2024-07-27 11:56:43 root INFO     building operator synonyms - intensity
2024-07-27 11:56:43 root INFO     [order_1_approx] starting weight calculation for A more intense word for unhappy is miserable
A more intense word for giggle is laugh
A more intense word for love is adore
A more intense word for dinner is feast
A more intense word for damp is drenched
A more intense word for bad is awful
A more intense word for lake is sea
A more intense word for jog is
2024-07-27 11:56:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 11:59:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0768,  0.1326, -0.0095,  ..., -0.1786, -0.4614, -0.3247],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2607, -4.7422,  1.6094,  ...,  4.0039, -4.7109, -2.3477],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1045,  0.0269,  0.0506,  ..., -0.0231,  0.0003,  0.0091],
        [-0.0148,  0.0389,  0.0207,  ...,  0.0140, -0.0035, -0.0188],
        [-0.0250,  0.0037,  0.0761,  ...,  0.0037,  0.0039,  0.0135],
        ...,
        [ 0.0453, -0.0171,  0.0208,  ...,  0.0847, -0.0064, -0.0121],
        [-0.0064, -0.0243, -0.0110,  ...,  0.0127,  0.0329, -0.0186],
        [-0.0062, -0.0257,  0.0120,  ..., -0.0341,  0.0157,  0.0826]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3223, -4.8125,  1.9756,  ...,  3.6465, -5.2812, -2.6699]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 11:59:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for unhappy is miserable
A more intense word for giggle is laugh
A more intense word for love is adore
A more intense word for dinner is feast
A more intense word for damp is drenched
A more intense word for bad is awful
A more intense word for lake is sea
A more intense word for jog is
2024-07-27 11:59:04 root INFO     [order_1_approx] starting weight calculation for A more intense word for giggle is laugh
A more intense word for unhappy is miserable
A more intense word for damp is drenched
A more intense word for lake is sea
A more intense word for love is adore
A more intense word for jog is run
A more intense word for bad is awful
A more intense word for dinner is
2024-07-27 11:59:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 12:01:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4233, -0.0633, -0.2844,  ..., -0.2036, -0.4346, -0.2314],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.7188, -2.9258,  0.7422,  ..., -2.1523, -1.9199, -3.7461],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0543, -0.0065, -0.0265,  ...,  0.0049,  0.0044, -0.0006],
        [-0.0133,  0.0944, -0.0016,  ...,  0.0113, -0.0137, -0.0146],
        [ 0.0141, -0.0495,  0.0903,  ...,  0.0053, -0.0327, -0.0071],
        ...,
        [-0.0172, -0.0044,  0.0247,  ...,  0.0919, -0.0053, -0.0160],
        [ 0.0091, -0.0284,  0.0140,  ...,  0.0253,  0.0625,  0.0233],
        [-0.0261,  0.0205, -0.0102,  ..., -0.0091, -0.0155,  0.0580]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.8555, -2.7324,  1.2754,  ..., -1.9688, -3.1250, -3.2363]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 12:01:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for giggle is laugh
A more intense word for unhappy is miserable
A more intense word for damp is drenched
A more intense word for lake is sea
A more intense word for love is adore
A more intense word for jog is run
A more intense word for bad is awful
A more intense word for dinner is
2024-07-27 12:01:23 root INFO     [order_1_approx] starting weight calculation for A more intense word for love is adore
A more intense word for jog is run
A more intense word for giggle is laugh
A more intense word for damp is drenched
A more intense word for unhappy is miserable
A more intense word for bad is awful
A more intense word for dinner is feast
A more intense word for lake is
2024-07-27 12:01:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 12:03:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1646,  0.1003, -0.1277,  ..., -0.4478, -0.1515,  0.0250],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5742, -3.3008,  0.6499,  ..., -1.2627, -0.6167, -0.8457],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0851,  0.0051, -0.0132,  ...,  0.0016,  0.0008,  0.0053],
        [-0.0305,  0.0658, -0.0182,  ...,  0.0192,  0.0220, -0.0267],
        [-0.0081, -0.0042,  0.0844,  ..., -0.0200, -0.0271,  0.0175],
        ...,
        [-0.0196,  0.0400, -0.0101,  ...,  0.0567,  0.0355, -0.0329],
        [ 0.0133, -0.0166, -0.0061,  ...,  0.0107,  0.0673,  0.0077],
        [-0.0039,  0.0057, -0.0033,  ..., -0.0049,  0.0041,  0.0704]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0283, -2.9102,  0.6519,  ..., -0.6436, -0.9160, -1.2969]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 12:03:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for love is adore
A more intense word for jog is run
A more intense word for giggle is laugh
A more intense word for damp is drenched
A more intense word for unhappy is miserable
A more intense word for bad is awful
A more intense word for dinner is feast
A more intense word for lake is
2024-07-27 12:03:44 root INFO     [order_1_approx] starting weight calculation for A more intense word for damp is drenched
A more intense word for unhappy is miserable
A more intense word for dinner is feast
A more intense word for love is adore
A more intense word for giggle is laugh
A more intense word for jog is run
A more intense word for lake is sea
A more intense word for bad is
2024-07-27 12:03:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 12:06:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2272,  0.1267, -0.0853,  ...,  0.0071,  0.1197, -0.1161],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.4766, -2.0703,  0.1831,  ...,  0.7383, -4.8438, -1.8125],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0629,  0.0135,  0.0219,  ..., -0.0147, -0.0216,  0.0428],
        [ 0.0038,  0.0614,  0.0288,  ...,  0.0016,  0.0299, -0.0503],
        [ 0.0114,  0.0010,  0.0575,  ...,  0.0066,  0.0148, -0.0100],
        ...,
        [ 0.0197,  0.0138,  0.0013,  ...,  0.0511, -0.0173, -0.0167],
        [-0.0132, -0.0267,  0.0060,  ...,  0.0306,  0.0576, -0.0241],
        [ 0.0228, -0.0286, -0.0029,  ..., -0.0125, -0.0196,  0.0447]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7969e+00, -1.8672e+00, -3.0518e-03,  ...,  6.1816e-01,
         -4.8008e+00, -2.0059e+00]], device='cuda:1', dtype=torch.float16,
       grad_fn=<SubBackward0>) 

                    
2024-07-27 12:06:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for damp is drenched
A more intense word for unhappy is miserable
A more intense word for dinner is feast
A more intense word for love is adore
A more intense word for giggle is laugh
A more intense word for jog is run
A more intense word for lake is sea
A more intense word for bad is
2024-07-27 12:06:05 root INFO     [order_1_approx] starting weight calculation for A more intense word for dinner is feast
A more intense word for lake is sea
A more intense word for unhappy is miserable
A more intense word for damp is drenched
A more intense word for bad is awful
A more intense word for love is adore
A more intense word for jog is run
A more intense word for giggle is
2024-07-27 12:06:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 12:08:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0692, -0.1927, -0.4570,  ..., -0.0596, -0.4202,  0.0663],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6846, -1.5029,  5.0000,  ...,  4.5156, -1.4238, -1.2090],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0779,  0.0141,  0.0067,  ..., -0.0063,  0.0002,  0.0221],
        [ 0.0024,  0.0569, -0.0059,  ...,  0.0069,  0.0353,  0.0150],
        [ 0.0198, -0.0103,  0.0583,  ..., -0.0114, -0.0044, -0.0096],
        ...,
        [ 0.0039, -0.0153,  0.0026,  ...,  0.0475, -0.0148, -0.0121],
        [-0.0146, -0.0069, -0.0080,  ...,  0.0007,  0.0358,  0.0185],
        [-0.0070, -0.0072, -0.0011,  ..., -0.0179,  0.0126,  0.0498]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8579, -2.1699,  5.2500,  ...,  4.3203, -1.6191, -1.2051]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 12:08:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for dinner is feast
A more intense word for lake is sea
A more intense word for unhappy is miserable
A more intense word for damp is drenched
A more intense word for bad is awful
A more intense word for love is adore
A more intense word for jog is run
A more intense word for giggle is
2024-07-27 12:08:26 root INFO     [order_1_approx] starting weight calculation for A more intense word for jog is run
A more intense word for damp is drenched
A more intense word for giggle is laugh
A more intense word for dinner is feast
A more intense word for lake is sea
A more intense word for love is adore
A more intense word for bad is awful
A more intense word for unhappy is
2024-07-27 12:08:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 12:10:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4314, -0.1621, -0.3672,  ..., -0.3433, -0.2064,  0.1268],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0586, -3.4570,  1.6895,  ..., -2.2246, -1.9004, -3.0098],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.0547e-02,  8.7204e-03,  5.0163e-04,  ..., -1.1627e-02,
          8.3618e-03,  2.9037e-02],
        [-2.2316e-03,  4.2969e-02, -1.3336e-02,  ...,  4.9973e-04,
          1.3275e-03, -2.3315e-02],
        [-3.3035e-03, -2.2888e-05,  6.0944e-02,  ...,  1.0605e-03,
         -1.8219e-02, -7.9117e-03],
        ...,
        [ 9.5825e-03, -6.6414e-03,  1.1902e-03,  ...,  2.6840e-02,
         -8.8196e-03, -9.6817e-03],
        [-1.4076e-03, -2.8477e-03, -1.7151e-02,  ..., -2.8152e-03,
          5.2704e-02, -8.2779e-03],
        [ 1.4200e-03, -3.4027e-02, -4.4289e-03,  ...,  3.7193e-04,
          8.2016e-04,  4.5074e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0742, -3.4336,  1.5752,  ..., -1.9707, -1.7959, -3.3730]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 12:10:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for jog is run
A more intense word for damp is drenched
A more intense word for giggle is laugh
A more intense word for dinner is feast
A more intense word for lake is sea
A more intense word for love is adore
A more intense word for bad is awful
A more intense word for unhappy is
2024-07-27 12:10:48 root INFO     [order_1_approx] starting weight calculation for A more intense word for love is adore
A more intense word for bad is awful
A more intense word for lake is sea
A more intense word for giggle is laugh
A more intense word for dinner is feast
A more intense word for jog is run
A more intense word for unhappy is miserable
A more intense word for damp is
2024-07-27 12:10:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 12:13:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3113, -0.1997, -0.5635,  ..., -0.1824, -0.3931,  0.2002],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.7852, -4.1953, -0.7026,  ..., -1.0195, -0.4453, -3.9961],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0782,  0.0055,  0.0065,  ...,  0.0047,  0.0121, -0.0041],
        [ 0.0115,  0.0742,  0.0028,  ...,  0.0266, -0.0392, -0.0192],
        [-0.0229, -0.0077,  0.0801,  ..., -0.0225,  0.0042,  0.0056],
        ...,
        [ 0.0241,  0.0121,  0.0042,  ...,  0.0763, -0.0029, -0.0093],
        [-0.0051,  0.0107, -0.0183,  ..., -0.0028,  0.0883, -0.0143],
        [-0.0165, -0.0007, -0.0034,  ..., -0.0076,  0.0097,  0.0621]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.1289, -4.4844, -0.8843,  ..., -1.2275, -0.9033, -3.9219]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 12:13:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for love is adore
A more intense word for bad is awful
A more intense word for lake is sea
A more intense word for giggle is laugh
A more intense word for dinner is feast
A more intense word for jog is run
A more intense word for unhappy is miserable
A more intense word for damp is
2024-07-27 12:13:06 root INFO     [order_1_approx] starting weight calculation for A more intense word for bad is awful
A more intense word for giggle is laugh
A more intense word for jog is run
A more intense word for lake is sea
A more intense word for dinner is feast
A more intense word for unhappy is miserable
A more intense word for damp is drenched
A more intense word for love is
2024-07-27 12:13:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 12:15:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3542, -0.0188, -0.1936,  ..., -0.2012,  0.0857,  0.0757],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.3359, -4.3594, -2.0566,  ...,  0.4922, -4.8203,  0.0850],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0662,  0.0107,  0.0235,  ...,  0.0035, -0.0058,  0.0227],
        [ 0.0007,  0.0484,  0.0222,  ...,  0.0092, -0.0060, -0.0026],
        [-0.0086, -0.0108,  0.0325,  ..., -0.0033, -0.0117, -0.0239],
        ...,
        [-0.0058,  0.0235,  0.0045,  ...,  0.0543,  0.0063, -0.0101],
        [-0.0037, -0.0160,  0.0072,  ...,  0.0168,  0.0318,  0.0057],
        [ 0.0100, -0.0083, -0.0126,  ...,  0.0027, -0.0034,  0.0398]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.1289, -4.3125, -1.9561,  ...,  0.3320, -4.7461, -0.1545]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 12:15:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for bad is awful
A more intense word for giggle is laugh
A more intense word for jog is run
A more intense word for lake is sea
A more intense word for dinner is feast
A more intense word for unhappy is miserable
A more intense word for damp is drenched
A more intense word for love is
2024-07-27 12:15:19 root INFO     total operator prediction time: 1116.1801538467407 seconds
2024-07-27 12:15:19 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - substance
2024-07-27 12:15:19 root INFO     building operator meronyms - substance
2024-07-27 12:15:19 root INFO     [order_1_approx] starting weight calculation for A lawn is made up of grass
A sea is made up of water
A beard is made up of hair
A yogurt is made up of milk
A lens is made up of glass
A chocolate is made up of cocoa
A money is made up of paper
A diamond is made up of
2024-07-27 12:15:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 12:17:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0612,  0.2568, -0.5747,  ..., -0.0287,  0.0646,  0.0837],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7910, -3.5176, -0.5840,  ..., -5.2812,  1.6562, -0.2412],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0390,  0.0008, -0.0073,  ...,  0.0115,  0.0074, -0.0139],
        [-0.0020,  0.0303,  0.0128,  ...,  0.0149,  0.0002, -0.0006],
        [-0.0013,  0.0108,  0.0214,  ...,  0.0072,  0.0054, -0.0064],
        ...,
        [ 0.0135, -0.0027,  0.0101,  ...,  0.0197,  0.0019, -0.0069],
        [-0.0134, -0.0017, -0.0166,  ...,  0.0206,  0.0205,  0.0172],
        [ 0.0119,  0.0012, -0.0034,  ..., -0.0006, -0.0063,  0.0036]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9805, -3.3770, -0.7529,  ..., -5.2500,  1.3857,  0.0793]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 12:17:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A lawn is made up of grass
A sea is made up of water
A beard is made up of hair
A yogurt is made up of milk
A lens is made up of glass
A chocolate is made up of cocoa
A money is made up of paper
A diamond is made up of
2024-07-27 12:17:41 root INFO     [order_1_approx] starting weight calculation for A diamond is made up of carbon
A beard is made up of hair
A chocolate is made up of cocoa
A money is made up of paper
A lawn is made up of grass
A sea is made up of water
A yogurt is made up of milk
A lens is made up of
2024-07-27 12:17:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 12:20:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1990, -0.2612, -0.5098,  ...,  0.3950,  0.1079, -0.3960],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4375, -3.0918, -0.6621,  ..., -0.9619,  2.8730, -0.5825],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0577,  0.0023, -0.0055,  ...,  0.0179, -0.0305, -0.0228],
        [-0.0248,  0.0527, -0.0183,  ...,  0.0428, -0.0266,  0.0026],
        [ 0.0261,  0.0222,  0.0553,  ...,  0.0038,  0.0033, -0.0255],
        ...,
        [ 0.0121, -0.0060,  0.0012,  ...,  0.0476, -0.0130,  0.0233],
        [-0.0257,  0.0256, -0.0250,  ...,  0.0086,  0.0205, -0.0029],
        [ 0.0184, -0.0254,  0.0071,  ..., -0.0072,  0.0011,  0.0360]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4375, -3.3008, -0.5615,  ..., -1.4385,  2.1680, -0.7764]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 12:20:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A diamond is made up of carbon
A beard is made up of hair
A chocolate is made up of cocoa
A money is made up of paper
A lawn is made up of grass
A sea is made up of water
A yogurt is made up of milk
A lens is made up of
2024-07-27 12:20:03 root INFO     [order_1_approx] starting weight calculation for A lens is made up of glass
A money is made up of paper
A sea is made up of water
A chocolate is made up of cocoa
A lawn is made up of grass
A diamond is made up of carbon
A beard is made up of hair
A yogurt is made up of
2024-07-27 12:20:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 12:22:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2891, -0.1760, -0.1294,  ...,  0.2539, -0.2252, -0.3413],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8008, -3.7246,  2.2910,  ..., -3.3281, -0.6699, -0.3486],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0167, -0.0132, -0.0037,  ...,  0.0083, -0.0095, -0.0012],
        [-0.0055,  0.0412,  0.0097,  ...,  0.0049,  0.0145,  0.0028],
        [ 0.0075,  0.0140,  0.0005,  ...,  0.0068,  0.0019,  0.0030],
        ...,
        [ 0.0106,  0.0190,  0.0114,  ...,  0.0422,  0.0014, -0.0101],
        [-0.0105,  0.0229,  0.0017,  ...,  0.0367,  0.0470,  0.0197],
        [-0.0087,  0.0091,  0.0112,  ..., -0.0151,  0.0238,  0.0537]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7324, -4.1836,  2.3457,  ..., -3.2051, -0.9990, -0.1917]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 12:22:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A lens is made up of glass
A money is made up of paper
A sea is made up of water
A chocolate is made up of cocoa
A lawn is made up of grass
A diamond is made up of carbon
A beard is made up of hair
A yogurt is made up of
2024-07-27 12:22:25 root INFO     [order_1_approx] starting weight calculation for A lens is made up of glass
A beard is made up of hair
A diamond is made up of carbon
A sea is made up of water
A money is made up of paper
A yogurt is made up of milk
A chocolate is made up of cocoa
A lawn is made up of
2024-07-27 12:22:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 12:24:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2568,  0.2661, -0.4780,  ...,  0.1836, -0.0168, -0.2974],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.2539, -6.0039, -1.9922,  ..., -1.7168,  2.5137, -1.1855],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0455, -0.0030,  0.0033,  ...,  0.0110, -0.0323, -0.0007],
        [ 0.0086,  0.0183,  0.0189,  ..., -0.0083,  0.0057, -0.0090],
        [-0.0082, -0.0023,  0.0486,  ..., -0.0293, -0.0104,  0.0023],
        ...,
        [ 0.0182, -0.0019,  0.0167,  ...,  0.0584, -0.0092,  0.0014],
        [-0.0237,  0.0244, -0.0192,  ...,  0.0002,  0.0302,  0.0333],
        [-0.0039, -0.0184,  0.0062,  ..., -0.0043, -0.0027,  0.0297]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 6.1406, -5.8125, -2.3555,  ..., -1.3799,  1.9346, -1.2393]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 12:24:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A lens is made up of glass
A beard is made up of hair
A diamond is made up of carbon
A sea is made up of water
A money is made up of paper
A yogurt is made up of milk
A chocolate is made up of cocoa
A lawn is made up of
2024-07-27 12:24:47 root INFO     [order_1_approx] starting weight calculation for A beard is made up of hair
A lens is made up of glass
A sea is made up of water
A diamond is made up of carbon
A yogurt is made up of milk
A lawn is made up of grass
A money is made up of paper
A chocolate is made up of
2024-07-27 12:24:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 12:27:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0348, -0.1217, -0.5889,  ...,  0.1329,  0.0033, -0.3496],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8770, -3.2129, -0.5439,  ..., -2.4297, -4.0039,  5.8281],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.2238e-02, -7.4310e-03,  1.1187e-03,  ...,  3.9749e-03,
         -6.1111e-03,  5.4855e-03],
        [-1.3323e-03,  1.3390e-02,  8.4076e-03,  ...,  3.3588e-03,
          8.7280e-03, -1.5678e-03],
        [ 6.2275e-04,  9.1648e-04,  1.1902e-02,  ...,  3.6740e-04,
         -3.1891e-03,  9.6321e-05],
        ...,
        [ 2.6512e-03,  5.5275e-03,  8.2397e-03,  ...,  2.3270e-02,
         -6.7215e-03, -3.3531e-03],
        [ 4.7607e-03,  8.9188e-03, -1.1391e-02,  ...,  1.6357e-02,
          1.3855e-02,  1.0551e-02],
        [-1.6727e-03, -1.0223e-02, -3.1357e-03,  ..., -1.2604e-02,
          9.7122e-03,  2.0584e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7676, -3.2461, -0.5444,  ..., -2.4453, -4.0664,  6.0273]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 12:27:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A beard is made up of hair
A lens is made up of glass
A sea is made up of water
A diamond is made up of carbon
A yogurt is made up of milk
A lawn is made up of grass
A money is made up of paper
A chocolate is made up of
2024-07-27 12:27:07 root INFO     [order_1_approx] starting weight calculation for A yogurt is made up of milk
A lens is made up of glass
A sea is made up of water
A chocolate is made up of cocoa
A beard is made up of hair
A diamond is made up of carbon
A lawn is made up of grass
A money is made up of
2024-07-27 12:27:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 12:29:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0507, -0.2361, -0.5649,  ..., -0.0622,  0.0499, -0.0082],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7007, -3.8086, -2.1777,  ..., -3.4805,  0.6841,  1.2734],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0500, -0.0312, -0.0208,  ..., -0.0255, -0.0043,  0.0087],
        [-0.0248,  0.0336,  0.0244,  ...,  0.0127,  0.0074, -0.0107],
        [ 0.0050,  0.0254,  0.0248,  ...,  0.0035, -0.0107, -0.0038],
        ...,
        [-0.0023,  0.0213,  0.0050,  ...,  0.0500,  0.0002, -0.0088],
        [-0.0054, -0.0074, -0.0030,  ...,  0.0158,  0.0191,  0.0015],
        [ 0.0091, -0.0097,  0.0066,  ...,  0.0052,  0.0136,  0.0281]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7993, -4.1211, -2.3164,  ..., -3.4824,  0.5273,  1.1875]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 12:29:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A yogurt is made up of milk
A lens is made up of glass
A sea is made up of water
A chocolate is made up of cocoa
A beard is made up of hair
A diamond is made up of carbon
A lawn is made up of grass
A money is made up of
2024-07-27 12:29:29 root INFO     [order_1_approx] starting weight calculation for A chocolate is made up of cocoa
A yogurt is made up of milk
A lawn is made up of grass
A diamond is made up of carbon
A money is made up of paper
A beard is made up of hair
A lens is made up of glass
A sea is made up of
2024-07-27 12:29:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 12:31:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0212,  0.0703, -0.1672,  ..., -0.2244,  0.0316,  0.0646],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4551, -2.5410,  0.7017,  ..., -3.6602,  3.0273, -1.4141],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0322, -0.0025,  0.0156,  ..., -0.0045, -0.0098, -0.0018],
        [-0.0071,  0.0476,  0.0033,  ..., -0.0222,  0.0062,  0.0074],
        [ 0.0012,  0.0081,  0.0610,  ..., -0.0151, -0.0275,  0.0128],
        ...,
        [ 0.0028,  0.0344,  0.0269,  ...,  0.0581,  0.0082, -0.0103],
        [-0.0102, -0.0020, -0.0189,  ...,  0.0256,  0.0421,  0.0145],
        [ 0.0001, -0.0012,  0.0092,  ..., -0.0107,  0.0107,  0.0359]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3555, -2.5293,  0.5957,  ..., -3.5684,  2.7617, -1.2988]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 12:31:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A chocolate is made up of cocoa
A yogurt is made up of milk
A lawn is made up of grass
A diamond is made up of carbon
A money is made up of paper
A beard is made up of hair
A lens is made up of glass
A sea is made up of
2024-07-27 12:31:51 root INFO     [order_1_approx] starting weight calculation for A chocolate is made up of cocoa
A lens is made up of glass
A sea is made up of water
A money is made up of paper
A lawn is made up of grass
A yogurt is made up of milk
A diamond is made up of carbon
A beard is made up of
2024-07-27 12:31:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 12:34:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2019,  0.0781, -0.2661,  ..., -0.0032, -0.0974,  0.0176],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5117, -5.5664, -2.2090,  ..., -2.3320,  1.0996, -1.5107],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0420, -0.0032, -0.0091,  ...,  0.0203, -0.0057,  0.0083],
        [-0.0043,  0.0325,  0.0148,  ..., -0.0205, -0.0042, -0.0022],
        [-0.0072, -0.0076,  0.0387,  ..., -0.0009, -0.0228, -0.0228],
        ...,
        [ 0.0100,  0.0138,  0.0263,  ...,  0.0574,  0.0106, -0.0156],
        [-0.0187,  0.0144, -0.0352,  ...,  0.0141,  0.0280, -0.0007],
        [ 0.0033, -0.0010,  0.0068,  ..., -0.0247,  0.0037,  0.0253]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6328, -5.3242, -2.0781,  ..., -2.0000,  0.7393, -1.4141]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 12:34:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A chocolate is made up of cocoa
A lens is made up of glass
A sea is made up of water
A money is made up of paper
A lawn is made up of grass
A yogurt is made up of milk
A diamond is made up of carbon
A beard is made up of
2024-07-27 12:34:12 root INFO     total operator prediction time: 1133.7287485599518 seconds
2024-07-27 12:34:12 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hypernyms - misc
2024-07-27 12:34:12 root INFO     building operator hypernyms - misc
2024-07-27 12:34:13 root INFO     [order_1_approx] starting weight calculation for The dress falls into the category of clothes
The tub falls into the category of container
The notepad falls into the category of pad
The postcard falls into the category of card
The notebook falls into the category of book
The toothbrush falls into the category of brush
The computer falls into the category of device
The toaster falls into the category of
2024-07-27 12:34:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 12:36:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4214,  0.3071, -0.2803,  ...,  0.0416, -0.2056,  0.0288],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9668, -2.6816,  0.8564,  ...,  0.6455, -5.9609,  1.8535],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1070, -0.0004, -0.0115,  ..., -0.0076, -0.0208,  0.0032],
        [ 0.0295,  0.1027,  0.0270,  ...,  0.0190, -0.0130, -0.0053],
        [ 0.0066, -0.0043,  0.0454,  ..., -0.0180, -0.0320, -0.0031],
        ...,
        [ 0.0073,  0.0356,  0.0151,  ...,  0.0997, -0.0042,  0.0025],
        [-0.0168, -0.0060,  0.0053,  ...,  0.0051,  0.0805, -0.0177],
        [-0.0025, -0.0031, -0.0022,  ..., -0.0084, -0.0173,  0.0739]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8066, -2.7012,  0.4377,  ...,  0.4233, -5.2695,  1.8662]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 12:36:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The dress falls into the category of clothes
The tub falls into the category of container
The notepad falls into the category of pad
The postcard falls into the category of card
The notebook falls into the category of book
The toothbrush falls into the category of brush
The computer falls into the category of device
The toaster falls into the category of
2024-07-27 12:36:32 root INFO     [order_1_approx] starting weight calculation for The tub falls into the category of container
The postcard falls into the category of card
The toaster falls into the category of appliance
The notepad falls into the category of pad
The toothbrush falls into the category of brush
The dress falls into the category of clothes
The notebook falls into the category of book
The computer falls into the category of
2024-07-27 12:36:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 12:38:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1132, -0.2656,  0.2180,  ...,  0.2502, -0.2145, -0.3384],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.1006, -4.1719, -0.1411,  ..., -1.8945, -1.4492, -2.8066],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0548, -0.0053,  0.0117,  ...,  0.0012, -0.0090,  0.0110],
        [ 0.0088,  0.0521, -0.0003,  ...,  0.0079,  0.0054,  0.0029],
        [-0.0074, -0.0008,  0.0552,  ..., -0.0152,  0.0011,  0.0208],
        ...,
        [-0.0010,  0.0161, -0.0044,  ...,  0.0435,  0.0068, -0.0019],
        [ 0.0061, -0.0150, -0.0008,  ...,  0.0191,  0.0376, -0.0054],
        [ 0.0108,  0.0045,  0.0004,  ..., -0.0070, -0.0048,  0.0433]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.9185, -4.2266, -0.1233,  ..., -1.7070, -1.3662, -2.3848]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 12:38:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The tub falls into the category of container
The postcard falls into the category of card
The toaster falls into the category of appliance
The notepad falls into the category of pad
The toothbrush falls into the category of brush
The dress falls into the category of clothes
The notebook falls into the category of book
The computer falls into the category of
2024-07-27 12:38:54 root INFO     [order_1_approx] starting weight calculation for The notebook falls into the category of book
The toaster falls into the category of appliance
The tub falls into the category of container
The computer falls into the category of device
The notepad falls into the category of pad
The dress falls into the category of clothes
The toothbrush falls into the category of brush
The postcard falls into the category of
2024-07-27 12:38:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 12:41:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1525,  0.0535, -0.2830,  ...,  0.1163, -0.3264, -0.2314],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7676, -3.5664,  0.4224,  ..., -1.4170, -4.8906,  0.3320],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 8.7158e-02,  7.5226e-03,  4.0627e-03,  ..., -3.2749e-03,
          1.2680e-02,  1.3573e-02],
        [ 1.6693e-02,  6.4209e-02, -3.9291e-03,  ...,  2.3804e-02,
         -2.8564e-02, -4.1733e-03],
        [ 0.0000e+00, -1.0223e-02,  6.4453e-02,  ...,  3.5496e-03,
         -3.6316e-02,  1.1528e-02],
        ...,
        [ 2.3849e-02,  3.8147e-05, -4.0512e-03,  ...,  6.5735e-02,
         -2.1172e-03, -2.0294e-02],
        [-7.0572e-03, -1.0292e-02,  1.5991e-02,  ...,  8.6441e-03,
          8.0688e-02, -8.3923e-03],
        [-3.7365e-03,  1.5656e-02, -1.3718e-02,  ..., -1.0452e-03,
         -1.2863e-02,  5.9265e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5532, -4.2500,  0.4570,  ..., -1.6162, -4.6406,  0.0701]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 12:41:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The notebook falls into the category of book
The toaster falls into the category of appliance
The tub falls into the category of container
The computer falls into the category of device
The notepad falls into the category of pad
The dress falls into the category of clothes
The toothbrush falls into the category of brush
The postcard falls into the category of
2024-07-27 12:41:15 root INFO     [order_1_approx] starting weight calculation for The postcard falls into the category of card
The toaster falls into the category of appliance
The tub falls into the category of container
The notebook falls into the category of book
The notepad falls into the category of pad
The dress falls into the category of clothes
The computer falls into the category of device
The toothbrush falls into the category of
2024-07-27 12:41:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 12:43:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2920,  0.0975, -0.0717,  ...,  0.2443, -0.3237, -0.1865],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1973, -2.5449, -1.0039,  ..., -2.6270, -4.9609, -0.1582],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0634, -0.0146,  0.0058,  ...,  0.0135, -0.0154,  0.0108],
        [ 0.0226,  0.0406, -0.0081,  ..., -0.0008, -0.0070,  0.0131],
        [-0.0114,  0.0125,  0.0305,  ...,  0.0012, -0.0068, -0.0019],
        ...,
        [ 0.0036, -0.0097,  0.0057,  ...,  0.0273,  0.0248, -0.0049],
        [ 0.0038, -0.0057,  0.0055,  ..., -0.0046,  0.0327, -0.0101],
        [ 0.0041,  0.0059, -0.0014,  ..., -0.0080, -0.0110,  0.0308]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0820, -2.9375, -1.0107,  ..., -2.2402, -4.9414, -0.3306]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 12:43:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The postcard falls into the category of card
The toaster falls into the category of appliance
The tub falls into the category of container
The notebook falls into the category of book
The notepad falls into the category of pad
The dress falls into the category of clothes
The computer falls into the category of device
The toothbrush falls into the category of
2024-07-27 12:43:36 root INFO     [order_1_approx] starting weight calculation for The toaster falls into the category of appliance
The toothbrush falls into the category of brush
The dress falls into the category of clothes
The notebook falls into the category of book
The postcard falls into the category of card
The notepad falls into the category of pad
The computer falls into the category of device
The tub falls into the category of
2024-07-27 12:43:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 12:45:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3281, -0.4116,  0.2739,  ..., -0.2006,  0.0400,  0.3660],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6963, -2.0938,  2.3809,  ..., -0.5703, -2.6016, -0.1025],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0845, -0.0064, -0.0282,  ...,  0.0164, -0.0078, -0.0124],
        [-0.0035,  0.0609,  0.0288,  ..., -0.0059, -0.0088, -0.0053],
        [-0.0056,  0.0073,  0.0302,  ..., -0.0082, -0.0249,  0.0344],
        ...,
        [ 0.0182,  0.0142,  0.0051,  ...,  0.0357,  0.0031, -0.0051],
        [ 0.0031,  0.0002,  0.0030,  ...,  0.0069,  0.0542, -0.0161],
        [-0.0055, -0.0003, -0.0132,  ..., -0.0171,  0.0010,  0.0420]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1123, -2.0918,  2.1074,  ..., -0.6450, -2.8555, -0.4900]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 12:45:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The toaster falls into the category of appliance
The toothbrush falls into the category of brush
The dress falls into the category of clothes
The notebook falls into the category of book
The postcard falls into the category of card
The notepad falls into the category of pad
The computer falls into the category of device
The tub falls into the category of
2024-07-27 12:45:51 root INFO     [order_1_approx] starting weight calculation for The toaster falls into the category of appliance
The tub falls into the category of container
The toothbrush falls into the category of brush
The notepad falls into the category of pad
The dress falls into the category of clothes
The postcard falls into the category of card
The computer falls into the category of device
The notebook falls into the category of
2024-07-27 12:45:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 12:48:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3887,  0.0858, -0.3213,  ...,  0.0692, -0.2296,  0.0474],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.2080, -4.4297,  2.6562,  ..., -1.0889, -3.4121, -2.2520],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0587,  0.0005,  0.0160,  ...,  0.0045,  0.0096, -0.0063],
        [ 0.0131,  0.0611,  0.0199,  ...,  0.0142,  0.0026,  0.0040],
        [-0.0113, -0.0162,  0.0524,  ..., -0.0058, -0.0359,  0.0174],
        ...,
        [ 0.0018, -0.0005, -0.0152,  ...,  0.0767,  0.0015,  0.0112],
        [ 0.0014, -0.0048,  0.0039,  ...,  0.0008,  0.0332, -0.0188],
        [-0.0079,  0.0138,  0.0128,  ..., -0.0167,  0.0040,  0.0496]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.0068, -4.1836,  2.2969,  ..., -0.7524, -3.4180, -2.0020]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 12:48:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The toaster falls into the category of appliance
The tub falls into the category of container
The toothbrush falls into the category of brush
The notepad falls into the category of pad
The dress falls into the category of clothes
The postcard falls into the category of card
The computer falls into the category of device
The notebook falls into the category of
2024-07-27 12:48:07 root INFO     [order_1_approx] starting weight calculation for The notebook falls into the category of book
The computer falls into the category of device
The notepad falls into the category of pad
The postcard falls into the category of card
The toothbrush falls into the category of brush
The toaster falls into the category of appliance
The tub falls into the category of container
The dress falls into the category of
2024-07-27 12:48:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 12:50:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2113, -0.2996, -0.1855,  ...,  0.2411, -0.2427, -0.2671],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5977, -5.4531, -0.6997,  ...,  0.5039, -3.9277, -1.7070],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.2694e-02,  1.2787e-02,  1.4687e-03,  ...,  9.6283e-03,
          8.5449e-03,  9.6130e-04],
        [ 1.0315e-02,  3.4729e-02, -5.3406e-05,  ...,  1.8368e-03,
         -1.9379e-02, -1.6327e-02],
        [ 4.5967e-03,  1.3138e-02,  1.8707e-02,  ..., -8.2092e-03,
          3.1204e-03,  6.3820e-03],
        ...,
        [ 7.1621e-04, -2.6398e-03,  1.7822e-02,  ...,  2.8732e-02,
          1.7273e-02, -1.1368e-02],
        [ 1.0948e-03,  6.3362e-03, -1.0902e-02,  ...,  6.4468e-03,
          2.4216e-02, -1.0239e-02],
        [ 8.3008e-03,  1.0277e-02,  1.4381e-02,  ..., -1.4618e-02,
         -1.9547e-02,  2.5040e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4824, -5.2891, -0.7891,  ...,  0.8086, -4.0039, -1.9219]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 12:50:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The notebook falls into the category of book
The computer falls into the category of device
The notepad falls into the category of pad
The postcard falls into the category of card
The toothbrush falls into the category of brush
The toaster falls into the category of appliance
The tub falls into the category of container
The dress falls into the category of
2024-07-27 12:50:20 root INFO     [order_1_approx] starting weight calculation for The tub falls into the category of container
The computer falls into the category of device
The toothbrush falls into the category of brush
The toaster falls into the category of appliance
The notebook falls into the category of book
The postcard falls into the category of card
The dress falls into the category of clothes
The notepad falls into the category of
2024-07-27 12:50:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 12:52:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1304, -0.2158, -0.4006,  ...,  0.0792, -0.5488, -0.3909],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0859, -3.4805,  2.6406,  ..., -2.7422, -2.7422,  0.1416],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.1127e-02,  6.8893e-03, -3.8910e-04,  ..., -3.5667e-03,
         -2.4719e-03,  3.0327e-03],
        [ 1.1421e-02,  3.7628e-02,  6.0272e-03,  ...,  1.0750e-02,
          1.0490e-04,  6.7139e-03],
        [-5.8098e-03,  8.4839e-03,  3.4973e-02,  ...,  1.1925e-02,
         -2.3239e-02,  2.1301e-02],
        ...,
        [ 2.8839e-03,  1.8320e-03,  1.8112e-02,  ...,  4.3915e-02,
          8.4534e-03, -1.3206e-02],
        [ 7.4615e-03, -8.0948e-03,  1.0429e-02,  ..., -7.0572e-05,
          3.4088e-02, -6.9885e-03],
        [-1.1322e-02,  1.1187e-03,  5.0354e-03,  ..., -1.7975e-02,
         -2.7580e-03,  4.3396e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9170, -3.7832,  2.7910,  ..., -2.4082, -2.7695,  0.1818]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 12:52:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The tub falls into the category of container
The computer falls into the category of device
The toothbrush falls into the category of brush
The toaster falls into the category of appliance
The notebook falls into the category of book
The postcard falls into the category of card
The dress falls into the category of clothes
The notepad falls into the category of
2024-07-27 12:52:40 root INFO     total operator prediction time: 1107.3048486709595 seconds
2024-07-27 12:52:40 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on synonyms - exact
2024-07-27 12:52:40 root INFO     building operator synonyms - exact
2024-07-27 12:52:40 root INFO     [order_1_approx] starting weight calculation for Another word for organized is arranged
Another word for baby is infant
Another word for flower is blossom
Another word for hieroglyph is hieroglyphic
Another word for murder is slaying
Another word for phone is telephone
Another word for railway is railroad
Another word for reasonable is
2024-07-27 12:52:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 12:55:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1360, -0.0257, -0.2325,  ..., -0.5122, -0.0905,  0.1426],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7109,  1.5762, -1.2129,  ..., -3.9395, -8.9219, -1.3613],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1192,  0.0017,  0.0196,  ...,  0.0122, -0.0251,  0.0087],
        [-0.0222,  0.0491, -0.0082,  ..., -0.0171,  0.0396, -0.0032],
        [ 0.0333, -0.0058,  0.1030,  ..., -0.0047, -0.0044,  0.0016],
        ...,
        [ 0.0256,  0.0370,  0.0339,  ...,  0.1294,  0.0235, -0.0345],
        [ 0.0436,  0.0384, -0.0109,  ..., -0.0105,  0.0255,  0.0114],
        [ 0.0015, -0.0235,  0.0201,  ..., -0.0118, -0.0299,  0.0485]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8457,  1.3594, -1.0605,  ..., -3.7852, -8.6406, -1.6611]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 12:55:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for organized is arranged
Another word for baby is infant
Another word for flower is blossom
Another word for hieroglyph is hieroglyphic
Another word for murder is slaying
Another word for phone is telephone
Another word for railway is railroad
Another word for reasonable is
2024-07-27 12:55:01 root INFO     [order_1_approx] starting weight calculation for Another word for organized is arranged
Another word for murder is slaying
Another word for flower is blossom
Another word for hieroglyph is hieroglyphic
Another word for railway is railroad
Another word for baby is infant
Another word for reasonable is sensible
Another word for phone is
2024-07-27 12:55:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 12:57:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0281, -0.4712, -0.1433,  ...,  0.1759,  0.0227, -0.4863],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.2012, -4.0352,  1.9639,  ...,  0.3042, -0.9028, -4.9141],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1077, -0.0263,  0.0147,  ..., -0.0026, -0.0153,  0.0238],
        [-0.0038,  0.0798,  0.0037,  ...,  0.0081,  0.0421, -0.0160],
        [ 0.0013, -0.0181,  0.0969,  ..., -0.0110,  0.0009,  0.0241],
        ...,
        [ 0.0020,  0.0117, -0.0046,  ...,  0.0486, -0.0228,  0.0185],
        [ 0.0255, -0.0259,  0.0089,  ...,  0.0049,  0.0363,  0.0013],
        [ 0.0063,  0.0251, -0.0097,  ...,  0.0036, -0.0017,  0.0407]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8604, -3.6523,  1.8174,  ...,  0.5918, -1.5117, -4.6914]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 12:57:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for organized is arranged
Another word for murder is slaying
Another word for flower is blossom
Another word for hieroglyph is hieroglyphic
Another word for railway is railroad
Another word for baby is infant
Another word for reasonable is sensible
Another word for phone is
2024-07-27 12:57:24 root INFO     [order_1_approx] starting weight calculation for Another word for phone is telephone
Another word for reasonable is sensible
Another word for hieroglyph is hieroglyphic
Another word for baby is infant
Another word for organized is arranged
Another word for murder is slaying
Another word for flower is blossom
Another word for railway is
2024-07-27 12:57:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 12:59:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([0.1915, 0.0192, 0.3293,  ..., 0.0801, 0.2495, 0.0173], device='cuda:1',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3923, -4.7031,  3.2324,  ...,  2.3203, -1.2119, -2.6523],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0958,  0.0067,  0.0247,  ...,  0.0005,  0.0413,  0.0178],
        [ 0.0101,  0.0878,  0.0051,  ...,  0.0131,  0.0429, -0.0051],
        [-0.0106,  0.0030,  0.0699,  ..., -0.0183, -0.0259,  0.0228],
        ...,
        [ 0.0379,  0.0221,  0.0276,  ...,  0.0717,  0.0028, -0.0361],
        [-0.0410,  0.0363, -0.0043,  ...,  0.0069,  0.0895,  0.0104],
        [ 0.0246,  0.0188,  0.0317,  ..., -0.0204, -0.0090,  0.0666]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8057, -4.2852,  3.3184,  ...,  2.3340, -0.9409, -2.6816]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 12:59:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for phone is telephone
Another word for reasonable is sensible
Another word for hieroglyph is hieroglyphic
Another word for baby is infant
Another word for organized is arranged
Another word for murder is slaying
Another word for flower is blossom
Another word for railway is
2024-07-27 12:59:46 root INFO     [order_1_approx] starting weight calculation for Another word for murder is slaying
Another word for reasonable is sensible
Another word for organized is arranged
Another word for baby is infant
Another word for phone is telephone
Another word for hieroglyph is hieroglyphic
Another word for railway is railroad
Another word for flower is
2024-07-27 12:59:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 13:02:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2256, -0.0997, -0.1599,  ..., -0.0151,  0.0912, -0.0138],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0098, -3.7617,  0.7588,  ...,  3.3906, -3.1641,  0.0977],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0747, -0.0176,  0.0205,  ..., -0.0111,  0.0005,  0.0032],
        [ 0.0102,  0.0651,  0.0300,  ...,  0.0285,  0.0029, -0.0130],
        [-0.0072,  0.0106,  0.0801,  ...,  0.0215, -0.0509, -0.0092],
        ...,
        [-0.0156,  0.0096, -0.0025,  ...,  0.0921, -0.0047,  0.0036],
        [-0.0050, -0.0092,  0.0100,  ...,  0.0047,  0.0440,  0.0037],
        [-0.0267, -0.0079, -0.0098,  ..., -0.0093, -0.0005,  0.0638]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8706, -3.3691,  0.7178,  ...,  3.5527, -3.4160,  0.6606]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 13:02:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for murder is slaying
Another word for reasonable is sensible
Another word for organized is arranged
Another word for baby is infant
Another word for phone is telephone
Another word for hieroglyph is hieroglyphic
Another word for railway is railroad
Another word for flower is
2024-07-27 13:02:04 root INFO     [order_1_approx] starting weight calculation for Another word for murder is slaying
Another word for baby is infant
Another word for railway is railroad
Another word for hieroglyph is hieroglyphic
Another word for flower is blossom
Another word for reasonable is sensible
Another word for phone is telephone
Another word for organized is
2024-07-27 13:02:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 13:04:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1304,  0.0807, -0.1820,  ..., -0.4397,  0.0172,  0.1602],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2905,  0.3428,  2.9668,  ...,  1.8555, -2.9688, -5.1055],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0673,  0.0352,  0.0318,  ...,  0.0068,  0.0264, -0.0067],
        [ 0.0382,  0.0536, -0.0130,  ..., -0.0200,  0.0321, -0.0251],
        [-0.0269,  0.0212,  0.0936,  ..., -0.0026,  0.0025,  0.0025],
        ...,
        [ 0.0455,  0.0112, -0.0422,  ...,  0.0876, -0.0090, -0.0317],
        [ 0.0058,  0.0231,  0.0047,  ...,  0.0282,  0.0888, -0.0698],
        [ 0.0143, -0.0007,  0.0105,  ..., -0.0152, -0.0190,  0.0632]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1787,  0.0623,  2.9062,  ...,  1.5127, -2.3867, -5.3945]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 13:04:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for murder is slaying
Another word for baby is infant
Another word for railway is railroad
Another word for hieroglyph is hieroglyphic
Another word for flower is blossom
Another word for reasonable is sensible
Another word for phone is telephone
Another word for organized is
2024-07-27 13:04:23 root INFO     [order_1_approx] starting weight calculation for Another word for reasonable is sensible
Another word for baby is infant
Another word for flower is blossom
Another word for murder is slaying
Another word for phone is telephone
Another word for railway is railroad
Another word for organized is arranged
Another word for hieroglyph is
2024-07-27 13:04:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 13:06:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1423,  0.4460, -0.0297,  ..., -0.2546, -0.5371,  0.3452],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.5078, -1.8047,  6.1562,  ...,  1.2578, -0.0811,  1.6396],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0703, -0.0170,  0.0189,  ..., -0.0055, -0.0087, -0.0072],
        [-0.0038,  0.0739,  0.0161,  ..., -0.0015, -0.0026,  0.0083],
        [-0.0120, -0.0122,  0.0405,  ...,  0.0082, -0.0007, -0.0192],
        ...,
        [ 0.0132,  0.0248,  0.0090,  ...,  0.0650,  0.0020,  0.0246],
        [-0.0320, -0.0150,  0.0155,  ..., -0.0027,  0.0345, -0.0087],
        [-0.0029,  0.0251, -0.0093,  ...,  0.0136, -0.0224,  0.0735]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.6504, -1.8994,  6.5000,  ...,  1.5195, -0.1703,  1.5449]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 13:06:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for reasonable is sensible
Another word for baby is infant
Another word for flower is blossom
Another word for murder is slaying
Another word for phone is telephone
Another word for railway is railroad
Another word for organized is arranged
Another word for hieroglyph is
2024-07-27 13:06:41 root INFO     [order_1_approx] starting weight calculation for Another word for murder is slaying
Another word for flower is blossom
Another word for hieroglyph is hieroglyphic
Another word for reasonable is sensible
Another word for organized is arranged
Another word for railway is railroad
Another word for phone is telephone
Another word for baby is
2024-07-27 13:06:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 13:09:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0133, -0.0970, -0.0416,  ..., -0.0047, -0.6807,  0.2773],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4395, -4.5078, -1.7520,  ..., -0.4580, -3.4062,  2.1836],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 9.3384e-02, -2.1057e-02,  2.4521e-02,  ...,  1.0902e-02,
         -2.9205e-02,  1.6556e-02],
        [ 5.9433e-03,  4.8615e-02, -7.5722e-03,  ...,  1.6327e-02,
          3.0655e-02, -4.6478e-02],
        [-7.2861e-03, -1.7700e-02,  6.5674e-02,  ..., -2.1118e-02,
          4.0054e-05,  1.8051e-02],
        ...,
        [-4.2786e-02,  3.8544e-02, -1.2512e-02,  ...,  4.3671e-02,
          2.1194e-02, -3.8223e-03],
        [-1.1719e-02, -1.7303e-02,  1.2596e-02,  ..., -7.9498e-03,
          1.4732e-02, -5.5847e-03],
        [ 3.5522e-02, -2.1042e-02,  1.4656e-02,  ..., -7.4005e-03,
          1.3977e-02,  3.5065e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1309, -3.9922, -1.8564,  ...,  0.2524, -3.1406,  1.5684]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 13:09:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for murder is slaying
Another word for flower is blossom
Another word for hieroglyph is hieroglyphic
Another word for reasonable is sensible
Another word for organized is arranged
Another word for railway is railroad
Another word for phone is telephone
Another word for baby is
2024-07-27 13:09:03 root INFO     [order_1_approx] starting weight calculation for Another word for baby is infant
Another word for phone is telephone
Another word for flower is blossom
Another word for organized is arranged
Another word for hieroglyph is hieroglyphic
Another word for reasonable is sensible
Another word for railway is railroad
Another word for murder is
2024-07-27 13:09:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 13:11:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0716,  0.2520,  0.3855,  ..., -0.0798, -0.1890, -0.0330],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2422, -5.2500, -1.8262,  ...,  0.1484, -2.0762, -3.7520],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0770, -0.0121,  0.0283,  ...,  0.0154, -0.0167,  0.0206],
        [-0.0154,  0.0616, -0.0010,  ..., -0.0318,  0.0203, -0.0195],
        [-0.0128,  0.0030,  0.0617,  ..., -0.0129,  0.0163, -0.0032],
        ...,
        [ 0.0194,  0.0097,  0.0072,  ...,  0.0641,  0.0028, -0.0146],
        [ 0.0063,  0.0131,  0.0161,  ..., -0.0218,  0.0345, -0.0162],
        [ 0.0357, -0.0044,  0.0054,  ..., -0.0246,  0.0239,  0.0421]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1807, -5.1641, -1.5020,  ..., -0.1326, -2.2402, -3.8203]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 13:11:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for baby is infant
Another word for phone is telephone
Another word for flower is blossom
Another word for organized is arranged
Another word for hieroglyph is hieroglyphic
Another word for reasonable is sensible
Another word for railway is railroad
Another word for murder is
2024-07-27 13:11:26 root INFO     total operator prediction time: 1126.4541704654694 seconds
2024-07-27 13:11:26 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - youth
2024-07-27 13:11:26 root INFO     building operator animal - youth
2024-07-27 13:11:26 root INFO     [order_1_approx] starting weight calculation for The offspring of a buffalo is referred to as a calf
The offspring of a fish is referred to as a fingerling
The offspring of a seal is referred to as a pup
The offspring of a rabbit is referred to as a bunny
The offspring of a duck is referred to as a duckling
The offspring of a panda is referred to as a cub
The offspring of a trout is referred to as a fingerling
The offspring of a butterfly is referred to as a
2024-07-27 13:11:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 13:13:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4336,  0.1637,  0.0086,  ...,  0.3589, -0.2468, -0.0610],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0000, -1.2051, -2.2930,  ...,  2.3691, -1.1143,  1.8857],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0243, -0.0124, -0.0053,  ...,  0.0080, -0.0044, -0.0280],
        [ 0.0039,  0.0233,  0.0071,  ..., -0.0016,  0.0048, -0.0221],
        [-0.0121,  0.0083,  0.0413,  ..., -0.0037, -0.0116, -0.0105],
        ...,
        [-0.0071,  0.0014, -0.0079,  ...,  0.0435,  0.0222, -0.0043],
        [-0.0020, -0.0011,  0.0136,  ...,  0.0063,  0.0029,  0.0061],
        [ 0.0090,  0.0018,  0.0112,  ..., -0.0073, -0.0056,  0.0372]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8809, -1.3809, -2.4648,  ...,  2.5566, -0.8931,  1.7793]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 13:13:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a buffalo is referred to as a calf
The offspring of a fish is referred to as a fingerling
The offspring of a seal is referred to as a pup
The offspring of a rabbit is referred to as a bunny
The offspring of a duck is referred to as a duckling
The offspring of a panda is referred to as a cub
The offspring of a trout is referred to as a fingerling
The offspring of a butterfly is referred to as a
2024-07-27 13:13:47 root INFO     [order_1_approx] starting weight calculation for The offspring of a seal is referred to as a pup
The offspring of a duck is referred to as a duckling
The offspring of a fish is referred to as a fingerling
The offspring of a trout is referred to as a fingerling
The offspring of a butterfly is referred to as a larva
The offspring of a panda is referred to as a cub
The offspring of a buffalo is referred to as a calf
The offspring of a rabbit is referred to as a
2024-07-27 13:13:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 13:16:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2524,  0.0165,  0.1410,  ..., -0.0847, -0.7261, -0.1362],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.2891, -2.0059, -0.7246,  ...,  2.1602, -2.6562,  0.0322],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.7252e-02, -1.7151e-02, -4.9639e-04,  ...,  1.7136e-02,
          3.0804e-03, -1.0727e-02],
        [-7.1411e-03,  2.0020e-02,  9.2545e-03,  ...,  3.3550e-03,
          6.5842e-03, -1.0780e-02],
        [-5.5084e-03,  7.1239e-04,  1.7288e-02,  ...,  1.4973e-04,
         -4.2572e-03, -1.4313e-02],
        ...,
        [ 3.5648e-03,  4.9095e-03,  1.1787e-03,  ...,  1.9455e-02,
          1.2924e-02, -5.5313e-05],
        [ 8.9264e-03, -4.5395e-04,  7.4863e-04,  ...,  4.2439e-04,
          2.4490e-03,  5.2223e-03],
        [-9.6321e-04,  5.1727e-03, -4.5052e-03,  ..., -9.9182e-03,
         -6.8855e-03,  1.1543e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.4336, -1.9258, -0.8125,  ...,  2.2109, -2.6719,  0.0123]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 13:16:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a seal is referred to as a pup
The offspring of a duck is referred to as a duckling
The offspring of a fish is referred to as a fingerling
The offspring of a trout is referred to as a fingerling
The offspring of a butterfly is referred to as a larva
The offspring of a panda is referred to as a cub
The offspring of a buffalo is referred to as a calf
The offspring of a rabbit is referred to as a
2024-07-27 13:16:07 root INFO     [order_1_approx] starting weight calculation for The offspring of a butterfly is referred to as a larva
The offspring of a duck is referred to as a duckling
The offspring of a seal is referred to as a pup
The offspring of a trout is referred to as a fingerling
The offspring of a rabbit is referred to as a bunny
The offspring of a panda is referred to as a cub
The offspring of a fish is referred to as a fingerling
The offspring of a buffalo is referred to as a
2024-07-27 13:16:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 13:18:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7324,  0.0137,  0.1387,  ...,  0.5020, -0.7266,  0.0664],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7412, -3.4746,  0.6133,  ...,  1.5439, -1.4619, -0.2520],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0435, -0.0129,  0.0046,  ...,  0.0053, -0.0004, -0.0090],
        [ 0.0177,  0.0195,  0.0216,  ..., -0.0114, -0.0136, -0.0301],
        [ 0.0150, -0.0180,  0.0543,  ...,  0.0036, -0.0060, -0.0327],
        ...,
        [ 0.0045,  0.0034,  0.0059,  ...,  0.0525,  0.0224, -0.0092],
        [ 0.0208,  0.0164,  0.0268,  ..., -0.0267,  0.0147, -0.0251],
        [-0.0007, -0.0018, -0.0173,  ..., -0.0061,  0.0069,  0.0367]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5156, -3.4004,  0.3621,  ...,  1.5156, -1.2871, -0.0952]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 13:18:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a butterfly is referred to as a larva
The offspring of a duck is referred to as a duckling
The offspring of a seal is referred to as a pup
The offspring of a trout is referred to as a fingerling
The offspring of a rabbit is referred to as a bunny
The offspring of a panda is referred to as a cub
The offspring of a fish is referred to as a fingerling
The offspring of a buffalo is referred to as a
2024-07-27 13:18:23 root INFO     [order_1_approx] starting weight calculation for The offspring of a trout is referred to as a fingerling
The offspring of a panda is referred to as a cub
The offspring of a buffalo is referred to as a calf
The offspring of a seal is referred to as a pup
The offspring of a rabbit is referred to as a bunny
The offspring of a butterfly is referred to as a larva
The offspring of a duck is referred to as a duckling
The offspring of a fish is referred to as a
2024-07-27 13:18:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 13:20:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4092, -0.0487, -0.2915,  ..., -0.0249, -0.2625,  0.2244],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6152, -2.4531, -3.3320,  ...,  0.2734, -4.4688,  0.4404],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0350, -0.0078, -0.0057,  ...,  0.0224, -0.0024, -0.0243],
        [-0.0012,  0.0565, -0.0054,  ..., -0.0051,  0.0083,  0.0008],
        [ 0.0034,  0.0155,  0.0263,  ...,  0.0276, -0.0073, -0.0091],
        ...,
        [-0.0109,  0.0018,  0.0047,  ...,  0.0307,  0.0108,  0.0009],
        [ 0.0118,  0.0316,  0.0091,  ...,  0.0032,  0.0176,  0.0062],
        [ 0.0113, -0.0026, -0.0086,  ..., -0.0250,  0.0057,  0.0157]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4355, -2.1699, -3.4668,  ...,  0.2986, -4.3516,  0.6211]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 13:20:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a trout is referred to as a fingerling
The offspring of a panda is referred to as a cub
The offspring of a buffalo is referred to as a calf
The offspring of a seal is referred to as a pup
The offspring of a rabbit is referred to as a bunny
The offspring of a butterfly is referred to as a larva
The offspring of a duck is referred to as a duckling
The offspring of a fish is referred to as a
2024-07-27 13:20:38 root INFO     [order_1_approx] starting weight calculation for The offspring of a rabbit is referred to as a bunny
The offspring of a trout is referred to as a fingerling
The offspring of a seal is referred to as a pup
The offspring of a fish is referred to as a fingerling
The offspring of a buffalo is referred to as a calf
The offspring of a butterfly is referred to as a larva
The offspring of a duck is referred to as a duckling
The offspring of a panda is referred to as a
2024-07-27 13:20:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 13:22:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0977, -0.1019, -0.2798,  ...,  0.3066, -0.5415,  0.4907],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9927, -3.7148, -0.6533,  ..., -0.9248, -2.2188,  3.1035],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0518, -0.0262, -0.0139,  ...,  0.0347,  0.0080,  0.0017],
        [-0.0013,  0.0634,  0.0112,  ..., -0.0095, -0.0232, -0.0485],
        [-0.0197,  0.0218,  0.0523,  ...,  0.0231, -0.0094, -0.0231],
        ...,
        [ 0.0219, -0.0096,  0.0029,  ...,  0.0697,  0.0052, -0.0126],
        [ 0.0303, -0.0256,  0.0216,  ...,  0.0007,  0.0362, -0.0020],
        [-0.0078, -0.0172, -0.0138,  ..., -0.0436,  0.0092,  0.0246]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9678, -3.1523, -0.4148,  ..., -0.7729, -2.4844,  2.9062]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 13:22:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a rabbit is referred to as a bunny
The offspring of a trout is referred to as a fingerling
The offspring of a seal is referred to as a pup
The offspring of a fish is referred to as a fingerling
The offspring of a buffalo is referred to as a calf
The offspring of a butterfly is referred to as a larva
The offspring of a duck is referred to as a duckling
The offspring of a panda is referred to as a
2024-07-27 13:22:57 root INFO     [order_1_approx] starting weight calculation for The offspring of a panda is referred to as a cub
The offspring of a buffalo is referred to as a calf
The offspring of a fish is referred to as a fingerling
The offspring of a seal is referred to as a pup
The offspring of a rabbit is referred to as a bunny
The offspring of a butterfly is referred to as a larva
The offspring of a duck is referred to as a duckling
The offspring of a trout is referred to as a
2024-07-27 13:22:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 13:25:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0057,  0.2393, -0.1577,  ...,  0.0552, -0.6562, -0.3794],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2002, -1.9004, -6.1289,  ...,  2.6367, -3.4102, -0.3848],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0381, -0.0054,  0.0045,  ...,  0.0061, -0.0167, -0.0240],
        [ 0.0251,  0.0570,  0.0126,  ..., -0.0022,  0.0196, -0.0060],
        [ 0.0114,  0.0040,  0.0370,  ...,  0.0177, -0.0051, -0.0054],
        ...,
        [-0.0242,  0.0021, -0.0039,  ...,  0.0576,  0.0275, -0.0036],
        [ 0.0101,  0.0019,  0.0283,  ...,  0.0307,  0.0383, -0.0057],
        [ 0.0078,  0.0044, -0.0277,  ..., -0.0254, -0.0073,  0.0166]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2988, -1.7676, -6.1250,  ...,  2.8906, -3.8145, -0.6504]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 13:25:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a panda is referred to as a cub
The offspring of a buffalo is referred to as a calf
The offspring of a fish is referred to as a fingerling
The offspring of a seal is referred to as a pup
The offspring of a rabbit is referred to as a bunny
The offspring of a butterfly is referred to as a larva
The offspring of a duck is referred to as a duckling
The offspring of a trout is referred to as a
2024-07-27 13:25:09 root INFO     [order_1_approx] starting weight calculation for The offspring of a butterfly is referred to as a larva
The offspring of a trout is referred to as a fingerling
The offspring of a fish is referred to as a fingerling
The offspring of a buffalo is referred to as a calf
The offspring of a rabbit is referred to as a bunny
The offspring of a duck is referred to as a duckling
The offspring of a panda is referred to as a cub
The offspring of a seal is referred to as a
2024-07-27 13:25:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 13:27:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7422, -0.4207,  0.0024,  ...,  0.1860, -0.7031,  0.1013],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2412, -3.6562, -2.8145,  ..., -1.0283, -3.7578,  2.5957],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0530, -0.0312, -0.0286,  ...,  0.0353, -0.0100, -0.0033],
        [ 0.0097,  0.0410,  0.0027,  ..., -0.0093, -0.0054, -0.0122],
        [ 0.0033, -0.0106,  0.0450,  ...,  0.0064, -0.0110, -0.0260],
        ...,
        [ 0.0216, -0.0048,  0.0294,  ...,  0.0418,  0.0280, -0.0067],
        [ 0.0080, -0.0176,  0.0305,  ...,  0.0319,  0.0216, -0.0162],
        [-0.0205, -0.0019,  0.0039,  ..., -0.0269, -0.0083,  0.0245]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4702, -3.1934, -2.6328,  ..., -0.6992, -3.7148,  2.5156]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 13:27:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a butterfly is referred to as a larva
The offspring of a trout is referred to as a fingerling
The offspring of a fish is referred to as a fingerling
The offspring of a buffalo is referred to as a calf
The offspring of a rabbit is referred to as a bunny
The offspring of a duck is referred to as a duckling
The offspring of a panda is referred to as a cub
The offspring of a seal is referred to as a
2024-07-27 13:27:28 root INFO     [order_1_approx] starting weight calculation for The offspring of a fish is referred to as a fingerling
The offspring of a panda is referred to as a cub
The offspring of a buffalo is referred to as a calf
The offspring of a trout is referred to as a fingerling
The offspring of a seal is referred to as a pup
The offspring of a rabbit is referred to as a bunny
The offspring of a butterfly is referred to as a larva
The offspring of a duck is referred to as a
2024-07-27 13:27:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 13:29:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7236, -0.1316,  0.3928,  ...,  0.1992, -0.7979,  0.0350],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0850, -1.6328, -1.6035,  ...,  0.7969, -5.6445,  2.5352],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.2450e-02, -1.6418e-02, -9.5463e-04,  ...,  5.4321e-03,
          5.1575e-03, -1.9455e-03],
        [ 3.8700e-03,  4.5013e-02,  1.3115e-02,  ...,  1.3781e-03,
         -8.9264e-03, -4.9286e-03],
        [ 4.0817e-03,  2.8801e-04,  3.6835e-02,  ..., -1.5236e-02,
         -1.0872e-02, -2.1317e-02],
        ...,
        [-1.2390e-02, -6.6757e-05,  7.8049e-03,  ...,  2.1469e-02,
          1.1612e-02, -1.5244e-02],
        [ 7.3242e-03, -1.0193e-02,  7.6141e-03,  ...,  1.1368e-02,
          2.0004e-02, -9.0256e-03],
        [ 1.7910e-03, -2.7466e-03,  7.4806e-03,  ...,  1.6155e-03,
         -9.0179e-03,  2.3300e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8770, -1.7031, -1.8350,  ...,  1.2139, -5.7109,  2.5527]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 13:29:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a fish is referred to as a fingerling
The offspring of a panda is referred to as a cub
The offspring of a buffalo is referred to as a calf
The offspring of a trout is referred to as a fingerling
The offspring of a seal is referred to as a pup
The offspring of a rabbit is referred to as a bunny
The offspring of a butterfly is referred to as a larva
The offspring of a duck is referred to as a
2024-07-27 13:29:49 root INFO     total operator prediction time: 1102.7248933315277 seconds
2024-07-27 13:29:49 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - sound
2024-07-27 13:29:49 root INFO     building operator animal - sound
2024-07-27 13:29:49 root INFO     [order_1_approx] starting weight calculation for The sound that a goat makes is called a bleat
The sound that a raven makes is called a caw
The sound that a duck makes is called a quack
The sound that a sheep makes is called a baa
The sound that a dog makes is called a bark
The sound that a whale makes is called a sing
The sound that a rat makes is called a squeak
The sound that a tiger makes is called a
2024-07-27 13:29:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 13:32:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0966,  0.3701,  0.0878,  ...,  0.1656, -0.2886, -0.0806],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1035, -5.6914, -0.9360,  ..., -2.8125, -0.6357,  0.7871],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0590, -0.0010,  0.0072,  ..., -0.0020, -0.0402, -0.0186],
        [ 0.0035,  0.0297,  0.0078,  ..., -0.0103,  0.0136, -0.0290],
        [-0.0288,  0.0289,  0.0473,  ..., -0.0204,  0.0178,  0.0079],
        ...,
        [ 0.0095,  0.0073,  0.0167,  ...,  0.0468,  0.0133, -0.0281],
        [ 0.0232, -0.0117,  0.0111,  ..., -0.0347,  0.0305,  0.0188],
        [ 0.0060, -0.0026, -0.0341,  ..., -0.0259,  0.0010, -0.0017]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7988, -5.4805, -0.5034,  ..., -2.6641, -0.8965,  0.4531]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 13:32:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a goat makes is called a bleat
The sound that a raven makes is called a caw
The sound that a duck makes is called a quack
The sound that a sheep makes is called a baa
The sound that a dog makes is called a bark
The sound that a whale makes is called a sing
The sound that a rat makes is called a squeak
The sound that a tiger makes is called a
2024-07-27 13:32:07 root INFO     [order_1_approx] starting weight calculation for The sound that a raven makes is called a caw
The sound that a duck makes is called a quack
The sound that a rat makes is called a squeak
The sound that a dog makes is called a bark
The sound that a goat makes is called a bleat
The sound that a whale makes is called a sing
The sound that a tiger makes is called a growl
The sound that a sheep makes is called a
2024-07-27 13:32:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 13:34:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1614, -0.2111,  0.2279,  ...,  0.1026, -0.3455,  0.6377],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3232, -0.6216,  2.5820,  ..., -0.0400, -0.4082, -1.1133],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0607, -0.0130,  0.0005,  ..., -0.0056, -0.0402, -0.0032],
        [-0.0194,  0.0509, -0.0233,  ...,  0.0078,  0.0262, -0.0235],
        [-0.0088,  0.0023,  0.0351,  ..., -0.0183, -0.0300, -0.0155],
        ...,
        [ 0.0175,  0.0321,  0.0145,  ...,  0.0516,  0.0059, -0.0219],
        [ 0.0107,  0.0253, -0.0060,  ...,  0.0112,  0.0362, -0.0018],
        [-0.0023, -0.0077, -0.0053,  ..., -0.0061,  0.0013,  0.0270]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7871, -0.3293,  2.6934,  ..., -0.5215, -0.8081, -1.2891]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 13:34:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a raven makes is called a caw
The sound that a duck makes is called a quack
The sound that a rat makes is called a squeak
The sound that a dog makes is called a bark
The sound that a goat makes is called a bleat
The sound that a whale makes is called a sing
The sound that a tiger makes is called a growl
The sound that a sheep makes is called a
2024-07-27 13:34:28 root INFO     [order_1_approx] starting weight calculation for The sound that a tiger makes is called a growl
The sound that a sheep makes is called a baa
The sound that a dog makes is called a bark
The sound that a raven makes is called a caw
The sound that a whale makes is called a sing
The sound that a rat makes is called a squeak
The sound that a goat makes is called a bleat
The sound that a duck makes is called a
2024-07-27 13:34:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 13:36:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2800, -0.2126,  0.6187,  ...,  0.1071, -0.5723,  0.1171],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5498, -4.4180,  2.8496,  ...,  0.9888, -4.3945,  1.6357],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0349, -0.0106, -0.0110,  ..., -0.0028, -0.0189, -0.0071],
        [-0.0049,  0.0357,  0.0144,  ..., -0.0039, -0.0205, -0.0191],
        [-0.0016, -0.0095,  0.0354,  ..., -0.0201, -0.0199,  0.0013],
        ...,
        [ 0.0081,  0.0150,  0.0041,  ...,  0.0316,  0.0109, -0.0218],
        [-0.0090,  0.0109,  0.0118,  ...,  0.0182,  0.0339, -0.0052],
        [-0.0039, -0.0132,  0.0062,  ..., -0.0224, -0.0062,  0.0267]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7148, -4.6445,  2.8477,  ...,  0.7959, -4.5430,  1.7061]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 13:36:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a tiger makes is called a growl
The sound that a sheep makes is called a baa
The sound that a dog makes is called a bark
The sound that a raven makes is called a caw
The sound that a whale makes is called a sing
The sound that a rat makes is called a squeak
The sound that a goat makes is called a bleat
The sound that a duck makes is called a
2024-07-27 13:36:49 root INFO     [order_1_approx] starting weight calculation for The sound that a whale makes is called a sing
The sound that a dog makes is called a bark
The sound that a sheep makes is called a baa
The sound that a raven makes is called a caw
The sound that a duck makes is called a quack
The sound that a goat makes is called a bleat
The sound that a tiger makes is called a growl
The sound that a rat makes is called a
2024-07-27 13:36:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 13:39:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1417, -0.1830,  0.3022,  ..., -0.2134, -0.1805, -0.0983],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8438, -0.6504,  0.4668,  ..., -2.8125, -0.2227,  2.3359],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.3608e-02, -9.4223e-03,  8.7357e-03,  ..., -8.0414e-03,
         -3.5339e-02, -1.5656e-02],
        [ 1.2978e-02,  8.5083e-02,  7.3318e-03,  ..., -8.8654e-03,
         -6.6071e-03, -3.0914e-02],
        [-7.9041e-03,  4.5395e-03,  6.6711e-02,  ..., -1.9882e-02,
         -2.7679e-02, -1.7761e-02],
        ...,
        [ 5.4169e-03, -1.3535e-02,  3.6469e-03,  ...,  3.9520e-02,
         -1.0658e-02, -9.2468e-03],
        [-4.0894e-03, -3.4828e-03,  1.4832e-02,  ..., -4.3068e-03,
          3.0380e-02,  1.5442e-02],
        [ 1.7578e-02, -5.7220e-06, -1.8951e-02,  ..., -4.0985e-02,
         -1.2062e-02,  3.7354e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8184, -0.9502, -0.0532,  ..., -3.0918, -0.2791,  2.1641]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 13:39:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a whale makes is called a sing
The sound that a dog makes is called a bark
The sound that a sheep makes is called a baa
The sound that a raven makes is called a caw
The sound that a duck makes is called a quack
The sound that a goat makes is called a bleat
The sound that a tiger makes is called a growl
The sound that a rat makes is called a
2024-07-27 13:39:08 root INFO     [order_1_approx] starting weight calculation for The sound that a sheep makes is called a baa
The sound that a tiger makes is called a growl
The sound that a raven makes is called a caw
The sound that a duck makes is called a quack
The sound that a dog makes is called a bark
The sound that a goat makes is called a bleat
The sound that a rat makes is called a squeak
The sound that a whale makes is called a
2024-07-27 13:39:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 13:41:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 4.6924e-01, -2.0483e-01,  3.1201e-01,  ..., -2.0508e-01,
        -3.3057e-01,  1.2207e-04], device='cuda:1', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4419,  0.0669,  2.7852,  ...,  0.2422, -1.7793,  1.3281],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0469, -0.0005, -0.0156,  ...,  0.0051, -0.0075,  0.0050],
        [ 0.0113,  0.0848, -0.0055,  ..., -0.0215, -0.0246, -0.0219],
        [-0.0110,  0.0125,  0.0493,  ..., -0.0025, -0.0236, -0.0157],
        ...,
        [ 0.0123,  0.0099,  0.0203,  ...,  0.0543, -0.0012, -0.0149],
        [ 0.0045, -0.0002,  0.0011,  ..., -0.0030,  0.0154,  0.0027],
        [ 0.0112, -0.0286, -0.0078,  ..., -0.0185, -0.0005,  0.0235]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0352, -0.0554,  2.5742,  ..., -0.1694, -2.1250,  1.3389]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 13:41:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a sheep makes is called a baa
The sound that a tiger makes is called a growl
The sound that a raven makes is called a caw
The sound that a duck makes is called a quack
The sound that a dog makes is called a bark
The sound that a goat makes is called a bleat
The sound that a rat makes is called a squeak
The sound that a whale makes is called a
2024-07-27 13:41:29 root INFO     [order_1_approx] starting weight calculation for The sound that a rat makes is called a squeak
The sound that a tiger makes is called a growl
The sound that a raven makes is called a caw
The sound that a sheep makes is called a baa
The sound that a duck makes is called a quack
The sound that a dog makes is called a bark
The sound that a whale makes is called a sing
The sound that a goat makes is called a
2024-07-27 13:41:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 13:43:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1327, -0.1077,  0.4780,  ...,  0.0749, -0.4856,  0.2583],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6484, -3.3672,  2.1816,  ..., -0.9072, -1.0625, -0.2705],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0498, -0.0041, -0.0103,  ..., -0.0252, -0.0337, -0.0098],
        [-0.0156,  0.0582, -0.0386,  ..., -0.0053,  0.0030, -0.0004],
        [-0.0251,  0.0096,  0.0523,  ..., -0.0324, -0.0038, -0.0047],
        ...,
        [-0.0012,  0.0196, -0.0056,  ...,  0.0477,  0.0001, -0.0325],
        [ 0.0223,  0.0351, -0.0058,  ...,  0.0065,  0.0348, -0.0142],
        [ 0.0105, -0.0408,  0.0282,  ..., -0.0316,  0.0094,  0.0307]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8340, -3.0840,  2.1934,  ..., -0.9736, -1.1182, -0.3208]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 13:43:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a rat makes is called a squeak
The sound that a tiger makes is called a growl
The sound that a raven makes is called a caw
The sound that a sheep makes is called a baa
The sound that a duck makes is called a quack
The sound that a dog makes is called a bark
The sound that a whale makes is called a sing
The sound that a goat makes is called a
2024-07-27 13:43:51 root INFO     [order_1_approx] starting weight calculation for The sound that a goat makes is called a bleat
The sound that a tiger makes is called a growl
The sound that a whale makes is called a sing
The sound that a raven makes is called a caw
The sound that a sheep makes is called a baa
The sound that a duck makes is called a quack
The sound that a rat makes is called a squeak
The sound that a dog makes is called a
2024-07-27 13:43:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 13:46:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2612,  0.0959,  0.3083,  ...,  0.1195, -0.3799,  0.1949],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.9204, -5.2695,  0.4746,  ..., -2.8672, -0.5928,  3.1504],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0276, -0.0087,  0.0038,  ..., -0.0279, -0.0244, -0.0003],
        [ 0.0001,  0.0322, -0.0040,  ..., -0.0064,  0.0187, -0.0220],
        [ 0.0083, -0.0028,  0.0562,  ..., -0.0179, -0.0100, -0.0211],
        ...,
        [-0.0030,  0.0125,  0.0008,  ...,  0.0459,  0.0008,  0.0016],
        [ 0.0017,  0.0023, -0.0068,  ...,  0.0223,  0.0275,  0.0066],
        [-0.0062, -0.0219, -0.0117,  ..., -0.0064,  0.0033,  0.0241]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7314, -4.8086,  0.4700,  ..., -3.2773, -0.6812,  3.1426]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 13:46:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a goat makes is called a bleat
The sound that a tiger makes is called a growl
The sound that a whale makes is called a sing
The sound that a raven makes is called a caw
The sound that a sheep makes is called a baa
The sound that a duck makes is called a quack
The sound that a rat makes is called a squeak
The sound that a dog makes is called a
2024-07-27 13:46:12 root INFO     [order_1_approx] starting weight calculation for The sound that a goat makes is called a bleat
The sound that a tiger makes is called a growl
The sound that a sheep makes is called a baa
The sound that a duck makes is called a quack
The sound that a rat makes is called a squeak
The sound that a whale makes is called a sing
The sound that a dog makes is called a bark
The sound that a raven makes is called a
2024-07-27 13:46:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 13:48:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1357,  0.1041,  0.1558,  ...,  0.2551, -0.4106, -0.2104],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5674, -3.6875,  0.9111,  ..., -2.4121,  0.3003,  2.5586],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0606,  0.0004, -0.0079,  ..., -0.0165, -0.0474, -0.0179],
        [-0.0255,  0.0453,  0.0140,  ...,  0.0261,  0.0265, -0.0480],
        [-0.0096, -0.0127,  0.0517,  ..., -0.0097, -0.0353, -0.0161],
        ...,
        [ 0.0168,  0.0079,  0.0064,  ...,  0.0586,  0.0257, -0.0273],
        [-0.0359, -0.0093, -0.0211,  ...,  0.0044,  0.0221, -0.0232],
        [ 0.0154, -0.0083, -0.0031,  ..., -0.0171, -0.0186,  0.0356]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2314, -3.5879,  0.7725,  ..., -3.2871, -0.0071,  2.3516]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 13:48:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a goat makes is called a bleat
The sound that a tiger makes is called a growl
The sound that a sheep makes is called a baa
The sound that a duck makes is called a quack
The sound that a rat makes is called a squeak
The sound that a whale makes is called a sing
The sound that a dog makes is called a bark
The sound that a raven makes is called a
2024-07-27 13:48:33 root INFO     total operator prediction time: 1123.804678440094 seconds
2024-07-27 13:48:33 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on things - color
2024-07-27 13:48:33 root INFO     building operator things - color
2024-07-27 13:48:33 root INFO     [order_1_approx] starting weight calculation for The sugar is colored white
The peony is colored red
The emerald is colored green
The celery is colored green
The cauliflower is colored white
The swan is colored white
The sea is colored blue
The coal is colored
2024-07-27 13:48:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 13:50:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1436, -0.3357, -0.2085,  ...,  0.0260,  0.1941,  0.2969],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.2285, -5.7188, -1.2627,  ..., -3.8867,  0.4585, -4.6094],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0602,  0.0046,  0.0008,  ..., -0.0072,  0.0117, -0.0174],
        [ 0.0204,  0.0561,  0.0225,  ...,  0.0129,  0.0213, -0.0055],
        [-0.0033, -0.0065,  0.0326,  ...,  0.0051, -0.0034, -0.0014],
        ...,
        [ 0.0217, -0.0063,  0.0031,  ...,  0.0329,  0.0323,  0.0127],
        [ 0.0097,  0.0165,  0.0018,  ...,  0.0291,  0.0449,  0.0005],
        [-0.0107, -0.0221, -0.0231,  ..., -0.0107, -0.0082,  0.0309]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1260, -5.5664, -1.2490,  ..., -3.5742,  0.2169, -3.8535]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 13:50:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sugar is colored white
The peony is colored red
The emerald is colored green
The celery is colored green
The cauliflower is colored white
The swan is colored white
The sea is colored blue
The coal is colored
2024-07-27 13:50:55 root INFO     [order_1_approx] starting weight calculation for The sea is colored blue
The peony is colored red
The coal is colored black
The cauliflower is colored white
The celery is colored green
The swan is colored white
The sugar is colored white
The emerald is colored
2024-07-27 13:50:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 13:53:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0632, -0.4272, -0.5933,  ...,  0.0287,  0.1792,  0.1484],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1777, -0.9062, -1.8457,  ..., -0.0430,  1.0166,  0.2285],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0683, -0.0035,  0.0105,  ..., -0.0043,  0.0250,  0.0099],
        [ 0.0112,  0.0359,  0.0182,  ...,  0.0139,  0.0036, -0.0111],
        [-0.0008, -0.0175,  0.0490,  ...,  0.0035, -0.0058,  0.0077],
        ...,
        [ 0.0086, -0.0056,  0.0139,  ...,  0.0605,  0.0259, -0.0273],
        [ 0.0110, -0.0041, -0.0084,  ...,  0.0285,  0.0530, -0.0158],
        [-0.0140, -0.0181,  0.0028,  ..., -0.0109, -0.0298,  0.0438]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3809, -0.8892, -2.0566,  ...,  0.2151,  1.0938,  0.2073]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 13:53:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sea is colored blue
The peony is colored red
The coal is colored black
The cauliflower is colored white
The celery is colored green
The swan is colored white
The sugar is colored white
The emerald is colored
2024-07-27 13:53:17 root INFO     [order_1_approx] starting weight calculation for The peony is colored red
The celery is colored green
The cauliflower is colored white
The sugar is colored white
The swan is colored white
The emerald is colored green
The coal is colored black
The sea is colored
2024-07-27 13:53:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 13:55:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1414, -0.2300, -0.0635,  ..., -0.0698, -0.0807,  0.1018],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.3936, -2.5684, -1.6562,  ...,  0.8691,  0.8057, -0.5601],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0418, -0.0002,  0.0111,  ..., -0.0092,  0.0138,  0.0083],
        [-0.0051,  0.0443,  0.0019,  ...,  0.0010,  0.0025,  0.0029],
        [-0.0100, -0.0031,  0.0517,  ...,  0.0037,  0.0056,  0.0209],
        ...,
        [-0.0030,  0.0136,  0.0229,  ...,  0.0496,  0.0024, -0.0143],
        [-0.0187, -0.0063,  0.0092,  ...,  0.0240,  0.0343, -0.0066],
        [-0.0062, -0.0117, -0.0079,  ...,  0.0019, -0.0174,  0.0182]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.4551, -2.6113, -1.8408,  ...,  1.0957,  0.8174, -0.6816]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 13:55:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The peony is colored red
The celery is colored green
The cauliflower is colored white
The sugar is colored white
The swan is colored white
The emerald is colored green
The coal is colored black
The sea is colored
2024-07-27 13:55:39 root INFO     [order_1_approx] starting weight calculation for The emerald is colored green
The swan is colored white
The sea is colored blue
The peony is colored red
The sugar is colored white
The coal is colored black
The cauliflower is colored white
The celery is colored
2024-07-27 13:55:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 13:58:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1047, -0.0374, -0.2170,  ..., -0.4329, -0.4580, -0.0841],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8604, -3.3945, -2.4395,  ..., -1.3125, -1.7227, -2.7070],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0727, -0.0094,  0.0103,  ...,  0.0072,  0.0129,  0.0059],
        [ 0.0139,  0.0491,  0.0111,  ...,  0.0165,  0.0094, -0.0178],
        [-0.0195, -0.0148,  0.0519,  ...,  0.0074, -0.0164,  0.0056],
        ...,
        [ 0.0212, -0.0146, -0.0019,  ...,  0.0730,  0.0162, -0.0052],
        [ 0.0114,  0.0223, -0.0132,  ...,  0.0055,  0.0497, -0.0022],
        [-0.0111, -0.0087,  0.0033,  ..., -0.0069,  0.0052,  0.0422]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1318, -3.7852, -2.2910,  ..., -0.8828, -1.9473, -2.0547]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 13:58:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The emerald is colored green
The swan is colored white
The sea is colored blue
The peony is colored red
The sugar is colored white
The coal is colored black
The cauliflower is colored white
The celery is colored
2024-07-27 13:58:01 root INFO     [order_1_approx] starting weight calculation for The cauliflower is colored white
The sea is colored blue
The celery is colored green
The emerald is colored green
The sugar is colored white
The coal is colored black
The peony is colored red
The swan is colored
2024-07-27 13:58:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 14:00:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4104, -0.5278,  0.2062,  ...,  0.1697, -0.1957,  0.1066],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-3.1641, -3.6602,  0.8218,  ...,  0.2690, -2.3086,  1.3506],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0813, -0.0072,  0.0099,  ..., -0.0190,  0.0244,  0.0094],
        [-0.0161,  0.0496,  0.0191,  ...,  0.0136, -0.0082, -0.0152],
        [-0.0103, -0.0141,  0.0353,  ..., -0.0076, -0.0069,  0.0006],
        ...,
        [-0.0052, -0.0011,  0.0159,  ...,  0.0649,  0.0157, -0.0232],
        [ 0.0182,  0.0058, -0.0009,  ...,  0.0241,  0.0522, -0.0279],
        [-0.0436, -0.0107, -0.0294,  ..., -0.0040,  0.0114,  0.0132]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.9258, -3.6680,  0.7861,  ...,  0.3406, -2.2695,  1.7109]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 14:00:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The cauliflower is colored white
The sea is colored blue
The celery is colored green
The emerald is colored green
The sugar is colored white
The coal is colored black
The peony is colored red
The swan is colored
2024-07-27 14:00:23 root INFO     [order_1_approx] starting weight calculation for The coal is colored black
The swan is colored white
The emerald is colored green
The peony is colored red
The sea is colored blue
The celery is colored green
The cauliflower is colored white
The sugar is colored
2024-07-27 14:00:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 14:02:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3384, -0.2529, -0.1261,  ...,  0.2129, -0.1682, -0.1907],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.4189, -6.0391,  0.2422,  ..., -2.1914, -1.5820, -0.5840],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0538, -0.0010,  0.0094,  ...,  0.0029, -0.0013,  0.0117],
        [ 0.0096,  0.0741,  0.0269,  ...,  0.0074,  0.0376, -0.0078],
        [ 0.0114, -0.0038,  0.0352,  ...,  0.0236, -0.0170,  0.0232],
        ...,
        [ 0.0206, -0.0202,  0.0061,  ...,  0.0454,  0.0194, -0.0101],
        [ 0.0020,  0.0113, -0.0042,  ...,  0.0243,  0.0415, -0.0145],
        [-0.0060, -0.0290,  0.0054,  ..., -0.0053, -0.0176,  0.0197]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.3369, -6.1641,  0.1436,  ..., -2.0195, -1.3721, -0.0430]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 14:02:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The coal is colored black
The swan is colored white
The emerald is colored green
The peony is colored red
The sea is colored blue
The celery is colored green
The cauliflower is colored white
The sugar is colored
2024-07-27 14:02:46 root INFO     [order_1_approx] starting weight calculation for The sugar is colored white
The sea is colored blue
The celery is colored green
The coal is colored black
The emerald is colored green
The swan is colored white
The peony is colored red
The cauliflower is colored
2024-07-27 14:02:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 14:05:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0057, -0.5205, -0.2307,  ...,  0.0516, -0.4856, -0.1039],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.4473, -5.2930,  0.2446,  ..., -1.1270,  0.0613, -0.6167],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0354,  0.0085,  0.0122,  ..., -0.0144, -0.0078, -0.0083],
        [ 0.0041,  0.0236,  0.0055,  ..., -0.0115,  0.0011, -0.0205],
        [-0.0170, -0.0117,  0.0317,  ...,  0.0173, -0.0175,  0.0104],
        ...,
        [ 0.0162, -0.0077, -0.0110,  ...,  0.0287, -0.0064, -0.0074],
        [-0.0024,  0.0100,  0.0011,  ...,  0.0164,  0.0267,  0.0149],
        [-0.0097, -0.0072,  0.0084,  ...,  0.0101, -0.0082,  0.0374]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.4189, -5.0156,  0.1199,  ..., -0.8525, -0.0411, -0.4565]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 14:05:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sugar is colored white
The sea is colored blue
The celery is colored green
The coal is colored black
The emerald is colored green
The swan is colored white
The peony is colored red
The cauliflower is colored
2024-07-27 14:05:08 root INFO     [order_1_approx] starting weight calculation for The coal is colored black
The emerald is colored green
The celery is colored green
The cauliflower is colored white
The sea is colored blue
The swan is colored white
The sugar is colored white
The peony is colored
2024-07-27 14:05:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 14:07:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1539, -0.1847, -0.3123,  ...,  0.1198, -0.4060,  0.0334],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.5371, -3.9219,  2.1973,  ..., -0.1035, -2.0898,  0.2617],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0571, -0.0077,  0.0102,  ..., -0.0047,  0.0122,  0.0090],
        [ 0.0048,  0.0383,  0.0297,  ..., -0.0020, -0.0001, -0.0117],
        [-0.0102,  0.0057,  0.0398,  ...,  0.0170, -0.0035,  0.0073],
        ...,
        [ 0.0117, -0.0048,  0.0048,  ...,  0.0493, -0.0178, -0.0109],
        [ 0.0048, -0.0017, -0.0113,  ...,  0.0091,  0.0590, -0.0095],
        [-0.0199, -0.0036, -0.0056,  ..., -0.0019, -0.0109,  0.0343]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.3340, -3.8301,  2.0195,  ...,  0.1924, -2.1191,  0.2430]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 14:07:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The coal is colored black
The emerald is colored green
The celery is colored green
The cauliflower is colored white
The sea is colored blue
The swan is colored white
The sugar is colored white
The peony is colored
2024-07-27 14:07:29 root INFO     total operator prediction time: 1136.5110409259796 seconds
2024-07-27 14:07:29 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on country - capital
2024-07-27 14:07:29 root INFO     building operator country - capital
2024-07-27 14:07:30 root INFO     [order_1_approx] starting weight calculation for The country with tehran as its capital is known as iran
The country with islamabad as its capital is known as pakistan
The country with tbilisi as its capital is known as georgia
The country with moscow as its capital is known as russia
The country with lisbon as its capital is known as portugal
The country with warsaw as its capital is known as poland
The country with kingston as its capital is known as jamaica
The country with dublin as its capital is known as
2024-07-27 14:07:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 14:09:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3977, -0.0685, -0.2969,  ...,  0.8516,  0.1558,  0.0168],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9180, -5.6211, -1.2432,  ...,  1.6973, -1.2354, -6.6953],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0443, -0.0152, -0.0113,  ...,  0.0124, -0.0011, -0.0038],
        [-0.0060,  0.0239, -0.0141,  ...,  0.0022, -0.0081, -0.0135],
        [-0.0042,  0.0206,  0.0375,  ...,  0.0087, -0.0080, -0.0093],
        ...,
        [-0.0104,  0.0061,  0.0021,  ...,  0.0248,  0.0199, -0.0062],
        [ 0.0083, -0.0062, -0.0017,  ...,  0.0095,  0.0216, -0.0042],
        [ 0.0033, -0.0026,  0.0086,  ...,  0.0071, -0.0011,  0.0121]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7773, -5.6523, -1.2334,  ...,  1.4707, -1.1650, -6.2812]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 14:09:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with tehran as its capital is known as iran
The country with islamabad as its capital is known as pakistan
The country with tbilisi as its capital is known as georgia
The country with moscow as its capital is known as russia
The country with lisbon as its capital is known as portugal
The country with warsaw as its capital is known as poland
The country with kingston as its capital is known as jamaica
The country with dublin as its capital is known as
2024-07-27 14:09:46 root INFO     [order_1_approx] starting weight calculation for The country with lisbon as its capital is known as portugal
The country with warsaw as its capital is known as poland
The country with tehran as its capital is known as iran
The country with moscow as its capital is known as russia
The country with tbilisi as its capital is known as georgia
The country with dublin as its capital is known as ireland
The country with islamabad as its capital is known as pakistan
The country with kingston as its capital is known as
2024-07-27 14:09:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 14:12:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0947,  0.1738, -0.1282,  ...,  0.3286,  0.2764,  0.0569],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8828, -2.4922, -0.2715,  ..., -0.1164,  0.3594, -2.0195],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0421,  0.0050, -0.0023,  ...,  0.0058, -0.0250,  0.0072],
        [ 0.0023,  0.0466,  0.0617,  ..., -0.0266, -0.0186,  0.0047],
        [ 0.0223,  0.0166,  0.0854,  ...,  0.0032, -0.0023, -0.0079],
        ...,
        [ 0.0057, -0.0001,  0.0122,  ...,  0.0712, -0.0069, -0.0033],
        [ 0.0052,  0.0016, -0.0190,  ...,  0.0023,  0.0300,  0.0047],
        [-0.0091,  0.0035,  0.0289,  ..., -0.0199,  0.0010,  0.0168]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9473, -2.4277, -0.8301,  ..., -0.1372,  0.3997, -1.6670]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 14:12:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with lisbon as its capital is known as portugal
The country with warsaw as its capital is known as poland
The country with tehran as its capital is known as iran
The country with moscow as its capital is known as russia
The country with tbilisi as its capital is known as georgia
The country with dublin as its capital is known as ireland
The country with islamabad as its capital is known as pakistan
The country with kingston as its capital is known as
2024-07-27 14:12:04 root INFO     [order_1_approx] starting weight calculation for The country with kingston as its capital is known as jamaica
The country with tbilisi as its capital is known as georgia
The country with islamabad as its capital is known as pakistan
The country with tehran as its capital is known as iran
The country with moscow as its capital is known as russia
The country with lisbon as its capital is known as portugal
The country with dublin as its capital is known as ireland
The country with warsaw as its capital is known as
2024-07-27 14:12:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 14:14:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4868, -0.1696, -0.6221,  ...,  0.6738, -0.0373, -0.2352],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2031, -6.9219, -1.8926,  ..., -1.1406,  1.7324, -4.3516],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0273, -0.0037, -0.0030,  ...,  0.0245, -0.0011,  0.0085],
        [ 0.0025,  0.0303,  0.0181,  ..., -0.0014,  0.0069, -0.0011],
        [-0.0022,  0.0303,  0.0370,  ...,  0.0069, -0.0085, -0.0098],
        ...,
        [-0.0076,  0.0081,  0.0210,  ...,  0.0476,  0.0102, -0.0025],
        [ 0.0161, -0.0038, -0.0240,  ...,  0.0144,  0.0196, -0.0081],
        [-0.0080,  0.0080, -0.0043,  ..., -0.0056, -0.0055,  0.0192]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2109, -6.7188, -2.0020,  ..., -1.0488,  1.7363, -4.1094]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 14:14:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with kingston as its capital is known as jamaica
The country with tbilisi as its capital is known as georgia
The country with islamabad as its capital is known as pakistan
The country with tehran as its capital is known as iran
The country with moscow as its capital is known as russia
The country with lisbon as its capital is known as portugal
The country with dublin as its capital is known as ireland
The country with warsaw as its capital is known as
2024-07-27 14:14:18 root INFO     [order_1_approx] starting weight calculation for The country with lisbon as its capital is known as portugal
The country with warsaw as its capital is known as poland
The country with dublin as its capital is known as ireland
The country with kingston as its capital is known as jamaica
The country with tehran as its capital is known as iran
The country with tbilisi as its capital is known as georgia
The country with islamabad as its capital is known as pakistan
The country with moscow as its capital is known as
2024-07-27 14:14:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 14:16:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5093, -0.0974, -0.2502,  ...,  0.4663,  0.2048, -0.2957],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6567, -5.0352, -2.5781,  ..., -2.5117,  0.1665, -4.0000],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0232, -0.0129, -0.0041,  ...,  0.0051, -0.0113,  0.0134],
        [ 0.0055,  0.0147,  0.0112,  ..., -0.0026,  0.0106, -0.0036],
        [ 0.0108,  0.0138,  0.0285,  ...,  0.0117, -0.0083, -0.0126],
        ...,
        [ 0.0085,  0.0121,  0.0079,  ...,  0.0282,  0.0081, -0.0204],
        [-0.0018,  0.0068, -0.0123,  ...,  0.0092,  0.0071, -0.0010],
        [-0.0002,  0.0003,  0.0004,  ...,  0.0032, -0.0128,  0.0141]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8701, -4.9258, -2.7324,  ..., -2.6172,  0.0657, -3.7168]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 14:16:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with lisbon as its capital is known as portugal
The country with warsaw as its capital is known as poland
The country with dublin as its capital is known as ireland
The country with kingston as its capital is known as jamaica
The country with tehran as its capital is known as iran
The country with tbilisi as its capital is known as georgia
The country with islamabad as its capital is known as pakistan
The country with moscow as its capital is known as
2024-07-27 14:16:33 root INFO     [order_1_approx] starting weight calculation for The country with lisbon as its capital is known as portugal
The country with moscow as its capital is known as russia
The country with dublin as its capital is known as ireland
The country with islamabad as its capital is known as pakistan
The country with warsaw as its capital is known as poland
The country with tehran as its capital is known as iran
The country with kingston as its capital is known as jamaica
The country with tbilisi as its capital is known as
2024-07-27 14:16:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 14:18:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1742, -0.1884, -0.5845,  ...,  0.5029,  0.1390,  0.3284],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7422, -5.1875, -0.9746,  ..., -2.6875,  0.5371, -2.6270],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0223, -0.0127, -0.0066,  ...,  0.0115, -0.0038,  0.0018],
        [ 0.0155,  0.0181,  0.0040,  ...,  0.0029,  0.0132, -0.0139],
        [-0.0021,  0.0038,  0.0210,  ...,  0.0140, -0.0005, -0.0111],
        ...,
        [ 0.0034,  0.0015, -0.0039,  ...,  0.0354,  0.0076, -0.0042],
        [ 0.0062,  0.0093, -0.0049,  ...,  0.0117,  0.0131, -0.0012],
        [-0.0116, -0.0039, -0.0092,  ..., -0.0020,  0.0059,  0.0055]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4414, -5.2617, -1.0820,  ..., -2.8086,  0.6270, -2.5781]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 14:18:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with lisbon as its capital is known as portugal
The country with moscow as its capital is known as russia
The country with dublin as its capital is known as ireland
The country with islamabad as its capital is known as pakistan
The country with warsaw as its capital is known as poland
The country with tehran as its capital is known as iran
The country with kingston as its capital is known as jamaica
The country with tbilisi as its capital is known as
2024-07-27 14:18:48 root INFO     [order_1_approx] starting weight calculation for The country with tbilisi as its capital is known as georgia
The country with kingston as its capital is known as jamaica
The country with moscow as its capital is known as russia
The country with islamabad as its capital is known as pakistan
The country with dublin as its capital is known as ireland
The country with lisbon as its capital is known as portugal
The country with warsaw as its capital is known as poland
The country with tehran as its capital is known as
2024-07-27 14:18:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 14:21:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1914, -0.1393, -0.4595,  ...,  0.4373,  0.3630,  0.4534],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5352, -3.7969, -0.4888,  ..., -1.0938,  0.4463, -4.7070],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0296, -0.0079, -0.0096,  ...,  0.0055, -0.0068, -0.0014],
        [ 0.0022,  0.0236,  0.0018,  ..., -0.0043,  0.0125, -0.0046],
        [ 0.0039,  0.0042,  0.0427,  ..., -0.0040, -0.0047, -0.0010],
        ...,
        [ 0.0020,  0.0101,  0.0009,  ...,  0.0289,  0.0098, -0.0033],
        [ 0.0005, -0.0051, -0.0070,  ...,  0.0043,  0.0187,  0.0024],
        [-0.0101,  0.0046, -0.0110,  ...,  0.0155,  0.0038,  0.0297]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4097, -3.3945, -0.5229,  ..., -0.7617,  0.5244, -4.1055]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 14:21:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with tbilisi as its capital is known as georgia
The country with kingston as its capital is known as jamaica
The country with moscow as its capital is known as russia
The country with islamabad as its capital is known as pakistan
The country with dublin as its capital is known as ireland
The country with lisbon as its capital is known as portugal
The country with warsaw as its capital is known as poland
The country with tehran as its capital is known as
2024-07-27 14:21:07 root INFO     [order_1_approx] starting weight calculation for The country with warsaw as its capital is known as poland
The country with moscow as its capital is known as russia
The country with tehran as its capital is known as iran
The country with tbilisi as its capital is known as georgia
The country with dublin as its capital is known as ireland
The country with lisbon as its capital is known as portugal
The country with kingston as its capital is known as jamaica
The country with islamabad as its capital is known as
2024-07-27 14:21:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 14:23:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3772,  0.0024, -0.2532,  ...,  1.0547, -0.0671,  0.5435],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0938, -6.6211, -0.3066,  ..., -1.0420, -0.9473, -2.1094],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.1158e-02, -1.3527e-02, -1.0223e-03,  ..., -6.0272e-04,
         -9.0408e-03,  9.9945e-03],
        [-2.7420e-02,  1.9089e-02, -1.6251e-03,  ...,  6.6147e-03,
         -3.8090e-03, -2.0172e-02],
        [ 2.3666e-02,  3.5889e-02,  4.7699e-02,  ...,  5.7869e-03,
         -1.3847e-02, -9.2010e-03],
        ...,
        [ 5.2118e-04,  5.7220e-05, -9.5825e-03,  ...,  3.7476e-02,
          2.0050e-02, -9.4757e-03],
        [-7.6008e-04, -9.1782e-03, -1.2489e-02,  ...,  9.2697e-03,
          9.7580e-03,  3.1548e-03],
        [-1.7944e-02,  8.4610e-03,  7.0152e-03,  ...,  1.9089e-02,
         -7.1030e-03,  2.1439e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7891, -6.1680, -0.7642,  ..., -0.7334, -0.9731, -2.1797]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 14:23:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with warsaw as its capital is known as poland
The country with moscow as its capital is known as russia
The country with tehran as its capital is known as iran
The country with tbilisi as its capital is known as georgia
The country with dublin as its capital is known as ireland
The country with lisbon as its capital is known as portugal
The country with kingston as its capital is known as jamaica
The country with islamabad as its capital is known as
2024-07-27 14:23:30 root INFO     [order_1_approx] starting weight calculation for The country with dublin as its capital is known as ireland
The country with tbilisi as its capital is known as georgia
The country with kingston as its capital is known as jamaica
The country with tehran as its capital is known as iran
The country with moscow as its capital is known as russia
The country with warsaw as its capital is known as poland
The country with islamabad as its capital is known as pakistan
The country with lisbon as its capital is known as
2024-07-27 14:23:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 14:25:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5259, -0.1754, -0.6460,  ...,  0.6802,  0.1964, -0.1547],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2305, -6.1328, -2.8828,  ..., -0.1041,  1.6484, -4.2578],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0326,  0.0036, -0.0085,  ...,  0.0100, -0.0057,  0.0035],
        [ 0.0106,  0.0297, -0.0024,  ..., -0.0037, -0.0053, -0.0101],
        [ 0.0123,  0.0130,  0.0475,  ...,  0.0035,  0.0146, -0.0303],
        ...,
        [-0.0107,  0.0139,  0.0137,  ...,  0.0390,  0.0141, -0.0217],
        [-0.0020,  0.0077, -0.0119,  ...,  0.0130,  0.0266, -0.0018],
        [-0.0098,  0.0114, -0.0285,  ...,  0.0022, -0.0068,  0.0174]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0195, -6.0039, -2.6777,  ..., -0.0997,  1.5254, -4.1797]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 14:25:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with dublin as its capital is known as ireland
The country with tbilisi as its capital is known as georgia
The country with kingston as its capital is known as jamaica
The country with tehran as its capital is known as iran
The country with moscow as its capital is known as russia
The country with warsaw as its capital is known as poland
The country with islamabad as its capital is known as pakistan
The country with lisbon as its capital is known as
2024-07-27 14:25:52 root INFO     total operator prediction time: 1102.7023181915283 seconds
2024-07-27 14:25:52 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on name - occupation
2024-07-27 14:25:52 root INFO     building operator name - occupation
2024-07-27 14:25:52 root INFO     [order_1_approx] starting weight calculation for raphael was known for their work as a  painter
kepler was known for their work as a  mathematician
aristotle was known for their work as a  philosopher
hume was known for their work as a  philosopher
euler was known for their work as a  mathematician
newton was known for their work as a  scientist
mencius was known for their work as a  philosopher
dickens was known for their work as a 
2024-07-27 14:25:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 14:28:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0229,  0.3232, -0.2852,  ...,  0.3203, -0.4854, -0.2168],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4180, -5.1094,  4.7344,  ..., -4.1562, -0.1445, -0.7773],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0386, -0.0014,  0.0202,  ...,  0.0164,  0.0001, -0.0070],
        [ 0.0359,  0.0286, -0.0015,  ...,  0.0123,  0.0023,  0.0049],
        [-0.0183, -0.0027,  0.0611,  ...,  0.0032,  0.0005,  0.0076],
        ...,
        [ 0.0185,  0.0042, -0.0024,  ...,  0.0578, -0.0004, -0.0005],
        [ 0.0108,  0.0027,  0.0095,  ...,  0.0112,  0.0301,  0.0060],
        [-0.0036,  0.0198, -0.0087,  ..., -0.0007,  0.0001,  0.0485]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3047, -4.9297,  4.3984,  ..., -4.0039,  0.0853, -0.8096]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 14:28:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for raphael was known for their work as a  painter
kepler was known for their work as a  mathematician
aristotle was known for their work as a  philosopher
hume was known for their work as a  philosopher
euler was known for their work as a  mathematician
newton was known for their work as a  scientist
mencius was known for their work as a  philosopher
dickens was known for their work as a 
2024-07-27 14:28:13 root INFO     [order_1_approx] starting weight calculation for euler was known for their work as a  mathematician
aristotle was known for their work as a  philosopher
hume was known for their work as a  philosopher
raphael was known for their work as a  painter
dickens was known for their work as a  novelist
mencius was known for their work as a  philosopher
newton was known for their work as a  scientist
kepler was known for their work as a 
2024-07-27 14:28:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 14:30:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0238, -0.1919,  0.2430,  ..., -0.0464, -0.0082,  0.4570],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7402, -5.8828,  1.8662,  ..., -7.0781,  0.4141, -0.2256],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0834,  0.0070,  0.0109,  ..., -0.0031, -0.0147, -0.0060],
        [-0.0044,  0.0437, -0.0029,  ...,  0.0019,  0.0075,  0.0125],
        [ 0.0124,  0.0248,  0.0721,  ...,  0.0051,  0.0088, -0.0010],
        ...,
        [-0.0009, -0.0034, -0.0125,  ...,  0.0646,  0.0251, -0.0061],
        [-0.0136,  0.0068, -0.0099,  ..., -0.0007,  0.0445,  0.0032],
        [ 0.0056,  0.0130,  0.0072,  ...,  0.0071, -0.0084,  0.0591]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7256, -5.9297,  1.5742,  ..., -6.5977,  0.5171, -0.2534]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 14:30:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for euler was known for their work as a  mathematician
aristotle was known for their work as a  philosopher
hume was known for their work as a  philosopher
raphael was known for their work as a  painter
dickens was known for their work as a  novelist
mencius was known for their work as a  philosopher
newton was known for their work as a  scientist
kepler was known for their work as a 
2024-07-27 14:30:33 root INFO     [order_1_approx] starting weight calculation for dickens was known for their work as a  novelist
aristotle was known for their work as a  philosopher
raphael was known for their work as a  painter
kepler was known for their work as a  mathematician
euler was known for their work as a  mathematician
newton was known for their work as a  scientist
mencius was known for their work as a  philosopher
hume was known for their work as a 
2024-07-27 14:30:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 14:32:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1107,  0.1957,  0.1733,  ...,  0.1155,  0.0621,  0.2360],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7910, -3.2227,  3.2266,  ..., -5.3750, -0.1240, -2.0000],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.8552e-02,  4.4250e-03, -5.7449e-03,  ...,  2.4445e-02,
         -5.6229e-03,  9.1019e-03],
        [ 1.0078e-02,  5.6885e-02,  2.1935e-04,  ..., -3.1986e-03,
         -1.6220e-02,  5.7335e-03],
        [ 1.1375e-02, -1.4999e-02,  9.4482e-02,  ..., -2.6520e-02,
          2.6291e-02, -1.3474e-02],
        ...,
        [ 2.2385e-02,  4.6768e-03, -7.1793e-03,  ...,  9.6436e-02,
          1.0025e-02,  1.1589e-02],
        [ 4.1313e-03,  8.6365e-03,  4.0131e-03,  ...,  1.5900e-02,
          6.4148e-02, -4.8218e-03],
        [-1.2207e-03,  1.3527e-02, -1.0437e-02,  ..., -7.6294e-05,
         -3.2593e-02,  8.3984e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8481, -3.3750,  2.8516,  ..., -5.6055, -0.2192, -1.7510]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 14:32:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for dickens was known for their work as a  novelist
aristotle was known for their work as a  philosopher
raphael was known for their work as a  painter
kepler was known for their work as a  mathematician
euler was known for their work as a  mathematician
newton was known for their work as a  scientist
mencius was known for their work as a  philosopher
hume was known for their work as a 
2024-07-27 14:32:46 root INFO     [order_1_approx] starting weight calculation for mencius was known for their work as a  philosopher
kepler was known for their work as a  mathematician
dickens was known for their work as a  novelist
euler was known for their work as a  mathematician
aristotle was known for their work as a  philosopher
hume was known for their work as a  philosopher
newton was known for their work as a  scientist
raphael was known for their work as a 
2024-07-27 14:32:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 14:34:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4980, -0.3511,  0.1124,  ...,  0.0701, -0.1003,  0.0566],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2051, -7.6406,  2.4414,  ..., -6.7773, -0.7295, -2.3438],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0564, -0.0115, -0.0114,  ...,  0.0095, -0.0115,  0.0077],
        [ 0.0278,  0.0287, -0.0033,  ..., -0.0201, -0.0166, -0.0035],
        [ 0.0094, -0.0060,  0.0711,  ..., -0.0086,  0.0039,  0.0109],
        ...,
        [-0.0066,  0.0137, -0.0084,  ...,  0.0579,  0.0290, -0.0033],
        [ 0.0112,  0.0026, -0.0032,  ...,  0.0085,  0.0334,  0.0050],
        [-0.0057,  0.0201, -0.0163,  ..., -0.0189, -0.0107,  0.0424]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7676, -7.1602,  2.1113,  ..., -6.6211, -0.5430, -2.0371]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 14:34:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for mencius was known for their work as a  philosopher
kepler was known for their work as a  mathematician
dickens was known for their work as a  novelist
euler was known for their work as a  mathematician
aristotle was known for their work as a  philosopher
hume was known for their work as a  philosopher
newton was known for their work as a  scientist
raphael was known for their work as a 
2024-07-27 14:34:58 root INFO     [order_1_approx] starting weight calculation for hume was known for their work as a  philosopher
kepler was known for their work as a  mathematician
euler was known for their work as a  mathematician
mencius was known for their work as a  philosopher
newton was known for their work as a  scientist
dickens was known for their work as a  novelist
raphael was known for their work as a  painter
aristotle was known for their work as a 
2024-07-27 14:34:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 14:37:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1266, -0.4272, -0.6812,  ...,  0.0658, -0.2993,  0.0452],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6113, -5.7500,  2.3711,  ..., -7.8281, -0.3176, -2.0039],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0304, -0.0021,  0.0032,  ...,  0.0065, -0.0083,  0.0055],
        [-0.0073,  0.0070, -0.0043,  ..., -0.0055, -0.0001, -0.0021],
        [ 0.0062,  0.0012,  0.0348,  ...,  0.0067, -0.0012,  0.0009],
        ...,
        [ 0.0198, -0.0085, -0.0052,  ...,  0.0300,  0.0006,  0.0013],
        [ 0.0034,  0.0249, -0.0009,  ...,  0.0101,  0.0189, -0.0061],
        [-0.0095,  0.0047, -0.0008,  ..., -0.0135, -0.0111,  0.0344]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6445, -5.8086,  2.4199,  ..., -7.7539, -0.2878, -2.2246]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 14:37:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for hume was known for their work as a  philosopher
kepler was known for their work as a  mathematician
euler was known for their work as a  mathematician
mencius was known for their work as a  philosopher
newton was known for their work as a  scientist
dickens was known for their work as a  novelist
raphael was known for their work as a  painter
aristotle was known for their work as a 
2024-07-27 14:37:10 root INFO     [order_1_approx] starting weight calculation for hume was known for their work as a  philosopher
dickens was known for their work as a  novelist
mencius was known for their work as a  philosopher
kepler was known for their work as a  mathematician
raphael was known for their work as a  painter
aristotle was known for their work as a  philosopher
newton was known for their work as a  scientist
euler was known for their work as a 
2024-07-27 14:37:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 14:39:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0321, -0.0086, -0.0950,  ..., -0.1936, -0.3667,  0.0476],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0811, -1.3945, -1.0918,  ..., -5.7148, -0.0781, -0.7510],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0440, -0.0244, -0.0180,  ..., -0.0111, -0.0110,  0.0005],
        [ 0.0079,  0.0353, -0.0093,  ..., -0.0006, -0.0131,  0.0074],
        [ 0.0376,  0.0073,  0.0865,  ..., -0.0127,  0.0057, -0.0153],
        ...,
        [ 0.0219,  0.0034, -0.0112,  ...,  0.0832,  0.0127,  0.0044],
        [ 0.0131,  0.0220,  0.0053,  ...,  0.0128,  0.0537, -0.0339],
        [-0.0062,  0.0062, -0.0059,  ..., -0.0043, -0.0159,  0.0746]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1497, -1.4561, -1.0996,  ..., -5.4688,  0.0734, -0.7041]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 14:39:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for hume was known for their work as a  philosopher
dickens was known for their work as a  novelist
mencius was known for their work as a  philosopher
kepler was known for their work as a  mathematician
raphael was known for their work as a  painter
aristotle was known for their work as a  philosopher
newton was known for their work as a  scientist
euler was known for their work as a 
2024-07-27 14:39:31 root INFO     [order_1_approx] starting weight calculation for mencius was known for their work as a  philosopher
kepler was known for their work as a  mathematician
hume was known for their work as a  philosopher
aristotle was known for their work as a  philosopher
euler was known for their work as a  mathematician
raphael was known for their work as a  painter
dickens was known for their work as a  novelist
newton was known for their work as a 
2024-07-27 14:39:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 14:41:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2639, -0.2607,  0.0663,  ...,  0.0350, -0.1240,  0.6172],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8716, -4.3984,  1.1104,  ..., -7.7344,  0.5488, -1.4268],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0515,  0.0105,  0.0082,  ..., -0.0043, -0.0314,  0.0076],
        [ 0.0019,  0.0312,  0.0021,  ...,  0.0153,  0.0108, -0.0029],
        [ 0.0080, -0.0150,  0.0759,  ..., -0.0070,  0.0030,  0.0098],
        ...,
        [ 0.0008,  0.0243, -0.0011,  ...,  0.0557,  0.0134, -0.0070],
        [ 0.0072,  0.0138, -0.0061,  ...,  0.0281,  0.0397, -0.0081],
        [-0.0142,  0.0057,  0.0053,  ..., -0.0271, -0.0152,  0.0579]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9507, -4.3672,  1.1992,  ..., -7.3359,  0.3770, -1.3486]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 14:41:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for mencius was known for their work as a  philosopher
kepler was known for their work as a  mathematician
hume was known for their work as a  philosopher
aristotle was known for their work as a  philosopher
euler was known for their work as a  mathematician
raphael was known for their work as a  painter
dickens was known for their work as a  novelist
newton was known for their work as a 
2024-07-27 14:41:49 root INFO     [order_1_approx] starting weight calculation for aristotle was known for their work as a  philosopher
hume was known for their work as a  philosopher
raphael was known for their work as a  painter
dickens was known for their work as a  novelist
euler was known for their work as a  mathematician
kepler was known for their work as a  mathematician
newton was known for their work as a  scientist
mencius was known for their work as a 
2024-07-27 14:41:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 14:44:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0372, -0.0909, -0.2986,  ...,  0.5732, -0.2512,  0.2915],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ -0.9121,  -4.5703,   5.0000,  ..., -10.5312,   1.6445,   0.9224],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0412,  0.0031,  0.0018,  ..., -0.0097, -0.0158,  0.0063],
        [-0.0047,  0.0414, -0.0006,  ..., -0.0044, -0.0055,  0.0021],
        [ 0.0074,  0.0134,  0.0515,  ..., -0.0204,  0.0080,  0.0134],
        ...,
        [ 0.0307, -0.0007,  0.0080,  ...,  0.0584,  0.0089, -0.0186],
        [-0.0003,  0.0287, -0.0157,  ...,  0.0013,  0.0486, -0.0088],
        [-0.0063,  0.0348, -0.0294,  ...,  0.0217, -0.0115,  0.0655]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ -0.8247,  -4.6484,   4.5039,  ..., -10.3594,   1.4336,   1.2168]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 14:44:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for aristotle was known for their work as a  philosopher
hume was known for their work as a  philosopher
raphael was known for their work as a  painter
dickens was known for their work as a  novelist
euler was known for their work as a  mathematician
kepler was known for their work as a  mathematician
newton was known for their work as a  scientist
mencius was known for their work as a 
2024-07-27 14:44:08 root INFO     total operator prediction time: 1095.8443820476532 seconds
2024-07-27 14:44:08 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on male - female
2024-07-27 14:44:08 root INFO     building operator male - female
2024-07-27 14:44:08 root INFO     [order_1_approx] starting weight calculation for A female groom is known as a bride
A female sir is known as a madam
A female superman is known as a superwoman
A female lion is known as a lioness
A female ram is known as a ewe
A female grandfather is known as a grandmother
A female uncle is known as a aunt
A female boar is known as a
2024-07-27 14:44:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 14:46:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6621, -0.1965, -0.0313,  ...,  0.2615, -0.4402,  0.3755],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9219, -4.2812, -0.9565,  ..., -1.0176, -0.7617,  0.6221],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0595, -0.0037, -0.0002,  ...,  0.0247, -0.0188, -0.0315],
        [ 0.0087,  0.0748, -0.0032,  ...,  0.0352,  0.0168, -0.0288],
        [ 0.0089, -0.0159,  0.0532,  ...,  0.0100, -0.0187, -0.0105],
        ...,
        [-0.0406, -0.0148, -0.0111,  ...,  0.0656, -0.0030, -0.0044],
        [ 0.0046,  0.0343,  0.0125,  ...,  0.0094,  0.0344, -0.0081],
        [ 0.0219, -0.0188, -0.0237,  ..., -0.0166,  0.0007,  0.0667]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0000, -4.3125, -1.0273,  ..., -1.1455, -0.9463,  0.7422]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 14:46:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female groom is known as a bride
A female sir is known as a madam
A female superman is known as a superwoman
A female lion is known as a lioness
A female ram is known as a ewe
A female grandfather is known as a grandmother
A female uncle is known as a aunt
A female boar is known as a
2024-07-27 14:46:29 root INFO     [order_1_approx] starting weight calculation for A female groom is known as a bride
A female grandfather is known as a grandmother
A female superman is known as a superwoman
A female sir is known as a madam
A female lion is known as a lioness
A female boar is known as a sow
A female ram is known as a ewe
A female uncle is known as a
2024-07-27 14:46:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 14:48:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1519,  0.5972,  0.2942,  ..., -0.0828, -0.1807, -0.0668],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3906, -0.7671, -0.3438,  ...,  0.3154, -4.9609, -1.4268],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0413, -0.0040,  0.0464,  ...,  0.0346, -0.0263,  0.0258],
        [ 0.0226,  0.0327, -0.0044,  ...,  0.0024,  0.0030, -0.0107],
        [ 0.0086, -0.0225,  0.0407,  ..., -0.0026,  0.0147, -0.0145],
        ...,
        [-0.0196,  0.0259,  0.0081,  ...,  0.0479, -0.0050, -0.0048],
        [-0.0069, -0.0073,  0.0031,  ...,  0.0363,  0.0150,  0.0121],
        [-0.0006,  0.0012,  0.0032,  ...,  0.0156,  0.0207,  0.0285]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5098, -0.3459, -0.0981,  ..., -0.3081, -5.4805, -1.5791]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 14:48:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female groom is known as a bride
A female grandfather is known as a grandmother
A female superman is known as a superwoman
A female sir is known as a madam
A female lion is known as a lioness
A female boar is known as a sow
A female ram is known as a ewe
A female uncle is known as a
2024-07-27 14:48:48 root INFO     [order_1_approx] starting weight calculation for A female uncle is known as a aunt
A female superman is known as a superwoman
A female lion is known as a lioness
A female grandfather is known as a grandmother
A female boar is known as a sow
A female sir is known as a madam
A female ram is known as a ewe
A female groom is known as a
2024-07-27 14:48:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 14:51:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.8018,  0.7568, -0.1777,  ..., -0.2087, -0.5015,  0.3262],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8984, -5.3672, -1.4033,  ..., -2.6172, -2.7812,  1.3623],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0435, -0.0027,  0.0067,  ...,  0.0265, -0.0043, -0.0196],
        [ 0.0300,  0.0641,  0.0183,  ...,  0.0185,  0.0198,  0.0034],
        [ 0.0070, -0.0181,  0.0560,  ..., -0.0339, -0.0029, -0.0036],
        ...,
        [-0.0295,  0.0325, -0.0045,  ...,  0.0486,  0.0224, -0.0123],
        [-0.0087,  0.0084, -0.0076,  ...,  0.0220,  0.0293,  0.0117],
        [ 0.0217, -0.0205, -0.0124,  ..., -0.0439,  0.0092,  0.0622]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7988, -4.7148, -1.4053,  ..., -2.1367, -2.4766,  1.1514]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 14:51:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female uncle is known as a aunt
A female superman is known as a superwoman
A female lion is known as a lioness
A female grandfather is known as a grandmother
A female boar is known as a sow
A female sir is known as a madam
A female ram is known as a ewe
A female groom is known as a
2024-07-27 14:51:09 root INFO     [order_1_approx] starting weight calculation for A female grandfather is known as a grandmother
A female sir is known as a madam
A female boar is known as a sow
A female groom is known as a bride
A female lion is known as a lioness
A female superman is known as a superwoman
A female uncle is known as a aunt
A female ram is known as a
2024-07-27 14:51:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 14:53:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3521, -0.0670, -0.2959,  ...,  0.3650, -0.4226,  0.2185],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9277, -1.3330,  0.8428,  ...,  1.8125, -2.3789, -1.6895],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0750,  0.0027, -0.0104,  ..., -0.0122, -0.0108, -0.0093],
        [ 0.0195,  0.0540,  0.0032,  ...,  0.0338,  0.0199, -0.0406],
        [-0.0013,  0.0038,  0.0660,  ..., -0.0025, -0.0097, -0.0244],
        ...,
        [-0.0375, -0.0109, -0.0166,  ...,  0.0762,  0.0050, -0.0248],
        [ 0.0300,  0.0297, -0.0140,  ..., -0.0260,  0.0233, -0.0103],
        [ 0.0077, -0.0266,  0.0044,  ..., -0.0297,  0.0152,  0.0419]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.3906, -1.0586,  0.5762,  ...,  2.1875, -2.5508, -1.6260]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 14:53:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female grandfather is known as a grandmother
A female sir is known as a madam
A female boar is known as a sow
A female groom is known as a bride
A female lion is known as a lioness
A female superman is known as a superwoman
A female uncle is known as a aunt
A female ram is known as a
2024-07-27 14:53:27 root INFO     [order_1_approx] starting weight calculation for A female lion is known as a lioness
A female groom is known as a bride
A female sir is known as a madam
A female superman is known as a superwoman
A female uncle is known as a aunt
A female ram is known as a ewe
A female boar is known as a sow
A female grandfather is known as a
2024-07-27 14:53:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 14:55:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5122,  0.4937,  0.1396,  ...,  0.0883, -0.2065, -0.2798],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4688, -1.0371, -0.2305,  ..., -0.0779, -4.2148, -2.9141],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0229, -0.0133,  0.0257,  ...,  0.0611, -0.0187,  0.0224],
        [ 0.0182,  0.0277, -0.0072,  ...,  0.0127, -0.0006, -0.0047],
        [-0.0047, -0.0019,  0.0530,  ...,  0.0259, -0.0008,  0.0064],
        ...,
        [-0.0040,  0.0115, -0.0163,  ...,  0.0399, -0.0035, -0.0032],
        [ 0.0086, -0.0099,  0.0039,  ...,  0.0046,  0.0125,  0.0216],
        [-0.0135,  0.0024,  0.0003,  ...,  0.0181,  0.0207,  0.0343]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8145, -1.0332, -0.4111,  ..., -0.2340, -4.2656, -3.2812]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 14:55:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female lion is known as a lioness
A female groom is known as a bride
A female sir is known as a madam
A female superman is known as a superwoman
A female uncle is known as a aunt
A female ram is known as a ewe
A female boar is known as a sow
A female grandfather is known as a
2024-07-27 14:55:45 root INFO     [order_1_approx] starting weight calculation for A female groom is known as a bride
A female superman is known as a superwoman
A female ram is known as a ewe
A female sir is known as a madam
A female boar is known as a sow
A female grandfather is known as a grandmother
A female uncle is known as a aunt
A female lion is known as a
2024-07-27 14:55:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 14:58:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.9590,  0.0236, -0.0271,  ...,  0.2739, -0.5181,  0.0508],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5039, -6.4609, -0.8545,  ...,  0.2100, -2.4570,  0.3892],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0403, -0.0019,  0.0064,  ...,  0.0068, -0.0209, -0.0104],
        [-0.0150,  0.0383,  0.0062,  ...,  0.0205,  0.0232, -0.0190],
        [-0.0121,  0.0130,  0.0510,  ..., -0.0231, -0.0037, -0.0355],
        ...,
        [-0.0205,  0.0206,  0.0189,  ...,  0.0589,  0.0196, -0.0143],
        [ 0.0015,  0.0078,  0.0128,  ...,  0.0109,  0.0184,  0.0044],
        [ 0.0108, -0.0169, -0.0207,  ..., -0.0326,  0.0059,  0.0328]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0312, -6.2539, -0.7432,  ...,  0.4214, -2.4863,  0.1781]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 14:58:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female groom is known as a bride
A female superman is known as a superwoman
A female ram is known as a ewe
A female sir is known as a madam
A female boar is known as a sow
A female grandfather is known as a grandmother
A female uncle is known as a aunt
A female lion is known as a
2024-07-27 14:58:05 root INFO     [order_1_approx] starting weight calculation for A female uncle is known as a aunt
A female ram is known as a ewe
A female lion is known as a lioness
A female grandfather is known as a grandmother
A female groom is known as a bride
A female sir is known as a madam
A female boar is known as a sow
A female superman is known as a
2024-07-27 14:58:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 15:00:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7026,  0.5312,  0.1052,  ...,  0.1523, -0.3672,  0.1227],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.2266, -3.9375,  0.8262,  ...,  0.5518, -2.2832,  2.0840],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0413, -0.0372,  0.0279,  ...,  0.0307, -0.0166,  0.0005],
        [ 0.0002,  0.0418,  0.0014,  ...,  0.0142,  0.0261, -0.0078],
        [ 0.0140,  0.0239,  0.0543,  ..., -0.0066,  0.0033, -0.0103],
        ...,
        [ 0.0237,  0.0026, -0.0219,  ...,  0.0716, -0.0210,  0.0059],
        [-0.0011, -0.0073, -0.0048,  ...,  0.0095,  0.0239,  0.0170],
        [-0.0027, -0.0310, -0.0052,  ..., -0.0129,  0.0145,  0.0338]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.9570, -3.6426,  0.6450,  ...,  0.7129, -2.0684,  2.0918]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 15:00:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female uncle is known as a aunt
A female ram is known as a ewe
A female lion is known as a lioness
A female grandfather is known as a grandmother
A female groom is known as a bride
A female sir is known as a madam
A female boar is known as a sow
A female superman is known as a
2024-07-27 15:00:25 root INFO     [order_1_approx] starting weight calculation for A female boar is known as a sow
A female ram is known as a ewe
A female uncle is known as a aunt
A female lion is known as a lioness
A female grandfather is known as a grandmother
A female groom is known as a bride
A female superman is known as a superwoman
A female sir is known as a
2024-07-27 15:00:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 15:02:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4958,  0.4736, -0.0465,  ...,  0.2622, -0.1036,  0.2668],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.7891, -2.6602, -1.8711,  ...,  0.0186, -3.4316, -4.2969],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0728, -0.0137,  0.0323,  ...,  0.0238, -0.0011, -0.0034],
        [ 0.0001,  0.0249, -0.0018,  ...,  0.0209,  0.0340, -0.0220],
        [ 0.0512, -0.0081,  0.0670,  ..., -0.0343,  0.0090,  0.0222],
        ...,
        [-0.0049,  0.0262,  0.0278,  ...,  0.0911,  0.0264, -0.0479],
        [ 0.0205, -0.0134, -0.0086,  ...,  0.0192,  0.0315,  0.0113],
        [ 0.0223, -0.0088, -0.0155,  ...,  0.0040,  0.0170,  0.0323]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.4375, -2.3633, -1.7500,  ..., -0.1526, -3.9023, -3.8262]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 15:02:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female boar is known as a sow
A female ram is known as a ewe
A female uncle is known as a aunt
A female lion is known as a lioness
A female grandfather is known as a grandmother
A female groom is known as a bride
A female superman is known as a superwoman
A female sir is known as a
2024-07-27 15:02:41 root INFO     total operator prediction time: 1113.4366669654846 seconds
2024-07-27 15:02:41 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - shelter
2024-07-27 15:02:41 root INFO     building operator animal - shelter
2024-07-27 15:02:42 root INFO     [order_1_approx] starting weight calculation for The place chimpanzee lives in is called grove
The place mouse lives in is called nest
The place hippopotamus lives in is called river
The place beaver lives in is called dam
The place rabbit lives in is called burrow
The place locust lives in is called nest
The place bee lives in is called hive
The place lion lives in is called
2024-07-27 15:02:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 15:05:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4817, -0.0807,  0.0629,  ...,  0.4873,  0.0073, -0.0897],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([  6.0781, -10.1719,   0.8467,  ...,   0.0959,  -0.3950,  -1.9883],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0407, -0.0098,  0.0113,  ...,  0.0297,  0.0020,  0.0164],
        [ 0.0013,  0.0279,  0.0259,  ...,  0.0165,  0.0059, -0.0247],
        [-0.0156,  0.0204,  0.0582,  ..., -0.0025, -0.0260, -0.0056],
        ...,
        [-0.0040, -0.0056,  0.0238,  ...,  0.0524,  0.0267, -0.0165],
        [ 0.0126, -0.0020,  0.0078,  ...,  0.0134,  0.0348, -0.0055],
        [-0.0032, -0.0247,  0.0012,  ..., -0.0090,  0.0009,  0.0508]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 6.1562, -9.7188,  0.6655,  ...,  0.0306, -0.5933, -1.8701]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 15:05:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place chimpanzee lives in is called grove
The place mouse lives in is called nest
The place hippopotamus lives in is called river
The place beaver lives in is called dam
The place rabbit lives in is called burrow
The place locust lives in is called nest
The place bee lives in is called hive
The place lion lives in is called
2024-07-27 15:05:01 root INFO     [order_1_approx] starting weight calculation for The place mouse lives in is called nest
The place lion lives in is called den
The place hippopotamus lives in is called river
The place bee lives in is called hive
The place rabbit lives in is called burrow
The place beaver lives in is called dam
The place locust lives in is called nest
The place chimpanzee lives in is called
2024-07-27 15:05:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 15:07:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3875, -0.3420, -0.0543,  ..., -0.0610, -0.4150,  0.0366],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4648, -5.8672,  0.8516,  ...,  0.3564, -2.4141,  0.5195],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0102, -0.0010, -0.0048,  ..., -0.0011, -0.0083, -0.0030],
        [-0.0042,  0.0106,  0.0021,  ...,  0.0086,  0.0026,  0.0033],
        [-0.0043,  0.0054,  0.0104,  ..., -0.0026,  0.0003, -0.0004],
        ...,
        [-0.0001,  0.0099,  0.0084,  ...,  0.0181,  0.0059,  0.0057],
        [ 0.0043,  0.0031, -0.0002,  ..., -0.0058,  0.0044,  0.0069],
        [-0.0035, -0.0002, -0.0050,  ..., -0.0029, -0.0024,  0.0121]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5391, -5.8906,  0.7261,  ...,  0.3193, -2.4277,  0.4595]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 15:07:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place mouse lives in is called nest
The place lion lives in is called den
The place hippopotamus lives in is called river
The place bee lives in is called hive
The place rabbit lives in is called burrow
The place beaver lives in is called dam
The place locust lives in is called nest
The place chimpanzee lives in is called
2024-07-27 15:07:22 root INFO     [order_1_approx] starting weight calculation for The place bee lives in is called hive
The place mouse lives in is called nest
The place lion lives in is called den
The place beaver lives in is called dam
The place chimpanzee lives in is called grove
The place locust lives in is called nest
The place hippopotamus lives in is called river
The place rabbit lives in is called
2024-07-27 15:07:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 15:09:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2357, -0.4004, -0.1202,  ...,  0.1605, -0.4238, -0.2659],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7930, -4.9297,  1.5566,  ..., -0.3071,  0.7217, -0.7695],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0314, -0.0017,  0.0010,  ...,  0.0112, -0.0078,  0.0044],
        [-0.0161,  0.0271,  0.0089,  ..., -0.0019, -0.0067, -0.0055],
        [-0.0068,  0.0095,  0.0385,  ...,  0.0027, -0.0121,  0.0004],
        ...,
        [ 0.0059, -0.0006,  0.0107,  ...,  0.0238,  0.0042,  0.0024],
        [ 0.0051,  0.0094,  0.0008,  ...,  0.0022,  0.0233,  0.0084],
        [-0.0006,  0.0020, -0.0059,  ..., -0.0099, -0.0232,  0.0244]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9297, -4.8711,  1.3867,  ..., -0.4727,  0.7036, -0.7500]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 15:09:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place bee lives in is called hive
The place mouse lives in is called nest
The place lion lives in is called den
The place beaver lives in is called dam
The place chimpanzee lives in is called grove
The place locust lives in is called nest
The place hippopotamus lives in is called river
The place rabbit lives in is called
2024-07-27 15:09:43 root INFO     [order_1_approx] starting weight calculation for The place beaver lives in is called dam
The place hippopotamus lives in is called river
The place rabbit lives in is called burrow
The place lion lives in is called den
The place locust lives in is called nest
The place chimpanzee lives in is called grove
The place bee lives in is called hive
The place mouse lives in is called
2024-07-27 15:09:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 15:11:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0354, -0.4131,  0.0577,  ...,  0.2062, -0.3271, -0.1659],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0254, -2.5664,  1.8408,  ...,  0.1138, -1.3662,  1.2471],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0594, -0.0180,  0.0191,  ...,  0.0175, -0.0116, -0.0057],
        [-0.0246,  0.0668, -0.0083,  ..., -0.0027,  0.0295, -0.0163],
        [-0.0187,  0.0342,  0.0547,  ..., -0.0138, -0.0079,  0.0171],
        ...,
        [ 0.0068, -0.0040,  0.0125,  ...,  0.0455,  0.0228, -0.0113],
        [ 0.0056,  0.0176, -0.0138,  ...,  0.0088,  0.0227,  0.0061],
        [-0.0126, -0.0029, -0.0011,  ...,  0.0066, -0.0147,  0.0618]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7744, -2.6289,  1.6035,  ..., -0.1814, -1.2832,  0.8496]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 15:12:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place beaver lives in is called dam
The place hippopotamus lives in is called river
The place rabbit lives in is called burrow
The place lion lives in is called den
The place locust lives in is called nest
The place chimpanzee lives in is called grove
The place bee lives in is called hive
The place mouse lives in is called
2024-07-27 15:12:00 root INFO     [order_1_approx] starting weight calculation for The place locust lives in is called nest
The place bee lives in is called hive
The place lion lives in is called den
The place chimpanzee lives in is called grove
The place mouse lives in is called nest
The place hippopotamus lives in is called river
The place rabbit lives in is called burrow
The place beaver lives in is called
2024-07-27 15:12:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 15:14:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4910, -0.2595,  0.0375,  ...,  0.1919, -0.4255,  0.1180],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3018, -5.1523, -1.2539,  ..., -1.8965,  0.5215, -0.9385],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0757, -0.0146, -0.0138,  ...,  0.0191, -0.0285, -0.0321],
        [-0.0050,  0.0603,  0.0043,  ...,  0.0067,  0.0043, -0.0384],
        [-0.0021,  0.0129,  0.0504,  ..., -0.0165, -0.0224, -0.0113],
        ...,
        [-0.0004,  0.0201,  0.0231,  ...,  0.0668,  0.0015, -0.0038],
        [ 0.0184, -0.0043,  0.0208,  ...,  0.0125,  0.0386, -0.0105],
        [-0.0034, -0.0013, -0.0269,  ..., -0.0067, -0.0247,  0.0566]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1621, -5.1797, -1.3262,  ..., -1.5615,  0.1018, -0.3096]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 15:14:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place locust lives in is called nest
The place bee lives in is called hive
The place lion lives in is called den
The place chimpanzee lives in is called grove
The place mouse lives in is called nest
The place hippopotamus lives in is called river
The place rabbit lives in is called burrow
The place beaver lives in is called
2024-07-27 15:14:20 root INFO     [order_1_approx] starting weight calculation for The place lion lives in is called den
The place chimpanzee lives in is called grove
The place rabbit lives in is called burrow
The place mouse lives in is called nest
The place beaver lives in is called dam
The place hippopotamus lives in is called river
The place locust lives in is called nest
The place bee lives in is called
2024-07-27 15:14:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 15:16:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5283, -0.3389,  0.0634,  ...,  0.1432, -0.0769, -0.1719],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2617, -5.6836,  2.6777,  ..., -2.5547,  0.5303, -0.8252],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.7390e-02, -3.9253e-03,  9.8038e-03,  ...,  2.1271e-02,
         -5.6686e-03,  6.7520e-03],
        [-2.2491e-02,  3.8513e-02,  2.4246e-02,  ..., -7.7629e-04,
         -1.3000e-02, -2.1973e-02],
        [-1.2421e-02,  3.8177e-02,  6.3782e-02,  ...,  1.4404e-02,
         -3.2349e-02,  4.9591e-03],
        ...,
        [-5.6381e-03, -7.6294e-06,  1.1917e-02,  ...,  3.8788e-02,
          1.7776e-02, -6.1569e-03],
        [-1.1871e-02,  3.0518e-04, -6.4468e-04,  ...,  1.9913e-02,
          6.9656e-03,  1.0864e-02],
        [-1.0582e-02, -1.0849e-02, -1.3359e-02,  ..., -5.9738e-03,
         -2.5269e-02,  4.3365e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7285, -5.7891,  2.6797,  ..., -2.6797,  0.8193, -0.4634]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 15:16:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place lion lives in is called den
The place chimpanzee lives in is called grove
The place rabbit lives in is called burrow
The place mouse lives in is called nest
The place beaver lives in is called dam
The place hippopotamus lives in is called river
The place locust lives in is called nest
The place bee lives in is called
2024-07-27 15:16:42 root INFO     [order_1_approx] starting weight calculation for The place beaver lives in is called dam
The place rabbit lives in is called burrow
The place chimpanzee lives in is called grove
The place hippopotamus lives in is called river
The place lion lives in is called den
The place mouse lives in is called nest
The place bee lives in is called hive
The place locust lives in is called
2024-07-27 15:16:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 15:19:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2103, -0.3994,  0.2058,  ...,  0.4216, -0.3962, -0.0698],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.4414, -4.1484,  2.1289,  ...,  0.5918,  0.0624, -2.2148],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0419, -0.0344,  0.0146,  ...,  0.0327, -0.0130,  0.0325],
        [ 0.0118,  0.0493,  0.0449,  ...,  0.0326, -0.0008, -0.0145],
        [ 0.0180,  0.0591,  0.0802,  ...,  0.0085, -0.0569, -0.0017],
        ...,
        [-0.0141,  0.0067,  0.0228,  ...,  0.0951,  0.0185,  0.0095],
        [-0.0105,  0.0077,  0.0093,  ...,  0.0079,  0.0285,  0.0189],
        [-0.0126,  0.0047, -0.0042,  ...,  0.0036, -0.0248,  0.0708]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.4727, -4.3164,  2.1035,  ...,  0.1592,  0.0158, -2.4492]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 15:19:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place beaver lives in is called dam
The place rabbit lives in is called burrow
The place chimpanzee lives in is called grove
The place hippopotamus lives in is called river
The place lion lives in is called den
The place mouse lives in is called nest
The place bee lives in is called hive
The place locust lives in is called
2024-07-27 15:19:02 root INFO     [order_1_approx] starting weight calculation for The place chimpanzee lives in is called grove
The place bee lives in is called hive
The place lion lives in is called den
The place rabbit lives in is called burrow
The place beaver lives in is called dam
The place mouse lives in is called nest
The place locust lives in is called nest
The place hippopotamus lives in is called
2024-07-27 15:19:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 15:21:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5381, -0.3591,  0.3193,  ...,  0.2534, -0.3306, -0.2028],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.3477, -3.7539, -1.1475,  ..., -1.6768, -0.3064,  1.1670],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0179,  0.0001, -0.0021,  ...,  0.0090, -0.0024, -0.0054],
        [-0.0061,  0.0157,  0.0050,  ..., -0.0013,  0.0059,  0.0029],
        [-0.0047,  0.0044,  0.0172,  ..., -0.0031,  0.0001, -0.0071],
        ...,
        [-0.0009,  0.0078,  0.0097,  ...,  0.0124,  0.0097,  0.0030],
        [ 0.0049,  0.0088,  0.0132,  ..., -0.0030,  0.0091,  0.0041],
        [ 0.0016, -0.0011, -0.0064,  ...,  0.0005, -0.0021,  0.0172]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.3047, -3.7344, -1.1865,  ..., -1.6777, -0.3953,  1.0967]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 15:21:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place chimpanzee lives in is called grove
The place bee lives in is called hive
The place lion lives in is called den
The place rabbit lives in is called burrow
The place beaver lives in is called dam
The place mouse lives in is called nest
The place locust lives in is called nest
The place hippopotamus lives in is called
2024-07-27 15:21:21 root INFO     total operator prediction time: 1119.77925491333 seconds
2024-07-27 15:21:21 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on country - language
2024-07-27 15:21:21 root INFO     building operator country - language
2024-07-27 15:21:21 root INFO     [order_1_approx] starting weight calculation for The country of egypt primarily speaks the language of arabic
The country of bolivia primarily speaks the language of spanish
The country of kazakhstan primarily speaks the language of kazak
The country of nicaragua primarily speaks the language of spanish
The country of guam primarily speaks the language of english
The country of taiwan primarily speaks the language of chinese
The country of argentina primarily speaks the language of spanish
The country of moldova primarily speaks the language of
2024-07-27 15:21:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 15:23:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6367, -0.2808, -0.2324,  ...,  0.3699, -0.2175, -0.2146],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.9365, -5.0156, -0.6865,  ..., -4.6328, -0.6748, -1.0762],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0234, -0.0157, -0.0192,  ..., -0.0042,  0.0059, -0.0247],
        [-0.0079,  0.0209, -0.0048,  ..., -0.0002,  0.0088, -0.0133],
        [-0.0012, -0.0042,  0.0356,  ...,  0.0155, -0.0089,  0.0061],
        ...,
        [-0.0048, -0.0052, -0.0181,  ...,  0.0179,  0.0132,  0.0020],
        [ 0.0083, -0.0037,  0.0167,  ...,  0.0063,  0.0047, -0.0013],
        [ 0.0002, -0.0109, -0.0101,  ...,  0.0023,  0.0015,  0.0010]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.8818, -5.0977, -0.6338,  ..., -4.5469, -0.6353, -1.1182]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 15:23:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of egypt primarily speaks the language of arabic
The country of bolivia primarily speaks the language of spanish
The country of kazakhstan primarily speaks the language of kazak
The country of nicaragua primarily speaks the language of spanish
The country of guam primarily speaks the language of english
The country of taiwan primarily speaks the language of chinese
The country of argentina primarily speaks the language of spanish
The country of moldova primarily speaks the language of
2024-07-27 15:23:39 root INFO     [order_1_approx] starting weight calculation for The country of moldova primarily speaks the language of moldovan
The country of bolivia primarily speaks the language of spanish
The country of argentina primarily speaks the language of spanish
The country of kazakhstan primarily speaks the language of kazak
The country of egypt primarily speaks the language of arabic
The country of nicaragua primarily speaks the language of spanish
The country of taiwan primarily speaks the language of chinese
The country of guam primarily speaks the language of
2024-07-27 15:23:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 15:25:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1257, -0.2432, -0.1334,  ...,  0.5049, -0.5562,  0.1316],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7896,  0.9170,  2.0918,  ...,  0.0598, -1.9170, -2.8789],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.5391e-02,  1.9379e-02, -4.0970e-03,  ...,  2.0447e-03,
         -1.2573e-02, -2.5726e-02],
        [ 1.0796e-02,  5.3894e-02,  1.0384e-02,  ...,  1.1292e-02,
         -3.8872e-03, -1.4229e-02],
        [-7.5493e-03, -1.7761e-02,  6.1768e-02,  ..., -5.6267e-04,
          2.8854e-02, -1.4732e-02],
        ...,
        [ 2.6703e-05,  3.4302e-02,  1.1959e-03,  ...,  6.5491e-02,
          1.5594e-02, -1.2321e-02],
        [ 1.5459e-03, -1.5354e-03, -4.3716e-03,  ...,  1.0277e-02,
          2.7985e-02, -1.5343e-02],
        [ 1.7334e-02, -1.6022e-02, -5.5656e-03,  ...,  1.4084e-02,
         -1.2169e-03,  7.1777e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9883,  1.0615,  1.8379,  ..., -0.1619, -1.8311, -2.4199]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 15:26:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of moldova primarily speaks the language of moldovan
The country of bolivia primarily speaks the language of spanish
The country of argentina primarily speaks the language of spanish
The country of kazakhstan primarily speaks the language of kazak
The country of egypt primarily speaks the language of arabic
The country of nicaragua primarily speaks the language of spanish
The country of taiwan primarily speaks the language of chinese
The country of guam primarily speaks the language of
2024-07-27 15:26:01 root INFO     [order_1_approx] starting weight calculation for The country of taiwan primarily speaks the language of chinese
The country of egypt primarily speaks the language of arabic
The country of bolivia primarily speaks the language of spanish
The country of kazakhstan primarily speaks the language of kazak
The country of argentina primarily speaks the language of spanish
The country of moldova primarily speaks the language of moldovan
The country of guam primarily speaks the language of english
The country of nicaragua primarily speaks the language of
2024-07-27 15:26:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 15:28:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1317, -0.2834, -0.0815,  ...,  0.2993, -0.4897, -0.1742],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.2686, -2.1465,  1.2041,  ..., -0.2339, -1.2939, -3.8906],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0160,  0.0115,  0.0012,  ..., -0.0059, -0.0176, -0.0275],
        [ 0.0098,  0.0224,  0.0151,  ...,  0.0017, -0.0181, -0.0078],
        [-0.0025, -0.0072,  0.0279,  ...,  0.0171,  0.0055,  0.0200],
        ...,
        [-0.0198, -0.0068, -0.0098,  ...,  0.0098,  0.0165,  0.0266],
        [ 0.0026, -0.0068, -0.0022,  ..., -0.0076,  0.0057, -0.0169],
        [ 0.0069,  0.0073,  0.0051,  ...,  0.0072, -0.0013, -0.0004]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.2314, -2.3320,  1.1016,  ..., -0.4294, -1.3135, -3.9160]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 15:28:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of taiwan primarily speaks the language of chinese
The country of egypt primarily speaks the language of arabic
The country of bolivia primarily speaks the language of spanish
The country of kazakhstan primarily speaks the language of kazak
The country of argentina primarily speaks the language of spanish
The country of moldova primarily speaks the language of moldovan
The country of guam primarily speaks the language of english
The country of nicaragua primarily speaks the language of
2024-07-27 15:28:18 root INFO     [order_1_approx] starting weight calculation for The country of nicaragua primarily speaks the language of spanish
The country of moldova primarily speaks the language of moldovan
The country of egypt primarily speaks the language of arabic
The country of guam primarily speaks the language of english
The country of kazakhstan primarily speaks the language of kazak
The country of bolivia primarily speaks the language of spanish
The country of taiwan primarily speaks the language of chinese
The country of argentina primarily speaks the language of
2024-07-27 15:28:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 15:30:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3516, -0.0382, -0.1577,  ...,  0.2568, -0.3459, -0.1254],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2812, -2.8359,  0.8936,  ...,  0.9102, -0.0176, -1.7520],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.4765e-02, -1.0262e-02,  9.7847e-04,  ...,  9.7370e-04,
         -7.5455e-03, -2.2064e-02],
        [ 3.6125e-03,  1.3565e-02,  1.5991e-02,  ...,  4.4174e-03,
         -7.8659e-03, -1.5915e-02],
        [-2.8610e-03,  1.0307e-02,  3.0640e-02,  ...,  9.2087e-03,
          1.6815e-02,  1.2039e-02],
        ...,
        [-1.2802e-02, -2.2984e-03,  2.5272e-03,  ...,  2.2568e-02,
          1.7715e-02,  2.4292e-02],
        [ 1.1932e-02, -8.6594e-03, -6.0463e-04,  ..., -4.1771e-04,
          9.9640e-03, -1.2817e-02],
        [ 5.3787e-04, -8.7891e-03, -6.5117e-03,  ...,  4.1008e-03,
          4.4823e-05,  4.6921e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2383, -2.8262,  0.7539,  ...,  0.8311,  0.0295, -1.6748]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 15:30:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of nicaragua primarily speaks the language of spanish
The country of moldova primarily speaks the language of moldovan
The country of egypt primarily speaks the language of arabic
The country of guam primarily speaks the language of english
The country of kazakhstan primarily speaks the language of kazak
The country of bolivia primarily speaks the language of spanish
The country of taiwan primarily speaks the language of chinese
The country of argentina primarily speaks the language of
2024-07-27 15:30:34 root INFO     [order_1_approx] starting weight calculation for The country of kazakhstan primarily speaks the language of kazak
The country of taiwan primarily speaks the language of chinese
The country of guam primarily speaks the language of english
The country of nicaragua primarily speaks the language of spanish
The country of egypt primarily speaks the language of arabic
The country of argentina primarily speaks the language of spanish
The country of moldova primarily speaks the language of moldovan
The country of bolivia primarily speaks the language of
2024-07-27 15:30:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 15:32:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2484, -0.1293, -0.0129,  ...,  0.1490, -0.0332, -0.0300],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1328, -1.9043,  2.3594,  ...,  1.2930, -0.2129, -2.1699],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0125,  0.0005,  0.0003,  ..., -0.0017, -0.0112, -0.0159],
        [ 0.0028,  0.0085,  0.0104,  ...,  0.0022, -0.0048, -0.0040],
        [ 0.0037,  0.0089,  0.0313,  ...,  0.0075,  0.0029,  0.0117],
        ...,
        [-0.0110,  0.0039,  0.0110,  ...,  0.0199,  0.0054,  0.0149],
        [ 0.0146, -0.0071, -0.0038,  ..., -0.0019,  0.0086, -0.0106],
        [-0.0036, -0.0049, -0.0028,  ...,  0.0027, -0.0052,  0.0125]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0946, -2.0078,  2.3340,  ...,  1.2949, -0.1746, -2.0391]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 15:32:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of kazakhstan primarily speaks the language of kazak
The country of taiwan primarily speaks the language of chinese
The country of guam primarily speaks the language of english
The country of nicaragua primarily speaks the language of spanish
The country of egypt primarily speaks the language of arabic
The country of argentina primarily speaks the language of spanish
The country of moldova primarily speaks the language of moldovan
The country of bolivia primarily speaks the language of
2024-07-27 15:32:54 root INFO     [order_1_approx] starting weight calculation for The country of bolivia primarily speaks the language of spanish
The country of moldova primarily speaks the language of moldovan
The country of kazakhstan primarily speaks the language of kazak
The country of nicaragua primarily speaks the language of spanish
The country of argentina primarily speaks the language of spanish
The country of egypt primarily speaks the language of arabic
The country of guam primarily speaks the language of english
The country of taiwan primarily speaks the language of
2024-07-27 15:32:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 15:35:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3088, -0.0934,  0.3306,  ...,  0.5259, -0.0667,  0.2776],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.8018, -2.0391,  3.0254,  ..., -0.5615, -3.4961, -0.2344],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0365, -0.0137, -0.0073,  ...,  0.0034,  0.0105, -0.0188],
        [-0.0024,  0.0267,  0.0040,  ...,  0.0091, -0.0085, -0.0048],
        [-0.0068,  0.0044,  0.0487,  ...,  0.0030, -0.0101,  0.0172],
        ...,
        [-0.0044,  0.0089,  0.0040,  ...,  0.0383,  0.0065,  0.0032],
        [ 0.0232, -0.0023, -0.0101,  ...,  0.0007,  0.0134, -0.0205],
        [ 0.0151, -0.0016, -0.0150,  ...,  0.0113, -0.0023,  0.0244]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.4961, -2.1270,  2.3633,  ..., -0.5591, -3.3672, -0.1302]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 15:35:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of bolivia primarily speaks the language of spanish
The country of moldova primarily speaks the language of moldovan
The country of kazakhstan primarily speaks the language of kazak
The country of nicaragua primarily speaks the language of spanish
The country of argentina primarily speaks the language of spanish
The country of egypt primarily speaks the language of arabic
The country of guam primarily speaks the language of english
The country of taiwan primarily speaks the language of
2024-07-27 15:35:13 root INFO     [order_1_approx] starting weight calculation for The country of taiwan primarily speaks the language of chinese
The country of nicaragua primarily speaks the language of spanish
The country of moldova primarily speaks the language of moldovan
The country of kazakhstan primarily speaks the language of kazak
The country of bolivia primarily speaks the language of spanish
The country of guam primarily speaks the language of english
The country of argentina primarily speaks the language of spanish
The country of egypt primarily speaks the language of
2024-07-27 15:35:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 15:37:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1544, -0.0333,  0.0245,  ..., -0.0367, -0.3733, -0.0616],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.1895, -4.8125,  2.9688,  ..., -0.8926,  0.0381, -0.0195],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.6591e-02, -2.0081e-02, -3.9368e-03,  ...,  3.1586e-03,
         -8.1177e-03, -2.0203e-02],
        [-1.6851e-03,  2.9312e-02,  2.0126e-02,  ..., -1.9722e-03,
          2.2430e-03, -1.1093e-02],
        [-6.0234e-03,  1.9516e-02,  6.9702e-02,  ...,  2.2858e-02,
          5.8212e-03,  1.7365e-02],
        ...,
        [-2.7847e-02,  1.4629e-03, -4.9591e-03,  ...,  3.9978e-02,
          2.0798e-02,  1.7303e-02],
        [ 1.3321e-02, -1.3275e-02, -9.2506e-05,  ..., -1.8988e-03,
          1.8845e-02, -1.8951e-02],
        [ 5.1117e-03, -7.6981e-03, -1.0719e-03,  ...,  2.0966e-02,
         -3.4370e-03,  1.3008e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.0332, -4.6211,  2.8301,  ..., -1.0039,  0.1844, -0.0112]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 15:37:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of taiwan primarily speaks the language of chinese
The country of nicaragua primarily speaks the language of spanish
The country of moldova primarily speaks the language of moldovan
The country of kazakhstan primarily speaks the language of kazak
The country of bolivia primarily speaks the language of spanish
The country of guam primarily speaks the language of english
The country of argentina primarily speaks the language of spanish
The country of egypt primarily speaks the language of
2024-07-27 15:37:33 root INFO     [order_1_approx] starting weight calculation for The country of taiwan primarily speaks the language of chinese
The country of nicaragua primarily speaks the language of spanish
The country of guam primarily speaks the language of english
The country of moldova primarily speaks the language of moldovan
The country of bolivia primarily speaks the language of spanish
The country of egypt primarily speaks the language of arabic
The country of argentina primarily speaks the language of spanish
The country of kazakhstan primarily speaks the language of
2024-07-27 15:37:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 15:39:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2123, -0.1252, -0.0189,  ...,  0.0835, -0.4341, -0.0471],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.3701, -3.6875, -0.5366,  ..., -1.7861, -2.8086, -1.2861],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0100, -0.0040, -0.0074,  ...,  0.0046, -0.0081, -0.0089],
        [-0.0018,  0.0072,  0.0067,  ...,  0.0018, -0.0049, -0.0022],
        [ 0.0002,  0.0073,  0.0273,  ...,  0.0072, -0.0047,  0.0032],
        ...,
        [-0.0079, -0.0073, -0.0005,  ...,  0.0152,  0.0019,  0.0077],
        [ 0.0103,  0.0006,  0.0046,  ..., -0.0007,  0.0037, -0.0095],
        [-0.0005,  0.0008,  0.0017,  ...,  0.0043, -0.0058,  0.0029]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.2871, -3.7051, -0.5596,  ..., -1.6943, -2.7305, -1.2373]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 15:39:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of taiwan primarily speaks the language of chinese
The country of nicaragua primarily speaks the language of spanish
The country of guam primarily speaks the language of english
The country of moldova primarily speaks the language of moldovan
The country of bolivia primarily speaks the language of spanish
The country of egypt primarily speaks the language of arabic
The country of argentina primarily speaks the language of spanish
The country of kazakhstan primarily speaks the language of
2024-07-27 15:39:54 root INFO     total operator prediction time: 1112.4875588417053 seconds
2024-07-27 15:39:54 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on name - nationality
2024-07-27 15:39:54 root INFO     building operator name - nationality
2024-07-27 15:39:54 root INFO     [order_1_approx] starting weight calculation for caesar was roman
hitler was german
lavoisier was french
homer was greek
marx was german
depp was american
balzac was french
lennon was
2024-07-27 15:39:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 15:42:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4814,  0.2438, -0.0708,  ...,  0.2361, -0.4485,  0.4590],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.7969, -3.4375,  0.3774,  ..., -2.7109,  0.0400, -2.6406],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.6021e-02,  8.7204e-03,  2.6512e-03,  ...,  4.9782e-03,
          7.9155e-04, -1.9913e-03],
        [ 9.8267e-03,  5.0720e-02, -3.3073e-03,  ...,  1.4172e-03,
          1.2794e-02, -2.3254e-02],
        [ 1.8120e-05, -1.0117e-02,  6.4514e-02,  ...,  3.7727e-03,
         -1.0521e-02,  1.2360e-02],
        ...,
        [ 1.2674e-03,  5.2071e-03, -7.6141e-03,  ...,  7.2388e-02,
          1.1253e-02, -8.9874e-03],
        [ 3.3569e-04, -1.4519e-02,  1.0094e-02,  ..., -1.6937e-02,
          2.3483e-02,  1.6846e-02],
        [-4.6768e-03, -4.7188e-03,  8.9216e-04,  ...,  1.1292e-02,
         -3.7270e-03,  4.9377e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.8086, -3.3750, -0.0591,  ..., -2.7773,  0.2363, -2.8184]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 15:42:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for caesar was roman
hitler was german
lavoisier was french
homer was greek
marx was german
depp was american
balzac was french
lennon was
2024-07-27 15:42:15 root INFO     [order_1_approx] starting weight calculation for caesar was roman
lennon was english
balzac was french
lavoisier was french
homer was greek
hitler was german
marx was german
depp was
2024-07-27 15:42:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 15:44:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1746,  0.2766, -0.0431,  ...,  0.6533, -0.5879,  0.1466],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.3242, -2.9922,  0.9985,  ..., -2.4805,  0.3477, -1.9141],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0879, -0.0211, -0.0114,  ..., -0.0202,  0.0206, -0.0009],
        [-0.0135,  0.0643,  0.0232,  ...,  0.0271,  0.0054,  0.0020],
        [-0.0129,  0.0043,  0.0894,  ..., -0.0012,  0.0008,  0.0085],
        ...,
        [ 0.0222,  0.0184,  0.0124,  ...,  0.0919,  0.0012,  0.0177],
        [-0.0060,  0.0143, -0.0072,  ...,  0.0113,  0.0385, -0.0076],
        [ 0.0147,  0.0015, -0.0071,  ..., -0.0017, -0.0155,  0.0732]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.8828, -3.5879,  1.5400,  ..., -2.8066,  0.3933, -1.5654]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 15:44:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for caesar was roman
lennon was english
balzac was french
lavoisier was french
homer was greek
hitler was german
marx was german
depp was
2024-07-27 15:44:37 root INFO     [order_1_approx] starting weight calculation for balzac was french
marx was german
depp was american
lennon was english
homer was greek
hitler was german
caesar was roman
lavoisier was
2024-07-27 15:44:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 15:46:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2400,  0.3147, -0.2424,  ..., -0.0389,  0.1281,  0.5127],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.8008, -2.8555,  0.6631,  ..., -4.6211,  0.2637,  0.9648],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1045, -0.0043, -0.0195,  ..., -0.0235,  0.0242, -0.0007],
        [ 0.0120,  0.0965, -0.0020,  ...,  0.0323, -0.0122,  0.0109],
        [ 0.0359,  0.0029,  0.1071,  ..., -0.0275,  0.0238, -0.0117],
        ...,
        [ 0.0178, -0.0095, -0.0059,  ...,  0.1042, -0.0067, -0.0057],
        [ 0.0206,  0.0146,  0.0044,  ...,  0.0158,  0.0772, -0.0186],
        [-0.0154, -0.0028, -0.0102,  ...,  0.0144, -0.0091,  0.1115]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.9531, -3.2324,  0.4863,  ..., -4.7734, -0.0388,  1.0264]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 15:46:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for balzac was french
marx was german
depp was american
lennon was english
homer was greek
hitler was german
caesar was roman
lavoisier was
2024-07-27 15:46:59 root INFO     [order_1_approx] starting weight calculation for depp was american
balzac was french
lavoisier was french
homer was greek
caesar was roman
marx was german
lennon was english
hitler was
2024-07-27 15:46:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 15:49:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5103, -0.0017, -0.1086,  ...,  0.5723,  0.0601,  0.1720],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3262, -6.0039, -1.2715,  ..., -2.8418, -0.6748, -1.6289],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0630, -0.0131, -0.0168,  ..., -0.0064,  0.0011,  0.0044],
        [-0.0069,  0.0458,  0.0257,  ..., -0.0113,  0.0009, -0.0271],
        [ 0.0161, -0.0160,  0.0729,  ..., -0.0163,  0.0067,  0.0147],
        ...,
        [ 0.0031,  0.0129,  0.0040,  ...,  0.0682, -0.0129,  0.0005],
        [ 0.0100,  0.0104,  0.0260,  ..., -0.0257,  0.0412, -0.0195],
        [-0.0212, -0.0009,  0.0205,  ...,  0.0146, -0.0144,  0.0577]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5469, -5.9648, -1.4648,  ..., -3.0859, -0.5278, -1.6445]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 15:49:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for depp was american
balzac was french
lavoisier was french
homer was greek
caesar was roman
marx was german
lennon was english
hitler was
2024-07-27 15:49:19 root INFO     [order_1_approx] starting weight calculation for hitler was german
homer was greek
lennon was english
marx was german
depp was american
balzac was french
lavoisier was french
caesar was
2024-07-27 15:49:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 15:51:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1184,  0.0069, -0.3813,  ...,  0.2424, -0.6450,  0.4624],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7109, -4.3672, -0.0515,  ..., -1.9277,  0.6201, -1.5391],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0620, -0.0019, -0.0069,  ..., -0.0291,  0.0284,  0.0055],
        [ 0.0022,  0.0566,  0.0165,  ..., -0.0107, -0.0115, -0.0180],
        [ 0.0118, -0.0082,  0.0823,  ...,  0.0082,  0.0148,  0.0179],
        ...,
        [ 0.0133,  0.0119, -0.0033,  ...,  0.1100, -0.0068, -0.0086],
        [ 0.0190,  0.0071,  0.0250,  ..., -0.0054,  0.0521,  0.0137],
        [-0.0016,  0.0061,  0.0105,  ..., -0.0083, -0.0124,  0.0645]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2324, -4.5000,  0.1180,  ..., -2.2031,  0.7280, -1.7715]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 15:51:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for hitler was german
homer was greek
lennon was english
marx was german
depp was american
balzac was french
lavoisier was french
caesar was
2024-07-27 15:51:40 root INFO     [order_1_approx] starting weight calculation for lavoisier was french
marx was german
hitler was german
balzac was french
depp was american
lennon was english
caesar was roman
homer was
2024-07-27 15:51:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 15:53:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3630,  0.2007, -0.3018,  ...,  0.2188, -0.1267,  0.1838],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9297, -5.2109, -2.6094,  ..., -4.4219, -2.2520, -0.6152],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0659, -0.0235,  0.0188,  ..., -0.0166,  0.0102, -0.0302],
        [ 0.0160,  0.0491,  0.0068,  ...,  0.0152, -0.0052, -0.0285],
        [ 0.0141, -0.0061,  0.0745,  ..., -0.0168,  0.0072, -0.0152],
        ...,
        [ 0.0175, -0.0051, -0.0046,  ...,  0.0580,  0.0184, -0.0116],
        [-0.0074,  0.0396,  0.0122,  ..., -0.0087,  0.0864, -0.0047],
        [ 0.0141, -0.0156,  0.0019,  ...,  0.0129, -0.0329,  0.0811]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0352, -5.4922, -2.9844,  ..., -4.8711, -1.6406, -1.1699]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 15:54:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for lavoisier was french
marx was german
hitler was german
balzac was french
depp was american
lennon was english
caesar was roman
homer was
2024-07-27 15:54:01 root INFO     [order_1_approx] starting weight calculation for lavoisier was french
lennon was english
balzac was french
hitler was german
depp was american
caesar was roman
homer was greek
marx was
2024-07-27 15:54:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 15:56:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([0.2244, 0.0643, 0.4727,  ..., 0.2003, 0.1531, 0.0457], device='cuda:1',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4297, -6.0352, -0.8164,  ..., -5.4844,  1.8809, -1.7119],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0368, -0.0159,  0.0086,  ..., -0.0356,  0.0209, -0.0102],
        [ 0.0063,  0.0461,  0.0172,  ...,  0.0058, -0.0227, -0.0196],
        [ 0.0037, -0.0157,  0.0525,  ..., -0.0003,  0.0058,  0.0142],
        ...,
        [ 0.0145, -0.0053,  0.0145,  ...,  0.0646,  0.0021,  0.0042],
        [ 0.0089,  0.0088,  0.0023,  ..., -0.0007,  0.0237, -0.0090],
        [ 0.0078,  0.0210,  0.0013,  ...,  0.0193, -0.0132,  0.0562]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0977, -5.8555, -1.3076,  ..., -5.5469,  2.0020, -1.9678]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 15:56:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for lavoisier was french
lennon was english
balzac was french
hitler was german
depp was american
caesar was roman
homer was greek
marx was
2024-07-27 15:56:18 root INFO     [order_1_approx] starting weight calculation for marx was german
depp was american
lavoisier was french
homer was greek
hitler was german
caesar was roman
lennon was english
balzac was
2024-07-27 15:56:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 15:58:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2368, -0.1522, -0.5166,  ..., -0.0729, -0.1669, -0.0894],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.2227, -4.2188,  1.1543,  ..., -4.9062,  0.4014,  0.7412],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0861,  0.0009, -0.0031,  ..., -0.0345,  0.0190, -0.0330],
        [-0.0035,  0.0495,  0.0081,  ...,  0.0254, -0.0011, -0.0023],
        [ 0.0034, -0.0102,  0.0681,  ...,  0.0126,  0.0128,  0.0220],
        ...,
        [-0.0006,  0.0004, -0.0156,  ...,  0.0879,  0.0011, -0.0100],
        [ 0.0177,  0.0090,  0.0129,  ..., -0.0166,  0.0631, -0.0054],
        [-0.0273,  0.0041, -0.0061,  ...,  0.0357, -0.0233,  0.0862]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.7422, -4.3164,  1.1699,  ..., -4.8789,  0.4270,  0.1558]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 15:58:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for marx was german
depp was american
lavoisier was french
homer was greek
hitler was german
caesar was roman
lennon was english
balzac was
2024-07-27 15:58:38 root INFO     total operator prediction time: 1124.6276953220367 seconds
2024-07-27 15:58:38 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on UK_city - county
2024-07-27 15:58:38 root INFO     building operator UK_city - county
2024-07-27 15:58:38 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of portsmouth is in the county of hampshire
In the United Kingdom, the city of cambridge is in the county of cambridgeshire
In the United Kingdom, the city of sheffield is in the county of yorkshire
In the United Kingdom, the city of southampton is in the county of hampshire
In the United Kingdom, the city of bradford is in the county of yorkshire
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of leicester is in the county of midlands
In the United Kingdom, the city of chichester is in the county of
2024-07-27 15:58:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 16:01:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3677,  0.2603, -0.5576,  ...,  0.4097, -0.1698, -0.0413],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.4297, -4.3438,  0.9424,  ..., -2.1875,  1.7773,  0.0969],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0233, -0.0033,  0.0091,  ..., -0.0021, -0.0166, -0.0245],
        [ 0.0013,  0.0345,  0.0105,  ...,  0.0188,  0.0134, -0.0257],
        [-0.0154, -0.0227,  0.0114,  ..., -0.0035, -0.0064, -0.0118],
        ...,
        [ 0.0132, -0.0064, -0.0123,  ...,  0.0321,  0.0239, -0.0053],
        [-0.0076, -0.0114,  0.0148,  ...,  0.0125,  0.0106, -0.0074],
        [-0.0069, -0.0004, -0.0002,  ..., -0.0007, -0.0112,  0.0236]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 6.3203, -4.3320,  1.2070,  ..., -1.8086,  1.7236, -0.3367]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 16:01:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of portsmouth is in the county of hampshire
In the United Kingdom, the city of cambridge is in the county of cambridgeshire
In the United Kingdom, the city of sheffield is in the county of yorkshire
In the United Kingdom, the city of southampton is in the county of hampshire
In the United Kingdom, the city of bradford is in the county of yorkshire
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of leicester is in the county of midlands
In the United Kingdom, the city of chichester is in the county of
2024-07-27 16:01:04 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of chichester is in the county of sussex
In the United Kingdom, the city of cambridge is in the county of cambridgeshire
In the United Kingdom, the city of sheffield is in the county of yorkshire
In the United Kingdom, the city of southampton is in the county of hampshire
In the United Kingdom, the city of leicester is in the county of midlands
In the United Kingdom, the city of bradford is in the county of yorkshire
In the United Kingdom, the city of portsmouth is in the county of hampshire
In the United Kingdom, the city of aberdeen is in the county of
2024-07-27 16:01:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 16:03:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3958, -0.1086, -0.3708,  ...,  0.2573, -0.0466,  0.2527],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5547, -6.5078,  1.0938,  ..., -5.2578, -1.3828, -1.9551],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 9.2926e-03, -4.8637e-04,  5.7716e-03,  ...,  3.7918e-03,
         -3.8261e-03,  4.9820e-03],
        [-6.1188e-03,  1.2825e-02,  1.2131e-02,  ..., -1.5774e-03,
          5.0201e-03, -5.3596e-03],
        [-2.4643e-03,  6.1417e-03,  3.3142e-02,  ...,  1.2695e-02,
         -1.3447e-03,  4.5872e-04],
        ...,
        [ 4.1237e-03, -5.0430e-03, -1.0521e-02,  ...,  1.9775e-02,
          8.8120e-03, -1.0597e-02],
        [ 1.4591e-03, -1.4519e-02,  6.8665e-05,  ...,  2.1362e-04,
          5.4741e-04,  3.8338e-03],
        [ 2.6741e-03, -5.3635e-03, -7.9803e-03,  ...,  2.3727e-03,
         -3.8033e-03,  1.8753e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5977, -6.7617,  1.0088,  ..., -5.0039, -1.2021, -1.8984]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 16:03:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of chichester is in the county of sussex
In the United Kingdom, the city of cambridge is in the county of cambridgeshire
In the United Kingdom, the city of sheffield is in the county of yorkshire
In the United Kingdom, the city of southampton is in the county of hampshire
In the United Kingdom, the city of leicester is in the county of midlands
In the United Kingdom, the city of bradford is in the county of yorkshire
In the United Kingdom, the city of portsmouth is in the county of hampshire
In the United Kingdom, the city of aberdeen is in the county of
2024-07-27 16:03:30 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of bradford is in the county of yorkshire
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of cambridge is in the county of cambridgeshire
In the United Kingdom, the city of chichester is in the county of sussex
In the United Kingdom, the city of portsmouth is in the county of hampshire
In the United Kingdom, the city of leicester is in the county of midlands
In the United Kingdom, the city of sheffield is in the county of yorkshire
In the United Kingdom, the city of southampton is in the county of
2024-07-27 16:03:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 16:05:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5269, -0.0098, -0.3503,  ...,  0.4529, -0.0251, -0.0493],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.5625, -6.3828,  0.7705,  ..., -3.7891,  0.4414, -0.4146],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.6408e-03,  8.2016e-03,  1.7822e-02,  ...,  1.0170e-02,
          8.2169e-03, -1.6891e-02],
        [-1.6022e-02,  1.2863e-02,  5.0583e-03,  ...,  7.0114e-03,
         -2.7695e-03, -6.2294e-03],
        [-4.3869e-03, -1.1597e-02,  2.9495e-02,  ..., -8.7738e-03,
          1.2444e-02, -6.1493e-03],
        ...,
        [ 4.7188e-03, -1.2253e-02, -1.0422e-02,  ...,  2.0309e-02,
          3.6316e-03, -1.8768e-03],
        [ 7.5760e-03, -2.5421e-02,  3.0041e-04,  ...,  1.3718e-02,
         -3.4313e-03, -7.5111e-03],
        [-1.3435e-02,  2.9106e-03, -3.2177e-03,  ...,  7.1526e-05,
         -8.3084e-03,  9.9030e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.5195, -6.2539,  0.5303,  ..., -3.7363,  0.4905, -0.3533]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 16:05:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of bradford is in the county of yorkshire
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of cambridge is in the county of cambridgeshire
In the United Kingdom, the city of chichester is in the county of sussex
In the United Kingdom, the city of portsmouth is in the county of hampshire
In the United Kingdom, the city of leicester is in the county of midlands
In the United Kingdom, the city of sheffield is in the county of yorkshire
In the United Kingdom, the city of southampton is in the county of
2024-07-27 16:05:55 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of southampton is in the county of hampshire
In the United Kingdom, the city of chichester is in the county of sussex
In the United Kingdom, the city of sheffield is in the county of yorkshire
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of cambridge is in the county of cambridgeshire
In the United Kingdom, the city of portsmouth is in the county of hampshire
In the United Kingdom, the city of leicester is in the county of midlands
In the United Kingdom, the city of bradford is in the county of
2024-07-27 16:05:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 16:08:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6353,  0.4531, -0.2180,  ...,  0.6401, -0.4539,  0.6367],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3359, -7.2031, -1.1299,  ..., -2.3105,  1.3945, -0.3311],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0112,  0.0071,  0.0088,  ...,  0.0017,  0.0081, -0.0064],
        [-0.0074,  0.0115,  0.0105,  ..., -0.0145,  0.0009, -0.0115],
        [-0.0134,  0.0113,  0.0336,  ...,  0.0229, -0.0049, -0.0101],
        ...,
        [ 0.0134,  0.0049, -0.0108,  ...,  0.0299,  0.0073, -0.0104],
        [-0.0048, -0.0104, -0.0040,  ...,  0.0111,  0.0138, -0.0087],
        [ 0.0098,  0.0114, -0.0228,  ..., -0.0090, -0.0118,  0.0224]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4238, -7.4023, -1.1934,  ..., -2.2129,  1.4971, -0.5752]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 16:08:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of southampton is in the county of hampshire
In the United Kingdom, the city of chichester is in the county of sussex
In the United Kingdom, the city of sheffield is in the county of yorkshire
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of cambridge is in the county of cambridgeshire
In the United Kingdom, the city of portsmouth is in the county of hampshire
In the United Kingdom, the city of leicester is in the county of midlands
In the United Kingdom, the city of bradford is in the county of
2024-07-27 16:08:21 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of chichester is in the county of sussex
In the United Kingdom, the city of portsmouth is in the county of hampshire
In the United Kingdom, the city of bradford is in the county of yorkshire
In the United Kingdom, the city of southampton is in the county of hampshire
In the United Kingdom, the city of sheffield is in the county of yorkshire
In the United Kingdom, the city of leicester is in the county of midlands
In the United Kingdom, the city of cambridge is in the county of
2024-07-27 16:08:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 16:10:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4390, -0.3491, -0.3633,  ...,  0.1509, -0.2292,  0.4165],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9414, -5.7422, -0.3613,  ..., -5.5273, -1.3486,  0.8320],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0129, -0.0193,  0.0028,  ..., -0.0067, -0.0237, -0.0004],
        [-0.0102,  0.0118,  0.0131,  ...,  0.0004,  0.0059, -0.0215],
        [-0.0189,  0.0248,  0.0340,  ...,  0.0027,  0.0104,  0.0113],
        ...,
        [ 0.0067,  0.0006, -0.0016,  ...,  0.0296,  0.0098, -0.0113],
        [-0.0037, -0.0042, -0.0109,  ...,  0.0036,  0.0077,  0.0038],
        [-0.0009, -0.0092, -0.0007,  ...,  0.0006, -0.0140,  0.0204]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8730, -5.8320, -0.7793,  ..., -5.4766, -1.2227,  0.7573]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 16:10:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of chichester is in the county of sussex
In the United Kingdom, the city of portsmouth is in the county of hampshire
In the United Kingdom, the city of bradford is in the county of yorkshire
In the United Kingdom, the city of southampton is in the county of hampshire
In the United Kingdom, the city of sheffield is in the county of yorkshire
In the United Kingdom, the city of leicester is in the county of midlands
In the United Kingdom, the city of cambridge is in the county of
2024-07-27 16:10:47 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of bradford is in the county of yorkshire
In the United Kingdom, the city of sheffield is in the county of yorkshire
In the United Kingdom, the city of cambridge is in the county of cambridgeshire
In the United Kingdom, the city of leicester is in the county of midlands
In the United Kingdom, the city of southampton is in the county of hampshire
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of chichester is in the county of sussex
In the United Kingdom, the city of portsmouth is in the county of
2024-07-27 16:10:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 16:13:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2544, -0.1890, -0.0602,  ...,  0.4819, -0.0978, -0.0502],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.4922, -6.7109,  1.8135,  ..., -3.5664,  0.3086, -1.3564],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 8.3237e-03,  3.5152e-03,  9.6436e-03,  ...,  1.3222e-02,
          2.2850e-03, -1.0849e-02],
        [-7.9269e-03,  1.3329e-02,  2.3041e-03,  ...,  4.8523e-03,
          3.0174e-03, -1.7481e-03],
        [-3.2043e-04, -5.0735e-03,  1.4778e-02,  ..., -2.6093e-03,
          1.2215e-02, -1.1425e-03],
        ...,
        [ 2.9106e-03, -7.3547e-03, -9.7885e-03,  ...,  9.9869e-03,
          4.2939e-04, -1.3952e-03],
        [-4.0550e-03, -8.0109e-03,  5.1498e-03,  ...,  5.1765e-03,
         -6.6090e-04, -5.1498e-03],
        [-5.7106e-03,  6.7635e-03, -1.9073e-06,  ...,  3.5477e-04,
         -3.6297e-03,  4.7035e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.5352, -6.7383,  1.6963,  ..., -3.4062,  0.4619, -1.4121]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 16:13:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of bradford is in the county of yorkshire
In the United Kingdom, the city of sheffield is in the county of yorkshire
In the United Kingdom, the city of cambridge is in the county of cambridgeshire
In the United Kingdom, the city of leicester is in the county of midlands
In the United Kingdom, the city of southampton is in the county of hampshire
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of chichester is in the county of sussex
In the United Kingdom, the city of portsmouth is in the county of
2024-07-27 16:13:13 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of portsmouth is in the county of hampshire
In the United Kingdom, the city of bradford is in the county of yorkshire
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of cambridge is in the county of cambridgeshire
In the United Kingdom, the city of chichester is in the county of sussex
In the United Kingdom, the city of sheffield is in the county of yorkshire
In the United Kingdom, the city of southampton is in the county of hampshire
In the United Kingdom, the city of leicester is in the county of
2024-07-27 16:13:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 16:15:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5986, -0.2598, -0.1349,  ...,  0.2671, -0.1438,  0.1606],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9521, -3.5117, -0.3320,  ..., -3.4102, -1.6084,  0.1348],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-3.2482e-03,  2.5864e-03,  7.9727e-03,  ..., -1.0681e-03,
         -6.7520e-03, -7.0572e-05],
        [-5.8022e-03,  1.5465e-02, -2.8191e-03,  ...,  1.1654e-03,
          5.1346e-03, -6.6833e-03],
        [ 1.6356e-03, -2.6627e-03,  1.2634e-02,  ...,  6.7215e-03,
          2.7313e-03, -7.0457e-03],
        ...,
        [ 3.6621e-03, -5.7449e-03, -3.9139e-03,  ...,  2.1805e-02,
          4.7913e-03, -6.0425e-03],
        [ 8.0795e-03, -1.8982e-02,  1.7815e-03,  ...,  1.4297e-02,
         -2.7924e-03, -2.0409e-03],
        [-2.7561e-03,  2.9469e-03, -2.5101e-03,  ..., -7.3471e-03,
         -1.3031e-02,  4.0932e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9805, -3.4238, -0.4324,  ..., -3.2715, -1.5420,  0.2678]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 16:15:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of portsmouth is in the county of hampshire
In the United Kingdom, the city of bradford is in the county of yorkshire
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of cambridge is in the county of cambridgeshire
In the United Kingdom, the city of chichester is in the county of sussex
In the United Kingdom, the city of sheffield is in the county of yorkshire
In the United Kingdom, the city of southampton is in the county of hampshire
In the United Kingdom, the city of leicester is in the county of
2024-07-27 16:15:39 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of chichester is in the county of sussex
In the United Kingdom, the city of portsmouth is in the county of hampshire
In the United Kingdom, the city of cambridge is in the county of cambridgeshire
In the United Kingdom, the city of bradford is in the county of yorkshire
In the United Kingdom, the city of southampton is in the county of hampshire
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of leicester is in the county of midlands
In the United Kingdom, the city of sheffield is in the county of
2024-07-27 16:15:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 16:18:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3838, -0.1790, -0.1726,  ...,  0.4092,  0.0186,  0.1399],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0469, -6.6758,  1.1387,  ..., -2.9609,  0.3320,  1.0615],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0076, -0.0009,  0.0044,  ...,  0.0034,  0.0017, -0.0074],
        [-0.0056,  0.0079,  0.0078,  ..., -0.0062,  0.0024, -0.0041],
        [-0.0054,  0.0088,  0.0180,  ...,  0.0135, -0.0045, -0.0008],
        ...,
        [ 0.0025, -0.0023, -0.0062,  ...,  0.0209,  0.0029, -0.0072],
        [ 0.0083, -0.0040, -0.0054,  ...,  0.0115, -0.0005, -0.0099],
        [ 0.0007,  0.0028, -0.0024,  ...,  0.0017, -0.0075,  0.0060]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0742, -6.7070,  1.0801,  ..., -2.9766,  0.4980,  1.1436]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 16:18:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of chichester is in the county of sussex
In the United Kingdom, the city of portsmouth is in the county of hampshire
In the United Kingdom, the city of cambridge is in the county of cambridgeshire
In the United Kingdom, the city of bradford is in the county of yorkshire
In the United Kingdom, the city of southampton is in the county of hampshire
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of leicester is in the county of midlands
In the United Kingdom, the city of sheffield is in the county of
2024-07-27 16:18:04 root INFO     total operator prediction time: 1165.866572856903 seconds
2024-07-27 16:18:04 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+ment_irreg
2024-07-27 16:18:04 root INFO     building operator verb+ment_irreg
2024-07-27 16:18:04 root INFO     [order_1_approx] starting weight calculation for To equip results in a equipment
To appoint results in a appointment
To harass results in a harassment
To infringe results in a infringement
To embarrass results in a embarrassment
To invest results in a investment
To amend results in a amendment
To redevelop results in a
2024-07-27 16:18:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 16:20:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5518,  0.3447, -0.5493,  ..., -0.0184, -0.2759, -0.3506],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2310, -3.8633,  0.3394,  ...,  1.1328, -1.2207, -1.7188],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0651,  0.0020,  0.0113,  ...,  0.0082,  0.0034,  0.0077],
        [-0.0016,  0.0604,  0.0149,  ...,  0.0179,  0.0236,  0.0035],
        [ 0.0040, -0.0047,  0.0508,  ..., -0.0038,  0.0173, -0.0096],
        ...,
        [-0.0070,  0.0075,  0.0076,  ...,  0.0665,  0.0032,  0.0231],
        [-0.0094,  0.0064,  0.0028,  ...,  0.0014,  0.0512, -0.0183],
        [ 0.0018, -0.0058, -0.0075,  ...,  0.0125, -0.0099,  0.0585]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0769, -3.4746,  0.3247,  ...,  1.4346, -1.1836, -1.7178]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 16:20:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To equip results in a equipment
To appoint results in a appointment
To harass results in a harassment
To infringe results in a infringement
To embarrass results in a embarrassment
To invest results in a investment
To amend results in a amendment
To redevelop results in a
2024-07-27 16:20:23 root INFO     [order_1_approx] starting weight calculation for To amend results in a amendment
To equip results in a equipment
To infringe results in a infringement
To harass results in a harassment
To embarrass results in a embarrassment
To redevelop results in a redevelopment
To invest results in a investment
To appoint results in a
2024-07-27 16:20:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 16:22:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5889,  0.5503,  0.0861,  ...,  0.1227, -0.4609, -0.1760],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4805, -4.0820,  1.8096,  ...,  4.3438, -2.1387, -2.6680],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.6194e-02, -8.3160e-03,  2.9793e-03,  ..., -2.5543e-02,
          3.1799e-02,  5.3215e-03],
        [ 3.2166e-02,  5.5267e-02,  1.2085e-02,  ...,  8.3496e-02,
         -1.5839e-02, -1.1787e-02],
        [ 1.4877e-02, -1.4572e-02,  4.5074e-02,  ..., -9.3536e-03,
         -1.1932e-02, -2.1652e-02],
        ...,
        [-2.7435e-02,  2.7618e-02, -1.7105e-02,  ...,  4.9042e-02,
         -9.3460e-04,  1.9836e-02],
        [ 4.4937e-03,  4.0054e-05,  3.2257e-02,  ...,  6.4087e-03,
          5.2765e-02, -2.4017e-02],
        [ 2.4673e-02, -6.1493e-03, -1.2302e-03,  ...,  2.9846e-02,
         -1.9684e-02,  6.0547e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2800, -3.9512,  1.6475,  ...,  3.7559, -2.2051, -3.2676]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 16:22:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To amend results in a amendment
To equip results in a equipment
To infringe results in a infringement
To harass results in a harassment
To embarrass results in a embarrassment
To redevelop results in a redevelopment
To invest results in a investment
To appoint results in a
2024-07-27 16:22:42 root INFO     [order_1_approx] starting weight calculation for To infringe results in a infringement
To embarrass results in a embarrassment
To equip results in a equipment
To amend results in a amendment
To redevelop results in a redevelopment
To appoint results in a appointment
To invest results in a investment
To harass results in a
2024-07-27 16:22:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 16:24:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0706,  0.1542, -0.2357,  ...,  0.1158, -0.4658, -0.0953],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4316, -3.0176,  0.1602,  ...,  0.2927,  1.2002, -1.9121],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0837,  0.0128,  0.0096,  ...,  0.0096, -0.0274,  0.0106],
        [ 0.0026,  0.0497,  0.0169,  ...,  0.0204,  0.0234, -0.0155],
        [ 0.0024, -0.0049,  0.0235,  ..., -0.0078,  0.0142,  0.0166],
        ...,
        [-0.0125,  0.0102,  0.0025,  ...,  0.0579,  0.0141, -0.0066],
        [-0.0327,  0.0099,  0.0164,  ..., -0.0092,  0.0498, -0.0149],
        [ 0.0153, -0.0026, -0.0046,  ...,  0.0164, -0.0128,  0.0520]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3867, -2.6758, -0.0680,  ...,  0.4253,  0.8174, -1.8467]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 16:24:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To infringe results in a infringement
To embarrass results in a embarrassment
To equip results in a equipment
To amend results in a amendment
To redevelop results in a redevelopment
To appoint results in a appointment
To invest results in a investment
To harass results in a
2024-07-27 16:24:59 root INFO     [order_1_approx] starting weight calculation for To appoint results in a appointment
To equip results in a equipment
To redevelop results in a redevelopment
To infringe results in a infringement
To embarrass results in a embarrassment
To amend results in a amendment
To harass results in a harassment
To invest results in a
2024-07-27 16:24:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 16:27:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0851, -0.1597, -0.0796,  ..., -0.0574,  0.1587, -0.1860],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1533, -2.8750,  0.3342,  ...,  2.0430, -0.0703, -1.6230],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0782,  0.0215, -0.0074,  ...,  0.0003, -0.0139,  0.0173],
        [ 0.0016,  0.0664,  0.0294,  ...,  0.0465,  0.0231,  0.0085],
        [ 0.0119, -0.0114,  0.0569,  ..., -0.0174, -0.0215,  0.0045],
        ...,
        [-0.0155,  0.0004, -0.0034,  ...,  0.0734,  0.0297,  0.0232],
        [-0.0135,  0.0172,  0.0296,  ...,  0.0019,  0.0558, -0.0357],
        [ 0.0193, -0.0014,  0.0026,  ...,  0.0057, -0.0156,  0.0625]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3408, -2.2637,  0.2529,  ...,  1.9424,  0.0027, -1.7324]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 16:27:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To appoint results in a appointment
To equip results in a equipment
To redevelop results in a redevelopment
To infringe results in a infringement
To embarrass results in a embarrassment
To amend results in a amendment
To harass results in a harassment
To invest results in a
2024-07-27 16:27:15 root INFO     [order_1_approx] starting weight calculation for To redevelop results in a redevelopment
To invest results in a investment
To equip results in a equipment
To harass results in a harassment
To amend results in a amendment
To embarrass results in a embarrassment
To appoint results in a appointment
To infringe results in a
2024-07-27 16:27:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 16:29:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2393, -0.0045, -0.6333,  ...,  0.1501, -0.3459, -0.0581],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5322, -5.0781,  0.4785,  ...,  1.6855, -0.8594, -0.6733],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0739,  0.0006,  0.0028,  ..., -0.0063,  0.0038,  0.0105],
        [-0.0316,  0.0606,  0.0116,  ...,  0.0022,  0.0287, -0.0108],
        [ 0.0040,  0.0020,  0.0405,  ..., -0.0081,  0.0063, -0.0082],
        ...,
        [-0.0061,  0.0126, -0.0099,  ...,  0.0670,  0.0002,  0.0014],
        [-0.0231, -0.0025, -0.0033,  ..., -0.0017,  0.0626, -0.0149],
        [ 0.0096,  0.0023,  0.0123,  ...,  0.0071, -0.0166,  0.0667]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6943, -4.4492,  0.6040,  ...,  1.8193, -1.1943, -0.9536]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 16:29:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To redevelop results in a redevelopment
To invest results in a investment
To equip results in a equipment
To harass results in a harassment
To amend results in a amendment
To embarrass results in a embarrassment
To appoint results in a appointment
To infringe results in a
2024-07-27 16:29:37 root INFO     [order_1_approx] starting weight calculation for To equip results in a equipment
To redevelop results in a redevelopment
To invest results in a investment
To infringe results in a infringement
To embarrass results in a embarrassment
To harass results in a harassment
To appoint results in a appointment
To amend results in a
2024-07-27 16:29:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 16:31:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0259,  0.4570, -0.7427,  ..., -0.0984, -0.1569, -0.1481],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6074, -2.0645, -0.7593,  ...,  0.2021, -0.8359, -0.7827],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0510,  0.0153, -0.0103,  ..., -0.0097, -0.0046,  0.0196],
        [ 0.0190,  0.0616,  0.0213,  ...,  0.0285, -0.0008,  0.0228],
        [-0.0069, -0.0040,  0.0445,  ...,  0.0070,  0.0197, -0.0326],
        ...,
        [ 0.0183,  0.0028, -0.0069,  ...,  0.0590,  0.0141,  0.0061],
        [-0.0021,  0.0116,  0.0077,  ...,  0.0065,  0.0670, -0.0147],
        [ 0.0055, -0.0225,  0.0232,  ...,  0.0120, -0.0226,  0.0740]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0859, -1.5059, -0.4414,  ...,  0.9121, -1.0430, -0.8960]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 16:31:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To equip results in a equipment
To redevelop results in a redevelopment
To invest results in a investment
To infringe results in a infringement
To embarrass results in a embarrassment
To harass results in a harassment
To appoint results in a appointment
To amend results in a
2024-07-27 16:31:55 root INFO     [order_1_approx] starting weight calculation for To redevelop results in a redevelopment
To embarrass results in a embarrassment
To appoint results in a appointment
To amend results in a amendment
To harass results in a harassment
To infringe results in a infringement
To invest results in a investment
To equip results in a
2024-07-27 16:31:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 16:34:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2493,  0.3733, -0.2817,  ..., -0.1382, -0.2695,  0.1644],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2842, -2.8867, -0.6416,  ...,  3.7695, -2.8320, -2.6387],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0635,  0.0018,  0.0102,  ..., -0.0066,  0.0017,  0.0079],
        [-0.0146,  0.0662, -0.0107,  ...,  0.0229,  0.0094, -0.0163],
        [ 0.0081,  0.0032,  0.0454,  ..., -0.0036, -0.0066,  0.0107],
        ...,
        [-0.0094, -0.0046,  0.0117,  ...,  0.0620,  0.0040,  0.0042],
        [ 0.0037,  0.0189,  0.0105,  ..., -0.0042,  0.0652, -0.0136],
        [-0.0139, -0.0161,  0.0040,  ...,  0.0185, -0.0112,  0.0457]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0731, -2.4844, -0.8789,  ...,  3.8867, -2.4922, -2.4805]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 16:34:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To redevelop results in a redevelopment
To embarrass results in a embarrassment
To appoint results in a appointment
To amend results in a amendment
To harass results in a harassment
To infringe results in a infringement
To invest results in a investment
To equip results in a
2024-07-27 16:34:13 root INFO     [order_1_approx] starting weight calculation for To equip results in a equipment
To invest results in a investment
To redevelop results in a redevelopment
To amend results in a amendment
To harass results in a harassment
To infringe results in a infringement
To appoint results in a appointment
To embarrass results in a
2024-07-27 16:34:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 16:36:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2808,  0.3276, -0.5420,  ...,  0.0963, -0.2847,  0.1294],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3535, -1.4004,  1.8809,  ...,  1.3457,  2.9551, -1.7881],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0613,  0.0148,  0.0011,  ..., -0.0086, -0.0158, -0.0169],
        [ 0.0181,  0.0577, -0.0080,  ...,  0.0204,  0.0050,  0.0007],
        [ 0.0142, -0.0045,  0.0372,  ..., -0.0069, -0.0049,  0.0142],
        ...,
        [ 0.0013,  0.0138, -0.0060,  ...,  0.0591,  0.0085, -0.0006],
        [-0.0121,  0.0257,  0.0027,  ...,  0.0012,  0.0385,  0.0059],
        [ 0.0196,  0.0032,  0.0108,  ...,  0.0165, -0.0130,  0.0481]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0664, -1.6094,  1.6699,  ...,  1.6016,  2.6582, -1.8018]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 16:36:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To equip results in a equipment
To invest results in a investment
To redevelop results in a redevelopment
To amend results in a amendment
To harass results in a harassment
To infringe results in a infringement
To appoint results in a appointment
To embarrass results in a
2024-07-27 16:36:29 root INFO     total operator prediction time: 1105.360598564148 seconds
2024-07-27 16:36:29 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun+less_reg
2024-07-27 16:36:29 root INFO     building operator noun+less_reg
2024-07-27 16:36:30 root INFO     [order_1_approx] starting weight calculation for Something without life is lifeless
Something without spine is spineless
Something without effort is effortless
Something without path is pathless
Something without bone is boneless
Something without expression is expressionless
Something without art is artless
Something without home is
2024-07-27 16:36:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 16:38:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3105, -0.2432, -0.2869,  ..., -0.0779, -0.0010, -0.0214],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9199, -2.6523, -1.8594,  ..., -1.8047, -3.0742,  2.0938],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0425, -0.0089,  0.0042,  ...,  0.0098, -0.0002,  0.0230],
        [ 0.0007,  0.0291, -0.0119,  ...,  0.0048,  0.0064, -0.0044],
        [ 0.0225,  0.0052,  0.0461,  ...,  0.0077, -0.0154,  0.0025],
        ...,
        [-0.0079,  0.0034, -0.0115,  ...,  0.0168,  0.0119, -0.0043],
        [-0.0052,  0.0264,  0.0021,  ..., -0.0116,  0.0371, -0.0353],
        [ 0.0179,  0.0174,  0.0019,  ...,  0.0003, -0.0147,  0.0308]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1426, -2.5234, -2.2402,  ..., -1.8291, -3.5488,  1.8711]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 16:38:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without life is lifeless
Something without spine is spineless
Something without effort is effortless
Something without path is pathless
Something without bone is boneless
Something without expression is expressionless
Something without art is artless
Something without home is
2024-07-27 16:38:49 root INFO     [order_1_approx] starting weight calculation for Something without life is lifeless
Something without spine is spineless
Something without bone is boneless
Something without effort is effortless
Something without expression is expressionless
Something without art is artless
Something without home is homeless
Something without path is
2024-07-27 16:38:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 16:41:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0507,  0.0150,  0.0149,  ..., -0.2742, -0.1587, -0.0500],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.2148e+00, -4.3438e+00, -3.6914e+00,  ..., -3.7842e-03,
        -3.9805e+00, -8.9453e-01], device='cuda:1', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0269,  0.0039, -0.0047,  ..., -0.0003,  0.0059,  0.0251],
        [-0.0009,  0.0339, -0.0006,  ...,  0.0109, -0.0005, -0.0016],
        [ 0.0036, -0.0022,  0.0405,  ...,  0.0180, -0.0067,  0.0097],
        ...,
        [ 0.0088,  0.0177, -0.0065,  ...,  0.0309, -0.0017,  0.0186],
        [-0.0043,  0.0116, -0.0191,  ..., -0.0151,  0.0355, -0.0126],
        [ 0.0085,  0.0045, -0.0037,  ...,  0.0041, -0.0108,  0.0130]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.3906, -4.1953, -4.1445,  ..., -0.3052, -3.3730, -0.7344]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 16:41:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without life is lifeless
Something without spine is spineless
Something without bone is boneless
Something without effort is effortless
Something without expression is expressionless
Something without art is artless
Something without home is homeless
Something without path is
2024-07-27 16:41:07 root INFO     [order_1_approx] starting weight calculation for Something without home is homeless
Something without effort is effortless
Something without bone is boneless
Something without path is pathless
Something without art is artless
Something without life is lifeless
Something without expression is expressionless
Something without spine is
2024-07-27 16:41:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 16:43:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1301, -0.4524, -0.2153,  ...,  0.4949,  0.0823,  0.3198],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6074, -1.8008, -2.1406,  ..., -2.0508, -3.0078,  0.0693],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.0629e-02,  5.6458e-03,  9.8114e-03,  ..., -4.7150e-03,
          7.1983e-03,  1.3245e-02],
        [ 1.6754e-02,  4.5319e-02,  5.2643e-04,  ...,  1.6647e-02,
          1.1574e-02,  1.1421e-02],
        [ 1.6342e-02, -1.0178e-02,  3.9062e-02,  ...,  7.2479e-05,
         -4.9553e-03, -5.7983e-04],
        ...,
        [ 1.0056e-02,  1.3367e-02, -4.0665e-03,  ...,  5.1300e-02,
          2.4261e-02, -1.2268e-02],
        [-7.6904e-03,  2.4231e-02, -5.3253e-03,  ..., -6.9141e-04,
          4.2603e-02, -3.8147e-02],
        [ 8.9569e-03,  3.2330e-03,  1.9226e-03,  ...,  8.4839e-03,
         -8.5831e-04,  2.5055e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2676, -1.6680, -2.2812,  ..., -1.5645, -3.2715,  0.5142]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 16:43:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without home is homeless
Something without effort is effortless
Something without bone is boneless
Something without path is pathless
Something without art is artless
Something without life is lifeless
Something without expression is expressionless
Something without spine is
2024-07-27 16:43:28 root INFO     [order_1_approx] starting weight calculation for Something without spine is spineless
Something without effort is effortless
Something without home is homeless
Something without bone is boneless
Something without life is lifeless
Something without expression is expressionless
Something without path is pathless
Something without art is
2024-07-27 16:43:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 16:45:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1328, -0.2026, -0.0777,  ..., -0.4561, -0.0136, -0.0918],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5234, -3.3906,  0.3350,  ..., -2.5176, -5.2148,  0.0840],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0160, -0.0042,  0.0041,  ..., -0.0063,  0.0118,  0.0032],
        [ 0.0083,  0.0394, -0.0030,  ...,  0.0206, -0.0046,  0.0188],
        [ 0.0163,  0.0164,  0.0270,  ...,  0.0074, -0.0132, -0.0033],
        ...,
        [ 0.0169,  0.0092,  0.0002,  ...,  0.0259,  0.0108,  0.0058],
        [ 0.0084, -0.0090,  0.0127,  ...,  0.0025,  0.0168, -0.0340],
        [ 0.0145,  0.0114,  0.0177,  ...,  0.0138, -0.0045,  0.0262]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7754, -3.3477,  0.0948,  ..., -2.4531, -5.3438,  0.0737]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 16:45:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without spine is spineless
Something without effort is effortless
Something without home is homeless
Something without bone is boneless
Something without life is lifeless
Something without expression is expressionless
Something without path is pathless
Something without art is
2024-07-27 16:45:48 root INFO     [order_1_approx] starting weight calculation for Something without home is homeless
Something without expression is expressionless
Something without effort is effortless
Something without bone is boneless
Something without path is pathless
Something without spine is spineless
Something without art is artless
Something without life is
2024-07-27 16:45:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 16:48:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3394, -0.3667,  0.0006,  ..., -0.1543,  0.0074, -0.0651],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3369, -3.1094,  0.8066,  ..., -3.1406, -3.6660,  0.1143],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0291,  0.0132, -0.0019,  ...,  0.0043,  0.0044,  0.0025],
        [ 0.0027,  0.0189, -0.0183,  ...,  0.0111,  0.0042, -0.0055],
        [ 0.0191,  0.0124,  0.0472,  ..., -0.0128, -0.0110,  0.0026],
        ...,
        [ 0.0104,  0.0140, -0.0143,  ...,  0.0181, -0.0023, -0.0092],
        [ 0.0062,  0.0022, -0.0009,  ..., -0.0099,  0.0153, -0.0339],
        [ 0.0240,  0.0051, -0.0013,  ..., -0.0023, -0.0061,  0.0185]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5732, -2.9941,  0.1655,  ..., -2.8926, -3.9043,  0.1812]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 16:48:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without home is homeless
Something without expression is expressionless
Something without effort is effortless
Something without bone is boneless
Something without path is pathless
Something without spine is spineless
Something without art is artless
Something without life is
2024-07-27 16:48:09 root INFO     [order_1_approx] starting weight calculation for Something without home is homeless
Something without life is lifeless
Something without path is pathless
Something without effort is effortless
Something without bone is boneless
Something without spine is spineless
Something without art is artless
Something without expression is
2024-07-27 16:48:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 16:50:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1685, -0.0448,  0.0507,  ...,  0.5259,  0.1306,  0.0634],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8315, -2.9492,  1.4277,  ..., -3.2949, -2.1074, -1.2402],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0273, -0.0034, -0.0054,  ..., -0.0038,  0.0129,  0.0192],
        [ 0.0073,  0.0372, -0.0048,  ...,  0.0280, -0.0011,  0.0087],
        [ 0.0048,  0.0092,  0.0294,  ...,  0.0012, -0.0191,  0.0001],
        ...,
        [ 0.0022,  0.0161, -0.0099,  ...,  0.0248,  0.0244, -0.0108],
        [-0.0036,  0.0115, -0.0040,  ..., -0.0226,  0.0329, -0.0215],
        [ 0.0155,  0.0060,  0.0031,  ...,  0.0246,  0.0038,  0.0180]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9634, -3.3457,  1.1465,  ..., -2.8711, -2.0996, -0.9219]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 16:50:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without home is homeless
Something without life is lifeless
Something without path is pathless
Something without effort is effortless
Something without bone is boneless
Something without spine is spineless
Something without art is artless
Something without expression is
2024-07-27 16:50:28 root INFO     [order_1_approx] starting weight calculation for Something without path is pathless
Something without art is artless
Something without spine is spineless
Something without expression is expressionless
Something without bone is boneless
Something without home is homeless
Something without life is lifeless
Something without effort is
2024-07-27 16:50:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 16:52:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0468, -0.0830,  0.1486,  ..., -0.0356, -0.0534,  0.4165],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3301, -4.6562, -0.9697,  ..., -1.8262, -3.7188, -4.4609],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0214, -0.0118, -0.0114,  ..., -0.0070, -0.0015,  0.0062],
        [ 0.0163,  0.0530, -0.0066,  ...,  0.0158,  0.0045,  0.0096],
        [ 0.0117,  0.0012,  0.0363,  ...,  0.0055, -0.0074, -0.0043],
        ...,
        [ 0.0123,  0.0262, -0.0065,  ...,  0.0303,  0.0209,  0.0107],
        [-0.0197,  0.0046, -0.0157,  ...,  0.0036,  0.0412, -0.0247],
        [ 0.0394,  0.0014,  0.0071,  ..., -0.0028, -0.0159,  0.0342]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5918, -4.6172, -0.6396,  ..., -2.0410, -3.6055, -4.4336]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 16:52:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without path is pathless
Something without art is artless
Something without spine is spineless
Something without expression is expressionless
Something without bone is boneless
Something without home is homeless
Something without life is lifeless
Something without effort is
2024-07-27 16:52:41 root INFO     [order_1_approx] starting weight calculation for Something without effort is effortless
Something without art is artless
Something without expression is expressionless
Something without life is lifeless
Something without home is homeless
Something without path is pathless
Something without spine is spineless
Something without bone is
2024-07-27 16:52:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 16:55:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4917, -0.0801, -0.3770,  ...,  0.1804, -0.6938,  0.4895],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0464, -1.4062, -0.1006,  ..., -2.7461, -1.9873, -1.4258],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0347, -0.0045, -0.0059,  ..., -0.0081,  0.0083,  0.0045],
        [ 0.0080,  0.0416,  0.0133,  ...,  0.0089,  0.0160, -0.0015],
        [-0.0047, -0.0024,  0.0302,  ...,  0.0042, -0.0086, -0.0134],
        ...,
        [ 0.0093,  0.0224, -0.0054,  ...,  0.0364,  0.0127, -0.0086],
        [-0.0257,  0.0105,  0.0049,  ..., -0.0059,  0.0304, -0.0308],
        [ 0.0264,  0.0160,  0.0047,  ...,  0.0101, -0.0099,  0.0170]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2607, -1.4043, -0.2336,  ..., -2.6699, -1.7295, -1.4629]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 16:55:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without effort is effortless
Something without art is artless
Something without expression is expressionless
Something without life is lifeless
Something without home is homeless
Something without path is pathless
Something without spine is spineless
Something without bone is
2024-07-27 16:55:01 root INFO     total operator prediction time: 1111.304006576538 seconds
2024-07-27 16:55:01 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj+ness_reg
2024-07-27 16:55:01 root INFO     building operator adj+ness_reg
2024-07-27 16:55:01 root INFO     [order_1_approx] starting weight calculation for The state of being massive is massiveness
The state of being marked is markedness
The state of being impressive is impressiveness
The state of being strange is strangeness
The state of being righteous is righteousness
The state of being serious is seriousness
The state of being directed is directedness
The state of being creative is
2024-07-27 16:55:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 16:57:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1914,  0.1260,  0.0735,  ..., -0.1227, -0.0177,  0.1066],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2043, -3.5703,  0.7432,  ...,  0.2708, -1.1406,  0.2881],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0505, -0.0014,  0.0071,  ...,  0.0063, -0.0033,  0.0081],
        [-0.0090,  0.0303,  0.0169,  ...,  0.0192,  0.0246, -0.0024],
        [ 0.0015, -0.0131,  0.0401,  ...,  0.0070, -0.0093, -0.0044],
        ...,
        [ 0.0160,  0.0012,  0.0009,  ...,  0.0271, -0.0028, -0.0036],
        [-0.0090,  0.0130, -0.0033,  ..., -0.0072,  0.0278, -0.0096],
        [ 0.0075, -0.0134, -0.0081,  ..., -0.0031, -0.0154,  0.0378]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3796, -3.5938,  0.8257,  ...,  0.7178, -1.3506,  0.2588]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 16:57:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being massive is massiveness
The state of being marked is markedness
The state of being impressive is impressiveness
The state of being strange is strangeness
The state of being righteous is righteousness
The state of being serious is seriousness
The state of being directed is directedness
The state of being creative is
2024-07-27 16:57:22 root INFO     [order_1_approx] starting weight calculation for The state of being marked is markedness
The state of being creative is creativeness
The state of being massive is massiveness
The state of being righteous is righteousness
The state of being strange is strangeness
The state of being serious is seriousness
The state of being directed is directedness
The state of being impressive is
2024-07-27 16:57:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 16:59:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0401, -0.0747, -0.5562,  ...,  0.0945, -0.3936, -0.0567],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.4180, -2.3965, -2.7324,  ..., -0.9287, -3.6621, -4.0859],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0410, -0.0015,  0.0121,  ..., -0.0062, -0.0011,  0.0031],
        [-0.0146,  0.0383,  0.0018,  ...,  0.0149,  0.0219,  0.0051],
        [ 0.0136,  0.0028,  0.0423,  ..., -0.0108, -0.0224, -0.0046],
        ...,
        [ 0.0153,  0.0062, -0.0065,  ...,  0.0191,  0.0022,  0.0057],
        [ 0.0198,  0.0194,  0.0198,  ..., -0.0017,  0.0236,  0.0008],
        [-0.0073,  0.0081,  0.0032,  ..., -0.0040, -0.0117,  0.0059]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.5898, -2.6973, -2.8555,  ..., -0.8486, -3.4648, -4.3164]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 16:59:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being marked is markedness
The state of being creative is creativeness
The state of being massive is massiveness
The state of being righteous is righteousness
The state of being strange is strangeness
The state of being serious is seriousness
The state of being directed is directedness
The state of being impressive is
2024-07-27 16:59:43 root INFO     [order_1_approx] starting weight calculation for The state of being marked is markedness
The state of being strange is strangeness
The state of being serious is seriousness
The state of being impressive is impressiveness
The state of being directed is directedness
The state of being righteous is righteousness
The state of being creative is creativeness
The state of being massive is
2024-07-27 16:59:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 17:02:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2551, -0.0757, -0.3027,  ...,  0.2817, -0.3149,  0.0627],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9814, -4.4766, -2.8379,  ..., -3.8242, -5.0000, -3.7227],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0521,  0.0031, -0.0041,  ...,  0.0171,  0.0055,  0.0110],
        [ 0.0015,  0.0522,  0.0095,  ...,  0.0027, -0.0010,  0.0099],
        [ 0.0289,  0.0023,  0.0484,  ..., -0.0067, -0.0288,  0.0184],
        ...,
        [-0.0015,  0.0066,  0.0148,  ...,  0.0405, -0.0086, -0.0122],
        [ 0.0017,  0.0066, -0.0161,  ...,  0.0006,  0.0586, -0.0146],
        [-0.0026,  0.0167, -0.0051,  ..., -0.0021, -0.0092,  0.0238]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7866, -4.5586, -2.7988,  ..., -3.4707, -4.9961, -3.8535]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 17:02:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being marked is markedness
The state of being strange is strangeness
The state of being serious is seriousness
The state of being impressive is impressiveness
The state of being directed is directedness
The state of being righteous is righteousness
The state of being creative is creativeness
The state of being massive is
2024-07-27 17:02:05 root INFO     [order_1_approx] starting weight calculation for The state of being creative is creativeness
The state of being directed is directedness
The state of being impressive is impressiveness
The state of being massive is massiveness
The state of being serious is seriousness
The state of being strange is strangeness
The state of being marked is markedness
The state of being righteous is
2024-07-27 17:02:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 17:04:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1017, -0.0449, -0.3367,  ...,  0.0546, -0.2793,  0.0393],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-5.4541e-01, -1.7881e+00,  4.8828e-04,  ..., -4.1484e+00,
        -4.1641e+00, -1.0430e+00], device='cuda:1', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0627, -0.0028,  0.0068,  ...,  0.0051,  0.0038,  0.0098],
        [ 0.0069,  0.0361,  0.0148,  ...,  0.0163,  0.0098,  0.0067],
        [-0.0060, -0.0061,  0.0453,  ..., -0.0105, -0.0160,  0.0042],
        ...,
        [ 0.0189,  0.0052, -0.0040,  ...,  0.0325, -0.0044,  0.0014],
        [-0.0055,  0.0215,  0.0033,  ..., -0.0260,  0.0351, -0.0080],
        [-0.0048,  0.0030,  0.0033,  ..., -0.0084, -0.0133,  0.0335]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5830, -1.7861, -0.1329,  ..., -4.0469, -4.2109, -1.0996]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 17:04:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being creative is creativeness
The state of being directed is directedness
The state of being impressive is impressiveness
The state of being massive is massiveness
The state of being serious is seriousness
The state of being strange is strangeness
The state of being marked is markedness
The state of being righteous is
2024-07-27 17:04:27 root INFO     [order_1_approx] starting weight calculation for The state of being righteous is righteousness
The state of being impressive is impressiveness
The state of being marked is markedness
The state of being creative is creativeness
The state of being strange is strangeness
The state of being massive is massiveness
The state of being serious is seriousness
The state of being directed is
2024-07-27 17:04:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 17:06:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0520,  0.0383, -0.3870,  ...,  0.4060, -0.3330,  0.1013],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1797, -4.0938, -0.6655,  ...,  0.3333, -3.3164, -5.0625],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.3303e-02,  4.5052e-03, -8.6517e-03,  ...,  2.5040e-02,
          2.1286e-02,  2.1027e-02],
        [-1.4420e-02,  6.1584e-02,  1.4946e-02,  ...,  1.3107e-02,
         -1.5610e-02, -1.6312e-02],
        [-5.5161e-03, -2.0828e-03,  4.5929e-02,  ..., -1.9623e-02,
         -7.6294e-05, -4.3869e-03],
        ...,
        [-2.5635e-03,  1.6678e-02, -2.0943e-03,  ...,  3.3234e-02,
         -1.1383e-02, -7.9632e-04],
        [-2.0142e-02,  1.7975e-02,  1.8570e-02,  ..., -2.5085e-02,
          5.0720e-02, -1.1078e-02],
        [ 2.5635e-02, -1.2184e-02,  1.2550e-03,  ...,  1.1665e-02,
         -1.3962e-02,  6.4087e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5938, -4.4414, -0.2642,  ...,  0.2510, -3.0684, -4.9961]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 17:06:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being righteous is righteousness
The state of being impressive is impressiveness
The state of being marked is markedness
The state of being creative is creativeness
The state of being strange is strangeness
The state of being massive is massiveness
The state of being serious is seriousness
The state of being directed is
2024-07-27 17:06:48 root INFO     [order_1_approx] starting weight calculation for The state of being impressive is impressiveness
The state of being creative is creativeness
The state of being massive is massiveness
The state of being strange is strangeness
The state of being marked is markedness
The state of being righteous is righteousness
The state of being directed is directedness
The state of being serious is
2024-07-27 17:06:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 17:09:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1109, -0.2192, -0.3687,  ...,  0.1543, -0.7461,  0.3391],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0518, -2.8945, -1.9482,  ..., -3.1836, -2.0117, -3.0977],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0620, -0.0071, -0.0056,  ...,  0.0028,  0.0104,  0.0097],
        [-0.0022,  0.0446,  0.0098,  ...,  0.0012,  0.0053,  0.0012],
        [ 0.0069,  0.0021,  0.0607,  ..., -0.0033, -0.0136,  0.0061],
        ...,
        [ 0.0162,  0.0349,  0.0066,  ...,  0.0214,  0.0004,  0.0039],
        [-0.0275,  0.0320,  0.0071,  ..., -0.0148,  0.0532, -0.0135],
        [ 0.0135,  0.0037,  0.0060,  ...,  0.0031, -0.0185,  0.0420]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2272, -2.7422, -2.0586,  ..., -3.5469, -2.1211, -2.9727]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 17:09:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being impressive is impressiveness
The state of being creative is creativeness
The state of being massive is massiveness
The state of being strange is strangeness
The state of being marked is markedness
The state of being righteous is righteousness
The state of being directed is directedness
The state of being serious is
2024-07-27 17:09:09 root INFO     [order_1_approx] starting weight calculation for The state of being creative is creativeness
The state of being directed is directedness
The state of being impressive is impressiveness
The state of being serious is seriousness
The state of being massive is massiveness
The state of being righteous is righteousness
The state of being marked is markedness
The state of being strange is
2024-07-27 17:09:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 17:11:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0110,  0.0247, -0.1436,  ..., -0.1177,  0.1147,  0.2720],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9033, -2.2461, -2.5410,  ..., -2.6289, -4.3086, -2.3164],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0408,  0.0094, -0.0123,  ..., -0.0003, -0.0041, -0.0018],
        [-0.0008,  0.0266,  0.0042,  ...,  0.0286,  0.0102,  0.0012],
        [ 0.0242,  0.0018,  0.0331,  ..., -0.0073, -0.0085,  0.0110],
        ...,
        [ 0.0074,  0.0192, -0.0088,  ...,  0.0209, -0.0044,  0.0008],
        [-0.0199,  0.0073,  0.0092,  ..., -0.0084,  0.0291, -0.0159],
        [ 0.0233,  0.0209,  0.0001,  ...,  0.0010, -0.0142,  0.0258]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9404, -1.8457, -2.5938,  ..., -2.5879, -4.7188, -2.2344]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 17:11:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being creative is creativeness
The state of being directed is directedness
The state of being impressive is impressiveness
The state of being serious is seriousness
The state of being massive is massiveness
The state of being righteous is righteousness
The state of being marked is markedness
The state of being strange is
2024-07-27 17:11:28 root INFO     [order_1_approx] starting weight calculation for The state of being impressive is impressiveness
The state of being directed is directedness
The state of being creative is creativeness
The state of being massive is massiveness
The state of being serious is seriousness
The state of being righteous is righteousness
The state of being strange is strangeness
The state of being marked is
2024-07-27 17:11:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 17:13:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0113,  0.0773, -0.4736,  ...,  0.5273, -0.0363,  0.1565],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8735, -3.1152, -2.6094,  ..., -2.1602, -3.1602, -2.2812],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.9824e-02,  1.0635e-02,  2.1648e-03,  ..., -7.8201e-05,
          1.1909e-02, -1.2474e-02],
        [ 1.5747e-02,  7.7881e-02, -5.8899e-03,  ...,  3.0365e-02,
          3.3417e-03,  2.1210e-03],
        [ 1.4557e-02, -2.4399e-02,  6.2469e-02,  ...,  1.0048e-02,
         -5.4550e-03,  3.5431e-02],
        ...,
        [ 3.7415e-02,  1.4450e-02, -5.8365e-04,  ...,  4.7363e-02,
         -2.7039e-02,  2.1454e-02],
        [-2.2690e-02,  1.8784e-02,  1.6663e-02,  ..., -2.8137e-02,
          5.7343e-02, -3.1311e-02],
        [ 1.9653e-02,  8.9111e-03, -1.7929e-02,  ...,  3.3112e-02,
         -3.0914e-02,  7.8308e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3989, -3.1660, -2.4297,  ..., -2.3867, -3.3965, -2.3418]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 17:13:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being impressive is impressiveness
The state of being directed is directedness
The state of being creative is creativeness
The state of being massive is massiveness
The state of being serious is seriousness
The state of being righteous is righteousness
The state of being strange is strangeness
The state of being marked is
2024-07-27 17:13:50 root INFO     total operator prediction time: 1129.3750903606415 seconds
2024-07-27 17:13:50 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on re+verb_reg
2024-07-27 17:13:50 root INFO     building operator re+verb_reg
2024-07-27 17:13:50 root INFO     [order_1_approx] starting weight calculation for To distribute again is to redistribute
To grow again is to regrow
To learn again is to relearn
To cognize again is to recognize
To marry again is to remarry
To define again is to redefine
To emerge again is to reemerge
To negotiate again is to
2024-07-27 17:13:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 17:16:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7603,  0.2434, -0.3086,  ..., -0.1721, -0.4148, -0.2534],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2500, -2.2812,  2.1484,  ..., -1.2539, -4.6953, -3.6250],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0317, -0.0052,  0.0129,  ...,  0.0021, -0.0061,  0.0082],
        [ 0.0019,  0.0295,  0.0045,  ...,  0.0041,  0.0059,  0.0071],
        [-0.0063,  0.0003,  0.0273,  ...,  0.0066, -0.0041,  0.0033],
        ...,
        [ 0.0166, -0.0004, -0.0068,  ...,  0.0352, -0.0009,  0.0049],
        [-0.0084,  0.0083, -0.0043,  ...,  0.0023,  0.0095, -0.0058],
        [ 0.0048, -0.0051, -0.0032,  ..., -0.0006, -0.0155,  0.0295]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2246, -2.5156,  2.0938,  ..., -1.2354, -4.7344, -3.2480]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 17:16:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To distribute again is to redistribute
To grow again is to regrow
To learn again is to relearn
To cognize again is to recognize
To marry again is to remarry
To define again is to redefine
To emerge again is to reemerge
To negotiate again is to
2024-07-27 17:16:12 root INFO     [order_1_approx] starting weight calculation for To emerge again is to reemerge
To distribute again is to redistribute
To grow again is to regrow
To negotiate again is to renegotiate
To marry again is to remarry
To define again is to redefine
To cognize again is to recognize
To learn again is to
2024-07-27 17:16:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 17:18:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0846, -0.0931, -0.0609,  ..., -0.2795, -0.0603,  0.1541],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7402, -2.8906,  1.4688,  ...,  2.9473, -5.6250, -5.4688],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.7720e-02, -5.4893e-03,  8.0566e-03,  ..., -9.5062e-03,
         -1.1803e-02,  1.0689e-02],
        [ 6.7978e-03,  3.6041e-02,  1.6651e-03,  ..., -1.3046e-03,
         -1.5747e-02,  6.9237e-03],
        [ 5.7526e-03, -1.4870e-02,  4.4098e-02,  ...,  4.7302e-03,
          5.5389e-03, -1.3866e-03],
        ...,
        [ 2.4216e-02, -6.0196e-03, -1.9436e-03,  ...,  4.1718e-02,
         -4.3869e-03,  1.7529e-03],
        [-6.1302e-03,  1.4877e-02, -4.2953e-03,  ...,  1.3351e-03,
          2.0691e-02, -7.3395e-03],
        [ 1.3885e-03,  1.9485e-02,  3.5305e-03,  ..., -9.0179e-03,
          2.6703e-05,  2.9434e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8145, -3.2363,  1.3174,  ...,  3.0176, -5.7031, -4.9102]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 17:18:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To emerge again is to reemerge
To distribute again is to redistribute
To grow again is to regrow
To negotiate again is to renegotiate
To marry again is to remarry
To define again is to redefine
To cognize again is to recognize
To learn again is to
2024-07-27 17:18:35 root INFO     [order_1_approx] starting weight calculation for To grow again is to regrow
To emerge again is to reemerge
To marry again is to remarry
To distribute again is to redistribute
To define again is to redefine
To learn again is to relearn
To negotiate again is to renegotiate
To cognize again is to
2024-07-27 17:18:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 17:20:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0166,  0.2939, -0.5869,  ...,  0.1439, -0.2023,  0.1967],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-3.0215, -2.7910,  3.5469,  ...,  0.9707, -3.6191, -1.5010],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.4880e-02, -8.9798e-03,  1.9272e-02,  ..., -2.3251e-03,
         -1.5182e-02,  1.2932e-03],
        [ 1.5991e-02,  4.3335e-02, -5.5122e-03,  ..., -1.4305e-05,
         -1.2123e-02,  3.8567e-03],
        [-9.1095e-03, -1.8890e-02,  3.6194e-02,  ..., -2.1172e-04,
         -1.9760e-03,  3.0785e-03],
        ...,
        [ 2.6947e-02,  1.4427e-02, -5.7144e-03,  ...,  4.4342e-02,
          2.4586e-03,  1.5686e-02],
        [ 5.8670e-03,  3.3722e-03, -1.5926e-03,  ..., -6.7863e-03,
          2.7679e-02, -1.6724e-02],
        [-1.0078e-02,  3.2444e-03, -2.9831e-03,  ..., -1.4465e-02,
         -1.0727e-02,  3.7811e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.7500, -2.6367,  3.3652,  ...,  1.4033, -3.6016, -1.6289]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 17:20:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To grow again is to regrow
To emerge again is to reemerge
To marry again is to remarry
To distribute again is to redistribute
To define again is to redefine
To learn again is to relearn
To negotiate again is to renegotiate
To cognize again is to
2024-07-27 17:20:56 root INFO     [order_1_approx] starting weight calculation for To emerge again is to reemerge
To cognize again is to recognize
To marry again is to remarry
To negotiate again is to renegotiate
To learn again is to relearn
To distribute again is to redistribute
To grow again is to regrow
To define again is to
2024-07-27 17:20:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 17:23:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4146, -0.0682,  0.1562,  ...,  0.0173, -0.0079, -0.2832],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-3.7285, -4.6953,  3.8730,  ...,  1.4258, -4.5234, -3.6016],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0464, -0.0055,  0.0075,  ..., -0.0099, -0.0016,  0.0046],
        [ 0.0084,  0.0407,  0.0051,  ..., -0.0033,  0.0018, -0.0032],
        [-0.0209,  0.0163,  0.0477,  ...,  0.0083, -0.0099,  0.0109],
        ...,
        [ 0.0136, -0.0005,  0.0027,  ...,  0.0557,  0.0085,  0.0036],
        [ 0.0073,  0.0090,  0.0079,  ..., -0.0045,  0.0332, -0.0077],
        [-0.0079,  0.0101, -0.0039,  ..., -0.0082, -0.0152,  0.0413]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-3.7949, -4.7812,  3.4844,  ...,  1.6465, -4.7422, -3.2715]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 17:23:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To emerge again is to reemerge
To cognize again is to recognize
To marry again is to remarry
To negotiate again is to renegotiate
To learn again is to relearn
To distribute again is to redistribute
To grow again is to regrow
To define again is to
2024-07-27 17:23:18 root INFO     [order_1_approx] starting weight calculation for To cognize again is to recognize
To grow again is to regrow
To distribute again is to redistribute
To learn again is to relearn
To emerge again is to reemerge
To negotiate again is to renegotiate
To define again is to redefine
To marry again is to
2024-07-27 17:23:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 17:25:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2170,  0.3340, -0.1002,  ...,  0.0327, -0.3799,  0.3806],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1870, -2.9355,  2.3809,  ..., -1.0508, -4.2109, -3.6055],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0328,  0.0083,  0.0232,  ..., -0.0010, -0.0129,  0.0048],
        [ 0.0041,  0.0306, -0.0067,  ...,  0.0060, -0.0068,  0.0051],
        [ 0.0240, -0.0002,  0.0333,  ..., -0.0096, -0.0223,  0.0161],
        ...,
        [ 0.0088, -0.0011, -0.0028,  ...,  0.0369,  0.0016, -0.0041],
        [ 0.0097, -0.0026,  0.0053,  ..., -0.0020,  0.0133,  0.0063],
        [ 0.0031, -0.0077, -0.0042,  ..., -0.0100, -0.0157,  0.0374]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0999, -3.0625,  2.1055,  ..., -0.8354, -4.1680, -3.5742]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 17:25:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To cognize again is to recognize
To grow again is to regrow
To distribute again is to redistribute
To learn again is to relearn
To emerge again is to reemerge
To negotiate again is to renegotiate
To define again is to redefine
To marry again is to
2024-07-27 17:25:39 root INFO     [order_1_approx] starting weight calculation for To negotiate again is to renegotiate
To grow again is to regrow
To distribute again is to redistribute
To learn again is to relearn
To marry again is to remarry
To cognize again is to recognize
To define again is to redefine
To emerge again is to
2024-07-27 17:25:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 17:28:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2385,  0.0576, -0.3787,  ...,  0.1562,  0.1558,  0.3735],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2480, -1.1650, -0.4280,  ...,  3.0547, -5.6875, -2.6172],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0383,  0.0035,  0.0080,  ..., -0.0050,  0.0012,  0.0148],
        [ 0.0047,  0.0398,  0.0125,  ...,  0.0101, -0.0082,  0.0034],
        [ 0.0087,  0.0075,  0.0293,  ...,  0.0068, -0.0072, -0.0230],
        ...,
        [ 0.0026,  0.0177, -0.0011,  ...,  0.0471, -0.0146,  0.0027],
        [-0.0044,  0.0220, -0.0151,  ..., -0.0032,  0.0466, -0.0095],
        [-0.0032,  0.0014,  0.0092,  ..., -0.0124, -0.0332,  0.0343]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1875, -1.1279, -0.2473,  ...,  2.9863, -5.9219, -2.4355]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 17:28:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To negotiate again is to renegotiate
To grow again is to regrow
To distribute again is to redistribute
To learn again is to relearn
To marry again is to remarry
To cognize again is to recognize
To define again is to redefine
To emerge again is to
2024-07-27 17:28:02 root INFO     [order_1_approx] starting weight calculation for To emerge again is to reemerge
To negotiate again is to renegotiate
To learn again is to relearn
To grow again is to regrow
To define again is to redefine
To cognize again is to recognize
To marry again is to remarry
To distribute again is to
2024-07-27 17:28:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 17:30:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4500,  0.5405, -0.2253,  ...,  0.4170,  0.0104,  0.3352],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3633, -5.0312,  1.8945,  ..., -0.4639, -7.6328, -3.7715],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0684,  0.0179,  0.0169,  ..., -0.0055, -0.0336,  0.0140],
        [ 0.0093,  0.0573,  0.0057,  ...,  0.0129, -0.0048, -0.0104],
        [ 0.0212, -0.0006,  0.0529,  ..., -0.0160, -0.0129, -0.0023],
        ...,
        [ 0.0265, -0.0022, -0.0148,  ...,  0.0501, -0.0014, -0.0064],
        [-0.0023,  0.0142, -0.0134,  ..., -0.0285,  0.0471, -0.0088],
        [-0.0037, -0.0049, -0.0022,  ..., -0.0117, -0.0109,  0.0673]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3477, -5.3086,  1.9023,  ..., -0.1248, -7.3359, -3.5527]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 17:30:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To emerge again is to reemerge
To negotiate again is to renegotiate
To learn again is to relearn
To grow again is to regrow
To define again is to redefine
To cognize again is to recognize
To marry again is to remarry
To distribute again is to
2024-07-27 17:30:24 root INFO     [order_1_approx] starting weight calculation for To cognize again is to recognize
To marry again is to remarry
To distribute again is to redistribute
To learn again is to relearn
To negotiate again is to renegotiate
To emerge again is to reemerge
To define again is to redefine
To grow again is to
2024-07-27 17:30:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 17:32:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3481,  0.0764, -0.3406,  ..., -0.1919, -0.1478,  0.0515],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4126, -2.7637,  0.6592,  ...,  0.0684, -4.8398, -3.9805],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.3243e-02, -8.8501e-03,  1.3153e-02,  ...,  1.5823e-02,
         -2.4536e-02,  1.3893e-02],
        [ 5.6458e-03,  2.9495e-02,  4.7264e-03,  ...,  5.8327e-03,
         -1.7319e-02,  4.0207e-03],
        [ 1.4732e-02,  8.3313e-03,  4.4769e-02,  ..., -5.0163e-03,
         -2.5787e-03,  3.0270e-03],
        ...,
        [-1.3351e-03,  1.4782e-05, -7.9193e-03,  ...,  6.2683e-02,
          2.2659e-03,  8.0948e-03],
        [-9.4910e-03,  2.3712e-02,  1.6220e-02,  ..., -8.3694e-03,
          2.9053e-02, -2.4551e-02],
        [ 1.0284e-02, -2.9678e-03,  1.3561e-03,  ..., -6.1340e-03,
         -1.3336e-02,  4.2969e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0747, -3.2852,  0.6377,  ...,  0.3149, -4.6875, -3.9785]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 17:32:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To cognize again is to recognize
To marry again is to remarry
To distribute again is to redistribute
To learn again is to relearn
To negotiate again is to renegotiate
To emerge again is to reemerge
To define again is to redefine
To grow again is to
2024-07-27 17:32:45 root INFO     total operator prediction time: 1134.526183605194 seconds
2024-07-27 17:32:45 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on un+adj_reg
2024-07-27 17:32:45 root INFO     building operator un+adj_reg
2024-07-27 17:32:45 root INFO     [order_1_approx] starting weight calculation for The opposite of popular is unpopular
The opposite of avoidable is unavoidable
The opposite of reliable is unreliable
The opposite of lawful is unlawful
The opposite of conscious is unconscious
The opposite of reasonable is unreasonable
The opposite of affected is unaffected
The opposite of noticed is
2024-07-27 17:32:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 17:35:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0126,  0.2759, -0.3567,  ..., -0.0839, -0.4453,  0.2211],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0771,  0.7207, -1.1172,  ..., -3.7188, -2.3496, -1.4775],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0760, -0.0162,  0.0102,  ...,  0.0279,  0.0120,  0.0347],
        [-0.0272,  0.0434,  0.0190,  ...,  0.0156,  0.0088, -0.0043],
        [ 0.0055,  0.0142,  0.0424,  ...,  0.0097, -0.0206, -0.0223],
        ...,
        [-0.0138,  0.0238,  0.0175,  ...,  0.0388, -0.0014, -0.0006],
        [-0.0227,  0.0149,  0.0180,  ..., -0.0152,  0.0466, -0.0327],
        [ 0.0156, -0.0138, -0.0431,  ...,  0.0039,  0.0054,  0.0578]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3374,  0.7412, -0.9038,  ..., -3.5996, -2.4746, -1.8184]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 17:35:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of popular is unpopular
The opposite of avoidable is unavoidable
The opposite of reliable is unreliable
The opposite of lawful is unlawful
The opposite of conscious is unconscious
The opposite of reasonable is unreasonable
The opposite of affected is unaffected
The opposite of noticed is
2024-07-27 17:35:06 root INFO     [order_1_approx] starting weight calculation for The opposite of affected is unaffected
The opposite of conscious is unconscious
The opposite of lawful is unlawful
The opposite of reliable is unreliable
The opposite of popular is unpopular
The opposite of noticed is unnoticed
The opposite of reasonable is unreasonable
The opposite of avoidable is
2024-07-27 17:35:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 17:37:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3574,  0.1722, -0.2388,  ..., -0.5098, -0.0783,  0.0696],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7744, -1.5664, -1.0469,  ..., -0.3486, -3.9258, -4.9492],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0788,  0.0342,  0.0012,  ...,  0.0213, -0.0463,  0.0182],
        [-0.0022,  0.0666, -0.0129,  ...,  0.0277,  0.0266, -0.0117],
        [ 0.0103, -0.0068,  0.0376,  ..., -0.0230, -0.0094,  0.0007],
        ...,
        [ 0.0081,  0.0059, -0.0050,  ...,  0.0017,  0.0181, -0.0203],
        [-0.0136,  0.0058,  0.0300,  ..., -0.0366,  0.0336, -0.0181],
        [-0.0015, -0.0100, -0.0067,  ..., -0.0199,  0.0188,  0.0383]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2344, -1.5088, -1.3330,  ...,  0.1489, -3.7715, -4.8594]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 17:37:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of affected is unaffected
The opposite of conscious is unconscious
The opposite of lawful is unlawful
The opposite of reliable is unreliable
The opposite of popular is unpopular
The opposite of noticed is unnoticed
The opposite of reasonable is unreasonable
The opposite of avoidable is
2024-07-27 17:37:28 root INFO     [order_1_approx] starting weight calculation for The opposite of reasonable is unreasonable
The opposite of noticed is unnoticed
The opposite of avoidable is unavoidable
The opposite of conscious is unconscious
The opposite of popular is unpopular
The opposite of reliable is unreliable
The opposite of affected is unaffected
The opposite of lawful is
2024-07-27 17:37:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 17:39:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3989,  0.0919, -0.3027,  ..., -0.0485, -0.2100, -0.3682],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7344, -1.7197,  0.8120,  ...,  2.3418, -0.3652, -1.2227],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0626, -0.0143, -0.0012,  ...,  0.0173, -0.0138,  0.0043],
        [ 0.0254,  0.0449,  0.0003,  ...,  0.0286,  0.0107,  0.0134],
        [-0.0134,  0.0233,  0.0151,  ...,  0.0169, -0.0398, -0.0324],
        ...,
        [ 0.0010,  0.0236, -0.0170,  ...,  0.0123, -0.0023, -0.0123],
        [-0.0099,  0.0007, -0.0001,  ...,  0.0049,  0.0584, -0.0098],
        [ 0.0005,  0.0167, -0.0386,  ..., -0.0238, -0.0135,  0.0569]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8496, -2.0312,  0.9321,  ...,  2.5898, -0.4233, -1.6016]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 17:39:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of reasonable is unreasonable
The opposite of noticed is unnoticed
The opposite of avoidable is unavoidable
The opposite of conscious is unconscious
The opposite of popular is unpopular
The opposite of reliable is unreliable
The opposite of affected is unaffected
The opposite of lawful is
2024-07-27 17:39:48 root INFO     [order_1_approx] starting weight calculation for The opposite of conscious is unconscious
The opposite of avoidable is unavoidable
The opposite of noticed is unnoticed
The opposite of popular is unpopular
The opposite of affected is unaffected
The opposite of reasonable is unreasonable
The opposite of lawful is unlawful
The opposite of reliable is
2024-07-27 17:39:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 17:42:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0557,  0.1085, -0.6177,  ...,  0.0741, -0.1979, -0.2939],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2324, -1.8047, -0.2148,  ...,  0.0054, -1.6309, -3.3203],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0919, -0.0092,  0.0063,  ...,  0.0083, -0.0207, -0.0050],
        [-0.0368,  0.0659,  0.0114,  ...,  0.0232,  0.0207, -0.0005],
        [ 0.0083, -0.0030,  0.0420,  ..., -0.0156, -0.0102, -0.0028],
        ...,
        [ 0.0024,  0.0268,  0.0146,  ...,  0.0343,  0.0017, -0.0043],
        [-0.0077, -0.0010, -0.0020,  ...,  0.0237,  0.0445, -0.0042],
        [-0.0043, -0.0238,  0.0013,  ..., -0.0159, -0.0094,  0.0568]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7285, -1.6514, -0.1704,  ...,  0.1201, -1.9180, -3.6406]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 17:42:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of conscious is unconscious
The opposite of avoidable is unavoidable
The opposite of noticed is unnoticed
The opposite of popular is unpopular
The opposite of affected is unaffected
The opposite of reasonable is unreasonable
The opposite of lawful is unlawful
The opposite of reliable is
2024-07-27 17:42:08 root INFO     [order_1_approx] starting weight calculation for The opposite of popular is unpopular
The opposite of lawful is unlawful
The opposite of noticed is unnoticed
The opposite of reasonable is unreasonable
The opposite of conscious is unconscious
The opposite of reliable is unreliable
The opposite of avoidable is unavoidable
The opposite of affected is
2024-07-27 17:42:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 17:44:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1516,  0.0376, -0.5688,  ..., -0.4453, -0.2732,  0.3945],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2227, -1.1465, -0.0166,  ..., -1.9463, -2.9297, -2.5625],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0212, -0.0500, -0.0119,  ...,  0.0013, -0.0366,  0.0481],
        [ 0.0131,  0.1003,  0.0384,  ...,  0.0619,  0.0039,  0.0059],
        [ 0.0037, -0.0158,  0.0582,  ...,  0.0026,  0.0046,  0.0189],
        ...,
        [ 0.0532,  0.0279,  0.0018,  ...,  0.0583,  0.0233, -0.0042],
        [ 0.0001, -0.0072, -0.0106,  ...,  0.0094,  0.0517, -0.0186],
        [ 0.0438,  0.0127, -0.0068,  ...,  0.0169,  0.0150,  0.0840]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5117, -1.5410, -0.3525,  ..., -1.5732, -3.2344, -3.1250]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 17:44:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of popular is unpopular
The opposite of lawful is unlawful
The opposite of noticed is unnoticed
The opposite of reasonable is unreasonable
The opposite of conscious is unconscious
The opposite of reliable is unreliable
The opposite of avoidable is unavoidable
The opposite of affected is
2024-07-27 17:44:31 root INFO     [order_1_approx] starting weight calculation for The opposite of noticed is unnoticed
The opposite of affected is unaffected
The opposite of popular is unpopular
The opposite of reliable is unreliable
The opposite of reasonable is unreasonable
The opposite of avoidable is unavoidable
The opposite of lawful is unlawful
The opposite of conscious is
2024-07-27 17:44:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 17:46:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1562,  0.1746, -0.3037,  ..., -0.1436, -0.1738,  0.2073],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0996, -0.7734,  4.3477,  ..., -1.9521,  1.1797, -1.2256],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0541, -0.0028, -0.0028,  ...,  0.0251, -0.0338,  0.0117],
        [-0.0317,  0.0381, -0.0002,  ...,  0.0099,  0.0289,  0.0019],
        [-0.0208, -0.0323,  0.0399,  ..., -0.0079, -0.0386,  0.0004],
        ...,
        [ 0.0231,  0.0122,  0.0221,  ...,  0.0429, -0.0006, -0.0220],
        [-0.0102, -0.0176,  0.0256,  ...,  0.0031,  0.0634, -0.0396],
        [ 0.0051, -0.0062, -0.0246,  ...,  0.0010, -0.0070,  0.0531]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6377, -1.0088,  3.5625,  ..., -2.0312,  0.9912, -1.3770]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 17:46:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of noticed is unnoticed
The opposite of affected is unaffected
The opposite of popular is unpopular
The opposite of reliable is unreliable
The opposite of reasonable is unreasonable
The opposite of avoidable is unavoidable
The opposite of lawful is unlawful
The opposite of conscious is
2024-07-27 17:46:53 root INFO     [order_1_approx] starting weight calculation for The opposite of noticed is unnoticed
The opposite of lawful is unlawful
The opposite of avoidable is unavoidable
The opposite of reliable is unreliable
The opposite of conscious is unconscious
The opposite of popular is unpopular
The opposite of affected is unaffected
The opposite of reasonable is
2024-07-27 17:46:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 17:49:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2678, -0.0067, -0.3970,  ..., -0.5596, -0.1351, -0.2859],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8086, -1.4648,  0.0605,  ..., -1.5195, -3.4062, -4.2500],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0764,  0.0070,  0.0129,  ...,  0.0067, -0.0056,  0.0201],
        [ 0.0244,  0.0385, -0.0170,  ...,  0.0069,  0.0216,  0.0057],
        [-0.0087,  0.0154,  0.0612,  ...,  0.0060, -0.0411,  0.0056],
        ...,
        [ 0.0128,  0.0166,  0.0114,  ...,  0.0607,  0.0067,  0.0162],
        [-0.0201,  0.0285,  0.0185,  ..., -0.0073,  0.0618, -0.0206],
        [ 0.0113,  0.0030, -0.0094,  ..., -0.0149, -0.0283,  0.0494]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6406, -1.8223,  0.3481,  ..., -1.3242, -2.9922, -4.1797]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 17:49:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of noticed is unnoticed
The opposite of lawful is unlawful
The opposite of avoidable is unavoidable
The opposite of reliable is unreliable
The opposite of conscious is unconscious
The opposite of popular is unpopular
The opposite of affected is unaffected
The opposite of reasonable is
2024-07-27 17:49:16 root INFO     [order_1_approx] starting weight calculation for The opposite of conscious is unconscious
The opposite of reasonable is unreasonable
The opposite of affected is unaffected
The opposite of avoidable is unavoidable
The opposite of noticed is unnoticed
The opposite of lawful is unlawful
The opposite of reliable is unreliable
The opposite of popular is
2024-07-27 17:49:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 17:51:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3794,  0.2140, -0.0385,  ...,  0.3508, -0.0990, -0.0674],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3701, -1.2715,  2.2422,  ..., -2.9609, -2.5645, -0.1094],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0703,  0.0070,  0.0159,  ...,  0.0093, -0.0016,  0.0209],
        [-0.0027,  0.0487, -0.0054,  ...,  0.0182, -0.0049, -0.0151],
        [ 0.0045, -0.0139,  0.0507,  ..., -0.0017,  0.0093, -0.0113],
        ...,
        [ 0.0215,  0.0261, -0.0031,  ...,  0.0456,  0.0159,  0.0072],
        [-0.0359, -0.0179,  0.0032,  ...,  0.0166,  0.0347, -0.0022],
        [ 0.0253, -0.0062, -0.0248,  ..., -0.0116, -0.0102,  0.0386]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6924, -1.1904,  1.8203,  ..., -2.5488, -2.5312, -0.2122]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 17:51:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of conscious is unconscious
The opposite of reasonable is unreasonable
The opposite of affected is unaffected
The opposite of avoidable is unavoidable
The opposite of noticed is unnoticed
The opposite of lawful is unlawful
The opposite of reliable is unreliable
The opposite of popular is
2024-07-27 17:51:37 root INFO     total operator prediction time: 1132.7503917217255 seconds
2024-07-27 17:51:37 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+able_reg
2024-07-27 17:51:37 root INFO     building operator verb+able_reg
2024-07-27 17:51:38 root INFO     [order_1_approx] starting weight calculation for If you can execute something, that thing is executable
If you can prefer something, that thing is preferable
If you can predict something, that thing is predictable
If you can learn something, that thing is learnable
If you can imagine something, that thing is imaginable
If you can maintain something, that thing is maintainable
If you can adapt something, that thing is adaptable
If you can recommend something, that thing is
2024-07-27 17:51:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 17:53:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1913,  0.4185,  0.1152,  ...,  0.3625,  0.0006, -0.3193],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0469,  1.2305, -0.9014,  ..., -1.8848, -9.4219, -3.3594],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0415,  0.0102,  0.0081,  ...,  0.0436, -0.0144,  0.0404],
        [ 0.0081,  0.0455, -0.0113,  ...,  0.0199, -0.0130,  0.0266],
        [ 0.0090,  0.0025,  0.0500,  ...,  0.0075, -0.0161, -0.0081],
        ...,
        [ 0.0084,  0.0142, -0.0095,  ...,  0.0870, -0.0031,  0.0275],
        [ 0.0094,  0.0049,  0.0103,  ..., -0.0378,  0.0264, -0.0427],
        [-0.0070, -0.0041, -0.0063,  ..., -0.0112, -0.0147,  0.0347]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0117,  1.6611, -1.5547,  ..., -1.6436, -9.6328, -3.6562]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 17:53:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can execute something, that thing is executable
If you can prefer something, that thing is preferable
If you can predict something, that thing is predictable
If you can learn something, that thing is learnable
If you can imagine something, that thing is imaginable
If you can maintain something, that thing is maintainable
If you can adapt something, that thing is adaptable
If you can recommend something, that thing is
2024-07-27 17:53:58 root INFO     [order_1_approx] starting weight calculation for If you can learn something, that thing is learnable
If you can imagine something, that thing is imaginable
If you can predict something, that thing is predictable
If you can maintain something, that thing is maintainable
If you can recommend something, that thing is recommendable
If you can execute something, that thing is executable
If you can prefer something, that thing is preferable
If you can adapt something, that thing is
2024-07-27 17:53:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 17:56:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2378,  0.5146, -0.3804,  ..., -0.3440, -0.0186,  0.3518],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9062,  0.7793, -2.6484,  ..., -1.2451, -9.5391, -0.8906],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.7109e-02,  4.7760e-03, -6.5117e-03,  ...,  1.5221e-02,
          1.6479e-02,  3.5156e-02],
        [-8.6365e-03,  5.2032e-02,  8.7357e-03,  ...,  1.1110e-03,
          2.6588e-03,  3.0479e-03],
        [-9.1553e-03, -1.4877e-02,  3.4760e-02,  ...,  1.8478e-02,
          4.0054e-03, -2.7664e-02],
        ...,
        [ 9.0027e-03,  1.9409e-02,  5.9242e-03,  ...,  3.7750e-02,
          1.4133e-03, -1.1223e-02],
        [ 1.5793e-02,  1.2405e-02, -6.0425e-03,  ..., -2.7145e-02,
          1.9333e-02, -8.1787e-03],
        [-2.4796e-05, -2.2125e-03, -7.9422e-03,  ..., -5.1117e-03,
         -2.1149e-02,  7.5264e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5977,  0.7295, -2.5625,  ..., -1.4092, -9.3125, -0.7969]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 17:56:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can learn something, that thing is learnable
If you can imagine something, that thing is imaginable
If you can predict something, that thing is predictable
If you can maintain something, that thing is maintainable
If you can recommend something, that thing is recommendable
If you can execute something, that thing is executable
If you can prefer something, that thing is preferable
If you can adapt something, that thing is
2024-07-27 17:56:19 root INFO     [order_1_approx] starting weight calculation for If you can maintain something, that thing is maintainable
If you can recommend something, that thing is recommendable
If you can learn something, that thing is learnable
If you can imagine something, that thing is imaginable
If you can prefer something, that thing is preferable
If you can execute something, that thing is executable
If you can adapt something, that thing is adaptable
If you can predict something, that thing is
2024-07-27 17:56:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 17:58:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2002,  0.5415,  0.2739,  ..., -0.1772,  0.3833, -0.0844],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5781,  0.8584, -1.8701,  ..., -1.6094, -7.9062, -1.6504],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0506,  0.0108, -0.0092,  ...,  0.0144, -0.0096,  0.0295],
        [-0.0280,  0.0381,  0.0261,  ...,  0.0069, -0.0084,  0.0112],
        [-0.0187, -0.0023,  0.0280,  ...,  0.0041, -0.0074, -0.0209],
        ...,
        [-0.0163,  0.0155,  0.0025,  ...,  0.0583,  0.0002, -0.0059],
        [ 0.0073,  0.0120, -0.0091,  ..., -0.0325,  0.0356, -0.0190],
        [-0.0095,  0.0095,  0.0108,  ..., -0.0120, -0.0269,  0.0277]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5820,  0.6084, -2.2695,  ..., -1.4473, -8.0156, -1.7803]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 17:58:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can maintain something, that thing is maintainable
If you can recommend something, that thing is recommendable
If you can learn something, that thing is learnable
If you can imagine something, that thing is imaginable
If you can prefer something, that thing is preferable
If you can execute something, that thing is executable
If you can adapt something, that thing is adaptable
If you can predict something, that thing is
2024-07-27 17:58:40 root INFO     [order_1_approx] starting weight calculation for If you can imagine something, that thing is imaginable
If you can recommend something, that thing is recommendable
If you can predict something, that thing is predictable
If you can learn something, that thing is learnable
If you can execute something, that thing is executable
If you can adapt something, that thing is adaptable
If you can maintain something, that thing is maintainable
If you can prefer something, that thing is
2024-07-27 17:58:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 18:00:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0422,  0.0057, -0.1218,  ...,  0.1240, -0.0345,  0.2627],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6875,  1.6133, -1.7178,  ..., -1.0371, -9.0938, -3.9414],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0287,  0.0111,  0.0058,  ...,  0.0144, -0.0217,  0.0266],
        [-0.0029,  0.0634,  0.0167,  ...,  0.0202, -0.0129,  0.0016],
        [-0.0109, -0.0141,  0.0368,  ...,  0.0127, -0.0142,  0.0039],
        ...,
        [ 0.0048,  0.0215,  0.0003,  ...,  0.0604, -0.0093,  0.0272],
        [ 0.0232,  0.0135,  0.0085,  ..., -0.0240,  0.0260, -0.0037],
        [-0.0039, -0.0239, -0.0047,  ..., -0.0156, -0.0007,  0.0332]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1074,  1.5088, -1.3828,  ..., -1.4102, -8.6328, -4.0156]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 18:01:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can imagine something, that thing is imaginable
If you can recommend something, that thing is recommendable
If you can predict something, that thing is predictable
If you can learn something, that thing is learnable
If you can execute something, that thing is executable
If you can adapt something, that thing is adaptable
If you can maintain something, that thing is maintainable
If you can prefer something, that thing is
2024-07-27 18:01:01 root INFO     [order_1_approx] starting weight calculation for If you can maintain something, that thing is maintainable
If you can recommend something, that thing is recommendable
If you can prefer something, that thing is preferable
If you can execute something, that thing is executable
If you can adapt something, that thing is adaptable
If you can imagine something, that thing is imaginable
If you can predict something, that thing is predictable
If you can learn something, that thing is
2024-07-27 18:01:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 18:03:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2876,  0.2603,  0.0045,  ..., -0.3962,  0.0621,  0.1063],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.0645, -0.3987,  1.6104,  ..., -0.3958, -9.1406, -4.6875],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0409, -0.0067, -0.0002,  ...,  0.0064,  0.0043,  0.0123],
        [-0.0219,  0.0464, -0.0023,  ..., -0.0010,  0.0051,  0.0149],
        [ 0.0041, -0.0198,  0.0380,  ...,  0.0011,  0.0005,  0.0006],
        ...,
        [ 0.0286,  0.0139, -0.0049,  ...,  0.0273,  0.0005, -0.0191],
        [ 0.0015, -0.0041,  0.0068,  ..., -0.0325,  0.0285, -0.0169],
        [-0.0153, -0.0186,  0.0190,  ..., -0.0072, -0.0162,  0.0075]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.2168, -0.3728,  1.5293,  ...,  0.0742, -8.8438, -4.9414]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 18:03:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can maintain something, that thing is maintainable
If you can recommend something, that thing is recommendable
If you can prefer something, that thing is preferable
If you can execute something, that thing is executable
If you can adapt something, that thing is adaptable
If you can imagine something, that thing is imaginable
If you can predict something, that thing is predictable
If you can learn something, that thing is
2024-07-27 18:03:21 root INFO     [order_1_approx] starting weight calculation for If you can learn something, that thing is learnable
If you can prefer something, that thing is preferable
If you can predict something, that thing is predictable
If you can recommend something, that thing is recommendable
If you can execute something, that thing is executable
If you can adapt something, that thing is adaptable
If you can maintain something, that thing is maintainable
If you can imagine something, that thing is
2024-07-27 18:03:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 18:05:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2742,  0.0144,  0.6479,  ...,  0.0024,  0.2032,  0.0284],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1973,  1.0156,  1.6182,  ..., -3.2168, -8.8281, -2.1875],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0311, -0.0070,  0.0009,  ...,  0.0152, -0.0020,  0.0177],
        [ 0.0018,  0.0613,  0.0062,  ...,  0.0208, -0.0266,  0.0163],
        [-0.0169, -0.0094,  0.0477,  ...,  0.0021, -0.0041, -0.0124],
        ...,
        [ 0.0046,  0.0202, -0.0132,  ...,  0.0834, -0.0202,  0.0080],
        [ 0.0111,  0.0026, -0.0174,  ..., -0.0414,  0.0420, -0.0089],
        [ 0.0125, -0.0035, -0.0104,  ..., -0.0178, -0.0602,  0.0530]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2793,  0.9199,  1.1631,  ..., -2.5742, -8.3750, -2.3867]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 18:05:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can learn something, that thing is learnable
If you can prefer something, that thing is preferable
If you can predict something, that thing is predictable
If you can recommend something, that thing is recommendable
If you can execute something, that thing is executable
If you can adapt something, that thing is adaptable
If you can maintain something, that thing is maintainable
If you can imagine something, that thing is
2024-07-27 18:05:38 root INFO     [order_1_approx] starting weight calculation for If you can recommend something, that thing is recommendable
If you can predict something, that thing is predictable
If you can adapt something, that thing is adaptable
If you can prefer something, that thing is preferable
If you can execute something, that thing is executable
If you can imagine something, that thing is imaginable
If you can learn something, that thing is learnable
If you can maintain something, that thing is
2024-07-27 18:05:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 18:07:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2810,  0.1599, -0.2324,  ...,  0.2900,  0.0197,  0.2120],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8818,  0.0796, -3.0625,  ..., -4.9141, -6.8672, -1.5215],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0381, -0.0007,  0.0018,  ...,  0.0437, -0.0096,  0.0289],
        [-0.0034,  0.0531,  0.0085,  ...,  0.0044,  0.0055, -0.0044],
        [ 0.0128, -0.0048,  0.0377,  ..., -0.0048,  0.0105,  0.0015],
        ...,
        [ 0.0152,  0.0114,  0.0027,  ...,  0.0388,  0.0071,  0.0014],
        [ 0.0148,  0.0037,  0.0010,  ..., -0.0384,  0.0229, -0.0341],
        [-0.0139,  0.0033, -0.0039,  ..., -0.0233, -0.0013,  0.0099]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.0371, -0.2109, -3.3965,  ..., -4.9766, -6.5391, -1.4092]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 18:07:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can recommend something, that thing is recommendable
If you can predict something, that thing is predictable
If you can adapt something, that thing is adaptable
If you can prefer something, that thing is preferable
If you can execute something, that thing is executable
If you can imagine something, that thing is imaginable
If you can learn something, that thing is learnable
If you can maintain something, that thing is
2024-07-27 18:07:57 root INFO     [order_1_approx] starting weight calculation for If you can recommend something, that thing is recommendable
If you can prefer something, that thing is preferable
If you can maintain something, that thing is maintainable
If you can adapt something, that thing is adaptable
If you can predict something, that thing is predictable
If you can imagine something, that thing is imaginable
If you can learn something, that thing is learnable
If you can execute something, that thing is
2024-07-27 18:07:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 18:10:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2737,  0.3486, -0.4453,  ...,  0.2365,  0.1906, -0.0550],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3330, -1.2207,  1.6836,  ..., -1.7725, -7.9141, -5.1094],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0285, -0.0063,  0.0043,  ...,  0.0266, -0.0070,  0.0318],
        [-0.0077,  0.0636, -0.0042,  ...,  0.0156, -0.0097, -0.0157],
        [ 0.0092, -0.0046,  0.0393,  ..., -0.0057, -0.0002,  0.0015],
        ...,
        [-0.0011,  0.0132, -0.0227,  ...,  0.0505,  0.0094, -0.0225],
        [ 0.0100,  0.0049, -0.0071,  ..., -0.0371,  0.0198, -0.0179],
        [ 0.0123, -0.0175, -0.0007,  ..., -0.0137, -0.0173,  0.0265]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2603, -1.0566,  1.5176,  ..., -1.5117, -7.5625, -4.8398]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 18:10:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can recommend something, that thing is recommendable
If you can prefer something, that thing is preferable
If you can maintain something, that thing is maintainable
If you can adapt something, that thing is adaptable
If you can predict something, that thing is predictable
If you can imagine something, that thing is imaginable
If you can learn something, that thing is learnable
If you can execute something, that thing is
2024-07-27 18:10:16 root INFO     total operator prediction time: 1118.801486492157 seconds
2024-07-27 18:10:16 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+tion_irreg
2024-07-27 18:10:16 root INFO     building operator verb+tion_irreg
2024-07-27 18:10:16 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To deprive results in deprivation
To starve results in starvation
To admire results in admiration
To standardize results in standardization
To condense results in condensation
To illumine results in illumination
To customize results in
2024-07-27 18:10:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 18:12:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1550, -0.2112, -0.8398,  ...,  0.1194, -0.8091, -0.1138],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0215, -2.0098,  0.9971,  ...,  2.2773, -3.4434, -1.6465],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0481, -0.0058,  0.0123,  ...,  0.0154,  0.0025,  0.0064],
        [-0.0047,  0.0619,  0.0069,  ...,  0.0252,  0.0011,  0.0173],
        [-0.0103, -0.0121,  0.0172,  ..., -0.0007,  0.0133, -0.0118],
        ...,
        [-0.0054,  0.0097,  0.0107,  ...,  0.0399,  0.0098, -0.0035],
        [-0.0050,  0.0012,  0.0029,  ..., -0.0092,  0.0411, -0.0153],
        [-0.0070,  0.0026,  0.0008,  ...,  0.0039, -0.0233,  0.0412]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8931, -1.9131,  1.2695,  ...,  2.6914, -3.3242, -1.5166]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 18:12:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To aspire results in aspiration
To deprive results in deprivation
To starve results in starvation
To admire results in admiration
To standardize results in standardization
To condense results in condensation
To illumine results in illumination
To customize results in
2024-07-27 18:12:39 root INFO     [order_1_approx] starting weight calculation for To standardize results in standardization
To starve results in starvation
To illumine results in illumination
To admire results in admiration
To aspire results in aspiration
To customize results in customization
To condense results in condensation
To deprive results in
2024-07-27 18:12:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 18:14:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2388,  0.2311, -0.7344,  ..., -0.1414,  0.0395,  0.1945],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0879, -3.3184,  2.2949,  ...,  0.7397, -2.3125, -1.9355],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0374,  0.0034, -0.0076,  ..., -0.0136,  0.0079, -0.0122],
        [ 0.0208,  0.0562,  0.0175,  ...,  0.0294, -0.0053,  0.0201],
        [-0.0008, -0.0267,  0.0305,  ...,  0.0060, -0.0087, -0.0092],
        ...,
        [ 0.0066,  0.0106, -0.0094,  ...,  0.0551, -0.0030,  0.0032],
        [-0.0142, -0.0036,  0.0077,  ...,  0.0098,  0.0538, -0.0164],
        [ 0.0133, -0.0020, -0.0005,  ...,  0.0041, -0.0318,  0.0552]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0059, -3.1465,  2.3125,  ...,  0.6680, -2.5098, -1.9355]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 18:14:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To standardize results in standardization
To starve results in starvation
To illumine results in illumination
To admire results in admiration
To aspire results in aspiration
To customize results in customization
To condense results in condensation
To deprive results in
2024-07-27 18:14:55 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To customize results in customization
To deprive results in deprivation
To condense results in condensation
To illumine results in illumination
To standardize results in standardization
To admire results in admiration
To starve results in
2024-07-27 18:14:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 18:17:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2235, -0.0974, -0.6597,  ..., -0.2913,  0.1214, -0.1260],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4375, -3.9727,  2.5234,  ...,  0.6719, -2.0723, -1.8750],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.4575e-02,  8.6746e-03,  2.2614e-02,  ...,  6.2256e-03,
         -4.2267e-03,  5.1117e-04],
        [ 5.0735e-03,  4.9622e-02, -5.1880e-03,  ...,  4.0680e-02,
          4.6692e-03,  9.7609e-04],
        [ 8.7967e-03, -3.3234e-02,  3.5797e-02,  ..., -3.2692e-03,
         -1.0330e-02, -5.0125e-03],
        ...,
        [ 4.4556e-03,  8.5220e-03, -4.6635e-04,  ...,  3.4363e-02,
          1.0284e-02, -5.7220e-05],
        [-2.2797e-02,  6.1569e-03,  1.9852e-02,  ...,  7.6523e-03,
          5.3986e-02, -9.1095e-03],
        [-1.6565e-03, -2.8362e-03, -1.9760e-02,  ...,  5.8556e-03,
         -2.0782e-02,  6.0638e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4629, -4.0234,  2.5488,  ...,  1.5410, -2.1973, -1.5176]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 18:17:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To aspire results in aspiration
To customize results in customization
To deprive results in deprivation
To condense results in condensation
To illumine results in illumination
To standardize results in standardization
To admire results in admiration
To starve results in
2024-07-27 18:17:18 root INFO     [order_1_approx] starting weight calculation for To condense results in condensation
To admire results in admiration
To deprive results in deprivation
To customize results in customization
To standardize results in standardization
To aspire results in aspiration
To starve results in starvation
To illumine results in
2024-07-27 18:17:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 18:19:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3442,  0.6548, -0.8135,  ...,  0.0492, -0.4138, -0.0167],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4697, -0.5430,  1.9453,  ...,  3.9277, -2.4414, -2.3867],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0427,  0.0030, -0.0082,  ..., -0.0169,  0.0023, -0.0069],
        [ 0.0194,  0.0515,  0.0301,  ...,  0.0257, -0.0043,  0.0191],
        [ 0.0040, -0.0059,  0.0399,  ..., -0.0094,  0.0130, -0.0104],
        ...,
        [-0.0032,  0.0019,  0.0102,  ...,  0.0616, -0.0150,  0.0130],
        [ 0.0040,  0.0135, -0.0079,  ..., -0.0029,  0.0385, -0.0050],
        [ 0.0094, -0.0020,  0.0059,  ...,  0.0059, -0.0113,  0.0546]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7041, -0.3562,  2.0117,  ...,  4.0820, -2.6191, -2.3047]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 18:19:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To condense results in condensation
To admire results in admiration
To deprive results in deprivation
To customize results in customization
To standardize results in standardization
To aspire results in aspiration
To starve results in starvation
To illumine results in
2024-07-27 18:19:39 root INFO     [order_1_approx] starting weight calculation for To illumine results in illumination
To standardize results in standardization
To starve results in starvation
To admire results in admiration
To customize results in customization
To deprive results in deprivation
To aspire results in aspiration
To condense results in
2024-07-27 18:19:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 18:21:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0182,  0.2642, -0.7144,  ...,  0.1766, -0.3169, -0.0823],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3040, -2.6035,  2.5820,  ...,  1.3516, -1.5059, -1.2764],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0833,  0.0007, -0.0126,  ..., -0.0101,  0.0055,  0.0106],
        [ 0.0068,  0.0762,  0.0096,  ...,  0.0303,  0.0069,  0.0190],
        [-0.0064, -0.0182,  0.0574,  ...,  0.0074, -0.0152, -0.0152],
        ...,
        [-0.0154,  0.0085,  0.0357,  ...,  0.0740,  0.0049,  0.0043],
        [-0.0018,  0.0075, -0.0024,  ...,  0.0016,  0.0669, -0.0012],
        [ 0.0045,  0.0059,  0.0060,  ..., -0.0053, -0.0266,  0.0674]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3364, -2.9629,  2.3984,  ...,  1.4072, -1.4404, -1.7861]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 18:21:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To illumine results in illumination
To standardize results in standardization
To starve results in starvation
To admire results in admiration
To customize results in customization
To deprive results in deprivation
To aspire results in aspiration
To condense results in
2024-07-27 18:21:58 root INFO     [order_1_approx] starting weight calculation for To standardize results in standardization
To aspire results in aspiration
To starve results in starvation
To condense results in condensation
To illumine results in illumination
To customize results in customization
To deprive results in deprivation
To admire results in
2024-07-27 18:21:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 18:24:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0409,  0.1091, -0.3945,  ...,  0.1384, -0.0480,  0.2336],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4023, -1.9941,  0.1763,  ...,  1.7266, -0.9819, -0.6846],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0277, -0.0192, -0.0112,  ..., -0.0264,  0.0035, -0.0171],
        [ 0.0272,  0.0474,  0.0009,  ...,  0.0178, -0.0009,  0.0204],
        [ 0.0031, -0.0222,  0.0466,  ...,  0.0026,  0.0048, -0.0048],
        ...,
        [ 0.0137, -0.0152,  0.0072,  ...,  0.0382,  0.0160,  0.0132],
        [-0.0121,  0.0107,  0.0066,  ...,  0.0090,  0.0393,  0.0033],
        [ 0.0080,  0.0043, -0.0076,  ..., -0.0080, -0.0203,  0.0442]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7617, -1.6436, -0.1223,  ...,  2.1211, -1.2773, -0.3445]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 18:24:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To standardize results in standardization
To aspire results in aspiration
To starve results in starvation
To condense results in condensation
To illumine results in illumination
To customize results in customization
To deprive results in deprivation
To admire results in
2024-07-27 18:24:17 root INFO     [order_1_approx] starting weight calculation for To starve results in starvation
To condense results in condensation
To admire results in admiration
To aspire results in aspiration
To customize results in customization
To illumine results in illumination
To deprive results in deprivation
To standardize results in
2024-07-27 18:24:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 18:26:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0027,  0.3572, -0.5840,  ..., -0.2944, -0.5029, -0.2590],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0771, -3.6328,  1.2119,  ...,  1.9746, -2.4180, -2.8887],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0495,  0.0007,  0.0091,  ..., -0.0036, -0.0126,  0.0063],
        [-0.0106,  0.0490,  0.0003,  ...,  0.0089,  0.0080,  0.0076],
        [-0.0192, -0.0061,  0.0268,  ...,  0.0023, -0.0010, -0.0042],
        ...,
        [-0.0135,  0.0063,  0.0108,  ...,  0.0381, -0.0051,  0.0034],
        [-0.0197,  0.0106, -0.0094,  ...,  0.0018,  0.0392, -0.0217],
        [-0.0169, -0.0022,  0.0043,  ..., -0.0015, -0.0197,  0.0332]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8818, -3.7070,  1.3535,  ...,  2.6035, -2.0469, -2.8652]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 18:26:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To starve results in starvation
To condense results in condensation
To admire results in admiration
To aspire results in aspiration
To customize results in customization
To illumine results in illumination
To deprive results in deprivation
To standardize results in
2024-07-27 18:26:36 root INFO     [order_1_approx] starting weight calculation for To starve results in starvation
To condense results in condensation
To standardize results in standardization
To deprive results in deprivation
To admire results in admiration
To customize results in customization
To illumine results in illumination
To aspire results in
2024-07-27 18:26:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 18:28:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4768,  0.1677, -0.7080,  ...,  0.0455, -0.3525,  0.2629],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6367, -2.9746,  0.6104,  ...,  1.9629, -3.4922, -1.1953],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0334, -0.0185,  0.0007,  ...,  0.0035,  0.0019,  0.0120],
        [ 0.0165,  0.0583,  0.0107,  ...,  0.0257,  0.0006,  0.0095],
        [ 0.0203, -0.0190,  0.0315,  ..., -0.0087,  0.0049, -0.0015],
        ...,
        [-0.0035, -0.0152, -0.0112,  ...,  0.0432,  0.0053, -0.0024],
        [ 0.0004, -0.0031,  0.0075,  ...,  0.0064,  0.0244, -0.0097],
        [ 0.0066, -0.0035, -0.0123,  ...,  0.0016, -0.0148,  0.0441]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8359, -2.8574,  0.5889,  ...,  2.2168, -3.8574, -1.3857]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 18:28:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To starve results in starvation
To condense results in condensation
To standardize results in standardization
To deprive results in deprivation
To admire results in admiration
To customize results in customization
To illumine results in illumination
To aspire results in
2024-07-27 18:28:57 root INFO     total operator prediction time: 1120.8261330127716 seconds
2024-07-27 18:28:57 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj+ly_reg
2024-07-27 18:28:57 root INFO     building operator adj+ly_reg
2024-07-27 18:28:57 root INFO     [order_1_approx] starting weight calculation for The adjective form of serious is seriously
The adjective form of political is politically
The adjective form of similar is similarly
The adjective form of practical is practically
The adjective form of creative is creatively
The adjective form of decided is decidedly
The adjective form of unique is uniquely
The adjective form of clinical is
2024-07-27 18:28:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 18:31:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3909, -0.3105, -0.4055,  ..., -0.4399, -0.6777, -0.2168],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3682, -0.4858, -0.3792,  ..., -1.5625,  1.8340, -0.4375],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0801, -0.0218, -0.0004,  ...,  0.0004, -0.0129,  0.0257],
        [-0.0104,  0.0645, -0.0033,  ...,  0.0240,  0.0223,  0.0201],
        [ 0.0060, -0.0192,  0.0617,  ..., -0.0110,  0.0103,  0.0047],
        ...,
        [ 0.0259,  0.0374, -0.0091,  ...,  0.0714, -0.0058,  0.0044],
        [ 0.0056,  0.0401,  0.0246,  ...,  0.0074,  0.0416, -0.0123],
        [-0.0022, -0.0069,  0.0179,  ...,  0.0016,  0.0057,  0.0568]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5312, -0.8926, -0.5840,  ..., -1.4297,  1.5977, -0.4624]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 18:31:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of serious is seriously
The adjective form of political is politically
The adjective form of similar is similarly
The adjective form of practical is practically
The adjective form of creative is creatively
The adjective form of decided is decidedly
The adjective form of unique is uniquely
The adjective form of clinical is
2024-07-27 18:31:19 root INFO     [order_1_approx] starting weight calculation for The adjective form of unique is uniquely
The adjective form of similar is similarly
The adjective form of serious is seriously
The adjective form of practical is practically
The adjective form of clinical is clinically
The adjective form of creative is creatively
The adjective form of political is politically
The adjective form of decided is
2024-07-27 18:31:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 18:33:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1409,  0.1521, -0.3853,  ..., -0.0189, -0.3069,  0.0101],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.9297, -4.5039,  2.3164,  ..., -0.8643, -3.3008, -1.8252],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0759, -0.0107, -0.0106,  ...,  0.0070,  0.0148,  0.0246],
        [ 0.0204,  0.0456,  0.0109,  ...,  0.0131,  0.0115, -0.0127],
        [ 0.0218, -0.0076,  0.0274,  ..., -0.0099,  0.0039, -0.0027],
        ...,
        [ 0.0059,  0.0218, -0.0018,  ...,  0.0598,  0.0101,  0.0032],
        [-0.0235,  0.0326,  0.0338,  ...,  0.0017,  0.0303, -0.0310],
        [-0.0018, -0.0186,  0.0104,  ...,  0.0036, -0.0181,  0.0328]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.5742, -4.2148,  2.9043,  ..., -1.2109, -2.3574, -1.4502]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 18:33:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of unique is uniquely
The adjective form of similar is similarly
The adjective form of serious is seriously
The adjective form of practical is practically
The adjective form of clinical is clinically
The adjective form of creative is creatively
The adjective form of political is politically
The adjective form of decided is
2024-07-27 18:33:38 root INFO     [order_1_approx] starting weight calculation for The adjective form of practical is practically
The adjective form of decided is decidedly
The adjective form of creative is creatively
The adjective form of serious is seriously
The adjective form of similar is similarly
The adjective form of clinical is clinically
The adjective form of unique is uniquely
The adjective form of political is
2024-07-27 18:33:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 18:35:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 5.3906e-01,  2.5293e-01, -1.6528e-01,  ..., -3.2397e-01,
        -5.0830e-01,  1.2207e-04], device='cuda:1', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0918, -2.3398,  1.0723,  ..., -2.4883, -1.6816, -0.4990],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.8818e-02, -6.1874e-03,  1.2299e-02,  ..., -9.4414e-05,
          8.5602e-03,  1.8967e-02],
        [-1.8272e-03,  4.8431e-02,  2.1713e-02,  ...,  1.1276e-02,
          6.6414e-03, -7.4463e-03],
        [ 1.8959e-03, -3.4065e-03,  5.3070e-02,  ...,  1.8524e-02,
         -1.7578e-02,  8.2092e-03],
        ...,
        [ 2.6352e-02, -2.0065e-03, -2.3468e-02,  ...,  6.6711e-02,
          7.5531e-03,  8.2626e-03],
        [-1.5167e-02,  1.7822e-02, -2.3422e-02,  ..., -2.7054e-02,
          5.4138e-02, -4.8676e-03],
        [ 6.4278e-03, -9.4452e-03, -9.0027e-03,  ...,  5.4359e-03,
          6.2370e-03,  4.6936e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5039, -2.4141,  0.7344,  ..., -2.4238, -1.3994, -0.6104]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 18:35:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of practical is practically
The adjective form of decided is decidedly
The adjective form of creative is creatively
The adjective form of serious is seriously
The adjective form of similar is similarly
The adjective form of clinical is clinically
The adjective form of unique is uniquely
The adjective form of political is
2024-07-27 18:35:59 root INFO     [order_1_approx] starting weight calculation for The adjective form of political is politically
The adjective form of unique is uniquely
The adjective form of decided is decidedly
The adjective form of clinical is clinically
The adjective form of practical is practically
The adjective form of similar is similarly
The adjective form of serious is seriously
The adjective form of creative is
2024-07-27 18:35:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 18:38:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5229,  0.2603, -0.1584,  ..., -0.1466, -0.2854, -0.1409],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6445, -1.9922,  3.3457,  ..., -1.2520, -0.6191,  0.7109],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0692, -0.0171,  0.0143,  ..., -0.0175,  0.0214,  0.0188],
        [-0.0115,  0.0632,  0.0180,  ...,  0.0063,  0.0206, -0.0087],
        [ 0.0057, -0.0180,  0.0632,  ..., -0.0093, -0.0076, -0.0061],
        ...,
        [ 0.0266,  0.0104,  0.0078,  ...,  0.0498, -0.0112,  0.0005],
        [ 0.0019,  0.0280,  0.0041,  ...,  0.0019,  0.0370, -0.0067],
        [ 0.0008, -0.0211, -0.0125,  ..., -0.0140, -0.0120,  0.0349]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4556, -2.0020,  3.7539,  ..., -1.1143, -0.8462,  0.7231]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 18:38:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of political is politically
The adjective form of unique is uniquely
The adjective form of decided is decidedly
The adjective form of clinical is clinically
The adjective form of practical is practically
The adjective form of similar is similarly
The adjective form of serious is seriously
The adjective form of creative is
2024-07-27 18:38:21 root INFO     [order_1_approx] starting weight calculation for The adjective form of political is politically
The adjective form of creative is creatively
The adjective form of clinical is clinically
The adjective form of similar is similarly
The adjective form of unique is uniquely
The adjective form of practical is practically
The adjective form of decided is decidedly
The adjective form of serious is
2024-07-27 18:38:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 18:40:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4338, -0.0796, -0.6343,  ...,  0.0168, -0.6338,  0.1631],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6016, -2.0391, -0.6743,  ..., -2.4570, -0.6152, -3.9980],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1080, -0.0123,  0.0176,  ...,  0.0070,  0.0223,  0.0260],
        [ 0.0066,  0.0558,  0.0116,  ...,  0.0045,  0.0081, -0.0001],
        [ 0.0193, -0.0050,  0.0670,  ...,  0.0103,  0.0006,  0.0035],
        ...,
        [-0.0050,  0.0249, -0.0098,  ...,  0.0773,  0.0052,  0.0175],
        [-0.0308,  0.0235,  0.0042,  ..., -0.0036,  0.0546, -0.0140],
        [ 0.0221, -0.0135,  0.0086,  ...,  0.0076, -0.0309,  0.0454]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9888, -1.9258, -0.5356,  ..., -2.2207, -0.3704, -3.9805]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 18:40:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of political is politically
The adjective form of creative is creatively
The adjective form of clinical is clinically
The adjective form of similar is similarly
The adjective form of unique is uniquely
The adjective form of practical is practically
The adjective form of decided is decidedly
The adjective form of serious is
2024-07-27 18:40:43 root INFO     [order_1_approx] starting weight calculation for The adjective form of creative is creatively
The adjective form of political is politically
The adjective form of decided is decidedly
The adjective form of unique is uniquely
The adjective form of serious is seriously
The adjective form of clinical is clinically
The adjective form of practical is practically
The adjective form of similar is
2024-07-27 18:40:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 18:43:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2249, -0.4683, -0.3833,  ...,  0.0686, -0.0999,  0.0825],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3105, -1.1689,  1.1582,  ..., -2.4316,  0.0625, -1.7168],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0787,  0.0011,  0.0232,  ..., -0.0016,  0.0318,  0.0402],
        [ 0.0157,  0.0580,  0.0276,  ...,  0.0086,  0.0146, -0.0174],
        [ 0.0185,  0.0126,  0.0592,  ...,  0.0063, -0.0162, -0.0031],
        ...,
        [ 0.0026,  0.0073, -0.0005,  ...,  0.1005, -0.0020,  0.0081],
        [-0.0203,  0.0271,  0.0083,  ..., -0.0109,  0.0140, -0.0151],
        [ 0.0052, -0.0046, -0.0030,  ...,  0.0123, -0.0327,  0.0302]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6147, -0.9028,  1.3516,  ..., -2.7070, -0.3625, -1.7910]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 18:43:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of creative is creatively
The adjective form of political is politically
The adjective form of decided is decidedly
The adjective form of unique is uniquely
The adjective form of serious is seriously
The adjective form of clinical is clinically
The adjective form of practical is practically
The adjective form of similar is
2024-07-27 18:43:04 root INFO     [order_1_approx] starting weight calculation for The adjective form of creative is creatively
The adjective form of practical is practically
The adjective form of decided is decidedly
The adjective form of similar is similarly
The adjective form of clinical is clinically
The adjective form of political is politically
The adjective form of serious is seriously
The adjective form of unique is
2024-07-27 18:43:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 18:45:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1973, -0.0432, -0.6147,  ...,  0.0043, -0.1742, -0.0026],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5732, -1.5439,  0.6309,  ..., -2.1719, -3.2852, -1.4385],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0906, -0.0085,  0.0192,  ...,  0.0257,  0.0121,  0.0095],
        [-0.0150,  0.0751, -0.0144,  ...,  0.0132,  0.0173,  0.0090],
        [ 0.0166, -0.0068,  0.0502,  ...,  0.0104,  0.0043, -0.0108],
        ...,
        [-0.0003,  0.0042,  0.0109,  ...,  0.0690, -0.0031, -0.0051],
        [ 0.0132,  0.0162,  0.0133,  ..., -0.0060,  0.0350, -0.0181],
        [ 0.0033, -0.0116, -0.0069,  ...,  0.0153, -0.0311,  0.0374]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2432, -1.9111,  1.0430,  ..., -2.1133, -3.3457, -1.7520]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 18:45:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of creative is creatively
The adjective form of practical is practically
The adjective form of decided is decidedly
The adjective form of similar is similarly
The adjective form of clinical is clinically
The adjective form of political is politically
The adjective form of serious is seriously
The adjective form of unique is
2024-07-27 18:45:25 root INFO     [order_1_approx] starting weight calculation for The adjective form of serious is seriously
The adjective form of unique is uniquely
The adjective form of creative is creatively
The adjective form of political is politically
The adjective form of clinical is clinically
The adjective form of decided is decidedly
The adjective form of similar is similarly
The adjective form of practical is
2024-07-27 18:45:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 18:47:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5176, -0.0903, -0.1847,  ..., -0.4727, -0.4070, -0.2452],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7295, -3.0293, -0.5811,  ..., -1.9883, -1.5498, -0.3438],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0704, -0.0113,  0.0015,  ...,  0.0076,  0.0126,  0.0232],
        [-0.0077,  0.0550,  0.0164,  ...,  0.0119,  0.0025, -0.0027],
        [ 0.0026, -0.0045,  0.0553,  ..., -0.0021, -0.0202, -0.0090],
        ...,
        [ 0.0253,  0.0169, -0.0043,  ...,  0.0903,  0.0064,  0.0009],
        [ 0.0071,  0.0045,  0.0212,  ..., -0.0132,  0.0454, -0.0233],
        [-0.0044, -0.0031, -0.0039,  ..., -0.0193, -0.0145,  0.0319]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8867, -2.8477, -0.3857,  ..., -1.4531, -1.4209, -0.1996]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 18:47:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of serious is seriously
The adjective form of unique is uniquely
The adjective form of creative is creatively
The adjective form of political is politically
The adjective form of clinical is clinically
The adjective form of decided is decidedly
The adjective form of similar is similarly
The adjective form of practical is
2024-07-27 18:47:47 root INFO     total operator prediction time: 1129.8525822162628 seconds
2024-07-27 18:47:47 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on over+adj_reg
2024-07-27 18:47:47 root INFO     building operator over+adj_reg
2024-07-27 18:47:47 root INFO     [order_1_approx] starting weight calculation for If something is too protected, it is overprotected
If something is too turned, it is overturned
If something is too written, it is overwritten
If something is too crowded, it is overcrowded
If something is too sold, it is oversold
If something is too simplified, it is oversimplified
If something is too populated, it is overpopulated
If something is too spent, it is
2024-07-27 18:47:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 18:50:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2202, -0.2522, -0.3359,  ..., -0.2734, -0.2871, -0.0096],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4102, -3.0430, -0.8604,  ..., -1.4561, -1.2480, -2.2695],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0690, -0.0059,  0.0043,  ..., -0.0083,  0.0090,  0.0282],
        [-0.0216,  0.0502, -0.0168,  ...,  0.0300,  0.0030,  0.0023],
        [ 0.0249,  0.0161,  0.0607,  ...,  0.0145, -0.0200, -0.0129],
        ...,
        [ 0.0149,  0.0041, -0.0156,  ...,  0.0649,  0.0137,  0.0060],
        [-0.0050,  0.0039,  0.0020,  ...,  0.0191,  0.0603, -0.0121],
        [-0.0063,  0.0154,  0.0103,  ...,  0.0050,  0.0021,  0.0770]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2627, -3.0469, -0.7539,  ..., -1.1016, -0.6240, -2.3438]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 18:50:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too protected, it is overprotected
If something is too turned, it is overturned
If something is too written, it is overwritten
If something is too crowded, it is overcrowded
If something is too sold, it is oversold
If something is too simplified, it is oversimplified
If something is too populated, it is overpopulated
If something is too spent, it is
2024-07-27 18:50:07 root INFO     [order_1_approx] starting weight calculation for If something is too turned, it is overturned
If something is too spent, it is overspent
If something is too sold, it is oversold
If something is too crowded, it is overcrowded
If something is too populated, it is overpopulated
If something is too simplified, it is oversimplified
If something is too written, it is overwritten
If something is too protected, it is
2024-07-27 18:50:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 18:52:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2693, -0.4656, -0.6016,  ..., -0.0785, -0.1132,  0.2690],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5698, -3.4805,  1.7920,  ..., -0.1055, -1.0127, -2.6309],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0475, -0.0153, -0.0009,  ...,  0.0108,  0.0039,  0.0222],
        [-0.0147,  0.0590,  0.0167,  ...,  0.0104,  0.0082, -0.0085],
        [-0.0009,  0.0093,  0.0571,  ...,  0.0327, -0.0227,  0.0148],
        ...,
        [ 0.0077,  0.0034, -0.0054,  ...,  0.0582,  0.0096,  0.0018],
        [ 0.0073,  0.0069, -0.0189,  ..., -0.0006,  0.0602, -0.0167],
        [ 0.0206,  0.0147, -0.0053,  ...,  0.0095, -0.0289,  0.0612]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5781, -3.4238,  1.7109,  ...,  0.0901, -1.1484, -2.6523]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 18:52:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too turned, it is overturned
If something is too spent, it is overspent
If something is too sold, it is oversold
If something is too crowded, it is overcrowded
If something is too populated, it is overpopulated
If something is too simplified, it is oversimplified
If something is too written, it is overwritten
If something is too protected, it is
2024-07-27 18:52:29 root INFO     [order_1_approx] starting weight calculation for If something is too spent, it is overspent
If something is too protected, it is overprotected
If something is too simplified, it is oversimplified
If something is too sold, it is oversold
If something is too written, it is overwritten
If something is too crowded, it is overcrowded
If something is too populated, it is overpopulated
If something is too turned, it is
2024-07-27 18:52:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 18:54:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1506, -0.3665, -0.1531,  ..., -0.1986, -0.0477,  0.1456],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3652, -3.5938,  1.8799,  ..., -0.1702, -0.4626, -1.1387],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0455,  0.0072, -0.0018,  ..., -0.0050,  0.0137,  0.0238],
        [-0.0101,  0.0378, -0.0122,  ...,  0.0208,  0.0037,  0.0042],
        [ 0.0282,  0.0012,  0.0621,  ...,  0.0355,  0.0154, -0.0006],
        ...,
        [ 0.0163, -0.0073, -0.0091,  ...,  0.0671,  0.0127,  0.0028],
        [-0.0045, -0.0081, -0.0021,  ...,  0.0079,  0.0408, -0.0362],
        [-0.0143,  0.0082,  0.0112,  ..., -0.0133, -0.0271,  0.0436]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4668, -3.6055,  1.5654,  ..., -0.1120, -0.1309, -1.4707]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 18:54:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too spent, it is overspent
If something is too protected, it is overprotected
If something is too simplified, it is oversimplified
If something is too sold, it is oversold
If something is too written, it is overwritten
If something is too crowded, it is overcrowded
If something is too populated, it is overpopulated
If something is too turned, it is
2024-07-27 18:54:45 root INFO     [order_1_approx] starting weight calculation for If something is too crowded, it is overcrowded
If something is too sold, it is oversold
If something is too protected, it is overprotected
If something is too turned, it is overturned
If something is too populated, it is overpopulated
If something is too written, it is overwritten
If something is too spent, it is overspent
If something is too simplified, it is
2024-07-27 18:54:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 18:57:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2089,  0.0963, -0.6826,  ..., -0.1658, -0.2322,  0.1035],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4902, -2.1465,  1.0547,  ..., -1.0830, -1.6719, -0.6982],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.0659e-02,  1.0956e-02,  1.0605e-02,  ..., -2.4872e-03,
          1.6968e-02, -1.2589e-03],
        [ 1.9257e-02,  5.9998e-02,  1.1169e-02,  ..., -8.2855e-03,
         -8.6823e-03,  4.4746e-03],
        [ 1.8219e-02,  1.8494e-02,  5.6244e-02,  ...,  2.0599e-02,
         -3.9001e-02, -1.5182e-03],
        ...,
        [ 8.8501e-03,  2.5009e-02,  1.2398e-05,  ...,  8.3557e-02,
          4.0474e-03, -1.6663e-02],
        [ 1.4145e-02,  1.1200e-02, -1.2642e-02,  ...,  1.7670e-02,
          4.4250e-02, -3.6926e-02],
        [-1.8295e-02,  1.8494e-02,  8.5144e-03,  ..., -1.3458e-02,
         -1.3046e-02,  3.4729e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4326, -2.1035,  1.1934,  ..., -0.8657, -1.6016, -0.6157]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 18:57:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too crowded, it is overcrowded
If something is too sold, it is oversold
If something is too protected, it is overprotected
If something is too turned, it is overturned
If something is too populated, it is overpopulated
If something is too written, it is overwritten
If something is too spent, it is overspent
If something is too simplified, it is
2024-07-27 18:57:04 root INFO     [order_1_approx] starting weight calculation for If something is too turned, it is overturned
If something is too simplified, it is oversimplified
If something is too sold, it is oversold
If something is too spent, it is overspent
If something is too protected, it is overprotected
If something is too written, it is overwritten
If something is too populated, it is overpopulated
If something is too crowded, it is
2024-07-27 18:57:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 18:59:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0767, -0.2344, -0.2578,  ..., -0.2671, -0.2756,  0.5796],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3413, -2.4297,  2.4863,  ...,  0.4370,  0.8843,  0.0176],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.1769e-02,  1.6518e-03,  3.0403e-03,  ..., -1.0841e-02,
          3.4485e-03,  9.8572e-03],
        [ 2.6474e-03,  3.6041e-02, -3.0861e-03,  ..., -1.8196e-03,
          4.4975e-03, -9.5215e-03],
        [-1.4725e-03,  1.1063e-02,  2.4612e-02,  ..., -1.3580e-03,
          1.5678e-03,  8.3313e-03],
        ...,
        [ 8.7128e-03,  5.9853e-03,  2.7504e-03,  ...,  4.3823e-02,
          1.1612e-02,  8.6212e-03],
        [-4.7073e-03,  3.7308e-03, -1.0971e-02,  ..., -1.4448e-03,
          3.1158e-02, -5.9929e-03],
        [-8.2245e-03,  8.8577e-03,  1.2009e-02,  ..., -9.0256e-03,
         -8.3685e-05,  3.7842e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2666, -2.2109,  2.4062,  ...,  0.5942,  0.9429, -0.2466]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 18:59:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too turned, it is overturned
If something is too simplified, it is oversimplified
If something is too sold, it is oversold
If something is too spent, it is overspent
If something is too protected, it is overprotected
If something is too written, it is overwritten
If something is too populated, it is overpopulated
If something is too crowded, it is
2024-07-27 18:59:16 root INFO     [order_1_approx] starting weight calculation for If something is too simplified, it is oversimplified
If something is too spent, it is overspent
If something is too turned, it is overturned
If something is too sold, it is oversold
If something is too populated, it is overpopulated
If something is too crowded, it is overcrowded
If something is too protected, it is overprotected
If something is too written, it is
2024-07-27 18:59:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 19:01:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1628, -0.2725, -0.2418,  ..., -0.4619, -0.1578, -0.0543],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8809, -2.9805,  1.8682,  ..., -0.7695, -2.0547, -1.4160],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0376, -0.0056,  0.0012,  ..., -0.0084,  0.0115,  0.0345],
        [-0.0119,  0.0599,  0.0203,  ...,  0.0159, -0.0087, -0.0041],
        [ 0.0075, -0.0009,  0.0598,  ...,  0.0284, -0.0101,  0.0191],
        ...,
        [ 0.0149,  0.0126, -0.0061,  ...,  0.0631, -0.0042, -0.0048],
        [ 0.0105, -0.0034,  0.0030,  ...,  0.0032,  0.0499, -0.0121],
        [ 0.0070,  0.0203,  0.0072,  ...,  0.0092, -0.0262,  0.0424]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8545, -3.1445,  1.9541,  ..., -0.6470, -1.6416, -1.5010]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 19:01:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too simplified, it is oversimplified
If something is too spent, it is overspent
If something is too turned, it is overturned
If something is too sold, it is oversold
If something is too populated, it is overpopulated
If something is too crowded, it is overcrowded
If something is too protected, it is overprotected
If something is too written, it is
2024-07-27 19:01:35 root INFO     [order_1_approx] starting weight calculation for If something is too written, it is overwritten
If something is too sold, it is oversold
If something is too simplified, it is oversimplified
If something is too spent, it is overspent
If something is too turned, it is overturned
If something is too protected, it is overprotected
If something is too crowded, it is overcrowded
If something is too populated, it is
2024-07-27 19:01:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 19:03:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1920,  0.2590, -0.3857,  ..., -0.0772, -0.4480,  0.1636],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6826, -2.3320,  0.7520,  ..., -0.5205, -0.3755, -1.5410],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0379,  0.0006,  0.0124,  ..., -0.0061,  0.0031,  0.0186],
        [ 0.0161,  0.0389,  0.0051,  ...,  0.0247,  0.0245, -0.0054],
        [ 0.0098,  0.0054,  0.0338,  ..., -0.0056, -0.0123,  0.0193],
        ...,
        [ 0.0051,  0.0010, -0.0009,  ...,  0.0483,  0.0123,  0.0027],
        [-0.0022, -0.0003, -0.0023,  ..., -0.0022,  0.0341, -0.0179],
        [ 0.0069,  0.0072,  0.0118,  ...,  0.0042, -0.0197,  0.0546]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7588, -2.3516,  0.9092,  ..., -0.3364, -0.0454, -1.5996]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 19:03:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too written, it is overwritten
If something is too sold, it is oversold
If something is too simplified, it is oversimplified
If something is too spent, it is overspent
If something is too turned, it is overturned
If something is too protected, it is overprotected
If something is too crowded, it is overcrowded
If something is too populated, it is
2024-07-27 19:03:56 root INFO     [order_1_approx] starting weight calculation for If something is too written, it is overwritten
If something is too populated, it is overpopulated
If something is too protected, it is overprotected
If something is too simplified, it is oversimplified
If something is too spent, it is overspent
If something is too crowded, it is overcrowded
If something is too turned, it is overturned
If something is too sold, it is
2024-07-27 19:03:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 19:06:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0117, -0.1587, -0.2742,  ..., -0.3623, -0.0758,  0.0491],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6821, -2.2773, -0.0527,  ..., -1.8945, -2.7578, -0.9150],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0596, -0.0366, -0.0114,  ..., -0.0031,  0.0229,  0.0440],
        [-0.0089,  0.0561,  0.0077,  ...,  0.0115, -0.0037, -0.0108],
        [ 0.0182,  0.0028,  0.0312,  ...,  0.0025, -0.0108,  0.0060],
        ...,
        [ 0.0109, -0.0063, -0.0053,  ...,  0.0671,  0.0206,  0.0263],
        [-0.0079,  0.0060, -0.0084,  ..., -0.0129,  0.0515, -0.0264],
        [-0.0043,  0.0202, -0.0069,  ..., -0.0049, -0.0219,  0.0453]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0527, -2.5723,  0.2871,  ..., -1.7070, -2.5508, -0.9321]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 19:06:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too written, it is overwritten
If something is too populated, it is overpopulated
If something is too protected, it is overprotected
If something is too simplified, it is oversimplified
If something is too spent, it is overspent
If something is too crowded, it is overcrowded
If something is too turned, it is overturned
If something is too sold, it is
2024-07-27 19:06:18 root INFO     total operator prediction time: 1110.7342476844788 seconds
2024-07-27 19:06:18 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+er_irreg
2024-07-27 19:06:18 root INFO     building operator verb+er_irreg
2024-07-27 19:06:18 root INFO     [order_1_approx] starting weight calculation for If you defend something, you are a defender
If you subscribe something, you are a subscriber
If you choreograph something, you are a choreographer
If you compose something, you are a composer
If you observe something, you are a observer
If you lose something, you are a loser
If you publish something, you are a publisher
If you destroy something, you are a
2024-07-27 19:06:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 19:08:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0128, -0.0070, -0.2405,  ..., -0.0824,  0.1054, -0.0135],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.4023, -3.0684,  1.1113,  ..., -3.5977, -4.3125, -0.9536],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0591,  0.0084, -0.0026,  ..., -0.0008,  0.0136, -0.0062],
        [ 0.0085,  0.0525,  0.0038,  ...,  0.0233,  0.0100,  0.0005],
        [ 0.0136,  0.0046,  0.0346,  ...,  0.0147,  0.0160, -0.0097],
        ...,
        [ 0.0050,  0.0149,  0.0158,  ...,  0.0338,  0.0320, -0.0172],
        [-0.0216,  0.0200, -0.0047,  ..., -0.0265,  0.0477,  0.0094],
        [ 0.0258, -0.0038, -0.0112,  ..., -0.0053, -0.0017,  0.0360]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 6.5352, -3.2910,  1.0039,  ..., -3.5723, -4.3398, -1.0576]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 19:08:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you defend something, you are a defender
If you subscribe something, you are a subscriber
If you choreograph something, you are a choreographer
If you compose something, you are a composer
If you observe something, you are a observer
If you lose something, you are a loser
If you publish something, you are a publisher
If you destroy something, you are a
2024-07-27 19:08:38 root INFO     [order_1_approx] starting weight calculation for If you publish something, you are a publisher
If you lose something, you are a loser
If you destroy something, you are a destroyer
If you subscribe something, you are a subscriber
If you defend something, you are a defender
If you choreograph something, you are a choreographer
If you observe something, you are a observer
If you compose something, you are a
2024-07-27 19:08:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 19:10:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6001,  0.0938, -0.3491,  ..., -0.3372,  0.0123,  0.2637],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7773, -2.2949,  0.5688,  ...,  0.0234, -3.0801, -1.0312],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0484, -0.0140,  0.0070,  ...,  0.0081, -0.0141,  0.0069],
        [ 0.0076,  0.0469,  0.0021,  ...,  0.0245,  0.0303, -0.0048],
        [ 0.0077,  0.0023,  0.0434,  ...,  0.0073, -0.0064,  0.0010],
        ...,
        [ 0.0184,  0.0150, -0.0034,  ...,  0.0651,  0.0075, -0.0425],
        [ 0.0071,  0.0117, -0.0147,  ..., -0.0267,  0.0375, -0.0121],
        [-0.0124,  0.0011,  0.0086,  ..., -0.0047, -0.0040,  0.0353]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9766, -2.1797,  0.8911,  ...,  0.3979, -3.3164, -1.1689]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 19:10:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you publish something, you are a publisher
If you lose something, you are a loser
If you destroy something, you are a destroyer
If you subscribe something, you are a subscriber
If you defend something, you are a defender
If you choreograph something, you are a choreographer
If you observe something, you are a observer
If you compose something, you are a
2024-07-27 19:10:58 root INFO     [order_1_approx] starting weight calculation for If you observe something, you are a observer
If you defend something, you are a defender
If you compose something, you are a composer
If you lose something, you are a loser
If you destroy something, you are a destroyer
If you subscribe something, you are a subscriber
If you publish something, you are a publisher
If you choreograph something, you are a
2024-07-27 19:10:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 19:13:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 2.1985e-01,  1.6650e-01,  1.6785e-04,  ..., -3.6102e-02,
        -6.3184e-01,  7.4951e-02], device='cuda:1', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1312, -4.3047,  2.6875,  ..., -2.3789, -3.9609, -1.4062],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0537, -0.0037,  0.0153,  ...,  0.0009,  0.0147, -0.0046],
        [ 0.0069,  0.0504, -0.0055,  ...,  0.0208,  0.0182, -0.0043],
        [ 0.0032,  0.0023,  0.0303,  ..., -0.0024, -0.0063,  0.0085],
        ...,
        [ 0.0255,  0.0088,  0.0032,  ...,  0.0366, -0.0034, -0.0130],
        [ 0.0081, -0.0016, -0.0140,  ..., -0.0215,  0.0291, -0.0046],
        [-0.0091, -0.0157,  0.0095,  ..., -0.0068,  0.0001,  0.0256]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4248, -4.3828,  2.7090,  ..., -1.9951, -3.9414, -1.5342]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 19:13:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you observe something, you are a observer
If you defend something, you are a defender
If you compose something, you are a composer
If you lose something, you are a loser
If you destroy something, you are a destroyer
If you subscribe something, you are a subscriber
If you publish something, you are a publisher
If you choreograph something, you are a
2024-07-27 19:13:19 root INFO     [order_1_approx] starting weight calculation for If you observe something, you are a observer
If you compose something, you are a composer
If you publish something, you are a publisher
If you lose something, you are a loser
If you destroy something, you are a destroyer
If you subscribe something, you are a subscriber
If you choreograph something, you are a choreographer
If you defend something, you are a
2024-07-27 19:13:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 19:15:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4424,  0.0256, -0.0898,  ..., -0.0563,  0.2817,  0.0793],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4590, -5.3164,  3.8008,  ..., -4.5977, -3.7422, -3.6641],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.1829e-02,  9.0485e-03,  1.6556e-02,  ...,  7.4730e-03,
          1.4591e-03, -9.4681e-03],
        [-2.3499e-02,  2.8595e-02, -8.3466e-03,  ...,  1.7014e-02,
          4.0192e-02, -1.1444e-02],
        [ 1.3786e-02, -5.7411e-03,  2.2385e-02,  ..., -1.3443e-02,
          1.2939e-02,  1.1444e-02],
        ...,
        [ 1.7136e-02,  8.4991e-03, -1.3031e-02,  ...,  3.9520e-02,
          1.2260e-02, -7.0953e-03],
        [-4.9286e-03,  1.2939e-02, -1.4442e-02,  ..., -1.9531e-02,
          4.4586e-02, -1.6144e-02],
        [ 1.2634e-02, -4.4975e-03,  1.5373e-02,  ...,  7.7248e-05,
         -1.6708e-02,  3.1128e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8457, -5.3164,  4.5312,  ..., -3.9688, -3.8984, -3.7305]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 19:15:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you observe something, you are a observer
If you compose something, you are a composer
If you publish something, you are a publisher
If you lose something, you are a loser
If you destroy something, you are a destroyer
If you subscribe something, you are a subscriber
If you choreograph something, you are a choreographer
If you defend something, you are a
2024-07-27 19:15:39 root INFO     [order_1_approx] starting weight calculation for If you compose something, you are a composer
If you subscribe something, you are a subscriber
If you lose something, you are a loser
If you choreograph something, you are a choreographer
If you observe something, you are a observer
If you destroy something, you are a destroyer
If you defend something, you are a defender
If you publish something, you are a
2024-07-27 19:15:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 19:17:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1907, -0.0364,  0.0267,  ...,  0.4160,  0.1587,  0.1564],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0723, -4.2109,  1.0664,  ..., -0.8223, -5.3555, -1.8730],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0738,  0.0050,  0.0108,  ...,  0.0086, -0.0025,  0.0246],
        [-0.0080,  0.0483,  0.0067,  ...,  0.0221,  0.0162, -0.0101],
        [ 0.0198, -0.0020,  0.0462,  ..., -0.0153, -0.0123,  0.0186],
        ...,
        [ 0.0189,  0.0254, -0.0018,  ...,  0.0376,  0.0162, -0.0130],
        [-0.0026,  0.0048, -0.0117,  ..., -0.0164,  0.0439, -0.0141],
        [-0.0131,  0.0024,  0.0156,  ..., -0.0224,  0.0121,  0.0209]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1289, -4.3008,  0.8359,  ..., -0.8550, -5.6445, -1.8643]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 19:18:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you compose something, you are a composer
If you subscribe something, you are a subscriber
If you lose something, you are a loser
If you choreograph something, you are a choreographer
If you observe something, you are a observer
If you destroy something, you are a destroyer
If you defend something, you are a defender
If you publish something, you are a
2024-07-27 19:18:00 root INFO     [order_1_approx] starting weight calculation for If you destroy something, you are a destroyer
If you compose something, you are a composer
If you defend something, you are a defender
If you publish something, you are a publisher
If you lose something, you are a loser
If you choreograph something, you are a choreographer
If you observe something, you are a observer
If you subscribe something, you are a
2024-07-27 19:18:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 19:20:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0626,  0.1373, -0.4246,  ...,  0.4165, -0.0443,  0.1073],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5391, -1.8076,  2.3008,  ...,  0.2676, -2.2109, -4.8555],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0539, -0.0100,  0.0092,  ..., -0.0023,  0.0033,  0.0151],
        [-0.0137,  0.0379,  0.0255,  ...,  0.0223, -0.0027, -0.0154],
        [ 0.0182, -0.0083,  0.0384,  ...,  0.0003, -0.0063,  0.0045],
        ...,
        [ 0.0200,  0.0224, -0.0071,  ...,  0.0500,  0.0098, -0.0128],
        [ 0.0013,  0.0106,  0.0020,  ..., -0.0079,  0.0277, -0.0208],
        [-0.0123, -0.0161, -0.0027,  ..., -0.0152,  0.0011,  0.0107]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4043, -2.0586,  2.7578,  ...,  0.1603, -2.4180, -5.0039]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 19:20:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you destroy something, you are a destroyer
If you compose something, you are a composer
If you defend something, you are a defender
If you publish something, you are a publisher
If you lose something, you are a loser
If you choreograph something, you are a choreographer
If you observe something, you are a observer
If you subscribe something, you are a
2024-07-27 19:20:21 root INFO     [order_1_approx] starting weight calculation for If you compose something, you are a composer
If you destroy something, you are a destroyer
If you defend something, you are a defender
If you choreograph something, you are a choreographer
If you subscribe something, you are a subscriber
If you publish something, you are a publisher
If you lose something, you are a loser
If you observe something, you are a
2024-07-27 19:20:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 19:22:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2737,  0.4016, -0.1510,  ..., -0.0204,  0.2495, -0.0326],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4824, -1.4502,  0.3237,  ..., -4.1875, -3.5820, -2.8184],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0740,  0.0139, -0.0023,  ...,  0.0106, -0.0011,  0.0144],
        [-0.0057,  0.0470,  0.0020,  ...,  0.0132,  0.0106, -0.0110],
        [-0.0047, -0.0076,  0.0554,  ..., -0.0069, -0.0067,  0.0105],
        ...,
        [ 0.0237,  0.0156,  0.0020,  ...,  0.0464,  0.0070, -0.0097],
        [-0.0007,  0.0113, -0.0086,  ..., -0.0156,  0.0246, -0.0071],
        [ 0.0066, -0.0005,  0.0099,  ..., -0.0121,  0.0054,  0.0237]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6621, -1.6748, -0.1360,  ..., -3.8730, -3.6211, -2.8027]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 19:22:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you compose something, you are a composer
If you destroy something, you are a destroyer
If you defend something, you are a defender
If you choreograph something, you are a choreographer
If you subscribe something, you are a subscriber
If you publish something, you are a publisher
If you lose something, you are a loser
If you observe something, you are a
2024-07-27 19:22:43 root INFO     [order_1_approx] starting weight calculation for If you publish something, you are a publisher
If you subscribe something, you are a subscriber
If you choreograph something, you are a choreographer
If you defend something, you are a defender
If you observe something, you are a observer
If you destroy something, you are a destroyer
If you compose something, you are a composer
If you lose something, you are a
2024-07-27 19:22:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 19:25:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1281,  0.1940,  0.0839,  ...,  0.1658,  0.4102, -0.2554],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4121, -1.2402,  1.0576,  ..., -1.2871, -2.9102,  0.8145],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0244, -0.0107,  0.0008,  ...,  0.0151, -0.0147,  0.0190],
        [ 0.0005,  0.0244,  0.0009,  ...,  0.0338,  0.0174,  0.0032],
        [ 0.0006, -0.0042,  0.0228,  ..., -0.0092,  0.0021, -0.0069],
        ...,
        [ 0.0134,  0.0022,  0.0020,  ...,  0.0116,  0.0097,  0.0099],
        [-0.0215,  0.0247, -0.0005,  ..., -0.0138,  0.0173,  0.0006],
        [ 0.0051,  0.0013,  0.0034,  ..., -0.0284, -0.0057,  0.0110]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2793, -1.0693,  1.2275,  ..., -0.9824, -3.1680,  0.4792]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 19:25:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you publish something, you are a publisher
If you subscribe something, you are a subscriber
If you choreograph something, you are a choreographer
If you defend something, you are a defender
If you observe something, you are a observer
If you destroy something, you are a destroyer
If you compose something, you are a composer
If you lose something, you are a
2024-07-27 19:25:03 root INFO     total operator prediction time: 1125.4428279399872 seconds
2024-07-27 19:25:03 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj - superlative
2024-07-27 19:25:03 root INFO     building operator adj - superlative
2024-07-27 19:25:03 root INFO     [order_1_approx] starting weight calculation for If something is the most strong, it is strongest
If something is the most risky, it is riskiest
If something is the most cruel, it is cruelest
If something is the most nasty, it is nastiest
If something is the most vague, it is vaguest
If something is the most hot, it is hottest
If something is the most tricky, it is trickiest
If something is the most harsh, it is
2024-07-27 19:25:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 19:27:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1004, -0.1672, -0.4133,  ...,  0.1125, -0.1683,  0.1998],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.6104, -4.6797, -2.1289,  ..., -2.5176, -1.4668,  0.5039],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0486,  0.0073,  0.0117,  ..., -0.0125, -0.0108,  0.0025],
        [ 0.0056,  0.0338,  0.0119,  ...,  0.0007,  0.0215, -0.0018],
        [ 0.0212, -0.0103,  0.0331,  ..., -0.0033, -0.0033, -0.0072],
        ...,
        [ 0.0177,  0.0150, -0.0017,  ...,  0.0236,  0.0070, -0.0024],
        [-0.0169,  0.0115, -0.0023,  ..., -0.0006,  0.0344, -0.0159],
        [-0.0094, -0.0006, -0.0015,  ...,  0.0065,  0.0015,  0.0143]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.2012, -4.4766, -1.8184,  ..., -2.4590, -1.4209,  0.5444]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 19:27:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most strong, it is strongest
If something is the most risky, it is riskiest
If something is the most cruel, it is cruelest
If something is the most nasty, it is nastiest
If something is the most vague, it is vaguest
If something is the most hot, it is hottest
If something is the most tricky, it is trickiest
If something is the most harsh, it is
2024-07-27 19:27:22 root INFO     [order_1_approx] starting weight calculation for If something is the most vague, it is vaguest
If something is the most strong, it is strongest
If something is the most tricky, it is trickiest
If something is the most harsh, it is harshest
If something is the most hot, it is hottest
If something is the most cruel, it is cruelest
If something is the most nasty, it is nastiest
If something is the most risky, it is
2024-07-27 19:27:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 19:29:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3481, -0.0923, -0.6665,  ..., -0.0775,  0.0853, -0.1367],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.9551, -5.3047, -2.4570,  ..., -3.2969,  0.0381,  0.1797],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0554,  0.0019,  0.0084,  ...,  0.0057, -0.0047,  0.0176],
        [ 0.0016,  0.0299,  0.0207,  ...,  0.0063, -0.0041,  0.0081],
        [ 0.0030,  0.0095,  0.0153,  ...,  0.0021, -0.0168,  0.0042],
        ...,
        [ 0.0282,  0.0147,  0.0021,  ...,  0.0378,  0.0081,  0.0065],
        [ 0.0053, -0.0033,  0.0035,  ...,  0.0076,  0.0384, -0.0168],
        [-0.0028, -0.0071,  0.0116,  ..., -0.0070, -0.0037,  0.0054]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-3.0078, -5.2109, -2.6719,  ..., -3.3809,  0.0164,  0.5771]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 19:29:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most vague, it is vaguest
If something is the most strong, it is strongest
If something is the most tricky, it is trickiest
If something is the most harsh, it is harshest
If something is the most hot, it is hottest
If something is the most cruel, it is cruelest
If something is the most nasty, it is nastiest
If something is the most risky, it is
2024-07-27 19:29:42 root INFO     [order_1_approx] starting weight calculation for If something is the most vague, it is vaguest
If something is the most nasty, it is nastiest
If something is the most harsh, it is harshest
If something is the most cruel, it is cruelest
If something is the most hot, it is hottest
If something is the most risky, it is riskiest
If something is the most tricky, it is trickiest
If something is the most strong, it is
2024-07-27 19:29:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 19:32:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1528, -0.4502, -0.2410,  ..., -0.2051, -0.1375, -0.2603],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5312, -6.9258, -2.2871,  ..., -0.5527, -2.1953, -2.2539],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0304, -0.0189,  0.0013,  ..., -0.0212,  0.0006,  0.0051],
        [-0.0045,  0.0368,  0.0043,  ..., -0.0087,  0.0083,  0.0119],
        [ 0.0109, -0.0104,  0.0190,  ..., -0.0008, -0.0176, -0.0080],
        ...,
        [ 0.0033,  0.0187,  0.0020,  ...,  0.0468, -0.0051,  0.0036],
        [-0.0100, -0.0164, -0.0069,  ..., -0.0149,  0.0325, -0.0243],
        [-0.0123,  0.0005,  0.0032,  ..., -0.0066, -0.0034,  0.0143]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4111, -6.9062, -2.2676,  ..., -0.5762, -2.4453, -2.1562]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 19:32:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most vague, it is vaguest
If something is the most nasty, it is nastiest
If something is the most harsh, it is harshest
If something is the most cruel, it is cruelest
If something is the most hot, it is hottest
If something is the most risky, it is riskiest
If something is the most tricky, it is trickiest
If something is the most strong, it is
2024-07-27 19:32:04 root INFO     [order_1_approx] starting weight calculation for If something is the most strong, it is strongest
If something is the most tricky, it is trickiest
If something is the most risky, it is riskiest
If something is the most harsh, it is harshest
If something is the most hot, it is hottest
If something is the most vague, it is vaguest
If something is the most cruel, it is cruelest
If something is the most nasty, it is
2024-07-27 19:32:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 19:34:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0728, -0.0952, -0.1697,  ..., -0.1592, -0.1646, -0.0662],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0663, -5.4062, -3.7559,  ..., -3.7988, -3.0508, -0.2686],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0292,  0.0008,  0.0249,  ..., -0.0155, -0.0184, -0.0005],
        [ 0.0120,  0.0206,  0.0066,  ...,  0.0044,  0.0257,  0.0099],
        [ 0.0012,  0.0065,  0.0124,  ..., -0.0019, -0.0099, -0.0048],
        ...,
        [ 0.0137,  0.0194,  0.0004,  ...,  0.0282,  0.0063,  0.0098],
        [ 0.0167, -0.0045, -0.0018,  ...,  0.0091,  0.0257,  0.0009],
        [-0.0073, -0.0021,  0.0011,  ..., -0.0044, -0.0157,  0.0082]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2047, -5.3086, -3.6406,  ..., -3.6582, -2.8262, -0.0454]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 19:34:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most strong, it is strongest
If something is the most tricky, it is trickiest
If something is the most risky, it is riskiest
If something is the most harsh, it is harshest
If something is the most hot, it is hottest
If something is the most vague, it is vaguest
If something is the most cruel, it is cruelest
If something is the most nasty, it is
2024-07-27 19:34:21 root INFO     [order_1_approx] starting weight calculation for If something is the most nasty, it is nastiest
If something is the most vague, it is vaguest
If something is the most strong, it is strongest
If something is the most risky, it is riskiest
If something is the most cruel, it is cruelest
If something is the most hot, it is hottest
If something is the most harsh, it is harshest
If something is the most tricky, it is
2024-07-27 19:34:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 19:36:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1351,  0.0067, -0.1221,  ...,  0.2341, -0.2208,  0.0812],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6924, -3.9238, -1.3965,  ...,  0.0132, -2.6992, -0.0430],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0696,  0.0092,  0.0178,  ...,  0.0163, -0.0141,  0.0114],
        [-0.0016,  0.0501,  0.0233,  ...,  0.0039, -0.0092,  0.0018],
        [ 0.0097,  0.0068,  0.0407,  ...,  0.0047, -0.0304,  0.0049],
        ...,
        [ 0.0022,  0.0292, -0.0052,  ...,  0.0803, -0.0034, -0.0267],
        [ 0.0177, -0.0027,  0.0129,  ..., -0.0100,  0.0561, -0.0058],
        [ 0.0158, -0.0067,  0.0087,  ..., -0.0417, -0.0194,  0.0601]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0371, -3.9766, -1.2861,  ...,  0.2996, -2.7441,  0.0054]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 19:36:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most nasty, it is nastiest
If something is the most vague, it is vaguest
If something is the most strong, it is strongest
If something is the most risky, it is riskiest
If something is the most cruel, it is cruelest
If something is the most hot, it is hottest
If something is the most harsh, it is harshest
If something is the most tricky, it is
2024-07-27 19:36:42 root INFO     [order_1_approx] starting weight calculation for If something is the most hot, it is hottest
If something is the most harsh, it is harshest
If something is the most risky, it is riskiest
If something is the most strong, it is strongest
If something is the most tricky, it is trickiest
If something is the most vague, it is vaguest
If something is the most nasty, it is nastiest
If something is the most cruel, it is
2024-07-27 19:36:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 19:38:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4609,  0.0820,  0.3516,  ..., -0.4800, -0.1581,  0.1682],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5576, -3.9043, -1.0361,  ..., -0.9209,  0.4277,  0.3291],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0596, -0.0058,  0.0194,  ...,  0.0006, -0.0143,  0.0165],
        [ 0.0107,  0.0316,  0.0146,  ...,  0.0018,  0.0229,  0.0097],
        [ 0.0097,  0.0063,  0.0300,  ..., -0.0165, -0.0172, -0.0035],
        ...,
        [ 0.0022,  0.0288,  0.0030,  ...,  0.0158,  0.0219, -0.0118],
        [-0.0037,  0.0029,  0.0198,  ..., -0.0065,  0.0455, -0.0157],
        [-0.0114, -0.0122,  0.0031,  ..., -0.0024, -0.0096,  0.0113]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.0547, -4.0039, -0.9966,  ..., -0.9023, -0.1128,  0.7134]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 19:38:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most hot, it is hottest
If something is the most harsh, it is harshest
If something is the most risky, it is riskiest
If something is the most strong, it is strongest
If something is the most tricky, it is trickiest
If something is the most vague, it is vaguest
If something is the most nasty, it is nastiest
If something is the most cruel, it is
2024-07-27 19:38:58 root INFO     [order_1_approx] starting weight calculation for If something is the most risky, it is riskiest
If something is the most tricky, it is trickiest
If something is the most strong, it is strongest
If something is the most nasty, it is nastiest
If something is the most harsh, it is harshest
If something is the most hot, it is hottest
If something is the most cruel, it is cruelest
If something is the most vague, it is
2024-07-27 19:38:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 19:41:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0794,  0.0715, -0.3284,  ...,  0.0814,  0.0764, -0.4016],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.9365, -4.0977, -0.0664,  ..., -0.0964, -3.3379, -0.6904],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0652,  0.0073,  0.0149,  ...,  0.0062, -0.0014,  0.0090],
        [-0.0187,  0.0659,  0.0036,  ..., -0.0013,  0.0016,  0.0218],
        [-0.0015,  0.0122,  0.0550,  ..., -0.0068, -0.0293,  0.0353],
        ...,
        [ 0.0289,  0.0760, -0.0067,  ...,  0.0897, -0.0056,  0.0009],
        [ 0.0208,  0.0031,  0.0116,  ...,  0.0121,  0.0535, -0.0351],
        [ 0.0083,  0.0056,  0.0014,  ..., -0.0160, -0.0124,  0.0372]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.5752, -4.1641, -0.2754,  ..., -0.1680, -3.0840, -0.5786]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 19:41:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most risky, it is riskiest
If something is the most tricky, it is trickiest
If something is the most strong, it is strongest
If something is the most nasty, it is nastiest
If something is the most harsh, it is harshest
If something is the most hot, it is hottest
If something is the most cruel, it is cruelest
If something is the most vague, it is
2024-07-27 19:41:18 root INFO     [order_1_approx] starting weight calculation for If something is the most risky, it is riskiest
If something is the most tricky, it is trickiest
If something is the most cruel, it is cruelest
If something is the most nasty, it is nastiest
If something is the most strong, it is strongest
If something is the most harsh, it is harshest
If something is the most vague, it is vaguest
If something is the most hot, it is
2024-07-27 19:41:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 19:43:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1113, -0.3828, -0.2568,  ...,  0.1062, -0.1663, -0.3682],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.6719, -4.2461, -1.7305,  ..., -2.0039, -3.0312,  0.0674],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0426, -0.0163,  0.0027,  ..., -0.0268, -0.0128, -0.0104],
        [ 0.0129,  0.0548,  0.0062,  ..., -0.0046,  0.0090,  0.0036],
        [ 0.0000, -0.0033,  0.0244,  ...,  0.0113, -0.0161,  0.0209],
        ...,
        [ 0.0084,  0.0250,  0.0026,  ...,  0.0428,  0.0005,  0.0051],
        [-0.0054,  0.0117, -0.0061,  ..., -0.0146,  0.0453, -0.0217],
        [ 0.0072, -0.0147, -0.0082,  ..., -0.0101, -0.0012,  0.0257]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.6162, -3.9570, -2.1152,  ..., -1.6133, -3.2637,  0.3535]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 19:43:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most risky, it is riskiest
If something is the most tricky, it is trickiest
If something is the most cruel, it is cruelest
If something is the most nasty, it is nastiest
If something is the most strong, it is strongest
If something is the most harsh, it is harshest
If something is the most vague, it is vaguest
If something is the most hot, it is
2024-07-27 19:43:37 root INFO     total operator prediction time: 1113.838454246521 seconds
2024-07-27 19:43:37 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_3pSg - Ved
2024-07-27 19:43:37 root INFO     building operator verb_3pSg - Ved
2024-07-27 19:43:37 root INFO     [order_1_approx] starting weight calculation for When he occurs something, something has been occurred
When he applies something, something has been applied
When he seems something, something has been seemed
When he agrees something, something has been agreed
When he intends something, something has been intended
When he believes something, something has been believed
When he considers something, something has been considered
When he announces something, something has been
2024-07-27 19:43:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 19:45:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2178,  0.3269, -0.3354,  ...,  0.2017,  0.3267, -0.2676],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9453, -1.0205,  3.0703,  ...,  0.3911, -2.2207,  1.1211],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0281, -0.0046,  0.0086,  ..., -0.0001, -0.0197,  0.0214],
        [-0.0101,  0.0212,  0.0025,  ...,  0.0105,  0.0087, -0.0054],
        [ 0.0084, -0.0158,  0.0013,  ..., -0.0194, -0.0060,  0.0008],
        ...,
        [ 0.0025, -0.0038, -0.0171,  ...,  0.0102,  0.0077,  0.0158],
        [ 0.0173,  0.0029,  0.0025,  ...,  0.0026,  0.0127, -0.0067],
        [-0.0027,  0.0014,  0.0129,  ..., -0.0032,  0.0066,  0.0088]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8496, -1.0127,  3.2305,  ...,  0.6606, -2.0176,  1.0469]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 19:45:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he occurs something, something has been occurred
When he applies something, something has been applied
When he seems something, something has been seemed
When he agrees something, something has been agreed
When he intends something, something has been intended
When he believes something, something has been believed
When he considers something, something has been considered
When he announces something, something has been
2024-07-27 19:45:57 root INFO     [order_1_approx] starting weight calculation for When he intends something, something has been intended
When he occurs something, something has been occurred
When he considers something, something has been considered
When he seems something, something has been seemed
When he announces something, something has been announced
When he believes something, something has been believed
When he agrees something, something has been agreed
When he applies something, something has been
2024-07-27 19:45:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 19:48:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0699, -0.2925,  0.0551,  ...,  0.3054, -0.0212, -0.1064],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9053,  0.4060,  0.5898,  ..., -0.7476, -1.6738, -0.1250],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0428, -0.0037,  0.0105,  ..., -0.0008, -0.0151,  0.0179],
        [ 0.0029,  0.0263,  0.0154,  ...,  0.0035,  0.0081,  0.0031],
        [-0.0040,  0.0027,  0.0238,  ..., -0.0092, -0.0040,  0.0023],
        ...,
        [-0.0072,  0.0226, -0.0160,  ...,  0.0458, -0.0001,  0.0271],
        [ 0.0134,  0.0097, -0.0033,  ...,  0.0009,  0.0278, -0.0309],
        [-0.0053,  0.0100,  0.0072,  ..., -0.0051,  0.0103,  0.0142]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6221, -0.2371,  0.8730,  ..., -0.8350, -1.3643,  0.0203]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 19:48:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he intends something, something has been intended
When he occurs something, something has been occurred
When he considers something, something has been considered
When he seems something, something has been seemed
When he announces something, something has been announced
When he believes something, something has been believed
When he agrees something, something has been agreed
When he applies something, something has been
2024-07-27 19:48:18 root INFO     [order_1_approx] starting weight calculation for When he applies something, something has been applied
When he intends something, something has been intended
When he occurs something, something has been occurred
When he considers something, something has been considered
When he seems something, something has been seemed
When he agrees something, something has been agreed
When he announces something, something has been announced
When he believes something, something has been
2024-07-27 19:48:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 19:50:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1519,  0.2651, -0.1123,  ..., -0.0184, -0.3103,  0.1884],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0586, -1.2998,  1.3877,  ...,  0.5923, -3.0352, -0.6719],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0204, -0.0085,  0.0038,  ...,  0.0008, -0.0009,  0.0282],
        [-0.0079,  0.0273,  0.0103,  ...,  0.0233,  0.0013,  0.0044],
        [-0.0069, -0.0084,  0.0184,  ..., -0.0139, -0.0077,  0.0028],
        ...,
        [-0.0012,  0.0065, -0.0026,  ...,  0.0207,  0.0129,  0.0153],
        [ 0.0123, -0.0020,  0.0015,  ..., -0.0022,  0.0161, -0.0302],
        [-0.0006,  0.0022,  0.0171,  ..., -0.0001, -0.0015, -0.0015]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.1406, -1.4619,  1.2363,  ...,  0.7319, -3.3008, -0.8540]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 19:50:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he applies something, something has been applied
When he intends something, something has been intended
When he occurs something, something has been occurred
When he considers something, something has been considered
When he seems something, something has been seemed
When he agrees something, something has been agreed
When he announces something, something has been announced
When he believes something, something has been
2024-07-27 19:50:40 root INFO     [order_1_approx] starting weight calculation for When he agrees something, something has been agreed
When he applies something, something has been applied
When he announces something, something has been announced
When he believes something, something has been believed
When he occurs something, something has been occurred
When he intends something, something has been intended
When he seems something, something has been seemed
When he considers something, something has been
2024-07-27 19:50:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 19:52:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2876, -0.3472, -0.1095,  ...,  0.0652,  0.3733, -0.0216],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1992, -0.6162,  3.7617,  ..., -0.7119, -0.2803, -0.9688],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.0802e-02, -1.4046e-02,  1.0902e-02,  ...,  7.7438e-03,
         -2.3987e-02,  3.1677e-02],
        [-4.8637e-04,  1.6739e-02,  1.9028e-02,  ...,  8.4991e-03,
          3.8471e-03,  7.5302e-03],
        [-1.4839e-02,  5.0125e-03,  3.2837e-02,  ..., -2.0111e-02,
         -9.2010e-03, -1.5091e-02],
        ...,
        [ 1.1581e-02, -1.5030e-03,  7.5798e-03,  ...,  2.5635e-02,
          1.0437e-02,  1.4977e-02],
        [ 1.8173e-02,  2.2186e-02, -1.9875e-03,  ..., -9.7122e-03,
          2.2903e-02, -2.6642e-02],
        [-1.0391e-02, -8.9645e-05,  2.4460e-02,  ...,  7.1716e-03,
          9.6054e-03, -6.4468e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6973, -0.5601,  3.4258,  ..., -0.3643, -0.7896, -0.8350]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 19:53:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he agrees something, something has been agreed
When he applies something, something has been applied
When he announces something, something has been announced
When he believes something, something has been believed
When he occurs something, something has been occurred
When he intends something, something has been intended
When he seems something, something has been seemed
When he considers something, something has been
2024-07-27 19:53:01 root INFO     [order_1_approx] starting weight calculation for When he agrees something, something has been agreed
When he applies something, something has been applied
When he announces something, something has been announced
When he intends something, something has been intended
When he considers something, something has been considered
When he believes something, something has been believed
When he occurs something, something has been occurred
When he seems something, something has been
2024-07-27 19:53:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 19:55:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4006, -0.1388, -0.3574,  ...,  0.4836, -0.3215, -0.2136],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4727,  2.5312, -0.3403,  ...,  1.8438, -1.7305, -2.5156],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0486, -0.0051,  0.0154,  ..., -0.0045,  0.0021,  0.0235],
        [ 0.0023,  0.0246,  0.0099,  ...,  0.0093, -0.0128, -0.0026],
        [-0.0120, -0.0035,  0.0303,  ..., -0.0159, -0.0137, -0.0087],
        ...,
        [-0.0062,  0.0104, -0.0154,  ...,  0.0333,  0.0098,  0.0404],
        [ 0.0038, -0.0062, -0.0231,  ..., -0.0117,  0.0435, -0.0316],
        [-0.0055, -0.0133,  0.0350,  ...,  0.0132, -0.0043,  0.0061]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4297,  2.5059, -0.6558,  ...,  1.7100, -1.5820, -2.1133]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 19:55:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he agrees something, something has been agreed
When he applies something, something has been applied
When he announces something, something has been announced
When he intends something, something has been intended
When he considers something, something has been considered
When he believes something, something has been believed
When he occurs something, something has been occurred
When he seems something, something has been
2024-07-27 19:55:18 root INFO     [order_1_approx] starting weight calculation for When he announces something, something has been announced
When he occurs something, something has been occurred
When he applies something, something has been applied
When he seems something, something has been seemed
When he believes something, something has been believed
When he intends something, something has been intended
When he considers something, something has been considered
When he agrees something, something has been
2024-07-27 19:55:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 19:57:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3591,  0.0289, -0.1182,  ...,  0.2727, -0.2288, -0.1938],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0586, -1.5879,  1.9336,  ..., -0.3311, -0.7100,  0.1680],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0292, -0.0062,  0.0040,  ...,  0.0049,  0.0066,  0.0195],
        [-0.0087,  0.0266,  0.0090,  ...,  0.0176, -0.0043, -0.0082],
        [-0.0017, -0.0055,  0.0257,  ..., -0.0107, -0.0081, -0.0116],
        ...,
        [ 0.0113,  0.0009, -0.0090,  ...,  0.0168,  0.0053,  0.0199],
        [ 0.0069,  0.0130, -0.0112,  ...,  0.0018,  0.0159, -0.0191],
        [ 0.0086, -0.0084,  0.0149,  ..., -0.0028, -0.0098,  0.0207]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9316, -1.3799,  1.8984,  ..., -0.1821, -0.7939,  0.4180]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 19:57:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he announces something, something has been announced
When he occurs something, something has been occurred
When he applies something, something has been applied
When he seems something, something has been seemed
When he believes something, something has been believed
When he intends something, something has been intended
When he considers something, something has been considered
When he agrees something, something has been
2024-07-27 19:57:39 root INFO     [order_1_approx] starting weight calculation for When he announces something, something has been announced
When he seems something, something has been seemed
When he intends something, something has been intended
When he believes something, something has been believed
When he considers something, something has been considered
When he applies something, something has been applied
When he agrees something, something has been agreed
When he occurs something, something has been
2024-07-27 19:57:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 19:59:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.6514, -0.1835, -0.4832,  ..., -0.2292, -0.1820, -0.8506],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3848,  1.2871,  2.2812,  ..., -0.2023, -1.1846,  0.5859],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0346,  0.0029,  0.0262,  ...,  0.0219, -0.0003,  0.0399],
        [-0.0169,  0.0310,  0.0166,  ...,  0.0142,  0.0070, -0.0082],
        [ 0.0202, -0.0048,  0.0215,  ..., -0.0281, -0.0031,  0.0004],
        ...,
        [ 0.0039,  0.0131, -0.0014,  ...,  0.0330, -0.0008,  0.0280],
        [-0.0022,  0.0051,  0.0031,  ...,  0.0001,  0.0302, -0.0221],
        [ 0.0024, -0.0048,  0.0276,  ..., -0.0106,  0.0204,  0.0254]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6426,  1.3311,  2.3906,  ..., -0.0205, -1.0381,  0.6597]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 20:00:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he announces something, something has been announced
When he seems something, something has been seemed
When he intends something, something has been intended
When he believes something, something has been believed
When he considers something, something has been considered
When he applies something, something has been applied
When he agrees something, something has been agreed
When he occurs something, something has been
2024-07-27 20:00:00 root INFO     [order_1_approx] starting weight calculation for When he agrees something, something has been agreed
When he occurs something, something has been occurred
When he seems something, something has been seemed
When he announces something, something has been announced
When he considers something, something has been considered
When he believes something, something has been believed
When he applies something, something has been applied
When he intends something, something has been
2024-07-27 20:00:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 20:02:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3486,  0.1443, -0.1119,  ...,  0.2205,  0.4229,  0.0814],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8955,  2.2441,  0.4658,  ..., -0.5986, -2.6738, -2.7402],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.7975e-02, -1.2764e-02,  1.4076e-03,  ...,  4.5891e-03,
         -1.0178e-02,  4.7760e-03],
        [-2.7069e-02,  1.0925e-02,  9.5520e-03,  ..., -6.4659e-03,
          1.4603e-02, -1.1078e-02],
        [ 3.4332e-05,  1.1528e-02,  1.5076e-02,  ..., -1.8585e-02,
         -1.2772e-02, -1.2352e-02],
        ...,
        [-8.8730e-03,  2.2945e-03,  6.7482e-03,  ...,  1.1856e-02,
          1.4297e-02,  2.0508e-02],
        [ 2.2385e-02,  3.4046e-03,  7.9041e-03,  ...,  1.1688e-02,
          2.0813e-02,  2.3193e-03],
        [-8.1444e-04,  5.6953e-03,  2.7557e-02,  ...,  1.6270e-03,
          1.7376e-03, -1.0262e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7705,  2.5645,  0.2593,  ..., -0.1172, -2.8320, -2.5020]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 20:02:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he agrees something, something has been agreed
When he occurs something, something has been occurred
When he seems something, something has been seemed
When he announces something, something has been announced
When he considers something, something has been considered
When he believes something, something has been believed
When he applies something, something has been applied
When he intends something, something has been
2024-07-27 20:02:21 root INFO     total operator prediction time: 1124.111849784851 seconds
2024-07-27 20:02:21 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun - plural_reg
2024-07-27 20:02:21 root INFO     building operator noun - plural_reg
2024-07-27 20:02:21 root INFO     [order_1_approx] starting weight calculation for The plural form of website is websites
The plural form of college is colleges
The plural form of difference is differences
The plural form of council is councils
The plural form of application is applications
The plural form of song is songs
The plural form of resource is resources
The plural form of period is
2024-07-27 20:02:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 20:04:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2751, -0.1285, -0.1361,  ..., -0.3442, -0.2549,  0.0076],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1985, -2.9531,  2.1445,  ..., -0.4673, -0.6973, -0.8794],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0663, -0.0064,  0.0127,  ..., -0.0037, -0.0105,  0.0024],
        [ 0.0149,  0.0629,  0.0239,  ...,  0.0077,  0.0168,  0.0118],
        [ 0.0076, -0.0081,  0.0889,  ..., -0.0238, -0.0177, -0.0016],
        ...,
        [-0.0018,  0.0076, -0.0008,  ...,  0.1035, -0.0176,  0.0211],
        [-0.0259, -0.0094,  0.0101,  ..., -0.0085,  0.0483,  0.0258],
        [-0.0027,  0.0150,  0.0033,  ...,  0.0088, -0.0106,  0.0600]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1139, -2.7754,  2.3555,  ..., -0.3965, -0.7480, -0.7852]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 20:04:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of website is websites
The plural form of college is colleges
The plural form of difference is differences
The plural form of council is councils
The plural form of application is applications
The plural form of song is songs
The plural form of resource is resources
The plural form of period is
2024-07-27 20:04:45 root INFO     [order_1_approx] starting weight calculation for The plural form of resource is resources
The plural form of application is applications
The plural form of period is periods
The plural form of difference is differences
The plural form of website is websites
The plural form of college is colleges
The plural form of council is councils
The plural form of song is
2024-07-27 20:04:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 20:07:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0234,  0.2439,  0.1187,  ...,  0.0851, -0.4692, -0.2866],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6250, -3.6191,  2.5859,  ..., -2.1797, -1.4141, -2.2500],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0741, -0.0041,  0.0364,  ..., -0.0050,  0.0114, -0.0009],
        [-0.0133,  0.0762, -0.0045,  ...,  0.0009,  0.0115, -0.0144],
        [ 0.0013, -0.0046,  0.0731,  ..., -0.0005, -0.0268,  0.0025],
        ...,
        [ 0.0030, -0.0002, -0.0103,  ...,  0.0518, -0.0013,  0.0004],
        [-0.0203,  0.0172, -0.0488,  ..., -0.0157,  0.0230,  0.0124],
        [ 0.0323,  0.0047, -0.0039,  ..., -0.0110,  0.0170,  0.0300]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6548, -3.5352,  2.4004,  ..., -1.6191, -0.9692, -1.7148]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 20:07:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of resource is resources
The plural form of application is applications
The plural form of period is periods
The plural form of difference is differences
The plural form of website is websites
The plural form of college is colleges
The plural form of council is councils
The plural form of song is
2024-07-27 20:07:08 root INFO     [order_1_approx] starting weight calculation for The plural form of difference is differences
The plural form of council is councils
The plural form of period is periods
The plural form of website is websites
The plural form of resource is resources
The plural form of application is applications
The plural form of song is songs
The plural form of college is
2024-07-27 20:07:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 20:09:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3901,  0.0657, -0.4878,  ..., -0.2336, -0.5864,  0.0168],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3789, -2.3359,  1.7139,  ..., -0.5928,  1.8262, -0.8896],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0798,  0.0021,  0.0047,  ...,  0.0072,  0.0088,  0.0044],
        [-0.0056,  0.0773,  0.0107,  ...,  0.0214,  0.0074,  0.0084],
        [ 0.0316,  0.0002,  0.0569,  ..., -0.0184, -0.0279,  0.0259],
        ...,
        [-0.0115,  0.0320, -0.0190,  ...,  0.0455, -0.0199,  0.0148],
        [-0.0383,  0.0151, -0.0090,  ...,  0.0094,  0.0573,  0.0375],
        [ 0.0152, -0.0047, -0.0113,  ..., -0.0042, -0.0235,  0.0565]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3398, -2.0977,  1.1504,  ..., -0.5137,  0.8955, -0.7744]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 20:09:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of difference is differences
The plural form of council is councils
The plural form of period is periods
The plural form of website is websites
The plural form of resource is resources
The plural form of application is applications
The plural form of song is songs
The plural form of college is
2024-07-27 20:09:30 root INFO     [order_1_approx] starting weight calculation for The plural form of council is councils
The plural form of website is websites
The plural form of song is songs
The plural form of college is colleges
The plural form of resource is resources
The plural form of difference is differences
The plural form of period is periods
The plural form of application is
2024-07-27 20:09:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 20:11:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3315,  0.1890, -0.3433,  ...,  0.1650, -0.2600, -0.3345],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7539, -2.1797, -0.8032,  ..., -0.1416, -3.4199, -1.5801],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.7322e-02,  1.8234e-02,  2.5330e-02,  ..., -5.2643e-03,
          9.9335e-03,  2.9724e-02],
        [-4.4060e-04,  8.1909e-02,  1.2352e-02,  ...,  3.3779e-03,
         -6.3133e-03,  1.4870e-02],
        [-1.2589e-02,  2.8782e-03,  5.9540e-02,  ..., -1.4969e-02,
         -5.6229e-03,  8.6060e-03],
        ...,
        [-1.0605e-02,  4.1580e-04, -2.2842e-02,  ...,  7.5562e-02,
         -5.6839e-03, -1.3603e-02],
        [-2.7695e-02, -1.9455e-04, -7.0267e-03,  ...,  1.4954e-03,
          3.6316e-02, -2.2781e-02],
        [ 7.7782e-03,  1.6357e-02,  9.9182e-05,  ...,  1.5465e-02,
         -1.5198e-02,  6.1310e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3669, -2.3535,  0.0820,  ..., -0.5146, -3.2305, -1.1387]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 20:11:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of council is councils
The plural form of website is websites
The plural form of song is songs
The plural form of college is colleges
The plural form of resource is resources
The plural form of difference is differences
The plural form of period is periods
The plural form of application is
2024-07-27 20:11:53 root INFO     [order_1_approx] starting weight calculation for The plural form of period is periods
The plural form of resource is resources
The plural form of song is songs
The plural form of application is applications
The plural form of college is colleges
The plural form of difference is differences
The plural form of website is websites
The plural form of council is
2024-07-27 20:11:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 20:14:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3611,  0.2900, -0.2261,  ...,  0.0460, -0.3459, -0.3022],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3438, -4.2578,  4.4766,  ..., -1.8643,  1.4766, -0.5317],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0671,  0.0288,  0.0255,  ...,  0.0030, -0.0106,  0.0052],
        [-0.0005,  0.0471, -0.0074,  ...,  0.0076,  0.0128, -0.0119],
        [-0.0023, -0.0094,  0.0612,  ...,  0.0111, -0.0229,  0.0023],
        ...,
        [-0.0157,  0.0157,  0.0174,  ...,  0.0535,  0.0010, -0.0008],
        [-0.0312,  0.0009, -0.0077,  ..., -0.0028,  0.0191,  0.0069],
        [-0.0016, -0.0026,  0.0024,  ..., -0.0007, -0.0005,  0.0501]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1328, -4.0742,  3.7773,  ..., -1.7695,  1.1133, -0.0234]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 20:14:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of period is periods
The plural form of resource is resources
The plural form of song is songs
The plural form of application is applications
The plural form of college is colleges
The plural form of difference is differences
The plural form of website is websites
The plural form of council is
2024-07-27 20:14:15 root INFO     [order_1_approx] starting weight calculation for The plural form of period is periods
The plural form of council is councils
The plural form of difference is differences
The plural form of song is songs
The plural form of application is applications
The plural form of website is websites
The plural form of college is colleges
The plural form of resource is
2024-07-27 20:14:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 20:16:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2300,  0.1305, -0.5156,  ..., -0.1310,  0.0258, -0.0258],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1616, -2.5918,  0.5474,  ..., -1.6484, -1.5684, -1.1475],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0660,  0.0089, -0.0061,  ..., -0.0169, -0.0022,  0.0003],
        [-0.0059,  0.0662,  0.0446,  ...,  0.0259,  0.0062,  0.0184],
        [ 0.0116,  0.0033,  0.0772,  ...,  0.0122,  0.0038, -0.0134],
        ...,
        [-0.0027,  0.0053, -0.0017,  ...,  0.0894,  0.0103, -0.0098],
        [-0.0161,  0.0148, -0.0338,  ..., -0.0413,  0.0485, -0.0107],
        [ 0.0252, -0.0083,  0.0092,  ...,  0.0080, -0.0108,  0.0670]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5698, -2.6426,  0.9922,  ..., -1.2686, -0.9116, -1.1914]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 20:16:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of period is periods
The plural form of council is councils
The plural form of difference is differences
The plural form of song is songs
The plural form of application is applications
The plural form of website is websites
The plural form of college is colleges
The plural form of resource is
2024-07-27 20:16:37 root INFO     [order_1_approx] starting weight calculation for The plural form of website is websites
The plural form of college is colleges
The plural form of resource is resources
The plural form of period is periods
The plural form of council is councils
The plural form of song is songs
The plural form of application is applications
The plural form of difference is
2024-07-27 20:16:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 20:18:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2389, -0.0231, -0.1287,  ...,  0.1382,  0.0323,  0.2280],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3340, -0.2837,  3.2266,  ..., -3.2188, -3.0879, -1.8379],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0519,  0.0046, -0.0044,  ...,  0.0144,  0.0021,  0.0158],
        [ 0.0170,  0.0779,  0.0299,  ...,  0.0329,  0.0234,  0.0028],
        [-0.0233,  0.0020,  0.0352,  ..., -0.0195, -0.0135,  0.0170],
        ...,
        [ 0.0052,  0.0048, -0.0005,  ...,  0.0697, -0.0330,  0.0292],
        [-0.0266, -0.0170, -0.0093,  ...,  0.0115,  0.0594, -0.0188],
        [ 0.0080,  0.0316,  0.0194,  ...,  0.0100, -0.0447,  0.0767]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8389, -1.2949,  2.8945,  ..., -3.0938, -2.8965, -1.7275]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 20:18:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of website is websites
The plural form of college is colleges
The plural form of resource is resources
The plural form of period is periods
The plural form of council is councils
The plural form of song is songs
The plural form of application is applications
The plural form of difference is
2024-07-27 20:18:59 root INFO     [order_1_approx] starting weight calculation for The plural form of application is applications
The plural form of period is periods
The plural form of song is songs
The plural form of council is councils
The plural form of difference is differences
The plural form of college is colleges
The plural form of resource is resources
The plural form of website is
2024-07-27 20:18:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 20:21:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1562,  0.3230, -0.2312,  ...,  0.0492, -0.3237, -0.0878],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5596, -3.1914,  1.7314,  ...,  0.6880, -1.0693, -0.8530],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0281, -0.0065,  0.0027,  ...,  0.0095,  0.0041,  0.0085],
        [-0.0032,  0.0777,  0.0156,  ..., -0.0020, -0.0002, -0.0032],
        [ 0.0207,  0.0156,  0.0533,  ...,  0.0150, -0.0243,  0.0258],
        ...,
        [-0.0059,  0.0071,  0.0120,  ...,  0.0323,  0.0085, -0.0094],
        [ 0.0009,  0.0231, -0.0174,  ...,  0.0158,  0.0496,  0.0106],
        [-0.0046,  0.0044, -0.0028,  ...,  0.0079, -0.0196,  0.0418]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9326, -3.5156,  1.5449,  ...,  0.8252, -1.1885, -0.5347]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 20:21:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of application is applications
The plural form of period is periods
The plural form of song is songs
The plural form of council is councils
The plural form of difference is differences
The plural form of college is colleges
The plural form of resource is resources
The plural form of website is
2024-07-27 20:21:22 root INFO     total operator prediction time: 1140.4577124118805 seconds
2024-07-27 20:21:22 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_Ving - 3pSg
2024-07-27 20:21:22 root INFO     building operator verb_Ving - 3pSg
2024-07-27 20:21:22 root INFO     [order_1_approx] starting weight calculation for When something is remaining, it remains
When something is consisting, it consists
When something is following, it follows
When something is occurring, it occurs
When something is operating, it operates
When something is seeming, it seems
When something is representing, it represents
When something is discovering, it
2024-07-27 20:21:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 20:23:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4607,  0.0388, -0.2734,  ..., -0.0862, -0.2561, -0.3574],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5547e+00, -4.1875e+00,  2.3945e+00,  ...,  2.9297e-03,
        -5.1875e+00,  7.8320e-01], device='cuda:1', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0473,  0.0091,  0.0182,  ...,  0.0142, -0.0139,  0.0039],
        [ 0.0140,  0.0310,  0.0007,  ..., -0.0032, -0.0027,  0.0185],
        [-0.0004, -0.0021,  0.0343,  ..., -0.0125,  0.0030, -0.0084],
        ...,
        [ 0.0243,  0.0040,  0.0017,  ...,  0.0213, -0.0004,  0.0110],
        [-0.0137, -0.0046, -0.0193,  ..., -0.0088,  0.0335, -0.0231],
        [-0.0157, -0.0073,  0.0219,  ...,  0.0026, -0.0025,  0.0135]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4199, -4.0898,  2.2539,  ...,  0.2308, -5.4688,  0.7178]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 20:23:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is remaining, it remains
When something is consisting, it consists
When something is following, it follows
When something is occurring, it occurs
When something is operating, it operates
When something is seeming, it seems
When something is representing, it represents
When something is discovering, it
2024-07-27 20:23:44 root INFO     [order_1_approx] starting weight calculation for When something is consisting, it consists
When something is representing, it represents
When something is remaining, it remains
When something is seeming, it seems
When something is discovering, it discovers
When something is following, it follows
When something is occurring, it occurs
When something is operating, it
2024-07-27 20:23:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 20:26:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1176, -0.3716, -0.3530,  ..., -0.0191,  0.0507, -0.3374],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3477, -4.4375,  0.2598,  ..., -1.7617, -3.9453, -0.4189],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0479, -0.0134,  0.0008,  ..., -0.0100, -0.0047,  0.0175],
        [ 0.0100,  0.0428,  0.0070,  ...,  0.0109, -0.0039,  0.0160],
        [-0.0077,  0.0258,  0.0332,  ..., -0.0201, -0.0071,  0.0008],
        ...,
        [ 0.0227,  0.0042, -0.0029,  ...,  0.0604, -0.0048,  0.0024],
        [-0.0065, -0.0047, -0.0145,  ..., -0.0053,  0.0302, -0.0259],
        [ 0.0080, -0.0179,  0.0158,  ..., -0.0038, -0.0137,  0.0314]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9531, -3.6797,  0.5459,  ..., -1.0039, -3.9062, -0.3853]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 20:26:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is consisting, it consists
When something is representing, it represents
When something is remaining, it remains
When something is seeming, it seems
When something is discovering, it discovers
When something is following, it follows
When something is occurring, it occurs
When something is operating, it
2024-07-27 20:26:05 root INFO     [order_1_approx] starting weight calculation for When something is consisting, it consists
When something is remaining, it remains
When something is discovering, it discovers
When something is operating, it operates
When something is following, it follows
When something is representing, it represents
When something is occurring, it occurs
When something is seeming, it
2024-07-27 20:26:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 20:28:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2996, -0.1022,  0.0018,  ...,  0.1997, -0.0222, -0.0925],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2109, -1.4551, -2.7910,  ...,  1.6504, -4.5898, -1.7559],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0462, -0.0090,  0.0037,  ...,  0.0002,  0.0033,  0.0052],
        [ 0.0008,  0.0502, -0.0070,  ...,  0.0118, -0.0010,  0.0075],
        [ 0.0122, -0.0168,  0.0477,  ..., -0.0147, -0.0083, -0.0038],
        ...,
        [ 0.0115,  0.0062,  0.0011,  ...,  0.0530, -0.0127,  0.0190],
        [-0.0145,  0.0147, -0.0216,  ..., -0.0167,  0.0299, -0.0365],
        [-0.0123, -0.0067,  0.0264,  ..., -0.0074,  0.0003,  0.0183]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1250, -0.9932, -2.8086,  ...,  1.9414, -4.9492, -1.4561]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 20:28:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is consisting, it consists
When something is remaining, it remains
When something is discovering, it discovers
When something is operating, it operates
When something is following, it follows
When something is representing, it represents
When something is occurring, it occurs
When something is seeming, it
2024-07-27 20:28:27 root INFO     [order_1_approx] starting weight calculation for When something is representing, it represents
When something is consisting, it consists
When something is following, it follows
When something is operating, it operates
When something is remaining, it remains
When something is seeming, it seems
When something is discovering, it discovers
When something is occurring, it
2024-07-27 20:28:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 20:30:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0897, -0.0098, -0.4602,  ..., -0.1200,  0.2191, -0.8359],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0547, -4.1680, -0.7070,  ..., -0.9473, -3.0566,  0.6299],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.0862e-02, -3.6888e-03, -1.7578e-02,  ...,  1.7212e-02,
         -4.9782e-03,  3.6591e-02],
        [ 7.8430e-03,  4.4006e-02,  3.4332e-03,  ...,  1.5991e-02,
         -3.6697e-03,  5.2032e-03],
        [ 7.1812e-04, -1.1253e-03,  2.5406e-02,  ..., -2.2583e-02,
         -2.4071e-03, -5.6992e-03],
        ...,
        [ 1.7731e-02, -2.4109e-03,  2.6970e-03,  ...,  2.9938e-02,
         -9.9487e-03,  1.4343e-03],
        [-1.6785e-02, -1.0887e-02,  8.7738e-05,  ..., -1.1086e-02,
          2.3254e-02, -2.0233e-02],
        [-2.0218e-03, -6.9160e-03,  1.4748e-02,  ..., -4.2305e-03,
         -4.3411e-03,  2.8244e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5752, -3.6172, -0.8027,  ..., -0.4829, -3.3281,  0.4243]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 20:30:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is representing, it represents
When something is consisting, it consists
When something is following, it follows
When something is operating, it operates
When something is remaining, it remains
When something is seeming, it seems
When something is discovering, it discovers
When something is occurring, it
2024-07-27 20:30:49 root INFO     [order_1_approx] starting weight calculation for When something is representing, it represents
When something is remaining, it remains
When something is operating, it operates
When something is seeming, it seems
When something is occurring, it occurs
When something is discovering, it discovers
When something is consisting, it consists
When something is following, it
2024-07-27 20:30:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 20:33:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2043,  0.0214, -0.1877,  ..., -0.1816,  0.1715, -0.1559],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7305, -2.1719,  1.2207,  ..., -0.3967, -5.8555, -0.8008],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0891,  0.0097, -0.0023,  ...,  0.0190,  0.0208,  0.0027],
        [-0.0006,  0.0717,  0.0204,  ...,  0.0060, -0.0044,  0.0002],
        [-0.0063, -0.0039,  0.0649,  ..., -0.0175,  0.0002, -0.0034],
        ...,
        [ 0.0025,  0.0311, -0.0024,  ...,  0.0693, -0.0050, -0.0040],
        [-0.0115,  0.0049, -0.0067,  ...,  0.0100,  0.0371, -0.0423],
        [-0.0179, -0.0011, -0.0007,  ..., -0.0189, -0.0078,  0.0277]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5566, -2.3984,  1.3350,  ..., -0.3284, -5.2891, -0.9541]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 20:33:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is representing, it represents
When something is remaining, it remains
When something is operating, it operates
When something is seeming, it seems
When something is occurring, it occurs
When something is discovering, it discovers
When something is consisting, it consists
When something is following, it
2024-07-27 20:33:10 root INFO     [order_1_approx] starting weight calculation for When something is consisting, it consists
When something is discovering, it discovers
When something is seeming, it seems
When something is operating, it operates
When something is following, it follows
When something is occurring, it occurs
When something is remaining, it remains
When something is representing, it
2024-07-27 20:33:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 20:35:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1278, -0.1027, -0.2747,  ..., -0.1097, -0.0287, -0.4617],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.9189, -3.4863,  1.9463,  ...,  0.8750, -6.1094,  0.1738],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0784, -0.0080,  0.0157,  ...,  0.0130,  0.0113,  0.0210],
        [-0.0082,  0.0648,  0.0025,  ...,  0.0161,  0.0105, -0.0046],
        [ 0.0015,  0.0067,  0.0311,  ..., -0.0185, -0.0229, -0.0116],
        ...,
        [ 0.0149,  0.0166, -0.0039,  ...,  0.0803, -0.0235,  0.0195],
        [-0.0041,  0.0024, -0.0170,  ..., -0.0236,  0.0577, -0.0381],
        [-0.0182, -0.0168,  0.0169,  ..., -0.0143, -0.0180,  0.0461]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8735, -3.3516,  2.1621,  ...,  0.7876, -5.8789,  0.1766]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 20:35:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is consisting, it consists
When something is discovering, it discovers
When something is seeming, it seems
When something is operating, it operates
When something is following, it follows
When something is occurring, it occurs
When something is remaining, it remains
When something is representing, it
2024-07-27 20:35:33 root INFO     [order_1_approx] starting weight calculation for When something is discovering, it discovers
When something is operating, it operates
When something is consisting, it consists
When something is seeming, it seems
When something is following, it follows
When something is representing, it represents
When something is occurring, it occurs
When something is remaining, it
2024-07-27 20:35:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 20:37:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1904,  0.0815, -0.2023,  ..., -0.1831, -0.1324, -0.0055],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5566, -2.8496, -0.9600,  ..., -1.6875, -1.8340, -1.3467],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0533, -0.0084, -0.0030,  ..., -0.0077,  0.0003,  0.0280],
        [ 0.0212,  0.0632, -0.0004,  ...,  0.0147,  0.0332,  0.0374],
        [-0.0045,  0.0075,  0.0611,  ..., -0.0154, -0.0197, -0.0226],
        ...,
        [ 0.0335,  0.0116,  0.0129,  ...,  0.0674, -0.0132,  0.0493],
        [-0.0239, -0.0091,  0.0133,  ...,  0.0135,  0.0415, -0.0341],
        [-0.0295,  0.0009,  0.0242,  ..., -0.0101, -0.0184,  0.0139]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5098, -2.6680, -0.4434,  ..., -1.4307, -1.5898, -1.0527]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 20:37:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is discovering, it discovers
When something is operating, it operates
When something is consisting, it consists
When something is seeming, it seems
When something is following, it follows
When something is representing, it represents
When something is occurring, it occurs
When something is remaining, it
2024-07-27 20:37:55 root INFO     [order_1_approx] starting weight calculation for When something is operating, it operates
When something is seeming, it seems
When something is remaining, it remains
When something is discovering, it discovers
When something is following, it follows
When something is occurring, it occurs
When something is representing, it represents
When something is consisting, it
2024-07-27 20:37:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 20:40:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1251, -0.0912, -0.7080,  ...,  0.0345, -0.1763, -0.1377],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.2969, -1.9727,  1.2725,  ...,  0.0420, -4.4062,  1.3916],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0417, -0.0064, -0.0117,  ...,  0.0063,  0.0131,  0.0088],
        [ 0.0044,  0.0715,  0.0124,  ...,  0.0239,  0.0013,  0.0176],
        [ 0.0020, -0.0021,  0.0468,  ..., -0.0295, -0.0169, -0.0151],
        ...,
        [ 0.0233,  0.0078, -0.0070,  ...,  0.0535, -0.0157,  0.0204],
        [-0.0307, -0.0077,  0.0127,  ..., -0.0123,  0.0319, -0.0199],
        [-0.0231, -0.0302, -0.0106,  ..., -0.0098, -0.0048,  0.0258]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0508, -1.5723,  0.7495,  ...,  0.2273, -4.6172,  1.7324]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 20:40:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is operating, it operates
When something is seeming, it seems
When something is remaining, it remains
When something is discovering, it discovers
When something is following, it follows
When something is occurring, it occurs
When something is representing, it represents
When something is consisting, it
2024-07-27 20:40:16 root INFO     total operator prediction time: 1134.4794318675995 seconds
2024-07-27 20:40:16 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_inf - 3pSg
2024-07-27 20:40:16 root INFO     building operator verb_inf - 3pSg
2024-07-27 20:40:16 root INFO     [order_1_approx] starting weight calculation for I exist, he exists
I believe, he believes
I apply, he applies
I happen, he happens
I consider, he considers
I hear, he hears
I involve, he involves
I describe, he
2024-07-27 20:40:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 20:42:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0352, -0.2330,  0.1434,  ..., -0.2905, -0.1512, -0.3691],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3809, -3.8828,  2.7793,  ..., -0.6318, -5.7969, -0.9707],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0292,  0.0075, -0.0094,  ...,  0.0170, -0.0027,  0.0102],
        [-0.0079,  0.0360,  0.0063,  ..., -0.0024,  0.0243,  0.0139],
        [-0.0082,  0.0056, -0.0054,  ..., -0.0125,  0.0191, -0.0122],
        ...,
        [ 0.0050,  0.0027,  0.0070,  ...,  0.0197,  0.0045,  0.0077],
        [-0.0222, -0.0011, -0.0205,  ..., -0.0114,  0.0269, -0.0193],
        [-0.0018,  0.0083,  0.0065,  ..., -0.0187, -0.0168,  0.0232]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6738, -4.2930,  2.6855,  ..., -0.4343, -5.4180, -0.9868]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 20:42:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I exist, he exists
I believe, he believes
I apply, he applies
I happen, he happens
I consider, he considers
I hear, he hears
I involve, he involves
I describe, he
2024-07-27 20:42:38 root INFO     [order_1_approx] starting weight calculation for I apply, he applies
I describe, he describes
I hear, he hears
I happen, he happens
I involve, he involves
I believe, he believes
I consider, he considers
I exist, he
2024-07-27 20:42:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 20:44:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0669, -0.3008, -0.5264,  ..., -0.2407,  0.1207, -0.0838],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1406, -3.3516, -1.3027,  ..., -1.2246, -4.8008,  0.3047],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0164,  0.0073, -0.0153,  ...,  0.0084, -0.0019,  0.0269],
        [ 0.0046,  0.0284, -0.0047,  ...,  0.0101,  0.0241,  0.0049],
        [ 0.0036,  0.0017,  0.0120,  ..., -0.0162, -0.0097, -0.0118],
        ...,
        [-0.0182,  0.0076, -0.0019,  ...,  0.0237,  0.0079, -0.0083],
        [-0.0284, -0.0142,  0.0164,  ..., -0.0135,  0.0288, -0.0052],
        [-0.0051,  0.0049,  0.0050,  ..., -0.0057, -0.0219, -0.0031]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2910, -3.2363, -1.1494,  ..., -0.7275, -5.0781,  0.5454]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 20:44:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I apply, he applies
I describe, he describes
I hear, he hears
I happen, he happens
I involve, he involves
I believe, he believes
I consider, he considers
I exist, he
2024-07-27 20:44:51 root INFO     [order_1_approx] starting weight calculation for I happen, he happens
I apply, he applies
I describe, he describes
I believe, he believes
I involve, he involves
I hear, he hears
I exist, he exists
I consider, he
2024-07-27 20:44:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 20:47:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2097, -0.2544,  0.0086,  ..., -0.3701, -0.1963,  0.1060],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.8516, -4.5391,  1.5664,  ..., -1.6719, -5.3594,  0.7715],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0412,  0.0013,  0.0106,  ..., -0.0012, -0.0052,  0.0290],
        [-0.0075,  0.0316, -0.0023,  ...,  0.0051,  0.0051, -0.0081],
        [-0.0106,  0.0150,  0.0293,  ..., -0.0258,  0.0028, -0.0107],
        ...,
        [-0.0014, -0.0067,  0.0053,  ...,  0.0337,  0.0099,  0.0121],
        [-0.0245,  0.0027, -0.0018,  ..., -0.0275,  0.0347, -0.0060],
        [-0.0178,  0.0085,  0.0151,  ..., -0.0135, -0.0263,  0.0088]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.5195, -4.1992,  1.5645,  ..., -1.4355, -5.6719,  0.6221]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 20:47:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I happen, he happens
I apply, he applies
I describe, he describes
I believe, he believes
I involve, he involves
I hear, he hears
I exist, he exists
I consider, he
2024-07-27 20:47:08 root INFO     [order_1_approx] starting weight calculation for I exist, he exists
I describe, he describes
I consider, he considers
I happen, he happens
I apply, he applies
I believe, he believes
I involve, he involves
I hear, he
2024-07-27 20:47:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 20:49:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0862, -0.0502,  0.2360,  ...,  0.0165, -0.1317,  0.1868],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3965, -4.0625, -1.3906,  ..., -2.3008, -8.0156, -3.0586],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0511,  0.0225, -0.0113,  ...,  0.0009,  0.0069,  0.0271],
        [-0.0144,  0.0233, -0.0172,  ...,  0.0168,  0.0127, -0.0303],
        [-0.0057, -0.0099,  0.0235,  ..., -0.0101, -0.0196, -0.0189],
        ...,
        [ 0.0112, -0.0056,  0.0027,  ...,  0.0149,  0.0110, -0.0030],
        [-0.0131, -0.0018, -0.0073,  ..., -0.0159,  0.0005, -0.0185],
        [-0.0002,  0.0009,  0.0035,  ..., -0.0110, -0.0190,  0.0079]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4124, -3.5078, -1.2109,  ..., -1.8594, -7.8125, -3.2207]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 20:49:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I exist, he exists
I describe, he describes
I consider, he considers
I happen, he happens
I apply, he applies
I believe, he believes
I involve, he involves
I hear, he
2024-07-27 20:49:32 root INFO     [order_1_approx] starting weight calculation for I happen, he happens
I consider, he considers
I exist, he exists
I describe, he describes
I hear, he hears
I believe, he believes
I apply, he applies
I involve, he
2024-07-27 20:49:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 20:51:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0164,  0.1943, -0.1455,  ..., -0.1772, -0.7559,  0.0213],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2812, -1.1416,  3.1094,  ...,  0.4463, -3.6172, -2.9961],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0246,  0.0116,  0.0083,  ...,  0.0197, -0.0034,  0.0080],
        [-0.0105,  0.0376, -0.0042,  ...,  0.0045,  0.0230,  0.0008],
        [ 0.0033, -0.0005,  0.0138,  ..., -0.0238,  0.0157,  0.0012],
        ...,
        [ 0.0162,  0.0065, -0.0148,  ..., -0.0019,  0.0097,  0.0114],
        [-0.0382, -0.0119,  0.0003,  ..., -0.0032,  0.0316, -0.0121],
        [-0.0316,  0.0134,  0.0135,  ..., -0.0058, -0.0106, -0.0063]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3164, -1.2139,  3.0137,  ...,  0.5635, -3.9395, -3.0527]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 20:51:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I happen, he happens
I consider, he considers
I exist, he exists
I describe, he describes
I hear, he hears
I believe, he believes
I apply, he applies
I involve, he
2024-07-27 20:51:51 root INFO     [order_1_approx] starting weight calculation for I believe, he believes
I hear, he hears
I consider, he considers
I involve, he involves
I apply, he applies
I describe, he describes
I exist, he exists
I happen, he
2024-07-27 20:51:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 20:54:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3618, -0.2239, -0.4993,  ..., -0.2627, -0.1575, -0.3220],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5488, -1.2227, -1.7012,  ..., -1.5977, -8.2031,  0.4023],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0184,  0.0024, -0.0135,  ..., -0.0054,  0.0087,  0.0149],
        [-0.0005,  0.0276, -0.0110,  ..., -0.0114,  0.0054,  0.0085],
        [-0.0059,  0.0062,  0.0068,  ..., -0.0169,  0.0002, -0.0105],
        ...,
        [-0.0123, -0.0158, -0.0077,  ...,  0.0246, -0.0065, -0.0131],
        [-0.0222, -0.0006,  0.0080,  ...,  0.0048, -0.0103, -0.0395],
        [-0.0037,  0.0071,  0.0022,  ..., -0.0026, -0.0216, -0.0176]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3887, -1.1309, -1.3398,  ..., -1.3945, -8.0859,  0.6914]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 20:54:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I believe, he believes
I hear, he hears
I consider, he considers
I involve, he involves
I apply, he applies
I describe, he describes
I exist, he exists
I happen, he
2024-07-27 20:54:12 root INFO     [order_1_approx] starting weight calculation for I happen, he happens
I hear, he hears
I exist, he exists
I involve, he involves
I describe, he describes
I consider, he considers
I apply, he applies
I believe, he
2024-07-27 20:54:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 20:56:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0530,  0.1559, -0.1086,  ..., -0.2866, -0.5479,  0.4814],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8691, -4.2695,  0.1562,  ...,  0.1865, -4.8047, -0.3809],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.3117e-02,  6.5613e-03,  7.3433e-03,  ...,  7.0038e-03,
          4.0131e-03,  2.9083e-02],
        [-3.7861e-03,  2.1973e-02, -6.2485e-03,  ...,  1.0624e-03,
          1.5175e-02, -2.7237e-03],
        [-3.8624e-03, -2.4147e-03,  1.4145e-02,  ..., -1.7319e-02,
          4.4518e-03, -6.9466e-03],
        ...,
        [-7.7896e-03, -7.6561e-03, -5.9433e-03,  ...,  7.1030e-03,
          1.6449e-02,  2.0180e-03],
        [-2.2583e-02, -4.5776e-05, -6.3438e-03,  ..., -9.5367e-03,
          1.0742e-02, -2.0920e-02],
        [-1.4694e-02,  1.2192e-02,  8.8043e-03,  ..., -2.3972e-02,
         -2.8046e-02, -3.6526e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5312, -4.2617,  0.2324,  ...,  0.7510, -4.8125, -0.6528]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 20:56:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I happen, he happens
I hear, he hears
I exist, he exists
I involve, he involves
I describe, he describes
I consider, he considers
I apply, he applies
I believe, he
2024-07-27 20:56:34 root INFO     [order_1_approx] starting weight calculation for I exist, he exists
I describe, he describes
I happen, he happens
I believe, he believes
I consider, he considers
I hear, he hears
I involve, he involves
I apply, he
2024-07-27 20:56:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 20:58:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3057, -0.1757,  0.2612,  ..., -0.3066, -0.3662, -0.0026],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5723, -2.8984, -0.8984,  ..., -0.5410, -7.5234, -0.8418],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0445,  0.0128,  0.0039,  ...,  0.0093, -0.0087,  0.0226],
        [-0.0109,  0.0383,  0.0055,  ..., -0.0158,  0.0269, -0.0024],
        [-0.0024,  0.0068,  0.0173,  ..., -0.0125,  0.0041, -0.0082],
        ...,
        [-0.0029,  0.0066, -0.0038,  ...,  0.0490,  0.0178,  0.0057],
        [-0.0155, -0.0085, -0.0085,  ..., -0.0090,  0.0303, -0.0338],
        [-0.0136,  0.0104,  0.0190,  ..., -0.0141, -0.0139,  0.0152]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1133, -3.0957, -0.2842,  ..., -0.4043, -6.7188, -0.6045]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 20:58:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I exist, he exists
I describe, he describes
I happen, he happens
I believe, he believes
I consider, he considers
I hear, he hears
I involve, he involves
I apply, he
2024-07-27 20:58:52 root INFO     total operator prediction time: 1115.859389781952 seconds
2024-07-27 20:58:52 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_inf - Ved
2024-07-27 20:58:52 root INFO     building operator verb_inf - Ved
2024-07-27 20:58:52 root INFO     [order_1_approx] starting weight calculation for If the present form is lose, the past form is lost
If the present form is hear, the past form is heard
If the present form is apply, the past form is applied
If the present form is introduce, the past form is introduced
If the present form is receive, the past form is received
If the present form is discover, the past form is discovered
If the present form is relate, the past form is related
If the present form is tell, the past form is
2024-07-27 20:58:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 21:01:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0640, -0.1487,  0.2200,  ..., -0.1934, -0.2489,  0.0765],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7412,  0.2283,  2.1836,  ...,  2.4453, -4.2930, -2.0117],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0525, -0.0108, -0.0007,  ...,  0.0079,  0.0039,  0.0301],
        [-0.0111,  0.0665,  0.0015,  ...,  0.0016,  0.0015,  0.0095],
        [ 0.0040, -0.0056,  0.0315,  ...,  0.0003, -0.0141,  0.0081],
        ...,
        [ 0.0089,  0.0102, -0.0126,  ...,  0.0450,  0.0082, -0.0017],
        [-0.0112, -0.0123, -0.0094,  ...,  0.0086,  0.0466, -0.0098],
        [-0.0051,  0.0129,  0.0368,  ..., -0.0109, -0.0094,  0.0312]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6309,  0.0894,  2.1172,  ...,  2.4277, -3.7051, -2.1035]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 21:01:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is lose, the past form is lost
If the present form is hear, the past form is heard
If the present form is apply, the past form is applied
If the present form is introduce, the past form is introduced
If the present form is receive, the past form is received
If the present form is discover, the past form is discovered
If the present form is relate, the past form is related
If the present form is tell, the past form is
2024-07-27 21:01:12 root INFO     [order_1_approx] starting weight calculation for If the present form is tell, the past form is told
If the present form is introduce, the past form is introduced
If the present form is hear, the past form is heard
If the present form is lose, the past form is lost
If the present form is discover, the past form is discovered
If the present form is apply, the past form is applied
If the present form is relate, the past form is related
If the present form is receive, the past form is
2024-07-27 21:01:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 21:03:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0201,  0.1283, -0.1504,  ..., -0.4714,  0.0445, -0.0737],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.4570, -0.1162, -0.7231,  ..., -3.4336, -1.2930, -1.5576],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0806, -0.0328,  0.0260,  ..., -0.0135, -0.0028,  0.0416],
        [-0.0414,  0.0740,  0.0369,  ...,  0.0002, -0.0129, -0.0175],
        [-0.0061,  0.0117,  0.0284,  ..., -0.0092, -0.0259,  0.0044],
        ...,
        [-0.0039, -0.0043, -0.0004,  ...,  0.0758,  0.0177, -0.0235],
        [ 0.0032, -0.0073, -0.0135,  ..., -0.0242,  0.0360, -0.0204],
        [-0.0149,  0.0067,  0.0112,  ..., -0.0098, -0.0140,  0.0281]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.3184, -0.3569, -0.7808,  ..., -2.9473, -1.0928, -1.0938]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 21:03:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is tell, the past form is told
If the present form is introduce, the past form is introduced
If the present form is hear, the past form is heard
If the present form is lose, the past form is lost
If the present form is discover, the past form is discovered
If the present form is apply, the past form is applied
If the present form is relate, the past form is related
If the present form is receive, the past form is
2024-07-27 21:03:31 root INFO     [order_1_approx] starting weight calculation for If the present form is introduce, the past form is introduced
If the present form is receive, the past form is received
If the present form is discover, the past form is discovered
If the present form is tell, the past form is told
If the present form is apply, the past form is applied
If the present form is relate, the past form is related
If the present form is lose, the past form is lost
If the present form is hear, the past form is
2024-07-27 21:03:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 21:05:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0397,  0.0367,  0.1155,  ...,  0.0820, -0.2152,  0.0089],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.9102, -0.5840,  0.7734,  ..., -0.2251, -3.0195, -2.9590],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0814, -0.0094,  0.0136,  ..., -0.0030,  0.0281,  0.0272],
        [ 0.0040,  0.0804,  0.0028,  ...,  0.0159,  0.0099, -0.0108],
        [ 0.0040,  0.0119,  0.0690,  ..., -0.0191, -0.0276,  0.0103],
        ...,
        [ 0.0114,  0.0211, -0.0073,  ...,  0.0534,  0.0226, -0.0178],
        [-0.0017,  0.0169,  0.0030,  ...,  0.0045,  0.0249, -0.0183],
        [-0.0128,  0.0018,  0.0133,  ..., -0.0121,  0.0104,  0.0369]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7910, -0.6680,  0.4895,  ...,  0.0615, -2.7480, -2.7793]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 21:05:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is introduce, the past form is introduced
If the present form is receive, the past form is received
If the present form is discover, the past form is discovered
If the present form is tell, the past form is told
If the present form is apply, the past form is applied
If the present form is relate, the past form is related
If the present form is lose, the past form is lost
If the present form is hear, the past form is
2024-07-27 21:05:49 root INFO     [order_1_approx] starting weight calculation for If the present form is hear, the past form is heard
If the present form is lose, the past form is lost
If the present form is relate, the past form is related
If the present form is tell, the past form is told
If the present form is apply, the past form is applied
If the present form is introduce, the past form is introduced
If the present form is receive, the past form is received
If the present form is discover, the past form is
2024-07-27 21:05:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 21:08:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0534,  0.1128, -0.1448,  ..., -0.3760, -0.5454,  0.1379],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8945, -1.4824,  2.4844,  ..., -0.9238, -0.9756,  1.0566],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0622, -0.0028,  0.0231,  ...,  0.0043,  0.0118,  0.0188],
        [-0.0029,  0.0634,  0.0213,  ...,  0.0262, -0.0129,  0.0044],
        [-0.0017,  0.0089,  0.0326,  ..., -0.0062, -0.0050, -0.0133],
        ...,
        [-0.0126,  0.0083, -0.0058,  ...,  0.0671,  0.0110, -0.0036],
        [-0.0021,  0.0190, -0.0094,  ..., -0.0121,  0.0333, -0.0102],
        [-0.0084, -0.0123,  0.0310,  ..., -0.0215, -0.0196,  0.0302]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7422, -1.8281,  2.3223,  ..., -0.5996, -0.7246,  0.9976]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 21:08:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is hear, the past form is heard
If the present form is lose, the past form is lost
If the present form is relate, the past form is related
If the present form is tell, the past form is told
If the present form is apply, the past form is applied
If the present form is introduce, the past form is introduced
If the present form is receive, the past form is received
If the present form is discover, the past form is
2024-07-27 21:08:07 root INFO     [order_1_approx] starting weight calculation for If the present form is tell, the past form is told
If the present form is hear, the past form is heard
If the present form is lose, the past form is lost
If the present form is discover, the past form is discovered
If the present form is relate, the past form is related
If the present form is introduce, the past form is introduced
If the present form is receive, the past form is received
If the present form is apply, the past form is
2024-07-27 21:08:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 21:10:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0192, -0.3093,  0.1058,  ..., -0.1372, -0.1746, -0.1575],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4062, -0.9824, -0.9150,  ..., -0.4136, -2.7266, -1.7539],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0651, -0.0313,  0.0173,  ...,  0.0076,  0.0107,  0.0209],
        [-0.0185,  0.0540,  0.0080,  ...,  0.0018, -0.0153, -0.0087],
        [ 0.0032, -0.0103,  0.0254,  ..., -0.0152, -0.0066, -0.0016],
        ...,
        [-0.0025,  0.0034, -0.0123,  ...,  0.0717,  0.0070,  0.0079],
        [-0.0004, -0.0140, -0.0069,  ...,  0.0039,  0.0089, -0.0216],
        [-0.0341,  0.0014, -0.0210,  ..., -0.0241, -0.0283,  0.0058]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7314, -1.1445, -0.9692,  ..., -0.2524, -2.5742, -1.3750]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 21:10:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is tell, the past form is told
If the present form is hear, the past form is heard
If the present form is lose, the past form is lost
If the present form is discover, the past form is discovered
If the present form is relate, the past form is related
If the present form is introduce, the past form is introduced
If the present form is receive, the past form is received
If the present form is apply, the past form is
2024-07-27 21:10:24 root INFO     [order_1_approx] starting weight calculation for If the present form is tell, the past form is told
If the present form is hear, the past form is heard
If the present form is discover, the past form is discovered
If the present form is receive, the past form is received
If the present form is apply, the past form is applied
If the present form is lose, the past form is lost
If the present form is relate, the past form is related
If the present form is introduce, the past form is
2024-07-27 21:10:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 21:12:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3394,  0.2891, -0.1041,  ..., -0.1533,  0.0061,  0.1559],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3701,  1.4639,  2.9297,  ...,  0.7275, -2.3965, -0.7471],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.8857e-02, -4.0855e-03,  1.4099e-02,  ...,  1.2695e-02,
         -8.8120e-03,  2.1286e-02],
        [-2.4475e-02,  5.0293e-02,  4.7684e-03,  ...,  1.5602e-02,
         -1.1673e-02, -2.6817e-03],
        [ 9.8419e-03, -1.2980e-03,  1.0048e-02,  ...,  9.9182e-03,
         -2.8442e-02,  1.2871e-02],
        ...,
        [ 6.3133e-04, -9.9106e-03, -1.0086e-02,  ...,  5.5206e-02,
         -4.6730e-04,  1.2848e-02],
        [ 9.3460e-05, -1.5564e-02, -7.0190e-03,  ..., -8.4229e-03,
          2.8015e-02, -1.1734e-02],
        [-2.5177e-02, -1.4572e-02,  3.4851e-02,  ..., -1.7624e-02,
         -2.2629e-02,  2.7557e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0483,  1.4004,  3.1602,  ...,  0.7334, -2.0195, -0.7788]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 21:12:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is tell, the past form is told
If the present form is hear, the past form is heard
If the present form is discover, the past form is discovered
If the present form is receive, the past form is received
If the present form is apply, the past form is applied
If the present form is lose, the past form is lost
If the present form is relate, the past form is related
If the present form is introduce, the past form is
2024-07-27 21:12:47 root INFO     [order_1_approx] starting weight calculation for If the present form is introduce, the past form is introduced
If the present form is discover, the past form is discovered
If the present form is lose, the past form is lost
If the present form is tell, the past form is told
If the present form is hear, the past form is heard
If the present form is apply, the past form is applied
If the present form is receive, the past form is received
If the present form is relate, the past form is
2024-07-27 21:12:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 21:15:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0930, -0.0760, -0.3416,  ..., -0.4373, -0.3918,  0.0356],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.5488,  0.7158,  2.1680,  ..., -0.0554, -1.9980, -1.5977],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0655,  0.0008, -0.0059,  ...,  0.0133, -0.0034,  0.0257],
        [-0.0210,  0.0901,  0.0277,  ...,  0.0153, -0.0087,  0.0026],
        [ 0.0054, -0.0035,  0.0565,  ..., -0.0004, -0.0167, -0.0148],
        ...,
        [ 0.0127,  0.0002, -0.0190,  ...,  0.0609,  0.0130,  0.0066],
        [-0.0023, -0.0125, -0.0218,  ...,  0.0217,  0.0322, -0.0163],
        [-0.0206, -0.0004,  0.0169,  ...,  0.0024, -0.0170,  0.0361]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.7168,  0.3206,  1.4180,  ..., -0.0384, -1.6602, -1.2861]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 21:15:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is introduce, the past form is introduced
If the present form is discover, the past form is discovered
If the present form is lose, the past form is lost
If the present form is tell, the past form is told
If the present form is hear, the past form is heard
If the present form is apply, the past form is applied
If the present form is receive, the past form is received
If the present form is relate, the past form is
2024-07-27 21:15:05 root INFO     [order_1_approx] starting weight calculation for If the present form is discover, the past form is discovered
If the present form is hear, the past form is heard
If the present form is introduce, the past form is introduced
If the present form is tell, the past form is told
If the present form is apply, the past form is applied
If the present form is receive, the past form is received
If the present form is relate, the past form is related
If the present form is lose, the past form is
2024-07-27 21:15:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 21:17:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1898,  0.1724,  0.1545,  ..., -0.4250,  0.3555, -0.0789],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3262, -1.5234, -0.1504,  ..., -0.7544, -0.4746, -0.8652],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0781, -0.0089,  0.0321,  ..., -0.0141,  0.0136,  0.0141],
        [-0.0043,  0.0626,  0.0294,  ...,  0.0018, -0.0201, -0.0116],
        [-0.0189,  0.0048,  0.0542,  ...,  0.0024, -0.0327, -0.0056],
        ...,
        [ 0.0063,  0.0147, -0.0271,  ...,  0.0597,  0.0205, -0.0041],
        [-0.0025, -0.0077,  0.0063,  ..., -0.0035,  0.0361, -0.0182],
        [-0.0145,  0.0149, -0.0005,  ..., -0.0275, -0.0105,  0.0251]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5615, -1.6875, -0.1040,  ..., -0.0630, -0.1829, -0.8608]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 21:17:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is discover, the past form is discovered
If the present form is hear, the past form is heard
If the present form is introduce, the past form is introduced
If the present form is tell, the past form is told
If the present form is apply, the past form is applied
If the present form is receive, the past form is received
If the present form is relate, the past form is related
If the present form is lose, the past form is
2024-07-27 21:17:26 root INFO     total operator prediction time: 1114.3395545482635 seconds
2024-07-27 21:17:26 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_Ving - Ved
2024-07-27 21:17:26 root INFO     building operator verb_Ving - Ved
2024-07-27 21:17:26 root INFO     [order_1_approx] starting weight calculation for After something is deciding, it has decided
After something is managing, it has managed
After something is appearing, it has appeared
After something is considering, it has considered
After something is receiving, it has received
After something is losing, it has lost
After something is suffering, it has suffered
After something is attending, it has
2024-07-27 21:17:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 21:19:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0020, -0.1076, -0.3652,  ..., -0.3110, -0.0342, -0.3816],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.4102,  1.2129,  1.3418,  ..., -1.0322, -4.7070, -0.9414],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0481,  0.0022,  0.0081,  ..., -0.0018,  0.0005, -0.0100],
        [-0.0295,  0.0876,  0.0106,  ..., -0.0042,  0.0181, -0.0182],
        [-0.0091, -0.0087,  0.0597,  ..., -0.0020,  0.0053, -0.0042],
        ...,
        [ 0.0137,  0.0160,  0.0177,  ...,  0.0469,  0.0034,  0.0120],
        [ 0.0178, -0.0228, -0.0177,  ...,  0.0032,  0.0253,  0.0062],
        [ 0.0118,  0.0130,  0.0011,  ..., -0.0100,  0.0054,  0.0412]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0938,  1.0996,  1.0820,  ..., -0.8213, -4.5273, -0.7100]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 21:19:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is deciding, it has decided
After something is managing, it has managed
After something is appearing, it has appeared
After something is considering, it has considered
After something is receiving, it has received
After something is losing, it has lost
After something is suffering, it has suffered
After something is attending, it has
2024-07-27 21:19:50 root INFO     [order_1_approx] starting weight calculation for After something is suffering, it has suffered
After something is considering, it has considered
After something is deciding, it has decided
After something is attending, it has attended
After something is receiving, it has received
After something is losing, it has lost
After something is managing, it has managed
After something is appearing, it has
2024-07-27 21:19:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 21:22:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1763, -0.0792, -0.1929,  ...,  0.0034,  0.1377, -0.5273],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8271,  0.9292,  0.7075,  ...,  0.4824, -2.0977,  2.1387],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0543, -0.0085,  0.0257,  ..., -0.0012,  0.0001,  0.0338],
        [-0.0238,  0.0696,  0.0162,  ...,  0.0289, -0.0155, -0.0179],
        [ 0.0206,  0.0166,  0.0613,  ..., -0.0247,  0.0014,  0.0005],
        ...,
        [-0.0102,  0.0260, -0.0226,  ...,  0.0374, -0.0005,  0.0081],
        [ 0.0254,  0.0097,  0.0005,  ..., -0.0046,  0.0468, -0.0179],
        [-0.0134, -0.0036,  0.0167,  ..., -0.0071, -0.0094,  0.0242]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4856,  0.4968,  0.5381,  ...,  0.6182, -1.6387,  2.3633]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 21:22:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is suffering, it has suffered
After something is considering, it has considered
After something is deciding, it has decided
After something is attending, it has attended
After something is receiving, it has received
After something is losing, it has lost
After something is managing, it has managed
After something is appearing, it has
2024-07-27 21:22:10 root INFO     [order_1_approx] starting weight calculation for After something is considering, it has considered
After something is suffering, it has suffered
After something is managing, it has managed
After something is receiving, it has received
After something is losing, it has lost
After something is attending, it has attended
After something is appearing, it has appeared
After something is deciding, it has
2024-07-27 21:22:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 21:24:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3933, -0.0688, -0.0858,  ...,  0.0692, -0.0020, -0.1324],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6211, -1.5742,  1.3320,  ..., -1.3975, -2.1016,  1.2129],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0187, -0.0084, -0.0073,  ..., -0.0108,  0.0017,  0.0182],
        [-0.0165,  0.0086,  0.0351,  ...,  0.0112,  0.0195, -0.0079],
        [ 0.0083,  0.0099,  0.0127,  ...,  0.0105, -0.0114, -0.0008],
        ...,
        [ 0.0130,  0.0244,  0.0088,  ...,  0.0358,  0.0152,  0.0066],
        [ 0.0066, -0.0005, -0.0103,  ..., -0.0058,  0.0210, -0.0093],
        [-0.0053,  0.0137, -0.0062,  ...,  0.0109, -0.0174, -0.0081]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4746, -1.7402,  1.4590,  ..., -1.2031, -2.1836,  1.3320]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 21:24:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is considering, it has considered
After something is suffering, it has suffered
After something is managing, it has managed
After something is receiving, it has received
After something is losing, it has lost
After something is attending, it has attended
After something is appearing, it has appeared
After something is deciding, it has
2024-07-27 21:24:33 root INFO     [order_1_approx] starting weight calculation for After something is attending, it has attended
After something is suffering, it has suffered
After something is losing, it has lost
After something is receiving, it has received
After something is appearing, it has appeared
After something is deciding, it has decided
After something is considering, it has considered
After something is managing, it has
2024-07-27 21:24:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 21:26:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0476,  0.2600, -0.0692,  ..., -0.0306, -0.1934, -0.2485],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9414, -0.8125,  1.6152,  ..., -2.2969, -1.8340, -1.9150],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0341,  0.0106, -0.0019,  ..., -0.0115, -0.0054,  0.0130],
        [-0.0195,  0.0362,  0.0120,  ...,  0.0186,  0.0188,  0.0050],
        [ 0.0026,  0.0083,  0.0348,  ..., -0.0083,  0.0025, -0.0164],
        ...,
        [ 0.0035,  0.0070,  0.0101,  ...,  0.0383, -0.0055,  0.0081],
        [ 0.0061,  0.0008, -0.0087,  ..., -0.0021,  0.0115, -0.0184],
        [-0.0138,  0.0090,  0.0108,  ..., -0.0165,  0.0077, -0.0060]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7109, -1.3486,  1.3125,  ..., -1.9355, -1.9990, -1.8672]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 21:26:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is attending, it has attended
After something is suffering, it has suffered
After something is losing, it has lost
After something is receiving, it has received
After something is appearing, it has appeared
After something is deciding, it has decided
After something is considering, it has considered
After something is managing, it has
2024-07-27 21:26:55 root INFO     [order_1_approx] starting weight calculation for After something is losing, it has lost
After something is deciding, it has decided
After something is attending, it has attended
After something is appearing, it has appeared
After something is receiving, it has received
After something is managing, it has managed
After something is suffering, it has suffered
After something is considering, it has
2024-07-27 21:26:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 21:29:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2286, -0.4197, -0.0877,  ...,  0.0282,  0.2837, -0.2959],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8555, -1.0430,  3.7559,  ..., -2.6074, -0.3467, -0.1152],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0476, -0.0114,  0.0017,  ..., -0.0040, -0.0133,  0.0275],
        [-0.0249,  0.0224,  0.0070,  ...,  0.0268, -0.0020,  0.0025],
        [-0.0207, -0.0074,  0.0362,  ..., -0.0054, -0.0079, -0.0172],
        ...,
        [ 0.0123,  0.0089,  0.0129,  ...,  0.0320,  0.0025,  0.0185],
        [ 0.0111,  0.0032,  0.0024,  ..., -0.0222,  0.0217, -0.0202],
        [ 0.0077,  0.0174,  0.0273,  ...,  0.0050, -0.0083, -0.0004]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0176, -1.0820,  3.7559,  ..., -2.2852, -0.5483,  0.1190]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 21:29:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is losing, it has lost
After something is deciding, it has decided
After something is attending, it has attended
After something is appearing, it has appeared
After something is receiving, it has received
After something is managing, it has managed
After something is suffering, it has suffered
After something is considering, it has
2024-07-27 21:29:16 root INFO     [order_1_approx] starting weight calculation for After something is appearing, it has appeared
After something is deciding, it has decided
After something is attending, it has attended
After something is suffering, it has suffered
After something is considering, it has considered
After something is losing, it has lost
After something is managing, it has managed
After something is receiving, it has
2024-07-27 21:29:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 21:31:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0760,  0.0279, -0.0236,  ..., -0.3743, -0.0006, -0.5322],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3262,  0.3799, -0.2988,  ..., -2.6445, -2.0996, -1.9805],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.9641e-02, -1.6769e-02,  2.6932e-02,  ...,  9.8228e-05,
         -9.2621e-03,  4.1626e-02],
        [-3.8788e-02,  4.8645e-02,  5.7144e-03,  ...,  2.2171e-02,
          1.3046e-02, -1.3153e-02],
        [ 4.0779e-03,  6.4850e-03,  3.0518e-02,  ..., -2.1454e-02,
          1.3794e-02, -1.8494e-02],
        ...,
        [ 9.0942e-03,  1.8463e-02,  2.2850e-03,  ...,  4.7028e-02,
         -8.1062e-04,  1.8051e-02],
        [ 9.5139e-03,  7.2479e-04, -4.8523e-03,  ..., -2.0466e-03,
          3.7750e-02, -1.2985e-02],
        [-1.5373e-02,  1.8570e-02,  9.8495e-03,  ..., -2.9659e-03,
         -1.4351e-02, -5.0316e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3931, -0.0757, -0.0220,  ..., -2.3516, -1.7852, -1.7930]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 21:31:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is appearing, it has appeared
After something is deciding, it has decided
After something is attending, it has attended
After something is suffering, it has suffered
After something is considering, it has considered
After something is losing, it has lost
After something is managing, it has managed
After something is receiving, it has
2024-07-27 21:31:39 root INFO     [order_1_approx] starting weight calculation for After something is deciding, it has decided
After something is receiving, it has received
After something is suffering, it has suffered
After something is appearing, it has appeared
After something is considering, it has considered
After something is managing, it has managed
After something is attending, it has attended
After something is losing, it has
2024-07-27 21:31:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 21:34:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1365, -0.1936,  0.0081,  ..., -0.2810,  0.5474, -0.4343],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9741, -0.8252,  0.0532,  ..., -1.8730, -0.5635, -1.5156],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0528, -0.0022,  0.0180,  ...,  0.0010, -0.0138,  0.0217],
        [-0.0338,  0.0356,  0.0114,  ...,  0.0111,  0.0059, -0.0007],
        [ 0.0030,  0.0035,  0.0420,  ..., -0.0122, -0.0087, -0.0124],
        ...,
        [-0.0048,  0.0289, -0.0226,  ...,  0.0213,  0.0149,  0.0123],
        [ 0.0276,  0.0007, -0.0207,  ...,  0.0085,  0.0183, -0.0162],
        [-0.0035,  0.0094,  0.0274,  ..., -0.0146,  0.0020,  0.0083]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0186, -1.1045,  0.1656,  ..., -1.4678, -0.3035, -1.3008]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 21:34:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is deciding, it has decided
After something is receiving, it has received
After something is suffering, it has suffered
After something is appearing, it has appeared
After something is considering, it has considered
After something is managing, it has managed
After something is attending, it has attended
After something is losing, it has
2024-07-27 21:34:02 root INFO     [order_1_approx] starting weight calculation for After something is attending, it has attended
After something is deciding, it has decided
After something is losing, it has lost
After something is managing, it has managed
After something is considering, it has considered
After something is appearing, it has appeared
After something is receiving, it has received
After something is suffering, it has
2024-07-27 21:34:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 21:36:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2930, -0.1785,  0.1799,  ..., -0.6245, -0.1024,  0.0309],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.4102, -2.6719,  0.6436,  ..., -3.2637,  2.3477,  1.4443],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0584, -0.0144,  0.0406,  ..., -0.0073,  0.0090,  0.0252],
        [-0.0213,  0.0317,  0.0213,  ...,  0.0210,  0.0138,  0.0006],
        [ 0.0007,  0.0035,  0.0185,  ..., -0.0147,  0.0131, -0.0239],
        ...,
        [-0.0054,  0.0113, -0.0001,  ...,  0.0339,  0.0253,  0.0118],
        [ 0.0166,  0.0225, -0.0181,  ...,  0.0047,  0.0133, -0.0222],
        [-0.0039,  0.0124,  0.0254,  ..., -0.0110, -0.0128,  0.0062]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2578, -2.7812,  0.4092,  ..., -2.9199,  2.4492,  1.5039]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 21:36:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is attending, it has attended
After something is deciding, it has decided
After something is losing, it has lost
After something is managing, it has managed
After something is considering, it has considered
After something is appearing, it has appeared
After something is receiving, it has received
After something is suffering, it has
2024-07-27 21:36:21 root INFO     total operator prediction time: 1134.780775308609 seconds
2024-07-27 21:36:21 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on Ving - verb_inf
2024-07-27 21:36:21 root INFO     building operator Ving - verb_inf
2024-07-27 21:36:21 root INFO     [order_1_approx] starting weight calculation for performing is the active form of perform
attending is the active form of attend
promoting is the active form of promote
losing is the active form of lose
identifying is the active form of identify
protecting is the active form of protect
developing is the active form of develop
containing is the active form of
2024-07-27 21:36:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 21:38:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2466, -0.7495, -0.7168,  ..., -0.0911, -0.0399, -0.2515],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1201, -1.2920,  2.5742,  ...,  0.1824, -1.3672, -2.2617],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.5684e-02, -2.1877e-03, -3.7384e-03,  ...,  7.4043e-03,
         -1.1742e-02,  9.2392e-03],
        [ 1.2253e-02,  6.0760e-02, -4.3488e-03,  ..., -3.1281e-03,
         -2.2919e-02, -1.6403e-02],
        [ 7.8430e-03,  1.2293e-03,  4.8462e-02,  ..., -5.6877e-03,
          9.2888e-04,  8.4877e-05],
        ...,
        [ 1.1131e-02,  3.6793e-03, -1.2230e-02,  ...,  5.1544e-02,
         -1.3494e-03, -4.4136e-03],
        [-6.0654e-04, -2.1191e-03,  6.4621e-03,  ...,  5.7602e-04,
          4.3427e-02,  8.2397e-03],
        [ 2.1915e-03,  6.5575e-03, -1.3718e-02,  ..., -1.4656e-02,
         -1.7136e-02,  5.2704e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9985, -1.5391,  2.4609,  ...,  0.2327, -1.4785, -2.3164]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 21:38:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for performing is the active form of perform
attending is the active form of attend
promoting is the active form of promote
losing is the active form of lose
identifying is the active form of identify
protecting is the active form of protect
developing is the active form of develop
containing is the active form of
2024-07-27 21:38:40 root INFO     [order_1_approx] starting weight calculation for promoting is the active form of promote
performing is the active form of perform
attending is the active form of attend
containing is the active form of contain
losing is the active form of lose
developing is the active form of develop
protecting is the active form of protect
identifying is the active form of
2024-07-27 21:38:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 21:40:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0453, -0.1932, -0.4351,  ...,  0.3418, -0.2764,  0.1254],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3096, -2.9883,  1.3574,  ...,  1.1406, -3.0781, -2.9258],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0511, -0.0068, -0.0007,  ...,  0.0115,  0.0027, -0.0017],
        [-0.0071,  0.0483,  0.0006,  ..., -0.0005,  0.0006,  0.0012],
        [ 0.0082, -0.0198,  0.0483,  ...,  0.0069, -0.0037,  0.0054],
        ...,
        [ 0.0101,  0.0017,  0.0113,  ...,  0.0476,  0.0026,  0.0089],
        [ 0.0028,  0.0113, -0.0065,  ..., -0.0013,  0.0457, -0.0004],
        [-0.0020,  0.0122,  0.0032,  ..., -0.0087, -0.0052,  0.0311]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2871, -3.1699,  1.3174,  ...,  1.1758, -2.8594, -3.0352]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 21:41:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for promoting is the active form of promote
performing is the active form of perform
attending is the active form of attend
containing is the active form of contain
losing is the active form of lose
developing is the active form of develop
protecting is the active form of protect
identifying is the active form of
2024-07-27 21:41:01 root INFO     [order_1_approx] starting weight calculation for developing is the active form of develop
attending is the active form of attend
performing is the active form of perform
losing is the active form of lose
protecting is the active form of protect
containing is the active form of contain
identifying is the active form of identify
promoting is the active form of
2024-07-27 21:41:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 21:43:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3447,  0.0293, -0.1289,  ...,  0.0415,  0.2808,  0.1504],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7520, -3.9492, -0.8672,  ...,  1.9131, -2.9336, -2.2656],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0488,  0.0079,  0.0017,  ...,  0.0068, -0.0253,  0.0040],
        [ 0.0016,  0.0490,  0.0029,  ...,  0.0170, -0.0112, -0.0110],
        [ 0.0125, -0.0033,  0.0328,  ...,  0.0009,  0.0006,  0.0048],
        ...,
        [ 0.0071,  0.0101,  0.0071,  ...,  0.0580, -0.0022, -0.0005],
        [-0.0014,  0.0008, -0.0104,  ..., -0.0004,  0.0289, -0.0139],
        [ 0.0008, -0.0053, -0.0239,  ..., -0.0208, -0.0150,  0.0327]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5859, -4.0156, -1.0537,  ...,  1.7852, -2.8066, -2.0605]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 21:43:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for developing is the active form of develop
attending is the active form of attend
performing is the active form of perform
losing is the active form of lose
protecting is the active form of protect
containing is the active form of contain
identifying is the active form of identify
promoting is the active form of
2024-07-27 21:43:24 root INFO     [order_1_approx] starting weight calculation for developing is the active form of develop
performing is the active form of perform
attending is the active form of attend
protecting is the active form of protect
promoting is the active form of promote
containing is the active form of contain
identifying is the active form of identify
losing is the active form of
2024-07-27 21:43:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 21:45:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1542, -0.2234, -0.0818,  ..., -0.3179,  0.4297,  0.0918],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0322, -3.1953, -0.6152,  ...,  0.8340,  1.2715, -1.5674],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0636, -0.0013,  0.0006,  ..., -0.0003, -0.0071,  0.0241],
        [ 0.0083,  0.0467,  0.0088,  ...,  0.0165,  0.0029, -0.0105],
        [ 0.0100, -0.0168,  0.0349,  ...,  0.0035, -0.0059, -0.0074],
        ...,
        [ 0.0082,  0.0039, -0.0298,  ...,  0.0509,  0.0057,  0.0037],
        [-0.0180,  0.0096,  0.0168,  ...,  0.0016,  0.0283, -0.0076],
        [-0.0034,  0.0125, -0.0037,  ..., -0.0191, -0.0040,  0.0469]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8271, -3.2441, -0.5898,  ...,  1.5273,  1.0557, -1.4287]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 21:45:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for developing is the active form of develop
performing is the active form of perform
attending is the active form of attend
protecting is the active form of protect
promoting is the active form of promote
containing is the active form of contain
identifying is the active form of identify
losing is the active form of
2024-07-27 21:45:46 root INFO     [order_1_approx] starting weight calculation for containing is the active form of contain
protecting is the active form of protect
developing is the active form of develop
promoting is the active form of promote
losing is the active form of lose
identifying is the active form of identify
attending is the active form of attend
performing is the active form of
2024-07-27 21:45:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 21:48:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6157, -0.4004, -0.4136,  ..., -0.1807, -0.0145,  0.2668],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9160, -3.7070,  2.4941,  ...,  1.3086, -1.3262, -3.7070],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0467, -0.0048,  0.0005,  ...,  0.0080,  0.0067,  0.0036],
        [ 0.0009,  0.0420, -0.0003,  ...,  0.0016,  0.0154, -0.0021],
        [ 0.0201, -0.0151,  0.0175,  ...,  0.0104, -0.0074,  0.0075],
        ...,
        [ 0.0064,  0.0180, -0.0093,  ...,  0.0241,  0.0026, -0.0073],
        [-0.0080,  0.0024,  0.0134,  ..., -0.0019,  0.0072, -0.0083],
        [ 0.0109, -0.0041, -0.0084,  ..., -0.0125, -0.0062,  0.0253]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7070, -3.6855,  2.6484,  ...,  1.4648, -1.3945, -3.5879]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 21:48:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for containing is the active form of contain
protecting is the active form of protect
developing is the active form of develop
promoting is the active form of promote
losing is the active form of lose
identifying is the active form of identify
attending is the active form of attend
performing is the active form of
2024-07-27 21:48:09 root INFO     [order_1_approx] starting weight calculation for promoting is the active form of promote
performing is the active form of perform
protecting is the active form of protect
containing is the active form of contain
identifying is the active form of identify
losing is the active form of lose
attending is the active form of attend
developing is the active form of
2024-07-27 21:48:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 21:50:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4890, -0.4102, -0.4111,  ..., -0.3342,  0.0936, -0.0496],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0000, -4.8945,  2.3086,  ...,  2.4492, -1.8643, -2.6836],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.5650e-02, -6.6280e-04, -3.9024e-03,  ...,  1.4324e-03,
         -8.5602e-03,  3.6201e-03],
        [-1.6522e-04,  2.6123e-02,  1.4172e-03,  ...,  5.2834e-03,
          8.7452e-04, -1.3885e-03],
        [ 1.9350e-03, -3.7899e-03,  2.6260e-02,  ..., -7.3433e-04,
         -3.1090e-03,  8.8215e-05],
        ...,
        [ 6.8436e-03,  4.0054e-03, -2.9984e-03,  ...,  2.5604e-02,
         -8.5373e-03,  8.2397e-03],
        [-1.4248e-03,  7.6981e-03,  1.5945e-03,  ...,  5.4817e-03,
          2.0248e-02, -6.0616e-03],
        [-2.8858e-03,  2.6112e-03, -7.1449e-03,  ..., -8.0643e-03,
         -7.6180e-03,  1.8890e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9512, -4.9062,  2.3418,  ...,  2.4238, -1.9424, -2.6074]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 21:50:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for promoting is the active form of promote
performing is the active form of perform
protecting is the active form of protect
containing is the active form of contain
identifying is the active form of identify
losing is the active form of lose
attending is the active form of attend
developing is the active form of
2024-07-27 21:50:31 root INFO     [order_1_approx] starting weight calculation for identifying is the active form of identify
performing is the active form of perform
losing is the active form of lose
developing is the active form of develop
promoting is the active form of promote
containing is the active form of contain
attending is the active form of attend
protecting is the active form of
2024-07-27 21:50:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 21:52:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3628, -0.6567, -0.3899,  ..., -0.2039, -0.1340,  0.1852],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2969, -5.3516, -0.7490,  ...,  1.6797, -1.2305, -1.9766],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.1128e-02,  3.3307e-04, -3.2005e-03,  ...,  9.9659e-04,
         -5.9624e-03,  7.8735e-03],
        [-3.8948e-03,  2.6215e-02,  2.9602e-03,  ..., -3.7956e-03,
          7.0190e-03, -1.6108e-03],
        [ 1.9363e-02, -2.9068e-03,  7.3395e-03,  ...,  5.6610e-03,
         -1.1421e-02,  2.9182e-04],
        ...,
        [ 4.7569e-03,  7.3318e-03,  2.2736e-03,  ...,  1.5594e-02,
          6.8512e-03,  8.5983e-03],
        [-1.4172e-03,  3.1471e-05,  1.0777e-03,  ...,  5.1956e-03,
          1.7654e-02, -4.6654e-03],
        [-1.8539e-03,  6.6223e-03, -5.1537e-03,  ..., -8.1177e-03,
         -7.8583e-03,  2.0462e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2874, -5.3008, -0.7993,  ...,  1.8818, -1.4766, -1.8564]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 21:52:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for identifying is the active form of identify
performing is the active form of perform
losing is the active form of lose
developing is the active form of develop
promoting is the active form of promote
containing is the active form of contain
attending is the active form of attend
protecting is the active form of
2024-07-27 21:52:50 root INFO     [order_1_approx] starting weight calculation for performing is the active form of perform
containing is the active form of contain
identifying is the active form of identify
promoting is the active form of promote
protecting is the active form of protect
losing is the active form of lose
developing is the active form of develop
attending is the active form of
2024-07-27 21:52:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 21:55:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0277, -0.1166, -0.3926,  ..., -0.3301, -0.0635, -0.0787],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1230, -2.8672, -2.2988,  ...,  2.2832, -3.7891, -3.6523],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1005,  0.0030, -0.0046,  ...,  0.0184,  0.0008,  0.0082],
        [-0.0099,  0.0934,  0.0034,  ...,  0.0010, -0.0093, -0.0182],
        [-0.0031,  0.0087,  0.0838,  ...,  0.0189,  0.0063,  0.0092],
        ...,
        [ 0.0001,  0.0140,  0.0041,  ...,  0.0746,  0.0062, -0.0148],
        [-0.0175, -0.0097,  0.0073,  ...,  0.0146,  0.0541, -0.0104],
        [ 0.0022, -0.0001, -0.0201,  ..., -0.0069, -0.0015,  0.0632]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0410, -2.8809, -2.7090,  ...,  2.4023, -3.6816, -3.5898]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 21:55:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for performing is the active form of perform
containing is the active form of contain
identifying is the active form of identify
promoting is the active form of promote
protecting is the active form of protect
losing is the active form of lose
developing is the active form of develop
attending is the active form of
2024-07-27 21:55:08 root INFO     total operator prediction time: 1126.9726243019104 seconds
2024-07-27 21:55:08 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun - plural_irreg
2024-07-27 21:55:08 root INFO     building operator noun - plural_irreg
2024-07-27 21:55:08 root INFO     [order_1_approx] starting weight calculation for The plural form of majority is majorities
The plural form of ability is abilities
The plural form of authority is authorities
The plural form of life is lives
The plural form of secretary is secretaries
The plural form of activity is activities
The plural form of county is counties
The plural form of security is
2024-07-27 21:55:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 21:57:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1802, -0.0481, -0.3989,  ...,  0.1470,  0.0394, -0.0794],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0708, -1.6357,  1.4834,  ..., -0.2295, -2.3438, -4.9336],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1066, -0.0265, -0.0177,  ..., -0.0116, -0.0084,  0.0236],
        [-0.0224,  0.0788,  0.0367,  ...,  0.0260,  0.0096,  0.0241],
        [ 0.0069,  0.0150,  0.0759,  ..., -0.0142, -0.0110,  0.0070],
        ...,
        [ 0.0060,  0.0096, -0.0101,  ...,  0.1031, -0.0084,  0.0021],
        [-0.0181,  0.0196, -0.0200,  ..., -0.0260,  0.0527, -0.0131],
        [ 0.0241, -0.0054,  0.0093,  ...,  0.0323, -0.0174,  0.0703]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0406, -2.2715,  2.1719,  ..., -0.4321, -2.1113, -4.8594]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 21:57:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of majority is majorities
The plural form of ability is abilities
The plural form of authority is authorities
The plural form of life is lives
The plural form of secretary is secretaries
The plural form of activity is activities
The plural form of county is counties
The plural form of security is
2024-07-27 21:57:31 root INFO     [order_1_approx] starting weight calculation for The plural form of life is lives
The plural form of majority is majorities
The plural form of activity is activities
The plural form of authority is authorities
The plural form of security is securities
The plural form of ability is abilities
The plural form of county is counties
The plural form of secretary is
2024-07-27 21:57:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 21:59:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4053,  0.0641, -0.4585,  ..., -0.3662, -0.1660,  0.1359],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7847, -1.6621,  2.6113,  ..., -1.4971, -0.8398, -3.5312],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0752, -0.0105,  0.0042,  ...,  0.0107,  0.0025,  0.0035],
        [ 0.0139,  0.0676,  0.0044,  ...,  0.0123,  0.0201,  0.0148],
        [ 0.0008,  0.0038,  0.0742,  ..., -0.0113, -0.0323,  0.0021],
        ...,
        [-0.0062,  0.0114,  0.0206,  ...,  0.0865, -0.0102,  0.0105],
        [-0.0224,  0.0236,  0.0072,  ...,  0.0135,  0.0287,  0.0023],
        [ 0.0238,  0.0093, -0.0182,  ..., -0.0075, -0.0060,  0.0601]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9219, -2.1953,  2.7168,  ..., -2.1172, -0.2549, -3.1445]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 21:59:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of life is lives
The plural form of majority is majorities
The plural form of activity is activities
The plural form of authority is authorities
The plural form of security is securities
The plural form of ability is abilities
The plural form of county is counties
The plural form of secretary is
2024-07-27 21:59:53 root INFO     [order_1_approx] starting weight calculation for The plural form of secretary is secretaries
The plural form of authority is authorities
The plural form of security is securities
The plural form of life is lives
The plural form of activity is activities
The plural form of majority is majorities
The plural form of county is counties
The plural form of ability is
2024-07-27 21:59:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 22:02:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1655,  0.1626, -0.2646,  ..., -0.3120, -0.0640,  0.1360],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0254, -1.1270,  0.6792,  ..., -0.6445, -2.3789, -1.2617],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0704,  0.0028,  0.0009,  ...,  0.0002,  0.0199,  0.0260],
        [ 0.0163,  0.0813,  0.0133,  ...,  0.0468,  0.0052,  0.0080],
        [-0.0033,  0.0009,  0.0493,  ..., -0.0218, -0.0137,  0.0190],
        ...,
        [ 0.0052,  0.0327, -0.0225,  ...,  0.0645, -0.0023,  0.0099],
        [-0.0144,  0.0219,  0.0133,  ..., -0.0037,  0.0266, -0.0047],
        [ 0.0043, -0.0079,  0.0001,  ...,  0.0066,  0.0079,  0.0529]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6553, -1.2637,  0.8589,  ..., -0.7646, -1.8301, -1.7207]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 22:02:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of secretary is secretaries
The plural form of authority is authorities
The plural form of security is securities
The plural form of life is lives
The plural form of activity is activities
The plural form of majority is majorities
The plural form of county is counties
The plural form of ability is
2024-07-27 22:02:16 root INFO     [order_1_approx] starting weight calculation for The plural form of authority is authorities
The plural form of ability is abilities
The plural form of security is securities
The plural form of activity is activities
The plural form of majority is majorities
The plural form of county is counties
The plural form of secretary is secretaries
The plural form of life is
2024-07-27 22:02:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 22:04:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2749, -0.0535, -0.1946,  ..., -0.0786, -0.3838, -0.0398],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8330, -2.5957,  0.2339,  ..., -1.8896, -3.0156, -1.8330],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.2175e-02,  3.3020e-02, -5.7602e-03,  ...,  2.2163e-03,
         -1.8372e-02,  2.4185e-02],
        [ 1.6830e-02,  8.9050e-02,  2.4979e-02,  ...,  2.3575e-02,
          2.2278e-02,  9.3002e-03],
        [ 1.6953e-02, -1.1063e-03,  7.0679e-02,  ..., -1.2329e-02,
         -1.1948e-02,  4.0405e-02],
        ...,
        [ 3.6560e-02,  3.2196e-02, -1.8509e-02,  ...,  7.2693e-02,
         -9.2239e-03,  2.4475e-02],
        [-4.3907e-03, -6.1035e-04,  1.1887e-02,  ..., -2.6817e-03,
          3.2471e-02,  9.0866e-03],
        [ 7.9727e-03, -5.6419e-03, -2.7573e-02,  ...,  6.8665e-05,
         -1.1238e-02,  5.7587e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8965, -3.3047,  0.4246,  ..., -1.9033, -2.9043, -2.0645]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 22:04:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of authority is authorities
The plural form of ability is abilities
The plural form of security is securities
The plural form of activity is activities
The plural form of majority is majorities
The plural form of county is counties
The plural form of secretary is secretaries
The plural form of life is
2024-07-27 22:04:39 root INFO     [order_1_approx] starting weight calculation for The plural form of life is lives
The plural form of county is counties
The plural form of ability is abilities
The plural form of security is securities
The plural form of majority is majorities
The plural form of authority is authorities
The plural form of secretary is secretaries
The plural form of activity is
2024-07-27 22:04:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 22:07:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0869,  0.0634, -0.3755,  ..., -0.3171, -0.1572, -0.2335],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4832, -0.8428,  1.3447,  ..., -0.2021, -0.3203, -2.3223],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0736,  0.0189,  0.0347,  ..., -0.0023, -0.0035,  0.0152],
        [ 0.0135,  0.0682,  0.0096,  ...,  0.0352, -0.0046,  0.0196],
        [-0.0160, -0.0096,  0.0467,  ..., -0.0043, -0.0012,  0.0013],
        ...,
        [-0.0031,  0.0176, -0.0277,  ...,  0.0650, -0.0162, -0.0042],
        [-0.0262,  0.0287, -0.0138,  ..., -0.0032,  0.0352,  0.0042],
        [ 0.0201,  0.0044, -0.0183,  ...,  0.0095, -0.0002,  0.0670]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2734, -1.1885,  1.8535,  ..., -0.1224, -0.6582, -2.2129]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 22:07:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of life is lives
The plural form of county is counties
The plural form of ability is abilities
The plural form of security is securities
The plural form of majority is majorities
The plural form of authority is authorities
The plural form of secretary is secretaries
The plural form of activity is
2024-07-27 22:07:01 root INFO     [order_1_approx] starting weight calculation for The plural form of activity is activities
The plural form of ability is abilities
The plural form of security is securities
The plural form of secretary is secretaries
The plural form of life is lives
The plural form of authority is authorities
The plural form of county is counties
The plural form of majority is
2024-07-27 22:07:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 22:09:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4968,  0.3457, -0.2847,  ...,  0.0330, -0.2458,  0.1362],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7402,  0.0962, -1.2227,  ..., -5.4883, -1.3105, -2.2090],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0130,  0.0172, -0.0021,  ...,  0.0255,  0.0143,  0.0102],
        [ 0.0458,  0.0704, -0.0015,  ...,  0.0386, -0.0204, -0.0068],
        [ 0.0325,  0.0038,  0.0678,  ..., -0.0095, -0.0137,  0.0136],
        ...,
        [ 0.0382,  0.0432,  0.0209,  ...,  0.0410, -0.0338,  0.0162],
        [-0.0330,  0.0138, -0.0287,  ...,  0.0313,  0.0398,  0.0024],
        [ 0.0327,  0.0028, -0.0165,  ...,  0.0052,  0.0100,  0.0668]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4863, -0.4873, -1.2480,  ..., -5.1406, -1.0020, -2.4922]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 22:09:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of activity is activities
The plural form of ability is abilities
The plural form of security is securities
The plural form of secretary is secretaries
The plural form of life is lives
The plural form of authority is authorities
The plural form of county is counties
The plural form of majority is
2024-07-27 22:09:23 root INFO     [order_1_approx] starting weight calculation for The plural form of ability is abilities
The plural form of majority is majorities
The plural form of secretary is secretaries
The plural form of county is counties
The plural form of security is securities
The plural form of life is lives
The plural form of activity is activities
The plural form of authority is
2024-07-27 22:09:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 22:11:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1741,  0.4971, -0.3230,  ..., -0.1309, -0.2473,  0.0104],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3057, -2.2754,  0.8369,  ..., -0.8193, -1.5918, -2.7422],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0454,  0.0101,  0.0024,  ...,  0.0036, -0.0126,  0.0088],
        [ 0.0164,  0.0651,  0.0123,  ...,  0.0292,  0.0034,  0.0152],
        [ 0.0107,  0.0198,  0.0330,  ...,  0.0028, -0.0138,  0.0009],
        ...,
        [ 0.0110,  0.0280, -0.0023,  ...,  0.0449, -0.0022,  0.0041],
        [-0.0289,  0.0143,  0.0079,  ..., -0.0030,  0.0406, -0.0054],
        [ 0.0331, -0.0069, -0.0044,  ...,  0.0110, -0.0049,  0.0426]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2299, -2.5332,  0.6416,  ..., -1.0889, -1.1416, -3.3613]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 22:11:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of ability is abilities
The plural form of majority is majorities
The plural form of secretary is secretaries
The plural form of county is counties
The plural form of security is securities
The plural form of life is lives
The plural form of activity is activities
The plural form of authority is
2024-07-27 22:11:45 root INFO     [order_1_approx] starting weight calculation for The plural form of security is securities
The plural form of ability is abilities
The plural form of secretary is secretaries
The plural form of authority is authorities
The plural form of activity is activities
The plural form of majority is majorities
The plural form of life is lives
The plural form of county is
2024-07-27 22:11:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 22:14:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1747,  0.0198, -0.1954,  ..., -0.1678, -0.0538,  0.0315],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4788, -4.4492,  2.8125,  ..., -2.1191,  2.3535, -3.5039],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0526,  0.0005, -0.0010,  ...,  0.0028, -0.0080, -0.0228],
        [ 0.0128,  0.0609,  0.0174,  ..., -0.0185, -0.0293,  0.0125],
        [-0.0073,  0.0130,  0.0634,  ...,  0.0157,  0.0032,  0.0264],
        ...,
        [-0.0111,  0.0224,  0.0018,  ...,  0.0466,  0.0029,  0.0164],
        [-0.0468,  0.0181,  0.0172,  ...,  0.0396,  0.0895,  0.0206],
        [ 0.0272, -0.0090, -0.0097,  ..., -0.0288, -0.0331,  0.0472]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2712, -3.7207,  1.8857,  ..., -1.9717,  1.0586, -2.7500]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 22:14:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of security is securities
The plural form of ability is abilities
The plural form of secretary is secretaries
The plural form of authority is authorities
The plural form of activity is activities
The plural form of majority is majorities
The plural form of life is lives
The plural form of county is
2024-07-27 22:14:07 root INFO     total operator prediction time: 1138.4274516105652 seconds
2024-07-27 22:14:07 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - member
2024-07-27 22:14:07 root INFO     building operator meronyms - member
2024-07-27 22:14:07 root INFO     [order_1_approx] starting weight calculation for A member is a member of a club
A kitten is a member of a litter
A book is a member of a library
A employee is a member of a staff
A bee is a member of a swarm
A citizen is a member of a citizenry
A calf is a member of a cattle
A person is a member of a
2024-07-27 22:14:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 22:16:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2981, -0.1461, -0.2329,  ...,  0.1758, -0.2556, -0.2729],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8848, -2.1367,  2.7109,  ..., -1.3740, -1.8574, -0.9946],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0289, -0.0176,  0.0041,  ...,  0.0229, -0.0006,  0.0079],
        [-0.0359,  0.0311,  0.0159,  ...,  0.0110, -0.0247, -0.0101],
        [ 0.0156, -0.0137,  0.0213,  ...,  0.0003,  0.0143,  0.0049],
        ...,
        [-0.0029,  0.0124,  0.0032,  ...,  0.0405, -0.0136, -0.0026],
        [ 0.0140,  0.0014, -0.0146,  ...,  0.0154,  0.0405, -0.0058],
        [-0.0123,  0.0020,  0.0151,  ..., -0.0097, -0.0212,  0.0204]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6855, -1.8203,  2.4688,  ..., -1.2832, -1.8633, -0.5996]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 22:16:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A member is a member of a club
A kitten is a member of a litter
A book is a member of a library
A employee is a member of a staff
A bee is a member of a swarm
A citizen is a member of a citizenry
A calf is a member of a cattle
A person is a member of a
2024-07-27 22:16:28 root INFO     [order_1_approx] starting weight calculation for A employee is a member of a staff
A kitten is a member of a litter
A citizen is a member of a citizenry
A calf is a member of a cattle
A member is a member of a club
A person is a member of a society
A bee is a member of a swarm
A book is a member of a
2024-07-27 22:16:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 22:18:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0333, -0.1874,  0.0304,  ...,  0.3843, -0.1772, -0.0743],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9668, -2.8184,  0.5806,  ..., -0.4927, -3.1328, -2.1445],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0422,  0.0034, -0.0010,  ...,  0.0090, -0.0216,  0.0220],
        [-0.0090,  0.0502,  0.0119,  ...,  0.0259, -0.0132,  0.0019],
        [ 0.0072, -0.0073,  0.0462,  ..., -0.0137,  0.0031,  0.0030],
        ...,
        [ 0.0190,  0.0083, -0.0246,  ...,  0.0679, -0.0082, -0.0339],
        [-0.0077,  0.0137, -0.0080,  ...,  0.0011,  0.0471, -0.0069],
        [-0.0080,  0.0068,  0.0149,  ..., -0.0135, -0.0243,  0.0483]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.3594, -2.9590,  0.6338,  ..., -0.2703, -2.8789, -1.8809]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 22:18:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A employee is a member of a staff
A kitten is a member of a litter
A citizen is a member of a citizenry
A calf is a member of a cattle
A member is a member of a club
A person is a member of a society
A bee is a member of a swarm
A book is a member of a
2024-07-27 22:18:47 root INFO     [order_1_approx] starting weight calculation for A bee is a member of a swarm
A member is a member of a club
A employee is a member of a staff
A person is a member of a society
A calf is a member of a cattle
A book is a member of a library
A citizen is a member of a citizenry
A kitten is a member of a
2024-07-27 22:18:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 22:21:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2361,  0.0146,  0.0649,  ...,  0.4155, -0.5693,  0.2200],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1289, -2.0273, -0.9312,  ..., -3.2852, -1.0605, -2.0684],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0226, -0.0027,  0.0121,  ...,  0.0153, -0.0265,  0.0267],
        [-0.0022,  0.0556,  0.0107,  ...,  0.0037,  0.0102, -0.0137],
        [-0.0062, -0.0065,  0.0686,  ..., -0.0054, -0.0278, -0.0025],
        ...,
        [-0.0034,  0.0002,  0.0005,  ...,  0.0521,  0.0222, -0.0124],
        [ 0.0149,  0.0085, -0.0166,  ...,  0.0102,  0.0297, -0.0189],
        [-0.0201, -0.0146, -0.0045,  ..., -0.0248, -0.0118,  0.0523]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.5938, -2.1367, -0.8672,  ..., -3.4609, -1.5713, -1.6475]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 22:21:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A bee is a member of a swarm
A member is a member of a club
A employee is a member of a staff
A person is a member of a society
A calf is a member of a cattle
A book is a member of a library
A citizen is a member of a citizenry
A kitten is a member of a
2024-07-27 22:21:09 root INFO     [order_1_approx] starting weight calculation for A kitten is a member of a litter
A book is a member of a library
A member is a member of a club
A citizen is a member of a citizenry
A employee is a member of a staff
A person is a member of a society
A calf is a member of a cattle
A bee is a member of a
2024-07-27 22:21:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 22:23:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7720, -0.1658, -0.0240,  ...,  0.1099, -0.2705, -0.2051],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1797, -2.2246,  2.8574,  ..., -2.3770, -1.6816, -0.3379],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0425, -0.0026,  0.0060,  ...,  0.0170, -0.0279,  0.0122],
        [-0.0185,  0.0502,  0.0114,  ..., -0.0042, -0.0094,  0.0016],
        [-0.0089,  0.0186,  0.0513,  ..., -0.0178, -0.0298, -0.0041],
        ...,
        [-0.0093, -0.0017,  0.0108,  ...,  0.0599,  0.0175, -0.0128],
        [-0.0019, -0.0030,  0.0027,  ...,  0.0046,  0.0392, -0.0032],
        [ 0.0052, -0.0168, -0.0110,  ..., -0.0090, -0.0186,  0.0594]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.2109, -2.2461,  2.6895,  ..., -2.2617, -1.5879, -0.1042]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 22:23:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A kitten is a member of a litter
A book is a member of a library
A member is a member of a club
A citizen is a member of a citizenry
A employee is a member of a staff
A person is a member of a society
A calf is a member of a cattle
A bee is a member of a
2024-07-27 22:23:32 root INFO     [order_1_approx] starting weight calculation for A calf is a member of a cattle
A book is a member of a library
A member is a member of a club
A person is a member of a society
A bee is a member of a swarm
A kitten is a member of a litter
A employee is a member of a staff
A citizen is a member of a
2024-07-27 22:23:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 22:25:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5679,  0.2949, -0.5703,  ..., -0.1799, -0.2207,  0.1606],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9268, -4.8008,  2.4551,  ..., -4.6797,  0.5293, -1.2441],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.4641e-02, -4.0474e-03,  2.9049e-03,  ...,  3.8795e-03,
         -3.8986e-03, -8.5115e-04],
        [ 2.6207e-03,  1.1284e-02,  2.8572e-03,  ..., -2.7046e-03,
          4.9210e-03, -9.8877e-03],
        [-1.9073e-05, -4.0359e-03,  7.6714e-03,  ..., -2.8305e-03,
          2.5063e-03,  2.2049e-03],
        ...,
        [ 4.6387e-03,  5.2147e-03,  2.9793e-03,  ...,  1.0841e-02,
          3.9520e-03, -1.0193e-02],
        [-4.8904e-03,  9.6273e-04, -7.4005e-03,  ...,  4.2152e-03,
          1.3618e-02,  5.2757e-03],
        [ 1.1269e-02, -2.0180e-03, -6.9523e-04,  ..., -3.0060e-03,
          6.7825e-03,  9.3536e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9502, -4.6875,  2.4707,  ..., -4.6211,  0.4714, -1.1963]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 22:25:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A calf is a member of a cattle
A book is a member of a library
A member is a member of a club
A person is a member of a society
A bee is a member of a swarm
A kitten is a member of a litter
A employee is a member of a staff
A citizen is a member of a
2024-07-27 22:25:55 root INFO     [order_1_approx] starting weight calculation for A citizen is a member of a citizenry
A employee is a member of a staff
A kitten is a member of a litter
A person is a member of a society
A book is a member of a library
A member is a member of a club
A bee is a member of a swarm
A calf is a member of a
2024-07-27 22:25:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 22:28:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5166, -0.1873,  0.4358,  ..., -0.1484, -0.4375,  0.4460],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.2969, -0.5098,  0.8335,  ..., -2.4629, -0.5977, -0.9526],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.9459e-02,  5.0697e-03,  1.9165e-02,  ...,  3.7632e-03,
         -2.7481e-02, -1.9211e-02],
        [ 1.8814e-02,  5.0323e-02, -1.2009e-02,  ...,  1.6968e-02,
          1.5480e-02, -1.9470e-02],
        [ 1.0300e-04, -1.1490e-02,  3.5461e-02,  ...,  2.2202e-03,
         -2.0782e-02, -6.0501e-03],
        ...,
        [ 2.8076e-03,  4.9286e-03,  5.6114e-03,  ...,  5.7831e-02,
          2.9617e-02, -1.4198e-02],
        [ 7.2823e-03,  5.9586e-03,  3.2425e-05,  ...,  2.2552e-02,
          6.2805e-02, -1.4824e-02],
        [ 2.2888e-05,  5.2109e-03, -5.4321e-03,  ..., -2.0248e-02,
          1.8730e-03,  6.1676e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.5000, -0.7295,  0.9209,  ..., -2.4941, -0.7285, -1.3633]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 22:28:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A citizen is a member of a citizenry
A employee is a member of a staff
A kitten is a member of a litter
A person is a member of a society
A book is a member of a library
A member is a member of a club
A bee is a member of a swarm
A calf is a member of a
2024-07-27 22:28:17 root INFO     [order_1_approx] starting weight calculation for A citizen is a member of a citizenry
A calf is a member of a cattle
A book is a member of a library
A bee is a member of a swarm
A person is a member of a society
A member is a member of a club
A kitten is a member of a litter
A employee is a member of a
2024-07-27 22:28:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 22:30:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3901,  0.2128, -0.6270,  ...,  0.1229, -0.0876, -0.0949],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8711, -5.2578,  4.5781,  ..., -3.7305,  1.3281, -3.0742],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0431, -0.0032,  0.0091,  ...,  0.0277,  0.0067,  0.0199],
        [-0.0068,  0.0464,  0.0169,  ...,  0.0140, -0.0053,  0.0006],
        [ 0.0100, -0.0062,  0.0595,  ...,  0.0049,  0.0209,  0.0248],
        ...,
        [-0.0090,  0.0114,  0.0093,  ...,  0.0453,  0.0165,  0.0156],
        [-0.0172,  0.0079, -0.0022,  ..., -0.0008,  0.0390,  0.0037],
        [-0.0017, -0.0177, -0.0208,  ..., -0.0021, -0.0176,  0.0566]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3584, -5.8320,  4.5898,  ..., -3.4473,  1.3984, -3.0703]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 22:30:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A citizen is a member of a citizenry
A calf is a member of a cattle
A book is a member of a library
A bee is a member of a swarm
A person is a member of a society
A member is a member of a club
A kitten is a member of a litter
A employee is a member of a
2024-07-27 22:30:39 root INFO     [order_1_approx] starting weight calculation for A calf is a member of a cattle
A person is a member of a society
A bee is a member of a swarm
A kitten is a member of a litter
A citizen is a member of a citizenry
A book is a member of a library
A employee is a member of a staff
A member is a member of a
2024-07-27 22:30:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 22:33:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6738, -0.3511, -0.2898,  ...,  0.3408,  0.4507, -0.2837],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5088, -2.2305,  2.9160,  ..., -2.3945,  1.0859, -0.6240],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0057,  0.0073, -0.0040,  ..., -0.0033, -0.0025, -0.0017],
        [-0.0017,  0.0064,  0.0080,  ..., -0.0002, -0.0025, -0.0097],
        [ 0.0018,  0.0052,  0.0034,  ..., -0.0025, -0.0039, -0.0025],
        ...,
        [ 0.0018,  0.0006,  0.0043,  ...,  0.0140,  0.0015, -0.0009],
        [ 0.0008,  0.0007, -0.0012,  ..., -0.0047,  0.0170,  0.0039],
        [ 0.0068, -0.0056, -0.0017,  ...,  0.0057,  0.0012,  0.0065]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4795, -2.2207,  2.8711,  ..., -2.5000,  1.0645, -0.7471]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 22:33:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A calf is a member of a cattle
A person is a member of a society
A bee is a member of a swarm
A kitten is a member of a litter
A citizen is a member of a citizenry
A book is a member of a library
A employee is a member of a staff
A member is a member of a
2024-07-27 22:33:01 root INFO     total operator prediction time: 1134.249591588974 seconds
2024-07-27 22:33:01 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on antonyms - binary
2024-07-27 22:33:01 root INFO     building operator antonyms - binary
2024-07-27 22:33:01 root INFO     [order_1_approx] starting weight calculation for The opposite of dive is emerge
The opposite of mortal is immortal
The opposite of interior is exterior
The opposite of rise is sink
The opposite of west is east
The opposite of inside is outside
The opposite of down is up
The opposite of climb is
2024-07-27 22:33:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 22:35:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1400, -0.0572,  0.4585,  ..., -0.3774, -0.6729,  0.1843],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4414, -1.1689,  1.9316,  ..., -0.6694, -3.8145, -1.5508],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0394,  0.0083, -0.0122,  ...,  0.0179, -0.0052, -0.0108],
        [-0.0008,  0.0390, -0.0144,  ...,  0.0049, -0.0079, -0.0016],
        [-0.0021, -0.0119,  0.0189,  ..., -0.0096, -0.0017,  0.0086],
        ...,
        [ 0.0032,  0.0193, -0.0070,  ...,  0.0163,  0.0065, -0.0090],
        [-0.0112,  0.0098,  0.0105,  ...,  0.0156,  0.0291,  0.0259],
        [ 0.0082,  0.0130,  0.0107,  ..., -0.0289, -0.0154,  0.0152]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1211, -1.2002,  1.7471,  ..., -0.6509, -3.8711, -1.6104]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 22:35:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of dive is emerge
The opposite of mortal is immortal
The opposite of interior is exterior
The opposite of rise is sink
The opposite of west is east
The opposite of inside is outside
The opposite of down is up
The opposite of climb is
2024-07-27 22:35:22 root INFO     [order_1_approx] starting weight calculation for The opposite of inside is outside
The opposite of climb is descend
The opposite of rise is sink
The opposite of dive is emerge
The opposite of mortal is immortal
The opposite of down is up
The opposite of west is east
The opposite of interior is
2024-07-27 22:35:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 22:37:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0859, -0.3069,  0.0089,  ..., -0.2974,  0.0756,  0.3979],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1221, -2.5234,  4.0703,  ..., -1.7539, -1.9473, -2.2715],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0693, -0.0040, -0.0098,  ..., -0.0040, -0.0461, -0.0257],
        [ 0.0181,  0.0852, -0.0148,  ...,  0.0006,  0.0161, -0.0037],
        [-0.0204, -0.0218,  0.0363,  ..., -0.0170, -0.0384,  0.0116],
        ...,
        [ 0.0224,  0.0094,  0.0045,  ...,  0.0710,  0.0534, -0.0264],
        [ 0.0333,  0.0246, -0.0085,  ...,  0.0282,  0.0718,  0.0207],
        [-0.0023,  0.0038, -0.0326,  ...,  0.0299, -0.0011,  0.0658]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5391, -2.5332,  3.6719,  ..., -1.3945, -2.2812, -2.1934]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 22:37:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of inside is outside
The opposite of climb is descend
The opposite of rise is sink
The opposite of dive is emerge
The opposite of mortal is immortal
The opposite of down is up
The opposite of west is east
The opposite of interior is
2024-07-27 22:37:43 root INFO     [order_1_approx] starting weight calculation for The opposite of climb is descend
The opposite of interior is exterior
The opposite of west is east
The opposite of inside is outside
The opposite of dive is emerge
The opposite of down is up
The opposite of mortal is immortal
The opposite of rise is
2024-07-27 22:37:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 22:40:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1377, -0.3403, -0.1925,  ...,  0.0397, -0.2949,  0.0509],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3281, -0.9453,  1.7500,  ..., -1.6465, -3.5430, -2.7461],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0501, -0.0097,  0.0010,  ...,  0.0125, -0.0120, -0.0095],
        [-0.0211,  0.0481, -0.0244,  ...,  0.0014,  0.0274, -0.0121],
        [-0.0288, -0.0192,  0.0467,  ..., -0.0022, -0.0175, -0.0191],
        ...,
        [-0.0061,  0.0003, -0.0040,  ...,  0.0453,  0.0292, -0.0064],
        [-0.0115,  0.0076, -0.0035,  ..., -0.0199,  0.0389,  0.0225],
        [ 0.0123,  0.0022,  0.0185,  ..., -0.0060, -0.0162,  0.0348]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2109, -1.1123,  2.1562,  ..., -1.9316, -4.1094, -2.6133]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 22:40:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of climb is descend
The opposite of interior is exterior
The opposite of west is east
The opposite of inside is outside
The opposite of dive is emerge
The opposite of down is up
The opposite of mortal is immortal
The opposite of rise is
2024-07-27 22:40:06 root INFO     [order_1_approx] starting weight calculation for The opposite of dive is emerge
The opposite of climb is descend
The opposite of west is east
The opposite of interior is exterior
The opposite of mortal is immortal
The opposite of inside is outside
The opposite of rise is sink
The opposite of down is
2024-07-27 22:40:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 22:42:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1560,  0.0482,  0.1212,  ..., -0.3206, -0.3584, -0.0031],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7725, -5.2891,  1.4062,  ...,  0.9746, -0.2705, -3.0898],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0393, -0.0204,  0.0076,  ..., -0.0104, -0.0283,  0.0084],
        [-0.0134,  0.0635, -0.0168,  ...,  0.0036,  0.0123, -0.0006],
        [-0.0222,  0.0008,  0.0134,  ..., -0.0143, -0.0037, -0.0019],
        ...,
        [ 0.0166, -0.0019, -0.0078,  ...,  0.0397,  0.0172, -0.0001],
        [ 0.0034,  0.0075,  0.0169,  ...,  0.0215,  0.0623,  0.0081],
        [ 0.0013,  0.0028,  0.0009,  ..., -0.0086, -0.0234, -0.0040]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6865, -4.6211,  1.1875,  ...,  0.5825, -1.0195, -2.4102]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 22:42:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of dive is emerge
The opposite of climb is descend
The opposite of west is east
The opposite of interior is exterior
The opposite of mortal is immortal
The opposite of inside is outside
The opposite of rise is sink
The opposite of down is
2024-07-27 22:42:27 root INFO     [order_1_approx] starting weight calculation for The opposite of down is up
The opposite of climb is descend
The opposite of dive is emerge
The opposite of mortal is immortal
The opposite of rise is sink
The opposite of interior is exterior
The opposite of west is east
The opposite of inside is
2024-07-27 22:42:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 22:44:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0762, -0.2939, -0.2048,  ..., -0.3320,  0.0712,  0.0769],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0039, -4.1133,  3.6543,  ..., -0.9253,  1.4980, -1.1172],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0466, -0.0163,  0.0037,  ...,  0.0138, -0.0052, -0.0287],
        [-0.0020,  0.0702, -0.0162,  ...,  0.0318,  0.0077,  0.0159],
        [-0.0292, -0.0134,  0.0232,  ..., -0.0361, -0.0414,  0.0063],
        ...,
        [-0.0007,  0.0119, -0.0151,  ...,  0.0679,  0.0266, -0.0085],
        [-0.0305,  0.0244, -0.0011,  ...,  0.0180,  0.0627,  0.0195],
        [-0.0009, -0.0204,  0.0066,  ..., -0.0047, -0.0207,  0.0449]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9980, -3.5879,  3.4863,  ..., -1.2422,  0.6484, -1.4268]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 22:44:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of down is up
The opposite of climb is descend
The opposite of dive is emerge
The opposite of mortal is immortal
The opposite of rise is sink
The opposite of interior is exterior
The opposite of west is east
The opposite of inside is
2024-07-27 22:44:48 root INFO     [order_1_approx] starting weight calculation for The opposite of inside is outside
The opposite of rise is sink
The opposite of down is up
The opposite of climb is descend
The opposite of west is east
The opposite of interior is exterior
The opposite of mortal is immortal
The opposite of dive is
2024-07-27 22:44:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 22:47:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0175, -0.0249,  0.0089,  ...,  0.1080, -0.2754, -0.0807],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2344, -0.1777, -0.5449,  ...,  2.2148, -2.9863,  2.1367],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0670, -0.0344, -0.0007,  ...,  0.0435,  0.0045,  0.0060],
        [ 0.0068,  0.0547, -0.0174,  ...,  0.0264, -0.0003,  0.0158],
        [ 0.0064, -0.0043,  0.0594,  ..., -0.0160, -0.0374, -0.0257],
        ...,
        [ 0.0070,  0.0171,  0.0039,  ...,  0.0315,  0.0040,  0.0199],
        [-0.0037,  0.0044,  0.0257,  ..., -0.0075,  0.0421,  0.0327],
        [ 0.0118,  0.0105,  0.0206,  ..., -0.0346,  0.0068,  0.0439]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4131, -0.0895, -0.8105,  ...,  1.5938, -3.3457,  1.7656]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 22:47:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of inside is outside
The opposite of rise is sink
The opposite of down is up
The opposite of climb is descend
The opposite of west is east
The opposite of interior is exterior
The opposite of mortal is immortal
The opposite of dive is
2024-07-27 22:47:09 root INFO     [order_1_approx] starting weight calculation for The opposite of west is east
The opposite of dive is emerge
The opposite of inside is outside
The opposite of interior is exterior
The opposite of rise is sink
The opposite of climb is descend
The opposite of down is up
The opposite of mortal is
2024-07-27 22:47:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 22:49:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1691,  0.1367, -0.1063,  ..., -0.2683, -0.4312,  0.2061],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9736, -3.2266,  0.7500,  ..., -3.4375, -4.6055, -3.1562],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0443,  0.0088,  0.0130,  ..., -0.0116, -0.0042, -0.0202],
        [ 0.0219,  0.0199, -0.0043,  ...,  0.0085, -0.0288, -0.0212],
        [ 0.0011, -0.0168,  0.0403,  ..., -0.0078,  0.0095,  0.0198],
        ...,
        [ 0.0111,  0.0145,  0.0023,  ..., -0.0149, -0.0238, -0.0262],
        [ 0.0069,  0.0058,  0.0439,  ...,  0.0076,  0.0289,  0.0096],
        [ 0.0115,  0.0113, -0.0006,  ..., -0.0212, -0.0249, -0.0040]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7285, -2.8223,  0.2334,  ..., -2.9688, -4.9922, -3.0371]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 22:49:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of west is east
The opposite of dive is emerge
The opposite of inside is outside
The opposite of interior is exterior
The opposite of rise is sink
The opposite of climb is descend
The opposite of down is up
The opposite of mortal is
2024-07-27 22:49:30 root INFO     [order_1_approx] starting weight calculation for The opposite of inside is outside
The opposite of mortal is immortal
The opposite of interior is exterior
The opposite of rise is sink
The opposite of climb is descend
The opposite of dive is emerge
The opposite of down is up
The opposite of west is
2024-07-27 22:49:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 22:51:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1125,  0.2302,  0.1216,  ...,  0.1387,  0.2429, -0.2529],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0801, -3.1895, -1.5273,  ..., -0.5444,  0.8364, -2.0547],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0798, -0.0212, -0.0023,  ...,  0.0233,  0.0112, -0.0101],
        [ 0.0181,  0.0584,  0.0119,  ..., -0.0043,  0.0141, -0.0050],
        [-0.0070, -0.0151,  0.0047,  ..., -0.0144, -0.0420,  0.0121],
        ...,
        [ 0.0206, -0.0133,  0.0174,  ...,  0.0527,  0.0043, -0.0211],
        [ 0.0012, -0.0321,  0.0116,  ...,  0.0192,  0.0639,  0.0271],
        [ 0.0244, -0.0034,  0.0135,  ...,  0.0124, -0.0019,  0.0114]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6426, -2.7402, -2.0977,  ..., -0.4241,  1.3838, -1.8320]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 22:51:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of inside is outside
The opposite of mortal is immortal
The opposite of interior is exterior
The opposite of rise is sink
The opposite of climb is descend
The opposite of dive is emerge
The opposite of down is up
The opposite of west is
2024-07-27 22:51:52 root INFO     total operator prediction time: 1130.8904836177826 seconds
2024-07-27 22:51:52 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hyponyms - misc
2024-07-27 22:51:52 root INFO     building operator hyponyms - misc
2024-07-27 22:51:52 root INFO     [order_1_approx] starting weight calculation for A more specific term for a car is limousine
A more specific term for a cookware is pot
A more specific term for a color is white
A more specific term for a dress is gown
A more specific term for a bed is bunk
A more specific term for a shelf is bookshelf
A more specific term for a trousers is jeans
A more specific term for a mixer is
2024-07-27 22:51:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 22:54:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-5.8228e-02,  5.0293e-02, -4.4678e-02,  ...,  5.7227e-01,
        -6.7334e-01, -1.2207e-04], device='cuda:1', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5303, -5.1133, -0.7954,  ...,  0.4434, -3.0684, -0.0996],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.2876e-02,  1.9989e-02, -1.4923e-02,  ...,  3.8239e-02,
          5.5885e-04, -1.1894e-02],
        [ 1.0727e-02,  8.0811e-02,  1.1902e-02,  ..., -6.7177e-03,
         -8.3447e-05,  4.6577e-03],
        [-1.1726e-02, -2.6443e-02,  8.3374e-02,  ..., -1.5320e-02,
          2.5879e-02,  2.9739e-02],
        ...,
        [ 3.2715e-02,  3.0670e-02, -6.6795e-03,  ...,  8.5938e-02,
         -3.7140e-02, -1.0529e-03],
        [-3.8025e-02, -1.3222e-02, -1.9073e-02,  ...,  1.7441e-02,
          9.2468e-02, -3.2257e-02],
        [ 9.0599e-04,  2.2690e-02,  1.8082e-02,  ..., -2.6245e-02,
         -2.7817e-02,  5.7220e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5605, -5.4375, -0.6929,  ...,  0.5703, -2.4512, -0.3276]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 22:54:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a car is limousine
A more specific term for a cookware is pot
A more specific term for a color is white
A more specific term for a dress is gown
A more specific term for a bed is bunk
A more specific term for a shelf is bookshelf
A more specific term for a trousers is jeans
A more specific term for a mixer is
2024-07-27 22:54:11 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a trousers is jeans
A more specific term for a shelf is bookshelf
A more specific term for a car is limousine
A more specific term for a cookware is pot
A more specific term for a dress is gown
A more specific term for a mixer is blender
A more specific term for a color is
2024-07-27 22:54:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 22:56:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1428, -0.4380, -0.2588,  ...,  0.4102, -0.1674, -0.2363],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.5342, -3.1660,  0.1680,  ...,  0.2720, -4.0117,  0.3872],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.2755e-02,  2.8248e-03, -3.3073e-03,  ...,  6.9656e-03,
          4.2343e-03,  1.6464e-02],
        [ 3.7415e-02,  5.3284e-02,  1.8036e-02,  ...,  3.5248e-02,
          2.1454e-02, -1.6037e-02],
        [-3.1677e-02, -4.0436e-04,  4.7913e-02,  ..., -3.0502e-02,
         -3.5522e-02,  9.3689e-03],
        ...,
        [ 1.4282e-02,  7.8583e-03,  6.1393e-06,  ...,  6.9702e-02,
          7.2098e-03, -5.5542e-03],
        [-1.3962e-03, -5.9738e-03, -6.7101e-03,  ...,  9.5978e-03,
          4.1931e-02, -5.3864e-03],
        [ 8.4534e-03,  1.0490e-02, -1.1482e-02,  ...,  1.0315e-02,
          9.1400e-03,  4.8187e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.3281, -3.0879, -0.2273,  ...,  0.4121, -4.2578,  0.6709]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 22:56:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a bed is bunk
A more specific term for a trousers is jeans
A more specific term for a shelf is bookshelf
A more specific term for a car is limousine
A more specific term for a cookware is pot
A more specific term for a dress is gown
A more specific term for a mixer is blender
A more specific term for a color is
2024-07-27 22:56:32 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a cookware is pot
A more specific term for a dress is gown
A more specific term for a mixer is blender
A more specific term for a trousers is jeans
A more specific term for a shelf is bookshelf
A more specific term for a color is white
A more specific term for a car is
2024-07-27 22:56:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 22:58:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3252, -0.2311, -0.0809,  ...,  0.0305, -0.0896, -0.1560],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0398, -8.9375,  1.4678,  ...,  1.0156, -2.0781, -1.7012],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0489, -0.0075,  0.0054,  ..., -0.0044, -0.0077,  0.0273],
        [ 0.0048,  0.0347,  0.0177,  ...,  0.0110,  0.0197, -0.0303],
        [ 0.0120, -0.0094,  0.0486,  ..., -0.0057, -0.0149,  0.0225],
        ...,
        [ 0.0025,  0.0214, -0.0117,  ...,  0.0356,  0.0143, -0.0004],
        [-0.0082, -0.0086,  0.0056,  ..., -0.0045,  0.0369, -0.0066],
        [ 0.0173,  0.0145, -0.0149,  ..., -0.0085, -0.0012,  0.0540]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0296, -8.9297,  1.5527,  ...,  0.8970, -2.1230, -1.5156]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 22:58:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a bed is bunk
A more specific term for a cookware is pot
A more specific term for a dress is gown
A more specific term for a mixer is blender
A more specific term for a trousers is jeans
A more specific term for a shelf is bookshelf
A more specific term for a color is white
A more specific term for a car is
2024-07-27 22:58:52 root INFO     [order_1_approx] starting weight calculation for A more specific term for a trousers is jeans
A more specific term for a bed is bunk
A more specific term for a cookware is pot
A more specific term for a dress is gown
A more specific term for a car is limousine
A more specific term for a mixer is blender
A more specific term for a color is white
A more specific term for a shelf is
2024-07-27 22:58:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 23:01:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0687, -0.4285, -0.4927,  ...,  0.3867, -0.2588, -0.0079],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.6875, -4.6914,  1.9736,  ...,  3.3477, -3.0273,  1.1094],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0663,  0.0140,  0.0131,  ...,  0.0180, -0.0218, -0.0051],
        [ 0.0005,  0.0679, -0.0143,  ...,  0.0245,  0.0179, -0.0192],
        [ 0.0095, -0.0102,  0.0676,  ..., -0.0156, -0.0080,  0.0063],
        ...,
        [ 0.0191,  0.0237, -0.0047,  ...,  0.0644,  0.0029,  0.0018],
        [-0.0147,  0.0221, -0.0242,  ..., -0.0097,  0.0445,  0.0013],
        [-0.0143,  0.0200, -0.0172,  ..., -0.0007, -0.0075,  0.0506]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.9336, -5.4844,  2.3555,  ...,  3.4883, -2.5918,  1.0264]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 23:01:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a trousers is jeans
A more specific term for a bed is bunk
A more specific term for a cookware is pot
A more specific term for a dress is gown
A more specific term for a car is limousine
A more specific term for a mixer is blender
A more specific term for a color is white
A more specific term for a shelf is
2024-07-27 23:01:10 root INFO     [order_1_approx] starting weight calculation for A more specific term for a dress is gown
A more specific term for a shelf is bookshelf
A more specific term for a cookware is pot
A more specific term for a mixer is blender
A more specific term for a color is white
A more specific term for a car is limousine
A more specific term for a bed is bunk
A more specific term for a trousers is
2024-07-27 23:01:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 23:03:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0723, -0.1942, -0.4915,  ...,  0.4985, -0.5708, -0.1476],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8535, -6.8516,  0.3584,  ...,  1.8789, -0.0605,  2.0664],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.8030e-02, -1.0185e-02,  8.3694e-03,  ...,  1.0002e-02,
          6.2714e-03, -8.3084e-03],
        [-1.3962e-03,  2.5925e-02, -7.9498e-03,  ...,  1.3218e-03,
          4.5624e-03,  3.3398e-03],
        [ 3.9024e-03, -8.0032e-03,  3.0304e-02,  ..., -1.0384e-02,
         -1.9012e-02, -3.4809e-03],
        ...,
        [ 3.6774e-03, -4.1008e-05, -3.3569e-04,  ...,  4.5227e-02,
          1.2024e-02, -1.0201e-02],
        [-6.3057e-03,  2.9755e-03, -9.3994e-03,  ...,  2.0523e-03,
          3.2715e-02, -4.1084e-03],
        [ 2.4090e-03, -3.4122e-03,  5.9242e-03,  ..., -2.4624e-03,
          1.5202e-03,  2.8152e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6777, -6.5273,  0.0857,  ...,  1.9258, -0.0817,  1.9854]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 23:03:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a dress is gown
A more specific term for a shelf is bookshelf
A more specific term for a cookware is pot
A more specific term for a mixer is blender
A more specific term for a color is white
A more specific term for a car is limousine
A more specific term for a bed is bunk
A more specific term for a trousers is
2024-07-27 23:03:31 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a car is limousine
A more specific term for a color is white
A more specific term for a mixer is blender
A more specific term for a shelf is bookshelf
A more specific term for a trousers is jeans
A more specific term for a cookware is pot
A more specific term for a dress is
2024-07-27 23:03:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 23:05:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2874, -0.3096, -0.1537,  ...,  0.3118, -0.2832, -0.2239],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0645, -4.8398, -1.5215,  ...,  1.7002, -3.7363,  1.1777],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0699,  0.0049,  0.0030,  ..., -0.0129,  0.0396,  0.0097],
        [-0.0273,  0.0357, -0.0002,  ..., -0.0040, -0.0141, -0.0125],
        [ 0.0256, -0.0169,  0.0464,  ..., -0.0216, -0.0089,  0.0029],
        ...,
        [-0.0206,  0.0143, -0.0007,  ...,  0.0467,  0.0268, -0.0249],
        [-0.0177, -0.0075, -0.0171,  ...,  0.0081,  0.0366, -0.0261],
        [ 0.0067, -0.0015,  0.0020,  ..., -0.0162, -0.0118,  0.0313]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2681, -5.0195, -1.4346,  ...,  2.0059, -3.7363,  1.0654]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 23:05:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a bed is bunk
A more specific term for a car is limousine
A more specific term for a color is white
A more specific term for a mixer is blender
A more specific term for a shelf is bookshelf
A more specific term for a trousers is jeans
A more specific term for a cookware is pot
A more specific term for a dress is
2024-07-27 23:05:53 root INFO     [order_1_approx] starting weight calculation for A more specific term for a car is limousine
A more specific term for a color is white
A more specific term for a mixer is blender
A more specific term for a bed is bunk
A more specific term for a trousers is jeans
A more specific term for a dress is gown
A more specific term for a shelf is bookshelf
A more specific term for a cookware is
2024-07-27 23:05:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 23:08:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0869, -0.2134, -0.0320,  ...,  0.2219, -0.1707, -0.4685],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7598, -2.8711,  2.6191,  ..., -3.0469, -3.2148, -1.0693],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.0751e-02,  5.8136e-03,  1.5137e-02,  ...,  3.4790e-03,
          5.0392e-03,  5.6763e-03],
        [ 1.0700e-03,  5.7343e-02, -7.7248e-03,  ..., -9.9564e-03,
         -2.6073e-03, -4.4594e-03],
        [ 4.8294e-03, -3.4821e-02,  5.1300e-02,  ...,  9.7656e-03,
          1.2207e-02, -6.7291e-03],
        ...,
        [ 7.1526e-03,  5.4054e-03, -2.0390e-03,  ...,  4.2236e-02,
          2.9278e-03,  2.5597e-03],
        [-2.6443e-02, -2.1225e-02, -1.2512e-03,  ..., -1.1322e-02,
          3.4882e-02, -1.1032e-02],
        [-5.4026e-04, -8.5831e-06,  1.7529e-03,  ..., -3.8788e-02,
         -1.2283e-03,  5.2246e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8320, -3.0957,  2.6172,  ..., -2.7969, -2.7715, -0.6914]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 23:08:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a car is limousine
A more specific term for a color is white
A more specific term for a mixer is blender
A more specific term for a bed is bunk
A more specific term for a trousers is jeans
A more specific term for a dress is gown
A more specific term for a shelf is bookshelf
A more specific term for a cookware is
2024-07-27 23:08:14 root INFO     [order_1_approx] starting weight calculation for A more specific term for a car is limousine
A more specific term for a cookware is pot
A more specific term for a color is white
A more specific term for a shelf is bookshelf
A more specific term for a dress is gown
A more specific term for a trousers is jeans
A more specific term for a mixer is blender
A more specific term for a bed is
2024-07-27 23:08:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 23:10:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4675, -0.1387, -0.1442,  ...,  0.0459, -0.5869, -0.1685],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.2725e-03, -4.9766e+00,  1.9980e+00,  ...,  6.8213e-01,
         7.2852e-01,  1.2148e+00], device='cuda:1', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.7444e-02,  1.0529e-02,  9.8953e-03,  ...,  1.4572e-02,
         -6.4163e-03,  9.1400e-03],
        [-1.4877e-02,  3.7659e-02,  9.2697e-03,  ...,  1.0643e-02,
          2.7237e-02, -3.1281e-04],
        [-1.3475e-03, -1.4168e-02,  5.6580e-02,  ..., -5.4359e-03,
         -5.1842e-03, -1.7334e-02],
        ...,
        [-1.7357e-04,  1.6815e-02, -2.1027e-02,  ...,  4.7516e-02,
         -4.3106e-04,  6.4850e-05],
        [-1.4740e-02,  7.5264e-03, -2.6123e-02,  ..., -3.1757e-03,
          4.2480e-02, -6.6833e-03],
        [-1.5564e-03, -8.3008e-03,  4.1656e-03,  ..., -2.0844e-02,
         -1.3031e-02,  3.8513e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1783, -5.2188,  1.8047,  ...,  0.8154,  0.5181,  1.1572]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 23:10:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a car is limousine
A more specific term for a cookware is pot
A more specific term for a color is white
A more specific term for a shelf is bookshelf
A more specific term for a dress is gown
A more specific term for a trousers is jeans
A more specific term for a mixer is blender
A more specific term for a bed is
2024-07-27 23:10:36 root INFO     total operator prediction time: 1123.824595451355 seconds
2024-07-27 23:10:36 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hypernyms - animals
2024-07-27 23:10:36 root INFO     building operator hypernyms - animals
2024-07-27 23:10:36 root INFO     [order_1_approx] starting weight calculation for The chimpanzee falls into the category of primate
The coyote falls into the category of canine
The bee falls into the category of insect
The jackal falls into the category of canine
The cow falls into the category of bovid
The triceratops falls into the category of dinosaur
The quail falls into the category of fowl
The stegosaurus falls into the category of
2024-07-27 23:10:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 23:12:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4888, -0.2952, -0.7646,  ...,  0.0627, -0.3518,  0.1252],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8882, -3.5078,  2.1426,  ..., -2.5742, -4.5781, -2.5586],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0450, -0.0086, -0.0014,  ...,  0.0136, -0.0260, -0.0076],
        [ 0.0014,  0.0272, -0.0038,  ..., -0.0038, -0.0015, -0.0161],
        [-0.0003, -0.0066,  0.0397,  ...,  0.0014, -0.0107,  0.0007],
        ...,
        [ 0.0024, -0.0064,  0.0100,  ...,  0.0609,  0.0124,  0.0010],
        [-0.0139,  0.0108,  0.0030,  ..., -0.0038,  0.0375, -0.0039],
        [ 0.0114, -0.0232,  0.0174,  ...,  0.0084, -0.0246,  0.0328]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0420, -3.2109,  1.9961,  ..., -2.5684, -4.5664, -2.5195]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 23:12:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The chimpanzee falls into the category of primate
The coyote falls into the category of canine
The bee falls into the category of insect
The jackal falls into the category of canine
The cow falls into the category of bovid
The triceratops falls into the category of dinosaur
The quail falls into the category of fowl
The stegosaurus falls into the category of
2024-07-27 23:12:58 root INFO     [order_1_approx] starting weight calculation for The cow falls into the category of bovid
The chimpanzee falls into the category of primate
The triceratops falls into the category of dinosaur
The jackal falls into the category of canine
The bee falls into the category of insect
The stegosaurus falls into the category of dinosaur
The coyote falls into the category of canine
The quail falls into the category of
2024-07-27 23:12:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 23:15:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0484, -0.3872, -0.1543,  ...,  0.5664, -0.2690, -0.0567],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1680e+00, -2.8789e+00,  3.8926e+00,  ..., -1.6357e+00,
        -6.6914e+00, -5.8594e-03], device='cuda:1', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0696,  0.0126, -0.0166,  ...,  0.0230, -0.0166, -0.0065],
        [ 0.0306,  0.0564,  0.0102,  ...,  0.0295, -0.0033, -0.0049],
        [-0.0108, -0.0209,  0.0704,  ..., -0.0138, -0.0287,  0.0173],
        ...,
        [ 0.0186, -0.0090,  0.0153,  ...,  0.0579, -0.0004,  0.0020],
        [ 0.0001, -0.0126,  0.0041,  ...,  0.0276,  0.0511, -0.0099],
        [ 0.0131, -0.0113, -0.0046,  ...,  0.0007, -0.0288,  0.0687]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5547, -2.5469,  3.2969,  ..., -1.4062, -6.5508,  0.2389]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 23:15:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The cow falls into the category of bovid
The chimpanzee falls into the category of primate
The triceratops falls into the category of dinosaur
The jackal falls into the category of canine
The bee falls into the category of insect
The stegosaurus falls into the category of dinosaur
The coyote falls into the category of canine
The quail falls into the category of
2024-07-27 23:15:18 root INFO     [order_1_approx] starting weight calculation for The jackal falls into the category of canine
The coyote falls into the category of canine
The bee falls into the category of insect
The triceratops falls into the category of dinosaur
The quail falls into the category of fowl
The chimpanzee falls into the category of primate
The stegosaurus falls into the category of dinosaur
The cow falls into the category of
2024-07-27 23:15:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 23:17:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1099, -0.1273,  0.0634,  ...,  0.3201, -0.1145,  0.1541],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7441, -5.0508,  3.6992,  ..., -1.0098, -5.7656,  0.2310],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0421,  0.0081,  0.0070,  ..., -0.0024, -0.0084, -0.0012],
        [ 0.0082,  0.0287,  0.0175,  ...,  0.0080, -0.0109, -0.0164],
        [ 0.0059,  0.0192,  0.0238,  ...,  0.0036,  0.0074,  0.0056],
        ...,
        [ 0.0120, -0.0095,  0.0147,  ...,  0.0464,  0.0113,  0.0096],
        [-0.0165, -0.0027, -0.0156,  ...,  0.0009,  0.0388,  0.0033],
        [ 0.0043, -0.0133,  0.0006,  ..., -0.0146, -0.0010,  0.0545]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8105, -4.8047,  2.9863,  ..., -0.8047, -5.9102,  0.5176]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 23:17:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The jackal falls into the category of canine
The coyote falls into the category of canine
The bee falls into the category of insect
The triceratops falls into the category of dinosaur
The quail falls into the category of fowl
The chimpanzee falls into the category of primate
The stegosaurus falls into the category of dinosaur
The cow falls into the category of
2024-07-27 23:17:38 root INFO     [order_1_approx] starting weight calculation for The chimpanzee falls into the category of primate
The quail falls into the category of fowl
The jackal falls into the category of canine
The cow falls into the category of bovid
The coyote falls into the category of canine
The stegosaurus falls into the category of dinosaur
The bee falls into the category of insect
The triceratops falls into the category of
2024-07-27 23:17:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 23:19:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3979, -0.2783, -0.5405,  ...,  0.4517, -0.5918,  0.3115],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6797, -3.3906,  0.6064,  ..., -0.8115, -4.6562, -2.4141],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0471, -0.0104, -0.0032,  ...,  0.0095, -0.0228, -0.0098],
        [ 0.0156,  0.0347,  0.0016,  ...,  0.0068,  0.0070, -0.0225],
        [ 0.0022,  0.0061,  0.0428,  ..., -0.0108, -0.0126,  0.0096],
        ...,
        [ 0.0038, -0.0054,  0.0217,  ...,  0.0750, -0.0003, -0.0053],
        [-0.0078,  0.0100,  0.0104,  ...,  0.0015,  0.0520, -0.0002],
        [ 0.0129, -0.0208,  0.0068,  ...,  0.0112, -0.0266,  0.0287]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6299, -3.0605,  0.3840,  ..., -0.5713, -4.8281, -2.2539]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 23:19:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The chimpanzee falls into the category of primate
The quail falls into the category of fowl
The jackal falls into the category of canine
The cow falls into the category of bovid
The coyote falls into the category of canine
The stegosaurus falls into the category of dinosaur
The bee falls into the category of insect
The triceratops falls into the category of
2024-07-27 23:19:57 root INFO     [order_1_approx] starting weight calculation for The triceratops falls into the category of dinosaur
The quail falls into the category of fowl
The stegosaurus falls into the category of dinosaur
The cow falls into the category of bovid
The chimpanzee falls into the category of primate
The coyote falls into the category of canine
The jackal falls into the category of canine
The bee falls into the category of
2024-07-27 23:19:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 23:22:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2306, -0.3330,  0.0776,  ...,  0.4009, -0.2173, -0.0907],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1836, -4.2539,  2.9004,  ..., -2.3164, -4.4922, -0.9482],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0327, -0.0067, -0.0166,  ...,  0.0141,  0.0005,  0.0054],
        [ 0.0095,  0.0128,  0.0154,  ..., -0.0060,  0.0042, -0.0225],
        [-0.0151,  0.0214,  0.0475,  ...,  0.0009, -0.0223,  0.0166],
        ...,
        [ 0.0040,  0.0107,  0.0147,  ...,  0.0303,  0.0204,  0.0052],
        [-0.0337,  0.0148, -0.0063,  ...,  0.0041,  0.0488,  0.0074],
        [ 0.0201, -0.0268,  0.0011,  ..., -0.0090, -0.0024,  0.0359]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2773, -3.9258,  1.7285,  ..., -1.8389, -4.8984, -0.3101]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 23:22:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The triceratops falls into the category of dinosaur
The quail falls into the category of fowl
The stegosaurus falls into the category of dinosaur
The cow falls into the category of bovid
The chimpanzee falls into the category of primate
The coyote falls into the category of canine
The jackal falls into the category of canine
The bee falls into the category of
2024-07-27 23:22:17 root INFO     [order_1_approx] starting weight calculation for The chimpanzee falls into the category of primate
The quail falls into the category of fowl
The jackal falls into the category of canine
The stegosaurus falls into the category of dinosaur
The bee falls into the category of insect
The triceratops falls into the category of dinosaur
The cow falls into the category of bovid
The coyote falls into the category of
2024-07-27 23:22:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 23:24:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1422,  0.0565, -0.1143,  ...,  0.4763, -0.5361, -0.1547],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.3740, -5.3516,  1.3428,  ..., -3.3203, -5.8047,  1.0371],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0450,  0.0114, -0.0023,  ..., -0.0112, -0.0278,  0.0015],
        [ 0.0098,  0.0129,  0.0293,  ...,  0.0068,  0.0002, -0.0008],
        [-0.0045, -0.0018,  0.0368,  ..., -0.0110, -0.0068, -0.0114],
        ...,
        [-0.0007,  0.0073, -0.0042,  ...,  0.0128,  0.0278,  0.0035],
        [-0.0099, -0.0192,  0.0059,  ...,  0.0136,  0.0270, -0.0006],
        [-0.0040, -0.0098,  0.0020,  ..., -0.0038, -0.0129,  0.0225]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.4346, -5.7070,  1.1914,  ..., -3.1426, -6.1484,  0.9448]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 23:24:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The chimpanzee falls into the category of primate
The quail falls into the category of fowl
The jackal falls into the category of canine
The stegosaurus falls into the category of dinosaur
The bee falls into the category of insect
The triceratops falls into the category of dinosaur
The cow falls into the category of bovid
The coyote falls into the category of
2024-07-27 23:24:36 root INFO     [order_1_approx] starting weight calculation for The cow falls into the category of bovid
The coyote falls into the category of canine
The quail falls into the category of fowl
The bee falls into the category of insect
The stegosaurus falls into the category of dinosaur
The jackal falls into the category of canine
The triceratops falls into the category of dinosaur
The chimpanzee falls into the category of
2024-07-27 23:24:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 23:26:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3140, -0.3411, -0.1832,  ...,  0.1217, -0.3799,  0.0215],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1938, -3.9805,  1.7500,  ..., -2.9590, -8.0156,  1.0039],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0320, -0.0016,  0.0037,  ...,  0.0014, -0.0105, -0.0091],
        [ 0.0103,  0.0132,  0.0048,  ..., -0.0092,  0.0045, -0.0057],
        [-0.0134,  0.0026,  0.0196,  ..., -0.0022,  0.0056, -0.0034],
        ...,
        [ 0.0077,  0.0112,  0.0032,  ...,  0.0070,  0.0013,  0.0035],
        [-0.0041, -0.0029, -0.0023,  ..., -0.0010,  0.0196, -0.0010],
        [ 0.0096, -0.0052,  0.0032,  ..., -0.0057, -0.0059,  0.0071]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1736, -3.8516,  1.6602,  ..., -3.0332, -7.9922,  0.9619]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 23:26:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The cow falls into the category of bovid
The coyote falls into the category of canine
The quail falls into the category of fowl
The bee falls into the category of insect
The stegosaurus falls into the category of dinosaur
The jackal falls into the category of canine
The triceratops falls into the category of dinosaur
The chimpanzee falls into the category of
2024-07-27 23:26:56 root INFO     [order_1_approx] starting weight calculation for The stegosaurus falls into the category of dinosaur
The bee falls into the category of insect
The triceratops falls into the category of dinosaur
The cow falls into the category of bovid
The chimpanzee falls into the category of primate
The coyote falls into the category of canine
The quail falls into the category of fowl
The jackal falls into the category of
2024-07-27 23:26:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 23:29:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0812,  0.0579, -0.0393,  ...,  0.4851, -0.5850, -0.1348],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.4072, -5.4062,  1.2881,  ..., -3.6270, -6.3516,  2.2129],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0651,  0.0156, -0.0026,  ..., -0.0184, -0.0164,  0.0096],
        [ 0.0206,  0.0377,  0.0222,  ..., -0.0085,  0.0043, -0.0029],
        [ 0.0003, -0.0153,  0.0500,  ..., -0.0228,  0.0008, -0.0203],
        ...,
        [ 0.0112,  0.0148,  0.0120,  ...,  0.0413,  0.0298,  0.0114],
        [-0.0165, -0.0200, -0.0096,  ...,  0.0065,  0.0241, -0.0114],
        [ 0.0059, -0.0059, -0.0044,  ..., -0.0010,  0.0009,  0.0386]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.3379, -5.8789,  1.0156,  ..., -2.9531, -6.9805,  2.0117]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 23:29:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The stegosaurus falls into the category of dinosaur
The bee falls into the category of insect
The triceratops falls into the category of dinosaur
The cow falls into the category of bovid
The chimpanzee falls into the category of primate
The coyote falls into the category of canine
The quail falls into the category of fowl
The jackal falls into the category of
2024-07-27 23:29:16 root INFO     total operator prediction time: 1120.6324276924133 seconds
2024-07-27 23:29:16 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on synonyms - intensity
2024-07-27 23:29:16 root INFO     building operator synonyms - intensity
2024-07-27 23:29:16 root INFO     [order_1_approx] starting weight calculation for A more intense word for opposed is averse
A more intense word for want is crave
A more intense word for unhappy is miserable
A more intense word for doze is sleep
A more intense word for interesting is exciting
A more intense word for poorly is afflicted
A more intense word for hungry is starving
A more intense word for nap is
2024-07-27 23:29:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 23:31:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1671, -0.2964,  0.1932,  ...,  0.3784, -0.9668, -0.0867],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8906, -3.7129,  3.5391,  ...,  1.4053, -0.4983, -1.3311],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.8533e-02, -1.6449e-02, -1.3176e-02,  ...,  1.2924e-02,
          1.5854e-02,  4.5090e-03],
        [-1.1566e-02,  7.1960e-02, -6.8283e-03,  ..., -1.3828e-03,
         -3.1281e-04, -1.4206e-02],
        [-2.1667e-02, -2.2934e-02,  3.9154e-02,  ..., -6.9885e-03,
         -4.9591e-05, -2.0142e-02],
        ...,
        [ 5.6877e-03,  2.2369e-02,  3.3630e-02,  ...,  4.5990e-02,
          1.6861e-02, -4.6425e-03],
        [ 1.2627e-02, -3.0518e-03, -1.3863e-02,  ...,  1.8768e-02,
          5.1689e-03, -1.4526e-02],
        [ 1.7624e-03, -1.0090e-03,  1.4969e-02,  ...,  1.4656e-02,
          1.1314e-02,  3.6285e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3701, -3.4609,  3.8516,  ...,  1.2324, -1.1211, -1.5215]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 23:31:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for opposed is averse
A more intense word for want is crave
A more intense word for unhappy is miserable
A more intense word for doze is sleep
A more intense word for interesting is exciting
A more intense word for poorly is afflicted
A more intense word for hungry is starving
A more intense word for nap is
2024-07-27 23:31:37 root INFO     [order_1_approx] starting weight calculation for A more intense word for unhappy is miserable
A more intense word for want is crave
A more intense word for opposed is averse
A more intense word for interesting is exciting
A more intense word for poorly is afflicted
A more intense word for doze is sleep
A more intense word for nap is sleep
A more intense word for hungry is
2024-07-27 23:31:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 23:33:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4155, -0.4795, -0.1125,  ..., -0.1102, -0.3516,  0.4500],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1895, -3.7852,  2.4141,  ..., -0.3425, -3.4316, -0.3027],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0441,  0.0155,  0.0144,  ..., -0.0028,  0.0012, -0.0075],
        [ 0.0110,  0.0685, -0.0073,  ...,  0.0016,  0.0006, -0.0044],
        [ 0.0125,  0.0047,  0.0630,  ...,  0.0059, -0.0079, -0.0134],
        ...,
        [ 0.0229,  0.0003,  0.0043,  ...,  0.0550,  0.0061, -0.0140],
        [-0.0157,  0.0233, -0.0123,  ...,  0.0082,  0.0445, -0.0132],
        [ 0.0068, -0.0142,  0.0029,  ...,  0.0046, -0.0112,  0.0527]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2617, -3.7285,  2.2285,  ..., -0.1750, -3.1934, -0.3704]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 23:33:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for unhappy is miserable
A more intense word for want is crave
A more intense word for opposed is averse
A more intense word for interesting is exciting
A more intense word for poorly is afflicted
A more intense word for doze is sleep
A more intense word for nap is sleep
A more intense word for hungry is
2024-07-27 23:33:58 root INFO     [order_1_approx] starting weight calculation for A more intense word for interesting is exciting
A more intense word for nap is sleep
A more intense word for poorly is afflicted
A more intense word for unhappy is miserable
A more intense word for opposed is averse
A more intense word for hungry is starving
A more intense word for doze is sleep
A more intense word for want is
2024-07-27 23:33:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 23:36:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1748, -0.0448, -0.1560,  ...,  0.0889, -0.0018,  0.1809],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5977, -3.6875,  1.4629,  ..., -2.1543, -5.7734, -4.4141],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0579, -0.0189, -0.0019,  ...,  0.0040, -0.0086,  0.0046],
        [-0.0128,  0.0497, -0.0032,  ..., -0.0011, -0.0317, -0.0323],
        [ 0.0179, -0.0136,  0.0565,  ..., -0.0246, -0.0130, -0.0251],
        ...,
        [ 0.0283,  0.0201,  0.0099,  ...,  0.0515,  0.0122, -0.0162],
        [ 0.0004,  0.0024,  0.0237,  ...,  0.0018,  0.0446, -0.0302],
        [-0.0110,  0.0030, -0.0154,  ..., -0.0285, -0.0316,  0.0547]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5488, -3.5215,  1.7793,  ..., -2.0859, -5.1094, -3.5840]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 23:36:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for interesting is exciting
A more intense word for nap is sleep
A more intense word for poorly is afflicted
A more intense word for unhappy is miserable
A more intense word for opposed is averse
A more intense word for hungry is starving
A more intense word for doze is sleep
A more intense word for want is
2024-07-27 23:36:16 root INFO     [order_1_approx] starting weight calculation for A more intense word for interesting is exciting
A more intense word for hungry is starving
A more intense word for nap is sleep
A more intense word for opposed is averse
A more intense word for want is crave
A more intense word for poorly is afflicted
A more intense word for unhappy is miserable
A more intense word for doze is
2024-07-27 23:36:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 23:38:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1227, -0.3816,  0.0185,  ..., -0.1317, -0.7065, -0.0685],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.6973, -3.5664,  2.1406,  ...,  0.4727, -1.1357, -0.0547],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0812,  0.0082,  0.0015,  ...,  0.0441, -0.0309,  0.0034],
        [ 0.0198,  0.0704, -0.0025,  ...,  0.0027,  0.0171,  0.0124],
        [-0.0508, -0.0170,  0.0573,  ..., -0.0086, -0.0352, -0.0284],
        ...,
        [-0.0108,  0.0069,  0.0082,  ...,  0.0645,  0.0164, -0.0145],
        [-0.0104,  0.0036, -0.0116,  ...,  0.0085,  0.0120, -0.0293],
        [ 0.0278, -0.0123, -0.0021,  ..., -0.0006, -0.0301,  0.0508]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.4971, -3.8086,  2.4102,  ..., -0.0361, -1.1494, -0.2421]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 23:38:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for interesting is exciting
A more intense word for hungry is starving
A more intense word for nap is sleep
A more intense word for opposed is averse
A more intense word for want is crave
A more intense word for poorly is afflicted
A more intense word for unhappy is miserable
A more intense word for doze is
2024-07-27 23:38:35 root INFO     [order_1_approx] starting weight calculation for A more intense word for doze is sleep
A more intense word for hungry is starving
A more intense word for interesting is exciting
A more intense word for nap is sleep
A more intense word for want is crave
A more intense word for opposed is averse
A more intense word for poorly is afflicted
A more intense word for unhappy is
2024-07-27 23:38:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 23:40:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5215, -0.2773, -0.3162,  ..., -0.3508, -0.2062,  0.1393],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7969, -3.9473,  1.8574,  ..., -2.6836, -0.6836, -0.6602],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.8594e-02,  1.1261e-02,  2.4948e-03,  ..., -9.6970e-03,
          9.6054e-03,  2.1576e-02],
        [-8.6670e-03,  3.5614e-02, -9.9030e-03,  ..., -2.0332e-03,
          4.3068e-03, -1.9226e-02],
        [ 1.1635e-03, -3.8853e-03,  5.9937e-02,  ...,  1.3123e-03,
         -1.5457e-02, -1.1520e-02],
        ...,
        [ 1.5182e-02, -1.3084e-02, -1.0738e-03,  ...,  3.8391e-02,
         -1.3161e-02, -7.5760e-03],
        [-9.9487e-03, -2.5597e-03,  3.8147e-06,  ..., -4.5547e-03,
          4.5776e-02, -9.6207e-03],
        [-3.4866e-03, -2.0203e-02, -3.4256e-03,  ...,  2.7256e-03,
         -3.2425e-04,  4.3793e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9414, -3.7910,  1.6426,  ..., -2.4902, -0.5830, -0.9385]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 23:40:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for doze is sleep
A more intense word for hungry is starving
A more intense word for interesting is exciting
A more intense word for nap is sleep
A more intense word for want is crave
A more intense word for opposed is averse
A more intense word for poorly is afflicted
A more intense word for unhappy is
2024-07-27 23:40:52 root INFO     [order_1_approx] starting weight calculation for A more intense word for want is crave
A more intense word for opposed is averse
A more intense word for doze is sleep
A more intense word for poorly is afflicted
A more intense word for unhappy is miserable
A more intense word for hungry is starving
A more intense word for nap is sleep
A more intense word for interesting is
2024-07-27 23:40:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 23:43:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0352,  0.1239, -0.0195,  ...,  0.1371, -0.4683, -0.1676],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5273,  0.2168,  0.7378,  ...,  0.3193, -5.3125, -2.5449],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0609,  0.0084, -0.0051,  ..., -0.0171,  0.0140,  0.0184],
        [-0.0161,  0.0455,  0.0099,  ...,  0.0048,  0.0127,  0.0008],
        [ 0.0128, -0.0241,  0.0755,  ..., -0.0003, -0.0009,  0.0018],
        ...,
        [ 0.0086, -0.0001, -0.0246,  ...,  0.0815,  0.0028,  0.0074],
        [ 0.0140,  0.0159,  0.0392,  ...,  0.0154,  0.0144,  0.0005],
        [ 0.0034, -0.0031,  0.0013,  ..., -0.0021, -0.0080,  0.0467]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5078e+00,  5.3711e-03,  8.9453e-01,  ...,  3.5352e-01,
         -5.4336e+00, -2.3633e+00]], device='cuda:1', dtype=torch.float16,
       grad_fn=<SubBackward0>) 

                    
2024-07-27 23:43:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for want is crave
A more intense word for opposed is averse
A more intense word for doze is sleep
A more intense word for poorly is afflicted
A more intense word for unhappy is miserable
A more intense word for hungry is starving
A more intense word for nap is sleep
A more intense word for interesting is
2024-07-27 23:43:04 root INFO     [order_1_approx] starting weight calculation for A more intense word for nap is sleep
A more intense word for interesting is exciting
A more intense word for poorly is afflicted
A more intense word for unhappy is miserable
A more intense word for doze is sleep
A more intense word for want is crave
A more intense word for hungry is starving
A more intense word for opposed is
2024-07-27 23:43:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 23:45:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2905, -0.1780, -0.4214,  ..., -0.0352, -0.1592,  0.2554],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8887, -4.9805,  2.6758,  ..., -1.0312, -3.8281, -1.6289],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0786,  0.0167,  0.0158,  ...,  0.0204, -0.0090, -0.0174],
        [ 0.0136,  0.0439,  0.0287,  ...,  0.0219,  0.0206, -0.0159],
        [ 0.0278, -0.0079,  0.0270,  ..., -0.0018,  0.0060,  0.0022],
        ...,
        [ 0.0127,  0.0083, -0.0017,  ...,  0.0728, -0.0142, -0.0208],
        [-0.0216, -0.0048,  0.0043,  ..., -0.0126,  0.0279,  0.0025],
        [ 0.0162, -0.0083,  0.0086,  ..., -0.0015,  0.0023,  0.0766]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7285, -4.8945,  2.6855,  ..., -0.9170, -3.3750, -1.6875]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 23:45:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for nap is sleep
A more intense word for interesting is exciting
A more intense word for poorly is afflicted
A more intense word for unhappy is miserable
A more intense word for doze is sleep
A more intense word for want is crave
A more intense word for hungry is starving
A more intense word for opposed is
2024-07-27 23:45:25 root INFO     [order_1_approx] starting weight calculation for A more intense word for want is crave
A more intense word for opposed is averse
A more intense word for nap is sleep
A more intense word for doze is sleep
A more intense word for interesting is exciting
A more intense word for hungry is starving
A more intense word for unhappy is miserable
A more intense word for poorly is
2024-07-27 23:45:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 23:47:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0981,  0.0146, -0.3142,  ..., -0.5186, -0.4321, -0.0568],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0547, -4.4375,  1.6758,  ..., -5.0898,  0.5781, -1.4795],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0638, -0.0317, -0.0224,  ..., -0.0116, -0.0174, -0.0041],
        [-0.0186,  0.0883,  0.0097,  ...,  0.0333,  0.0120, -0.0018],
        [-0.0480, -0.0104,  0.0699,  ...,  0.0201, -0.0129, -0.0277],
        ...,
        [ 0.0354,  0.0213, -0.0090,  ...,  0.0941,  0.0044, -0.0233],
        [-0.0150, -0.0790,  0.0215,  ...,  0.0073,  0.0541,  0.0024],
        [ 0.0009, -0.0423, -0.0055,  ..., -0.0106,  0.0113,  0.0732]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1797, -3.7207,  1.1934,  ..., -4.7383,  0.4746, -1.4805]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 23:47:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for want is crave
A more intense word for opposed is averse
A more intense word for nap is sleep
A more intense word for doze is sleep
A more intense word for interesting is exciting
A more intense word for hungry is starving
A more intense word for unhappy is miserable
A more intense word for poorly is
2024-07-27 23:47:45 root INFO     total operator prediction time: 1109.2534584999084 seconds
2024-07-27 23:47:45 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - substance
2024-07-27 23:47:45 root INFO     building operator meronyms - substance
2024-07-27 23:47:46 root INFO     [order_1_approx] starting weight calculation for A flag is made up of fabric
A spoon is made up of aluminium
A roof is made up of shingles
A cloud is made up of vapor
A ice is made up of water
A pill is made up of medicine
A doorknob is made up of metal
A beard is made up of
2024-07-27 23:47:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 23:50:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2266,  0.0403, -0.0906,  ...,  0.1842, -0.1589,  0.1583],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2969, -5.6719, -2.5781,  ..., -3.0898,  1.5273, -0.7832],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0469,  0.0112, -0.0033,  ...,  0.0125, -0.0062,  0.0096],
        [-0.0057,  0.0337,  0.0085,  ..., -0.0276, -0.0082, -0.0002],
        [-0.0109,  0.0004,  0.0406,  ..., -0.0023, -0.0222, -0.0350],
        ...,
        [ 0.0113,  0.0077,  0.0229,  ...,  0.0472,  0.0069, -0.0181],
        [-0.0155,  0.0104, -0.0346,  ...,  0.0165,  0.0255,  0.0053],
        [ 0.0065,  0.0013,  0.0047,  ..., -0.0125,  0.0007,  0.0369]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4648, -5.4727, -2.5645,  ..., -2.5664,  1.3672, -0.7974]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 23:50:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A flag is made up of fabric
A spoon is made up of aluminium
A roof is made up of shingles
A cloud is made up of vapor
A ice is made up of water
A pill is made up of medicine
A doorknob is made up of metal
A beard is made up of
2024-07-27 23:50:06 root INFO     [order_1_approx] starting weight calculation for A doorknob is made up of metal
A flag is made up of fabric
A roof is made up of shingles
A beard is made up of hair
A cloud is made up of vapor
A ice is made up of water
A spoon is made up of aluminium
A pill is made up of
2024-07-27 23:50:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 23:52:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0856, -0.0037, -0.1183,  ..., -0.2441, -0.2632, -0.1539],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4268, -6.8672,  0.9761,  ..., -2.6055,  0.1982,  0.9277],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0284, -0.0010, -0.0145,  ..., -0.0105,  0.0002, -0.0059],
        [ 0.0085,  0.0189, -0.0027,  ...,  0.0104,  0.0079, -0.0052],
        [ 0.0042,  0.0029,  0.0077,  ...,  0.0281, -0.0087, -0.0020],
        ...,
        [ 0.0061,  0.0003,  0.0057,  ...,  0.0547, -0.0276, -0.0152],
        [ 0.0148,  0.0056, -0.0333,  ...,  0.0154,  0.0370,  0.0089],
        [ 0.0041, -0.0105,  0.0052,  ..., -0.0060,  0.0030,  0.0248]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4719, -7.0430,  0.6885,  ..., -2.4707, -0.1143,  1.0469]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 23:52:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A doorknob is made up of metal
A flag is made up of fabric
A roof is made up of shingles
A beard is made up of hair
A cloud is made up of vapor
A ice is made up of water
A spoon is made up of aluminium
A pill is made up of
2024-07-27 23:52:28 root INFO     [order_1_approx] starting weight calculation for A pill is made up of medicine
A flag is made up of fabric
A roof is made up of shingles
A cloud is made up of vapor
A doorknob is made up of metal
A ice is made up of water
A beard is made up of hair
A spoon is made up of
2024-07-27 23:52:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 23:54:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0426, -0.3694, -0.1736,  ...,  0.3818, -0.2279,  0.0587],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1914, -0.7480, -1.9062,  ..., -2.0273, -1.1973,  0.4863],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0489, -0.0034, -0.0250,  ...,  0.0325, -0.0005, -0.0273],
        [-0.0093,  0.0766, -0.0143,  ...,  0.0005, -0.0076, -0.0098],
        [-0.0045, -0.0072,  0.0357,  ...,  0.0201, -0.0235, -0.0184],
        ...,
        [ 0.0133, -0.0089,  0.0085,  ...,  0.0503, -0.0022, -0.0220],
        [-0.0116,  0.0085, -0.0195,  ...,  0.0219,  0.0496,  0.0129],
        [ 0.0101,  0.0013,  0.0075,  ...,  0.0196,  0.0164,  0.0590]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3047, -1.0127, -1.6562,  ..., -2.0098, -1.4355,  0.5630]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 23:54:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A pill is made up of medicine
A flag is made up of fabric
A roof is made up of shingles
A cloud is made up of vapor
A doorknob is made up of metal
A ice is made up of water
A beard is made up of hair
A spoon is made up of
2024-07-27 23:54:51 root INFO     [order_1_approx] starting weight calculation for A ice is made up of water
A flag is made up of fabric
A pill is made up of medicine
A beard is made up of hair
A doorknob is made up of metal
A spoon is made up of aluminium
A roof is made up of shingles
A cloud is made up of
2024-07-27 23:54:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 23:57:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2749,  0.0883,  0.1052,  ..., -0.0521, -0.2230, -0.0192],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1602, -0.5122,  2.4883,  ..., -4.5156,  1.7510, -0.6543],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0470, -0.0002, -0.0009,  ..., -0.0062, -0.0044, -0.0132],
        [-0.0168,  0.0337, -0.0087,  ...,  0.0228, -0.0155, -0.0099],
        [ 0.0213, -0.0018,  0.0375,  ...,  0.0073, -0.0218, -0.0034],
        ...,
        [-0.0027,  0.0186,  0.0056,  ...,  0.0426,  0.0012, -0.0111],
        [-0.0133, -0.0103,  0.0079,  ...,  0.0176,  0.0397,  0.0096],
        [ 0.0215, -0.0086,  0.0027,  ..., -0.0153,  0.0032,  0.0230]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3223, -0.9521,  2.4102,  ..., -4.1562,  1.5977, -0.7529]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 23:57:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A ice is made up of water
A flag is made up of fabric
A pill is made up of medicine
A beard is made up of hair
A doorknob is made up of metal
A spoon is made up of aluminium
A roof is made up of shingles
A cloud is made up of
2024-07-27 23:57:12 root INFO     [order_1_approx] starting weight calculation for A beard is made up of hair
A ice is made up of water
A doorknob is made up of metal
A pill is made up of medicine
A cloud is made up of vapor
A spoon is made up of aluminium
A flag is made up of fabric
A roof is made up of
2024-07-27 23:57:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-27 23:59:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1615, -0.1499,  0.0890,  ..., -0.2883, -0.3428, -0.2568],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0977, -6.5195,  1.2227,  ..., -2.1328, -0.5625, -1.6924],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0470,  0.0025,  0.0111,  ..., -0.0107, -0.0231, -0.0015],
        [ 0.0099,  0.0434,  0.0091,  ...,  0.0040, -0.0216, -0.0064],
        [ 0.0077,  0.0078,  0.0210,  ..., -0.0258, -0.0135, -0.0221],
        ...,
        [ 0.0055, -0.0073,  0.0225,  ...,  0.0785, -0.0019, -0.0233],
        [ 0.0043,  0.0126, -0.0226,  ..., -0.0156,  0.0363,  0.0124],
        [ 0.0071,  0.0011,  0.0056,  ...,  0.0185, -0.0022,  0.0067]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.1719, -6.2578,  0.9004,  ..., -2.0039, -0.8486, -1.4463]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 23:59:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A beard is made up of hair
A ice is made up of water
A doorknob is made up of metal
A pill is made up of medicine
A cloud is made up of vapor
A spoon is made up of aluminium
A flag is made up of fabric
A roof is made up of
2024-07-27 23:59:35 root INFO     [order_1_approx] starting weight calculation for A flag is made up of fabric
A beard is made up of hair
A roof is made up of shingles
A pill is made up of medicine
A cloud is made up of vapor
A doorknob is made up of metal
A spoon is made up of aluminium
A ice is made up of
2024-07-27 23:59:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 00:01:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0810,  0.3086, -0.4114,  ...,  0.0251,  0.0361,  0.1372],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3555, -4.3945,  0.3208,  ..., -6.3828,  1.1914,  0.4561],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0481, -0.0101, -0.0159,  ..., -0.0058, -0.0096, -0.0162],
        [-0.0089,  0.0386, -0.0040,  ...,  0.0037,  0.0028, -0.0023],
        [ 0.0067, -0.0171,  0.0214,  ..., -0.0033, -0.0088, -0.0141],
        ...,
        [ 0.0215,  0.0155,  0.0170,  ...,  0.0345,  0.0018,  0.0041],
        [-0.0040,  0.0061, -0.0037,  ...,  0.0362,  0.0305,  0.0327],
        [ 0.0100,  0.0040, -0.0065,  ..., -0.0003,  0.0091,  0.0273]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2373, -4.5312,  0.4614,  ..., -5.7539,  0.9551,  0.5679]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 00:01:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A flag is made up of fabric
A beard is made up of hair
A roof is made up of shingles
A pill is made up of medicine
A cloud is made up of vapor
A doorknob is made up of metal
A spoon is made up of aluminium
A ice is made up of
2024-07-28 00:01:57 root INFO     [order_1_approx] starting weight calculation for A spoon is made up of aluminium
A beard is made up of hair
A flag is made up of fabric
A ice is made up of water
A roof is made up of shingles
A pill is made up of medicine
A cloud is made up of vapor
A doorknob is made up of
2024-07-28 00:01:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 00:04:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1821, -0.1088, -0.3042,  ...,  0.4141, -0.3296, -0.2671],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0586, -2.7227, -1.1328,  ..., -2.0586, -0.4907, -0.5273],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0590, -0.0028, -0.0278,  ...,  0.0435, -0.0167, -0.0248],
        [-0.0088,  0.0523, -0.0011,  ...,  0.0061, -0.0108,  0.0020],
        [ 0.0214,  0.0030,  0.0611,  ...,  0.0049, -0.0079, -0.0038],
        ...,
        [ 0.0384,  0.0028,  0.0173,  ...,  0.0736, -0.0198,  0.0010],
        [ 0.0081,  0.0102, -0.0059,  ...,  0.0092,  0.0428, -0.0065],
        [ 0.0008, -0.0054,  0.0361,  ..., -0.0036,  0.0067,  0.0285]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9570, -2.2988, -0.9932,  ..., -2.0000, -0.5400, -0.1904]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 00:04:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A spoon is made up of aluminium
A beard is made up of hair
A flag is made up of fabric
A ice is made up of water
A roof is made up of shingles
A pill is made up of medicine
A cloud is made up of vapor
A doorknob is made up of
2024-07-28 00:04:19 root INFO     [order_1_approx] starting weight calculation for A pill is made up of medicine
A roof is made up of shingles
A spoon is made up of aluminium
A beard is made up of hair
A ice is made up of water
A doorknob is made up of metal
A cloud is made up of vapor
A flag is made up of
2024-07-28 00:04:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 00:06:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3787,  0.1754, -0.4868,  ...,  0.2292, -0.2688, -0.3164],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7852, -6.2734,  3.5645,  ..., -3.9492,  0.6592, -0.2969],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0393,  0.0010,  0.0040,  ..., -0.0114, -0.0123, -0.0206],
        [ 0.0092,  0.0301,  0.0309,  ...,  0.0355, -0.0092, -0.0041],
        [-0.0066,  0.0099,  0.0234,  ...,  0.0055, -0.0115, -0.0243],
        ...,
        [-0.0032,  0.0167,  0.0176,  ...,  0.0773, -0.0134, -0.0279],
        [ 0.0037,  0.0061, -0.0300,  ..., -0.0081,  0.0494,  0.0002],
        [ 0.0273,  0.0068,  0.0314,  ..., -0.0043, -0.0042,  0.0115]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.1992, -6.3672,  3.3105,  ..., -3.8633,  0.5781, -0.4980]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 00:06:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A pill is made up of medicine
A roof is made up of shingles
A spoon is made up of aluminium
A beard is made up of hair
A ice is made up of water
A doorknob is made up of metal
A cloud is made up of vapor
A flag is made up of
2024-07-28 00:06:41 root INFO     total operator prediction time: 1135.7751379013062 seconds
2024-07-28 00:06:41 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hypernyms - misc
2024-07-28 00:06:41 root INFO     building operator hypernyms - misc
2024-07-28 00:06:41 root INFO     [order_1_approx] starting weight calculation for The mascara falls into the category of makeup
The photo falls into the category of picture
The tv falls into the category of device
The juicer falls into the category of utensil
The gasoline falls into the category of fuel
The sunscreen falls into the category of cream
The dishwasher falls into the category of appliance
The hairnet falls into the category of
2024-07-28 00:06:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 00:09:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1581, -0.2690, -0.4377,  ...,  0.2820, -0.1304,  0.1779],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6406, -2.7148,  1.3018,  ..., -0.7017, -4.0898,  3.4590],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0836, -0.0021,  0.0045,  ...,  0.0138, -0.0147,  0.0035],
        [-0.0088,  0.0666, -0.0209,  ..., -0.0182, -0.0080, -0.0103],
        [-0.0078,  0.0191,  0.0680,  ...,  0.0029, -0.0112,  0.0081],
        ...,
        [ 0.0124, -0.0079,  0.0160,  ...,  0.0546,  0.0126, -0.0035],
        [ 0.0067, -0.0098,  0.0165,  ...,  0.0019,  0.0448, -0.0254],
        [-0.0118, -0.0170, -0.0147,  ..., -0.0119, -0.0088,  0.0742]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2402, -3.3398,  0.8623,  ..., -0.1675, -4.1172,  3.0352]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 00:09:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The mascara falls into the category of makeup
The photo falls into the category of picture
The tv falls into the category of device
The juicer falls into the category of utensil
The gasoline falls into the category of fuel
The sunscreen falls into the category of cream
The dishwasher falls into the category of appliance
The hairnet falls into the category of
2024-07-28 00:09:03 root INFO     [order_1_approx] starting weight calculation for The sunscreen falls into the category of cream
The photo falls into the category of picture
The juicer falls into the category of utensil
The dishwasher falls into the category of appliance
The mascara falls into the category of makeup
The gasoline falls into the category of fuel
The hairnet falls into the category of net
The tv falls into the category of
2024-07-28 00:09:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 00:11:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1370, -0.3262,  0.0431,  ...,  0.3767, -0.2360, -0.1429],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.6768, -3.6621,  3.2930,  ..., -0.9434, -4.4883, -1.5898],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0732, -0.0108,  0.0168,  ..., -0.0030,  0.0149,  0.0049],
        [-0.0055,  0.0571,  0.0051,  ...,  0.0030,  0.0077,  0.0132],
        [-0.0007, -0.0195,  0.0695,  ..., -0.0020,  0.0077,  0.0067],
        ...,
        [ 0.0117,  0.0253,  0.0192,  ...,  0.0693,  0.0037, -0.0088],
        [ 0.0181, -0.0025,  0.0128,  ...,  0.0034,  0.0676, -0.0039],
        [ 0.0133,  0.0012, -0.0068,  ...,  0.0055, -0.0043,  0.0447]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.6758, -3.5098,  3.3223,  ..., -0.9194, -4.4297, -1.3965]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 00:11:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sunscreen falls into the category of cream
The photo falls into the category of picture
The juicer falls into the category of utensil
The dishwasher falls into the category of appliance
The mascara falls into the category of makeup
The gasoline falls into the category of fuel
The hairnet falls into the category of net
The tv falls into the category of
2024-07-28 00:11:25 root INFO     [order_1_approx] starting weight calculation for The sunscreen falls into the category of cream
The juicer falls into the category of utensil
The mascara falls into the category of makeup
The photo falls into the category of picture
The tv falls into the category of device
The hairnet falls into the category of net
The gasoline falls into the category of fuel
The dishwasher falls into the category of
2024-07-28 00:11:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 00:13:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1399, -0.0352, -0.3672,  ...,  0.2278, -0.6528, -0.6045],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5830, -1.9355,  1.9707,  ..., -1.2607, -3.6680,  1.5625],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0255, -0.0053,  0.0060,  ...,  0.0138,  0.0046,  0.0051],
        [ 0.0084,  0.0353,  0.0118,  ...,  0.0033,  0.0119, -0.0003],
        [-0.0001,  0.0033,  0.0266,  ..., -0.0057, -0.0150,  0.0073],
        ...,
        [ 0.0034,  0.0120, -0.0015,  ...,  0.0341,  0.0028,  0.0086],
        [ 0.0058,  0.0018, -0.0020,  ..., -0.0032,  0.0305, -0.0208],
        [ 0.0033, -0.0011,  0.0022,  ..., -0.0029, -0.0014,  0.0273]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7725, -1.7949,  1.8057,  ..., -1.3428, -3.4727,  1.6543]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 00:13:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sunscreen falls into the category of cream
The juicer falls into the category of utensil
The mascara falls into the category of makeup
The photo falls into the category of picture
The tv falls into the category of device
The hairnet falls into the category of net
The gasoline falls into the category of fuel
The dishwasher falls into the category of
2024-07-28 00:13:46 root INFO     [order_1_approx] starting weight calculation for The mascara falls into the category of makeup
The hairnet falls into the category of net
The gasoline falls into the category of fuel
The juicer falls into the category of utensil
The tv falls into the category of device
The dishwasher falls into the category of appliance
The photo falls into the category of picture
The sunscreen falls into the category of
2024-07-28 00:13:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 00:16:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3550, -0.3655, -0.3179,  ..., -0.0929,  0.0397, -0.5933],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4648,  0.2207,  3.6406,  ..., -2.8770, -1.9922, -0.4668],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0523, -0.0244,  0.0036,  ...,  0.0074, -0.0114,  0.0038],
        [ 0.0101,  0.0714, -0.0012,  ...,  0.0141, -0.0050,  0.0150],
        [-0.0301,  0.0049,  0.0472,  ..., -0.0046, -0.0090,  0.0115],
        ...,
        [ 0.0089,  0.0066, -0.0019,  ...,  0.0492,  0.0249,  0.0196],
        [ 0.0018,  0.0112, -0.0108,  ...,  0.0186,  0.0470, -0.0150],
        [ 0.0126, -0.0233,  0.0008,  ...,  0.0023, -0.0093,  0.0551]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2219, -0.1433,  3.6348,  ..., -2.6719, -1.9268, -0.4998]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 00:16:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The mascara falls into the category of makeup
The hairnet falls into the category of net
The gasoline falls into the category of fuel
The juicer falls into the category of utensil
The tv falls into the category of device
The dishwasher falls into the category of appliance
The photo falls into the category of picture
The sunscreen falls into the category of
2024-07-28 00:16:07 root INFO     [order_1_approx] starting weight calculation for The tv falls into the category of device
The dishwasher falls into the category of appliance
The photo falls into the category of picture
The mascara falls into the category of makeup
The hairnet falls into the category of net
The juicer falls into the category of utensil
The sunscreen falls into the category of cream
The gasoline falls into the category of
2024-07-28 00:16:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 00:18:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0632, -0.0552, -0.4561,  ...,  0.1450, -0.2135,  0.0050],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9531, -3.3457,  2.0195,  ..., -3.8750, -0.3740,  0.0215],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0516, -0.0206,  0.0026,  ...,  0.0057,  0.0024,  0.0074],
        [-0.0019,  0.0453,  0.0090,  ...,  0.0134,  0.0111, -0.0217],
        [-0.0218,  0.0128,  0.0431,  ..., -0.0155, -0.0190,  0.0046],
        ...,
        [-0.0019,  0.0029, -0.0010,  ...,  0.0318,  0.0055, -0.0060],
        [-0.0020,  0.0044, -0.0134,  ...,  0.0050,  0.0509, -0.0132],
        [ 0.0026, -0.0101, -0.0008,  ..., -0.0143, -0.0046,  0.0444]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1250, -3.4414,  1.6895,  ..., -3.3535, -0.3286,  0.0058]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 00:18:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The tv falls into the category of device
The dishwasher falls into the category of appliance
The photo falls into the category of picture
The mascara falls into the category of makeup
The hairnet falls into the category of net
The juicer falls into the category of utensil
The sunscreen falls into the category of cream
The gasoline falls into the category of
2024-07-28 00:18:28 root INFO     [order_1_approx] starting weight calculation for The dishwasher falls into the category of appliance
The gasoline falls into the category of fuel
The mascara falls into the category of makeup
The hairnet falls into the category of net
The juicer falls into the category of utensil
The sunscreen falls into the category of cream
The tv falls into the category of device
The photo falls into the category of
2024-07-28 00:18:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 00:20:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4919, -0.1300,  0.3472,  ..., -0.1066, -0.0371, -0.0682],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5850, -2.8711,  0.4124,  ..., -1.9561, -1.0186, -0.3613],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0542,  0.0020, -0.0034,  ..., -0.0007,  0.0060, -0.0057],
        [ 0.0037,  0.0295,  0.0013,  ...,  0.0211, -0.0121,  0.0179],
        [ 0.0105,  0.0057,  0.0392,  ...,  0.0153,  0.0072,  0.0121],
        ...,
        [ 0.0120, -0.0015,  0.0164,  ...,  0.0388, -0.0108, -0.0048],
        [ 0.0021,  0.0139, -0.0108,  ...,  0.0190,  0.0502,  0.0088],
        [ 0.0014,  0.0136,  0.0042,  ..., -0.0032, -0.0075,  0.0327]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3608, -2.9395,  0.5210,  ..., -1.9873, -1.0713, -0.7012]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 00:20:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The dishwasher falls into the category of appliance
The gasoline falls into the category of fuel
The mascara falls into the category of makeup
The hairnet falls into the category of net
The juicer falls into the category of utensil
The sunscreen falls into the category of cream
The tv falls into the category of device
The photo falls into the category of
2024-07-28 00:20:49 root INFO     [order_1_approx] starting weight calculation for The juicer falls into the category of utensil
The tv falls into the category of device
The hairnet falls into the category of net
The photo falls into the category of picture
The sunscreen falls into the category of cream
The dishwasher falls into the category of appliance
The gasoline falls into the category of fuel
The mascara falls into the category of
2024-07-28 00:20:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 00:23:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.6309, -0.4929, -0.3245,  ...,  0.0087, -0.4585, -0.2939],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8633, -0.4443,  0.6689,  ...,  0.1260, -2.4102,  1.6387],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0453,  0.0092,  0.0054,  ..., -0.0001, -0.0072,  0.0221],
        [ 0.0035,  0.0464, -0.0017,  ..., -0.0003,  0.0014, -0.0060],
        [-0.0071, -0.0065,  0.0562,  ..., -0.0131, -0.0175,  0.0024],
        ...,
        [ 0.0123, -0.0084,  0.0132,  ...,  0.0493,  0.0131, -0.0013],
        [-0.0060,  0.0111, -0.0002,  ..., -0.0030,  0.0453, -0.0093],
        [ 0.0174,  0.0213,  0.0004,  ..., -0.0126, -0.0083,  0.0554]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5039, -0.4702,  0.8447,  ...,  0.2734, -2.5078,  1.5742]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 00:23:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The juicer falls into the category of utensil
The tv falls into the category of device
The hairnet falls into the category of net
The photo falls into the category of picture
The sunscreen falls into the category of cream
The dishwasher falls into the category of appliance
The gasoline falls into the category of fuel
The mascara falls into the category of
2024-07-28 00:23:11 root INFO     [order_1_approx] starting weight calculation for The hairnet falls into the category of net
The sunscreen falls into the category of cream
The tv falls into the category of device
The dishwasher falls into the category of appliance
The photo falls into the category of picture
The mascara falls into the category of makeup
The gasoline falls into the category of fuel
The juicer falls into the category of
2024-07-28 00:23:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 00:25:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0865, -0.2729, -0.0612,  ..., -0.1007, -0.6392, -0.5200],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4229, -4.1953,  0.3196,  ..., -2.2227, -1.5186, -0.0674],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0505, -0.0067,  0.0037,  ...,  0.0036, -0.0005,  0.0050],
        [ 0.0059,  0.0690,  0.0011,  ...,  0.0063,  0.0020,  0.0010],
        [-0.0086,  0.0081,  0.0471,  ..., -0.0094, -0.0145,  0.0091],
        ...,
        [ 0.0067,  0.0114, -0.0036,  ...,  0.0449,  0.0021, -0.0007],
        [-0.0027, -0.0117, -0.0121,  ..., -0.0041,  0.0403, -0.0263],
        [-0.0124,  0.0050, -0.0047,  ..., -0.0007, -0.0124,  0.0472]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5771, -4.3633, -0.0859,  ..., -2.3535, -1.1855, -0.0816]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 00:25:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The hairnet falls into the category of net
The sunscreen falls into the category of cream
The tv falls into the category of device
The dishwasher falls into the category of appliance
The photo falls into the category of picture
The mascara falls into the category of makeup
The gasoline falls into the category of fuel
The juicer falls into the category of
2024-07-28 00:25:31 root INFO     total operator prediction time: 1129.562905550003 seconds
2024-07-28 00:25:31 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on synonyms - exact
2024-07-28 00:25:31 root INFO     building operator synonyms - exact
2024-07-28 00:25:31 root INFO     [order_1_approx] starting weight calculation for Another word for mesh is gauze
Another word for package is parcel
Another word for jewel is gem
Another word for help is aid
Another word for portion is part
Another word for sofa is couch
Another word for bicycle is bike
Another word for homogeneous is
2024-07-28 00:25:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 00:27:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1172,  0.0845, -0.2900,  ..., -0.1912, -0.0096,  0.6255],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7227,  1.4287,  1.7021,  ..., -1.2793, -7.1328, -1.4414],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1046, -0.0243,  0.0155,  ..., -0.0432, -0.0272,  0.0072],
        [-0.0017,  0.1431,  0.0281,  ...,  0.0759,  0.0572, -0.0399],
        [-0.0229, -0.0700,  0.1044,  ..., -0.0628, -0.0138,  0.0421],
        ...,
        [ 0.0240,  0.0722,  0.0150,  ...,  0.1703, -0.0079, -0.0541],
        [ 0.0229, -0.0259, -0.0010,  ..., -0.0425,  0.0764,  0.0438],
        [ 0.0155,  0.0188,  0.0119,  ...,  0.0154, -0.0053,  0.0605]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5312,  1.1816,  1.4248,  ..., -0.8799, -6.5469, -1.0889]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 00:27:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for mesh is gauze
Another word for package is parcel
Another word for jewel is gem
Another word for help is aid
Another word for portion is part
Another word for sofa is couch
Another word for bicycle is bike
Another word for homogeneous is
2024-07-28 00:27:53 root INFO     [order_1_approx] starting weight calculation for Another word for homogeneous is uniform
Another word for package is parcel
Another word for bicycle is bike
Another word for sofa is couch
Another word for jewel is gem
Another word for portion is part
Another word for help is aid
Another word for mesh is
2024-07-28 00:27:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 00:30:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4702,  0.0204, -0.3276,  ...,  0.5522, -0.0940,  0.3372],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7148, -1.0615,  1.5039,  ...,  0.6299, -2.8086,  1.2793],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1423,  0.0041,  0.0026,  ...,  0.0218,  0.0003, -0.0127],
        [-0.0064,  0.0916,  0.0294,  ...,  0.0021, -0.0006, -0.0215],
        [ 0.0457, -0.0194,  0.1082,  ..., -0.0430,  0.0019, -0.0470],
        ...,
        [ 0.0096,  0.0274,  0.0173,  ...,  0.1503, -0.0139,  0.0047],
        [-0.0030, -0.0131, -0.0399,  ..., -0.0087,  0.0708, -0.0071],
        [-0.0216,  0.0047,  0.0011,  ..., -0.0366, -0.0392,  0.1014]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4287, -1.4307,  1.1953,  ...,  0.9692, -3.1484,  0.6099]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 00:30:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for homogeneous is uniform
Another word for package is parcel
Another word for bicycle is bike
Another word for sofa is couch
Another word for jewel is gem
Another word for portion is part
Another word for help is aid
Another word for mesh is
2024-07-28 00:30:16 root INFO     [order_1_approx] starting weight calculation for Another word for homogeneous is uniform
Another word for mesh is gauze
Another word for bicycle is bike
Another word for package is parcel
Another word for help is aid
Another word for portion is part
Another word for jewel is gem
Another word for sofa is
2024-07-28 00:30:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 00:32:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3477, -0.1656,  0.1737,  ...,  0.3145, -0.2495, -0.0173],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.3750, -3.5234,  4.0859,  ..., -0.8936, -2.7480, -2.1797],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1089,  0.0119,  0.0194,  ...,  0.0352, -0.0037,  0.0022],
        [ 0.0100,  0.0693, -0.0041,  ...,  0.0085,  0.0186, -0.0081],
        [-0.0294, -0.0181,  0.0840,  ..., -0.0215, -0.0272, -0.0056],
        ...,
        [ 0.0403,  0.0012, -0.0252,  ...,  0.1107,  0.0069, -0.0071],
        [ 0.0075,  0.0060, -0.0187,  ...,  0.0038,  0.0523,  0.0199],
        [-0.0010,  0.0241, -0.0112,  ..., -0.0357,  0.0050,  0.0409]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.4355, -2.8672,  3.3652,  ..., -0.8154, -1.9609, -2.0234]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 00:32:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for homogeneous is uniform
Another word for mesh is gauze
Another word for bicycle is bike
Another word for package is parcel
Another word for help is aid
Another word for portion is part
Another word for jewel is gem
Another word for sofa is
2024-07-28 00:32:39 root INFO     [order_1_approx] starting weight calculation for Another word for homogeneous is uniform
Another word for package is parcel
Another word for help is aid
Another word for jewel is gem
Another word for mesh is gauze
Another word for sofa is couch
Another word for portion is part
Another word for bicycle is
2024-07-28 00:32:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 00:34:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3806, -0.3584, -0.2595,  ..., -0.0889, -0.1298, -0.2046],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8164, -4.5195,  1.3994,  ...,  0.9980, -0.6484, -2.1270],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0473, -0.0124,  0.0152,  ...,  0.0102,  0.0123, -0.0125],
        [ 0.0012,  0.0341, -0.0017,  ...,  0.0183, -0.0017, -0.0179],
        [-0.0008,  0.0026,  0.0337,  ..., -0.0229,  0.0026,  0.0133],
        ...,
        [ 0.0097,  0.0034, -0.0008,  ...,  0.0341, -0.0080,  0.0049],
        [-0.0182,  0.0014, -0.0011,  ..., -0.0002,  0.0173, -0.0026],
        [ 0.0206, -0.0067,  0.0073,  ..., -0.0203, -0.0074,  0.0259]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6128, -4.4961,  1.1436,  ...,  0.8687, -0.6045, -2.4883]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 00:34:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for homogeneous is uniform
Another word for package is parcel
Another word for help is aid
Another word for jewel is gem
Another word for mesh is gauze
Another word for sofa is couch
Another word for portion is part
Another word for bicycle is
2024-07-28 00:34:59 root INFO     [order_1_approx] starting weight calculation for Another word for mesh is gauze
Another word for portion is part
Another word for homogeneous is uniform
Another word for sofa is couch
Another word for help is aid
Another word for package is parcel
Another word for bicycle is bike
Another word for jewel is
2024-07-28 00:34:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 00:37:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2869, -0.0638, -0.1197,  ..., -0.0737, -0.1940, -0.3235],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0010, -2.5703, -2.4180,  ..., -0.0342, -3.5312,  2.3555],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0458, -0.0135,  0.0071,  ..., -0.0037, -0.0036,  0.0094],
        [ 0.0047,  0.0232, -0.0101,  ...,  0.0108,  0.0105, -0.0055],
        [-0.0006,  0.0002,  0.0268,  ...,  0.0051, -0.0198,  0.0126],
        ...,
        [-0.0144,  0.0161, -0.0042,  ...,  0.0329,  0.0145, -0.0114],
        [-0.0055, -0.0110,  0.0047,  ...,  0.0133,  0.0222, -0.0078],
        [-0.0055, -0.0014, -0.0055,  ..., -0.0173,  0.0079,  0.0156]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.0361, -2.5254, -2.7109,  ...,  0.2073, -3.8262,  2.3691]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 00:37:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for mesh is gauze
Another word for portion is part
Another word for homogeneous is uniform
Another word for sofa is couch
Another word for help is aid
Another word for package is parcel
Another word for bicycle is bike
Another word for jewel is
2024-07-28 00:37:19 root INFO     [order_1_approx] starting weight calculation for Another word for homogeneous is uniform
Another word for help is aid
Another word for jewel is gem
Another word for bicycle is bike
Another word for portion is part
Another word for mesh is gauze
Another word for sofa is couch
Another word for package is
2024-07-28 00:37:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 00:39:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2081, -0.2012,  0.1256,  ...,  0.0223, -0.1689, -0.0860],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.2109, -2.2305, -1.5176,  ..., -1.3477, -1.0771, -0.9678],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0779,  0.0036,  0.0092,  ...,  0.0438, -0.0628,  0.0293],
        [ 0.0002,  0.0995,  0.0305,  ..., -0.0253,  0.0313, -0.0222],
        [ 0.0073, -0.0040,  0.0787,  ...,  0.0126, -0.0314, -0.0197],
        ...,
        [ 0.0356,  0.0096,  0.0054,  ...,  0.0872, -0.0104, -0.0084],
        [-0.0035,  0.0080, -0.0229,  ..., -0.0011,  0.0702, -0.0123],
        [ 0.0052, -0.0284, -0.0057,  ..., -0.0393,  0.0069,  0.0742]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.0000, -2.9238, -1.2402,  ..., -2.1797, -0.9819, -1.1387]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 00:39:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for homogeneous is uniform
Another word for help is aid
Another word for jewel is gem
Another word for bicycle is bike
Another word for portion is part
Another word for mesh is gauze
Another word for sofa is couch
Another word for package is
2024-07-28 00:39:40 root INFO     [order_1_approx] starting weight calculation for Another word for bicycle is bike
Another word for jewel is gem
Another word for mesh is gauze
Another word for sofa is couch
Another word for package is parcel
Another word for homogeneous is uniform
Another word for help is aid
Another word for portion is
2024-07-28 00:39:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 00:41:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5088, -0.4680,  0.0151,  ..., -0.2896,  0.1120,  0.2673],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2705, -3.7852,  0.1409,  ..., -2.3086, -1.4727, -1.9414],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1043, -0.0309,  0.0059,  ...,  0.0186, -0.0151,  0.0027],
        [-0.0134,  0.0605,  0.0041,  ...,  0.0212,  0.0143, -0.0175],
        [-0.0238, -0.0024,  0.0988,  ..., -0.0020, -0.0081, -0.0173],
        ...,
        [ 0.0184, -0.0031, -0.0045,  ...,  0.1101,  0.0053, -0.0198],
        [-0.0199,  0.0441,  0.0045,  ..., -0.0171,  0.0840, -0.0059],
        [-0.0256, -0.0136, -0.0159,  ..., -0.0478, -0.0119,  0.0897]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0732, -3.4551,  0.5283,  ..., -2.4492, -1.2207, -1.9785]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 00:41:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for bicycle is bike
Another word for jewel is gem
Another word for mesh is gauze
Another word for sofa is couch
Another word for package is parcel
Another word for homogeneous is uniform
Another word for help is aid
Another word for portion is
2024-07-28 00:41:58 root INFO     [order_1_approx] starting weight calculation for Another word for portion is part
Another word for homogeneous is uniform
Another word for jewel is gem
Another word for bicycle is bike
Another word for package is parcel
Another word for mesh is gauze
Another word for sofa is couch
Another word for help is
2024-07-28 00:41:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 00:44:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1968, -0.2384,  0.2120,  ...,  0.1644, -0.1895,  0.3359],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.3438, -6.3984,  1.6465,  ...,  2.2246, -3.1094, -1.4365],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0612, -0.0249,  0.0135,  ...,  0.0131,  0.0081,  0.0037],
        [-0.0087,  0.0305, -0.0012,  ...,  0.0262, -0.0025, -0.0165],
        [-0.0056,  0.0203,  0.0381,  ..., -0.0032, -0.0070, -0.0294],
        ...,
        [ 0.0048,  0.0154,  0.0052,  ...,  0.0406,  0.0185,  0.0075],
        [ 0.0014,  0.0122,  0.0084,  ..., -0.0039,  0.0523, -0.0127],
        [ 0.0092, -0.0133,  0.0075,  ...,  0.0031, -0.0287,  0.0589]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.3594, -5.5742,  1.4551,  ...,  2.1719, -3.4141, -1.4971]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 00:44:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for portion is part
Another word for homogeneous is uniform
Another word for jewel is gem
Another word for bicycle is bike
Another word for package is parcel
Another word for mesh is gauze
Another word for sofa is couch
Another word for help is
2024-07-28 00:44:20 root INFO     total operator prediction time: 1129.0179460048676 seconds
2024-07-28 00:44:20 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - youth
2024-07-28 00:44:20 root INFO     building operator animal - youth
2024-07-28 00:44:20 root INFO     [order_1_approx] starting weight calculation for The offspring of a deer is referred to as a fawn
The offspring of a weasel is referred to as a kit
The offspring of a skunk is referred to as a kit
The offspring of a trout is referred to as a fingerling
The offspring of a whale is referred to as a calf
The offspring of a camel is referred to as a calf
The offspring of a elephant is referred to as a calf
The offspring of a insect is referred to as a
2024-07-28 00:44:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 00:46:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1632,  0.1313,  0.2532,  ...,  0.2578, -0.1456, -0.3188],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9922, -2.0508,  0.0630,  ..., -0.6694, -2.5977,  0.7920],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.5878e-02, -2.0950e-02,  1.3933e-03,  ...,  2.4200e-02,
         -1.6602e-02, -1.6663e-02],
        [ 1.1131e-02,  2.5757e-02,  5.2185e-03,  ...,  1.1086e-02,
          7.6294e-06, -6.2866e-03],
        [-2.8629e-03, -4.5013e-04,  5.4535e-02,  ...,  6.5308e-03,
         -8.7357e-03, -2.5024e-02],
        ...,
        [ 1.4515e-03,  1.5747e-02, -1.4732e-02,  ...,  2.4185e-02,
          1.8280e-02,  1.5268e-03],
        [ 7.9575e-03,  1.2421e-02,  1.4259e-02,  ...,  2.0050e-02,
          6.3400e-03,  2.6436e-03],
        [ 8.6746e-03, -1.0582e-02, -7.6904e-03,  ..., -1.6235e-02,
         -1.6266e-02,  2.5009e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7070, -1.9053, -0.3286,  ..., -0.2791, -2.4531,  0.4480]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 00:46:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a deer is referred to as a fawn
The offspring of a weasel is referred to as a kit
The offspring of a skunk is referred to as a kit
The offspring of a trout is referred to as a fingerling
The offspring of a whale is referred to as a calf
The offspring of a camel is referred to as a calf
The offspring of a elephant is referred to as a calf
The offspring of a insect is referred to as a
2024-07-28 00:46:41 root INFO     [order_1_approx] starting weight calculation for The offspring of a insect is referred to as a larva
The offspring of a skunk is referred to as a kit
The offspring of a elephant is referred to as a calf
The offspring of a trout is referred to as a fingerling
The offspring of a deer is referred to as a fawn
The offspring of a whale is referred to as a calf
The offspring of a camel is referred to as a calf
The offspring of a weasel is referred to as a
2024-07-28 00:46:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 00:48:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0821,  0.0063,  0.2209,  ...,  0.0441, -0.5913, -0.3621],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9902, -2.1406, -0.7373,  ...,  1.0078, -1.3232,  1.3779],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0242,  0.0035, -0.0029,  ..., -0.0002,  0.0007,  0.0078],
        [-0.0054,  0.0230,  0.0047,  ..., -0.0022,  0.0094, -0.0056],
        [ 0.0005, -0.0017,  0.0209,  ...,  0.0085, -0.0107, -0.0142],
        ...,
        [ 0.0023,  0.0066,  0.0073,  ...,  0.0172,  0.0192, -0.0076],
        [-0.0014, -0.0044,  0.0061,  ...,  0.0139,  0.0019, -0.0102],
        [ 0.0013, -0.0076,  0.0021,  ..., -0.0036, -0.0081,  0.0116]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0840, -2.2520, -0.7559,  ...,  1.0234, -1.2930,  1.2998]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 00:49:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a insect is referred to as a larva
The offspring of a skunk is referred to as a kit
The offspring of a elephant is referred to as a calf
The offspring of a trout is referred to as a fingerling
The offspring of a deer is referred to as a fawn
The offspring of a whale is referred to as a calf
The offspring of a camel is referred to as a calf
The offspring of a weasel is referred to as a
2024-07-28 00:49:00 root INFO     [order_1_approx] starting weight calculation for The offspring of a camel is referred to as a calf
The offspring of a weasel is referred to as a kit
The offspring of a skunk is referred to as a kit
The offspring of a insect is referred to as a larva
The offspring of a trout is referred to as a fingerling
The offspring of a deer is referred to as a fawn
The offspring of a whale is referred to as a calf
The offspring of a elephant is referred to as a
2024-07-28 00:49:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 00:51:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4009, -0.3289,  0.2157,  ..., -0.1602, -0.4756, -0.2074],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7969, -2.3438, -1.1123,  ...,  0.0303, -3.0703,  1.2090],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0079, -0.0054, -0.0042,  ..., -0.0010,  0.0010, -0.0096],
        [-0.0134,  0.0079,  0.0042,  ..., -0.0074,  0.0004,  0.0013],
        [-0.0040,  0.0032,  0.0072,  ...,  0.0068, -0.0002, -0.0028],
        ...,
        [-0.0017,  0.0014,  0.0025,  ...,  0.0071,  0.0085, -0.0037],
        [ 0.0079, -0.0012,  0.0101,  ...,  0.0045,  0.0024,  0.0092],
        [-0.0011, -0.0016, -0.0038,  ..., -0.0120, -0.0003,  0.0055]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8164, -2.2988, -1.1357,  ...,  0.0602, -3.1680,  1.2461]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 00:51:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a camel is referred to as a calf
The offspring of a weasel is referred to as a kit
The offspring of a skunk is referred to as a kit
The offspring of a insect is referred to as a larva
The offspring of a trout is referred to as a fingerling
The offspring of a deer is referred to as a fawn
The offspring of a whale is referred to as a calf
The offspring of a elephant is referred to as a
2024-07-28 00:51:18 root INFO     [order_1_approx] starting weight calculation for The offspring of a insect is referred to as a larva
The offspring of a weasel is referred to as a kit
The offspring of a elephant is referred to as a calf
The offspring of a deer is referred to as a fawn
The offspring of a skunk is referred to as a kit
The offspring of a whale is referred to as a calf
The offspring of a trout is referred to as a fingerling
The offspring of a camel is referred to as a
2024-07-28 00:51:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 00:53:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3906, -0.2827,  0.1255,  ..., -0.0224, -0.3691,  0.2148],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5469, -1.6953, -0.9351,  ...,  0.8599, -3.0254,  0.7393],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.5776e-02, -1.6571e-02,  2.3632e-03,  ...,  1.8585e-02,
         -9.4604e-03, -2.0096e-02],
        [-1.2226e-03,  2.7649e-02,  1.7960e-02,  ...,  3.5801e-03,
          7.2479e-05, -3.0319e-02],
        [-4.3335e-03,  2.3361e-02,  2.5681e-02,  ..., -1.8356e-02,
         -3.9101e-03, -3.1952e-02],
        ...,
        [ 2.4811e-02,  1.6464e-02, -9.0027e-04,  ...,  4.0131e-02,
          1.6891e-02,  1.6159e-02],
        [ 3.0182e-02, -3.0594e-03, -5.5885e-04,  ...,  3.8586e-03,
         -6.7329e-04, -5.1460e-03],
        [-8.3771e-03,  2.0866e-03, -2.4933e-02,  ..., -1.1909e-02,
          2.2369e-02,  4.0985e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4067, -1.1621, -1.3164,  ...,  0.6299, -2.7695,  1.1270]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 00:53:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a insect is referred to as a larva
The offspring of a weasel is referred to as a kit
The offspring of a elephant is referred to as a calf
The offspring of a deer is referred to as a fawn
The offspring of a skunk is referred to as a kit
The offspring of a whale is referred to as a calf
The offspring of a trout is referred to as a fingerling
The offspring of a camel is referred to as a
2024-07-28 00:53:36 root INFO     [order_1_approx] starting weight calculation for The offspring of a weasel is referred to as a kit
The offspring of a skunk is referred to as a kit
The offspring of a camel is referred to as a calf
The offspring of a insect is referred to as a larva
The offspring of a trout is referred to as a fingerling
The offspring of a elephant is referred to as a calf
The offspring of a whale is referred to as a calf
The offspring of a deer is referred to as a
2024-07-28 00:53:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 00:55:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5552,  0.2031,  0.2144,  ...,  0.2791, -0.4800,  0.0170],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0547, -2.1426, -1.6963,  ...,  0.6846, -4.5859, -0.1240],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0267, -0.0292, -0.0090,  ...,  0.0025, -0.0065, -0.0007],
        [ 0.0028,  0.0363,  0.0092,  ..., -0.0039, -0.0061, -0.0212],
        [-0.0031,  0.0184,  0.0294,  ..., -0.0054, -0.0070, -0.0266],
        ...,
        [-0.0142,  0.0136,  0.0137,  ...,  0.0400,  0.0197, -0.0067],
        [ 0.0139,  0.0134, -0.0043,  ..., -0.0015,  0.0276,  0.0082],
        [-0.0032, -0.0090, -0.0168,  ..., -0.0122, -0.0150,  0.0235]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4023, -2.0664, -1.5332,  ...,  0.5962, -4.8672, -0.2178]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 00:55:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a weasel is referred to as a kit
The offspring of a skunk is referred to as a kit
The offspring of a camel is referred to as a calf
The offspring of a insect is referred to as a larva
The offspring of a trout is referred to as a fingerling
The offspring of a elephant is referred to as a calf
The offspring of a whale is referred to as a calf
The offspring of a deer is referred to as a
2024-07-28 00:55:52 root INFO     [order_1_approx] starting weight calculation for The offspring of a camel is referred to as a calf
The offspring of a skunk is referred to as a kit
The offspring of a elephant is referred to as a calf
The offspring of a whale is referred to as a calf
The offspring of a deer is referred to as a fawn
The offspring of a insect is referred to as a larva
The offspring of a weasel is referred to as a kit
The offspring of a trout is referred to as a
2024-07-28 00:55:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 00:58:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0742,  0.0477,  0.0282,  ...,  0.2080, -0.6206, -0.1725],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7031, -2.0117, -5.7344,  ...,  1.0303, -3.3672, -0.2168],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0412, -0.0088, -0.0057,  ...,  0.0081, -0.0087, -0.0228],
        [ 0.0164,  0.0523,  0.0111,  ..., -0.0072,  0.0125, -0.0086],
        [ 0.0012,  0.0025,  0.0187,  ...,  0.0233, -0.0123, -0.0008],
        ...,
        [-0.0130,  0.0079,  0.0054,  ...,  0.0465,  0.0229, -0.0039],
        [ 0.0171, -0.0006,  0.0340,  ...,  0.0321,  0.0447,  0.0020],
        [ 0.0091,  0.0021, -0.0216,  ..., -0.0141, -0.0055,  0.0251]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7324, -1.8418, -5.6094,  ...,  1.1270, -3.4141, -0.4116]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 00:58:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a camel is referred to as a calf
The offspring of a skunk is referred to as a kit
The offspring of a elephant is referred to as a calf
The offspring of a whale is referred to as a calf
The offspring of a deer is referred to as a fawn
The offspring of a insect is referred to as a larva
The offspring of a weasel is referred to as a kit
The offspring of a trout is referred to as a
2024-07-28 00:58:12 root INFO     [order_1_approx] starting weight calculation for The offspring of a camel is referred to as a calf
The offspring of a skunk is referred to as a kit
The offspring of a elephant is referred to as a calf
The offspring of a deer is referred to as a fawn
The offspring of a insect is referred to as a larva
The offspring of a trout is referred to as a fingerling
The offspring of a weasel is referred to as a kit
The offspring of a whale is referred to as a
2024-07-28 00:58:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 01:00:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7300, -0.1965,  0.0359,  ..., -0.1589, -0.4014,  0.0027],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3281, -3.0469, -1.5527,  ..., -1.3057, -4.4688,  2.8691],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0381, -0.0249, -0.0143,  ...,  0.0248,  0.0052, -0.0141],
        [-0.0091,  0.0499,  0.0072,  ..., -0.0185, -0.0061, -0.0177],
        [ 0.0108, -0.0016,  0.0586,  ...,  0.0109, -0.0016, -0.0210],
        ...,
        [ 0.0064, -0.0010,  0.0298,  ...,  0.0370,  0.0227, -0.0138],
        [ 0.0176,  0.0068,  0.0312,  ...,  0.0275,  0.0053, -0.0046],
        [-0.0138, -0.0017, -0.0039,  ..., -0.0315, -0.0071,  0.0312]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5479, -2.8340, -1.9434,  ..., -1.2441, -4.6797,  2.8145]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 01:00:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a camel is referred to as a calf
The offspring of a skunk is referred to as a kit
The offspring of a elephant is referred to as a calf
The offspring of a deer is referred to as a fawn
The offspring of a insect is referred to as a larva
The offspring of a trout is referred to as a fingerling
The offspring of a weasel is referred to as a kit
The offspring of a whale is referred to as a
2024-07-28 01:00:32 root INFO     [order_1_approx] starting weight calculation for The offspring of a camel is referred to as a calf
The offspring of a whale is referred to as a calf
The offspring of a weasel is referred to as a kit
The offspring of a deer is referred to as a fawn
The offspring of a insect is referred to as a larva
The offspring of a elephant is referred to as a calf
The offspring of a trout is referred to as a fingerling
The offspring of a skunk is referred to as a
2024-07-28 01:00:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 01:02:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0526,  0.0883,  0.2228,  ...,  0.3135, -0.6714,  0.0434],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3496, -2.1875, -1.7744,  ...,  0.4053, -2.8477,  1.6494],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0506, -0.0355, -0.0308,  ...,  0.0436, -0.0014, -0.0051],
        [-0.0056,  0.0449, -0.0008,  ..., -0.0108, -0.0139,  0.0065],
        [-0.0023, -0.0024,  0.0456,  ...,  0.0369, -0.0256,  0.0011],
        ...,
        [ 0.0029,  0.0044,  0.0359,  ...,  0.0433,  0.0316, -0.0006],
        [ 0.0128, -0.0201,  0.0397,  ..., -0.0171,  0.0035, -0.0188],
        [-0.0029,  0.0201, -0.0024,  ..., -0.0135, -0.0111,  0.0345]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6426, -1.9590, -2.1934,  ...,  0.5239, -2.8438,  1.1875]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 01:02:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a camel is referred to as a calf
The offspring of a whale is referred to as a calf
The offspring of a weasel is referred to as a kit
The offspring of a deer is referred to as a fawn
The offspring of a insect is referred to as a larva
The offspring of a elephant is referred to as a calf
The offspring of a trout is referred to as a fingerling
The offspring of a skunk is referred to as a
2024-07-28 01:02:51 root INFO     total operator prediction time: 1111.3026733398438 seconds
2024-07-28 01:02:51 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - sound
2024-07-28 01:02:51 root INFO     building operator animal - sound
2024-07-28 01:02:51 root INFO     [order_1_approx] starting weight calculation for The sound that a hyena makes is called a laugh
The sound that a leopard makes is called a growl
The sound that a sheep makes is called a baa
The sound that a raven makes is called a caw
The sound that a fox makes is called a howl
The sound that a dog makes is called a bark
The sound that a coyote makes is called a howl
The sound that a cricket makes is called a
2024-07-28 01:02:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 01:05:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2654,  0.3691,  0.2463,  ...,  0.0650, -0.0527, -0.2620],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8687, -1.7500,  3.3125,  ..., -0.3706, -0.3252,  1.1904],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0717, -0.0270, -0.0022,  ..., -0.0013, -0.0222, -0.0014],
        [-0.0020,  0.0534, -0.0032,  ...,  0.0088,  0.0017, -0.0334],
        [ 0.0090,  0.0195,  0.0652,  ..., -0.0051, -0.0115, -0.0107],
        ...,
        [ 0.0121, -0.0114,  0.0093,  ...,  0.0839,  0.0059, -0.0330],
        [-0.0057,  0.0208,  0.0297,  ..., -0.0274,  0.0586, -0.0081],
        [-0.0255,  0.0113, -0.0172,  ..., -0.0162, -0.0144,  0.0598]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5786, -1.8174,  2.9180,  ..., -0.4485, -0.3359,  1.1670]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 01:05:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a hyena makes is called a laugh
The sound that a leopard makes is called a growl
The sound that a sheep makes is called a baa
The sound that a raven makes is called a caw
The sound that a fox makes is called a howl
The sound that a dog makes is called a bark
The sound that a coyote makes is called a howl
The sound that a cricket makes is called a
2024-07-28 01:05:10 root INFO     [order_1_approx] starting weight calculation for The sound that a raven makes is called a caw
The sound that a coyote makes is called a howl
The sound that a hyena makes is called a laugh
The sound that a fox makes is called a howl
The sound that a cricket makes is called a chirp
The sound that a sheep makes is called a baa
The sound that a dog makes is called a bark
The sound that a leopard makes is called a
2024-07-28 01:05:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 01:07:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0668, -0.0461, -0.0090,  ...,  0.4487, -0.3699, -0.0912],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6406, -4.7539, -1.3105,  ..., -2.4766, -0.9697,  1.5654],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0222,  0.0067, -0.0003,  ..., -0.0101, -0.0249,  0.0004],
        [ 0.0060,  0.0177,  0.0065,  ..., -0.0085,  0.0219, -0.0046],
        [-0.0103,  0.0021,  0.0097,  ..., -0.0195,  0.0057,  0.0103],
        ...,
        [ 0.0049,  0.0100,  0.0092,  ...,  0.0308,  0.0131, -0.0158],
        [ 0.0022, -0.0041, -0.0055,  ..., -0.0160,  0.0139,  0.0102],
        [-0.0048, -0.0068, -0.0208,  ..., -0.0263,  0.0031,  0.0088]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5781, -4.7305, -1.2500,  ..., -2.4121, -1.0439,  1.4395]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 01:07:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a raven makes is called a caw
The sound that a coyote makes is called a howl
The sound that a hyena makes is called a laugh
The sound that a fox makes is called a howl
The sound that a cricket makes is called a chirp
The sound that a sheep makes is called a baa
The sound that a dog makes is called a bark
The sound that a leopard makes is called a
2024-07-28 01:07:32 root INFO     [order_1_approx] starting weight calculation for The sound that a fox makes is called a howl
The sound that a leopard makes is called a growl
The sound that a sheep makes is called a baa
The sound that a cricket makes is called a chirp
The sound that a hyena makes is called a laugh
The sound that a raven makes is called a caw
The sound that a coyote makes is called a howl
The sound that a dog makes is called a
2024-07-28 01:07:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 01:09:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1779,  0.1272,  0.2032,  ...,  0.1129, -0.3386,  0.1206],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3594, -5.6875,  2.1445,  ..., -3.2246, -0.1416,  3.5254],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.8091e-02, -1.7426e-02,  6.6261e-03,  ..., -2.0477e-02,
         -2.3331e-02,  2.5101e-03],
        [-9.3460e-03,  3.4668e-02, -3.7003e-03,  ..., -2.4414e-03,
          1.6968e-02, -1.4847e-02],
        [ 1.3351e-02,  1.8845e-03,  5.9998e-02,  ..., -1.7532e-02,
         -1.2035e-03, -1.7319e-02],
        ...,
        [-6.0310e-03,  9.9258e-03, -2.6207e-03,  ...,  5.6946e-02,
         -1.9989e-03,  3.5973e-03],
        [-5.4626e-03,  2.4506e-02, -8.0261e-03,  ...,  4.3884e-02,
          2.4765e-02, -3.7670e-05],
        [-2.2774e-03, -3.0701e-02, -8.6441e-03,  ..., -1.2581e-02,
          1.4553e-03,  3.0350e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4656, -5.3672,  2.1797,  ..., -3.5215, -0.3369,  3.5117]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 01:09:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a fox makes is called a howl
The sound that a leopard makes is called a growl
The sound that a sheep makes is called a baa
The sound that a cricket makes is called a chirp
The sound that a hyena makes is called a laugh
The sound that a raven makes is called a caw
The sound that a coyote makes is called a howl
The sound that a dog makes is called a
2024-07-28 01:09:53 root INFO     [order_1_approx] starting weight calculation for The sound that a cricket makes is called a chirp
The sound that a dog makes is called a bark
The sound that a leopard makes is called a growl
The sound that a hyena makes is called a laugh
The sound that a coyote makes is called a howl
The sound that a fox makes is called a howl
The sound that a sheep makes is called a baa
The sound that a raven makes is called a
2024-07-28 01:09:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 01:12:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2472, -0.0255,  0.1676,  ...,  0.4280, -0.4395, -0.1348],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9102, -4.0625,  2.0898,  ..., -2.5508,  0.0000,  2.5176],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.4413e-02, -5.4131e-03,  1.3809e-03,  ..., -1.8463e-02,
         -4.3182e-02, -1.6068e-02],
        [-2.9617e-02,  4.2786e-02,  6.5193e-03,  ...,  2.1378e-02,
          3.0457e-02, -4.4800e-02],
        [-3.2330e-04, -1.5717e-02,  6.8726e-02,  ..., -1.3107e-02,
         -3.5400e-02, -1.9257e-02],
        ...,
        [ 1.7487e-02,  5.3406e-05, -1.4801e-03,  ...,  6.4270e-02,
          1.4496e-02, -2.4429e-02],
        [-3.9398e-02, -5.9357e-03, -1.1108e-02,  ...,  7.7019e-03,
          3.3325e-02, -2.2278e-02],
        [ 1.7395e-02, -7.2250e-03, -1.2054e-03,  ..., -1.4328e-02,
         -1.1215e-02,  4.4922e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5391, -3.9551,  1.9434,  ..., -3.1348, -0.4224,  2.3652]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 01:12:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a cricket makes is called a chirp
The sound that a dog makes is called a bark
The sound that a leopard makes is called a growl
The sound that a hyena makes is called a laugh
The sound that a coyote makes is called a howl
The sound that a fox makes is called a howl
The sound that a sheep makes is called a baa
The sound that a raven makes is called a
2024-07-28 01:12:11 root INFO     [order_1_approx] starting weight calculation for The sound that a coyote makes is called a howl
The sound that a raven makes is called a caw
The sound that a leopard makes is called a growl
The sound that a dog makes is called a bark
The sound that a hyena makes is called a laugh
The sound that a cricket makes is called a chirp
The sound that a sheep makes is called a baa
The sound that a fox makes is called a
2024-07-28 01:12:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 01:14:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3633,  0.1505,  0.2915,  ...,  0.1975, -0.2235, -0.2368],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9043, -4.8750, -0.0859,  ..., -2.5137, -1.2783,  4.1211],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0330,  0.0089, -0.0014,  ..., -0.0017, -0.0191, -0.0107],
        [-0.0224,  0.0588,  0.0029,  ..., -0.0096,  0.0104, -0.0461],
        [ 0.0171, -0.0273,  0.0463,  ..., -0.0468, -0.0016, -0.0083],
        ...,
        [ 0.0069, -0.0072,  0.0083,  ...,  0.0457,  0.0266, -0.0235],
        [-0.0101,  0.0053,  0.0093,  ...,  0.0126,  0.0421, -0.0018],
        [ 0.0102, -0.0161, -0.0275,  ..., -0.0229, -0.0171,  0.0136]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0918, -4.4570,  0.2500,  ..., -2.7559, -1.5537,  3.7949]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 01:14:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a coyote makes is called a howl
The sound that a raven makes is called a caw
The sound that a leopard makes is called a growl
The sound that a dog makes is called a bark
The sound that a hyena makes is called a laugh
The sound that a cricket makes is called a chirp
The sound that a sheep makes is called a baa
The sound that a fox makes is called a
2024-07-28 01:14:32 root INFO     [order_1_approx] starting weight calculation for The sound that a cricket makes is called a chirp
The sound that a leopard makes is called a growl
The sound that a raven makes is called a caw
The sound that a dog makes is called a bark
The sound that a coyote makes is called a howl
The sound that a fox makes is called a howl
The sound that a sheep makes is called a baa
The sound that a hyena makes is called a
2024-07-28 01:14:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 01:16:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3530, -0.0795,  0.6440,  ...,  0.6333, -0.4873, -0.1758],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9136, -3.8750,  2.4492,  ..., -1.5254, -1.0303,  0.3838],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0609, -0.0059,  0.0112,  ...,  0.0005, -0.0336, -0.0160],
        [-0.0197,  0.0309, -0.0105,  ..., -0.0077,  0.0158, -0.0115],
        [-0.0042,  0.0256,  0.0667,  ..., -0.0816, -0.0201, -0.0274],
        ...,
        [ 0.0118,  0.0193,  0.0285,  ...,  0.0656,  0.0271,  0.0089],
        [-0.0056, -0.0049, -0.0043,  ..., -0.0245,  0.0409, -0.0004],
        [-0.0115, -0.0298, -0.0279,  ..., -0.0062, -0.0128,  0.0365]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3018, -3.3027,  2.3418,  ..., -1.1191, -1.1650, -0.1270]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 01:16:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a cricket makes is called a chirp
The sound that a leopard makes is called a growl
The sound that a raven makes is called a caw
The sound that a dog makes is called a bark
The sound that a coyote makes is called a howl
The sound that a fox makes is called a howl
The sound that a sheep makes is called a baa
The sound that a hyena makes is called a
2024-07-28 01:16:48 root INFO     [order_1_approx] starting weight calculation for The sound that a fox makes is called a howl
The sound that a leopard makes is called a growl
The sound that a hyena makes is called a laugh
The sound that a raven makes is called a caw
The sound that a sheep makes is called a baa
The sound that a dog makes is called a bark
The sound that a cricket makes is called a chirp
The sound that a coyote makes is called a
2024-07-28 01:16:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 01:19:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0041,  0.0232, -0.0996,  ...,  0.2966, -0.6016, -0.2057],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0684, -5.1172, -0.1309,  ..., -2.5547, -0.2478,  1.9785],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0302, -0.0117, -0.0039,  ..., -0.0169, -0.0189,  0.0032],
        [-0.0173,  0.0286, -0.0053,  ..., -0.0008,  0.0210, -0.0277],
        [ 0.0107,  0.0038,  0.0309,  ..., -0.0310, -0.0262, -0.0037],
        ...,
        [ 0.0006,  0.0021,  0.0086,  ...,  0.0578,  0.0058, -0.0037],
        [ 0.0113, -0.0146, -0.0006,  ..., -0.0112,  0.0199, -0.0151],
        [-0.0051, -0.0115, -0.0271,  ..., -0.0170, -0.0077,  0.0126]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1191, -4.7812,  0.0248,  ..., -2.7266, -0.0962,  1.8740]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 01:19:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a fox makes is called a howl
The sound that a leopard makes is called a growl
The sound that a hyena makes is called a laugh
The sound that a raven makes is called a caw
The sound that a sheep makes is called a baa
The sound that a dog makes is called a bark
The sound that a cricket makes is called a chirp
The sound that a coyote makes is called a
2024-07-28 01:19:10 root INFO     [order_1_approx] starting weight calculation for The sound that a raven makes is called a caw
The sound that a cricket makes is called a chirp
The sound that a leopard makes is called a growl
The sound that a dog makes is called a bark
The sound that a fox makes is called a howl
The sound that a coyote makes is called a howl
The sound that a hyena makes is called a laugh
The sound that a sheep makes is called a
2024-07-28 01:19:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 01:21:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0602, -0.2241,  0.2512,  ...,  0.1632, -0.3296,  0.5747],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1069, -0.4060,  3.1602,  ...,  0.0312, -0.0752, -0.1143],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0638, -0.0150,  0.0010,  ..., -0.0124, -0.0339, -0.0026],
        [-0.0191,  0.0457, -0.0119,  ...,  0.0088,  0.0280, -0.0322],
        [-0.0099,  0.0003,  0.0476,  ..., -0.0123, -0.0307, -0.0168],
        ...,
        [ 0.0179,  0.0311,  0.0212,  ...,  0.0641,  0.0021, -0.0257],
        [ 0.0060,  0.0275, -0.0050,  ...,  0.0204,  0.0370, -0.0016],
        [ 0.0039, -0.0021, -0.0061,  ..., -0.0132,  0.0038,  0.0414]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3792, -0.0667,  3.0098,  ..., -0.4087, -0.5479, -0.2263]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 01:21:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a raven makes is called a caw
The sound that a cricket makes is called a chirp
The sound that a leopard makes is called a growl
The sound that a dog makes is called a bark
The sound that a fox makes is called a howl
The sound that a coyote makes is called a howl
The sound that a hyena makes is called a laugh
The sound that a sheep makes is called a
2024-07-28 01:21:31 root INFO     total operator prediction time: 1119.8501017093658 seconds
2024-07-28 01:21:31 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on things - color
2024-07-28 01:21:31 root INFO     building operator things - color
2024-07-28 01:21:31 root INFO     [order_1_approx] starting weight calculation for The sun is colored yellow
The cherry is colored red
The tea is colored black
The peony is colored red
The toothpaste is colored white
The pepper is colored black
The cranberry is colored red
The cream is colored
2024-07-28 01:21:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 01:23:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2050, -0.2920,  0.1556,  ..., -0.1195, -0.2593,  0.1763],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.2656, -4.8125,  2.4551,  ..., -1.7930, -0.8267,  0.4883],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0460,  0.0188,  0.0080,  ..., -0.0014, -0.0144,  0.0262],
        [ 0.0129,  0.0322,  0.0141,  ...,  0.0043,  0.0123, -0.0046],
        [-0.0100, -0.0001,  0.0406,  ...,  0.0077, -0.0055,  0.0180],
        ...,
        [ 0.0140,  0.0009, -0.0110,  ...,  0.0509,  0.0035, -0.0109],
        [ 0.0069, -0.0010, -0.0161,  ...,  0.0126,  0.0266,  0.0134],
        [-0.0056,  0.0052, -0.0023,  ..., -0.0054, -0.0048,  0.0266]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.2490, -4.6094,  2.2383,  ..., -1.5781, -0.9321,  0.4607]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 01:23:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sun is colored yellow
The cherry is colored red
The tea is colored black
The peony is colored red
The toothpaste is colored white
The pepper is colored black
The cranberry is colored red
The cream is colored
2024-07-28 01:23:54 root INFO     [order_1_approx] starting weight calculation for The cherry is colored red
The cream is colored white
The pepper is colored black
The tea is colored black
The peony is colored red
The sun is colored yellow
The toothpaste is colored white
The cranberry is colored
2024-07-28 01:23:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 01:26:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5474, -0.7026, -0.6089,  ...,  0.1164, -0.4631, -0.1741],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-4.5469, -7.0156, -1.2568,  ..., -1.9346,  0.7188, -0.4141],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0677,  0.0038, -0.0100,  ..., -0.0162,  0.0158,  0.0001],
        [-0.0054,  0.0411,  0.0225,  ...,  0.0132,  0.0263, -0.0126],
        [ 0.0041, -0.0013,  0.0475,  ...,  0.0103, -0.0192,  0.0082],
        ...,
        [ 0.0112, -0.0019, -0.0004,  ...,  0.0735, -0.0047, -0.0003],
        [-0.0018, -0.0078, -0.0003,  ...,  0.0343,  0.0344,  0.0110],
        [-0.0106, -0.0061, -0.0030,  ..., -0.0090, -0.0238,  0.0445]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-4.5352, -6.9570, -0.9531,  ..., -1.5859,  0.2603, -0.2089]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 01:26:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The cherry is colored red
The cream is colored white
The pepper is colored black
The tea is colored black
The peony is colored red
The sun is colored yellow
The toothpaste is colored white
The cranberry is colored
2024-07-28 01:26:16 root INFO     [order_1_approx] starting weight calculation for The cranberry is colored red
The cream is colored white
The sun is colored yellow
The pepper is colored black
The tea is colored black
The cherry is colored red
The peony is colored red
The toothpaste is colored
2024-07-28 01:26:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 01:28:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1061, -0.4741, -0.1338,  ..., -0.0832, -0.3040, -0.0134],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.1680, -2.5020, -0.0132,  ...,  0.9385, -3.2852, -0.5518],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0623,  0.0217,  0.0133,  ...,  0.0061, -0.0127, -0.0007],
        [ 0.0258,  0.0497,  0.0115,  ...,  0.0121, -0.0061, -0.0011],
        [-0.0078, -0.0111,  0.0504,  ...,  0.0069, -0.0236,  0.0135],
        ...,
        [ 0.0106,  0.0184, -0.0033,  ...,  0.0463, -0.0135,  0.0018],
        [ 0.0140,  0.0090, -0.0092,  ...,  0.0209,  0.0456, -0.0210],
        [-0.0040, -0.0131,  0.0081,  ..., -0.0007, -0.0067,  0.0425]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.8887, -2.7500, -0.1421,  ...,  1.1445, -3.5391, -0.5684]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 01:28:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The cranberry is colored red
The cream is colored white
The sun is colored yellow
The pepper is colored black
The tea is colored black
The cherry is colored red
The peony is colored red
The toothpaste is colored
2024-07-28 01:28:38 root INFO     [order_1_approx] starting weight calculation for The sun is colored yellow
The cherry is colored red
The peony is colored red
The cream is colored white
The pepper is colored black
The toothpaste is colored white
The cranberry is colored red
The tea is colored
2024-07-28 01:28:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 01:30:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2522, -0.2812,  0.0817,  ..., -0.2305, -0.0073, -0.0510],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.6875, -3.2637, -1.5322,  ..., -2.9922, -0.4058,  0.3877],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0471,  0.0219,  0.0161,  ..., -0.0041, -0.0008,  0.0149],
        [-0.0018,  0.0439,  0.0131,  ...,  0.0109,  0.0034, -0.0006],
        [-0.0132, -0.0084,  0.0331,  ...,  0.0206, -0.0027,  0.0123],
        ...,
        [ 0.0061,  0.0023, -0.0062,  ...,  0.0439, -0.0008, -0.0111],
        [ 0.0057,  0.0102, -0.0284,  ...,  0.0231,  0.0471, -0.0049],
        [-0.0325, -0.0257, -0.0032,  ..., -0.0017,  0.0118,  0.0334]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.9072, -3.6855, -1.4268,  ..., -2.8496, -0.4731,  0.1682]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 01:30:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sun is colored yellow
The cherry is colored red
The peony is colored red
The cream is colored white
The pepper is colored black
The toothpaste is colored white
The cranberry is colored red
The tea is colored
2024-07-28 01:30:58 root INFO     [order_1_approx] starting weight calculation for The cranberry is colored red
The tea is colored black
The cream is colored white
The cherry is colored red
The peony is colored red
The pepper is colored black
The toothpaste is colored white
The sun is colored
2024-07-28 01:30:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 01:33:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2112, -0.1836,  0.0948,  ...,  0.1927,  0.0358,  0.0309],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-3.2578, -7.4453,  0.0364,  ..., -1.5566, -1.3145, -0.6572],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0626,  0.0003, -0.0079,  ..., -0.0125,  0.0002,  0.0006],
        [ 0.0195,  0.0557,  0.0092,  ...,  0.0022,  0.0160, -0.0128],
        [-0.0045, -0.0060,  0.0515,  ..., -0.0023,  0.0111,  0.0239],
        ...,
        [-0.0128,  0.0079,  0.0203,  ...,  0.0629,  0.0014, -0.0134],
        [-0.0058, -0.0083,  0.0176,  ...,  0.0117,  0.0399,  0.0031],
        [-0.0041, -0.0231,  0.0175,  ...,  0.0142, -0.0179,  0.0431]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-3.2344, -7.4531, -0.1138,  ..., -1.3389, -1.3535, -0.7637]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 01:33:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The cranberry is colored red
The tea is colored black
The cream is colored white
The cherry is colored red
The peony is colored red
The pepper is colored black
The toothpaste is colored white
The sun is colored
2024-07-28 01:33:21 root INFO     [order_1_approx] starting weight calculation for The peony is colored red
The sun is colored yellow
The cranberry is colored red
The tea is colored black
The toothpaste is colored white
The pepper is colored black
The cream is colored white
The cherry is colored
2024-07-28 01:33:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 01:35:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0390, -0.6514, -0.1976,  ...,  0.0291, -0.4368,  0.0098],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.1230, -7.3906, -2.5391,  ..., -1.8555,  0.9214, -1.6309],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0495,  0.0129, -0.0066,  ..., -0.0089,  0.0148,  0.0174],
        [-0.0127,  0.0427,  0.0101,  ...,  0.0239,  0.0258, -0.0123],
        [ 0.0114,  0.0047,  0.0484,  ...,  0.0130, -0.0076, -0.0016],
        ...,
        [ 0.0126,  0.0020, -0.0086,  ...,  0.0667, -0.0047, -0.0024],
        [ 0.0063, -0.0130, -0.0110,  ...,  0.0207,  0.0312, -0.0183],
        [-0.0079, -0.0200, -0.0084,  ..., -0.0068, -0.0257,  0.0496]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.0312, -7.1562, -2.4648,  ..., -1.5723,  0.5977, -1.4678]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 01:35:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The peony is colored red
The sun is colored yellow
The cranberry is colored red
The tea is colored black
The toothpaste is colored white
The pepper is colored black
The cream is colored white
The cherry is colored
2024-07-28 01:35:42 root INFO     [order_1_approx] starting weight calculation for The toothpaste is colored white
The sun is colored yellow
The cream is colored white
The pepper is colored black
The cranberry is colored red
The cherry is colored red
The tea is colored black
The peony is colored
2024-07-28 01:35:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 01:38:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1499, -0.0219, -0.4905,  ...,  0.1857, -0.2581, -0.0510],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.5508, -4.2227,  1.8730,  ...,  0.1279, -2.7559,  0.9297],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0705, -0.0005,  0.0003,  ..., -0.0014,  0.0142,  0.0120],
        [ 0.0050,  0.0457,  0.0254,  ...,  0.0007,  0.0034, -0.0118],
        [-0.0054,  0.0027,  0.0561,  ...,  0.0150, -0.0085,  0.0121],
        ...,
        [ 0.0075,  0.0032, -0.0008,  ...,  0.0554, -0.0207, -0.0080],
        [-0.0002, -0.0064, -0.0055,  ...,  0.0118,  0.0714, -0.0127],
        [-0.0215, -0.0039, -0.0067,  ..., -0.0035, -0.0053,  0.0421]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.5547, -4.2773,  1.6270,  ...,  0.3696, -2.7031,  0.9751]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 01:38:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The toothpaste is colored white
The sun is colored yellow
The cream is colored white
The pepper is colored black
The cranberry is colored red
The cherry is colored red
The tea is colored black
The peony is colored
2024-07-28 01:38:04 root INFO     [order_1_approx] starting weight calculation for The cherry is colored red
The peony is colored red
The sun is colored yellow
The tea is colored black
The toothpaste is colored white
The cranberry is colored red
The cream is colored white
The pepper is colored
2024-07-28 01:38:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 01:40:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4072,  0.1353, -0.4355,  ...,  0.0010, -0.1970, -0.0079],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.7256, -6.3984, -1.9199,  ..., -1.8564, -1.2285, -2.2695],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0874,  0.0300,  0.0094,  ..., -0.0311,  0.0230, -0.0007],
        [ 0.0305,  0.0894,  0.0319,  ..., -0.0052,  0.0251, -0.0025],
        [-0.0035, -0.0368,  0.0603,  ...,  0.0161, -0.0217,  0.0103],
        ...,
        [ 0.0278,  0.0182,  0.0291,  ...,  0.0703,  0.0037, -0.0052],
        [ 0.0418,  0.0134, -0.0371,  ...,  0.0145,  0.0706, -0.0194],
        [ 0.0030,  0.0036, -0.0092,  ..., -0.0131, -0.0099,  0.0229]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.6875, -6.3711, -2.2422,  ..., -2.2695, -0.8804, -2.0039]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 01:40:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The cherry is colored red
The peony is colored red
The sun is colored yellow
The tea is colored black
The toothpaste is colored white
The cranberry is colored red
The cream is colored white
The pepper is colored
2024-07-28 01:40:25 root INFO     total operator prediction time: 1134.2827072143555 seconds
2024-07-28 01:40:25 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on country - capital
2024-07-28 01:40:25 root INFO     building operator country - capital
2024-07-28 01:40:26 root INFO     [order_1_approx] starting weight calculation for The country with bangkok as its capital is known as thailand
The country with stockholm as its capital is known as sweden
The country with copenhagen as its capital is known as denmark
The country with tokyo as its capital is known as japan
The country with madrid as its capital is known as spain
The country with athens as its capital is known as greece
The country with canberra as its capital is known as australia
The country with kingston as its capital is known as
2024-07-28 01:40:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 01:42:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1426,  0.0870, -0.2432,  ...,  0.1987,  0.2930, -0.0310],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.3438, -3.2656, -0.4170,  ..., -0.0104,  0.2666, -2.3496],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0405,  0.0043,  0.0005,  ...,  0.0036, -0.0197,  0.0142],
        [ 0.0075,  0.0374,  0.0647,  ..., -0.0305, -0.0177, -0.0053],
        [ 0.0138, -0.0092,  0.0832,  ...,  0.0056, -0.0035, -0.0102],
        ...,
        [ 0.0061, -0.0094,  0.0152,  ...,  0.0735, -0.0162, -0.0008],
        [-0.0087,  0.0059, -0.0232,  ..., -0.0057,  0.0307,  0.0028],
        [-0.0193, -0.0096,  0.0323,  ..., -0.0227, -0.0102,  0.0057]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.6523, -3.4336, -0.9111,  ..., -0.3296,  0.2700, -2.4395]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 01:42:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with bangkok as its capital is known as thailand
The country with stockholm as its capital is known as sweden
The country with copenhagen as its capital is known as denmark
The country with tokyo as its capital is known as japan
The country with madrid as its capital is known as spain
The country with athens as its capital is known as greece
The country with canberra as its capital is known as australia
The country with kingston as its capital is known as
2024-07-28 01:42:45 root INFO     [order_1_approx] starting weight calculation for The country with canberra as its capital is known as australia
The country with tokyo as its capital is known as japan
The country with stockholm as its capital is known as sweden
The country with athens as its capital is known as greece
The country with kingston as its capital is known as jamaica
The country with madrid as its capital is known as spain
The country with bangkok as its capital is known as thailand
The country with copenhagen as its capital is known as
2024-07-28 01:42:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 01:45:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0407, -0.1455, -0.6787,  ...,  0.2062,  0.3606, -0.3032],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2227, -5.0156,  1.3340,  ..., -2.7988, -1.0039, -4.9766],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.7273e-02, -3.2425e-05, -1.0773e-02,  ..., -3.0785e-03,
         -5.8517e-03, -4.4670e-03],
        [ 6.1264e-03,  1.8921e-02,  3.0823e-03,  ..., -3.2520e-03,
          3.1548e-03, -1.0063e-02],
        [-4.4785e-03,  4.6082e-03,  3.2501e-02,  ...,  1.3596e-02,
         -9.1934e-04, -1.6907e-02],
        ...,
        [-2.5120e-03,  1.2024e-02,  3.6526e-03,  ...,  2.4918e-02,
          7.7362e-03, -2.9240e-03],
        [ 2.3441e-03,  2.2545e-03, -9.4528e-03,  ...,  2.1896e-03,
          8.3694e-03, -2.0714e-03],
        [-1.3359e-02, -7.4158e-03, -7.4692e-03,  ...,  7.9041e-03,
         -7.6599e-03,  9.4452e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0996, -4.9688,  1.4150,  ..., -2.6094, -1.0781, -4.7695]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 01:45:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with canberra as its capital is known as australia
The country with tokyo as its capital is known as japan
The country with stockholm as its capital is known as sweden
The country with athens as its capital is known as greece
The country with kingston as its capital is known as jamaica
The country with madrid as its capital is known as spain
The country with bangkok as its capital is known as thailand
The country with copenhagen as its capital is known as
2024-07-28 01:45:03 root INFO     [order_1_approx] starting weight calculation for The country with bangkok as its capital is known as thailand
The country with madrid as its capital is known as spain
The country with tokyo as its capital is known as japan
The country with canberra as its capital is known as australia
The country with copenhagen as its capital is known as denmark
The country with athens as its capital is known as greece
The country with kingston as its capital is known as jamaica
The country with stockholm as its capital is known as
2024-07-28 01:45:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 01:47:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5117, -0.1807, -0.5063,  ...,  0.3733,  0.3228,  0.1714],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9883, -6.0781, -2.1465,  ..., -1.1465, -1.4561, -3.2695],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0369, -0.0008, -0.0070,  ...,  0.0040,  0.0016,  0.0090],
        [ 0.0009,  0.0198,  0.0189,  ...,  0.0077, -0.0042, -0.0146],
        [-0.0076,  0.0017,  0.0389,  ...,  0.0141,  0.0087, -0.0106],
        ...,
        [-0.0072,  0.0121,  0.0157,  ...,  0.0493,  0.0108, -0.0181],
        [ 0.0033,  0.0062, -0.0219,  ...,  0.0078,  0.0073,  0.0030],
        [-0.0193, -0.0074, -0.0040,  ...,  0.0078, -0.0188,  0.0247]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8594, -5.9570, -2.2324,  ..., -0.9009, -1.1768, -3.0547]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 01:47:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with bangkok as its capital is known as thailand
The country with madrid as its capital is known as spain
The country with tokyo as its capital is known as japan
The country with canberra as its capital is known as australia
The country with copenhagen as its capital is known as denmark
The country with athens as its capital is known as greece
The country with kingston as its capital is known as jamaica
The country with stockholm as its capital is known as
2024-07-28 01:47:17 root INFO     [order_1_approx] starting weight calculation for The country with tokyo as its capital is known as japan
The country with madrid as its capital is known as spain
The country with stockholm as its capital is known as sweden
The country with kingston as its capital is known as jamaica
The country with athens as its capital is known as greece
The country with copenhagen as its capital is known as denmark
The country with bangkok as its capital is known as thailand
The country with canberra as its capital is known as
2024-07-28 01:47:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 01:49:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2847, -0.1670, -0.6128,  ...,  0.4421,  0.0381, -0.1317],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8945, -4.2500,  2.0156,  ..., -1.9414, -1.9688, -1.7715],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0169, -0.0047, -0.0122,  ...,  0.0166, -0.0084,  0.0031],
        [-0.0059,  0.0210,  0.0013,  ..., -0.0122,  0.0003, -0.0101],
        [-0.0076,  0.0048,  0.0251,  ...,  0.0166, -0.0004, -0.0022],
        ...,
        [ 0.0027,  0.0075,  0.0030,  ...,  0.0226,  0.0070, -0.0123],
        [-0.0044,  0.0086,  0.0036,  ..., -0.0073,  0.0052, -0.0036],
        [-0.0114,  0.0025, -0.0043,  ..., -0.0015, -0.0074,  0.0192]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7520, -4.3008,  1.8281,  ..., -1.9326, -2.0938, -1.7617]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 01:49:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with tokyo as its capital is known as japan
The country with madrid as its capital is known as spain
The country with stockholm as its capital is known as sweden
The country with kingston as its capital is known as jamaica
The country with athens as its capital is known as greece
The country with copenhagen as its capital is known as denmark
The country with bangkok as its capital is known as thailand
The country with canberra as its capital is known as
2024-07-28 01:49:34 root INFO     [order_1_approx] starting weight calculation for The country with bangkok as its capital is known as thailand
The country with kingston as its capital is known as jamaica
The country with canberra as its capital is known as australia
The country with athens as its capital is known as greece
The country with copenhagen as its capital is known as denmark
The country with tokyo as its capital is known as japan
The country with stockholm as its capital is known as sweden
The country with madrid as its capital is known as
2024-07-28 01:49:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 01:51:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4973, -0.3362, -0.6870,  ...,  0.7349,  0.4075,  0.0059],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2598, -4.7734, -2.2598,  ...,  0.8765,  0.9541, -5.1602],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0286,  0.0036, -0.0195,  ...,  0.0112, -0.0152,  0.0111],
        [ 0.0002,  0.0260,  0.0202,  ..., -0.0060, -0.0049, -0.0100],
        [-0.0008,  0.0155,  0.0497,  ...,  0.0156,  0.0188, -0.0133],
        ...,
        [-0.0002,  0.0158,  0.0030,  ...,  0.0289,  0.0184, -0.0168],
        [ 0.0138, -0.0005, -0.0074,  ..., -0.0094,  0.0037, -0.0053],
        [-0.0120, -0.0085,  0.0069,  ...,  0.0140, -0.0057,  0.0092]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2539, -4.6016, -2.5449,  ...,  0.6396,  1.1592, -4.9141]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 01:51:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with bangkok as its capital is known as thailand
The country with kingston as its capital is known as jamaica
The country with canberra as its capital is known as australia
The country with athens as its capital is known as greece
The country with copenhagen as its capital is known as denmark
The country with tokyo as its capital is known as japan
The country with stockholm as its capital is known as sweden
The country with madrid as its capital is known as
2024-07-28 01:51:55 root INFO     [order_1_approx] starting weight calculation for The country with copenhagen as its capital is known as denmark
The country with bangkok as its capital is known as thailand
The country with athens as its capital is known as greece
The country with kingston as its capital is known as jamaica
The country with canberra as its capital is known as australia
The country with stockholm as its capital is known as sweden
The country with madrid as its capital is known as spain
The country with tokyo as its capital is known as
2024-07-28 01:51:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 01:54:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3540, -0.0874, -0.0693,  ...,  0.2837,  0.1337, -0.0668],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0352, -4.7852, -0.5947,  ...,  0.4072,  0.9678, -2.6172],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0091,  0.0045, -0.0077,  ...,  0.0012, -0.0084,  0.0067],
        [-0.0021,  0.0152,  0.0040,  ..., -0.0028,  0.0041, -0.0102],
        [ 0.0052,  0.0121,  0.0300,  ...,  0.0144, -0.0016, -0.0074],
        ...,
        [ 0.0004,  0.0134,  0.0068,  ...,  0.0264,  0.0087, -0.0206],
        [ 0.0087, -0.0119, -0.0037,  ..., -0.0005,  0.0084, -0.0023],
        [-0.0046, -0.0005,  0.0013,  ...,  0.0031, -0.0083,  0.0095]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8965, -4.5000, -0.9844,  ...,  0.4622,  1.0205, -2.5234]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 01:54:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with copenhagen as its capital is known as denmark
The country with bangkok as its capital is known as thailand
The country with athens as its capital is known as greece
The country with kingston as its capital is known as jamaica
The country with canberra as its capital is known as australia
The country with stockholm as its capital is known as sweden
The country with madrid as its capital is known as spain
The country with tokyo as its capital is known as
2024-07-28 01:54:14 root INFO     [order_1_approx] starting weight calculation for The country with copenhagen as its capital is known as denmark
The country with madrid as its capital is known as spain
The country with canberra as its capital is known as australia
The country with tokyo as its capital is known as japan
The country with kingston as its capital is known as jamaica
The country with bangkok as its capital is known as thailand
The country with stockholm as its capital is known as sweden
The country with athens as its capital is known as
2024-07-28 01:54:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 01:56:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4697, -0.1367, -0.6572,  ...,  0.5059,  0.0692, -0.4058],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9980, -5.4453, -3.0879,  ...,  0.0737,  1.3525, -2.9258],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.3173e-02, -3.8242e-04, -1.1810e-02,  ...,  3.9101e-04,
         -7.9117e-03, -5.8556e-04],
        [-3.9902e-03,  2.2766e-02,  1.0002e-02,  ..., -8.7738e-05,
          8.0824e-04, -1.9531e-02],
        [-1.3268e-02,  2.0657e-03,  5.0018e-02,  ...,  7.8430e-03,
         -2.0065e-03, -1.1047e-02],
        ...,
        [-9.1095e-03,  4.9515e-03,  1.3336e-02,  ...,  3.3997e-02,
          1.7365e-02, -1.3985e-02],
        [ 2.5101e-03, -3.7537e-03, -1.0399e-02,  ...,  5.6419e-03,
          2.0874e-02, -3.1357e-03],
        [-1.6861e-02, -3.7155e-03, -4.9362e-03,  ...,  3.1605e-03,
         -1.9455e-03,  1.3016e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0449, -5.5273, -2.9648,  ...,  0.0141,  1.2305, -2.4219]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 01:56:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with copenhagen as its capital is known as denmark
The country with madrid as its capital is known as spain
The country with canberra as its capital is known as australia
The country with tokyo as its capital is known as japan
The country with kingston as its capital is known as jamaica
The country with bangkok as its capital is known as thailand
The country with stockholm as its capital is known as sweden
The country with athens as its capital is known as
2024-07-28 01:56:33 root INFO     [order_1_approx] starting weight calculation for The country with tokyo as its capital is known as japan
The country with madrid as its capital is known as spain
The country with canberra as its capital is known as australia
The country with stockholm as its capital is known as sweden
The country with kingston as its capital is known as jamaica
The country with copenhagen as its capital is known as denmark
The country with athens as its capital is known as greece
The country with bangkok as its capital is known as
2024-07-28 01:56:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 01:58:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2856, -0.0323, -0.4849,  ...,  0.5386,  0.1260,  0.1917],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1006, -5.3477,  1.0918,  ..., -0.3286, -2.0039, -3.6914],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.5419e-02, -6.9504e-03, -5.3406e-05,  ...,  7.5989e-03,
         -5.9814e-03,  2.5902e-03],
        [-2.1477e-03,  1.1047e-02,  6.6071e-03,  ..., -6.2218e-03,
          6.5269e-03, -2.3087e-02],
        [ 8.0032e-03,  8.2397e-03,  3.2654e-02,  ...,  2.1866e-02,
          2.6751e-04, -1.4565e-02],
        ...,
        [-2.9907e-03,  5.8517e-03,  1.0834e-02,  ...,  2.4811e-02,
          8.5144e-03, -1.6098e-02],
        [ 1.4162e-03, -7.1945e-03, -4.1199e-03,  ..., -4.8447e-03,
          6.2637e-03, -2.6751e-04],
        [-3.2902e-03, -1.0071e-02, -1.7090e-02,  ...,  1.4553e-03,
          3.3112e-03,  1.5274e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0771, -5.1406,  1.0215,  ..., -0.2118, -1.9326, -3.6348]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 01:58:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with tokyo as its capital is known as japan
The country with madrid as its capital is known as spain
The country with canberra as its capital is known as australia
The country with stockholm as its capital is known as sweden
The country with kingston as its capital is known as jamaica
The country with copenhagen as its capital is known as denmark
The country with athens as its capital is known as greece
The country with bangkok as its capital is known as
2024-07-28 01:58:54 root INFO     total operator prediction time: 1108.4101300239563 seconds
2024-07-28 01:58:54 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on name - occupation
2024-07-28 01:58:54 root INFO     building operator name - occupation
2024-07-28 01:58:54 root INFO     [order_1_approx] starting weight calculation for raphael was known for their work as a  painter
haydn was known for their work as a  composer
aristotle was known for their work as a  philosopher
depp was known for their work as a  actor
darwin was known for their work as a  naturalist
einstein was known for their work as a  physicist
confucius was known for their work as a  philosopher
mozart was known for their work as a 
2024-07-28 01:58:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 02:01:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0113, -0.1172, -0.2271,  ...,  0.3528, -0.3940, -0.1192],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0879, -4.8984,  1.7236,  ..., -1.8652,  1.2529, -0.1543],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.8915e-02,  6.5269e-03,  7.2632e-03,  ...,  4.3869e-03,
          9.0599e-05, -9.2010e-03],
        [ 9.3918e-03,  2.0386e-02,  9.1934e-03,  ..., -5.7650e-04,
         -8.0490e-04,  9.4223e-04],
        [-2.7943e-03,  4.5128e-03,  4.1077e-02,  ..., -2.0676e-03,
         -4.9400e-03,  7.6447e-03],
        ...,
        [ 8.9493e-03, -4.0665e-03, -1.9264e-04,  ...,  4.7119e-02,
          7.9803e-03,  7.5722e-04],
        [ 4.9171e-03,  5.8861e-03,  3.9043e-03,  ...,  5.8556e-04,
          2.2705e-02,  2.0733e-03],
        [-5.7602e-03, -3.1090e-03, -7.8735e-03,  ...,  1.5850e-03,
         -8.1558e-03,  3.4973e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0215, -4.6602,  1.8145,  ..., -1.8164,  1.2266, -0.1465]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 02:01:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for raphael was known for their work as a  painter
haydn was known for their work as a  composer
aristotle was known for their work as a  philosopher
depp was known for their work as a  actor
darwin was known for their work as a  naturalist
einstein was known for their work as a  physicist
confucius was known for their work as a  philosopher
mozart was known for their work as a 
2024-07-28 02:01:15 root INFO     [order_1_approx] starting weight calculation for einstein was known for their work as a  physicist
depp was known for their work as a  actor
mozart was known for their work as a  composer
darwin was known for their work as a  naturalist
confucius was known for their work as a  philosopher
raphael was known for their work as a  painter
haydn was known for their work as a  composer
aristotle was known for their work as a 
2024-07-28 02:01:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 02:03:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1824, -0.4099, -0.6436,  ...,  0.1021, -0.1938,  0.1245],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7090, -5.0703,  2.9043,  ..., -7.0391, -0.4346, -3.0820],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0284, -0.0058,  0.0033,  ...,  0.0058, -0.0101,  0.0040],
        [-0.0086,  0.0145, -0.0031,  ..., -0.0053, -0.0016, -0.0023],
        [ 0.0061, -0.0009,  0.0260,  ...,  0.0041, -0.0028,  0.0039],
        ...,
        [ 0.0070,  0.0098, -0.0079,  ...,  0.0220,  0.0027, -0.0106],
        [ 0.0009,  0.0142, -0.0016,  ...,  0.0058,  0.0126, -0.0037],
        [ 0.0030,  0.0126, -0.0006,  ...,  0.0040, -0.0015,  0.0213]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6523, -5.0234,  2.8711,  ..., -6.8477, -0.5273, -3.2656]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 02:03:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for einstein was known for their work as a  physicist
depp was known for their work as a  actor
mozart was known for their work as a  composer
darwin was known for their work as a  naturalist
confucius was known for their work as a  philosopher
raphael was known for their work as a  painter
haydn was known for their work as a  composer
aristotle was known for their work as a 
2024-07-28 02:03:36 root INFO     [order_1_approx] starting weight calculation for mozart was known for their work as a  composer
confucius was known for their work as a  philosopher
einstein was known for their work as a  physicist
haydn was known for their work as a  composer
aristotle was known for their work as a  philosopher
raphael was known for their work as a  painter
depp was known for their work as a  actor
darwin was known for their work as a 
2024-07-28 02:03:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 02:05:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2002, -0.1547, -0.0897,  ...,  0.0503,  0.0320,  0.1536],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6582, -5.2812,  2.5000,  ..., -5.5859,  0.1919, -2.0508],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0451, -0.0072,  0.0043,  ..., -0.0066, -0.0031,  0.0063],
        [-0.0063,  0.0428, -0.0023,  ..., -0.0040,  0.0017,  0.0065],
        [ 0.0207, -0.0103,  0.0630,  ..., -0.0056,  0.0113,  0.0125],
        ...,
        [ 0.0157,  0.0060,  0.0026,  ...,  0.0466,  0.0195, -0.0086],
        [-0.0078,  0.0118,  0.0027,  ..., -0.0027,  0.0396, -0.0066],
        [-0.0032, -0.0056, -0.0014,  ..., -0.0088, -0.0050,  0.0520]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5791, -5.4219,  2.3652,  ..., -5.4141,  0.3223, -1.9121]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 02:05:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for mozart was known for their work as a  composer
confucius was known for their work as a  philosopher
einstein was known for their work as a  physicist
haydn was known for their work as a  composer
aristotle was known for their work as a  philosopher
raphael was known for their work as a  painter
depp was known for their work as a  actor
darwin was known for their work as a 
2024-07-28 02:05:55 root INFO     [order_1_approx] starting weight calculation for raphael was known for their work as a  painter
confucius was known for their work as a  philosopher
einstein was known for their work as a  physicist
depp was known for their work as a  actor
aristotle was known for their work as a  philosopher
mozart was known for their work as a  composer
darwin was known for their work as a  naturalist
haydn was known for their work as a 
2024-07-28 02:05:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 02:08:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1220, -0.1217, -0.1509,  ...,  0.3164, -0.1448,  0.2054],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5508, -4.7266,  2.5781,  ..., -2.6270,  0.9629, -2.4180],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0350,  0.0169,  0.0118,  ...,  0.0058, -0.0069, -0.0139],
        [ 0.0225,  0.0272,  0.0149,  ...,  0.0012,  0.0058,  0.0007],
        [-0.0061,  0.0033,  0.0511,  ..., -0.0034,  0.0010,  0.0098],
        ...,
        [ 0.0053,  0.0020, -0.0060,  ...,  0.0463,  0.0143, -0.0055],
        [ 0.0146,  0.0059, -0.0005,  ..., -0.0046,  0.0257, -0.0030],
        [-0.0038, -0.0092, -0.0095,  ...,  0.0034, -0.0079,  0.0385]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2949, -4.5625,  2.6426,  ..., -2.7617,  1.0811, -2.3105]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 02:08:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for raphael was known for their work as a  painter
confucius was known for their work as a  philosopher
einstein was known for their work as a  physicist
depp was known for their work as a  actor
aristotle was known for their work as a  philosopher
mozart was known for their work as a  composer
darwin was known for their work as a  naturalist
haydn was known for their work as a 
2024-07-28 02:08:14 root INFO     [order_1_approx] starting weight calculation for aristotle was known for their work as a  philosopher
raphael was known for their work as a  painter
mozart was known for their work as a  composer
confucius was known for their work as a  philosopher
haydn was known for their work as a  composer
depp was known for their work as a  actor
darwin was known for their work as a  naturalist
einstein was known for their work as a 
2024-07-28 02:08:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 02:10:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0128, -0.3904, -0.4507,  ..., -0.0116, -0.3906,  0.3035],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6465, -4.6172,  1.7578,  ..., -5.7305, -0.1074, -1.7432],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0297, -0.0096,  0.0115,  ..., -0.0071, -0.0093, -0.0053],
        [-0.0001,  0.0323,  0.0008,  ...,  0.0009, -0.0078, -0.0104],
        [ 0.0023, -0.0043,  0.0450,  ..., -0.0003,  0.0037,  0.0111],
        ...,
        [ 0.0060,  0.0027,  0.0017,  ...,  0.0432,  0.0092, -0.0017],
        [ 0.0064,  0.0081,  0.0063,  ...,  0.0032,  0.0115,  0.0008],
        [ 0.0049, -0.0018, -0.0101,  ..., -0.0032, -0.0052,  0.0282]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7109, -4.5703,  1.7393,  ..., -5.4531, -0.0520, -1.5850]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 02:10:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for aristotle was known for their work as a  philosopher
raphael was known for their work as a  painter
mozart was known for their work as a  composer
confucius was known for their work as a  philosopher
haydn was known for their work as a  composer
depp was known for their work as a  actor
darwin was known for their work as a  naturalist
einstein was known for their work as a 
2024-07-28 02:10:35 root INFO     [order_1_approx] starting weight calculation for aristotle was known for their work as a  philosopher
mozart was known for their work as a  composer
darwin was known for their work as a  naturalist
confucius was known for their work as a  philosopher
raphael was known for their work as a  painter
haydn was known for their work as a  composer
einstein was known for their work as a  physicist
depp was known for their work as a 
2024-07-28 02:10:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 02:12:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0105,  0.3145, -0.1224,  ...,  0.7100, -0.5645, -0.0657],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8438, -3.7070,  1.8379,  ..., -3.6992,  0.2581,  0.3643],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0498, -0.0135,  0.0093,  ...,  0.0066, -0.0002,  0.0061],
        [-0.0049,  0.0424,  0.0119,  ..., -0.0079, -0.0030, -0.0042],
        [ 0.0157,  0.0079,  0.0504,  ...,  0.0097,  0.0032,  0.0122],
        ...,
        [ 0.0188,  0.0032,  0.0083,  ...,  0.0494, -0.0044,  0.0013],
        [-0.0085,  0.0148, -0.0036,  ..., -0.0014,  0.0163,  0.0052],
        [-0.0047, -0.0014, -0.0045,  ...,  0.0033, -0.0066,  0.0370]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5684, -4.3516,  1.9395,  ..., -3.6523,  0.3591,  0.3806]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 02:12:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for aristotle was known for their work as a  philosopher
mozart was known for their work as a  composer
darwin was known for their work as a  naturalist
confucius was known for their work as a  philosopher
raphael was known for their work as a  painter
haydn was known for their work as a  composer
einstein was known for their work as a  physicist
depp was known for their work as a 
2024-07-28 02:12:58 root INFO     [order_1_approx] starting weight calculation for haydn was known for their work as a  composer
darwin was known for their work as a  naturalist
einstein was known for their work as a  physicist
aristotle was known for their work as a  philosopher
depp was known for their work as a  actor
mozart was known for their work as a  composer
raphael was known for their work as a  painter
confucius was known for their work as a 
2024-07-28 02:12:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 02:15:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0778, -0.2900, -0.7329,  ...,  0.4404, -0.2034,  0.1466],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0352, -5.5859,  4.1523,  ..., -8.5078,  1.1914, -0.1104],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.1351e-02,  1.6851e-03,  1.0109e-02,  ...,  6.2523e-03,
         -1.3916e-02, -3.9253e-03],
        [-6.8474e-03,  3.1189e-02,  2.5558e-03,  ..., -8.5754e-03,
         -7.7858e-03, -1.6832e-03],
        [ 1.3229e-02, -6.8245e-03,  3.2562e-02,  ...,  2.4414e-03,
         -4.3983e-03,  9.5062e-03],
        ...,
        [ 1.3321e-02,  8.7585e-03, -5.2261e-03,  ...,  3.5950e-02,
          6.4373e-05, -4.9477e-03],
        [-4.2953e-03,  5.6763e-03,  1.1759e-03,  ...,  2.0657e-03,
          1.2070e-02,  4.8180e-03],
        [-1.3504e-02,  7.1831e-03,  2.5063e-03,  ...,  5.7411e-03,
         -1.0166e-03,  2.5208e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0966, -5.6680,  3.9023,  ..., -8.2188,  1.2217, -0.0385]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 02:15:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for haydn was known for their work as a  composer
darwin was known for their work as a  naturalist
einstein was known for their work as a  physicist
aristotle was known for their work as a  philosopher
depp was known for their work as a  actor
mozart was known for their work as a  composer
raphael was known for their work as a  painter
confucius was known for their work as a 
2024-07-28 02:15:17 root INFO     [order_1_approx] starting weight calculation for aristotle was known for their work as a  philosopher
einstein was known for their work as a  physicist
depp was known for their work as a  actor
haydn was known for their work as a  composer
confucius was known for their work as a  philosopher
darwin was known for their work as a  naturalist
mozart was known for their work as a  composer
raphael was known for their work as a 
2024-07-28 02:15:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 02:17:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4531, -0.3022, -0.0396,  ...,  0.1628, -0.2593,  0.0026],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2637, -7.4961,  2.6816,  ..., -6.4883, -0.8945, -2.1191],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0638, -0.0040, -0.0016,  ...,  0.0038, -0.0106,  0.0166],
        [ 0.0182,  0.0332, -0.0003,  ..., -0.0159, -0.0186, -0.0011],
        [ 0.0159,  0.0038,  0.0754,  ...,  0.0029, -0.0018,  0.0094],
        ...,
        [ 0.0101,  0.0043, -0.0087,  ...,  0.0535,  0.0162, -0.0057],
        [ 0.0154, -0.0057, -0.0046,  ...,  0.0003,  0.0160,  0.0095],
        [-0.0049,  0.0027, -0.0337,  ..., -0.0183, -0.0160,  0.0491]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7754, -7.1367,  2.3691,  ..., -6.0352, -0.4858, -1.8799]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 02:17:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for aristotle was known for their work as a  philosopher
einstein was known for their work as a  physicist
depp was known for their work as a  actor
haydn was known for their work as a  composer
confucius was known for their work as a  philosopher
darwin was known for their work as a  naturalist
mozart was known for their work as a  composer
raphael was known for their work as a 
2024-07-28 02:17:35 root INFO     total operator prediction time: 1121.0101985931396 seconds
2024-07-28 02:17:35 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on male - female
2024-07-28 02:17:35 root INFO     building operator male - female
2024-07-28 02:17:35 root INFO     [order_1_approx] starting weight calculation for A female superman is known as a superwoman
A female poet is known as a poetess
A female father is known as a mother
A female son is known as a daughter
A female uncle is known as a aunt
A female fox is known as a vixen
A female rooster is known as a hen
A female hero is known as a
2024-07-28 02:17:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 02:19:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4824,  0.7354,  0.1368,  ..., -0.3450, -0.2197,  0.0266],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.8477, -6.2461, -0.3457,  ..., -2.8594, -2.8301,  1.3232],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.7913e-02, -2.6443e-02,  2.6245e-02,  ...,  1.9760e-02,
          4.1161e-03,  4.4708e-03],
        [ 1.6602e-02,  4.2877e-02, -6.1111e-03,  ..., -8.3771e-03,
          7.9155e-05, -1.8799e-02],
        [ 1.2238e-02,  2.8248e-03,  5.2765e-02,  ..., -1.1086e-02,
         -1.6357e-02, -4.6005e-03],
        ...,
        [ 8.9035e-03, -1.3321e-02, -9.9182e-03,  ...,  6.2683e-02,
         -1.8494e-02, -2.9129e-02],
        [-7.4005e-04,  2.5864e-02,  1.1986e-02,  ...,  4.5967e-03,
          9.4147e-03,  7.8354e-03],
        [ 1.1856e-02, -2.0782e-02, -1.9684e-02,  ..., -1.8066e-02,
          3.0258e-02,  3.5828e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.4141, -5.9180, -0.2844,  ..., -2.5469, -3.0508,  1.4893]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 02:19:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female superman is known as a superwoman
A female poet is known as a poetess
A female father is known as a mother
A female son is known as a daughter
A female uncle is known as a aunt
A female fox is known as a vixen
A female rooster is known as a hen
A female hero is known as a
2024-07-28 02:19:57 root INFO     [order_1_approx] starting weight calculation for A female son is known as a daughter
A female superman is known as a superwoman
A female uncle is known as a aunt
A female hero is known as a heroine
A female fox is known as a vixen
A female rooster is known as a hen
A female poet is known as a poetess
A female father is known as a
2024-07-28 02:19:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 02:22:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6792,  0.3237, -0.1252,  ..., -0.1426, -0.4714,  0.1445],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.7617, -2.7500, -1.2871,  ...,  0.4705, -4.3984, -1.1504],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0312, -0.0019,  0.0307,  ...,  0.0313, -0.0023,  0.0362],
        [-0.0114,  0.0510, -0.0006,  ...,  0.0202,  0.0054, -0.0271],
        [ 0.0070, -0.0290,  0.0666,  ...,  0.0049, -0.0096, -0.0007],
        ...,
        [-0.0082,  0.0109, -0.0177,  ...,  0.0584,  0.0065, -0.0227],
        [ 0.0140, -0.0078,  0.0139,  ...,  0.0078,  0.0071, -0.0106],
        [ 0.0284, -0.0181, -0.0227,  ..., -0.0367,  0.0080,  0.0200]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0625, -2.8223, -0.9307,  ...,  0.7290, -4.1367, -0.1865]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 02:22:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female son is known as a daughter
A female superman is known as a superwoman
A female uncle is known as a aunt
A female hero is known as a heroine
A female fox is known as a vixen
A female rooster is known as a hen
A female poet is known as a poetess
A female father is known as a
2024-07-28 02:22:20 root INFO     [order_1_approx] starting weight calculation for A female poet is known as a poetess
A female son is known as a daughter
A female fox is known as a vixen
A female father is known as a mother
A female superman is known as a superwoman
A female hero is known as a heroine
A female rooster is known as a hen
A female uncle is known as a
2024-07-28 02:22:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 02:24:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3262,  0.7490,  0.1929,  ..., -0.1405, -0.2700, -0.1849],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8574, -1.9258, -0.9561,  ..., -0.3477, -3.5801, -1.3047],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0304, -0.0017,  0.0545,  ...,  0.0444, -0.0289,  0.0237],
        [ 0.0211,  0.0407, -0.0061,  ...,  0.0097,  0.0033, -0.0029],
        [ 0.0044, -0.0165,  0.0320,  ..., -0.0036,  0.0103, -0.0142],
        ...,
        [-0.0069,  0.0169, -0.0021,  ...,  0.0468,  0.0018, -0.0058],
        [-0.0124, -0.0113,  0.0015,  ...,  0.0317,  0.0085,  0.0041],
        [-0.0052,  0.0036,  0.0018,  ...,  0.0064,  0.0210,  0.0278]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9473, -1.8145, -0.9282,  ..., -0.9146, -4.0547, -1.2910]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 02:24:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female poet is known as a poetess
A female son is known as a daughter
A female fox is known as a vixen
A female father is known as a mother
A female superman is known as a superwoman
A female hero is known as a heroine
A female rooster is known as a hen
A female uncle is known as a
2024-07-28 02:24:39 root INFO     [order_1_approx] starting weight calculation for A female hero is known as a heroine
A female superman is known as a superwoman
A female son is known as a daughter
A female poet is known as a poetess
A female father is known as a mother
A female uncle is known as a aunt
A female rooster is known as a hen
A female fox is known as a
2024-07-28 02:24:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 02:26:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.8608,  0.3621,  0.0392,  ...,  0.0535, -0.4746, -0.1489],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3799, -6.0117, -1.1592,  ..., -1.0020, -2.5234,  3.8672],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0509, -0.0039,  0.0178,  ...,  0.0065, -0.0060,  0.0114],
        [ 0.0034,  0.0471,  0.0120,  ..., -0.0017,  0.0074, -0.0376],
        [ 0.0012, -0.0118,  0.0344,  ..., -0.0207, -0.0034, -0.0133],
        ...,
        [-0.0003, -0.0123, -0.0117,  ...,  0.0356,  0.0072, -0.0175],
        [-0.0068, -0.0092,  0.0012,  ..., -0.0005,  0.0111,  0.0118],
        [-0.0028, -0.0063, -0.0006,  ..., -0.0264, -0.0031,  0.0255]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8945, -6.0781, -0.8477,  ..., -0.9941, -2.6758,  3.9473]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 02:27:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female hero is known as a heroine
A female superman is known as a superwoman
A female son is known as a daughter
A female poet is known as a poetess
A female father is known as a mother
A female uncle is known as a aunt
A female rooster is known as a hen
A female fox is known as a
2024-07-28 02:27:00 root INFO     [order_1_approx] starting weight calculation for A female hero is known as a heroine
A female fox is known as a vixen
A female son is known as a daughter
A female uncle is known as a aunt
A female superman is known as a superwoman
A female rooster is known as a hen
A female father is known as a mother
A female poet is known as a
2024-07-28 02:27:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 02:29:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4253,  0.1295,  0.0947,  ..., -0.2522, -0.2062,  0.0062],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4414, -7.1055,  1.1641,  ..., -1.9805, -4.6367, -0.9229],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0544, -0.0155, -0.0052,  ...,  0.0066,  0.0101,  0.0002],
        [ 0.0257,  0.0292,  0.0111,  ...,  0.0105,  0.0016, -0.0160],
        [ 0.0204,  0.0153,  0.0757,  ...,  0.0192, -0.0245,  0.0014],
        ...,
        [ 0.0009,  0.0060,  0.0196,  ...,  0.0710, -0.0144, -0.0237],
        [-0.0078,  0.0099,  0.0113,  ...,  0.0120,  0.0135,  0.0125],
        [-0.0067, -0.0081,  0.0020,  ..., -0.0093,  0.0213,  0.0330]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2168, -6.7070,  0.9609,  ..., -2.1953, -4.9609, -1.0234]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 02:29:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female hero is known as a heroine
A female fox is known as a vixen
A female son is known as a daughter
A female uncle is known as a aunt
A female superman is known as a superwoman
A female rooster is known as a hen
A female father is known as a mother
A female poet is known as a
2024-07-28 02:29:20 root INFO     [order_1_approx] starting weight calculation for A female fox is known as a vixen
A female father is known as a mother
A female son is known as a daughter
A female uncle is known as a aunt
A female poet is known as a poetess
A female rooster is known as a hen
A female hero is known as a heroine
A female superman is known as a
2024-07-28 02:29:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 02:31:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.8589,  0.5981,  0.1071,  ...,  0.0901, -0.3599,  0.1251],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.9727, -3.7871,  1.4062,  ...,  0.0532, -2.5020,  1.6553],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0308, -0.0257,  0.0282,  ...,  0.0331, -0.0185,  0.0057],
        [ 0.0093,  0.0418, -0.0009,  ...,  0.0086,  0.0159, -0.0076],
        [ 0.0079,  0.0071,  0.0415,  ..., -0.0023,  0.0056, -0.0089],
        ...,
        [ 0.0288,  0.0037, -0.0196,  ...,  0.0479, -0.0186,  0.0032],
        [-0.0102,  0.0004, -0.0005,  ...,  0.0060,  0.0186,  0.0144],
        [-0.0020, -0.0299, -0.0016,  ..., -0.0061,  0.0112,  0.0364]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 6.5273, -3.5176,  1.2539,  ...,  0.1774, -2.4199,  1.6982]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 02:31:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female fox is known as a vixen
A female father is known as a mother
A female son is known as a daughter
A female uncle is known as a aunt
A female poet is known as a poetess
A female rooster is known as a hen
A female hero is known as a heroine
A female superman is known as a
2024-07-28 02:31:43 root INFO     [order_1_approx] starting weight calculation for A female fox is known as a vixen
A female superman is known as a superwoman
A female poet is known as a poetess
A female rooster is known as a hen
A female father is known as a mother
A female hero is known as a heroine
A female uncle is known as a aunt
A female son is known as a
2024-07-28 02:31:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 02:33:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4436,  0.6904,  0.3086,  ...,  0.1048, -0.0309,  0.0836],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.5703, -2.2871, -2.1465,  ...,  2.2871, -3.2812,  0.0859],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.2460e-02, -2.4658e-02,  3.6564e-03,  ...,  3.9940e-03,
         -7.3433e-03,  1.5060e-02],
        [ 2.6337e-02,  4.1656e-02, -1.4915e-02,  ...,  2.8362e-03,
         -2.3994e-03, -4.2572e-02],
        [-1.5274e-02, -2.5726e-02,  7.1411e-02,  ..., -2.6642e-02,
         -1.4603e-02, -1.0010e-02],
        ...,
        [-2.0294e-02,  4.0817e-03, -1.3397e-02,  ...,  7.4646e-02,
         -6.7253e-03,  4.7112e-03],
        [-6.8092e-03,  5.8517e-03,  1.0277e-02,  ..., -7.6294e-05,
          2.5055e-02,  4.4136e-03],
        [ 1.7517e-02, -3.7727e-03, -1.6464e-02,  ..., -6.8207e-03,
         -3.1757e-03,  4.4647e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.1289, -2.3359, -2.2754,  ...,  2.4434, -3.4414, -0.0265]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 02:33:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female fox is known as a vixen
A female superman is known as a superwoman
A female poet is known as a poetess
A female rooster is known as a hen
A female father is known as a mother
A female hero is known as a heroine
A female uncle is known as a aunt
A female son is known as a
2024-07-28 02:33:59 root INFO     [order_1_approx] starting weight calculation for A female superman is known as a superwoman
A female son is known as a daughter
A female hero is known as a heroine
A female uncle is known as a aunt
A female fox is known as a vixen
A female father is known as a mother
A female poet is known as a poetess
A female rooster is known as a
2024-07-28 02:34:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 02:36:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4810,  0.3252,  0.0176,  ...,  0.3118, -0.4937,  0.5210],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6738, -3.6504,  1.0234,  ...,  0.3467, -2.1055,  2.7891],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0647, -0.0128, -0.0061,  ...,  0.0262, -0.0113,  0.0002],
        [-0.0134,  0.0417,  0.0084,  ...,  0.0027,  0.0253, -0.0188],
        [ 0.0262, -0.0319,  0.0589,  ..., -0.0042, -0.0375, -0.0045],
        ...,
        [-0.0056, -0.0121,  0.0041,  ...,  0.0585, -0.0105, -0.0002],
        [ 0.0131,  0.0577, -0.0180,  ...,  0.0048,  0.0341, -0.0168],
        [ 0.0263, -0.0151, -0.0143,  ..., -0.0249,  0.0093,  0.0337]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6943, -3.0508,  1.1025,  ..., -0.0420, -2.2715,  2.5000]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 02:36:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female superman is known as a superwoman
A female son is known as a daughter
A female hero is known as a heroine
A female uncle is known as a aunt
A female fox is known as a vixen
A female father is known as a mother
A female poet is known as a poetess
A female rooster is known as a
2024-07-28 02:36:19 root INFO     total operator prediction time: 1124.6715397834778 seconds
2024-07-28 02:36:19 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - shelter
2024-07-28 02:36:19 root INFO     building operator animal - shelter
2024-07-28 02:36:20 root INFO     [order_1_approx] starting weight calculation for The place chinchilla lives in is called nest
The place trout lives in is called river
The place scorpion lives in is called nest
The place monkey lives in is called tree
The place duck lives in is called pond
The place seal lives in is called den
The place hamster lives in is called nest
The place dolphin lives in is called
2024-07-28 02:36:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 02:38:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4109, -0.4468, -0.0361,  ...,  0.1108, -0.3359, -0.1166],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7061, -5.6445, -0.6743,  ..., -2.3730, -0.2216,  1.1953],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0156, -0.0015, -0.0012,  ...,  0.0009, -0.0078, -0.0038],
        [ 0.0009,  0.0124, -0.0015,  ...,  0.0021, -0.0040,  0.0013],
        [ 0.0006,  0.0015,  0.0092,  ...,  0.0031, -0.0035, -0.0035],
        ...,
        [-0.0019,  0.0009,  0.0040,  ...,  0.0087,  0.0034,  0.0027],
        [ 0.0037,  0.0047,  0.0031,  ...,  0.0019,  0.0089,  0.0053],
        [ 0.0009, -0.0023, -0.0019,  ..., -0.0026,  0.0005,  0.0071]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7734, -5.6133, -0.6885,  ..., -2.3438, -0.2333,  1.1709]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 02:38:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place chinchilla lives in is called nest
The place trout lives in is called river
The place scorpion lives in is called nest
The place monkey lives in is called tree
The place duck lives in is called pond
The place seal lives in is called den
The place hamster lives in is called nest
The place dolphin lives in is called
2024-07-28 02:38:39 root INFO     [order_1_approx] starting weight calculation for The place trout lives in is called river
The place monkey lives in is called tree
The place hamster lives in is called nest
The place chinchilla lives in is called nest
The place seal lives in is called den
The place duck lives in is called pond
The place dolphin lives in is called sea
The place scorpion lives in is called
2024-07-28 02:38:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 02:40:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1575, -0.0757, -0.0504,  ...,  0.2402, -0.2656, -0.1443],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0195, -3.9258,  1.5723,  ..., -2.5410,  1.3662, -0.3135],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0156, -0.0018,  0.0026,  ...,  0.0052, -0.0066, -0.0012],
        [-0.0079,  0.0125,  0.0022,  ..., -0.0016,  0.0030,  0.0023],
        [-0.0071,  0.0071,  0.0177,  ...,  0.0013, -0.0041,  0.0078],
        ...,
        [ 0.0091,  0.0024,  0.0034,  ...,  0.0093,  0.0056, -0.0016],
        [ 0.0051,  0.0025, -0.0001,  ...,  0.0054,  0.0159,  0.0028],
        [-0.0032, -0.0011, -0.0099,  ..., -0.0072, -0.0031,  0.0129]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1250, -4.0586,  1.4668,  ..., -2.6328,  1.3047, -0.2283]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 02:40:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place trout lives in is called river
The place monkey lives in is called tree
The place hamster lives in is called nest
The place chinchilla lives in is called nest
The place seal lives in is called den
The place duck lives in is called pond
The place dolphin lives in is called sea
The place scorpion lives in is called
2024-07-28 02:40:57 root INFO     [order_1_approx] starting weight calculation for The place chinchilla lives in is called nest
The place scorpion lives in is called nest
The place dolphin lives in is called sea
The place hamster lives in is called nest
The place trout lives in is called river
The place seal lives in is called den
The place monkey lives in is called tree
The place duck lives in is called
2024-07-28 02:40:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 02:43:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6211, -0.2410,  0.3799,  ...,  0.2507, -0.3879,  0.0187],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1094, -5.5625,  1.3057,  ..., -1.8008, -0.2676,  0.3135],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0249,  0.0028, -0.0131,  ...,  0.0119, -0.0100, -0.0100],
        [-0.0025,  0.0586,  0.0044,  ..., -0.0096, -0.0237, -0.0204],
        [-0.0081,  0.0003,  0.0295,  ...,  0.0138, -0.0048, -0.0059],
        ...,
        [ 0.0045, -0.0024,  0.0177,  ...,  0.0318,  0.0112, -0.0052],
        [ 0.0270, -0.0062, -0.0088,  ...,  0.0115,  0.0396, -0.0069],
        [-0.0132,  0.0033, -0.0018,  ...,  0.0044,  0.0028,  0.0414]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3770, -5.1367,  0.8818,  ..., -2.3203, -0.4424,  0.2649]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 02:43:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place chinchilla lives in is called nest
The place scorpion lives in is called nest
The place dolphin lives in is called sea
The place hamster lives in is called nest
The place trout lives in is called river
The place seal lives in is called den
The place monkey lives in is called tree
The place duck lives in is called
2024-07-28 02:43:17 root INFO     [order_1_approx] starting weight calculation for The place duck lives in is called pond
The place hamster lives in is called nest
The place dolphin lives in is called sea
The place scorpion lives in is called nest
The place chinchilla lives in is called nest
The place monkey lives in is called tree
The place seal lives in is called den
The place trout lives in is called
2024-07-28 02:43:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 02:45:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0320, -0.2903, -0.1285,  ...,  0.3035, -0.3677, -0.2101],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3711, -6.1562,  1.1357,  ..., -3.9043, -1.0078, -3.5488],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0397, -0.0161, -0.0056,  ...,  0.0150, -0.0423, -0.0244],
        [-0.0014,  0.0580,  0.0043,  ..., -0.0004, -0.0137, -0.0329],
        [-0.0054, -0.0152,  0.0402,  ...,  0.0087,  0.0146,  0.0099],
        ...,
        [ 0.0106,  0.0053,  0.0181,  ...,  0.0361,  0.0060, -0.0127],
        [ 0.0274,  0.0073, -0.0137,  ...,  0.0137,  0.0466,  0.0142],
        [ 0.0004, -0.0009, -0.0189,  ..., -0.0217, -0.0221,  0.0431]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7188, -6.1484,  0.6001,  ..., -4.0039, -1.3379, -3.5234]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 02:45:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place duck lives in is called pond
The place hamster lives in is called nest
The place dolphin lives in is called sea
The place scorpion lives in is called nest
The place chinchilla lives in is called nest
The place monkey lives in is called tree
The place seal lives in is called den
The place trout lives in is called
2024-07-28 02:45:36 root INFO     [order_1_approx] starting weight calculation for The place hamster lives in is called nest
The place dolphin lives in is called sea
The place scorpion lives in is called nest
The place duck lives in is called pond
The place seal lives in is called den
The place chinchilla lives in is called nest
The place trout lives in is called river
The place monkey lives in is called
2024-07-28 02:45:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 02:47:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1591, -0.2661,  0.0709,  ...,  0.3140, -0.2993,  0.1227],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1133, -7.7656,  2.7129,  ..., -0.5811, -2.3555, -0.1074],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.7943e-02, -1.2894e-02, -9.7198e-03,  ..., -9.9030e-03,
         -1.1703e-02,  1.1597e-03],
        [-1.7029e-02,  4.4434e-02, -1.3863e-02,  ...,  6.2485e-03,
          2.4796e-05, -2.5635e-02],
        [-9.9106e-03,  9.0485e-03,  4.1565e-02,  ..., -5.2414e-03,
         -6.1073e-03,  1.6632e-02],
        ...,
        [ 6.5155e-03,  1.7944e-02,  2.3605e-02,  ...,  5.0751e-02,
          6.7673e-03, -6.8760e-04],
        [ 7.7133e-03,  6.8359e-03, -1.4923e-02,  ...,  1.7128e-03,
          4.5349e-02,  8.4000e-03],
        [-2.5604e-02,  1.3229e-02, -7.3318e-03,  ..., -1.8692e-02,
         -1.3306e-02,  3.5492e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.3047, -7.5000,  1.8496,  ..., -0.6909, -2.5566,  0.2239]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 02:47:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place hamster lives in is called nest
The place dolphin lives in is called sea
The place scorpion lives in is called nest
The place duck lives in is called pond
The place seal lives in is called den
The place chinchilla lives in is called nest
The place trout lives in is called river
The place monkey lives in is called
2024-07-28 02:47:52 root INFO     [order_1_approx] starting weight calculation for The place scorpion lives in is called nest
The place trout lives in is called river
The place hamster lives in is called nest
The place duck lives in is called pond
The place dolphin lives in is called sea
The place monkey lives in is called tree
The place seal lives in is called den
The place chinchilla lives in is called
2024-07-28 02:47:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 02:50:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1326, -0.4749,  0.0062,  ...,  0.2898, -0.1646,  0.0241],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3281, -4.5703,  1.1230,  ..., -0.4014, -0.4502,  0.7188],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0268, -0.0316, -0.0101,  ...,  0.0268, -0.0060, -0.0129],
        [-0.0163,  0.0640,  0.0030,  ...,  0.0081,  0.0110, -0.0119],
        [-0.0333,  0.0247,  0.0442,  ...,  0.0103,  0.0024,  0.0216],
        ...,
        [ 0.0067, -0.0141, -0.0051,  ...,  0.0538,  0.0160,  0.0108],
        [ 0.0005,  0.0079,  0.0098,  ...,  0.0151,  0.0450,  0.0056],
        [-0.0074,  0.0061, -0.0006,  ..., -0.0427, -0.0037,  0.0549]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8809, -4.4180,  1.2070,  ..., -0.4890, -0.8994,  0.8594]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 02:50:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place scorpion lives in is called nest
The place trout lives in is called river
The place hamster lives in is called nest
The place duck lives in is called pond
The place dolphin lives in is called sea
The place monkey lives in is called tree
The place seal lives in is called den
The place chinchilla lives in is called
2024-07-28 02:50:05 root INFO     [order_1_approx] starting weight calculation for The place duck lives in is called pond
The place hamster lives in is called nest
The place chinchilla lives in is called nest
The place monkey lives in is called tree
The place trout lives in is called river
The place dolphin lives in is called sea
The place scorpion lives in is called nest
The place seal lives in is called
2024-07-28 02:50:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 02:52:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.8936, -0.5903, -0.1212,  ...,  0.3564, -0.2957, -0.0214],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2891, -9.2266, -1.1719,  ..., -1.9766,  1.1084, -0.4180],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0473, -0.0084, -0.0056,  ...,  0.0185, -0.0207, -0.0180],
        [ 0.0017,  0.0539,  0.0043,  ..., -0.0066, -0.0134, -0.0305],
        [ 0.0076,  0.0064,  0.0315,  ..., -0.0164,  0.0049, -0.0148],
        ...,
        [-0.0004,  0.0123,  0.0146,  ...,  0.0666,  0.0009, -0.0018],
        [ 0.0126,  0.0011, -0.0094,  ...,  0.0094,  0.0344, -0.0112],
        [-0.0129, -0.0103,  0.0072,  ..., -0.0036, -0.0025,  0.0400]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6211, -9.1797, -1.0449,  ..., -2.2676,  0.9014, -0.6172]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 02:52:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place duck lives in is called pond
The place hamster lives in is called nest
The place chinchilla lives in is called nest
The place monkey lives in is called tree
The place trout lives in is called river
The place dolphin lives in is called sea
The place scorpion lives in is called nest
The place seal lives in is called
2024-07-28 02:52:23 root INFO     [order_1_approx] starting weight calculation for The place monkey lives in is called tree
The place chinchilla lives in is called nest
The place trout lives in is called river
The place dolphin lives in is called sea
The place scorpion lives in is called nest
The place seal lives in is called den
The place duck lives in is called pond
The place hamster lives in is called
2024-07-28 02:52:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 02:54:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0876, -0.5220,  0.2510,  ...,  0.1777, -0.3359,  0.1855],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8320, -4.7500,  1.3418,  ..., -0.0293, -2.5430,  3.0000],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0638, -0.0205, -0.0002,  ...,  0.0026, -0.0400,  0.0061],
        [-0.0142,  0.0485, -0.0058,  ...,  0.0108, -0.0015, -0.0133],
        [ 0.0019,  0.0251,  0.0339,  ...,  0.0086, -0.0036,  0.0127],
        ...,
        [ 0.0068, -0.0220,  0.0083,  ...,  0.0439,  0.0203,  0.0006],
        [ 0.0093,  0.0277,  0.0127,  ...,  0.0457,  0.0363, -0.0027],
        [-0.0094,  0.0123,  0.0010,  ...,  0.0141,  0.0219,  0.0666]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5059, -4.4648,  1.6406,  ...,  0.1077, -2.8086,  2.8887]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 02:54:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place monkey lives in is called tree
The place chinchilla lives in is called nest
The place trout lives in is called river
The place dolphin lives in is called sea
The place scorpion lives in is called nest
The place seal lives in is called den
The place duck lives in is called pond
The place hamster lives in is called
2024-07-28 02:54:42 root INFO     total operator prediction time: 1102.6504681110382 seconds
2024-07-28 02:54:42 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on country - language
2024-07-28 02:54:42 root INFO     building operator country - language
2024-07-28 02:54:42 root INFO     [order_1_approx] starting weight calculation for The country of cyprus primarily speaks the language of greek
The country of kuwait primarily speaks the language of arabic
The country of venezuela primarily speaks the language of spanish
The country of ireland primarily speaks the language of english
The country of guyana primarily speaks the language of english
The country of haiti primarily speaks the language of creole
The country of australia primarily speaks the language of english
The country of cuba primarily speaks the language of
2024-07-28 02:54:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 02:56:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0717, -0.0503,  0.2949,  ..., -0.1077, -0.1270,  0.1787],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9609, -2.5684,  0.6396,  ...,  0.6289, -0.0352, -2.5000],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0328,  0.0020,  0.0136,  ...,  0.0095,  0.0117, -0.0192],
        [-0.0066,  0.0364, -0.0006,  ..., -0.0026, -0.0067,  0.0067],
        [-0.0097,  0.0168,  0.0610,  ...,  0.0293,  0.0230,  0.0113],
        ...,
        [-0.0202,  0.0091,  0.0116,  ...,  0.0462,  0.0175, -0.0033],
        [ 0.0043, -0.0054, -0.0125,  ..., -0.0048,  0.0152,  0.0060],
        [ 0.0032, -0.0047,  0.0042,  ...,  0.0060,  0.0098,  0.0199]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9570, -2.3047,  0.3054,  ...,  0.1914,  0.0714, -2.4219]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 02:56:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of cyprus primarily speaks the language of greek
The country of kuwait primarily speaks the language of arabic
The country of venezuela primarily speaks the language of spanish
The country of ireland primarily speaks the language of english
The country of guyana primarily speaks the language of english
The country of haiti primarily speaks the language of creole
The country of australia primarily speaks the language of english
The country of cuba primarily speaks the language of
2024-07-28 02:56:58 root INFO     [order_1_approx] starting weight calculation for The country of venezuela primarily speaks the language of spanish
The country of cyprus primarily speaks the language of greek
The country of cuba primarily speaks the language of spanish
The country of guyana primarily speaks the language of english
The country of haiti primarily speaks the language of creole
The country of ireland primarily speaks the language of english
The country of kuwait primarily speaks the language of arabic
The country of australia primarily speaks the language of
2024-07-28 02:56:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 02:59:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3589,  0.1241,  0.0598,  ...,  0.3843, -0.1323,  0.2338],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2754, -2.5742,  1.3135,  ..., -0.1538, -0.8770, -1.7705],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0224, -0.0118, -0.0062,  ...,  0.0104, -0.0140, -0.0135],
        [ 0.0071,  0.0175,  0.0169,  ...,  0.0052, -0.0073, -0.0005],
        [-0.0229,  0.0216,  0.0459,  ...,  0.0180,  0.0061,  0.0121],
        ...,
        [-0.0192,  0.0100,  0.0107,  ...,  0.0201,  0.0110, -0.0003],
        [-0.0036, -0.0085, -0.0194,  ..., -0.0038,  0.0273, -0.0123],
        [ 0.0184, -0.0133, -0.0055,  ...,  0.0036, -0.0045,  0.0173]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3955, -2.4668,  0.9429,  ..., -0.4014, -0.8813, -1.5039]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 02:59:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of venezuela primarily speaks the language of spanish
The country of cyprus primarily speaks the language of greek
The country of cuba primarily speaks the language of spanish
The country of guyana primarily speaks the language of english
The country of haiti primarily speaks the language of creole
The country of ireland primarily speaks the language of english
The country of kuwait primarily speaks the language of arabic
The country of australia primarily speaks the language of
2024-07-28 02:59:15 root INFO     [order_1_approx] starting weight calculation for The country of kuwait primarily speaks the language of arabic
The country of australia primarily speaks the language of english
The country of ireland primarily speaks the language of english
The country of cuba primarily speaks the language of spanish
The country of cyprus primarily speaks the language of greek
The country of haiti primarily speaks the language of creole
The country of guyana primarily speaks the language of english
The country of venezuela primarily speaks the language of
2024-07-28 02:59:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 03:01:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5718, -0.1757, -0.1030,  ...,  0.4126, -0.3911,  0.1381],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3213, -3.7031,  1.4277,  ...,  0.3618,  0.3262, -1.7646],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0299,  0.0084,  0.0068,  ...,  0.0078, -0.0163, -0.0266],
        [ 0.0005,  0.0121,  0.0107,  ..., -0.0022, -0.0172, -0.0091],
        [-0.0161,  0.0097,  0.0234,  ...,  0.0127,  0.0142,  0.0280],
        ...,
        [-0.0070, -0.0004, -0.0037,  ...,  0.0185,  0.0135,  0.0203],
        [ 0.0178, -0.0121, -0.0072,  ...,  0.0027,  0.0177, -0.0034],
        [ 0.0149,  0.0030,  0.0067,  ...,  0.0138, -0.0047,  0.0104]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3799, -3.8047,  1.1406,  ...,  0.2202,  0.4255, -1.6289]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 03:01:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of kuwait primarily speaks the language of arabic
The country of australia primarily speaks the language of english
The country of ireland primarily speaks the language of english
The country of cuba primarily speaks the language of spanish
The country of cyprus primarily speaks the language of greek
The country of haiti primarily speaks the language of creole
The country of guyana primarily speaks the language of english
The country of venezuela primarily speaks the language of
2024-07-28 03:01:37 root INFO     [order_1_approx] starting weight calculation for The country of kuwait primarily speaks the language of arabic
The country of cyprus primarily speaks the language of greek
The country of guyana primarily speaks the language of english
The country of haiti primarily speaks the language of creole
The country of venezuela primarily speaks the language of spanish
The country of cuba primarily speaks the language of spanish
The country of australia primarily speaks the language of english
The country of ireland primarily speaks the language of
2024-07-28 03:01:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 03:03:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2810,  0.2053, -0.1028,  ...,  0.3496,  0.0645,  0.1375],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4456, -2.4180, -0.8833,  ...,  0.8770,  0.5371, -2.3770],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.2053e-02,  1.7700e-03,  1.1948e-02,  ...,  1.4954e-02,
         -1.7349e-02, -2.4155e-02],
        [-2.1935e-03,  3.8361e-02,  1.8433e-02,  ..., -5.8556e-04,
         -1.1925e-02, -5.2261e-03],
        [-1.1192e-02,  1.0529e-02,  4.9591e-02,  ...,  1.3535e-02,
          1.1681e-02,  6.5575e-03],
        ...,
        [-1.9409e-02,  6.4278e-03,  1.8654e-03,  ...,  2.9358e-02,
          8.5297e-03,  1.2619e-02],
        [ 5.7716e-03, -9.3079e-03,  6.3629e-03,  ...,  1.4404e-02,
          2.3422e-02, -4.0092e-03],
        [ 7.5531e-04, -1.1948e-02, -9.1553e-05,  ...,  1.6489e-03,
          2.0523e-03,  1.2924e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2947, -2.3848, -1.0420,  ...,  0.8027,  0.6245, -2.0840]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 03:03:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of kuwait primarily speaks the language of arabic
The country of cyprus primarily speaks the language of greek
The country of guyana primarily speaks the language of english
The country of haiti primarily speaks the language of creole
The country of venezuela primarily speaks the language of spanish
The country of cuba primarily speaks the language of spanish
The country of australia primarily speaks the language of english
The country of ireland primarily speaks the language of
2024-07-28 03:03:57 root INFO     [order_1_approx] starting weight calculation for The country of cuba primarily speaks the language of spanish
The country of australia primarily speaks the language of english
The country of kuwait primarily speaks the language of arabic
The country of haiti primarily speaks the language of creole
The country of ireland primarily speaks the language of english
The country of cyprus primarily speaks the language of greek
The country of venezuela primarily speaks the language of spanish
The country of guyana primarily speaks the language of
2024-07-28 03:03:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 03:06:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1282, -0.0287,  0.4155,  ...,  0.2029, -0.7539,  0.0769],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0898, -0.3662,  1.3916,  ...,  0.7578,  0.3438, -3.2734],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0164,  0.0175, -0.0112,  ...,  0.0009, -0.0099, -0.0122],
        [-0.0005,  0.0275,  0.0026,  ..., -0.0076, -0.0015, -0.0183],
        [-0.0053,  0.0056,  0.0529,  ...,  0.0273,  0.0030,  0.0177],
        ...,
        [-0.0101, -0.0067, -0.0030,  ...,  0.0260,  0.0030,  0.0061],
        [ 0.0117,  0.0097, -0.0103,  ..., -0.0073,  0.0273, -0.0152],
        [ 0.0135, -0.0025,  0.0039,  ...,  0.0026, -0.0016,  0.0218]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9160, -0.3169,  1.3164,  ...,  0.6221,  0.3992, -2.8828]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 03:06:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of cuba primarily speaks the language of spanish
The country of australia primarily speaks the language of english
The country of kuwait primarily speaks the language of arabic
The country of haiti primarily speaks the language of creole
The country of ireland primarily speaks the language of english
The country of cyprus primarily speaks the language of greek
The country of venezuela primarily speaks the language of spanish
The country of guyana primarily speaks the language of
2024-07-28 03:06:13 root INFO     [order_1_approx] starting weight calculation for The country of australia primarily speaks the language of english
The country of venezuela primarily speaks the language of spanish
The country of kuwait primarily speaks the language of arabic
The country of cuba primarily speaks the language of spanish
The country of guyana primarily speaks the language of english
The country of cyprus primarily speaks the language of greek
The country of ireland primarily speaks the language of english
The country of haiti primarily speaks the language of
2024-07-28 03:06:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 03:08:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0807,  0.2668, -0.1132,  ...,  0.2822, -0.3853,  0.2252],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9863, -1.8604,  1.5840,  ..., -1.3564,  1.0703, -0.0972],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.2745e-02,  1.5545e-03, -2.5749e-04,  ...,  1.4343e-02,
         -1.6388e-02, -8.4686e-03],
        [ 1.0918e-02,  3.9154e-02,  1.5541e-02,  ...,  2.4033e-04,
         -5.7220e-05, -2.1042e-02],
        [-4.1771e-03,  5.6038e-03,  6.3293e-02,  ..., -7.1144e-04,
          2.6398e-02,  2.9945e-03],
        ...,
        [-2.4368e-02,  1.1505e-02,  8.6823e-03,  ...,  3.2410e-02,
         -4.3602e-03,  1.4038e-03],
        [ 3.4332e-03,  2.0325e-02,  1.1711e-03,  ...,  4.1771e-03,
          4.1992e-02,  4.6539e-04],
        [ 1.2840e-02, -1.4816e-02,  1.4313e-02,  ..., -1.9226e-02,
          6.3057e-03,  3.1677e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6997, -1.6592,  1.5332,  ..., -1.6367,  1.2949, -0.3003]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 03:08:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of australia primarily speaks the language of english
The country of venezuela primarily speaks the language of spanish
The country of kuwait primarily speaks the language of arabic
The country of cuba primarily speaks the language of spanish
The country of guyana primarily speaks the language of english
The country of cyprus primarily speaks the language of greek
The country of ireland primarily speaks the language of english
The country of haiti primarily speaks the language of
2024-07-28 03:08:29 root INFO     [order_1_approx] starting weight calculation for The country of haiti primarily speaks the language of creole
The country of venezuela primarily speaks the language of spanish
The country of cuba primarily speaks the language of spanish
The country of kuwait primarily speaks the language of arabic
The country of australia primarily speaks the language of english
The country of guyana primarily speaks the language of english
The country of ireland primarily speaks the language of english
The country of cyprus primarily speaks the language of
2024-07-28 03:08:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 03:10:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5312, -0.2266, -0.0917,  ...,  0.3223, -0.1556, -0.2344],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.1738, -4.4297, -1.1914,  ..., -2.3301, -1.4551, -1.9551],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0237, -0.0028, -0.0005,  ...,  0.0170, -0.0126, -0.0216],
        [-0.0001,  0.0177,  0.0101,  ..., -0.0056,  0.0023, -0.0036],
        [ 0.0033,  0.0034,  0.0356,  ..., -0.0005, -0.0009,  0.0087],
        ...,
        [-0.0027, -0.0036, -0.0010,  ...,  0.0182,  0.0122,  0.0092],
        [-0.0054,  0.0002,  0.0055,  ..., -0.0015,  0.0231, -0.0074],
        [ 0.0070, -0.0013,  0.0019,  ...,  0.0088, -0.0053,  0.0044]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.0947, -4.3633, -1.3340,  ..., -2.3203, -1.4326, -1.9004]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 03:10:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of haiti primarily speaks the language of creole
The country of venezuela primarily speaks the language of spanish
The country of cuba primarily speaks the language of spanish
The country of kuwait primarily speaks the language of arabic
The country of australia primarily speaks the language of english
The country of guyana primarily speaks the language of english
The country of ireland primarily speaks the language of english
The country of cyprus primarily speaks the language of
2024-07-28 03:10:46 root INFO     [order_1_approx] starting weight calculation for The country of venezuela primarily speaks the language of spanish
The country of haiti primarily speaks the language of creole
The country of cuba primarily speaks the language of spanish
The country of australia primarily speaks the language of english
The country of ireland primarily speaks the language of english
The country of guyana primarily speaks the language of english
The country of cyprus primarily speaks the language of greek
The country of kuwait primarily speaks the language of
2024-07-28 03:10:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 03:13:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1399,  0.0400, -0.3066,  ...,  0.5859, -0.1726,  0.4888],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.5869, -3.3867, -0.2271,  ..., -0.7212, -0.1084, -1.2393],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0336, -0.0061,  0.0015,  ...,  0.0095, -0.0104, -0.0181],
        [ 0.0186,  0.0185,  0.0140,  ..., -0.0053,  0.0049, -0.0167],
        [-0.0042,  0.0110,  0.0358,  ..., -0.0014,  0.0047,  0.0064],
        ...,
        [-0.0028, -0.0005, -0.0019,  ...,  0.0265,  0.0130,  0.0094],
        [ 0.0050, -0.0169,  0.0003,  ...,  0.0055,  0.0190, -0.0051],
        [ 0.0039, -0.0065, -0.0035,  ...,  0.0126, -0.0086,  0.0124]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.3418, -3.1621, -0.3074,  ..., -0.7114, -0.1379, -1.2998]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 03:13:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of venezuela primarily speaks the language of spanish
The country of haiti primarily speaks the language of creole
The country of cuba primarily speaks the language of spanish
The country of australia primarily speaks the language of english
The country of ireland primarily speaks the language of english
The country of guyana primarily speaks the language of english
The country of cyprus primarily speaks the language of greek
The country of kuwait primarily speaks the language of
2024-07-28 03:13:07 root INFO     total operator prediction time: 1105.1852328777313 seconds
2024-07-28 03:13:07 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on name - nationality
2024-07-28 03:13:07 root INFO     building operator name - nationality
2024-07-28 03:13:08 root INFO     [order_1_approx] starting weight calculation for wagner was german
mencius was chinese
plato was greek
jolie was american
copernicus was polish
strauss was austrian
maxwell was scottish
michelangelo was
2024-07-28 03:13:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 03:15:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1638, -0.1183, -0.2979,  ...,  0.2056, -0.0723,  0.5942],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1328, -5.5625,  1.8496,  ..., -2.8301, -1.8477, -0.7822],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0837,  0.0069, -0.0049,  ..., -0.0157, -0.0092,  0.0011],
        [ 0.0216,  0.0538,  0.0370,  ..., -0.0254,  0.0190, -0.0470],
        [ 0.0019, -0.0037,  0.0770,  ..., -0.0008, -0.0087,  0.0119],
        ...,
        [ 0.0125,  0.0125, -0.0096,  ...,  0.0413,  0.0149, -0.0193],
        [ 0.0265,  0.0080,  0.0054,  ..., -0.0297,  0.0649, -0.0041],
        [-0.0060,  0.0119,  0.0070,  ...,  0.0050,  0.0096,  0.0575]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9902, -5.3203,  1.4619,  ..., -2.5762, -1.6094, -0.6558]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 03:15:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for wagner was german
mencius was chinese
plato was greek
jolie was american
copernicus was polish
strauss was austrian
maxwell was scottish
michelangelo was
2024-07-28 03:15:28 root INFO     [order_1_approx] starting weight calculation for jolie was american
strauss was austrian
plato was greek
mencius was chinese
maxwell was scottish
wagner was german
michelangelo was italian
copernicus was
2024-07-28 03:15:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 03:17:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0629, -0.2115, -0.7778,  ...,  0.1343, -0.2783,  0.3794],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8965, -5.7852,  0.3862,  ..., -4.9062, -2.0605, -1.5596],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0663,  0.0015, -0.0011,  ..., -0.0084,  0.0130,  0.0097],
        [ 0.0242,  0.0291,  0.0111,  ..., -0.0039, -0.0251, -0.0303],
        [-0.0054, -0.0084,  0.0635,  ...,  0.0084,  0.0014,  0.0203],
        ...,
        [ 0.0156,  0.0032, -0.0023,  ...,  0.0546, -0.0185, -0.0209],
        [ 0.0145,  0.0042,  0.0068,  ..., -0.0063,  0.0289, -0.0093],
        [-0.0228, -0.0002, -0.0070,  ...,  0.0249, -0.0030,  0.0512]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1914, -5.8477,  0.3762,  ..., -4.6602, -1.9746, -1.4209]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 03:17:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for jolie was american
strauss was austrian
plato was greek
mencius was chinese
maxwell was scottish
wagner was german
michelangelo was italian
copernicus was
2024-07-28 03:17:50 root INFO     [order_1_approx] starting weight calculation for plato was greek
mencius was chinese
strauss was austrian
jolie was american
michelangelo was italian
copernicus was polish
wagner was german
maxwell was
2024-07-28 03:17:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 03:20:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2498, -0.0330, -0.0824,  ...,  0.1595,  0.0078,  0.1277],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8496, -1.7070, -0.5024,  ..., -3.2012, -1.4951, -2.5039],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0991,  0.0237, -0.0021,  ..., -0.0327,  0.0216, -0.0270],
        [-0.0130,  0.0819, -0.0026,  ...,  0.0782, -0.0262,  0.0326],
        [ 0.0412, -0.0213,  0.0819,  ...,  0.0045,  0.0189,  0.0435],
        ...,
        [ 0.0023,  0.0120, -0.0249,  ...,  0.0992,  0.0057,  0.0150],
        [ 0.0122, -0.0025, -0.0049,  ..., -0.0040,  0.0664, -0.0087],
        [-0.0229,  0.0317, -0.0097,  ...,  0.0193, -0.0102,  0.0923]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8242, -2.6797, -0.3611,  ..., -3.3047, -1.6641, -2.6523]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 03:20:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for plato was greek
mencius was chinese
strauss was austrian
jolie was american
michelangelo was italian
copernicus was polish
wagner was german
maxwell was
2024-07-28 03:20:10 root INFO     [order_1_approx] starting weight calculation for maxwell was scottish
michelangelo was italian
jolie was american
wagner was german
plato was greek
mencius was chinese
copernicus was polish
strauss was
2024-07-28 03:20:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 03:22:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0460, -0.2517,  0.0728,  ...,  0.0737, -0.2690, -0.1951],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7783, -4.4922,  1.0547,  ..., -3.3379, -1.4395, -0.9785],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0579, -0.0099,  0.0159,  ..., -0.0120,  0.0093, -0.0166],
        [ 0.0577,  0.0769, -0.0150,  ..., -0.0247, -0.0351, -0.0051],
        [-0.0135, -0.0212,  0.0775,  ...,  0.0287,  0.0166,  0.0123],
        ...,
        [ 0.0263,  0.0224, -0.0195,  ...,  0.0817,  0.0037,  0.0140],
        [ 0.0423,  0.0148, -0.0164,  ..., -0.0175,  0.0506, -0.0239],
        [ 0.0110,  0.0275, -0.0251,  ..., -0.0004, -0.0363,  0.0759]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7207, -4.9922,  0.8765,  ..., -3.7617, -0.9360, -0.7271]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 03:22:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for maxwell was scottish
michelangelo was italian
jolie was american
wagner was german
plato was greek
mencius was chinese
copernicus was polish
strauss was
2024-07-28 03:22:30 root INFO     [order_1_approx] starting weight calculation for maxwell was scottish
plato was greek
mencius was chinese
jolie was american
michelangelo was italian
strauss was austrian
copernicus was polish
wagner was
2024-07-28 03:22:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 03:24:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3970,  0.2461,  0.1567,  ...,  0.2277, -0.1340, -0.1636],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9834, -5.1367,  0.4619,  ..., -2.3516, -1.5098, -1.3711],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0623, -0.0194, -0.0005,  ..., -0.0177,  0.0049, -0.0224],
        [ 0.0341,  0.0472,  0.0007,  ...,  0.0165, -0.0010, -0.0068],
        [ 0.0003,  0.0150,  0.0811,  ...,  0.0278,  0.0177,  0.0104],
        ...,
        [ 0.0062,  0.0144,  0.0097,  ...,  0.0675, -0.0225,  0.0034],
        [ 0.0156,  0.0391, -0.0016,  ..., -0.0213,  0.0630, -0.0200],
        [ 0.0126,  0.0117,  0.0101,  ...,  0.0092, -0.0336,  0.0827]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0781, -5.5000,  0.0178,  ..., -2.6484, -1.3945, -1.4053]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 03:24:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for maxwell was scottish
plato was greek
mencius was chinese
jolie was american
michelangelo was italian
strauss was austrian
copernicus was polish
wagner was
2024-07-28 03:24:50 root INFO     [order_1_approx] starting weight calculation for michelangelo was italian
wagner was german
jolie was american
mencius was chinese
copernicus was polish
maxwell was scottish
strauss was austrian
plato was
2024-07-28 03:24:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 03:27:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0186, -0.2683, -0.5718,  ...,  0.2382, -0.0488,  0.2389],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1816, -3.8301,  0.2539,  ..., -4.4297, -1.3340, -1.1250],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0576, -0.0047, -0.0108,  ..., -0.0102, -0.0183,  0.0085],
        [ 0.0289,  0.0445,  0.0362,  ...,  0.0169, -0.0083, -0.0098],
        [ 0.0036,  0.0025,  0.0693,  ...,  0.0039, -0.0031,  0.0064],
        ...,
        [ 0.0199,  0.0222,  0.0040,  ...,  0.0369,  0.0271, -0.0328],
        [ 0.0267,  0.0065,  0.0302,  ...,  0.0146,  0.0624, -0.0036],
        [ 0.0114,  0.0098,  0.0090,  ...,  0.0148, -0.0092,  0.0598]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3496, -4.0820, -0.0166,  ..., -4.5117, -1.3652, -1.2227]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 03:27:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for michelangelo was italian
wagner was german
jolie was american
mencius was chinese
copernicus was polish
maxwell was scottish
strauss was austrian
plato was
2024-07-28 03:27:12 root INFO     [order_1_approx] starting weight calculation for strauss was austrian
michelangelo was italian
wagner was german
maxwell was scottish
copernicus was polish
jolie was american
plato was greek
mencius was
2024-07-28 03:27:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 03:29:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2529,  0.1304, -0.5244,  ...,  0.5562, -0.1340,  0.3513],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2266, -1.2666,  2.4688,  ..., -5.0430, -0.8125,  1.3633],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0688,  0.0242, -0.0136,  ..., -0.0086, -0.0202, -0.0241],
        [-0.0030,  0.0551,  0.0163,  ...,  0.0037, -0.0064,  0.0141],
        [-0.0093,  0.0031,  0.0563,  ...,  0.0132,  0.0045,  0.0350],
        ...,
        [ 0.0260,  0.0050, -0.0166,  ...,  0.0425, -0.0064, -0.0364],
        [-0.0137,  0.0075, -0.0071,  ..., -0.0158,  0.0692,  0.0060],
        [-0.0262,  0.0162, -0.0150,  ...,  0.0386, -0.0126,  0.0949]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2559, -1.6260,  1.5664,  ..., -4.6445, -1.2812,  1.4521]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 03:29:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for strauss was austrian
michelangelo was italian
wagner was german
maxwell was scottish
copernicus was polish
jolie was american
plato was greek
mencius was
2024-07-28 03:29:34 root INFO     [order_1_approx] starting weight calculation for michelangelo was italian
mencius was chinese
copernicus was polish
plato was greek
wagner was german
strauss was austrian
maxwell was scottish
jolie was
2024-07-28 03:29:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 03:31:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0551,  0.3171, -0.3826,  ...,  0.6362, -0.5522,  0.1980],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2793, -2.2578,  0.3213,  ..., -1.8379, -1.8730,  0.3699],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0466, -0.0202, -0.0099,  ..., -0.0131,  0.0298,  0.0024],
        [ 0.0366,  0.0711,  0.0372,  ...,  0.0579,  0.0116, -0.0100],
        [ 0.0008,  0.0181,  0.0632,  ...,  0.0020,  0.0190,  0.0168],
        ...,
        [ 0.0337,  0.0228,  0.0040,  ...,  0.0690, -0.0182,  0.0115],
        [-0.0037,  0.0067, -0.0173,  ..., -0.0223,  0.0333, -0.0019],
        [ 0.0142,  0.0142,  0.0009,  ...,  0.0084, -0.0081,  0.0861]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9922, -2.7285,  0.0710,  ..., -2.3945, -1.9004,  0.0957]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 03:31:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for michelangelo was italian
mencius was chinese
copernicus was polish
plato was greek
wagner was german
strauss was austrian
maxwell was scottish
jolie was
2024-07-28 03:31:55 root INFO     total operator prediction time: 1127.5991549491882 seconds
2024-07-28 03:31:55 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on UK_city - county
2024-07-28 03:31:55 root INFO     building operator UK_city - county
2024-07-28 03:31:55 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of ely is in the county of cambridgeshire
In the United Kingdom, the city of lincoln is in the county of lincolnshire
In the United Kingdom, the city of york is in the county of yorkshire
In the United Kingdom, the city of southampton is in the county of hampshire
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of worcester is in the county of worcestershire
In the United Kingdom, the city of edinburgh is in the county of lowlands
In the United Kingdom, the city of belfast is in the county of
2024-07-28 03:31:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 03:34:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7041, -0.0454, -0.6445,  ...,  0.4668, -0.0464,  0.2402],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.8711, -7.7891,  2.9121,  ..., -4.3438, -1.6611, -2.3320],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.4539e-03,  4.1199e-03,  5.6915e-03,  ...,  4.1504e-03,
         -1.3351e-05, -1.4858e-03],
        [ 2.1076e-04,  1.3397e-02,  8.4686e-03,  ..., -4.5815e-03,
         -2.5444e-03, -1.0139e-02],
        [ 3.6621e-03,  7.2174e-03,  1.4877e-02,  ...,  1.2878e-02,
         -3.4695e-03, -4.2648e-03],
        ...,
        [-4.9858e-03, -1.3371e-03, -9.9792e-03,  ...,  1.2428e-02,
         -4.3564e-03,  1.9455e-04],
        [ 6.0959e-03, -2.1927e-02,  5.2719e-03,  ...,  4.6768e-03,
         -4.0817e-03, -7.5340e-04],
        [-1.6394e-03, -6.1913e-03,  2.0809e-03,  ...,  2.0456e-04,
         -6.6233e-04,  1.4420e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 7.0977, -7.8438,  2.6465,  ..., -4.3047, -1.4375, -2.2285]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 03:34:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of ely is in the county of cambridgeshire
In the United Kingdom, the city of lincoln is in the county of lincolnshire
In the United Kingdom, the city of york is in the county of yorkshire
In the United Kingdom, the city of southampton is in the county of hampshire
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of worcester is in the county of worcestershire
In the United Kingdom, the city of edinburgh is in the county of lowlands
In the United Kingdom, the city of belfast is in the county of
2024-07-28 03:34:20 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of york is in the county of yorkshire
In the United Kingdom, the city of lincoln is in the county of lincolnshire
In the United Kingdom, the city of ely is in the county of cambridgeshire
In the United Kingdom, the city of worcester is in the county of worcestershire
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of southampton is in the county of hampshire
In the United Kingdom, the city of edinburgh is in the county of
2024-07-28 03:34:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 03:36:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3926,  0.3159, -0.6260,  ...,  0.3882, -0.0322,  0.4983],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3926, -4.3281,  1.4570,  ..., -1.2324, -0.6934, -1.1758],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0084, -0.0065,  0.0061,  ...,  0.0123, -0.0081, -0.0131],
        [-0.0205,  0.0093,  0.0246,  ...,  0.0062,  0.0089, -0.0117],
        [-0.0142,  0.0291,  0.0530,  ...,  0.0178,  0.0064, -0.0156],
        ...,
        [ 0.0274, -0.0136, -0.0038,  ...,  0.0457,  0.0193, -0.0118],
        [ 0.0092, -0.0200,  0.0019,  ...,  0.0172,  0.0150,  0.0005],
        [-0.0237,  0.0037, -0.0020,  ..., -0.0089, -0.0039,  0.0334]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7578, -4.2109,  1.3145,  ..., -0.9995, -0.6191, -1.0010]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 03:36:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of york is in the county of yorkshire
In the United Kingdom, the city of lincoln is in the county of lincolnshire
In the United Kingdom, the city of ely is in the county of cambridgeshire
In the United Kingdom, the city of worcester is in the county of worcestershire
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of southampton is in the county of hampshire
In the United Kingdom, the city of edinburgh is in the county of
2024-07-28 03:36:46 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of lincoln is in the county of lincolnshire
In the United Kingdom, the city of worcester is in the county of worcestershire
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of edinburgh is in the county of lowlands
In the United Kingdom, the city of york is in the county of yorkshire
In the United Kingdom, the city of southampton is in the county of hampshire
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of ely is in the county of
2024-07-28 03:36:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 03:39:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3435, -0.2408,  0.0747,  ...,  0.2793,  0.0836,  0.3408],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8164, -3.8047,  0.8159,  ..., -4.9531, -0.6680, -0.1675],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0246,  0.0046, -0.0056,  ..., -0.0226, -0.0133, -0.0404],
        [-0.0162,  0.0580, -0.0109,  ..., -0.0001,  0.0212, -0.0109],
        [-0.0317, -0.0382,  0.0637,  ...,  0.0414,  0.0130,  0.0134],
        ...,
        [ 0.0520,  0.0284, -0.0001,  ...,  0.0581, -0.0020, -0.0450],
        [ 0.0058, -0.0234,  0.0130,  ...,  0.0373,  0.0258, -0.0259],
        [-0.0282, -0.0194, -0.0343,  ..., -0.0359,  0.0211, -0.0043]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5156, -3.2871,  0.4822,  ..., -4.6641,  0.2617, -0.6006]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 03:39:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of lincoln is in the county of lincolnshire
In the United Kingdom, the city of worcester is in the county of worcestershire
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of edinburgh is in the county of lowlands
In the United Kingdom, the city of york is in the county of yorkshire
In the United Kingdom, the city of southampton is in the county of hampshire
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of ely is in the county of
2024-07-28 03:39:15 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of ely is in the county of cambridgeshire
In the United Kingdom, the city of lincoln is in the county of lincolnshire
In the United Kingdom, the city of york is in the county of yorkshire
In the United Kingdom, the city of edinburgh is in the county of lowlands
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of southampton is in the county of hampshire
In the United Kingdom, the city of worcester is in the county of
2024-07-28 03:39:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 03:41:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4114, -0.4246, -0.0723,  ...,  0.4753, -0.4785,  0.0033],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8105, -6.6172,  2.2500,  ..., -3.2812,  1.7461, -1.6055],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0029,  0.0087,  0.0068,  ..., -0.0018, -0.0030, -0.0037],
        [ 0.0052,  0.0147, -0.0018,  ...,  0.0095, -0.0079, -0.0040],
        [ 0.0025,  0.0071,  0.0167,  ...,  0.0080,  0.0013, -0.0067],
        ...,
        [ 0.0112, -0.0020, -0.0039,  ...,  0.0176,  0.0053, -0.0042],
        [-0.0027, -0.0050,  0.0044,  ...,  0.0056, -0.0007, -0.0034],
        [ 0.0018, -0.0006,  0.0039,  ..., -0.0080, -0.0025,  0.0047]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8262, -6.6367,  2.2285,  ..., -3.2559,  1.8320, -1.5918]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 03:41:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of ely is in the county of cambridgeshire
In the United Kingdom, the city of lincoln is in the county of lincolnshire
In the United Kingdom, the city of york is in the county of yorkshire
In the United Kingdom, the city of edinburgh is in the county of lowlands
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of southampton is in the county of hampshire
In the United Kingdom, the city of worcester is in the county of
2024-07-28 03:41:45 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of edinburgh is in the county of lowlands
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of southampton is in the county of hampshire
In the United Kingdom, the city of lincoln is in the county of lincolnshire
In the United Kingdom, the city of worcester is in the county of worcestershire
In the United Kingdom, the city of ely is in the county of cambridgeshire
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of york is in the county of
2024-07-28 03:41:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 03:44:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3472,  0.0272, -0.1780,  ...,  0.1677, -0.0356,  0.1917],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9385, -3.5586, -1.7510,  ..., -2.5898,  0.0669,  0.7974],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.7406e-03, -7.6866e-03,  4.4479e-03,  ..., -1.4305e-02,
         -1.9943e-02,  7.6294e-06],
        [-7.8583e-03,  2.1927e-02,  8.7662e-03,  ...,  2.4147e-03,
          6.5308e-03, -1.1002e-02],
        [-8.0261e-03,  4.2953e-03,  2.7298e-02,  ...,  1.0269e-02,
         -1.0727e-02, -1.0551e-02],
        ...,
        [ 1.5045e-02, -5.5695e-03, -9.5520e-03,  ...,  4.4861e-02,
          1.4648e-03,  3.0766e-03],
        [ 3.4847e-03, -2.1851e-02,  3.0365e-03,  ...,  1.0910e-02,
          2.4090e-03, -4.6310e-03],
        [-1.7181e-02,  1.1757e-02, -1.2550e-03,  ...,  1.5850e-03,
         -6.9199e-03,  1.8005e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0273, -3.3652, -1.5146,  ..., -2.3516,  0.3923,  0.5376]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 03:44:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of edinburgh is in the county of lowlands
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of southampton is in the county of hampshire
In the United Kingdom, the city of lincoln is in the county of lincolnshire
In the United Kingdom, the city of worcester is in the county of worcestershire
In the United Kingdom, the city of ely is in the county of cambridgeshire
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of york is in the county of
2024-07-28 03:44:11 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of edinburgh is in the county of lowlands
In the United Kingdom, the city of york is in the county of yorkshire
In the United Kingdom, the city of lincoln is in the county of lincolnshire
In the United Kingdom, the city of ely is in the county of cambridgeshire
In the United Kingdom, the city of worcester is in the county of worcestershire
In the United Kingdom, the city of southampton is in the county of hampshire
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of preston is in the county of
2024-07-28 03:44:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 03:46:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3284,  0.1844, -0.1703,  ...,  0.7046,  0.1098,  0.2339],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4355, -4.7695,  1.5791,  ..., -2.0059,  0.8887, -1.2607],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.4246e-02,  1.8280e-02, -1.5221e-02,  ...,  9.0942e-03,
          4.9706e-03, -5.8365e-03],
        [ 9.5367e-06,  2.7542e-02,  2.8198e-02,  ...,  6.7139e-03,
          1.0628e-02,  3.3340e-03],
        [-7.2021e-03,  1.0422e-02,  4.1626e-02,  ...,  2.4368e-02,
         -1.3428e-02, -2.2171e-02],
        ...,
        [ 1.6022e-02, -1.4214e-02, -3.2520e-04,  ...,  3.2440e-02,
         -8.2245e-03, -3.0884e-02],
        [ 1.0452e-02, -4.5490e-04,  4.7684e-03,  ..., -2.0733e-03,
          1.5869e-02, -2.5940e-02],
        [ 2.7649e-02, -2.8015e-02, -9.2773e-03,  ..., -2.9190e-02,
         -2.8412e-02,  1.3596e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3555, -4.7500,  1.4365,  ..., -2.0020,  1.1719, -0.6665]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 03:46:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of edinburgh is in the county of lowlands
In the United Kingdom, the city of york is in the county of yorkshire
In the United Kingdom, the city of lincoln is in the county of lincolnshire
In the United Kingdom, the city of ely is in the county of cambridgeshire
In the United Kingdom, the city of worcester is in the county of worcestershire
In the United Kingdom, the city of southampton is in the county of hampshire
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of preston is in the county of
2024-07-28 03:46:40 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of worcester is in the county of worcestershire
In the United Kingdom, the city of ely is in the county of cambridgeshire
In the United Kingdom, the city of lincoln is in the county of lincolnshire
In the United Kingdom, the city of york is in the county of yorkshire
In the United Kingdom, the city of edinburgh is in the county of lowlands
In the United Kingdom, the city of southampton is in the county of
2024-07-28 03:46:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 03:49:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6479, -0.0203, -0.4980,  ...,  0.6025, -0.1509, -0.1549],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.3906, -6.8125,  1.8037,  ..., -5.3164,  0.1748, -1.5645],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0068,  0.0078,  0.0044,  ...,  0.0047,  0.0092, -0.0136],
        [-0.0133,  0.0122,  0.0047,  ...,  0.0137, -0.0018, -0.0087],
        [-0.0049, -0.0038,  0.0261,  ..., -0.0040,  0.0058, -0.0029],
        ...,
        [ 0.0061, -0.0096, -0.0088,  ...,  0.0158,  0.0021, -0.0047],
        [ 0.0101, -0.0205,  0.0022,  ...,  0.0176,  0.0030, -0.0091],
        [-0.0100, -0.0057,  0.0004,  ..., -0.0023, -0.0059,  0.0093]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.4492, -6.6875,  1.6016,  ..., -5.3984,  0.2209, -1.4551]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 03:49:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of worcester is in the county of worcestershire
In the United Kingdom, the city of ely is in the county of cambridgeshire
In the United Kingdom, the city of lincoln is in the county of lincolnshire
In the United Kingdom, the city of york is in the county of yorkshire
In the United Kingdom, the city of edinburgh is in the county of lowlands
In the United Kingdom, the city of southampton is in the county of
2024-07-28 03:49:06 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of york is in the county of yorkshire
In the United Kingdom, the city of ely is in the county of cambridgeshire
In the United Kingdom, the city of edinburgh is in the county of lowlands
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of worcester is in the county of worcestershire
In the United Kingdom, the city of southampton is in the county of hampshire
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of lincoln is in the county of
2024-07-28 03:49:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 03:51:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3596,  0.0418, -0.2125,  ...,  0.0577, -0.4363,  0.2188],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0664, -3.0039,  0.8022,  ..., -6.2031, -2.5059,  0.7412],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0063, -0.0003, -0.0126,  ..., -0.0183, -0.0057, -0.0061],
        [ 0.0002,  0.0279,  0.0367,  ...,  0.0127,  0.0056, -0.0103],
        [-0.0164, -0.0039,  0.0329,  ...,  0.0142,  0.0021, -0.0138],
        ...,
        [ 0.0265,  0.0014,  0.0049,  ...,  0.0366, -0.0057,  0.0194],
        [ 0.0065, -0.0097, -0.0029,  ...,  0.0086,  0.0046, -0.0250],
        [-0.0060, -0.0097, -0.0006,  ...,  0.0055, -0.0048,  0.0154]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0742, -3.2344,  0.7168,  ..., -6.2930, -2.3223,  0.9082]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 03:51:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of york is in the county of yorkshire
In the United Kingdom, the city of ely is in the county of cambridgeshire
In the United Kingdom, the city of edinburgh is in the county of lowlands
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of worcester is in the county of worcestershire
In the United Kingdom, the city of southampton is in the county of hampshire
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of lincoln is in the county of
2024-07-28 03:51:30 root INFO     total operator prediction time: 1175.3670868873596 seconds
2024-07-28 03:51:30 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+ment_irreg
2024-07-28 03:51:30 root INFO     building operator verb+ment_irreg
2024-07-28 03:51:30 root INFO     [order_1_approx] starting weight calculation for To disagree results in a disagreement
To accomplish results in a accomplishment
To detach results in a detachment
To involve results in a involvement
To develop results in a development
To entertain results in a entertainment
To displace results in a displacement
To harass results in a
2024-07-28 03:51:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 03:53:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0691,  0.4443, -0.3411,  ..., -0.0917, -0.4011, -0.1235],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3867, -2.5781, -0.5220,  ..., -0.0475,  0.7129, -1.2803],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0692,  0.0061,  0.0143,  ..., -0.0110, -0.0118,  0.0075],
        [ 0.0099,  0.0580, -0.0053,  ...,  0.0278,  0.0126, -0.0052],
        [-0.0033, -0.0038,  0.0344,  ..., -0.0059,  0.0146,  0.0046],
        ...,
        [ 0.0053,  0.0194, -0.0106,  ...,  0.0677,  0.0103, -0.0028],
        [-0.0144,  0.0006,  0.0121,  ..., -0.0106,  0.0571, -0.0086],
        [ 0.0130, -0.0136, -0.0097,  ...,  0.0142, -0.0179,  0.0424]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2207, -2.3398, -0.6284,  ...,  0.4675,  0.3472, -1.2529]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 03:53:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To disagree results in a disagreement
To accomplish results in a accomplishment
To detach results in a detachment
To involve results in a involvement
To develop results in a development
To entertain results in a entertainment
To displace results in a displacement
To harass results in a
2024-07-28 03:53:53 root INFO     [order_1_approx] starting weight calculation for To detach results in a detachment
To disagree results in a disagreement
To displace results in a displacement
To involve results in a involvement
To harass results in a harassment
To accomplish results in a accomplishment
To develop results in a development
To entertain results in a
2024-07-28 03:53:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 03:56:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0508,  0.1299, -0.2273,  ..., -0.0670, -0.4290, -0.0312],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5547, -2.1621,  1.1172,  ...,  0.9043,  0.2781, -0.9014],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0739,  0.0033,  0.0261,  ...,  0.0127, -0.0204,  0.0115],
        [-0.0280,  0.0467, -0.0059,  ...,  0.0147,  0.0027, -0.0047],
        [-0.0016, -0.0038,  0.0448,  ...,  0.0058, -0.0028,  0.0092],
        ...,
        [ 0.0046, -0.0095, -0.0202,  ...,  0.0337,  0.0070,  0.0033],
        [-0.0004,  0.0183,  0.0026,  ..., -0.0035,  0.0390, -0.0139],
        [ 0.0019, -0.0119,  0.0010,  ...,  0.0036, -0.0193,  0.0616]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8926, -2.0664,  0.7402,  ...,  1.3818,  0.1208, -0.9858]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 03:56:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To detach results in a detachment
To disagree results in a disagreement
To displace results in a displacement
To involve results in a involvement
To harass results in a harassment
To accomplish results in a accomplishment
To develop results in a development
To entertain results in a
2024-07-28 03:56:16 root INFO     [order_1_approx] starting weight calculation for To disagree results in a disagreement
To harass results in a harassment
To involve results in a involvement
To entertain results in a entertainment
To detach results in a detachment
To accomplish results in a accomplishment
To displace results in a displacement
To develop results in a
2024-07-28 03:56:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 03:58:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2690, -0.0569, -0.0694,  ..., -0.3936, -0.2184, -0.1626],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5254, -3.9375,  1.2852,  ...,  2.6816, -0.5000, -1.8965],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.6213e-02,  1.9058e-02, -3.3951e-04,  ..., -4.2191e-03,
          1.1806e-03,  3.5187e-02],
        [-1.8311e-02,  3.7994e-02,  1.0315e-02,  ...,  1.7761e-02,
          1.7288e-02,  1.6083e-02],
        [-1.0567e-03, -2.0630e-02,  1.6937e-02,  ...,  3.4981e-03,
          4.5395e-03,  5.9738e-03],
        ...,
        [-1.6136e-03,  1.7385e-03, -4.8904e-03,  ...,  3.3752e-02,
         -1.1040e-02,  1.4618e-02],
        [-1.4557e-02,  1.5411e-02, -5.4893e-03,  ..., -4.1733e-03,
          3.6682e-02, -1.0780e-02],
        [-5.0430e-03, -8.0414e-03,  2.8610e-05,  ...,  7.9346e-04,
         -1.2512e-02,  3.3356e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4355, -3.7832,  1.0020,  ...,  2.4258, -0.7271, -1.5947]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 03:58:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To disagree results in a disagreement
To harass results in a harassment
To involve results in a involvement
To entertain results in a entertainment
To detach results in a detachment
To accomplish results in a accomplishment
To displace results in a displacement
To develop results in a
2024-07-28 03:58:39 root INFO     [order_1_approx] starting weight calculation for To develop results in a development
To accomplish results in a accomplishment
To disagree results in a disagreement
To detach results in a detachment
To harass results in a harassment
To displace results in a displacement
To entertain results in a entertainment
To involve results in a
2024-07-28 03:58:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 04:00:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1732,  0.4014, -0.2141,  ...,  0.0103, -0.5039, -0.1487],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6455, -3.3984,  1.6064,  ...,  1.7754,  0.4473, -3.5391],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0412,  0.0169,  0.0064,  ...,  0.0082,  0.0103,  0.0195],
        [-0.0092,  0.0446,  0.0152,  ...,  0.0460,  0.0107,  0.0072],
        [-0.0067, -0.0261,  0.0066,  ..., -0.0163, -0.0029, -0.0077],
        ...,
        [ 0.0027,  0.0140, -0.0138,  ...,  0.0559,  0.0161,  0.0262],
        [-0.0270,  0.0193,  0.0212,  ..., -0.0006,  0.0371, -0.0264],
        [ 0.0068,  0.0018,  0.0194,  ...,  0.0185, -0.0184,  0.0382]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8623, -3.1094,  1.5254,  ...,  1.9863, -0.1240, -3.1855]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 04:01:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To develop results in a development
To accomplish results in a accomplishment
To disagree results in a disagreement
To detach results in a detachment
To harass results in a harassment
To displace results in a displacement
To entertain results in a entertainment
To involve results in a
2024-07-28 04:01:00 root INFO     [order_1_approx] starting weight calculation for To harass results in a harassment
To detach results in a detachment
To disagree results in a disagreement
To accomplish results in a accomplishment
To entertain results in a entertainment
To involve results in a involvement
To develop results in a development
To displace results in a
2024-07-28 04:01:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 04:03:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0522,  0.2681, -0.3655,  ...,  0.2749,  0.0997,  0.4451],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5508, -2.6719, -0.8174,  ...,  1.4531, -0.3059, -0.1536],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0583,  0.0164, -0.0094,  ..., -0.0440, -0.0148, -0.0015],
        [ 0.0173,  0.0594,  0.0093,  ...,  0.0678, -0.0077,  0.0135],
        [ 0.0026, -0.0156,  0.0341,  ..., -0.0302,  0.0028, -0.0267],
        ...,
        [ 0.0043,  0.0166,  0.0062,  ...,  0.1034,  0.0030,  0.0239],
        [-0.0088,  0.0262,  0.0022,  ..., -0.0239,  0.0659, -0.0065],
        [ 0.0244,  0.0231,  0.0141,  ...,  0.0200, -0.0259,  0.0891]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2910, -2.5918, -1.0674,  ...,  1.0596, -0.4497, -1.1562]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 04:03:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To harass results in a harassment
To detach results in a detachment
To disagree results in a disagreement
To accomplish results in a accomplishment
To entertain results in a entertainment
To involve results in a involvement
To develop results in a development
To displace results in a
2024-07-28 04:03:20 root INFO     [order_1_approx] starting weight calculation for To develop results in a development
To entertain results in a entertainment
To harass results in a harassment
To displace results in a displacement
To disagree results in a disagreement
To involve results in a involvement
To accomplish results in a accomplishment
To detach results in a
2024-07-28 04:03:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 04:05:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2126,  0.1217, -0.2354,  ..., -0.0196, -0.1217, -0.1133],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6934, -2.7383, -0.1191,  ...,  1.6445, -0.4932, -2.6523],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0558,  0.0227, -0.0052,  ..., -0.0104,  0.0142, -0.0054],
        [ 0.0198,  0.0388,  0.0246,  ...,  0.0228,  0.0054,  0.0027],
        [-0.0050, -0.0116,  0.0345,  ..., -0.0016, -0.0034, -0.0049],
        ...,
        [ 0.0057, -0.0002,  0.0075,  ...,  0.0739, -0.0049,  0.0210],
        [-0.0212,  0.0064, -0.0054,  ..., -0.0084,  0.0529, -0.0103],
        [ 0.0084,  0.0013,  0.0031,  ...,  0.0121, -0.0300,  0.0612]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7617, -2.6973, -0.1826,  ...,  1.8555, -0.6172, -2.5391]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 04:05:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To develop results in a development
To entertain results in a entertainment
To harass results in a harassment
To displace results in a displacement
To disagree results in a disagreement
To involve results in a involvement
To accomplish results in a accomplishment
To detach results in a
2024-07-28 04:05:40 root INFO     [order_1_approx] starting weight calculation for To displace results in a displacement
To entertain results in a entertainment
To harass results in a harassment
To develop results in a development
To involve results in a involvement
To detach results in a detachment
To accomplish results in a accomplishment
To disagree results in a
2024-07-28 04:05:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 04:07:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4741,  0.1621, -0.2961,  ...,  0.4822, -0.3843, -0.0467],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8584, -4.1172,  1.8281,  ..., -0.1858,  1.8789, -0.5820],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0173,  0.0166, -0.0039,  ..., -0.0144, -0.0017, -0.0023],
        [ 0.0290,  0.0212,  0.0108,  ...,  0.0212,  0.0130,  0.0088],
        [-0.0008, -0.0089,  0.0176,  ..., -0.0006,  0.0005, -0.0047],
        ...,
        [ 0.0152, -0.0042,  0.0070,  ...,  0.0435, -0.0072,  0.0122],
        [-0.0189, -0.0084,  0.0105,  ...,  0.0050,  0.0225, -0.0128],
        [ 0.0133,  0.0038,  0.0058,  ...,  0.0035, -0.0277,  0.0357]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7363, -3.6074,  1.7100,  ...,  0.0165,  1.6094, -0.6689]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 04:07:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To displace results in a displacement
To entertain results in a entertainment
To harass results in a harassment
To develop results in a development
To involve results in a involvement
To detach results in a detachment
To accomplish results in a accomplishment
To disagree results in a
2024-07-28 04:07:56 root INFO     [order_1_approx] starting weight calculation for To involve results in a involvement
To entertain results in a entertainment
To detach results in a detachment
To harass results in a harassment
To develop results in a development
To disagree results in a disagreement
To displace results in a displacement
To accomplish results in a
2024-07-28 04:07:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 04:10:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1892,  0.2445, -0.4858,  ...,  0.1602, -0.6270, -0.2139],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0586, -3.7324, -0.3040,  ...,  1.6709, -0.6182, -1.3535],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0046, -0.0180, -0.0232,  ..., -0.0107,  0.0110, -0.0309],
        [ 0.0550,  0.0928,  0.0452,  ...,  0.0376,  0.0173,  0.0276],
        [ 0.0071, -0.0003,  0.0245,  ..., -0.0067, -0.0034, -0.0141],
        ...,
        [ 0.0270,  0.0175,  0.0088,  ...,  0.0613,  0.0201,  0.0116],
        [-0.0100,  0.0128,  0.0292,  ...,  0.0105,  0.0294, -0.0222],
        [ 0.0163,  0.0033,  0.0030,  ..., -0.0020, -0.0086,  0.0589]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0703, -3.0332, -0.4673,  ...,  2.5625, -0.8032, -0.9116]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 04:10:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To involve results in a involvement
To entertain results in a entertainment
To detach results in a detachment
To harass results in a harassment
To develop results in a development
To disagree results in a disagreement
To displace results in a displacement
To accomplish results in a
2024-07-28 04:10:19 root INFO     total operator prediction time: 1128.3976731300354 seconds
2024-07-28 04:10:19 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun+less_reg
2024-07-28 04:10:19 root INFO     building operator noun+less_reg
2024-07-28 04:10:19 root INFO     [order_1_approx] starting weight calculation for Something without friction is frictionless
Something without defence is defenceless
Something without meat is meatless
Something without emotion is emotionless
Something without carbon is carbonless
Something without faith is faithless
Something without effort is effortless
Something without breath is
2024-07-28 04:10:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 04:12:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2695, -0.2083,  0.1265,  ..., -0.2971, -0.1030, -0.1350],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1016, -5.3750,  0.4087,  ..., -3.1035, -2.3125, -1.2451],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0406,  0.0092, -0.0049,  ...,  0.0319,  0.0077,  0.0152],
        [ 0.0025,  0.0475,  0.0061,  ...,  0.0154, -0.0048,  0.0023],
        [ 0.0176, -0.0005,  0.0429,  ...,  0.0284, -0.0173,  0.0026],
        ...,
        [-0.0073,  0.0176,  0.0054,  ...,  0.0022,  0.0122, -0.0081],
        [-0.0062, -0.0127,  0.0140,  ..., -0.0210,  0.0280, -0.0069],
        [ 0.0025,  0.0213,  0.0129,  ..., -0.0028, -0.0050,  0.0132]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8203, -5.0781,  0.0317,  ..., -2.7969, -2.4531, -1.1104]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 04:12:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without friction is frictionless
Something without defence is defenceless
Something without meat is meatless
Something without emotion is emotionless
Something without carbon is carbonless
Something without faith is faithless
Something without effort is effortless
Something without breath is
2024-07-28 04:12:37 root INFO     [order_1_approx] starting weight calculation for Something without effort is effortless
Something without defence is defenceless
Something without friction is frictionless
Something without breath is breathless
Something without emotion is emotionless
Something without carbon is carbonless
Something without meat is meatless
Something without faith is
2024-07-28 04:12:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 04:14:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3093, -0.0243, -0.1270,  ..., -0.1738, -0.0823,  0.5059],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.4219, -3.1484,  1.3545,  ..., -1.4092, -5.1211, -0.7949],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0251,  0.0076, -0.0014,  ...,  0.0035,  0.0016,  0.0081],
        [ 0.0095,  0.0345,  0.0032,  ...,  0.0216, -0.0084, -0.0006],
        [ 0.0063, -0.0040,  0.0369,  ...,  0.0024, -0.0170, -0.0059],
        ...,
        [ 0.0091,  0.0212, -0.0046,  ...,  0.0233,  0.0016,  0.0177],
        [-0.0090,  0.0058,  0.0061,  ..., -0.0071,  0.0351, -0.0252],
        [ 0.0276,  0.0169, -0.0096,  ...,  0.0085, -0.0203,  0.0165]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.0234, -3.2129,  1.1709,  ..., -1.4590, -5.3984, -0.7168]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 04:14:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without effort is effortless
Something without defence is defenceless
Something without friction is frictionless
Something without breath is breathless
Something without emotion is emotionless
Something without carbon is carbonless
Something without meat is meatless
Something without faith is
2024-07-28 04:14:57 root INFO     [order_1_approx] starting weight calculation for Something without friction is frictionless
Something without meat is meatless
Something without defence is defenceless
Something without breath is breathless
Something without carbon is carbonless
Something without emotion is emotionless
Something without faith is faithless
Something without effort is
2024-07-28 04:14:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 04:17:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0302, -0.1683, -0.0192,  ..., -0.2455, -0.0867,  0.4272],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9844, -4.5156, -1.7314,  ..., -1.9307, -3.6875, -4.1523],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0119, -0.0213, -0.0148,  ...,  0.0102,  0.0082,  0.0127],
        [ 0.0121,  0.0663, -0.0117,  ...,  0.0269, -0.0012,  0.0058],
        [ 0.0003, -0.0098,  0.0395,  ...,  0.0009, -0.0264, -0.0223],
        ...,
        [ 0.0145,  0.0344, -0.0100,  ...,  0.0394,  0.0144,  0.0071],
        [-0.0123,  0.0082, -0.0104,  ...,  0.0009,  0.0305, -0.0185],
        [ 0.0313,  0.0022,  0.0013,  ..., -0.0022, -0.0057,  0.0161]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2031, -4.4531, -1.6699,  ..., -2.0625, -3.7188, -4.0039]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 04:17:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without friction is frictionless
Something without meat is meatless
Something without defence is defenceless
Something without breath is breathless
Something without carbon is carbonless
Something without emotion is emotionless
Something without faith is faithless
Something without effort is
2024-07-28 04:17:17 root INFO     [order_1_approx] starting weight calculation for Something without emotion is emotionless
Something without faith is faithless
Something without effort is effortless
Something without friction is frictionless
Something without meat is meatless
Something without defence is defenceless
Something without breath is breathless
Something without carbon is
2024-07-28 04:17:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 04:19:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4885, -0.3660, -0.8540,  ..., -0.3359,  0.0371, -0.0583],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6851, -2.3574,  2.2188,  ..., -4.3242, -2.7852, -0.2480],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.1113e-02, -4.8180e-03, -6.7787e-03,  ..., -9.6989e-04,
          1.4633e-02,  2.2354e-02],
        [ 5.9204e-03,  3.6804e-02, -8.1940e-03,  ...,  2.2324e-02,
          1.0529e-02,  1.6327e-03],
        [ 3.0518e-03, -8.6288e-03,  2.5543e-02,  ...,  6.8741e-03,
         -6.7368e-03,  1.8997e-03],
        ...,
        [ 1.7578e-02,  3.5217e-02,  2.0981e-02,  ...,  1.4267e-02,
         -3.3455e-03,  1.0872e-04],
        [ 2.1820e-02,  3.9253e-03,  5.8441e-03,  ...,  9.5062e-03,
          1.2764e-02, -3.3508e-02],
        [ 6.5765e-03,  2.0767e-02, -3.1376e-04,  ..., -9.1553e-05,
         -6.6910e-03, -1.1230e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9404, -2.2168,  1.9736,  ..., -4.1836, -2.5430, -0.2413]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 04:19:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without emotion is emotionless
Something without faith is faithless
Something without effort is effortless
Something without friction is frictionless
Something without meat is meatless
Something without defence is defenceless
Something without breath is breathless
Something without carbon is
2024-07-28 04:19:38 root INFO     [order_1_approx] starting weight calculation for Something without meat is meatless
Something without faith is faithless
Something without defence is defenceless
Something without carbon is carbonless
Something without breath is breathless
Something without effort is effortless
Something without emotion is emotionless
Something without friction is
2024-07-28 04:19:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 04:21:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5391, -0.3003, -0.4426,  ..., -0.1401,  0.4319, -0.0464],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1699, -0.6157,  1.4453,  ..., -2.0078, -2.9062,  0.4365],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0362,  0.0048,  0.0144,  ...,  0.0069,  0.0185,  0.0042],
        [-0.0009,  0.0418,  0.0030,  ...,  0.0102, -0.0138,  0.0009],
        [ 0.0047, -0.0025,  0.0351,  ..., -0.0053, -0.0084, -0.0167],
        ...,
        [ 0.0101,  0.0062,  0.0067,  ...,  0.0530,  0.0109,  0.0083],
        [-0.0063,  0.0131, -0.0085,  ..., -0.0107,  0.0497, -0.0156],
        [ 0.0163,  0.0101, -0.0069,  ...,  0.0050,  0.0137,  0.0359]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0098, -0.8247,  1.5781,  ..., -1.9463, -2.5605,  0.4475]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 04:22:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without meat is meatless
Something without faith is faithless
Something without defence is defenceless
Something without carbon is carbonless
Something without breath is breathless
Something without effort is effortless
Something without emotion is emotionless
Something without friction is
2024-07-28 04:22:01 root INFO     [order_1_approx] starting weight calculation for Something without effort is effortless
Something without carbon is carbonless
Something without friction is frictionless
Something without breath is breathless
Something without faith is faithless
Something without defence is defenceless
Something without emotion is emotionless
Something without meat is
2024-07-28 04:22:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 04:24:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1213, -0.5425,  0.2122,  ..., -0.2401, -0.4265,  0.1422],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5312, -3.8164, -0.2424,  ..., -3.7695, -6.8438, -2.3516],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0250, -0.0139,  0.0165,  ...,  0.0226,  0.0183,  0.0124],
        [ 0.0052,  0.0435, -0.0105,  ...,  0.0015,  0.0271,  0.0054],
        [ 0.0031, -0.0145,  0.0182,  ...,  0.0130, -0.0151,  0.0087],
        ...,
        [ 0.0169,  0.0168,  0.0122,  ...,  0.0060,  0.0092,  0.0009],
        [ 0.0065, -0.0130, -0.0008,  ...,  0.0130,  0.0439, -0.0495],
        [ 0.0073,  0.0088,  0.0038,  ...,  0.0039, -0.0112,  0.0225]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7188, -3.3008, -0.4224,  ..., -3.5469, -6.3984, -2.0879]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 04:24:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without effort is effortless
Something without carbon is carbonless
Something without friction is frictionless
Something without breath is breathless
Something without faith is faithless
Something without defence is defenceless
Something without emotion is emotionless
Something without meat is
2024-07-28 04:24:22 root INFO     [order_1_approx] starting weight calculation for Something without effort is effortless
Something without carbon is carbonless
Something without friction is frictionless
Something without breath is breathless
Something without defence is defenceless
Something without faith is faithless
Something without meat is meatless
Something without emotion is
2024-07-28 04:24:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 04:26:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0818, -0.4485, -0.1552,  ..., -0.1561, -0.1462,  0.4138],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7793, -1.2031, -0.4473,  ..., -3.4316, -2.6914, -4.0156],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0327, -0.0104,  0.0153,  ..., -0.0033, -0.0056,  0.0208],
        [-0.0085,  0.0533,  0.0078,  ...,  0.0106, -0.0053, -0.0046],
        [-0.0017, -0.0090,  0.0188,  ...,  0.0127, -0.0144,  0.0007],
        ...,
        [ 0.0190,  0.0173, -0.0006,  ...,  0.0326,  0.0135,  0.0062],
        [ 0.0017,  0.0235,  0.0097,  ..., -0.0177,  0.0358, -0.0108],
        [ 0.0232, -0.0077, -0.0056,  ...,  0.0086, -0.0013,  0.0222]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0039, -1.6367, -0.6450,  ..., -3.2148, -3.3008, -3.7305]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 04:26:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without effort is effortless
Something without carbon is carbonless
Something without friction is frictionless
Something without breath is breathless
Something without defence is defenceless
Something without faith is faithless
Something without meat is meatless
Something without emotion is
2024-07-28 04:26:43 root INFO     [order_1_approx] starting weight calculation for Something without breath is breathless
Something without faith is faithless
Something without carbon is carbonless
Something without emotion is emotionless
Something without meat is meatless
Something without friction is frictionless
Something without effort is effortless
Something without defence is
2024-07-28 04:26:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 04:28:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4219, -0.1329,  0.0828,  ..., -0.2169, -0.0427, -0.2876],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2344, -4.5820,  1.9316,  ..., -2.7227, -2.3965, -2.4688],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0355,  0.0073, -0.0054,  ...,  0.0390, -0.0038,  0.0182],
        [-0.0133,  0.0303,  0.0014,  ..., -0.0011,  0.0007, -0.0028],
        [ 0.0111, -0.0018,  0.0259,  ...,  0.0172, -0.0245,  0.0087],
        ...,
        [-0.0030,  0.0148, -0.0243,  ...,  0.0006,  0.0284,  0.0013],
        [-0.0181,  0.0009, -0.0033,  ..., -0.0055,  0.0638, -0.0347],
        [ 0.0349,  0.0006, -0.0228,  ..., -0.0162, -0.0173,  0.0155]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1562, -4.0156,  1.7549,  ..., -2.0918, -2.4004, -2.5078]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 04:28:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without breath is breathless
Something without faith is faithless
Something without carbon is carbonless
Something without emotion is emotionless
Something without meat is meatless
Something without friction is frictionless
Something without effort is effortless
Something without defence is
2024-07-28 04:28:59 root INFO     total operator prediction time: 1120.3643913269043 seconds
2024-07-28 04:28:59 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj+ness_reg
2024-07-28 04:28:59 root INFO     building operator adj+ness_reg
2024-07-28 04:28:59 root INFO     [order_1_approx] starting weight calculation for The state of being dangerous is dangerousness
The state of being reasonable is reasonableness
The state of being situated is situatedness
The state of being devoted is devotedness
The state of being foreign is foreignness
The state of being useful is usefulness
The state of being happy is happiness
The state of being directed is
2024-07-28 04:28:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 04:31:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1163, -0.1260, -0.3159,  ...,  0.2620, -0.5322,  0.2693],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6025, -3.1758, -0.3818,  ...,  0.6152, -2.8633, -4.9375],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0776,  0.0130, -0.0178,  ...,  0.0157,  0.0089,  0.0125],
        [-0.0199,  0.0578,  0.0101,  ...,  0.0071, -0.0061, -0.0084],
        [-0.0015,  0.0054,  0.0527,  ..., -0.0110, -0.0153, -0.0121],
        ...,
        [ 0.0010,  0.0228, -0.0081,  ...,  0.0511, -0.0089,  0.0094],
        [-0.0070,  0.0320,  0.0143,  ..., -0.0180,  0.0587, -0.0114],
        [ 0.0279, -0.0039, -0.0036,  ...,  0.0107, -0.0171,  0.0717]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9502, -3.2070,  0.0469,  ...,  0.3271, -3.0566, -4.6445]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 04:31:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being dangerous is dangerousness
The state of being reasonable is reasonableness
The state of being situated is situatedness
The state of being devoted is devotedness
The state of being foreign is foreignness
The state of being useful is usefulness
The state of being happy is happiness
The state of being directed is
2024-07-28 04:31:22 root INFO     [order_1_approx] starting weight calculation for The state of being dangerous is dangerousness
The state of being foreign is foreignness
The state of being devoted is devotedness
The state of being directed is directedness
The state of being happy is happiness
The state of being reasonable is reasonableness
The state of being situated is situatedness
The state of being useful is
2024-07-28 04:31:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 04:33:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0660,  0.0304,  0.3665,  ...,  0.0145, -0.2434, -0.1396],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7344, -2.1211, -1.4150,  ..., -1.8457, -4.1055, -1.6523],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0452, -0.0057, -0.0104,  ...,  0.0161,  0.0114,  0.0107],
        [-0.0237,  0.0474,  0.0186,  ...,  0.0248,  0.0165,  0.0056],
        [ 0.0061, -0.0089,  0.0460,  ..., -0.0224, -0.0225,  0.0013],
        ...,
        [-0.0012,  0.0051,  0.0106,  ...,  0.0340,  0.0130, -0.0063],
        [ 0.0010,  0.0341,  0.0190,  ..., -0.0126,  0.0305, -0.0196],
        [ 0.0155,  0.0025,  0.0045,  ..., -0.0184, -0.0195,  0.0410]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8320, -1.6367, -1.5166,  ..., -1.8564, -4.4141, -1.9219]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 04:33:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being dangerous is dangerousness
The state of being foreign is foreignness
The state of being devoted is devotedness
The state of being directed is directedness
The state of being happy is happiness
The state of being reasonable is reasonableness
The state of being situated is situatedness
The state of being useful is
2024-07-28 04:33:44 root INFO     [order_1_approx] starting weight calculation for The state of being dangerous is dangerousness
The state of being useful is usefulness
The state of being happy is happiness
The state of being directed is directedness
The state of being foreign is foreignness
The state of being situated is situatedness
The state of being devoted is devotedness
The state of being reasonable is
2024-07-28 04:33:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 04:36:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0507, -0.2998, -0.1252,  ..., -0.4583,  0.0420, -0.0048],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9160, -1.8379, -0.7202,  ..., -2.7344, -5.0938, -2.0273],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0529, -0.0080, -0.0107,  ..., -0.0002, -0.0170,  0.0305],
        [-0.0265,  0.0342,  0.0109,  ...,  0.0071,  0.0235, -0.0049],
        [ 0.0267, -0.0152,  0.0556,  ..., -0.0112, -0.0168,  0.0127],
        ...,
        [ 0.0175,  0.0166,  0.0233,  ...,  0.0509,  0.0015,  0.0085],
        [ 0.0206,  0.0286,  0.0362,  ..., -0.0011,  0.0384, -0.0123],
        [ 0.0035,  0.0150,  0.0180,  ..., -0.0007, -0.0243,  0.0344]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5518, -1.9092, -0.5400,  ..., -2.2930, -5.2969, -2.2051]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 04:36:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being dangerous is dangerousness
The state of being useful is usefulness
The state of being happy is happiness
The state of being directed is directedness
The state of being foreign is foreignness
The state of being situated is situatedness
The state of being devoted is devotedness
The state of being reasonable is
2024-07-28 04:36:07 root INFO     [order_1_approx] starting weight calculation for The state of being reasonable is reasonableness
The state of being situated is situatedness
The state of being foreign is foreignness
The state of being happy is happiness
The state of being directed is directedness
The state of being useful is usefulness
The state of being dangerous is dangerousness
The state of being devoted is
2024-07-28 04:36:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 04:38:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3057,  0.1045, -0.3379,  ...,  0.2295, -0.6992,  0.3452],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3906, -4.1250, -1.1855,  ..., -1.5449, -3.2031, -1.8086],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0399,  0.0117,  0.0016,  ...,  0.0298,  0.0244,  0.0064],
        [ 0.0199,  0.0260, -0.0032,  ...,  0.0209,  0.0098,  0.0179],
        [ 0.0204, -0.0227,  0.0455,  ..., -0.0117, -0.0113, -0.0032],
        ...,
        [ 0.0129,  0.0013,  0.0141,  ...,  0.0399,  0.0030,  0.0110],
        [ 0.0033,  0.0175,  0.0225,  ..., -0.0213,  0.0537, -0.0251],
        [ 0.0405, -0.0145, -0.0246,  ..., -0.0168, -0.0213,  0.0563]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8457, -3.7656, -1.2188,  ..., -1.8555, -3.5488, -1.5488]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 04:38:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being reasonable is reasonableness
The state of being situated is situatedness
The state of being foreign is foreignness
The state of being happy is happiness
The state of being directed is directedness
The state of being useful is usefulness
The state of being dangerous is dangerousness
The state of being devoted is
2024-07-28 04:38:29 root INFO     [order_1_approx] starting weight calculation for The state of being dangerous is dangerousness
The state of being devoted is devotedness
The state of being happy is happiness
The state of being directed is directedness
The state of being situated is situatedness
The state of being reasonable is reasonableness
The state of being useful is usefulness
The state of being foreign is
2024-07-28 04:38:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 04:40:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0185,  0.1594,  0.1321,  ..., -0.1671,  0.2339,  0.3403],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2866, -2.6543,  0.7061,  ..., -2.3281, -2.1230, -1.2188],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0502,  0.0005,  0.0046,  ...,  0.0156,  0.0122,  0.0081],
        [ 0.0091,  0.0268,  0.0069,  ...,  0.0161,  0.0245, -0.0024],
        [-0.0047,  0.0051,  0.0370,  ..., -0.0093,  0.0020,  0.0103],
        ...,
        [-0.0069,  0.0169, -0.0193,  ...,  0.0223,  0.0083, -0.0164],
        [-0.0114,  0.0154,  0.0059,  ..., -0.0067,  0.0468, -0.0117],
        [ 0.0059,  0.0211, -0.0037,  ...,  0.0054, -0.0207,  0.0366]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5522, -2.3496,  0.5479,  ..., -2.0195, -2.3730, -1.6426]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 04:40:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being dangerous is dangerousness
The state of being devoted is devotedness
The state of being happy is happiness
The state of being directed is directedness
The state of being situated is situatedness
The state of being reasonable is reasonableness
The state of being useful is usefulness
The state of being foreign is
2024-07-28 04:40:51 root INFO     [order_1_approx] starting weight calculation for The state of being dangerous is dangerousness
The state of being situated is situatedness
The state of being useful is usefulness
The state of being reasonable is reasonableness
The state of being devoted is devotedness
The state of being foreign is foreignness
The state of being directed is directedness
The state of being happy is
2024-07-28 04:40:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 04:43:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0012, -0.4573, -0.2949,  ..., -0.1873, -0.2065, -0.0569],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0732,  0.2988,  1.0625,  ..., -2.3242, -4.3594, -2.6113],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.9570e-02,  5.2986e-03,  7.0305e-03,  ...,  1.4915e-02,
          1.4324e-03,  1.5526e-02],
        [ 4.3640e-03,  3.7872e-02,  6.0272e-04,  ...,  2.4475e-02,
          1.3000e-02,  8.3313e-03],
        [-7.5684e-03, -1.4297e-02,  6.2805e-02,  ...,  2.9869e-03,
         -2.8625e-02, -7.9393e-05],
        ...,
        [ 6.8169e-03, -1.1612e-02, -1.6460e-03,  ...,  4.1779e-02,
         -1.8845e-02,  1.0437e-02],
        [-4.3716e-03,  2.2217e-02,  1.1845e-03,  ..., -2.3392e-02,
          5.1849e-02, -2.8992e-02],
        [ 8.9798e-03, -5.5771e-03, -8.8806e-03,  ...,  1.4458e-03,
         -2.4109e-02,  6.8604e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9360, -0.1155,  1.0127,  ..., -1.9043, -4.2695, -2.9453]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 04:43:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being dangerous is dangerousness
The state of being situated is situatedness
The state of being useful is usefulness
The state of being reasonable is reasonableness
The state of being devoted is devotedness
The state of being foreign is foreignness
The state of being directed is directedness
The state of being happy is
2024-07-28 04:43:13 root INFO     [order_1_approx] starting weight calculation for The state of being happy is happiness
The state of being devoted is devotedness
The state of being useful is usefulness
The state of being reasonable is reasonableness
The state of being foreign is foreignness
The state of being dangerous is dangerousness
The state of being directed is directedness
The state of being situated is
2024-07-28 04:43:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 04:45:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1489,  0.1702, -0.2058,  ...,  0.2942, -0.5859, -0.0618],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3164, -2.0508, -2.3301,  ..., -2.8730, -3.5273, -3.2109],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0571,  0.0059,  0.0053,  ...,  0.0209, -0.0026,  0.0426],
        [-0.0076,  0.0443,  0.0024,  ...,  0.0322,  0.0078,  0.0297],
        [ 0.0303, -0.0079,  0.0258,  ..., -0.0054, -0.0298, -0.0085],
        ...,
        [-0.0029,  0.0109,  0.0074,  ...,  0.0446,  0.0026,  0.0092],
        [-0.0092,  0.0136,  0.0047,  ..., -0.0120,  0.0544, -0.0298],
        [ 0.0101,  0.0171,  0.0075,  ...,  0.0044, -0.0490,  0.0180]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2910, -2.5176, -2.8145,  ..., -2.8105, -3.8105, -3.6582]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 04:45:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being happy is happiness
The state of being devoted is devotedness
The state of being useful is usefulness
The state of being reasonable is reasonableness
The state of being foreign is foreignness
The state of being dangerous is dangerousness
The state of being directed is directedness
The state of being situated is
2024-07-28 04:45:32 root INFO     [order_1_approx] starting weight calculation for The state of being situated is situatedness
The state of being happy is happiness
The state of being reasonable is reasonableness
The state of being useful is usefulness
The state of being devoted is devotedness
The state of being directed is directedness
The state of being foreign is foreignness
The state of being dangerous is
2024-07-28 04:45:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 04:47:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0567,  0.2084, -0.4580,  ..., -0.0078, -0.3594, -0.0325],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8066, -4.0273, -1.8516,  ..., -2.4355, -2.0625, -2.1445],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0542, -0.0091, -0.0100,  ...,  0.0018, -0.0188, -0.0007],
        [-0.0143,  0.0197,  0.0242,  ...,  0.0273,  0.0278,  0.0074],
        [-0.0028, -0.0004,  0.0269,  ..., -0.0104, -0.0134, -0.0079],
        ...,
        [ 0.0090,  0.0178,  0.0052,  ...,  0.0268,  0.0049, -0.0080],
        [ 0.0048,  0.0182,  0.0131,  ..., -0.0059,  0.0351, -0.0073],
        [ 0.0155, -0.0067, -0.0020,  ...,  0.0126, -0.0143,  0.0169]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8027, -3.9980, -1.8545,  ..., -2.3438, -2.1270, -2.0996]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 04:47:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being situated is situatedness
The state of being happy is happiness
The state of being reasonable is reasonableness
The state of being useful is usefulness
The state of being devoted is devotedness
The state of being directed is directedness
The state of being foreign is foreignness
The state of being dangerous is
2024-07-28 04:47:54 root INFO     total operator prediction time: 1135.1808938980103 seconds
2024-07-28 04:47:54 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on re+verb_reg
2024-07-28 04:47:54 root INFO     building operator re+verb_reg
2024-07-28 04:47:54 root INFO     [order_1_approx] starting weight calculation for To upload again is to reupload
To install again is to reinstall
To publish again is to republish
To emerge again is to reemerge
To arrange again is to rearrange
To solve again is to resolve
To configure again is to reconfigure
To confirm again is to
2024-07-28 04:47:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 04:50:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0361,  0.1671, -0.1169,  ...,  0.3730,  0.1802,  0.4065],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8950, -3.5996,  2.2676,  ...,  2.9023, -5.2969, -2.4355],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0727, -0.0100,  0.0144,  ..., -0.0113,  0.0079,  0.0179],
        [ 0.0045,  0.0525,  0.0140,  ...,  0.0291, -0.0110,  0.0203],
        [ 0.0070,  0.0061,  0.0427,  ..., -0.0244,  0.0034, -0.0025],
        ...,
        [ 0.0135,  0.0002, -0.0064,  ...,  0.0738,  0.0123,  0.0106],
        [ 0.0121,  0.0149, -0.0188,  ..., -0.0032,  0.0440, -0.0078],
        [-0.0057,  0.0046,  0.0004,  ..., -0.0131, -0.0364,  0.0370]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.9233, -3.9414,  2.3926,  ...,  3.3203, -4.9492, -2.5508]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 04:50:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To upload again is to reupload
To install again is to reinstall
To publish again is to republish
To emerge again is to reemerge
To arrange again is to rearrange
To solve again is to resolve
To configure again is to reconfigure
To confirm again is to
2024-07-28 04:50:12 root INFO     [order_1_approx] starting weight calculation for To upload again is to reupload
To confirm again is to reconfirm
To emerge again is to reemerge
To solve again is to resolve
To arrange again is to rearrange
To install again is to reinstall
To configure again is to reconfigure
To publish again is to
2024-07-28 04:50:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 04:52:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0323,  0.2585, -0.0480,  ...,  0.2417,  0.1897,  0.3801],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4717, -3.4258, -0.9863,  ...,  1.9502, -5.3203, -2.6094],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.8798e-02,  5.1498e-04,  1.2642e-02,  ..., -4.3030e-03,
         -1.0910e-02,  1.4488e-02],
        [-6.4812e-03,  3.9520e-02, -4.0894e-03,  ...,  1.6418e-02,
         -7.8735e-03,  1.6815e-02],
        [ 1.2779e-02,  5.0240e-03,  3.8483e-02,  ..., -2.6123e-02,
          6.6280e-05, -9.4757e-03],
        ...,
        [ 1.0254e-02, -2.6741e-03, -1.6525e-02,  ...,  4.1107e-02,
          2.0035e-02,  1.2894e-03],
        [ 2.9564e-05, -3.4275e-03,  4.9591e-05,  ..., -6.1951e-03,
          3.9978e-02, -5.5542e-03],
        [-6.4278e-04, -3.4637e-03,  6.2408e-03,  ..., -1.4877e-03,
         -3.2257e-02,  3.8422e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6323, -3.5781, -0.9575,  ...,  2.1973, -5.1875, -2.8203]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 04:52:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To upload again is to reupload
To confirm again is to reconfirm
To emerge again is to reemerge
To solve again is to resolve
To arrange again is to rearrange
To install again is to reinstall
To configure again is to reconfigure
To publish again is to
2024-07-28 04:52:28 root INFO     [order_1_approx] starting weight calculation for To install again is to reinstall
To confirm again is to reconfirm
To emerge again is to reemerge
To upload again is to reupload
To configure again is to reconfigure
To publish again is to republish
To arrange again is to rearrange
To solve again is to
2024-07-28 04:52:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 04:54:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1255,  0.1882,  0.0112,  ..., -0.2944, -0.3616,  0.4751],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1846, -1.7480, -1.6299,  ...,  1.5508, -5.6367, -0.2695],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.5868e-02, -7.8797e-05,  2.9556e-02,  ..., -1.1368e-02,
         -8.7357e-03,  8.0109e-03],
        [ 1.4069e-02,  4.0680e-02,  4.7836e-03,  ...,  3.1281e-02,
         -1.2993e-02,  1.2337e-02],
        [-3.0327e-03, -3.2101e-03,  4.1748e-02,  ..., -4.3488e-03,
          2.5162e-02, -5.0125e-03],
        ...,
        [ 2.3422e-02, -2.2087e-03,  2.8114e-03,  ...,  6.5552e-02,
         -2.1381e-03,  5.7030e-03],
        [-2.3819e-02,  2.2308e-02, -7.2479e-03,  ..., -2.4662e-03,
          4.2175e-02, -2.4094e-02],
        [ 8.4229e-03, -1.9913e-02,  2.1118e-02,  ...,  2.1179e-02,
         -1.2421e-02,  6.1157e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0140, -2.1016, -1.4941,  ...,  1.4238, -5.4102, -0.6758]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 04:54:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To install again is to reinstall
To confirm again is to reconfirm
To emerge again is to reemerge
To upload again is to reupload
To configure again is to reconfigure
To publish again is to republish
To arrange again is to rearrange
To solve again is to
2024-07-28 04:54:49 root INFO     [order_1_approx] starting weight calculation for To install again is to reinstall
To emerge again is to reemerge
To arrange again is to rearrange
To configure again is to reconfigure
To confirm again is to reconfirm
To solve again is to resolve
To publish again is to republish
To upload again is to
2024-07-28 04:54:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 04:57:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1317, -0.0845, -0.1893,  ...,  0.0370, -0.0464,  0.0145],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2290, -3.5684,  0.4858,  ...,  1.6348, -3.7305, -1.4717],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0520, -0.0037,  0.0097,  ..., -0.0080, -0.0008,  0.0088],
        [ 0.0065,  0.0425,  0.0023,  ...,  0.0131, -0.0142,  0.0211],
        [ 0.0077, -0.0030,  0.0386,  ..., -0.0072, -0.0108, -0.0077],
        ...,
        [ 0.0070, -0.0115, -0.0089,  ...,  0.0486,  0.0123, -0.0063],
        [ 0.0029,  0.0112, -0.0075,  ..., -0.0090,  0.0267,  0.0004],
        [-0.0028,  0.0053,  0.0024,  ...,  0.0017, -0.0081,  0.0511]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0862, -3.3555,  0.5928,  ...,  1.9014, -3.8105, -1.6006]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 04:57:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To install again is to reinstall
To emerge again is to reemerge
To arrange again is to rearrange
To configure again is to reconfigure
To confirm again is to reconfirm
To solve again is to resolve
To publish again is to republish
To upload again is to
2024-07-28 04:57:08 root INFO     [order_1_approx] starting weight calculation for To configure again is to reconfigure
To confirm again is to reconfirm
To solve again is to resolve
To install again is to reinstall
To emerge again is to reemerge
To publish again is to republish
To upload again is to reupload
To arrange again is to
2024-07-28 04:57:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 04:59:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3264,  0.4409, -0.3401,  ...,  0.0308, -0.1968, -0.0415],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0806, -2.7500, -1.1865,  ...,  2.6133, -4.3750, -5.6406],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0818, -0.0028,  0.0135,  ..., -0.0048, -0.0168,  0.0081],
        [ 0.0109,  0.0453, -0.0125,  ...,  0.0159, -0.0150, -0.0044],
        [ 0.0077,  0.0162,  0.0450,  ..., -0.0251,  0.0065,  0.0045],
        ...,
        [ 0.0278, -0.0166, -0.0019,  ...,  0.0770,  0.0125, -0.0070],
        [-0.0186,  0.0228,  0.0083,  ...,  0.0079,  0.0498, -0.0107],
        [ 0.0217, -0.0114, -0.0117,  ..., -0.0043,  0.0053,  0.0582]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1326, -2.7988, -1.3711,  ...,  2.6914, -4.3438, -5.4141]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 04:59:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To configure again is to reconfigure
To confirm again is to reconfirm
To solve again is to resolve
To install again is to reinstall
To emerge again is to reemerge
To publish again is to republish
To upload again is to reupload
To arrange again is to
2024-07-28 04:59:27 root INFO     [order_1_approx] starting weight calculation for To install again is to reinstall
To configure again is to reconfigure
To confirm again is to reconfirm
To upload again is to reupload
To arrange again is to rearrange
To publish again is to republish
To solve again is to resolve
To emerge again is to
2024-07-28 04:59:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 05:01:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0955,  0.1687, -0.2441,  ...,  0.0690,  0.0198,  0.2876],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4199, -1.5430, -0.9351,  ...,  4.4141, -7.3516, -2.0176],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0578,  0.0074,  0.0124,  ..., -0.0113, -0.0056, -0.0032],
        [ 0.0018,  0.0449,  0.0084,  ...,  0.0158, -0.0071,  0.0205],
        [-0.0066, -0.0022,  0.0196,  ..., -0.0103,  0.0023, -0.0337],
        ...,
        [ 0.0105, -0.0031,  0.0136,  ...,  0.0711, -0.0098,  0.0170],
        [-0.0138,  0.0106, -0.0105,  ..., -0.0116,  0.0529, -0.0126],
        [ 0.0022, -0.0162,  0.0108,  ..., -0.0153, -0.0251,  0.0552]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3906, -1.5977, -0.7705,  ...,  4.3555, -7.2266, -2.1250]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 05:01:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To install again is to reinstall
To configure again is to reconfigure
To confirm again is to reconfirm
To upload again is to reupload
To arrange again is to rearrange
To publish again is to republish
To solve again is to resolve
To emerge again is to
2024-07-28 05:01:48 root INFO     [order_1_approx] starting weight calculation for To solve again is to resolve
To confirm again is to reconfirm
To arrange again is to rearrange
To publish again is to republish
To upload again is to reupload
To emerge again is to reemerge
To configure again is to reconfigure
To install again is to
2024-07-28 05:01:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 05:04:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2079,  0.0093, -0.1357,  ...,  0.2399,  0.0256,  0.0226],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3359, -1.9863, -0.0396,  ...,  2.2246, -2.8926, -3.3516],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0353, -0.0253,  0.0126,  ...,  0.0110, -0.0024,  0.0066],
        [ 0.0051,  0.0355,  0.0008,  ...,  0.0121,  0.0021,  0.0030],
        [ 0.0061,  0.0063,  0.0443,  ..., -0.0188, -0.0160, -0.0021],
        ...,
        [ 0.0099,  0.0095, -0.0122,  ...,  0.0473,  0.0133,  0.0008],
        [ 0.0060, -0.0120,  0.0080,  ..., -0.0073,  0.0157, -0.0032],
        [ 0.0010, -0.0058,  0.0068,  ...,  0.0015, -0.0124,  0.0320]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4319, -2.0430, -0.0169,  ...,  2.3555, -2.4688, -3.4023]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 05:04:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To solve again is to resolve
To confirm again is to reconfirm
To arrange again is to rearrange
To publish again is to republish
To upload again is to reupload
To emerge again is to reemerge
To configure again is to reconfigure
To install again is to
2024-07-28 05:04:05 root INFO     [order_1_approx] starting weight calculation for To upload again is to reupload
To emerge again is to reemerge
To install again is to reinstall
To confirm again is to reconfirm
To arrange again is to rearrange
To publish again is to republish
To solve again is to resolve
To configure again is to
2024-07-28 05:04:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 05:06:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0729, -0.0591, -0.9082,  ..., -0.0087, -0.2203, -0.1217],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.9941, -2.6934,  2.3555,  ...,  3.0781, -3.2734, -1.9375],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0625, -0.0049,  0.0055,  ..., -0.0118,  0.0048,  0.0158],
        [ 0.0019,  0.0471, -0.0023,  ...,  0.0223,  0.0071,  0.0140],
        [-0.0010,  0.0321,  0.0302,  ..., -0.0079,  0.0128,  0.0078],
        ...,
        [ 0.0116, -0.0062, -0.0126,  ...,  0.0571, -0.0053, -0.0133],
        [ 0.0083,  0.0080, -0.0050,  ..., -0.0168,  0.0431, -0.0216],
        [-0.0077, -0.0053,  0.0018,  ...,  0.0023, -0.0186,  0.0405]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.1289, -2.8730,  2.4258,  ...,  3.1191, -2.8809, -2.0059]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 05:06:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To upload again is to reupload
To emerge again is to reemerge
To install again is to reinstall
To confirm again is to reconfirm
To arrange again is to rearrange
To publish again is to republish
To solve again is to resolve
To configure again is to
2024-07-28 05:06:25 root INFO     total operator prediction time: 1111.27689909935 seconds
2024-07-28 05:06:25 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on un+adj_reg
2024-07-28 05:06:25 root INFO     building operator un+adj_reg
2024-07-28 05:06:26 root INFO     [order_1_approx] starting weight calculation for The opposite of veiled is unveiled
The opposite of published is unpublished
The opposite of identified is unidentified
The opposite of finished is unfinished
The opposite of paid is unpaid
The opposite of comfortable is uncomfortable
The opposite of restricted is unrestricted
The opposite of employed is
2024-07-28 05:06:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 05:08:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5977,  0.1997, -0.0690,  ..., -0.0530, -0.3408,  0.0858],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8623, -0.3042, -0.9023,  ..., -0.1748,  1.1992, -2.1621],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.9124e-02,  1.3237e-03,  1.7731e-02,  ...,  1.5289e-02,
         -1.3084e-02,  1.2770e-03],
        [-3.0334e-02,  5.1819e-02, -1.8051e-02,  ...,  1.7715e-02,
          4.4861e-02,  3.0411e-02],
        [ 2.3689e-03,  9.7733e-03,  4.8889e-02,  ..., -1.7609e-02,
          1.2939e-02,  5.8174e-03],
        ...,
        [-1.3752e-03,  1.9150e-02, -1.4046e-02,  ...,  1.8631e-02,
         -3.2997e-03, -1.5564e-03],
        [-2.4353e-02,  2.7580e-03,  4.6844e-03,  ...,  2.0233e-02,
          7.8003e-02, -7.8430e-03],
        [ 3.0041e-03,  6.6757e-05, -1.4076e-02,  ..., -2.8210e-03,
          4.1275e-03,  4.8676e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6465, -0.8516, -1.3184,  ..., -0.0477,  1.2793, -1.7920]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 05:08:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of veiled is unveiled
The opposite of published is unpublished
The opposite of identified is unidentified
The opposite of finished is unfinished
The opposite of paid is unpaid
The opposite of comfortable is uncomfortable
The opposite of restricted is unrestricted
The opposite of employed is
2024-07-28 05:08:48 root INFO     [order_1_approx] starting weight calculation for The opposite of restricted is unrestricted
The opposite of comfortable is uncomfortable
The opposite of published is unpublished
The opposite of employed is unemployed
The opposite of paid is unpaid
The opposite of identified is unidentified
The opposite of finished is unfinished
The opposite of veiled is
2024-07-28 05:08:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 05:11:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1766, -0.5703, -0.2108,  ...,  0.1550,  0.0259,  0.1553],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0424,  0.9336, -0.3145,  ...,  2.9629, -2.1445,  0.0967],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.5491e-02, -1.8631e-02,  1.3840e-02,  ...,  1.5976e-02,
          6.7863e-03,  1.4763e-03],
        [-7.3719e-04,  6.5430e-02, -2.8885e-02,  ...,  1.5793e-02,
         -1.1604e-02, -4.3411e-03],
        [ 5.9395e-03, -2.7161e-03,  4.4678e-02,  ..., -2.2888e-05,
         -1.0117e-02,  1.2039e-02],
        ...,
        [ 1.0967e-03,  5.3177e-03,  2.1759e-02,  ...,  5.7373e-02,
          1.1978e-02,  2.3376e-02],
        [ 7.2708e-03, -5.1689e-03,  7.4997e-03,  ..., -9.2850e-03,
          5.8319e-02, -1.3992e-02],
        [-1.4877e-03, -1.2672e-02, -1.2798e-03,  ...,  7.2060e-03,
          2.3174e-03,  8.5510e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0779,  1.0166, -0.7544,  ...,  3.0645, -2.1895,  0.3513]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 05:11:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of restricted is unrestricted
The opposite of comfortable is uncomfortable
The opposite of published is unpublished
The opposite of employed is unemployed
The opposite of paid is unpaid
The opposite of identified is unidentified
The opposite of finished is unfinished
The opposite of veiled is
2024-07-28 05:11:07 root INFO     [order_1_approx] starting weight calculation for The opposite of finished is unfinished
The opposite of veiled is unveiled
The opposite of published is unpublished
The opposite of identified is unidentified
The opposite of paid is unpaid
The opposite of restricted is unrestricted
The opposite of employed is unemployed
The opposite of comfortable is
2024-07-28 05:11:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 05:13:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2463, -0.4004, -0.1819,  ..., -0.3740, -0.3237,  0.4839],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7568, -0.1846,  1.5078,  ..., -1.6074,  1.2148,  0.9834],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0643,  0.0079,  0.0171,  ..., -0.0197, -0.0009,  0.0168],
        [ 0.0026,  0.0690, -0.0082,  ...,  0.0023,  0.0257, -0.0044],
        [ 0.0060,  0.0008,  0.0523,  ...,  0.0207, -0.0177,  0.0110],
        ...,
        [ 0.0141,  0.0145, -0.0249,  ...,  0.0548,  0.0106, -0.0002],
        [-0.0194, -0.0097,  0.0035,  ...,  0.0051,  0.0350, -0.0060],
        [-0.0438, -0.0372, -0.0137,  ...,  0.0072, -0.0035,  0.0687]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4492, -0.4653,  1.0967,  ..., -1.2100,  0.9736,  0.3394]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 05:13:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of finished is unfinished
The opposite of veiled is unveiled
The opposite of published is unpublished
The opposite of identified is unidentified
The opposite of paid is unpaid
The opposite of restricted is unrestricted
The opposite of employed is unemployed
The opposite of comfortable is
2024-07-28 05:13:30 root INFO     [order_1_approx] starting weight calculation for The opposite of published is unpublished
The opposite of identified is unidentified
The opposite of veiled is unveiled
The opposite of comfortable is uncomfortable
The opposite of employed is unemployed
The opposite of finished is unfinished
The opposite of paid is unpaid
The opposite of restricted is
2024-07-28 05:13:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 05:15:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0469,  0.0759, -0.5898,  ...,  0.0674,  0.2979,  0.0597],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4316,  0.2402,  1.4609,  ...,  0.7559, -1.3301, -1.4004],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.3345e-02, -7.5798e-03,  5.9433e-03,  ...,  5.7220e-05,
         -2.3289e-03,  2.7283e-02],
        [-2.9114e-02,  6.1035e-02,  1.4145e-02,  ..., -4.5891e-03,
          1.1406e-02,  1.1055e-02],
        [ 7.6027e-03, -1.4362e-03,  4.0649e-02,  ..., -7.8087e-03,
         -1.5289e-02,  4.0474e-03],
        ...,
        [ 9.6817e-03,  2.1591e-02,  1.7136e-02,  ...,  4.0009e-02,
          1.0445e-02,  1.5480e-02],
        [ 4.6196e-03, -1.9531e-02, -5.6953e-03,  ...,  4.9362e-03,
          4.4861e-02,  3.2558e-03],
        [-2.0050e-02,  7.9498e-03, -1.8082e-02,  ..., -5.2719e-03,
          2.0508e-02,  5.4779e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3350, -0.1711,  1.1738,  ...,  0.2153, -1.1826, -1.0762]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 05:15:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of published is unpublished
The opposite of identified is unidentified
The opposite of veiled is unveiled
The opposite of comfortable is uncomfortable
The opposite of employed is unemployed
The opposite of finished is unfinished
The opposite of paid is unpaid
The opposite of restricted is
2024-07-28 05:15:52 root INFO     [order_1_approx] starting weight calculation for The opposite of employed is unemployed
The opposite of identified is unidentified
The opposite of veiled is unveiled
The opposite of finished is unfinished
The opposite of published is unpublished
The opposite of restricted is unrestricted
The opposite of comfortable is uncomfortable
The opposite of paid is
2024-07-28 05:15:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 05:18:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4031, -0.4497, -0.2698,  ..., -0.1404, -0.3027, -0.0519],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6602, -2.7520,  0.6016,  ..., -4.7070, -1.6523, -0.9541],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0571, -0.0337, -0.0029,  ..., -0.0113, -0.0367,  0.0195],
        [-0.0090,  0.0670, -0.0131,  ..., -0.0103, -0.0056, -0.0177],
        [ 0.0244,  0.0230,  0.0608,  ...,  0.0144,  0.0331,  0.0212],
        ...,
        [ 0.0052,  0.0315, -0.0189,  ...,  0.0331,  0.0340, -0.0292],
        [-0.0581, -0.0276,  0.0050,  ...,  0.0379,  0.0706, -0.0268],
        [ 0.0102, -0.0154, -0.0348,  ..., -0.0083,  0.0345,  0.0835]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5098, -2.5703,  0.2437,  ..., -4.2383, -2.1230, -1.3936]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 05:18:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of employed is unemployed
The opposite of identified is unidentified
The opposite of veiled is unveiled
The opposite of finished is unfinished
The opposite of published is unpublished
The opposite of restricted is unrestricted
The opposite of comfortable is uncomfortable
The opposite of paid is
2024-07-28 05:18:15 root INFO     [order_1_approx] starting weight calculation for The opposite of identified is unidentified
The opposite of comfortable is uncomfortable
The opposite of employed is unemployed
The opposite of veiled is unveiled
The opposite of paid is unpaid
The opposite of restricted is unrestricted
The opposite of finished is unfinished
The opposite of published is
2024-07-28 05:18:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 05:20:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1418,  0.2612,  0.1665,  ...,  0.0438, -0.0555,  0.1571],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1494, -1.3047,  0.1309,  ..., -2.2090, -0.8057,  1.4414],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0677, -0.0002,  0.0010,  ...,  0.0306, -0.0034,  0.0356],
        [-0.0162,  0.0695, -0.0054,  ...,  0.0063, -0.0052,  0.0038],
        [-0.0014, -0.0128,  0.0386,  ...,  0.0098,  0.0005, -0.0204],
        ...,
        [ 0.0012,  0.0200, -0.0140,  ...,  0.0255,  0.0079, -0.0122],
        [-0.0408, -0.0282,  0.0140,  ...,  0.0243,  0.0820, -0.0208],
        [ 0.0065,  0.0122, -0.0155,  ..., -0.0188,  0.0093,  0.0589]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1415, -1.4863, -0.2632,  ..., -1.3320, -0.2217,  0.9194]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 05:20:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of identified is unidentified
The opposite of comfortable is uncomfortable
The opposite of employed is unemployed
The opposite of veiled is unveiled
The opposite of paid is unpaid
The opposite of restricted is unrestricted
The opposite of finished is unfinished
The opposite of published is
2024-07-28 05:20:37 root INFO     [order_1_approx] starting weight calculation for The opposite of veiled is unveiled
The opposite of restricted is unrestricted
The opposite of comfortable is uncomfortable
The opposite of published is unpublished
The opposite of employed is unemployed
The opposite of paid is unpaid
The opposite of identified is unidentified
The opposite of finished is
2024-07-28 05:20:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 05:22:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2981,  0.0076, -0.2632,  ..., -0.0824, -0.1064,  0.5381],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5420, -1.8574,  0.2021,  ...,  1.0801,  1.1934, -1.9043],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0563, -0.0147, -0.0040,  ..., -0.0107, -0.0138,  0.0035],
        [ 0.0322,  0.0729,  0.0068,  ...,  0.0104,  0.0077,  0.0006],
        [ 0.0099, -0.0072,  0.0510,  ..., -0.0053, -0.0009, -0.0074],
        ...,
        [ 0.0045,  0.0154, -0.0025,  ...,  0.0563, -0.0074, -0.0226],
        [ 0.0080, -0.0014,  0.0332,  ...,  0.0008,  0.0578,  0.0131],
        [ 0.0114,  0.0051, -0.0055,  ...,  0.0172,  0.0099,  0.0438]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3320, -1.5508,  0.5093,  ...,  1.4531,  0.6748, -1.9541]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 05:22:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of veiled is unveiled
The opposite of restricted is unrestricted
The opposite of comfortable is uncomfortable
The opposite of published is unpublished
The opposite of employed is unemployed
The opposite of paid is unpaid
The opposite of identified is unidentified
The opposite of finished is
2024-07-28 05:22:55 root INFO     [order_1_approx] starting weight calculation for The opposite of comfortable is uncomfortable
The opposite of finished is unfinished
The opposite of paid is unpaid
The opposite of published is unpublished
The opposite of veiled is unveiled
The opposite of employed is unemployed
The opposite of restricted is unrestricted
The opposite of identified is
2024-07-28 05:22:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 05:25:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1382,  0.0444, -0.2493,  ..., -0.0062, -0.2969,  0.0662],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.4521, -0.3943,  1.4199,  ...,  0.0286, -0.3149, -1.0508],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0475,  0.0048,  0.0280,  ...,  0.0176,  0.0031,  0.0218],
        [ 0.0090,  0.0523, -0.0068,  ...,  0.0232, -0.0255, -0.0036],
        [ 0.0021, -0.0174,  0.0412,  ...,  0.0242,  0.0121,  0.0054],
        ...,
        [ 0.0149,  0.0069, -0.0191,  ...,  0.0460, -0.0392, -0.0186],
        [-0.0109, -0.0013,  0.0247,  ...,  0.0267,  0.0711, -0.0056],
        [ 0.0170,  0.0083, -0.0256,  ...,  0.0073, -0.0119,  0.0344]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1914, -0.5381,  1.5146,  ...,  0.2449, -0.0807, -1.2539]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 05:25:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of comfortable is uncomfortable
The opposite of finished is unfinished
The opposite of paid is unpaid
The opposite of published is unpublished
The opposite of veiled is unveiled
The opposite of employed is unemployed
The opposite of restricted is unrestricted
The opposite of identified is
2024-07-28 05:25:18 root INFO     total operator prediction time: 1132.2013709545135 seconds
2024-07-28 05:25:18 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+able_reg
2024-07-28 05:25:18 root INFO     building operator verb+able_reg
2024-07-28 05:25:18 root INFO     [order_1_approx] starting weight calculation for If you can execute something, that thing is executable
If you can improve something, that thing is improvable
If you can prefer something, that thing is preferable
If you can learn something, that thing is learnable
If you can recognize something, that thing is recognizable
If you can protect something, that thing is protectable
If you can believe something, that thing is believeable
If you can download something, that thing is
2024-07-28 05:25:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 05:27:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1638, -0.1536, -0.0824,  ...,  0.5229, -0.1182, -0.3328],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.9731, -3.4199,  1.4238,  ..., -3.0625, -7.7500, -2.6953],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0570, -0.0203,  0.0124,  ...,  0.0190,  0.0276,  0.0230],
        [-0.0148,  0.0417,  0.0038,  ...,  0.0041, -0.0044, -0.0038],
        [ 0.0138,  0.0045,  0.0479,  ...,  0.0103, -0.0287, -0.0132],
        ...,
        [ 0.0172,  0.0147,  0.0017,  ...,  0.0664,  0.0210, -0.0128],
        [ 0.0025, -0.0193, -0.0112,  ..., -0.0223,  0.0158, -0.0215],
        [ 0.0036, -0.0024, -0.0129,  ..., -0.0107, -0.0175,  0.0439]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8667, -3.0195,  1.6230,  ..., -2.9629, -7.2070, -2.4961]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 05:27:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can execute something, that thing is executable
If you can improve something, that thing is improvable
If you can prefer something, that thing is preferable
If you can learn something, that thing is learnable
If you can recognize something, that thing is recognizable
If you can protect something, that thing is protectable
If you can believe something, that thing is believeable
If you can download something, that thing is
2024-07-28 05:27:39 root INFO     [order_1_approx] starting weight calculation for If you can download something, that thing is downloadable
If you can protect something, that thing is protectable
If you can execute something, that thing is executable
If you can believe something, that thing is believeable
If you can prefer something, that thing is preferable
If you can improve something, that thing is improvable
If you can learn something, that thing is learnable
If you can recognize something, that thing is
2024-07-28 05:27:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 05:29:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2788,  0.3154, -0.2134,  ...,  0.2607,  0.0024,  0.0282],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-3.3516, -0.8115, -0.1666,  ..., -2.6797, -7.5156, -0.5576],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0835,  0.0066,  0.0051,  ...,  0.0254,  0.0071,  0.0219],
        [-0.0279,  0.0832,  0.0219,  ...,  0.0100, -0.0134,  0.0102],
        [ 0.0166, -0.0233,  0.0666,  ...,  0.0008,  0.0041, -0.0134],
        ...,
        [ 0.0188,  0.0343,  0.0166,  ...,  0.0770,  0.0034,  0.0227],
        [-0.0049, -0.0071,  0.0137,  ..., -0.0255,  0.0585, -0.0239],
        [ 0.0181, -0.0109,  0.0055,  ..., -0.0142, -0.0551,  0.0605]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-3.4902, -1.3594, -0.2859,  ..., -2.6133, -7.3867, -0.9053]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 05:29:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can download something, that thing is downloadable
If you can protect something, that thing is protectable
If you can execute something, that thing is executable
If you can believe something, that thing is believeable
If you can prefer something, that thing is preferable
If you can improve something, that thing is improvable
If you can learn something, that thing is learnable
If you can recognize something, that thing is
2024-07-28 05:29:59 root INFO     [order_1_approx] starting weight calculation for If you can improve something, that thing is improvable
If you can protect something, that thing is protectable
If you can execute something, that thing is executable
If you can believe something, that thing is believeable
If you can prefer something, that thing is preferable
If you can download something, that thing is downloadable
If you can recognize something, that thing is recognizable
If you can learn something, that thing is
2024-07-28 05:29:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 05:32:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0729,  0.1157, -0.0944,  ..., -0.2279, -0.0012,  0.0703],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.6094, -1.5264,  0.7554,  ...,  0.2874, -7.4414, -5.0469],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0320, -0.0114,  0.0008,  ...,  0.0168,  0.0004,  0.0307],
        [-0.0148,  0.0584,  0.0045,  ...,  0.0072, -0.0109,  0.0200],
        [ 0.0064, -0.0186,  0.0320,  ...,  0.0065, -0.0020,  0.0019],
        ...,
        [ 0.0314, -0.0045, -0.0117,  ...,  0.0213,  0.0010, -0.0186],
        [ 0.0058, -0.0076,  0.0097,  ..., -0.0285,  0.0233, -0.0155],
        [-0.0050,  0.0086,  0.0147,  ..., -0.0096, -0.0112,  0.0051]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-3.0273, -1.1943,  0.6436,  ...,  0.4094, -7.3477, -4.9180]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 05:32:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can improve something, that thing is improvable
If you can protect something, that thing is protectable
If you can execute something, that thing is executable
If you can believe something, that thing is believeable
If you can prefer something, that thing is preferable
If you can download something, that thing is downloadable
If you can recognize something, that thing is recognizable
If you can learn something, that thing is
2024-07-28 05:32:19 root INFO     [order_1_approx] starting weight calculation for If you can recognize something, that thing is recognizable
If you can download something, that thing is downloadable
If you can believe something, that thing is believeable
If you can execute something, that thing is executable
If you can improve something, that thing is improvable
If you can learn something, that thing is learnable
If you can protect something, that thing is protectable
If you can prefer something, that thing is
2024-07-28 05:32:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 05:34:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0825, -0.1039, -0.0773,  ..., -0.0194, -0.0138,  0.2886],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0293,  0.4434, -1.4717,  ..., -0.4399, -6.6250, -4.5547],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0726,  0.0041, -0.0050,  ...,  0.0150, -0.0247,  0.0587],
        [-0.0054,  0.0721,  0.0286,  ...,  0.0179, -0.0067, -0.0055],
        [ 0.0034, -0.0118,  0.0448,  ...,  0.0077, -0.0090,  0.0131],
        ...,
        [-0.0012,  0.0040, -0.0065,  ...,  0.0657,  0.0140,  0.0126],
        [ 0.0026,  0.0070,  0.0078,  ..., -0.0377,  0.0483, -0.0023],
        [-0.0113, -0.0278,  0.0006,  ..., -0.0229, -0.0065,  0.0327]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9883,  0.0188, -0.9814,  ..., -0.3027, -6.3438, -4.6367]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 05:34:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can recognize something, that thing is recognizable
If you can download something, that thing is downloadable
If you can believe something, that thing is believeable
If you can execute something, that thing is executable
If you can improve something, that thing is improvable
If you can learn something, that thing is learnable
If you can protect something, that thing is protectable
If you can prefer something, that thing is
2024-07-28 05:34:42 root INFO     [order_1_approx] starting weight calculation for If you can believe something, that thing is believeable
If you can download something, that thing is downloadable
If you can improve something, that thing is improvable
If you can protect something, that thing is protectable
If you can prefer something, that thing is preferable
If you can recognize something, that thing is recognizable
If you can learn something, that thing is learnable
If you can execute something, that thing is
2024-07-28 05:34:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 05:37:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5469,  0.3635, -0.4761,  ...,  0.2175,  0.0042, -0.1041],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3584, -2.8281,  2.3633,  ..., -1.9346, -7.0938, -5.1719],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0390, -0.0099,  0.0088,  ...,  0.0241, -0.0073,  0.0205],
        [-0.0102,  0.0723,  0.0034,  ...,  0.0251, -0.0157, -0.0166],
        [ 0.0087, -0.0039,  0.0517,  ..., -0.0031, -0.0096,  0.0070],
        ...,
        [ 0.0087,  0.0141, -0.0240,  ...,  0.0626,  0.0215, -0.0211],
        [ 0.0112,  0.0038,  0.0042,  ..., -0.0365,  0.0286, -0.0156],
        [ 0.0114, -0.0209,  0.0108,  ..., -0.0275, -0.0134,  0.0316]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4314, -2.6602,  1.9453,  ..., -1.5264, -6.9141, -4.9414]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 05:37:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can believe something, that thing is believeable
If you can download something, that thing is downloadable
If you can improve something, that thing is improvable
If you can protect something, that thing is protectable
If you can prefer something, that thing is preferable
If you can recognize something, that thing is recognizable
If you can learn something, that thing is learnable
If you can execute something, that thing is
2024-07-28 05:37:01 root INFO     [order_1_approx] starting weight calculation for If you can prefer something, that thing is preferable
If you can learn something, that thing is learnable
If you can execute something, that thing is executable
If you can recognize something, that thing is recognizable
If you can improve something, that thing is improvable
If you can protect something, that thing is protectable
If you can download something, that thing is downloadable
If you can believe something, that thing is
2024-07-28 05:37:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 05:39:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1802,  0.2534,  0.0875,  ...,  0.1443, -0.2007,  0.3730],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7202, -1.4736,  0.0596,  ..., -3.1914, -6.2578, -3.0156],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0305, -0.0016, -0.0085,  ...,  0.0210, -0.0255,  0.0266],
        [-0.0159,  0.0354,  0.0169,  ...,  0.0226, -0.0014,  0.0077],
        [ 0.0104,  0.0008,  0.0274,  ...,  0.0046, -0.0139,  0.0094],
        ...,
        [ 0.0081,  0.0034, -0.0145,  ...,  0.0299,  0.0022, -0.0086],
        [ 0.0094,  0.0058, -0.0092,  ..., -0.0340,  0.0319, -0.0145],
        [ 0.0096, -0.0097, -0.0131,  ..., -0.0159, -0.0102,  0.0145]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 7.9932e-01, -1.8867e+00, -8.2397e-04,  ..., -2.7422e+00,
         -6.1016e+00, -3.0352e+00]], device='cuda:1', dtype=torch.float16,
       grad_fn=<SubBackward0>) 

                    
2024-07-28 05:39:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can prefer something, that thing is preferable
If you can learn something, that thing is learnable
If you can execute something, that thing is executable
If you can recognize something, that thing is recognizable
If you can improve something, that thing is improvable
If you can protect something, that thing is protectable
If you can download something, that thing is downloadable
If you can believe something, that thing is
2024-07-28 05:39:19 root INFO     [order_1_approx] starting weight calculation for If you can recognize something, that thing is recognizable
If you can download something, that thing is downloadable
If you can prefer something, that thing is preferable
If you can believe something, that thing is believeable
If you can execute something, that thing is executable
If you can protect something, that thing is protectable
If you can learn something, that thing is learnable
If you can improve something, that thing is
2024-07-28 05:39:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 05:41:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1611, -0.1256, -0.0018,  ...,  0.0623, -0.0383,  0.4448],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4297, -1.4355,  0.5259,  ..., -2.2188, -8.0859, -3.4004],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0431, -0.0136,  0.0037,  ...,  0.0145, -0.0071,  0.0279],
        [-0.0011,  0.0623,  0.0187,  ...,  0.0218, -0.0184,  0.0118],
        [-0.0048, -0.0126,  0.0306,  ...,  0.0056,  0.0132, -0.0159],
        ...,
        [ 0.0148,  0.0023,  0.0025,  ...,  0.0441,  0.0026, -0.0054],
        [-0.0039, -0.0029, -0.0026,  ..., -0.0244,  0.0202, -0.0051],
        [-0.0107, -0.0095, -0.0032,  ..., -0.0097, -0.0222,  0.0109]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3867, -1.7559,  0.6445,  ..., -1.8672, -7.9609, -3.8828]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 05:41:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can recognize something, that thing is recognizable
If you can download something, that thing is downloadable
If you can prefer something, that thing is preferable
If you can believe something, that thing is believeable
If you can execute something, that thing is executable
If you can protect something, that thing is protectable
If you can learn something, that thing is learnable
If you can improve something, that thing is
2024-07-28 05:41:37 root INFO     [order_1_approx] starting weight calculation for If you can recognize something, that thing is recognizable
If you can believe something, that thing is believeable
If you can learn something, that thing is learnable
If you can download something, that thing is downloadable
If you can prefer something, that thing is preferable
If you can improve something, that thing is improvable
If you can execute something, that thing is executable
If you can protect something, that thing is
2024-07-28 05:41:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 05:43:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2925,  0.0021, -0.2412,  ..., -0.0502,  0.1938,  0.1268],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3975, -2.7344, -0.7031,  ..., -1.9551, -6.3594, -1.7061],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0446, -0.0040,  0.0157,  ...,  0.0179,  0.0004,  0.0330],
        [-0.0223,  0.0540,  0.0398,  ...,  0.0197, -0.0086, -0.0028],
        [-0.0044, -0.0031,  0.0095,  ..., -0.0087, -0.0053, -0.0044],
        ...,
        [ 0.0149,  0.0269, -0.0140,  ...,  0.0286,  0.0109,  0.0006],
        [-0.0010,  0.0023,  0.0120,  ..., -0.0326,  0.0252, -0.0269],
        [ 0.0035, -0.0052,  0.0151,  ..., -0.0144, -0.0225,  0.0199]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4897, -3.2109, -0.5566,  ..., -1.4678, -6.1914, -1.7305]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 05:43:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can recognize something, that thing is recognizable
If you can believe something, that thing is believeable
If you can learn something, that thing is learnable
If you can download something, that thing is downloadable
If you can prefer something, that thing is preferable
If you can improve something, that thing is improvable
If you can execute something, that thing is executable
If you can protect something, that thing is
2024-07-28 05:43:54 root INFO     total operator prediction time: 1116.295737028122 seconds
2024-07-28 05:43:54 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+tion_irreg
2024-07-28 05:43:54 root INFO     building operator verb+tion_irreg
2024-07-28 05:43:54 root INFO     [order_1_approx] starting weight calculation for To compile results in compilation
To realize results in realization
To oblige results in obligation
To imagine results in imagination
To deprive results in deprivation
To inspire results in inspiration
To characterize results in characterization
To perspire results in
2024-07-28 05:43:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 05:46:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0608, -0.1666, -0.7539,  ..., -0.1549,  0.2032, -0.2539],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7773, -4.9688,  1.3369,  ..., -1.3906, -0.6479, -0.7764],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0220,  0.0066, -0.0240,  ..., -0.0478,  0.0486, -0.0455],
        [ 0.0591,  0.0685,  0.0106,  ...,  0.0360, -0.0364,  0.0438],
        [ 0.0015, -0.0016,  0.0681,  ...,  0.0126, -0.0094,  0.0052],
        ...,
        [ 0.0432, -0.0089,  0.0072,  ...,  0.0764, -0.0168,  0.0290],
        [-0.0071, -0.0096,  0.0168,  ...,  0.0115,  0.0471, -0.0086],
        [ 0.0177, -0.0184,  0.0007,  ...,  0.0088, -0.0154,  0.0662]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0078, -5.0508,  1.1768,  ..., -1.5176, -0.3799, -0.9263]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 05:46:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To compile results in compilation
To realize results in realization
To oblige results in obligation
To imagine results in imagination
To deprive results in deprivation
To inspire results in inspiration
To characterize results in characterization
To perspire results in
2024-07-28 05:46:15 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To compile results in compilation
To realize results in realization
To imagine results in imagination
To oblige results in obligation
To perspire results in perspiration
To deprive results in deprivation
To inspire results in
2024-07-28 05:46:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 05:48:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0058,  0.3142, -0.5308,  ...,  0.2817, -0.0866,  0.1367],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9551, -3.2520,  1.6602,  ...,  4.2070, -1.0684, -2.1562],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0655,  0.0069, -0.0003,  ..., -0.0195, -0.0059,  0.0002],
        [ 0.0138,  0.0767,  0.0134,  ...,  0.0367, -0.0057,  0.0012],
        [ 0.0111, -0.0086,  0.0417,  ..., -0.0057,  0.0080,  0.0064],
        ...,
        [-0.0042,  0.0047, -0.0019,  ...,  0.0533,  0.0052,  0.0087],
        [ 0.0032,  0.0103,  0.0052,  ...,  0.0039,  0.0530, -0.0091],
        [ 0.0028, -0.0139,  0.0012,  ...,  0.0157, -0.0202,  0.0541]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1348, -3.4316,  1.8330,  ...,  4.3008, -1.1719, -2.5605]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 05:48:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To characterize results in characterization
To compile results in compilation
To realize results in realization
To imagine results in imagination
To oblige results in obligation
To perspire results in perspiration
To deprive results in deprivation
To inspire results in
2024-07-28 05:48:38 root INFO     [order_1_approx] starting weight calculation for To imagine results in imagination
To oblige results in obligation
To perspire results in perspiration
To inspire results in inspiration
To characterize results in characterization
To deprive results in deprivation
To realize results in realization
To compile results in
2024-07-28 05:48:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 05:50:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1399,  0.1172, -0.4390,  ...,  0.0060, -0.4138, -0.0362],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6270, -4.6367,  3.3477,  ...,  1.2852, -1.9570,  0.4404],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0767,  0.0090,  0.0189,  ...,  0.0067,  0.0091,  0.0112],
        [ 0.0123,  0.0684,  0.0247,  ...,  0.0359, -0.0069,  0.0262],
        [-0.0008, -0.0293,  0.0476,  ..., -0.0037,  0.0095, -0.0189],
        ...,
        [ 0.0103, -0.0066,  0.0237,  ...,  0.0817,  0.0041, -0.0089],
        [-0.0125,  0.0141,  0.0092,  ...,  0.0074,  0.0687, -0.0107],
        [ 0.0137, -0.0058,  0.0348,  ...,  0.0146, -0.0221,  0.0820]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4900, -4.5352,  3.3145,  ...,  1.2607, -1.9307, -0.0085]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 05:50:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To imagine results in imagination
To oblige results in obligation
To perspire results in perspiration
To inspire results in inspiration
To characterize results in characterization
To deprive results in deprivation
To realize results in realization
To compile results in
2024-07-28 05:51:00 root INFO     [order_1_approx] starting weight calculation for To deprive results in deprivation
To realize results in realization
To inspire results in inspiration
To perspire results in perspiration
To oblige results in obligation
To imagine results in imagination
To compile results in compilation
To characterize results in
2024-07-28 05:51:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 05:53:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0234, -0.0084, -0.2957,  ...,  0.1716, -0.3411, -0.4863],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.4189, -0.8818,  3.0195,  ...,  2.7754, -2.0586, -2.4844],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0302, -0.0096,  0.0193,  ..., -0.0204,  0.0317, -0.0163],
        [ 0.0042,  0.0527,  0.0069,  ...,  0.0465, -0.0060,  0.0284],
        [-0.0019, -0.0226,  0.0253,  ...,  0.0118,  0.0085, -0.0089],
        ...,
        [ 0.0184,  0.0013,  0.0153,  ...,  0.0528, -0.0025,  0.0217],
        [ 0.0155, -0.0089,  0.0244,  ..., -0.0063,  0.0451,  0.0008],
        [ 0.0015, -0.0096, -0.0006,  ..., -0.0014, -0.0105,  0.0328]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.4922, -0.8350,  3.0156,  ...,  2.9043, -1.9082, -2.4531]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 05:53:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To deprive results in deprivation
To realize results in realization
To inspire results in inspiration
To perspire results in perspiration
To oblige results in obligation
To imagine results in imagination
To compile results in compilation
To characterize results in
2024-07-28 05:53:21 root INFO     [order_1_approx] starting weight calculation for To deprive results in deprivation
To compile results in compilation
To oblige results in obligation
To characterize results in characterization
To imagine results in imagination
To perspire results in perspiration
To inspire results in inspiration
To realize results in
2024-07-28 05:53:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 05:55:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2175, -0.0169, -0.6553,  ...,  0.0543, -0.1586,  0.1338],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6748, -4.6719,  1.7793,  ...,  2.6719, -2.0527, -0.7725],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0450, -0.0002, -0.0044,  ..., -0.0416,  0.0058, -0.0011],
        [ 0.0597,  0.0742,  0.0448,  ...,  0.0529, -0.0014,  0.0485],
        [-0.0054, -0.0282,  0.0669,  ..., -0.0025,  0.0013, -0.0139],
        ...,
        [ 0.0293,  0.0277,  0.0131,  ...,  0.0973,  0.0178,  0.0264],
        [-0.0274,  0.0043, -0.0016,  ..., -0.0265,  0.0604, -0.0696],
        [ 0.0307, -0.0040,  0.0150,  ...,  0.0245, -0.0304,  0.0906]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6562, -4.3555,  2.1797,  ...,  3.0312, -2.2754, -0.8174]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 05:55:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To deprive results in deprivation
To compile results in compilation
To oblige results in obligation
To characterize results in characterization
To imagine results in imagination
To perspire results in perspiration
To inspire results in inspiration
To realize results in
2024-07-28 05:55:43 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To realize results in realization
To imagine results in imagination
To compile results in compilation
To deprive results in deprivation
To inspire results in inspiration
To perspire results in perspiration
To oblige results in
2024-07-28 05:55:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 05:58:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0892,  1.0908, -0.6924,  ...,  0.0864, -0.1700, -0.1382],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5898, -5.2422,  0.7373,  ...,  2.6953, -1.2715, -0.8418],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0597,  0.0066,  0.0119,  ...,  0.0051, -0.0113,  0.0002],
        [ 0.0040,  0.0690,  0.0025,  ...,  0.0430, -0.0044,  0.0093],
        [-0.0098, -0.0196,  0.0222,  ...,  0.0110,  0.0043,  0.0086],
        ...,
        [ 0.0007,  0.0093,  0.0051,  ...,  0.0557, -0.0015,  0.0279],
        [-0.0080, -0.0048, -0.0126,  ...,  0.0053,  0.0619, -0.0260],
        [ 0.0086, -0.0062,  0.0112,  ...,  0.0231, -0.0184,  0.0531]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5996, -5.3711,  1.1035,  ...,  2.1816, -1.5322, -1.0684]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 05:58:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To characterize results in characterization
To realize results in realization
To imagine results in imagination
To compile results in compilation
To deprive results in deprivation
To inspire results in inspiration
To perspire results in perspiration
To oblige results in
2024-07-28 05:58:04 root INFO     [order_1_approx] starting weight calculation for To compile results in compilation
To characterize results in characterization
To deprive results in deprivation
To perspire results in perspiration
To realize results in realization
To inspire results in inspiration
To oblige results in obligation
To imagine results in
2024-07-28 05:58:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 06:00:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0725, -0.0506,  0.2295,  ..., -0.1744, -0.2747, -0.1149],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5332, -3.1758,  5.1953,  ...,  2.0723, -2.0508, -0.3521],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.0823e-03,  2.3499e-03, -3.3325e-02,  ..., -1.5236e-02,
          6.6757e-04, -1.8494e-02],
        [ 6.3110e-02,  8.0688e-02,  5.0110e-02,  ...,  3.8788e-02,
         -5.4283e-03,  3.0792e-02],
        [-6.7520e-03, -2.5635e-02,  4.9072e-02,  ..., -6.6071e-03,
         -5.5161e-03,  9.0504e-04],
        ...,
        [ 9.1629e-03,  4.8637e-05, -9.4299e-03,  ...,  8.3313e-02,
          8.1253e-03,  4.5967e-03],
        [ 2.7817e-02,  1.3039e-02,  2.0447e-02,  ...,  4.3716e-03,
          5.9937e-02, -7.9117e-03],
        [ 2.7740e-02,  1.2329e-02,  3.6621e-04,  ...,  8.2016e-03,
         -3.2532e-02,  6.4697e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0508, -2.2207,  4.6797,  ...,  2.6836, -2.2695, -1.0840]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 06:00:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To compile results in compilation
To characterize results in characterization
To deprive results in deprivation
To perspire results in perspiration
To realize results in realization
To inspire results in inspiration
To oblige results in obligation
To imagine results in
2024-07-28 06:00:25 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To imagine results in imagination
To inspire results in inspiration
To perspire results in perspiration
To realize results in realization
To compile results in compilation
To oblige results in obligation
To deprive results in
2024-07-28 06:00:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 06:02:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3862,  0.4116, -0.6841,  ...,  0.0940,  0.1151,  0.4485],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4473, -3.7812,  2.1035,  ...,  0.7256, -3.7773, -2.2852],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0235,  0.0070, -0.0213,  ..., -0.0692,  0.0278, -0.0107],
        [ 0.0356,  0.0536,  0.0270,  ...,  0.0873, -0.0024,  0.0209],
        [-0.0085, -0.0327,  0.0299,  ..., -0.0034,  0.0033, -0.0133],
        ...,
        [ 0.0260, -0.0013, -0.0088,  ...,  0.0791,  0.0013,  0.0211],
        [-0.0123, -0.0017,  0.0197,  ...,  0.0078,  0.0674, -0.0187],
        [ 0.0296, -0.0118,  0.0130,  ...,  0.0166, -0.0360,  0.0614]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9219, -4.0586,  2.3340,  ...,  0.7681, -3.8105, -2.6133]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 06:02:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To characterize results in characterization
To imagine results in imagination
To inspire results in inspiration
To perspire results in perspiration
To realize results in realization
To compile results in compilation
To oblige results in obligation
To deprive results in
2024-07-28 06:02:47 root INFO     total operator prediction time: 1132.6200013160706 seconds
2024-07-28 06:02:47 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj+ly_reg
2024-07-28 06:02:47 root INFO     building operator adj+ly_reg
2024-07-28 06:02:47 root INFO     [order_1_approx] starting weight calculation for The adjective form of according is accordingly
The adjective form of subsequent is subsequently
The adjective form of practical is practically
The adjective form of serious is seriously
The adjective form of beautiful is beautifully
The adjective form of popular is popularly
The adjective form of critical is critically
The adjective form of successful is
2024-07-28 06:02:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 06:05:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4851,  0.1331, -0.1772,  ..., -0.1155, -0.3589, -0.0085],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3301, -1.2139,  0.3184,  ...,  0.2969, -1.2168, -2.2188],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0442, -0.0072,  0.0141,  ...,  0.0078, -0.0059,  0.0257],
        [-0.0140,  0.0471, -0.0051,  ...,  0.0199, -0.0028, -0.0079],
        [ 0.0199, -0.0095,  0.0395,  ...,  0.0033, -0.0188,  0.0002],
        ...,
        [-0.0154, -0.0065, -0.0118,  ...,  0.0538, -0.0005,  0.0118],
        [-0.0228,  0.0114,  0.0036,  ...,  0.0030,  0.0405, -0.0336],
        [-0.0108, -0.0127, -0.0007,  ...,  0.0052, -0.0092,  0.0138]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0156, -1.2842,  0.6108,  ...,  0.3389, -0.9971, -2.1348]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 06:05:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of according is accordingly
The adjective form of subsequent is subsequently
The adjective form of practical is practically
The adjective form of serious is seriously
The adjective form of beautiful is beautifully
The adjective form of popular is popularly
The adjective form of critical is critically
The adjective form of successful is
2024-07-28 06:05:09 root INFO     [order_1_approx] starting weight calculation for The adjective form of according is accordingly
The adjective form of practical is practically
The adjective form of successful is successfully
The adjective form of popular is popularly
The adjective form of serious is seriously
The adjective form of subsequent is subsequently
The adjective form of critical is critically
The adjective form of beautiful is
2024-07-28 06:05:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 06:07:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6885, -0.1113, -0.0851,  ...,  0.0206, -0.2262, -0.1792],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2676, -2.3164, -0.7437,  ...,  0.9502, -3.3789, -2.4961],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0823, -0.0098,  0.0247,  ..., -0.0066,  0.0039,  0.0172],
        [ 0.0128,  0.0579, -0.0014,  ...,  0.0014,  0.0061,  0.0070],
        [ 0.0152, -0.0158,  0.0938,  ...,  0.0173, -0.0040, -0.0232],
        ...,
        [-0.0012, -0.0228, -0.0218,  ...,  0.0934, -0.0040, -0.0121],
        [-0.0085,  0.0212,  0.0038,  ..., -0.0003,  0.0321,  0.0208],
        [-0.0068, -0.0114, -0.0122,  ...,  0.0147, -0.0279,  0.0173]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1582, -2.2461, -0.4453,  ...,  0.5586, -3.7207, -2.8164]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 06:07:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of according is accordingly
The adjective form of practical is practically
The adjective form of successful is successfully
The adjective form of popular is popularly
The adjective form of serious is seriously
The adjective form of subsequent is subsequently
The adjective form of critical is critically
The adjective form of beautiful is
2024-07-28 06:07:32 root INFO     [order_1_approx] starting weight calculation for The adjective form of practical is practically
The adjective form of successful is successfully
The adjective form of according is accordingly
The adjective form of serious is seriously
The adjective form of critical is critically
The adjective form of popular is popularly
The adjective form of beautiful is beautifully
The adjective form of subsequent is
2024-07-28 06:07:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 06:09:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0191,  0.3057, -0.2651,  ..., -0.3059, -0.4431,  0.1653],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7500,  0.7622,  1.8682,  ..., -0.4844,  1.6953, -3.4336],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0640, -0.0127,  0.0058,  ..., -0.0155,  0.0323,  0.0067],
        [-0.0102,  0.0868,  0.0134,  ...,  0.0425, -0.0167, -0.0113],
        [ 0.0392, -0.0297,  0.0663,  ..., -0.0200, -0.0177,  0.0083],
        ...,
        [ 0.0084,  0.0195,  0.0040,  ...,  0.1009,  0.0031,  0.0244],
        [-0.0251,  0.0013,  0.0375,  ..., -0.0078,  0.0376,  0.0031],
        [-0.0116, -0.0024, -0.0077,  ..., -0.0191, -0.0279,  0.0547]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2285,  0.4707,  2.1387,  ...,  0.0913,  1.5967, -3.7207]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 06:09:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of practical is practically
The adjective form of successful is successfully
The adjective form of according is accordingly
The adjective form of serious is seriously
The adjective form of critical is critically
The adjective form of popular is popularly
The adjective form of beautiful is beautifully
The adjective form of subsequent is
2024-07-28 06:09:54 root INFO     [order_1_approx] starting weight calculation for The adjective form of according is accordingly
The adjective form of subsequent is subsequently
The adjective form of practical is practically
The adjective form of critical is critically
The adjective form of beautiful is beautifully
The adjective form of successful is successfully
The adjective form of serious is seriously
The adjective form of popular is
2024-07-28 06:09:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 06:12:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4834,  0.1621, -0.1301,  ...,  0.2583, -0.3926, -0.0934],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6348, -2.2969, -1.6211,  ..., -0.5024, -2.1328, -0.5957],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0657, -0.0088,  0.0216,  ...,  0.0109, -0.0059,  0.0236],
        [ 0.0101,  0.0516,  0.0055,  ...,  0.0061, -0.0378,  0.0018],
        [ 0.0190, -0.0008,  0.0624,  ...,  0.0115,  0.0065, -0.0067],
        ...,
        [ 0.0064, -0.0010, -0.0130,  ...,  0.0726, -0.0294,  0.0248],
        [-0.0121,  0.0123,  0.0212,  ...,  0.0076,  0.0505, -0.0121],
        [-0.0118, -0.0122, -0.0189,  ..., -0.0187, -0.0276,  0.0200]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5664, -2.2012, -1.7754,  ..., -0.2729, -2.0469, -0.7119]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 06:12:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of according is accordingly
The adjective form of subsequent is subsequently
The adjective form of practical is practically
The adjective form of critical is critically
The adjective form of beautiful is beautifully
The adjective form of successful is successfully
The adjective form of serious is seriously
The adjective form of popular is
2024-07-28 06:12:16 root INFO     [order_1_approx] starting weight calculation for The adjective form of beautiful is beautifully
The adjective form of critical is critically
The adjective form of practical is practically
The adjective form of subsequent is subsequently
The adjective form of serious is seriously
The adjective form of popular is popularly
The adjective form of successful is successfully
The adjective form of according is
2024-07-28 06:12:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 06:14:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4346, -0.0934, -0.7197,  ..., -0.4512, -0.4402, -0.2678],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6470, -3.8496,  1.3516,  ...,  2.8633, -1.9424, -0.9473],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0804, -0.0218,  0.0125,  ..., -0.0105,  0.0369,  0.0200],
        [-0.0061,  0.0616, -0.0029,  ...,  0.0048, -0.0173,  0.0101],
        [ 0.0200, -0.0159,  0.0659,  ..., -0.0260, -0.0101, -0.0086],
        ...,
        [-0.0034,  0.0227, -0.0036,  ...,  0.0924,  0.0035,  0.0067],
        [-0.0156, -0.0240,  0.0252,  ..., -0.0393,  0.0227,  0.0096],
        [-0.0235, -0.0337, -0.0156,  ...,  0.0153, -0.0136,  0.0473]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6636, -2.7090,  1.6592,  ...,  2.4531, -2.6758, -1.5166]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 06:14:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of beautiful is beautifully
The adjective form of critical is critically
The adjective form of practical is practically
The adjective form of subsequent is subsequently
The adjective form of serious is seriously
The adjective form of popular is popularly
The adjective form of successful is successfully
The adjective form of according is
2024-07-28 06:14:32 root INFO     [order_1_approx] starting weight calculation for The adjective form of popular is popularly
The adjective form of serious is seriously
The adjective form of critical is critically
The adjective form of beautiful is beautifully
The adjective form of according is accordingly
The adjective form of successful is successfully
The adjective form of subsequent is subsequently
The adjective form of practical is
2024-07-28 06:14:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 06:16:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3220, -0.1130, -0.1569,  ..., -0.3855, -0.4285, -0.1694],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5254, -3.5117, -0.3555,  ..., -1.2070, -1.2998, -1.0166],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0693, -0.0094, -0.0010,  ...,  0.0121,  0.0089,  0.0238],
        [-0.0029,  0.0613,  0.0155,  ...,  0.0083,  0.0035, -0.0087],
        [-0.0005, -0.0115,  0.0561,  ...,  0.0016, -0.0185, -0.0052],
        ...,
        [ 0.0241,  0.0097, -0.0044,  ...,  0.1003,  0.0093,  0.0016],
        [ 0.0001, -0.0016,  0.0275,  ..., -0.0170,  0.0501, -0.0101],
        [-0.0054, -0.0035, -0.0107,  ..., -0.0300, -0.0110,  0.0328]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5586, -3.1660, -0.2400,  ..., -0.7837, -1.2988, -0.8359]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 06:16:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of popular is popularly
The adjective form of serious is seriously
The adjective form of critical is critically
The adjective form of beautiful is beautifully
The adjective form of according is accordingly
The adjective form of successful is successfully
The adjective form of subsequent is subsequently
The adjective form of practical is
2024-07-28 06:16:48 root INFO     [order_1_approx] starting weight calculation for The adjective form of successful is successfully
The adjective form of according is accordingly
The adjective form of beautiful is beautifully
The adjective form of popular is popularly
The adjective form of subsequent is subsequently
The adjective form of practical is practically
The adjective form of serious is seriously
The adjective form of critical is
2024-07-28 06:16:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 06:19:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1985, -0.1543, -0.3086,  ..., -0.1498, -0.1954, -0.1183],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7129, -2.5371,  1.8242,  ..., -1.3799,  0.7441, -0.0576],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0714, -0.0257, -0.0053,  ..., -0.0093,  0.0041, -0.0079],
        [-0.0170,  0.0557,  0.0129,  ..., -0.0010, -0.0064, -0.0002],
        [ 0.0031,  0.0150,  0.0587,  ...,  0.0035, -0.0178,  0.0127],
        ...,
        [ 0.0047,  0.0212,  0.0161,  ...,  0.0576,  0.0151,  0.0085],
        [-0.0323,  0.0321, -0.0107,  ..., -0.0291,  0.0148, -0.0011],
        [-0.0159, -0.0083, -0.0180,  ..., -0.0005, -0.0180,  0.0391]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4443, -2.2129,  1.7207,  ..., -0.8979,  1.0371,  0.3445]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 06:19:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of successful is successfully
The adjective form of according is accordingly
The adjective form of beautiful is beautifully
The adjective form of popular is popularly
The adjective form of subsequent is subsequently
The adjective form of practical is practically
The adjective form of serious is seriously
The adjective form of critical is
2024-07-28 06:19:10 root INFO     [order_1_approx] starting weight calculation for The adjective form of popular is popularly
The adjective form of beautiful is beautifully
The adjective form of critical is critically
The adjective form of practical is practically
The adjective form of subsequent is subsequently
The adjective form of successful is successfully
The adjective form of according is accordingly
The adjective form of serious is
2024-07-28 06:19:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 06:21:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3455, -0.0294, -0.6899,  ..., -0.0397, -0.6519,  0.2231],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8066, -1.9971, -0.6982,  ..., -1.9609, -0.4370, -4.1133],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0996, -0.0002,  0.0211,  ..., -0.0004,  0.0147,  0.0173],
        [ 0.0069,  0.0427,  0.0076,  ...,  0.0142,  0.0128, -0.0112],
        [ 0.0197, -0.0055,  0.0671,  ...,  0.0137,  0.0107,  0.0045],
        ...,
        [-0.0060,  0.0225, -0.0182,  ...,  0.0721,  0.0025,  0.0195],
        [-0.0348,  0.0161,  0.0083,  ..., -0.0031,  0.0565, -0.0050],
        [ 0.0253, -0.0070,  0.0082,  ...,  0.0064, -0.0384,  0.0455]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2520, -1.7842, -0.4517,  ..., -1.5723, -0.3774, -3.9258]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 06:21:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of popular is popularly
The adjective form of beautiful is beautifully
The adjective form of critical is critically
The adjective form of practical is practically
The adjective form of subsequent is subsequently
The adjective form of successful is successfully
The adjective form of according is accordingly
The adjective form of serious is
2024-07-28 06:21:32 root INFO     total operator prediction time: 1125.1962442398071 seconds
2024-07-28 06:21:32 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on over+adj_reg
2024-07-28 06:21:32 root INFO     building operator over+adj_reg
2024-07-28 06:21:32 root INFO     [order_1_approx] starting weight calculation for If something is too loaded, it is overloaded
If something is too stimulated, it is overstimulated
If something is too played, it is overplayed
If something is too optimistic, it is overoptimistic
If something is too ambitious, it is overambitious
If something is too protective, it is overprotective
If something is too excited, it is overexcited
If something is too confident, it is
2024-07-28 06:21:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 06:23:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1006,  0.0044, -0.1516,  ...,  0.4375, -0.0469,  0.0405],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5229, -3.6836,  1.1797,  ...,  2.0586, -1.0547, -2.1465],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0450, -0.0198, -0.0066,  ..., -0.0023,  0.0086,  0.0167],
        [ 0.0063,  0.0477,  0.0072,  ...,  0.0039,  0.0026,  0.0007],
        [ 0.0047, -0.0024,  0.0368,  ..., -0.0075,  0.0011,  0.0018],
        ...,
        [ 0.0014,  0.0041, -0.0013,  ...,  0.0646,  0.0076, -0.0012],
        [ 0.0096,  0.0068,  0.0095,  ...,  0.0022,  0.0383, -0.0281],
        [-0.0026, -0.0033,  0.0045,  ...,  0.0090, -0.0065,  0.0345]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0469, -3.6895,  0.7578,  ...,  2.2500, -1.1904, -2.3535]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 06:23:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too loaded, it is overloaded
If something is too stimulated, it is overstimulated
If something is too played, it is overplayed
If something is too optimistic, it is overoptimistic
If something is too ambitious, it is overambitious
If something is too protective, it is overprotective
If something is too excited, it is overexcited
If something is too confident, it is
2024-07-28 06:23:51 root INFO     [order_1_approx] starting weight calculation for If something is too ambitious, it is overambitious
If something is too loaded, it is overloaded
If something is too protective, it is overprotective
If something is too confident, it is overconfident
If something is too excited, it is overexcited
If something is too stimulated, it is overstimulated
If something is too optimistic, it is overoptimistic
If something is too played, it is
2024-07-28 06:23:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 06:26:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0901, -0.2166, -0.1396,  ..., -0.3945, -0.4175,  0.3555],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5488, -3.0762,  0.7236,  ...,  0.1726, -0.8237, -2.5371],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0776,  0.0060, -0.0075,  ..., -0.0011,  0.0252,  0.0416],
        [-0.0116,  0.0622, -0.0074,  ..., -0.0020, -0.0079, -0.0095],
        [ 0.0316,  0.0028,  0.0388,  ..., -0.0050, -0.0027,  0.0128],
        ...,
        [ 0.0042, -0.0056, -0.0149,  ...,  0.0768,  0.0075, -0.0003],
        [-0.0055,  0.0066, -0.0002,  ..., -0.0139,  0.0439, -0.0409],
        [-0.0074,  0.0190,  0.0073,  ..., -0.0053,  0.0061,  0.0804]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1055, -2.9785,  0.6162,  ...,  0.8086, -0.5010, -3.2109]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 06:26:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too ambitious, it is overambitious
If something is too loaded, it is overloaded
If something is too protective, it is overprotective
If something is too confident, it is overconfident
If something is too excited, it is overexcited
If something is too stimulated, it is overstimulated
If something is too optimistic, it is overoptimistic
If something is too played, it is
2024-07-28 06:26:12 root INFO     [order_1_approx] starting weight calculation for If something is too stimulated, it is overstimulated
If something is too played, it is overplayed
If something is too confident, it is overconfident
If something is too optimistic, it is overoptimistic
If something is too excited, it is overexcited
If something is too ambitious, it is overambitious
If something is too loaded, it is overloaded
If something is too protective, it is
2024-07-28 06:26:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 06:28:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3171, -0.1665, -0.5381,  ..., -0.0479, -0.1887,  0.1406],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2891, -4.5000,  0.5469,  ...,  0.8789, -1.2383, -2.5820],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0437, -0.0030,  0.0060,  ...,  0.0060,  0.0054,  0.0138],
        [ 0.0058,  0.0263,  0.0025,  ..., -0.0018,  0.0224, -0.0031],
        [-0.0123,  0.0158,  0.0273,  ...,  0.0308, -0.0070,  0.0037],
        ...,
        [-0.0006,  0.0053,  0.0113,  ...,  0.0429,  0.0097,  0.0063],
        [ 0.0103, -0.0006, -0.0118,  ..., -0.0135,  0.0420, -0.0280],
        [-0.0002,  0.0049,  0.0038,  ...,  0.0040, -0.0172,  0.0424]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3096, -4.3672,  0.5596,  ...,  1.0078, -1.1025, -2.7207]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 06:28:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too stimulated, it is overstimulated
If something is too played, it is overplayed
If something is too confident, it is overconfident
If something is too optimistic, it is overoptimistic
If something is too excited, it is overexcited
If something is too ambitious, it is overambitious
If something is too loaded, it is overloaded
If something is too protective, it is
2024-07-28 06:28:33 root INFO     [order_1_approx] starting weight calculation for If something is too excited, it is overexcited
If something is too loaded, it is overloaded
If something is too ambitious, it is overambitious
If something is too stimulated, it is overstimulated
If something is too played, it is overplayed
If something is too confident, it is overconfident
If something is too protective, it is overprotective
If something is too optimistic, it is
2024-07-28 06:28:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 06:30:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1873, -0.2341, -0.2742,  ..., -0.3005,  0.0045,  0.0126],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4336, -3.3125,  0.6152,  ...,  0.6206, -0.4497, -1.7305],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0446,  0.0018, -0.0001,  ...,  0.0019, -0.0011,  0.0009],
        [ 0.0079,  0.0466, -0.0032,  ..., -0.0038,  0.0006, -0.0023],
        [ 0.0106, -0.0076,  0.0368,  ..., -0.0021, -0.0007,  0.0071],
        ...,
        [-0.0015,  0.0005, -0.0021,  ...,  0.0563,  0.0015,  0.0032],
        [-0.0042,  0.0096,  0.0019,  ..., -0.0045,  0.0400, -0.0112],
        [ 0.0002, -0.0060, -0.0026,  ...,  0.0058, -0.0082,  0.0358]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5137, -3.4277,  0.3872,  ...,  0.5684, -0.3889, -1.8213]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 06:30:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too excited, it is overexcited
If something is too loaded, it is overloaded
If something is too ambitious, it is overambitious
If something is too stimulated, it is overstimulated
If something is too played, it is overplayed
If something is too confident, it is overconfident
If something is too protective, it is overprotective
If something is too optimistic, it is
2024-07-28 06:30:52 root INFO     [order_1_approx] starting weight calculation for If something is too protective, it is overprotective
If something is too confident, it is overconfident
If something is too ambitious, it is overambitious
If something is too excited, it is overexcited
If something is too loaded, it is overloaded
If something is too optimistic, it is overoptimistic
If something is too played, it is overplayed
If something is too stimulated, it is
2024-07-28 06:30:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 06:33:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2600, -0.4065, -0.7075,  ..., -0.3623, -0.7363,  0.0535],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0215, -2.3672,  0.2338,  ...,  0.4507, -1.1895, -2.6230],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0465, -0.0002, -0.0047,  ..., -0.0033,  0.0109,  0.0130],
        [ 0.0085,  0.0486,  0.0128,  ..., -0.0085, -0.0108, -0.0124],
        [ 0.0183,  0.0077,  0.0298,  ...,  0.0018,  0.0043, -0.0105],
        ...,
        [ 0.0010,  0.0107, -0.0081,  ...,  0.0566,  0.0161,  0.0121],
        [ 0.0016,  0.0065, -0.0095,  ..., -0.0081,  0.0238, -0.0279],
        [-0.0134,  0.0045,  0.0013,  ...,  0.0118, -0.0175,  0.0437]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1445, -2.5762,  0.1470,  ...,  0.7490, -1.2725, -2.6914]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 06:33:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too protective, it is overprotective
If something is too confident, it is overconfident
If something is too ambitious, it is overambitious
If something is too excited, it is overexcited
If something is too loaded, it is overloaded
If something is too optimistic, it is overoptimistic
If something is too played, it is overplayed
If something is too stimulated, it is
2024-07-28 06:33:12 root INFO     [order_1_approx] starting weight calculation for If something is too loaded, it is overloaded
If something is too played, it is overplayed
If something is too ambitious, it is overambitious
If something is too protective, it is overprotective
If something is too confident, it is overconfident
If something is too stimulated, it is overstimulated
If something is too optimistic, it is overoptimistic
If something is too excited, it is
2024-07-28 06:33:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 06:35:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1459, -0.4609, -0.4814,  ...,  0.1296, -0.5327,  0.4277],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1953, -3.9551, -0.5757,  ...,  0.8818, -0.9546, -3.7266],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0483, -0.0096, -0.0070,  ..., -0.0073,  0.0169,  0.0161],
        [ 0.0113,  0.0586, -0.0048,  ..., -0.0017, -0.0104, -0.0114],
        [ 0.0251, -0.0024,  0.0392,  ...,  0.0039, -0.0047,  0.0062],
        ...,
        [ 0.0099,  0.0180,  0.0003,  ...,  0.0657,  0.0092,  0.0079],
        [ 0.0074,  0.0063, -0.0115,  ..., -0.0038,  0.0397, -0.0277],
        [ 0.0086,  0.0028,  0.0070,  ...,  0.0060, -0.0195,  0.0573]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2800, -4.1641, -0.6953,  ...,  0.8574, -0.9019, -3.9531]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 06:35:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too loaded, it is overloaded
If something is too played, it is overplayed
If something is too ambitious, it is overambitious
If something is too protective, it is overprotective
If something is too confident, it is overconfident
If something is too stimulated, it is overstimulated
If something is too optimistic, it is overoptimistic
If something is too excited, it is
2024-07-28 06:35:32 root INFO     [order_1_approx] starting weight calculation for If something is too played, it is overplayed
If something is too confident, it is overconfident
If something is too ambitious, it is overambitious
If something is too optimistic, it is overoptimistic
If something is too protective, it is overprotective
If something is too excited, it is overexcited
If something is too stimulated, it is overstimulated
If something is too loaded, it is
2024-07-28 06:35:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 06:37:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3198, -0.1567, -0.5479,  ..., -0.1375, -0.4041,  0.4534],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4678, -2.7930,  0.8345,  ...,  1.6572, -2.0410, -1.8047],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.9845e-02, -9.1019e-03, -4.5166e-03,  ...,  1.1604e-02,
          1.1169e-02,  8.1711e-03],
        [ 2.6474e-03,  4.3610e-02, -5.4474e-03,  ...,  5.3635e-03,
          3.3188e-03, -9.5139e-03],
        [ 4.3297e-03,  1.7380e-02,  4.9438e-02,  ...,  1.2695e-02,
         -4.2610e-03,  6.9857e-05],
        ...,
        [ 1.3992e-02,  1.6571e-02, -1.8139e-03,  ...,  6.3110e-02,
          2.0905e-02, -9.4757e-03],
        [ 1.0757e-02,  2.9335e-03, -2.8198e-02,  ..., -2.2984e-03,
          5.2429e-02, -2.3407e-02],
        [ 3.1471e-03, -2.8439e-03, -8.7662e-03,  ...,  4.7722e-03,
          6.2084e-04,  6.0944e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8037, -2.3398,  0.3433,  ...,  1.7764, -1.5928, -1.8574]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 06:37:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too played, it is overplayed
If something is too confident, it is overconfident
If something is too ambitious, it is overambitious
If something is too optimistic, it is overoptimistic
If something is too protective, it is overprotective
If something is too excited, it is overexcited
If something is too stimulated, it is overstimulated
If something is too loaded, it is
2024-07-28 06:37:54 root INFO     [order_1_approx] starting weight calculation for If something is too loaded, it is overloaded
If something is too confident, it is overconfident
If something is too protective, it is overprotective
If something is too excited, it is overexcited
If something is too stimulated, it is overstimulated
If something is too optimistic, it is overoptimistic
If something is too played, it is overplayed
If something is too ambitious, it is
2024-07-28 06:37:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 06:40:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3157, -0.0896, -0.6079,  ..., -0.2213, -0.2253, -0.0391],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0039, -3.2031, -0.0913,  ...,  0.6694, -1.3418, -2.5859],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0351,  0.0021,  0.0015,  ...,  0.0037,  0.0044,  0.0064],
        [-0.0005,  0.0309, -0.0012,  ..., -0.0116,  0.0082, -0.0073],
        [ 0.0038, -0.0019,  0.0296,  ..., -0.0025,  0.0075,  0.0003],
        ...,
        [ 0.0070,  0.0079, -0.0089,  ...,  0.0392,  0.0038, -0.0044],
        [-0.0010,  0.0068,  0.0013,  ...,  0.0046,  0.0453, -0.0107],
        [-0.0029, -0.0113, -0.0086,  ..., -0.0106, -0.0131,  0.0365]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0371, -3.1758, -0.0225,  ...,  0.9321, -1.3291, -2.4902]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 06:40:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too loaded, it is overloaded
If something is too confident, it is overconfident
If something is too protective, it is overprotective
If something is too excited, it is overexcited
If something is too stimulated, it is overstimulated
If something is too optimistic, it is overoptimistic
If something is too played, it is overplayed
If something is too ambitious, it is
2024-07-28 06:40:15 root INFO     total operator prediction time: 1123.175444841385 seconds
2024-07-28 06:40:15 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+er_irreg
2024-07-28 06:40:15 root INFO     building operator verb+er_irreg
2024-07-28 06:40:15 root INFO     [order_1_approx] starting weight calculation for If you contend something, you are a contender
If you eat something, you are a eater
If you interpret something, you are a interpreter
If you suffer something, you are a sufferer
If you defend something, you are a defender
If you subscribe something, you are a subscriber
If you achieve something, you are a achiever
If you compose something, you are a
2024-07-28 06:40:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 06:42:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3906,  0.2294, -0.3857,  ..., -0.1964, -0.0323, -0.0449],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4863, -3.1582,  0.6753,  ...,  0.6621, -3.3867, -1.0840],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0354, -0.0110, -0.0006,  ...,  0.0204, -0.0073,  0.0173],
        [ 0.0074,  0.0459, -0.0022,  ...,  0.0168,  0.0336, -0.0055],
        [ 0.0008, -0.0106,  0.0403,  ...,  0.0027, -0.0104,  0.0043],
        ...,
        [ 0.0394,  0.0243,  0.0043,  ...,  0.0569,  0.0065, -0.0493],
        [ 0.0140,  0.0186, -0.0051,  ..., -0.0258,  0.0360, -0.0045],
        [-0.0082,  0.0065,  0.0046,  ..., -0.0069, -0.0073,  0.0238]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6885, -3.1250,  0.7725,  ...,  1.1221, -3.4980, -0.9673]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 06:42:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you contend something, you are a contender
If you eat something, you are a eater
If you interpret something, you are a interpreter
If you suffer something, you are a sufferer
If you defend something, you are a defender
If you subscribe something, you are a subscriber
If you achieve something, you are a achiever
If you compose something, you are a
2024-07-28 06:42:36 root INFO     [order_1_approx] starting weight calculation for If you interpret something, you are a interpreter
If you contend something, you are a contender
If you achieve something, you are a achiever
If you compose something, you are a composer
If you eat something, you are a eater
If you defend something, you are a defender
If you suffer something, you are a sufferer
If you subscribe something, you are a
2024-07-28 06:42:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 06:44:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0566, -0.0059, -0.3799,  ...,  0.3496,  0.0562,  0.0736],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2031, -2.9473,  1.4521,  ...,  0.6387, -1.2695, -4.8672],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0626, -0.0022,  0.0083,  ...,  0.0103,  0.0045,  0.0244],
        [-0.0134,  0.0300,  0.0331,  ...,  0.0269, -0.0008, -0.0184],
        [ 0.0241, -0.0220,  0.0363,  ..., -0.0035, -0.0198,  0.0032],
        ...,
        [ 0.0170,  0.0316, -0.0013,  ...,  0.0560,  0.0153,  0.0038],
        [ 0.0042,  0.0112,  0.0027,  ..., -0.0080,  0.0308, -0.0277],
        [ 0.0063, -0.0131, -0.0089,  ..., -0.0151, -0.0094,  0.0255]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9902, -3.0098,  1.5703,  ...,  0.5986, -1.4102, -4.8477]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 06:44:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you interpret something, you are a interpreter
If you contend something, you are a contender
If you achieve something, you are a achiever
If you compose something, you are a composer
If you eat something, you are a eater
If you defend something, you are a defender
If you suffer something, you are a sufferer
If you subscribe something, you are a
2024-07-28 06:44:58 root INFO     [order_1_approx] starting weight calculation for If you compose something, you are a composer
If you defend something, you are a defender
If you subscribe something, you are a subscriber
If you interpret something, you are a interpreter
If you contend something, you are a contender
If you eat something, you are a eater
If you achieve something, you are a achiever
If you suffer something, you are a
2024-07-28 06:44:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 06:47:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0474,  0.1066,  0.0270,  ..., -0.4475,  0.1238,  0.0165],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.3516, -3.2500,  0.6445,  ..., -2.3125,  0.2061, -0.1592],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0365, -0.0338,  0.0283,  ...,  0.0067, -0.0137,  0.0111],
        [-0.0096,  0.0377,  0.0030,  ...,  0.0056,  0.0220, -0.0156],
        [ 0.0060, -0.0117,  0.0359,  ...,  0.0027, -0.0017, -0.0096],
        ...,
        [ 0.0121,  0.0128, -0.0110,  ...,  0.0258,  0.0145, -0.0070],
        [-0.0031,  0.0382, -0.0092,  ...,  0.0029,  0.0210, -0.0271],
        [ 0.0098, -0.0030,  0.0096,  ..., -0.0077, -0.0169,  0.0198]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.3633, -3.1074,  0.3545,  ..., -1.8174,  0.0066, -0.4294]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 06:47:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you compose something, you are a composer
If you defend something, you are a defender
If you subscribe something, you are a subscriber
If you interpret something, you are a interpreter
If you contend something, you are a contender
If you eat something, you are a eater
If you achieve something, you are a achiever
If you suffer something, you are a
2024-07-28 06:47:19 root INFO     [order_1_approx] starting weight calculation for If you defend something, you are a defender
If you subscribe something, you are a subscriber
If you eat something, you are a eater
If you compose something, you are a composer
If you contend something, you are a contender
If you achieve something, you are a achiever
If you suffer something, you are a sufferer
If you interpret something, you are a
2024-07-28 06:47:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 06:49:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1919,  0.0428, -0.1547,  ...,  0.3743,  0.1580,  0.1777],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8086, -3.0195,  4.0547,  ..., -1.7666, -4.1172, -4.2188],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0415, -0.0027,  0.0012,  ...,  0.0244, -0.0055,  0.0194],
        [ 0.0037,  0.0554,  0.0105,  ...,  0.0060,  0.0094, -0.0153],
        [ 0.0126,  0.0043,  0.0210,  ...,  0.0099, -0.0337,  0.0121],
        ...,
        [ 0.0149,  0.0058,  0.0059,  ...,  0.0318,  0.0204, -0.0116],
        [ 0.0090, -0.0034,  0.0021,  ..., -0.0245,  0.0295, -0.0082],
        [-0.0065,  0.0006,  0.0264,  ..., -0.0270, -0.0208,  0.0374]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9121, -3.1855,  4.2188,  ..., -1.6250, -4.2812, -4.3125]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 06:49:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you defend something, you are a defender
If you subscribe something, you are a subscriber
If you eat something, you are a eater
If you compose something, you are a composer
If you contend something, you are a contender
If you achieve something, you are a achiever
If you suffer something, you are a sufferer
If you interpret something, you are a
2024-07-28 06:49:41 root INFO     [order_1_approx] starting weight calculation for If you suffer something, you are a sufferer
If you contend something, you are a contender
If you defend something, you are a defender
If you compose something, you are a composer
If you interpret something, you are a interpreter
If you achieve something, you are a achiever
If you subscribe something, you are a subscriber
If you eat something, you are a
2024-07-28 06:49:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 06:52:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2106, -0.2505, -0.2043,  ..., -0.2141, -0.0883, -0.1153],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9590, -0.3369,  0.3250,  ...,  0.6797, -6.4453, -3.9121],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0396, -0.0045, -0.0006,  ...,  0.0108,  0.0071,  0.0149],
        [-0.0040,  0.0557, -0.0209,  ...,  0.0074,  0.0314, -0.0147],
        [ 0.0031, -0.0230,  0.0367,  ..., -0.0066, -0.0140,  0.0149],
        ...,
        [ 0.0226,  0.0027,  0.0012,  ...,  0.0391,  0.0043, -0.0244],
        [-0.0032,  0.0285, -0.0122,  ..., -0.0251,  0.0245,  0.0118],
        [ 0.0101, -0.0148,  0.0091,  ..., -0.0014, -0.0236,  0.0248]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9736, -0.3755,  0.1770,  ...,  1.0957, -6.6602, -4.0312]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 06:52:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you suffer something, you are a sufferer
If you contend something, you are a contender
If you defend something, you are a defender
If you compose something, you are a composer
If you interpret something, you are a interpreter
If you achieve something, you are a achiever
If you subscribe something, you are a subscriber
If you eat something, you are a
2024-07-28 06:52:03 root INFO     [order_1_approx] starting weight calculation for If you suffer something, you are a sufferer
If you defend something, you are a defender
If you subscribe something, you are a subscriber
If you interpret something, you are a interpreter
If you eat something, you are a eater
If you achieve something, you are a achiever
If you compose something, you are a composer
If you contend something, you are a
2024-07-28 06:52:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 06:54:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2759,  0.3994, -0.6616,  ..., -0.0337, -0.0287, -0.1235],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4863, -5.6797,  2.2188,  ..., -3.2969, -1.3438, -3.0938],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0445,  0.0105,  0.0175,  ...,  0.0211,  0.0004,  0.0258],
        [ 0.0084,  0.0544,  0.0043,  ...,  0.0226,  0.0322,  0.0103],
        [-0.0007,  0.0046,  0.0481,  ..., -0.0082,  0.0173,  0.0112],
        ...,
        [ 0.0387,  0.0027,  0.0006,  ...,  0.0497,  0.0157,  0.0169],
        [-0.0178,  0.0149,  0.0230,  ..., -0.0352,  0.0684, -0.0282],
        [ 0.0119, -0.0025, -0.0053,  ..., -0.0046, -0.0056,  0.0281]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5293, -5.8125,  2.4688,  ..., -2.6484, -1.5283, -2.8594]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 06:54:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you suffer something, you are a sufferer
If you defend something, you are a defender
If you subscribe something, you are a subscriber
If you interpret something, you are a interpreter
If you eat something, you are a eater
If you achieve something, you are a achiever
If you compose something, you are a composer
If you contend something, you are a
2024-07-28 06:54:24 root INFO     [order_1_approx] starting weight calculation for If you eat something, you are a eater
If you achieve something, you are a achiever
If you subscribe something, you are a subscriber
If you suffer something, you are a sufferer
If you contend something, you are a contender
If you compose something, you are a composer
If you interpret something, you are a interpreter
If you defend something, you are a
2024-07-28 06:54:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 06:56:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4758, -0.0789, -0.1802,  ..., -0.0941,  0.3047, -0.0091],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1758, -5.8672,  3.2812,  ..., -3.2812, -3.4727, -3.7148],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0518,  0.0040,  0.0033,  ...,  0.0103,  0.0018, -0.0021],
        [-0.0172,  0.0263, -0.0112,  ...,  0.0169,  0.0330, -0.0090],
        [ 0.0078, -0.0072,  0.0134,  ..., -0.0173,  0.0114,  0.0130],
        ...,
        [ 0.0147,  0.0051, -0.0158,  ...,  0.0381,  0.0097, -0.0059],
        [ 0.0015,  0.0116, -0.0148,  ..., -0.0116,  0.0434, -0.0213],
        [ 0.0095, -0.0093,  0.0082,  ..., -0.0040, -0.0219,  0.0237]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4922, -5.7617,  3.6387,  ..., -2.7598, -3.5176, -3.7246]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 06:56:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you eat something, you are a eater
If you achieve something, you are a achiever
If you subscribe something, you are a subscriber
If you suffer something, you are a sufferer
If you contend something, you are a contender
If you compose something, you are a composer
If you interpret something, you are a interpreter
If you defend something, you are a
2024-07-28 06:56:46 root INFO     [order_1_approx] starting weight calculation for If you interpret something, you are a interpreter
If you compose something, you are a composer
If you contend something, you are a contender
If you defend something, you are a defender
If you suffer something, you are a sufferer
If you subscribe something, you are a subscriber
If you eat something, you are a eater
If you achieve something, you are a
2024-07-28 06:56:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 06:59:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2598,  0.2715, -0.3577,  ...,  0.2446, -0.2761,  0.0660],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1953, -1.0439, -0.5796,  ...,  0.3535, -4.6289, -2.5078],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0493,  0.0027,  0.0133,  ...,  0.0137, -0.0147,  0.0318],
        [-0.0095,  0.0462,  0.0043,  ...,  0.0141,  0.0173, -0.0066],
        [ 0.0137, -0.0100,  0.0336,  ...,  0.0142, -0.0074,  0.0136],
        ...,
        [ 0.0157,  0.0107, -0.0361,  ...,  0.0370,  0.0262,  0.0093],
        [ 0.0016,  0.0260,  0.0052,  ..., -0.0016,  0.0079,  0.0029],
        [ 0.0071, -0.0170, -0.0031,  ...,  0.0008, -0.0013,  0.0186]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1816, -1.1924, -0.4253,  ...,  0.7559, -4.9492, -2.4355]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 06:59:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you interpret something, you are a interpreter
If you compose something, you are a composer
If you contend something, you are a contender
If you defend something, you are a defender
If you suffer something, you are a sufferer
If you subscribe something, you are a subscriber
If you eat something, you are a eater
If you achieve something, you are a
2024-07-28 06:59:05 root INFO     total operator prediction time: 1129.960561990738 seconds
2024-07-28 06:59:05 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj - superlative
2024-07-28 06:59:05 root INFO     building operator adj - superlative
2024-07-28 06:59:05 root INFO     [order_1_approx] starting weight calculation for If something is the most hot, it is hottest
If something is the most strange, it is strangest
If something is the most noisy, it is noisiest
If something is the most cheap, it is cheapest
If something is the most fierce, it is fiercest
If something is the most weak, it is weakest
If something is the most ugly, it is ugliest
If something is the most mild, it is
2024-07-28 06:59:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 07:01:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1116,  0.2054, -0.2725,  ..., -0.5034,  0.0547, -0.0116],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2041, -3.1172, -0.5010,  ..., -2.0254, -1.4531, -2.5371],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0436, -0.0160, -0.0140,  ...,  0.0124,  0.0075,  0.0128],
        [ 0.0144,  0.0383,  0.0116,  ...,  0.0112,  0.0003,  0.0007],
        [-0.0054, -0.0089,  0.0372,  ..., -0.0085, -0.0112,  0.0103],
        ...,
        [ 0.0204,  0.0413,  0.0108,  ...,  0.0665,  0.0256, -0.0053],
        [-0.0070, -0.0115, -0.0026,  ..., -0.0188,  0.0374, -0.0215],
        [-0.0107,  0.0002,  0.0082,  ...,  0.0047, -0.0103,  0.0191]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9189, -3.1660, -0.7783,  ..., -1.6094, -1.4727, -2.5410]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 07:01:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most hot, it is hottest
If something is the most strange, it is strangest
If something is the most noisy, it is noisiest
If something is the most cheap, it is cheapest
If something is the most fierce, it is fiercest
If something is the most weak, it is weakest
If something is the most ugly, it is ugliest
If something is the most mild, it is
2024-07-28 07:01:26 root INFO     [order_1_approx] starting weight calculation for If something is the most weak, it is weakest
If something is the most ugly, it is ugliest
If something is the most noisy, it is noisiest
If something is the most mild, it is mildest
If something is the most cheap, it is cheapest
If something is the most hot, it is hottest
If something is the most strange, it is strangest
If something is the most fierce, it is
2024-07-28 07:01:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 07:03:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3931,  0.4575, -0.3040,  ..., -0.2332, -0.2524,  0.0391],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.8086, -5.4062, -1.6211,  ..., -2.3555, -2.5840, -0.4756],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0316, -0.0009,  0.0156,  ..., -0.0089, -0.0036, -0.0008],
        [-0.0011,  0.0197,  0.0248,  ...,  0.0015,  0.0305,  0.0075],
        [ 0.0055, -0.0035,  0.0139,  ..., -0.0224, -0.0076, -0.0039],
        ...,
        [ 0.0062,  0.0229,  0.0130,  ...,  0.0343,  0.0155,  0.0007],
        [-0.0013,  0.0020, -0.0087,  ...,  0.0024,  0.0339, -0.0136],
        [-0.0081, -0.0104, -0.0043,  ..., -0.0050, -0.0014,  0.0073]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.8262, -5.3086, -1.4072,  ..., -2.2656, -2.8066, -0.3516]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 07:03:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most weak, it is weakest
If something is the most ugly, it is ugliest
If something is the most noisy, it is noisiest
If something is the most mild, it is mildest
If something is the most cheap, it is cheapest
If something is the most hot, it is hottest
If something is the most strange, it is strangest
If something is the most fierce, it is
2024-07-28 07:03:48 root INFO     [order_1_approx] starting weight calculation for If something is the most noisy, it is noisiest
If something is the most ugly, it is ugliest
If something is the most strange, it is strangest
If something is the most mild, it is mildest
If something is the most hot, it is hottest
If something is the most fierce, it is fiercest
If something is the most cheap, it is cheapest
If something is the most weak, it is
2024-07-28 07:03:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 07:06:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2123, -0.0782, -0.3708,  ..., -0.2744, -0.0587, -0.1136],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8354, -4.2656, -2.0957,  ..., -4.5547,  2.8281, -3.6133],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0258, -0.0070, -0.0124,  ..., -0.0163,  0.0024,  0.0124],
        [ 0.0063,  0.0369,  0.0104,  ...,  0.0042, -0.0092, -0.0018],
        [ 0.0039, -0.0044,  0.0087,  ...,  0.0079, -0.0124,  0.0079],
        ...,
        [ 0.0011,  0.0223, -0.0071,  ...,  0.0337,  0.0187,  0.0011],
        [-0.0008, -0.0045, -0.0072,  ...,  0.0066,  0.0284, -0.0155],
        [ 0.0003, -0.0115,  0.0052,  ..., -0.0021, -0.0115, -0.0014]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2544, -4.0000, -2.3418,  ..., -4.6797,  2.4609, -3.1211]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 07:06:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most noisy, it is noisiest
If something is the most ugly, it is ugliest
If something is the most strange, it is strangest
If something is the most mild, it is mildest
If something is the most hot, it is hottest
If something is the most fierce, it is fiercest
If something is the most cheap, it is cheapest
If something is the most weak, it is
2024-07-28 07:06:09 root INFO     [order_1_approx] starting weight calculation for If something is the most weak, it is weakest
If something is the most mild, it is mildest
If something is the most fierce, it is fiercest
If something is the most strange, it is strangest
If something is the most cheap, it is cheapest
If something is the most ugly, it is ugliest
If something is the most hot, it is hottest
If something is the most noisy, it is
2024-07-28 07:06:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 07:08:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1758,  0.2483, -0.0408,  ...,  0.0641, -0.2537,  0.0692],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-5.0820, -3.8027, -0.7705,  ..., -1.5186, -1.5898,  0.5049],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0458,  0.0084, -0.0080,  ...,  0.0128, -0.0036,  0.0100],
        [ 0.0043,  0.0388,  0.0140,  ...,  0.0083, -0.0032,  0.0170],
        [ 0.0077, -0.0077,  0.0235,  ...,  0.0038, -0.0165, -0.0024],
        ...,
        [ 0.0141,  0.0220,  0.0152,  ...,  0.0237, -0.0112,  0.0022],
        [ 0.0029,  0.0035, -0.0124,  ...,  0.0022,  0.0309, -0.0042],
        [-0.0024,  0.0015, -0.0008,  ..., -0.0127,  0.0039,  0.0138]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-5.1055, -3.8789, -1.3076,  ..., -1.2666, -1.4463,  0.5137]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 07:08:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most weak, it is weakest
If something is the most mild, it is mildest
If something is the most fierce, it is fiercest
If something is the most strange, it is strangest
If something is the most cheap, it is cheapest
If something is the most ugly, it is ugliest
If something is the most hot, it is hottest
If something is the most noisy, it is
2024-07-28 07:08:29 root INFO     [order_1_approx] starting weight calculation for If something is the most ugly, it is ugliest
If something is the most weak, it is weakest
If something is the most noisy, it is noisiest
If something is the most cheap, it is cheapest
If something is the most hot, it is hottest
If something is the most mild, it is mildest
If something is the most fierce, it is fiercest
If something is the most strange, it is
2024-07-28 07:08:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 07:10:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1011, -0.1207, -0.0975,  ..., -0.3457,  0.2053, -0.0120],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7012, -4.4297, -2.2930,  ..., -1.1387, -0.9521, -2.2539],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0399,  0.0070,  0.0076,  ..., -0.0066, -0.0049,  0.0058],
        [ 0.0112,  0.0428,  0.0117,  ...,  0.0119, -0.0029,  0.0052],
        [ 0.0153, -0.0008,  0.0311,  ..., -0.0037, -0.0133,  0.0170],
        ...,
        [-0.0038,  0.0233, -0.0134,  ...,  0.0587,  0.0082, -0.0044],
        [-0.0075,  0.0059,  0.0045,  ...,  0.0028,  0.0286, -0.0158],
        [ 0.0070,  0.0094,  0.0176,  ..., -0.0110, -0.0259,  0.0211]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6016, -4.4297, -2.3789,  ..., -1.1533, -1.3506, -2.1777]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 07:10:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most ugly, it is ugliest
If something is the most weak, it is weakest
If something is the most noisy, it is noisiest
If something is the most cheap, it is cheapest
If something is the most hot, it is hottest
If something is the most mild, it is mildest
If something is the most fierce, it is fiercest
If something is the most strange, it is
2024-07-28 07:10:44 root INFO     [order_1_approx] starting weight calculation for If something is the most mild, it is mildest
If something is the most fierce, it is fiercest
If something is the most weak, it is weakest
If something is the most cheap, it is cheapest
If something is the most noisy, it is noisiest
If something is the most strange, it is strangest
If something is the most hot, it is hottest
If something is the most ugly, it is
2024-07-28 07:10:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 07:13:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1516,  0.1100,  0.2382,  ..., -0.1819,  0.3682, -0.1340],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.2412, -3.8477, -1.2637,  ..., -2.4141, -1.1084,  0.5820],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0338, -0.0174, -0.0074,  ..., -0.0123,  0.0078,  0.0116],
        [ 0.0018,  0.0278,  0.0226,  ..., -0.0046,  0.0048,  0.0070],
        [-0.0036,  0.0018,  0.0380,  ...,  0.0054, -0.0153, -0.0056],
        ...,
        [ 0.0071,  0.0190, -0.0044,  ...,  0.0439,  0.0021, -0.0245],
        [-0.0137,  0.0112,  0.0070,  ...,  0.0064,  0.0364, -0.0180],
        [-0.0025,  0.0061,  0.0005,  ..., -0.0103, -0.0117,  0.0210]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.9824, -3.8418, -1.3242,  ..., -2.2383, -1.1611,  0.5483]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 07:13:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most mild, it is mildest
If something is the most fierce, it is fiercest
If something is the most weak, it is weakest
If something is the most cheap, it is cheapest
If something is the most noisy, it is noisiest
If something is the most strange, it is strangest
If something is the most hot, it is hottest
If something is the most ugly, it is
2024-07-28 07:13:03 root INFO     [order_1_approx] starting weight calculation for If something is the most noisy, it is noisiest
If something is the most fierce, it is fiercest
If something is the most weak, it is weakest
If something is the most cheap, it is cheapest
If something is the most ugly, it is ugliest
If something is the most strange, it is strangest
If something is the most mild, it is mildest
If something is the most hot, it is
2024-07-28 07:13:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 07:15:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0964, -0.2681, -0.1614,  ...,  0.0385, -0.3010, -0.4109],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.4307, -4.9023, -2.6562,  ..., -2.8750, -2.2324,  0.0625],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.7262e-02, -2.1271e-02, -4.8866e-03,  ..., -2.6260e-02,
         -8.1482e-03, -4.8828e-03],
        [-9.7275e-04,  4.4739e-02,  1.3092e-02,  ..., -3.3169e-03,
          3.2578e-03,  2.4776e-03],
        [-1.6556e-03, -4.7836e-03,  2.5238e-02,  ...,  1.3046e-02,
         -1.2299e-02,  2.2568e-02],
        ...,
        [ 2.7294e-03,  2.8336e-02,  5.4703e-03,  ...,  3.9612e-02,
          1.0521e-02, -2.0905e-03],
        [-6.0806e-03,  1.8295e-02, -6.9809e-03,  ..., -3.5133e-03,
          4.6814e-02, -1.4694e-02],
        [ 2.8133e-03, -8.6365e-03, -9.6893e-04,  ..., -1.2985e-02,
         -1.6212e-05,  2.4094e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.4404, -4.6367, -2.8242,  ..., -2.6367, -2.5098,  0.2656]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 07:15:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most noisy, it is noisiest
If something is the most fierce, it is fiercest
If something is the most weak, it is weakest
If something is the most cheap, it is cheapest
If something is the most ugly, it is ugliest
If something is the most strange, it is strangest
If something is the most mild, it is mildest
If something is the most hot, it is
2024-07-28 07:15:25 root INFO     [order_1_approx] starting weight calculation for If something is the most ugly, it is ugliest
If something is the most weak, it is weakest
If something is the most fierce, it is fiercest
If something is the most hot, it is hottest
If something is the most strange, it is strangest
If something is the most mild, it is mildest
If something is the most noisy, it is noisiest
If something is the most cheap, it is
2024-07-28 07:15:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 07:17:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0014, -0.2275, -0.2529,  ..., -0.1482, -0.1309, -0.1932],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.0078, -0.4492, -1.6387,  ..., -2.9590, -1.4004, -1.6230],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0416, -0.0183,  0.0109,  ...,  0.0083,  0.0048,  0.0037],
        [-0.0010,  0.0307,  0.0168,  ..., -0.0115, -0.0003,  0.0137],
        [-0.0041,  0.0128,  0.0245,  ..., -0.0044, -0.0160,  0.0192],
        ...,
        [-0.0038,  0.0218, -0.0046,  ...,  0.0474,  0.0374, -0.0095],
        [-0.0041,  0.0065, -0.0077,  ..., -0.0050,  0.0326, -0.0356],
        [-0.0124, -0.0095,  0.0021,  ..., -0.0086, -0.0077,  0.0246]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.2441, -0.8101, -2.0840,  ..., -2.8789, -1.1426, -1.6582]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 07:17:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most ugly, it is ugliest
If something is the most weak, it is weakest
If something is the most fierce, it is fiercest
If something is the most hot, it is hottest
If something is the most strange, it is strangest
If something is the most mild, it is mildest
If something is the most noisy, it is noisiest
If something is the most cheap, it is
2024-07-28 07:17:47 root INFO     total operator prediction time: 1121.9866306781769 seconds
2024-07-28 07:17:47 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_3pSg - Ved
2024-07-28 07:17:47 root INFO     building operator verb_3pSg - Ved
2024-07-28 07:17:47 root INFO     [order_1_approx] starting weight calculation for When he intends something, something has been intended
When he requires something, something has been required
When he believes something, something has been believed
When he introduces something, something has been introduced
When he develops something, something has been developed
When he adds something, something has been added
When he happens something, something has been happened
When he appoints something, something has been
2024-07-28 07:17:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 07:20:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0439,  0.0798, -0.3606,  ...,  0.1392, -0.0786, -0.1460],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6172,  0.5732,  2.0508,  ...,  0.9561, -1.8975,  0.2559],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0271, -0.0095,  0.0004,  ..., -0.0121, -0.0139,  0.0230],
        [-0.0092,  0.0125,  0.0134,  ...,  0.0083,  0.0285, -0.0031],
        [ 0.0034, -0.0069,  0.0005,  ..., -0.0115, -0.0132, -0.0149],
        ...,
        [ 0.0016,  0.0080, -0.0018,  ..., -0.0011, -0.0046,  0.0246],
        [ 0.0080, -0.0027, -0.0057,  ...,  0.0120,  0.0082, -0.0225],
        [-0.0053,  0.0115,  0.0125,  ...,  0.0065, -0.0020, -0.0010]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4473,  0.5029,  2.2988,  ...,  0.9565, -1.5381, -0.0181]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 07:20:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he intends something, something has been intended
When he requires something, something has been required
When he believes something, something has been believed
When he introduces something, something has been introduced
When he develops something, something has been developed
When he adds something, something has been added
When he happens something, something has been happened
When he appoints something, something has been
2024-07-28 07:20:06 root INFO     [order_1_approx] starting weight calculation for When he develops something, something has been developed
When he adds something, something has been added
When he appoints something, something has been appointed
When he believes something, something has been believed
When he intends something, something has been intended
When he happens something, something has been happened
When he requires something, something has been required
When he introduces something, something has been
2024-07-28 07:20:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 07:22:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.7358, -0.1604, -0.5615,  ...,  0.2917,  0.1588,  0.0185],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6777,  1.0918,  2.4336,  ...,  1.4248, -1.9336, -0.0801],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0430, -0.0005,  0.0046,  ...,  0.0097, -0.0047,  0.0074],
        [-0.0123,  0.0262, -0.0014,  ...,  0.0069, -0.0057, -0.0027],
        [ 0.0051, -0.0077,  0.0202,  ..., -0.0109, -0.0020, -0.0049],
        ...,
        [ 0.0043, -0.0138,  0.0042,  ...,  0.0314, -0.0016,  0.0206],
        [ 0.0144,  0.0040, -0.0047,  ..., -0.0038,  0.0258, -0.0079],
        [-0.0110,  0.0063,  0.0190,  ..., -0.0097, -0.0018,  0.0284]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7129,  0.8618,  2.7422,  ...,  1.3594, -1.8574, -0.3291]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 07:22:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he develops something, something has been developed
When he adds something, something has been added
When he appoints something, something has been appointed
When he believes something, something has been believed
When he intends something, something has been intended
When he happens something, something has been happened
When he requires something, something has been required
When he introduces something, something has been
2024-07-28 07:22:23 root INFO     [order_1_approx] starting weight calculation for When he adds something, something has been added
When he requires something, something has been required
When he appoints something, something has been appointed
When he develops something, something has been developed
When he believes something, something has been believed
When he happens something, something has been happened
When he introduces something, something has been introduced
When he intends something, something has been
2024-07-28 07:22:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 07:24:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4824,  0.1433, -0.3218,  ...,  0.1750,  0.2153,  0.0850],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2891,  2.1230, -0.0034,  ..., -1.0205, -2.1621, -2.6172],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0323, -0.0172, -0.0010,  ..., -0.0044, -0.0059, -0.0033],
        [-0.0323,  0.0159,  0.0074,  ..., -0.0051,  0.0114, -0.0121],
        [ 0.0056,  0.0054,  0.0178,  ..., -0.0178, -0.0089, -0.0205],
        ...,
        [-0.0090,  0.0007,  0.0067,  ...,  0.0224,  0.0159,  0.0202],
        [ 0.0216,  0.0058,  0.0057,  ...,  0.0200,  0.0159, -0.0040],
        [-0.0023,  0.0059,  0.0281,  ...,  0.0024,  0.0034,  0.0077]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1074,  2.4688, -0.0646,  ..., -0.4395, -2.2363, -2.4863]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 07:24:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he adds something, something has been added
When he requires something, something has been required
When he appoints something, something has been appointed
When he develops something, something has been developed
When he believes something, something has been believed
When he happens something, something has been happened
When he introduces something, something has been introduced
When he intends something, something has been
2024-07-28 07:24:44 root INFO     [order_1_approx] starting weight calculation for When he develops something, something has been developed
When he happens something, something has been happened
When he requires something, something has been required
When he intends something, something has been intended
When he introduces something, something has been introduced
When he believes something, something has been believed
When he appoints something, something has been appointed
When he adds something, something has been
2024-07-28 07:24:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 07:27:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2505, -0.5029, -0.2472,  ...,  0.1809, -0.1599,  0.0543],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2754,  1.5830, -0.7104,  ...,  0.8911, -3.3672, -0.2031],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.4840e-02, -4.4098e-03, -6.9380e-05,  ..., -5.0354e-04,
         -6.5231e-03,  1.2718e-02],
        [-1.6464e-02,  2.7161e-02,  1.8204e-02,  ...,  2.5909e-02,
         -1.5450e-02, -2.0218e-04],
        [ 5.2299e-03, -1.1810e-02,  2.5436e-02,  ..., -3.8567e-03,
         -1.5137e-02,  3.2597e-03],
        ...,
        [ 1.5182e-02,  8.1635e-03, -8.9722e-03,  ...,  2.5558e-02,
          3.3234e-02,  1.7014e-02],
        [ 3.7720e-02,  2.8458e-03,  1.7796e-03,  ...,  6.1798e-03,
          2.2491e-02, -1.8402e-02],
        [-9.8267e-03,  2.4109e-03,  3.2288e-02,  ..., -2.0370e-02,
          6.2103e-03,  1.5869e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1953,  1.2275, -0.8535,  ...,  0.6660, -3.0703,  0.0353]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 07:27:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he develops something, something has been developed
When he happens something, something has been happened
When he requires something, something has been required
When he intends something, something has been intended
When he introduces something, something has been introduced
When he believes something, something has been believed
When he appoints something, something has been appointed
When he adds something, something has been
2024-07-28 07:27:04 root INFO     [order_1_approx] starting weight calculation for When he happens something, something has been happened
When he appoints something, something has been appointed
When he believes something, something has been believed
When he introduces something, something has been introduced
When he develops something, something has been developed
When he adds something, something has been added
When he intends something, something has been intended
When he requires something, something has been
2024-07-28 07:27:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 07:29:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2361,  0.0856, -0.0977,  ..., -0.0157, -0.0828, -0.3550],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1221,  0.8228,  1.8066,  ..., -0.8945, -2.5078, -1.7383],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0400, -0.0100,  0.0087,  ..., -0.0038, -0.0047,  0.0178],
        [-0.0225,  0.0246, -0.0009,  ..., -0.0021,  0.0192,  0.0069],
        [-0.0036, -0.0134,  0.0220,  ..., -0.0215,  0.0112, -0.0009],
        ...,
        [-0.0126,  0.0128, -0.0023,  ...,  0.0310,  0.0134,  0.0207],
        [ 0.0069,  0.0077,  0.0020,  ...,  0.0075,  0.0414, -0.0334],
        [-0.0300, -0.0107,  0.0225,  ...,  0.0025,  0.0022,  0.0123]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1863,  0.6694,  1.8506,  ..., -0.9985, -2.2422, -1.4150]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 07:29:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he happens something, something has been happened
When he appoints something, something has been appointed
When he believes something, something has been believed
When he introduces something, something has been introduced
When he develops something, something has been developed
When he adds something, something has been added
When he intends something, something has been intended
When he requires something, something has been
2024-07-28 07:29:24 root INFO     [order_1_approx] starting weight calculation for When he believes something, something has been believed
When he introduces something, something has been introduced
When he intends something, something has been intended
When he happens something, something has been happened
When he appoints something, something has been appointed
When he adds something, something has been added
When he requires something, something has been required
When he develops something, something has been
2024-07-28 07:29:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 07:31:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0338, -0.4041, -0.3042,  ...,  0.0745,  0.0362, -0.0493],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5918, -1.0879,  4.0273,  ..., -0.4307, -2.0547, -2.0391],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0163,  0.0023,  0.0019,  ...,  0.0020, -0.0150,  0.0246],
        [-0.0108,  0.0201,  0.0152,  ...,  0.0087,  0.0153,  0.0130],
        [-0.0079, -0.0019, -0.0041,  ..., -0.0116, -0.0023, -0.0026],
        ...,
        [ 0.0097,  0.0041, -0.0024,  ...,  0.0139, -0.0124,  0.0282],
        [ 0.0137,  0.0035, -0.0093,  ..., -0.0029,  0.0071, -0.0053],
        [-0.0019,  0.0080,  0.0128,  ..., -0.0041,  0.0012, -0.0031]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6465, -1.3057,  4.1953,  ..., -0.6113, -2.2500, -2.3086]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 07:31:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he believes something, something has been believed
When he introduces something, something has been introduced
When he intends something, something has been intended
When he happens something, something has been happened
When he appoints something, something has been appointed
When he adds something, something has been added
When he requires something, something has been required
When he develops something, something has been
2024-07-28 07:31:44 root INFO     [order_1_approx] starting weight calculation for When he introduces something, something has been introduced
When he develops something, something has been developed
When he intends something, something has been intended
When he appoints something, something has been appointed
When he requires something, something has been required
When he adds something, something has been added
When he believes something, something has been believed
When he happens something, something has been
2024-07-28 07:31:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 07:34:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.5317, -0.2844, -0.4683,  ..., -0.1224, -0.1021, -0.3901],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9570,  1.4219,  3.6953,  ..., -0.3679, -4.5000,  1.0957],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0064, -0.0126,  0.0017,  ...,  0.0071, -0.0200,  0.0170],
        [-0.0110,  0.0160,  0.0135,  ..., -0.0018,  0.0096, -0.0212],
        [ 0.0141,  0.0010,  0.0085,  ..., -0.0140,  0.0085,  0.0191],
        ...,
        [ 0.0123,  0.0152, -0.0227,  ...,  0.0046,  0.0235,  0.0122],
        [ 0.0040,  0.0092,  0.0159,  ...,  0.0178,  0.0054, -0.0268],
        [-0.0143, -0.0074,  0.0280,  ..., -0.0026,  0.0004, -0.0031]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8711,  1.2695,  3.9062,  ..., -0.1814, -4.4219,  0.9526]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 07:34:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he introduces something, something has been introduced
When he develops something, something has been developed
When he intends something, something has been intended
When he appoints something, something has been appointed
When he requires something, something has been required
When he adds something, something has been added
When he believes something, something has been believed
When he happens something, something has been
2024-07-28 07:34:05 root INFO     [order_1_approx] starting weight calculation for When he introduces something, something has been introduced
When he intends something, something has been intended
When he adds something, something has been added
When he develops something, something has been developed
When he requires something, something has been required
When he appoints something, something has been appointed
When he happens something, something has been happened
When he believes something, something has been
2024-07-28 07:34:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 07:36:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1974,  0.3315, -0.1495,  ...,  0.1031, -0.4172,  0.2278],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.5898, -0.5830,  1.9053,  ...,  0.7842, -3.3086, -0.8145],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0237, -0.0043,  0.0029,  ..., -0.0006, -0.0043,  0.0361],
        [-0.0095,  0.0351,  0.0077,  ...,  0.0247, -0.0010,  0.0043],
        [-0.0147, -0.0105,  0.0342,  ..., -0.0106, -0.0101,  0.0028],
        ...,
        [ 0.0013,  0.0108, -0.0083,  ...,  0.0270,  0.0122,  0.0115],
        [ 0.0214,  0.0019, -0.0058,  ...,  0.0038,  0.0168, -0.0345],
        [-0.0010, -0.0040,  0.0110,  ..., -0.0025, -0.0072,  0.0034]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.3086, -0.9131,  1.7891,  ...,  0.7725, -3.3242, -0.9556]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 07:36:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he introduces something, something has been introduced
When he intends something, something has been intended
When he adds something, something has been added
When he develops something, something has been developed
When he requires something, something has been required
When he appoints something, something has been appointed
When he happens something, something has been happened
When he believes something, something has been
2024-07-28 07:36:24 root INFO     total operator prediction time: 1117.4386987686157 seconds
2024-07-28 07:36:24 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun - plural_reg
2024-07-28 07:36:24 root INFO     building operator noun - plural_reg
2024-07-28 07:36:25 root INFO     [order_1_approx] starting weight calculation for The plural form of hour is hours
The plural form of problem is problems
The plural form of night is nights
The plural form of street is streets
The plural form of event is events
The plural form of council is councils
The plural form of thing is things
The plural form of friend is
2024-07-28 07:36:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 07:38:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4854, -0.0786, -0.3638,  ...,  0.0490,  0.3149, -0.3193],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9990, -2.3320,  2.9453,  ...,  0.1775, -0.8711, -1.7910],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0595, -0.0074,  0.0099,  ..., -0.0048, -0.0051,  0.0152],
        [ 0.0138,  0.0390,  0.0074,  ...,  0.0131, -0.0036, -0.0033],
        [ 0.0089,  0.0132,  0.0450,  ..., -0.0033, -0.0053,  0.0134],
        ...,
        [-0.0060,  0.0151, -0.0008,  ...,  0.0560, -0.0118,  0.0085],
        [-0.0077,  0.0153, -0.0184,  ...,  0.0258,  0.0548, -0.0028],
        [ 0.0133,  0.0068,  0.0033,  ..., -0.0135, -0.0118,  0.0305]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3281, -2.4004,  2.8633,  ...,  0.0365, -1.3457, -1.8438]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 07:38:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of hour is hours
The plural form of problem is problems
The plural form of night is nights
The plural form of street is streets
The plural form of event is events
The plural form of council is councils
The plural form of thing is things
The plural form of friend is
2024-07-28 07:38:48 root INFO     [order_1_approx] starting weight calculation for The plural form of hour is hours
The plural form of council is councils
The plural form of street is streets
The plural form of friend is friends
The plural form of problem is problems
The plural form of night is nights
The plural form of event is events
The plural form of thing is
2024-07-28 07:38:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 07:41:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3262, -0.0461, -0.3533,  ..., -0.0513,  0.1593, -0.4004],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4219, -2.9570,  1.6650,  ...,  0.1250, -1.6338, -2.5977],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0622,  0.0001,  0.0029,  ..., -0.0030,  0.0052,  0.0115],
        [ 0.0164,  0.0518, -0.0048,  ...,  0.0099,  0.0027,  0.0101],
        [-0.0041, -0.0260,  0.0798,  ..., -0.0184, -0.0247,  0.0234],
        ...,
        [-0.0103,  0.0090, -0.0083,  ...,  0.0572,  0.0057,  0.0248],
        [-0.0213,  0.0139, -0.0194,  ..., -0.0083,  0.0457,  0.0032],
        [ 0.0264,  0.0094, -0.0206,  ...,  0.0057, -0.0331,  0.0752]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8164, -3.9414,  1.7930,  ...,  0.3369, -1.5879, -2.5684]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 07:41:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of hour is hours
The plural form of council is councils
The plural form of street is streets
The plural form of friend is friends
The plural form of problem is problems
The plural form of night is nights
The plural form of event is events
The plural form of thing is
2024-07-28 07:41:11 root INFO     [order_1_approx] starting weight calculation for The plural form of problem is problems
The plural form of thing is things
The plural form of friend is friends
The plural form of street is streets
The plural form of council is councils
The plural form of hour is hours
The plural form of event is events
The plural form of night is
2024-07-28 07:41:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 07:43:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0925,  0.2380,  0.0131,  ..., -0.0172, -0.4639, -0.1411],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7241, -4.1680,  0.3706,  ..., -0.7144, -0.4404, -2.1934],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0476,  0.0024, -0.0027,  ...,  0.0047,  0.0274,  0.0026],
        [ 0.0201,  0.0563, -0.0129,  ...,  0.0143,  0.0170, -0.0131],
        [-0.0008,  0.0036,  0.0206,  ..., -0.0107, -0.0157,  0.0247],
        ...,
        [ 0.0029,  0.0015, -0.0081,  ...,  0.0515, -0.0113,  0.0169],
        [ 0.0058,  0.0168,  0.0026,  ...,  0.0125,  0.0386,  0.0069],
        [-0.0103,  0.0110, -0.0105,  ..., -0.0172, -0.0108,  0.0452]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5850, -3.8535,  0.0576,  ..., -0.9360, -0.1453, -1.5723]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 07:43:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of problem is problems
The plural form of thing is things
The plural form of friend is friends
The plural form of street is streets
The plural form of council is councils
The plural form of hour is hours
The plural form of event is events
The plural form of night is
2024-07-28 07:43:33 root INFO     [order_1_approx] starting weight calculation for The plural form of thing is things
The plural form of hour is hours
The plural form of problem is problems
The plural form of event is events
The plural form of friend is friends
The plural form of night is nights
The plural form of council is councils
The plural form of street is
2024-07-28 07:43:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 07:45:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0360,  0.1852,  0.2102,  ..., -0.0928, -0.1091, -0.0201],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6875, -3.9336, -0.5679,  ...,  1.0195, -0.0447, -2.6250],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0504,  0.0147, -0.0257,  ...,  0.0137, -0.0068, -0.0012],
        [-0.0058,  0.0443, -0.0064,  ...,  0.0123,  0.0055, -0.0138],
        [-0.0021,  0.0225,  0.0422,  ..., -0.0082,  0.0069,  0.0327],
        ...,
        [-0.0059,  0.0139, -0.0109,  ...,  0.0511, -0.0112,  0.0219],
        [-0.0444,  0.0304, -0.0111,  ...,  0.0134,  0.0352,  0.0175],
        [ 0.0149, -0.0046, -0.0077,  ...,  0.0081,  0.0054,  0.0310]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1367, -3.9766,  0.1099,  ...,  1.1621, -0.1418, -2.2852]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 07:45:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of thing is things
The plural form of hour is hours
The plural form of problem is problems
The plural form of event is events
The plural form of friend is friends
The plural form of night is nights
The plural form of council is councils
The plural form of street is
2024-07-28 07:45:53 root INFO     [order_1_approx] starting weight calculation for The plural form of council is councils
The plural form of friend is friends
The plural form of night is nights
The plural form of hour is hours
The plural form of street is streets
The plural form of problem is problems
The plural form of thing is things
The plural form of event is
2024-07-28 07:45:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 07:48:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2712,  0.3564, -0.0966,  ..., -0.4888, -0.2404, -0.4932],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4316, -1.7793,  0.0952,  ...,  0.3660, -1.8965, -2.7520],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0638,  0.0089,  0.0334,  ...,  0.0087,  0.0059,  0.0119],
        [-0.0146,  0.0539,  0.0072,  ...,  0.0087, -0.0028,  0.0013],
        [ 0.0075, -0.0117,  0.0550,  ...,  0.0034,  0.0019,  0.0090],
        ...,
        [-0.0012,  0.0121, -0.0134,  ...,  0.0446, -0.0096, -0.0018],
        [-0.0208, -0.0005, -0.0028,  ..., -0.0073,  0.0445,  0.0002],
        [ 0.0103, -0.0106, -0.0124,  ..., -0.0090, -0.0157,  0.0461]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6484, -1.8652, -0.1307,  ...,  0.9688, -2.0293, -2.4785]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 07:48:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of council is councils
The plural form of friend is friends
The plural form of night is nights
The plural form of hour is hours
The plural form of street is streets
The plural form of problem is problems
The plural form of thing is things
The plural form of event is
2024-07-28 07:48:16 root INFO     [order_1_approx] starting weight calculation for The plural form of friend is friends
The plural form of street is streets
The plural form of problem is problems
The plural form of council is councils
The plural form of thing is things
The plural form of event is events
The plural form of night is nights
The plural form of hour is
2024-07-28 07:48:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 07:50:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2493,  0.0937,  0.1205,  ...,  0.0490, -0.0319, -0.2330],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2910, -3.3320,  0.4785,  ..., -1.3145,  0.7632, -2.5664],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0522,  0.0126,  0.0022,  ...,  0.0127, -0.0178,  0.0162],
        [-0.0060,  0.0498, -0.0103,  ...,  0.0163,  0.0177, -0.0002],
        [ 0.0040,  0.0034,  0.0403,  ..., -0.0017, -0.0275,  0.0294],
        ...,
        [ 0.0136,  0.0118,  0.0185,  ...,  0.0505, -0.0118, -0.0042],
        [ 0.0083, -0.0065,  0.0045,  ...,  0.0070,  0.0342,  0.0070],
        [-0.0012, -0.0052, -0.0129,  ...,  0.0003,  0.0018,  0.0334]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0856, -3.1855,  0.0178,  ..., -1.0840,  0.1807, -2.1719]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 07:50:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of friend is friends
The plural form of street is streets
The plural form of problem is problems
The plural form of council is councils
The plural form of thing is things
The plural form of event is events
The plural form of night is nights
The plural form of hour is
2024-07-28 07:50:35 root INFO     [order_1_approx] starting weight calculation for The plural form of event is events
The plural form of problem is problems
The plural form of street is streets
The plural form of hour is hours
The plural form of friend is friends
The plural form of night is nights
The plural form of thing is things
The plural form of council is
2024-07-28 07:50:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 07:52:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3926,  0.2520, -0.3066,  ...,  0.0007, -0.3853, -0.2429],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3867, -4.7344,  4.9766,  ..., -1.4531,  1.0752, -0.8604],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0648,  0.0204,  0.0179,  ...,  0.0064, -0.0168,  0.0106],
        [ 0.0195,  0.0394,  0.0069,  ...,  0.0193, -0.0024,  0.0008],
        [-0.0024,  0.0038,  0.0573,  ...,  0.0063, -0.0093,  0.0098],
        ...,
        [ 0.0037,  0.0167,  0.0150,  ...,  0.0541, -0.0119,  0.0037],
        [-0.0486,  0.0025, -0.0057,  ..., -0.0009,  0.0292,  0.0021],
        [ 0.0026, -0.0033, -0.0101,  ...,  0.0012, -0.0050,  0.0544]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2793, -4.7148,  4.5195,  ..., -1.4023,  0.6475, -0.6699]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 07:52:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of event is events
The plural form of problem is problems
The plural form of street is streets
The plural form of hour is hours
The plural form of friend is friends
The plural form of night is nights
The plural form of thing is things
The plural form of council is
2024-07-28 07:52:59 root INFO     [order_1_approx] starting weight calculation for The plural form of hour is hours
The plural form of council is councils
The plural form of night is nights
The plural form of event is events
The plural form of friend is friends
The plural form of thing is things
The plural form of street is streets
The plural form of problem is
2024-07-28 07:52:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 07:55:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0825,  0.0265, -0.1060,  ..., -0.3735, -0.4531,  0.2314],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9062, -3.1719,  0.8916,  ..., -0.1436, -0.1714, -0.6318],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0637,  0.0053,  0.0108,  ...,  0.0093,  0.0077,  0.0077],
        [ 0.0131,  0.0459,  0.0040,  ...,  0.0364, -0.0072,  0.0094],
        [-0.0082, -0.0027,  0.0707,  ..., -0.0060, -0.0096,  0.0017],
        ...,
        [ 0.0033,  0.0196, -0.0110,  ...,  0.0628, -0.0010,  0.0160],
        [-0.0317,  0.0043, -0.0105,  ...,  0.0096,  0.0387, -0.0105],
        [ 0.0176,  0.0112, -0.0052,  ...,  0.0078, -0.0229,  0.0542]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9092, -3.4531,  0.9092,  ...,  0.0925, -0.1547, -0.8916]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 07:55:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of hour is hours
The plural form of council is councils
The plural form of night is nights
The plural form of event is events
The plural form of friend is friends
The plural form of thing is things
The plural form of street is streets
The plural form of problem is
2024-07-28 07:55:22 root INFO     total operator prediction time: 1137.165791273117 seconds
2024-07-28 07:55:22 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_Ving - 3pSg
2024-07-28 07:55:22 root INFO     building operator verb_Ving - 3pSg
2024-07-28 07:55:22 root INFO     [order_1_approx] starting weight calculation for When something is consisting, it consists
When something is understanding, it understands
When something is thanking, it thanks
When something is seeming, it seems
When something is creating, it creates
When something is providing, it provides
When something is becoming, it becomes
When something is following, it
2024-07-28 07:55:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 07:57:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0234, -0.0387, -0.0658,  ..., -0.2476,  0.0603, -0.1467],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7891, -3.0195,  0.7207,  ..., -1.0088, -6.6445, -0.2441],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0723,  0.0159, -0.0039,  ...,  0.0217, -0.0018,  0.0166],
        [-0.0027,  0.0632,  0.0141,  ..., -0.0028, -0.0011, -0.0042],
        [-0.0052,  0.0025,  0.0418,  ..., -0.0064, -0.0078, -0.0062],
        ...,
        [ 0.0043,  0.0215, -0.0059,  ...,  0.0550, -0.0070, -0.0003],
        [ 0.0024,  0.0063, -0.0258,  ...,  0.0111,  0.0410, -0.0543],
        [-0.0149,  0.0088,  0.0061,  ..., -0.0173,  0.0024,  0.0151]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2344, -3.3438,  1.1768,  ..., -0.7119, -5.7969, -0.2549]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 07:57:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is consisting, it consists
When something is understanding, it understands
When something is thanking, it thanks
When something is seeming, it seems
When something is creating, it creates
When something is providing, it provides
When something is becoming, it becomes
When something is following, it
2024-07-28 07:57:41 root INFO     [order_1_approx] starting weight calculation for When something is following, it follows
When something is creating, it creates
When something is thanking, it thanks
When something is seeming, it seems
When something is becoming, it becomes
When something is providing, it provides
When something is consisting, it consists
When something is understanding, it
2024-07-28 07:57:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 08:00:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2279,  0.2319,  0.0231,  ..., -0.0922, -0.2180, -0.4561],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5117, -1.8584,  0.1465,  ..., -1.3555, -5.0938,  2.5000],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0294,  0.0045, -0.0016,  ..., -0.0044, -0.0169,  0.0119],
        [ 0.0148,  0.0425,  0.0087,  ...,  0.0056,  0.0066,  0.0136],
        [ 0.0114, -0.0174,  0.0536,  ..., -0.0164, -0.0086, -0.0119],
        ...,
        [ 0.0101,  0.0124,  0.0100,  ...,  0.0367, -0.0117,  0.0034],
        [-0.0054,  0.0015, -0.0002,  ...,  0.0004,  0.0312, -0.0247],
        [-0.0106, -0.0044,  0.0157,  ..., -0.0057, -0.0060,  0.0216]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2500, -1.6553,  0.3101,  ..., -1.3105, -4.7109,  2.4023]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 08:00:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is following, it follows
When something is creating, it creates
When something is thanking, it thanks
When something is seeming, it seems
When something is becoming, it becomes
When something is providing, it provides
When something is consisting, it consists
When something is understanding, it
2024-07-28 08:00:04 root INFO     [order_1_approx] starting weight calculation for When something is thanking, it thanks
When something is following, it follows
When something is seeming, it seems
When something is understanding, it understands
When something is creating, it creates
When something is consisting, it consists
When something is becoming, it becomes
When something is providing, it
2024-07-28 08:00:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 08:02:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5093, -0.4724, -0.2954,  ...,  0.0649, -0.1339, -0.3816],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3066, -7.1641, -0.0293,  ..., -0.8809, -6.6094, -0.1680],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0810,  0.0019,  0.0202,  ...,  0.0130, -0.0177,  0.0438],
        [-0.0116,  0.0517,  0.0105,  ...,  0.0075, -0.0034,  0.0390],
        [-0.0078, -0.0030,  0.0492,  ..., -0.0131, -0.0017, -0.0090],
        ...,
        [ 0.0080, -0.0015,  0.0201,  ...,  0.0751, -0.0019,  0.0223],
        [ 0.0069, -0.0258, -0.0053,  ..., -0.0074,  0.0569, -0.0592],
        [-0.0063, -0.0042,  0.0094,  ..., -0.0248, -0.0084,  0.0457]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9238, -6.8203,  0.2983,  ..., -0.7910, -5.8164, -0.0817]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 08:02:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is thanking, it thanks
When something is following, it follows
When something is seeming, it seems
When something is understanding, it understands
When something is creating, it creates
When something is consisting, it consists
When something is becoming, it becomes
When something is providing, it
2024-07-28 08:02:25 root INFO     [order_1_approx] starting weight calculation for When something is becoming, it becomes
When something is seeming, it seems
When something is thanking, it thanks
When something is following, it follows
When something is providing, it provides
When something is creating, it creates
When something is understanding, it understands
When something is consisting, it
2024-07-28 08:02:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 08:04:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2764, -0.1676, -0.8940,  ...,  0.0458, -0.4133, -0.0359],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7344, -2.3164,  0.1523,  ..., -0.7305, -3.9570,  1.8232],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.8340e-02,  3.9024e-03, -1.6785e-02,  ...,  8.5983e-03,
          7.8430e-03,  1.5167e-02],
        [ 3.1433e-03,  7.9895e-02,  2.4429e-02,  ...,  1.5427e-02,
         -8.9874e-03,  1.5152e-02],
        [-4.2915e-05, -9.6588e-03,  3.7659e-02,  ..., -2.4918e-02,
         -4.7722e-03, -7.5226e-03],
        ...,
        [ 1.3084e-02,  4.8065e-03,  8.0414e-03,  ...,  6.2561e-02,
         -1.5251e-02,  2.4933e-02],
        [-3.0304e-02, -7.8430e-03,  9.7122e-03,  ..., -1.5167e-02,
          5.4718e-02, -2.9221e-02],
        [-1.0963e-02, -3.2043e-02, -6.5193e-03,  ..., -4.8599e-03,
         -5.9547e-03,  2.7390e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9121, -2.0117, -0.3574,  ..., -0.5488, -4.1641,  1.7959]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 08:04:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is becoming, it becomes
When something is seeming, it seems
When something is thanking, it thanks
When something is following, it follows
When something is providing, it provides
When something is creating, it creates
When something is understanding, it understands
When something is consisting, it
2024-07-28 08:04:47 root INFO     [order_1_approx] starting weight calculation for When something is consisting, it consists
When something is becoming, it becomes
When something is following, it follows
When something is understanding, it understands
When something is providing, it provides
When something is seeming, it seems
When something is thanking, it thanks
When something is creating, it
2024-07-28 08:04:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 08:07:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0160, -0.0485, -0.1801,  ..., -0.2461, -0.1157, -0.4556],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3896, -3.8770,  0.8633,  ...,  0.1650, -5.9062,  0.7246],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0646,  0.0015,  0.0096,  ...,  0.0180, -0.0223,  0.0070],
        [ 0.0044,  0.0704, -0.0136,  ...,  0.0160,  0.0020,  0.0080],
        [ 0.0168, -0.0043,  0.0410,  ...,  0.0068, -0.0027,  0.0050],
        ...,
        [ 0.0105,  0.0031,  0.0023,  ...,  0.0483, -0.0065,  0.0052],
        [-0.0052,  0.0267, -0.0391,  ..., -0.0048,  0.0337, -0.0208],
        [-0.0218, -0.0048,  0.0043,  ..., -0.0206, -0.0133,  0.0316]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5430, -3.9219,  0.7573,  ...,  0.3022, -6.1445,  0.7993]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 08:07:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is consisting, it consists
When something is becoming, it becomes
When something is following, it follows
When something is understanding, it understands
When something is providing, it provides
When something is seeming, it seems
When something is thanking, it thanks
When something is creating, it
2024-07-28 08:07:09 root INFO     [order_1_approx] starting weight calculation for When something is creating, it creates
When something is following, it follows
When something is becoming, it becomes
When something is providing, it provides
When something is thanking, it thanks
When something is consisting, it consists
When something is understanding, it understands
When something is seeming, it
2024-07-28 08:07:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 08:09:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1892, -0.1763,  0.0868,  ..., -0.0599, -0.1548, -0.1355],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2656, -2.4082, -3.2109,  ...,  1.2422, -4.1953, -1.2559],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0461, -0.0122,  0.0049,  ..., -0.0047,  0.0027,  0.0083],
        [ 0.0009,  0.0374, -0.0070,  ...,  0.0138,  0.0003,  0.0046],
        [ 0.0113, -0.0107,  0.0387,  ..., -0.0244, -0.0081, -0.0096],
        ...,
        [ 0.0094,  0.0063, -0.0043,  ...,  0.0442, -0.0204,  0.0222],
        [-0.0084,  0.0175, -0.0208,  ..., -0.0043,  0.0304, -0.0472],
        [-0.0158, -0.0053,  0.0271,  ..., -0.0015,  0.0096,  0.0123]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3965, -2.3809, -3.1562,  ...,  1.4180, -4.5234, -1.1240]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 08:09:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is creating, it creates
When something is following, it follows
When something is becoming, it becomes
When something is providing, it provides
When something is thanking, it thanks
When something is consisting, it consists
When something is understanding, it understands
When something is seeming, it
2024-07-28 08:09:31 root INFO     [order_1_approx] starting weight calculation for When something is following, it follows
When something is thanking, it thanks
When something is consisting, it consists
When something is providing, it provides
When something is understanding, it understands
When something is seeming, it seems
When something is creating, it creates
When something is becoming, it
2024-07-28 08:09:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 08:11:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1516,  0.2148,  0.0460,  ...,  0.0759, -0.2140, -0.0639],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1758, -2.8711, -0.2109,  ...,  0.5645, -1.9033, -1.8164],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0490,  0.0082,  0.0094,  ...,  0.0201,  0.0013,  0.0330],
        [ 0.0060,  0.0481, -0.0166,  ...,  0.0164,  0.0033,  0.0237],
        [ 0.0012, -0.0118,  0.0463,  ..., -0.0134,  0.0294,  0.0008],
        ...,
        [ 0.0231, -0.0047, -0.0097,  ...,  0.0731, -0.0075,  0.0294],
        [ 0.0117,  0.0326, -0.0132,  ..., -0.0175,  0.0479, -0.0263],
        [ 0.0021,  0.0039,  0.0103,  ..., -0.0063, -0.0174,  0.0335]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8750, -2.9316, -0.1493,  ...,  0.6514, -2.1016, -1.5430]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 08:11:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is following, it follows
When something is thanking, it thanks
When something is consisting, it consists
When something is providing, it provides
When something is understanding, it understands
When something is seeming, it seems
When something is creating, it creates
When something is becoming, it
2024-07-28 08:11:51 root INFO     [order_1_approx] starting weight calculation for When something is creating, it creates
When something is following, it follows
When something is seeming, it seems
When something is understanding, it understands
When something is becoming, it becomes
When something is providing, it provides
When something is consisting, it consists
When something is thanking, it
2024-07-28 08:11:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 08:14:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3369, -0.0474, -0.1575,  ...,  0.2402, -0.1024, -0.2603],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6191, -3.8730, -1.3516,  ..., -1.4756, -7.4453,  1.2080],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0245,  0.0042,  0.0158,  ..., -0.0007, -0.0037, -0.0047],
        [-0.0013,  0.0296, -0.0065,  ..., -0.0070, -0.0035,  0.0222],
        [-0.0026, -0.0017,  0.0116,  ..., -0.0072, -0.0142, -0.0094],
        ...,
        [ 0.0083,  0.0029, -0.0079,  ...,  0.0155, -0.0069,  0.0163],
        [ 0.0172,  0.0084, -0.0203,  ...,  0.0050,  0.0244, -0.0265],
        [-0.0294, -0.0039,  0.0164,  ...,  0.0075, -0.0081,  0.0162]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4551, -3.8809, -1.1533,  ..., -1.4834, -7.2422,  1.0146]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 08:14:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is creating, it creates
When something is following, it follows
When something is seeming, it seems
When something is understanding, it understands
When something is becoming, it becomes
When something is providing, it provides
When something is consisting, it consists
When something is thanking, it
2024-07-28 08:14:13 root INFO     total operator prediction time: 1131.138417005539 seconds
2024-07-28 08:14:13 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_inf - 3pSg
2024-07-28 08:14:13 root INFO     building operator verb_inf - 3pSg
2024-07-28 08:14:13 root INFO     [order_1_approx] starting weight calculation for I add, he adds
I occur, he occurs
I improve, he improves
I promote, he promotes
I become, he becomes
I seem, he seems
I consider, he considers
I require, he
2024-07-28 08:14:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 08:16:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1897,  0.0107, -0.2632,  ..., -0.3911,  0.1185, -0.4028],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8447, -3.4902,  2.1426,  ..., -0.3257, -6.3438, -0.8262],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0432,  0.0159,  0.0110,  ...,  0.0213, -0.0147,  0.0235],
        [-0.0085,  0.0377, -0.0224,  ..., -0.0017,  0.0017,  0.0121],
        [-0.0091, -0.0137,  0.0265,  ..., -0.0222,  0.0056, -0.0025],
        ...,
        [ 0.0198,  0.0125,  0.0045,  ...,  0.0446, -0.0099,  0.0144],
        [-0.0197, -0.0224, -0.0096,  ..., -0.0261,  0.0364, -0.0350],
        [-0.0235, -0.0212,  0.0079,  ..., -0.0274, -0.0239,  0.0052]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6816, -3.7227,  2.3008,  ..., -0.1226, -5.7344, -0.4790]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 08:16:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I add, he adds
I occur, he occurs
I improve, he improves
I promote, he promotes
I become, he becomes
I seem, he seems
I consider, he considers
I require, he
2024-07-28 08:16:34 root INFO     [order_1_approx] starting weight calculation for I add, he adds
I consider, he considers
I become, he becomes
I improve, he improves
I require, he requires
I promote, he promotes
I seem, he seems
I occur, he
2024-07-28 08:16:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 08:18:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0296,  0.0201, -0.2686,  ..., -0.3806, -0.1042, -0.4807],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5176, -3.4707, -1.3516,  ..., -0.9727, -4.4141,  2.0156],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0289, -0.0011,  0.0205,  ...,  0.0051,  0.0133,  0.0349],
        [-0.0020,  0.0511,  0.0009,  ...,  0.0058, -0.0042, -0.0217],
        [ 0.0011,  0.0008,  0.0304,  ..., -0.0304, -0.0162, -0.0103],
        ...,
        [ 0.0131,  0.0151,  0.0191,  ...,  0.0341, -0.0109,  0.0124],
        [-0.0204, -0.0051, -0.0139,  ..., -0.0167,  0.0073, -0.0244],
        [ 0.0049, -0.0232,  0.0028,  ..., -0.0191, -0.0132,  0.0208]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3069, -3.2832, -1.1436,  ..., -0.2817, -4.4805,  1.8438]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 08:18:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I add, he adds
I consider, he considers
I become, he becomes
I improve, he improves
I require, he requires
I promote, he promotes
I seem, he seems
I occur, he
2024-07-28 08:18:56 root INFO     [order_1_approx] starting weight calculation for I occur, he occurs
I improve, he improves
I seem, he seems
I promote, he promotes
I become, he becomes
I add, he adds
I require, he requires
I consider, he
2024-07-28 08:18:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 08:21:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0889, -0.1305, -0.0046,  ..., -0.0513,  0.3342, -0.1936],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.5000, -4.4883,  2.2070,  ..., -0.2734, -6.3359, -0.4043],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0315,  0.0028,  0.0110,  ...,  0.0074, -0.0068,  0.0278],
        [ 0.0027,  0.0172,  0.0009,  ..., -0.0019,  0.0072, -0.0021],
        [-0.0142, -0.0072,  0.0344,  ..., -0.0233, -0.0100, -0.0005],
        ...,
        [ 0.0096,  0.0015,  0.0145,  ...,  0.0303,  0.0043,  0.0136],
        [-0.0245, -0.0121, -0.0055,  ..., -0.0218,  0.0235, -0.0203],
        [-0.0149, -0.0070,  0.0088,  ..., -0.0115, -0.0150,  0.0096]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9023, -4.1172,  2.2520,  ...,  0.2124, -6.5391, -0.3528]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 08:21:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I occur, he occurs
I improve, he improves
I seem, he seems
I promote, he promotes
I become, he becomes
I add, he adds
I require, he requires
I consider, he
2024-07-28 08:21:18 root INFO     [order_1_approx] starting weight calculation for I promote, he promotes
I add, he adds
I consider, he considers
I improve, he improves
I seem, he seems
I occur, he occurs
I require, he requires
I become, he
2024-07-28 08:21:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 08:23:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2306,  0.1772, -0.1315,  ..., -0.2198, -0.4526,  0.1652],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1641, -2.9922, -0.1484,  ...,  1.2266, -1.7275, -1.4824],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0438,  0.0010,  0.0218,  ...,  0.0058, -0.0022,  0.0331],
        [-0.0116,  0.0311, -0.0060,  ...,  0.0083,  0.0070,  0.0022],
        [-0.0089, -0.0013,  0.0226,  ..., -0.0058, -0.0011, -0.0079],
        ...,
        [ 0.0008,  0.0002, -0.0136,  ...,  0.0384,  0.0008,  0.0062],
        [ 0.0044,  0.0137, -0.0132,  ..., -0.0221,  0.0123, -0.0127],
        [-0.0185, -0.0101,  0.0112,  ..., -0.0128, -0.0147,  0.0080]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8242, -3.0898, -0.0401,  ...,  1.6895, -1.7002, -1.2197]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 08:23:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I promote, he promotes
I add, he adds
I consider, he considers
I improve, he improves
I seem, he seems
I occur, he occurs
I require, he requires
I become, he
2024-07-28 08:23:41 root INFO     [order_1_approx] starting weight calculation for I seem, he seems
I add, he adds
I promote, he promotes
I become, he becomes
I occur, he occurs
I consider, he considers
I require, he requires
I improve, he
2024-07-28 08:23:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 08:25:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1067, -0.2271, -0.1048,  ..., -0.4219, -0.1222,  0.0456],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.2695, -3.4199, -1.6055,  ...,  1.1318, -6.7812,  0.9082],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0313, -0.0029,  0.0034,  ...,  0.0017, -0.0010,  0.0257],
        [ 0.0099,  0.0218, -0.0031,  ..., -0.0029,  0.0098,  0.0033],
        [ 0.0101,  0.0040,  0.0043,  ..., -0.0005,  0.0144,  0.0022],
        ...,
        [ 0.0005,  0.0144, -0.0062,  ...,  0.0318,  0.0126,  0.0010],
        [-0.0113, -0.0203, -0.0139,  ..., -0.0078,  0.0061, -0.0435],
        [-0.0199, -0.0061, -0.0022,  ..., -0.0212, -0.0015, -0.0058]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.9883, -3.2773, -1.2197,  ...,  1.4414, -6.7852,  0.7432]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 08:26:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I seem, he seems
I add, he adds
I promote, he promotes
I become, he becomes
I occur, he occurs
I consider, he considers
I require, he requires
I improve, he
2024-07-28 08:26:01 root INFO     [order_1_approx] starting weight calculation for I promote, he promotes
I improve, he improves
I occur, he occurs
I consider, he considers
I require, he requires
I become, he becomes
I add, he adds
I seem, he
2024-07-28 08:26:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 08:28:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4595, -0.0966, -0.1915,  ...,  0.2285, -0.0859, -0.1849],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5371, -2.0488, -1.6465,  ...,  2.4238, -7.3047, -0.6895],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0519, -0.0067,  0.0087,  ..., -0.0122,  0.0140,  0.0439],
        [-0.0139,  0.0209, -0.0108,  ...,  0.0012,  0.0091, -0.0009],
        [ 0.0006, -0.0111,  0.0398,  ..., -0.0209, -0.0046, -0.0159],
        ...,
        [-0.0009,  0.0032, -0.0011,  ...,  0.0370,  0.0085,  0.0107],
        [-0.0348,  0.0192, -0.0063,  ..., -0.0148,  0.0132, -0.0376],
        [ 0.0010, -0.0134,  0.0165,  ...,  0.0052, -0.0094, -0.0037]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2480, -2.1992, -1.6660,  ...,  2.5840, -6.9727, -0.4663]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 08:28:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I promote, he promotes
I improve, he improves
I occur, he occurs
I consider, he considers
I require, he requires
I become, he becomes
I add, he adds
I seem, he
2024-07-28 08:28:22 root INFO     [order_1_approx] starting weight calculation for I occur, he occurs
I improve, he improves
I add, he adds
I seem, he seems
I become, he becomes
I consider, he considers
I require, he requires
I promote, he
2024-07-28 08:28:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 08:30:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0232,  0.0430, -0.2302,  ..., -0.0687,  0.0650,  0.0789],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.7773, -4.2109, -0.4551,  ..., -0.0586, -9.2969,  0.2402],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0366,  0.0018,  0.0151,  ...,  0.0134, -0.0045,  0.0274],
        [-0.0173,  0.0325, -0.0093,  ...,  0.0058,  0.0202, -0.0007],
        [ 0.0055,  0.0098,  0.0151,  ..., -0.0190, -0.0064,  0.0073],
        ...,
        [ 0.0067,  0.0090, -0.0026,  ...,  0.0354,  0.0107,  0.0062],
        [-0.0291, -0.0040, -0.0198,  ..., -0.0117,  0.0340, -0.0396],
        [-0.0078, -0.0071, -0.0092,  ..., -0.0259, -0.0171,  0.0115]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.5273, -4.0273, -0.3545,  ...,  0.3301, -9.1875,  0.2644]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 08:30:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I occur, he occurs
I improve, he improves
I add, he adds
I seem, he seems
I become, he becomes
I consider, he considers
I require, he requires
I promote, he
2024-07-28 08:30:43 root INFO     [order_1_approx] starting weight calculation for I promote, he promotes
I seem, he seems
I improve, he improves
I become, he becomes
I occur, he occurs
I consider, he considers
I require, he requires
I add, he
2024-07-28 08:30:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 08:33:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1973, -0.3958,  0.0088,  ..., -0.1536, -0.0425, -0.0726],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3311e+00, -2.3574e+00, -1.9473e+00,  ...,  1.6787e+00,
        -9.5938e+00, -7.8125e-03], device='cuda:1', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0442,  0.0066, -0.0164,  ..., -0.0083, -0.0056,  0.0027],
        [-0.0136,  0.0370, -0.0005,  ..., -0.0049,  0.0094, -0.0174],
        [-0.0050,  0.0018,  0.0356,  ...,  0.0036, -0.0106, -0.0004],
        ...,
        [ 0.0220,  0.0026, -0.0060,  ...,  0.0327,  0.0061, -0.0042],
        [ 0.0035, -0.0088,  0.0037,  ..., -0.0086,  0.0203, -0.0185],
        [-0.0043,  0.0050,  0.0162,  ..., -0.0205, -0.0183,  0.0232]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9902, -2.3906, -2.0176,  ...,  2.0215, -8.9531,  0.1298]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 08:33:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I promote, he promotes
I seem, he seems
I improve, he improves
I become, he becomes
I occur, he occurs
I consider, he considers
I require, he requires
I add, he
2024-07-28 08:33:05 root INFO     total operator prediction time: 1132.5097043514252 seconds
2024-07-28 08:33:05 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_inf - Ved
2024-07-28 08:33:05 root INFO     building operator verb_inf - Ved
2024-07-28 08:33:06 root INFO     [order_1_approx] starting weight calculation for If the present form is believe, the past form is believed
If the present form is include, the past form is included
If the present form is become, the past form is became
If the present form is allow, the past form is allowed
If the present form is accept, the past form is accepted
If the present form is lose, the past form is lost
If the present form is develop, the past form is developed
If the present form is locate, the past form is
2024-07-28 08:33:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 08:35:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2391,  0.3533, -0.7217,  ..., -0.1899, -0.2454, -0.0706],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.2529, -1.1865, -1.4219,  ..., -2.1289, -1.7148, -1.8887],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0917, -0.0084, -0.0057,  ..., -0.0062,  0.0048,  0.0210],
        [-0.0059,  0.0818, -0.0071,  ...,  0.0079, -0.0134, -0.0066],
        [ 0.0244,  0.0177,  0.0442,  ..., -0.0114, -0.0117,  0.0054],
        ...,
        [-0.0106,  0.0072, -0.0106,  ...,  0.0764, -0.0077,  0.0058],
        [ 0.0138, -0.0128, -0.0075,  ...,  0.0066,  0.0281, -0.0153],
        [-0.0086, -0.0037, -0.0209,  ..., -0.0196, -0.0220,  0.0608]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.2500, -1.1289, -1.7012,  ..., -1.8008, -1.2383, -1.6475]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 08:35:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is believe, the past form is believed
If the present form is include, the past form is included
If the present form is become, the past form is became
If the present form is allow, the past form is allowed
If the present form is accept, the past form is accepted
If the present form is lose, the past form is lost
If the present form is develop, the past form is developed
If the present form is locate, the past form is
2024-07-28 08:35:27 root INFO     [order_1_approx] starting weight calculation for If the present form is believe, the past form is believed
If the present form is accept, the past form is accepted
If the present form is allow, the past form is allowed
If the present form is develop, the past form is developed
If the present form is lose, the past form is lost
If the present form is locate, the past form is located
If the present form is include, the past form is included
If the present form is become, the past form is
2024-07-28 08:35:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 08:37:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3350,  0.4321,  0.0462,  ..., -0.2122, -0.3750,  0.2446],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1904, -0.1774,  1.2441,  ..., -0.0051,  0.6895, -1.2705],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0684, -0.0271,  0.0222,  ...,  0.0165,  0.0185,  0.0156],
        [-0.0012,  0.0667,  0.0088,  ...,  0.0002, -0.0054, -0.0074],
        [ 0.0010, -0.0053,  0.0499,  ..., -0.0050,  0.0041, -0.0083],
        ...,
        [ 0.0051,  0.0136, -0.0015,  ...,  0.0740,  0.0148,  0.0037],
        [ 0.0062,  0.0184, -0.0104,  ...,  0.0050,  0.0431,  0.0207],
        [-0.0153, -0.0007,  0.0145,  ..., -0.0220, -0.0183,  0.0366]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9902, -0.6226,  0.9814,  ...,  0.3220,  0.3979, -1.0020]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 08:37:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is believe, the past form is believed
If the present form is accept, the past form is accepted
If the present form is allow, the past form is allowed
If the present form is develop, the past form is developed
If the present form is lose, the past form is lost
If the present form is locate, the past form is located
If the present form is include, the past form is included
If the present form is become, the past form is
2024-07-28 08:37:48 root INFO     [order_1_approx] starting weight calculation for If the present form is allow, the past form is allowed
If the present form is include, the past form is included
If the present form is become, the past form is became
If the present form is accept, the past form is accepted
If the present form is lose, the past form is lost
If the present form is locate, the past form is located
If the present form is develop, the past form is developed
If the present form is believe, the past form is
2024-07-28 08:37:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 08:40:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0355,  0.3210,  0.2603,  ..., -0.1772, -0.4241,  0.2117],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6348, -2.5508,  0.7822,  ..., -0.0049, -2.3672, -1.5742],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0415, -0.0159,  0.0239,  ..., -0.0101, -0.0040,  0.0284],
        [-0.0191,  0.0443,  0.0052,  ...,  0.0196, -0.0030, -0.0080],
        [-0.0139,  0.0172,  0.0452,  ..., -0.0024, -0.0164,  0.0218],
        ...,
        [-0.0063,  0.0091, -0.0163,  ...,  0.0501,  0.0017,  0.0115],
        [ 0.0076,  0.0024, -0.0110,  ...,  0.0080,  0.0184, -0.0307],
        [-0.0099,  0.0061, -0.0028,  ..., -0.0032, -0.0177,  0.0161]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3115, -2.6699,  0.5488,  ..., -0.0611, -2.2109, -1.7568]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 08:40:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is allow, the past form is allowed
If the present form is include, the past form is included
If the present form is become, the past form is became
If the present form is accept, the past form is accepted
If the present form is lose, the past form is lost
If the present form is locate, the past form is located
If the present form is develop, the past form is developed
If the present form is believe, the past form is
2024-07-28 08:40:08 root INFO     [order_1_approx] starting weight calculation for If the present form is lose, the past form is lost
If the present form is develop, the past form is developed
If the present form is locate, the past form is located
If the present form is include, the past form is included
If the present form is believe, the past form is believed
If the present form is allow, the past form is allowed
If the present form is become, the past form is became
If the present form is accept, the past form is
2024-07-28 08:40:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 08:42:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2837,  0.3506, -0.2546,  ...,  0.1283, -0.1927, -0.1080],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1436,  0.7173, -1.1963,  ..., -0.5898, -2.8457,  1.1367],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0459, -0.0366,  0.0050,  ..., -0.0197, -0.0037,  0.0186],
        [-0.0065,  0.0688,  0.0083,  ...,  0.0085, -0.0055, -0.0131],
        [ 0.0138,  0.0101,  0.0319,  ...,  0.0035, -0.0332, -0.0005],
        ...,
        [-0.0008, -0.0070, -0.0285,  ...,  0.0502,  0.0220, -0.0180],
        [ 0.0039, -0.0019, -0.0091,  ..., -0.0114,  0.0303, -0.0097],
        [-0.0101, -0.0164,  0.0046,  ..., -0.0193, -0.0169,  0.0218]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2422,  0.4656, -1.2754,  ..., -0.1106, -2.7031,  1.4541]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 08:42:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is lose, the past form is lost
If the present form is develop, the past form is developed
If the present form is locate, the past form is located
If the present form is include, the past form is included
If the present form is believe, the past form is believed
If the present form is allow, the past form is allowed
If the present form is become, the past form is became
If the present form is accept, the past form is
2024-07-28 08:42:27 root INFO     [order_1_approx] starting weight calculation for If the present form is locate, the past form is located
If the present form is believe, the past form is believed
If the present form is lose, the past form is lost
If the present form is develop, the past form is developed
If the present form is become, the past form is became
If the present form is include, the past form is included
If the present form is accept, the past form is accepted
If the present form is allow, the past form is
2024-07-28 08:42:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 08:44:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1807,  0.2356,  0.0894,  ..., -0.2583,  0.0888, -0.0948],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0195, -3.1211, -1.1504,  ..., -0.3521, -2.5781,  0.7227],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0382, -0.0122, -0.0085,  ..., -0.0204,  0.0200,  0.0015],
        [-0.0138,  0.0396, -0.0266,  ...,  0.0126,  0.0191, -0.0207],
        [ 0.0043,  0.0105,  0.0300,  ..., -0.0149, -0.0153, -0.0052],
        ...,
        [ 0.0144,  0.0176,  0.0004,  ...,  0.0585,  0.0055,  0.0169],
        [-0.0015,  0.0024, -0.0145,  ..., -0.0009,  0.0058, -0.0317],
        [-0.0052, -0.0009, -0.0018,  ..., -0.0110, -0.0115,  0.0231]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0996, -2.9551, -1.1328,  ..., -0.0278, -2.3066,  1.3818]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 08:44:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is locate, the past form is located
If the present form is believe, the past form is believed
If the present form is lose, the past form is lost
If the present form is develop, the past form is developed
If the present form is become, the past form is became
If the present form is include, the past form is included
If the present form is accept, the past form is accepted
If the present form is allow, the past form is
2024-07-28 08:44:44 root INFO     [order_1_approx] starting weight calculation for If the present form is accept, the past form is accepted
If the present form is become, the past form is became
If the present form is believe, the past form is believed
If the present form is develop, the past form is developed
If the present form is allow, the past form is allowed
If the present form is lose, the past form is lost
If the present form is locate, the past form is located
If the present form is include, the past form is
2024-07-28 08:44:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 08:47:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0384,  0.1350,  0.1069,  ..., -0.0166,  0.2047,  0.0712],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6807,  0.7822,  0.1646,  ..., -1.2988, -1.0020, -1.5342],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.3608e-02, -2.2690e-02,  2.8763e-02,  ..., -6.1035e-05,
          1.2543e-02,  6.7673e-03],
        [-1.2222e-02,  7.2021e-02,  1.3123e-02,  ...,  3.0823e-02,
          1.1587e-03, -2.0569e-02],
        [ 3.9864e-03,  1.4343e-02,  2.3651e-02,  ..., -1.2802e-02,
         -3.2257e-02,  3.1395e-03],
        ...,
        [-2.1042e-02,  8.5526e-03, -2.1362e-03,  ...,  8.3130e-02,
         -1.2760e-03,  2.2720e-02],
        [-1.6136e-03,  2.0416e-02, -5.4855e-03,  ..., -2.6588e-03,
          1.2291e-02,  2.2812e-03],
        [-2.2980e-02, -9.7275e-03, -7.7438e-03,  ..., -2.6825e-02,
         -3.6133e-02,  3.2684e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.9614,  0.9604, -0.0293,  ..., -1.3711, -0.4707, -0.5039]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 08:47:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is accept, the past form is accepted
If the present form is become, the past form is became
If the present form is believe, the past form is believed
If the present form is develop, the past form is developed
If the present form is allow, the past form is allowed
If the present form is lose, the past form is lost
If the present form is locate, the past form is located
If the present form is include, the past form is
2024-07-28 08:47:03 root INFO     [order_1_approx] starting weight calculation for If the present form is allow, the past form is allowed
If the present form is accept, the past form is accepted
If the present form is become, the past form is became
If the present form is locate, the past form is located
If the present form is lose, the past form is lost
If the present form is believe, the past form is believed
If the present form is include, the past form is included
If the present form is develop, the past form is
2024-07-28 08:47:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 08:49:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2590,  0.0345, -0.0449,  ..., -0.5493, -0.0093, -0.1095],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5635, -1.3047,  3.2793,  ..., -1.6846, -1.7666, -2.0781],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0412, -0.0034, -0.0054,  ..., -0.0076, -0.0144,  0.0275],
        [-0.0137,  0.0679,  0.0131,  ...,  0.0125,  0.0082,  0.0020],
        [ 0.0117, -0.0062,  0.0108,  ..., -0.0079, -0.0107,  0.0130],
        ...,
        [ 0.0208, -0.0072, -0.0091,  ...,  0.0620, -0.0080,  0.0142],
        [ 0.0184,  0.0012,  0.0075,  ...,  0.0125,  0.0235, -0.0027],
        [-0.0099, -0.0182,  0.0004,  ..., -0.0158, -0.0198,  0.0137]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3066, -1.4102,  2.7695,  ..., -1.7002, -1.3057, -1.8242]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 08:49:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is allow, the past form is allowed
If the present form is accept, the past form is accepted
If the present form is become, the past form is became
If the present form is locate, the past form is located
If the present form is lose, the past form is lost
If the present form is believe, the past form is believed
If the present form is include, the past form is included
If the present form is develop, the past form is
2024-07-28 08:49:23 root INFO     [order_1_approx] starting weight calculation for If the present form is include, the past form is included
If the present form is develop, the past form is developed
If the present form is allow, the past form is allowed
If the present form is locate, the past form is located
If the present form is believe, the past form is believed
If the present form is become, the past form is became
If the present form is accept, the past form is accepted
If the present form is lose, the past form is
2024-07-28 08:49:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 08:51:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1078,  0.1743,  0.0925,  ..., -0.5405,  0.2988, -0.1755],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8018, -1.2666, -0.2773,  ..., -0.9653, -0.3125, -1.0000],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0696, -0.0104,  0.0333,  ..., -0.0070,  0.0027,  0.0063],
        [-0.0065,  0.0610,  0.0236,  ...,  0.0103, -0.0154, -0.0056],
        [-0.0164,  0.0033,  0.0473,  ...,  0.0012, -0.0352, -0.0040],
        ...,
        [ 0.0063,  0.0124, -0.0362,  ...,  0.0505,  0.0222,  0.0028],
        [-0.0013, -0.0045,  0.0158,  ..., -0.0038,  0.0302, -0.0195],
        [-0.0096,  0.0068, -0.0005,  ..., -0.0313, -0.0079,  0.0319]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8999, -1.2568, -0.1266,  ..., -0.4478, -0.1610, -0.8218]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 08:51:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is include, the past form is included
If the present form is develop, the past form is developed
If the present form is allow, the past form is allowed
If the present form is locate, the past form is located
If the present form is believe, the past form is believed
If the present form is become, the past form is became
If the present form is accept, the past form is accepted
If the present form is lose, the past form is
2024-07-28 08:51:43 root INFO     total operator prediction time: 1117.7523612976074 seconds
2024-07-28 08:51:43 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_Ving - Ved
2024-07-28 08:51:43 root INFO     building operator verb_Ving - Ved
2024-07-28 08:51:43 root INFO     [order_1_approx] starting weight calculation for After something is announcing, it has announced
After something is representing, it has represented
After something is attending, it has attended
After something is following, it has followed
After something is allowing, it has allowed
After something is establishing, it has established
After something is developing, it has developed
After something is providing, it has
2024-07-28 08:51:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 08:54:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3552, -0.4453, -0.0302,  ..., -0.0395,  0.0618, -0.4243],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7188, -3.1133,  2.5684,  ..., -1.1299, -1.4844,  0.3672],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0690, -0.0023,  0.0245,  ...,  0.0121, -0.0053,  0.0249],
        [-0.0305,  0.0451,  0.0170,  ...,  0.0222,  0.0106,  0.0186],
        [-0.0115, -0.0130,  0.0378,  ..., -0.0107,  0.0058, -0.0005],
        ...,
        [ 0.0078,  0.0090, -0.0064,  ...,  0.0622,  0.0171,  0.0143],
        [ 0.0182, -0.0039, -0.0192,  ..., -0.0058,  0.0456, -0.0351],
        [-0.0151,  0.0097, -0.0022,  ..., -0.0219, -0.0048,  0.0379]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5928, -3.2109,  2.4941,  ..., -0.9883, -0.7812,  0.7983]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 08:54:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is announcing, it has announced
After something is representing, it has represented
After something is attending, it has attended
After something is following, it has followed
After something is allowing, it has allowed
After something is establishing, it has established
After something is developing, it has developed
After something is providing, it has
2024-07-28 08:54:06 root INFO     [order_1_approx] starting weight calculation for After something is providing, it has provided
After something is establishing, it has established
After something is announcing, it has announced
After something is developing, it has developed
After something is attending, it has attended
After something is representing, it has represented
After something is following, it has followed
After something is allowing, it has
2024-07-28 08:54:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 08:56:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2391, -0.0245, -0.1682,  ..., -0.2944, -0.0653, -0.3037],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1523, -1.8389,  0.6841,  ..., -1.6660, -1.2891,  1.4473],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0499, -0.0049, -0.0109,  ..., -0.0009,  0.0140,  0.0131],
        [-0.0148,  0.0576, -0.0172,  ...,  0.0318,  0.0090, -0.0169],
        [-0.0120, -0.0214,  0.0444,  ..., -0.0153, -0.0182, -0.0049],
        ...,
        [-0.0047,  0.0142, -0.0073,  ...,  0.0452,  0.0078,  0.0222],
        [ 0.0109,  0.0178, -0.0070,  ...,  0.0058,  0.0334, -0.0396],
        [-0.0126, -0.0007,  0.0045,  ...,  0.0109, -0.0048,  0.0202]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8291, -1.8389,  0.5972,  ..., -1.1406, -1.0596,  1.5283]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 08:56:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is providing, it has provided
After something is establishing, it has established
After something is announcing, it has announced
After something is developing, it has developed
After something is attending, it has attended
After something is representing, it has represented
After something is following, it has followed
After something is allowing, it has
2024-07-28 08:56:29 root INFO     [order_1_approx] starting weight calculation for After something is attending, it has attended
After something is representing, it has represented
After something is following, it has followed
After something is providing, it has provided
After something is allowing, it has allowed
After something is establishing, it has established
After something is announcing, it has announced
After something is developing, it has
2024-07-28 08:56:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 08:58:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2900, -0.3103, -0.4893,  ..., -0.1138,  0.2261, -0.3750],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4766, -0.7158,  3.0039,  ..., -2.5625, -0.7969, -1.9258],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0361,  0.0142, -0.0135,  ..., -0.0006, -0.0080,  0.0164],
        [-0.0192,  0.0586,  0.0047,  ...,  0.0258,  0.0126,  0.0104],
        [-0.0015, -0.0099,  0.0188,  ..., -0.0080,  0.0198, -0.0107],
        ...,
        [ 0.0264,  0.0051, -0.0007,  ...,  0.0492, -0.0167,  0.0225],
        [ 0.0032,  0.0048, -0.0157,  ..., -0.0050,  0.0391, -0.0110],
        [-0.0087, -0.0083,  0.0069,  ..., -0.0187, -0.0159,  0.0165]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1875, -0.9023,  3.0879,  ..., -2.4141, -0.7773, -1.7920]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 08:58:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is attending, it has attended
After something is representing, it has represented
After something is following, it has followed
After something is providing, it has provided
After something is allowing, it has allowed
After something is establishing, it has established
After something is announcing, it has announced
After something is developing, it has
2024-07-28 08:58:52 root INFO     [order_1_approx] starting weight calculation for After something is following, it has followed
After something is attending, it has attended
After something is establishing, it has established
After something is announcing, it has announced
After something is developing, it has developed
After something is providing, it has provided
After something is allowing, it has allowed
After something is representing, it has
2024-07-28 08:58:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 09:01:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0110,  0.1066, -0.5000,  ..., -0.1708, -0.1008, -0.2180],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6572,  0.7373,  2.8105,  ..., -1.6133, -0.9761, -0.2676],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.8533e-02, -2.2087e-03,  7.6294e-05,  ...,  1.8799e-02,
          7.3814e-04,  1.7258e-02],
        [-4.8492e-02,  5.4962e-02, -3.1223e-03,  ...,  1.4130e-02,
          1.4305e-02, -3.0624e-02],
        [ 1.3611e-02,  9.4604e-04,  4.4556e-02,  ...,  2.6569e-03,
         -8.4686e-03, -1.1078e-02],
        ...,
        [ 1.2405e-02,  1.7563e-02, -2.2827e-02,  ...,  7.2388e-02,
         -1.8356e-02,  2.1057e-02],
        [ 1.2779e-02,  3.9902e-03, -4.8294e-03,  ..., -7.3090e-03,
          4.1260e-02, -2.7191e-02],
        [-2.6245e-03, -6.2027e-03,  3.8414e-03,  ...,  6.2180e-04,
         -1.3451e-02,  2.7054e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3806,  0.3650,  2.7910,  ..., -1.5596, -0.7114, -0.0970]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 09:01:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is following, it has followed
After something is attending, it has attended
After something is establishing, it has established
After something is announcing, it has announced
After something is developing, it has developed
After something is providing, it has provided
After something is allowing, it has allowed
After something is representing, it has
2024-07-28 09:01:14 root INFO     [order_1_approx] starting weight calculation for After something is allowing, it has allowed
After something is attending, it has attended
After something is following, it has followed
After something is representing, it has represented
After something is developing, it has developed
After something is providing, it has provided
After something is announcing, it has announced
After something is establishing, it has
2024-07-28 09:01:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 09:03:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2404, -0.2394, -0.2434,  ...,  0.0192, -0.1880, -0.1006],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0898, -0.1006,  1.5430,  ..., -1.7168,  0.0303, -0.9570],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.9531e-02, -5.3501e-04, -8.1406e-03,  ..., -1.6918e-03,
         -9.2926e-03,  1.6403e-02],
        [-1.8692e-02,  2.1820e-02,  2.3003e-03,  ...,  9.1629e-03,
          8.6746e-03,  6.6833e-03],
        [ 2.8214e-02, -5.7487e-03,  1.3542e-02,  ...,  4.1580e-04,
          6.3248e-03,  4.9877e-04],
        ...,
        [ 9.0561e-03, -6.8665e-05,  3.9024e-03,  ...,  2.8000e-02,
         -1.1787e-02,  1.1566e-02],
        [-2.5673e-03,  1.4206e-02,  3.9577e-04,  ...,  5.4588e-03,
          2.6199e-02, -1.2856e-02],
        [-1.5297e-02,  1.0460e-02,  9.1095e-03,  ...,  4.0398e-03,
          1.5182e-03, -7.6675e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3545, -0.2302,  1.8545,  ..., -1.4463, -0.1221, -0.8975]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 09:03:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is allowing, it has allowed
After something is attending, it has attended
After something is following, it has followed
After something is representing, it has represented
After something is developing, it has developed
After something is providing, it has provided
After something is announcing, it has announced
After something is establishing, it has
2024-07-28 09:03:37 root INFO     [order_1_approx] starting weight calculation for After something is developing, it has developed
After something is providing, it has provided
After something is allowing, it has allowed
After something is announcing, it has announced
After something is attending, it has attended
After something is establishing, it has established
After something is representing, it has represented
After something is following, it has
2024-07-28 09:03:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 09:05:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0063, -0.2883, -0.2200,  ..., -0.1418,  0.1758,  0.0089],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3438, -0.6597,  3.6523,  ..., -0.5845, -3.0000,  0.0586],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0757,  0.0100,  0.0007,  ...,  0.0073,  0.0104,  0.0159],
        [-0.0262,  0.0745,  0.0105,  ...,  0.0105,  0.0049, -0.0266],
        [-0.0012,  0.0023,  0.0408,  ...,  0.0105,  0.0055, -0.0021],
        ...,
        [-0.0064,  0.0400, -0.0204,  ...,  0.0615,  0.0021, -0.0062],
        [ 0.0056,  0.0068, -0.0066,  ...,  0.0136,  0.0244,  0.0005],
        [-0.0214,  0.0123,  0.0132,  ..., -0.0164,  0.0010,  0.0309]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7344, -1.2148,  3.7188,  ..., -0.1040, -2.4648, -0.0140]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 09:05:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is developing, it has developed
After something is providing, it has provided
After something is allowing, it has allowed
After something is announcing, it has announced
After something is attending, it has attended
After something is establishing, it has established
After something is representing, it has represented
After something is following, it has
2024-07-28 09:05:59 root INFO     [order_1_approx] starting weight calculation for After something is representing, it has represented
After something is announcing, it has announced
After something is allowing, it has allowed
After something is establishing, it has established
After something is providing, it has provided
After something is developing, it has developed
After something is following, it has followed
After something is attending, it has
2024-07-28 09:06:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 09:08:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1118,  0.0896, -0.4006,  ..., -0.4275, -0.1493, -0.1964],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9414,  1.6641,  1.2109,  ..., -1.3418, -4.0312, -0.7148],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0482, -0.0120, -0.0124,  ...,  0.0091,  0.0098,  0.0066],
        [-0.0177,  0.0620,  0.0230,  ..., -0.0048,  0.0098, -0.0161],
        [-0.0059, -0.0014,  0.0246,  ...,  0.0016,  0.0114,  0.0048],
        ...,
        [ 0.0115,  0.0123,  0.0017,  ...,  0.0280,  0.0063,  0.0083],
        [ 0.0071,  0.0004, -0.0130,  ..., -0.0017,  0.0265,  0.0006],
        [ 0.0076,  0.0063, -0.0002,  ..., -0.0051,  0.0020,  0.0205]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7383,  1.6162,  1.2666,  ..., -0.7168, -3.9258, -0.6011]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 09:08:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is representing, it has represented
After something is announcing, it has announced
After something is allowing, it has allowed
After something is establishing, it has established
After something is providing, it has provided
After something is developing, it has developed
After something is following, it has followed
After something is attending, it has
2024-07-28 09:08:22 root INFO     [order_1_approx] starting weight calculation for After something is following, it has followed
After something is developing, it has developed
After something is providing, it has provided
After something is establishing, it has established
After something is attending, it has attended
After something is representing, it has represented
After something is allowing, it has allowed
After something is announcing, it has
2024-07-28 09:08:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 09:10:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1312,  0.3872, -0.4146,  ...,  0.0330, -0.1488, -0.4314],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1924, -0.7422,  2.9844,  ..., -0.6826, -0.9370,  1.4023],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.1931e-02, -9.2468e-03,  2.2736e-03,  ...,  5.1498e-05,
         -1.5686e-02,  2.0386e-02],
        [-2.0508e-02,  2.8381e-02,  2.9678e-03,  ...,  1.6678e-02,
          1.5961e-02, -8.6136e-03],
        [ 1.9363e-02, -2.9419e-02,  4.7207e-04,  ..., -1.1208e-02,
         -6.6719e-03, -5.6190e-03],
        ...,
        [ 7.1411e-03,  4.6387e-03, -2.1530e-02,  ...,  1.9501e-02,
         -6.9427e-03,  1.1635e-02],
        [ 1.8433e-02,  4.5128e-03, -8.7357e-03,  ..., -2.7161e-03,
          1.9852e-02, -7.5302e-03],
        [-6.4850e-03,  2.0996e-02,  1.5549e-02,  ...,  1.6985e-03,
          5.8365e-03,  3.1090e-04]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0752, -0.8179,  3.3789,  ..., -0.4365, -0.7622,  1.0684]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 09:10:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is following, it has followed
After something is developing, it has developed
After something is providing, it has provided
After something is establishing, it has established
After something is attending, it has attended
After something is representing, it has represented
After something is allowing, it has allowed
After something is announcing, it has
2024-07-28 09:10:44 root INFO     total operator prediction time: 1141.0851519107819 seconds
2024-07-28 09:10:44 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on Ving - verb_inf
2024-07-28 09:10:44 root INFO     building operator Ving - verb_inf
2024-07-28 09:10:44 root INFO     [order_1_approx] starting weight calculation for ensuring is the active form of ensure
attending is the active form of attend
maintaining is the active form of maintain
operating is the active form of operate
seeming is the active form of seem
enjoying is the active form of enjoy
creating is the active form of create
providing is the active form of
2024-07-28 09:10:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 09:13:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6025, -0.5679, -0.2112,  ..., -0.0196,  0.0708, -0.1648],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9385, -6.0781,  0.7080,  ...,  1.8906, -2.0938, -1.0107],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.2327e-02, -6.7711e-03,  3.1929e-03,  ..., -8.7643e-04,
         -1.4992e-02,  1.8433e-02],
        [-3.1490e-03,  3.8696e-02, -6.6090e-04,  ...,  1.8692e-04,
         -4.4250e-04,  1.6460e-03],
        [ 1.6336e-03,  4.8399e-05,  4.0039e-02,  ..., -1.1642e-02,
         -5.8060e-03,  1.0498e-02],
        ...,
        [ 3.5362e-03,  6.1378e-03,  3.5954e-04,  ...,  6.3660e-02,
          5.2261e-03,  1.7242e-03],
        [ 1.0262e-02,  1.0994e-02,  2.0691e-02,  ...,  1.4519e-02,
          4.5197e-02, -1.7822e-02],
        [-1.8187e-03,  1.1101e-02, -7.7667e-03,  ..., -1.9882e-02,
         -1.4290e-02,  4.6204e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5645, -6.2773,  0.6143,  ...,  1.9033, -1.8184, -0.8813]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 09:13:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for ensuring is the active form of ensure
attending is the active form of attend
maintaining is the active form of maintain
operating is the active form of operate
seeming is the active form of seem
enjoying is the active form of enjoy
creating is the active form of create
providing is the active form of
2024-07-28 09:13:07 root INFO     [order_1_approx] starting weight calculation for providing is the active form of provide
creating is the active form of create
seeming is the active form of seem
maintaining is the active form of maintain
attending is the active form of attend
enjoying is the active form of enjoy
ensuring is the active form of ensure
operating is the active form of
2024-07-28 09:13:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 09:15:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3040, -0.4094, -0.5483,  ..., -0.1398, -0.2358, -0.3076],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7090, -4.4727,  1.2891,  ...,  1.8350,  0.0520, -1.1641],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0586,  0.0042,  0.0046,  ...,  0.0003,  0.0051,  0.0107],
        [ 0.0042,  0.0440,  0.0058,  ...,  0.0103, -0.0007, -0.0063],
        [ 0.0131,  0.0077,  0.0358,  ..., -0.0087, -0.0006,  0.0079],
        ...,
        [ 0.0042,  0.0048, -0.0076,  ...,  0.0478,  0.0005,  0.0027],
        [ 0.0026,  0.0054, -0.0032,  ...,  0.0010,  0.0145, -0.0072],
        [-0.0044, -0.0051, -0.0060,  ...,  0.0015, -0.0106,  0.0365]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5806, -4.3906,  1.2646,  ...,  1.8320, -0.1659, -1.0977]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 09:15:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for providing is the active form of provide
creating is the active form of create
seeming is the active form of seem
maintaining is the active form of maintain
attending is the active form of attend
enjoying is the active form of enjoy
ensuring is the active form of ensure
operating is the active form of
2024-07-28 09:15:29 root INFO     [order_1_approx] starting weight calculation for maintaining is the active form of maintain
seeming is the active form of seem
creating is the active form of create
providing is the active form of provide
operating is the active form of operate
enjoying is the active form of enjoy
ensuring is the active form of ensure
attending is the active form of
2024-07-28 09:15:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 09:17:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0970, -0.2400, -0.6357,  ..., -0.1160, -0.1091, -0.1262],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1328, -2.7207, -1.8203,  ...,  2.2676, -2.8887, -3.0508],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0866, -0.0004, -0.0011,  ...,  0.0006, -0.0046,  0.0176],
        [ 0.0107,  0.0771,  0.0005,  ...,  0.0092, -0.0097, -0.0112],
        [ 0.0080,  0.0103,  0.0635,  ..., -0.0053,  0.0028,  0.0029],
        ...,
        [-0.0003, -0.0082,  0.0096,  ...,  0.0538, -0.0008, -0.0090],
        [-0.0232, -0.0136,  0.0123,  ...,  0.0073,  0.0446, -0.0072],
        [ 0.0089, -0.0023, -0.0164,  ...,  0.0047, -0.0057,  0.0567]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0410, -2.9121, -2.1348,  ...,  2.5332, -2.7812, -3.0195]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 09:17:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for maintaining is the active form of maintain
seeming is the active form of seem
creating is the active form of create
providing is the active form of provide
operating is the active form of operate
enjoying is the active form of enjoy
ensuring is the active form of ensure
attending is the active form of
2024-07-28 09:17:51 root INFO     [order_1_approx] starting weight calculation for enjoying is the active form of enjoy
operating is the active form of operate
attending is the active form of attend
seeming is the active form of seem
providing is the active form of provide
creating is the active form of create
ensuring is the active form of ensure
maintaining is the active form of
2024-07-28 09:17:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 09:20:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7012, -0.4312, -0.0676,  ..., -0.1162, -0.2512,  0.2338],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2246, -4.2344, -0.8232,  ...,  0.1270, -0.9854, -2.1602],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0544, -0.0054,  0.0032,  ...,  0.0045,  0.0005,  0.0089],
        [ 0.0095,  0.0466, -0.0028,  ...,  0.0196,  0.0135, -0.0050],
        [ 0.0164,  0.0006,  0.0483,  ..., -0.0154, -0.0062,  0.0020],
        ...,
        [ 0.0098,  0.0069,  0.0041,  ...,  0.0355, -0.0088,  0.0100],
        [-0.0103,  0.0170,  0.0082,  ..., -0.0074,  0.0267,  0.0009],
        [-0.0014,  0.0079, -0.0089,  ..., -0.0105, -0.0059,  0.0326]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0742, -4.3945, -0.8540,  ...,  0.1855, -0.9824, -2.0352]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 09:20:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for enjoying is the active form of enjoy
operating is the active form of operate
attending is the active form of attend
seeming is the active form of seem
providing is the active form of provide
creating is the active form of create
ensuring is the active form of ensure
maintaining is the active form of
2024-07-28 09:20:15 root INFO     [order_1_approx] starting weight calculation for operating is the active form of operate
creating is the active form of create
providing is the active form of provide
enjoying is the active form of enjoy
seeming is the active form of seem
attending is the active form of attend
maintaining is the active form of maintain
ensuring is the active form of
2024-07-28 09:20:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 09:22:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0552, -0.1544, -0.3115,  ...,  0.1948,  0.2771, -0.2465],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4883, -4.1484, -0.3457,  ...,  1.4600, -1.4678, -2.4609],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.6580e-02, -3.4332e-05,  2.7122e-03,  ..., -6.1607e-04,
         -2.7943e-03,  1.0963e-02],
        [-2.4128e-04,  4.6967e-02, -3.8147e-06,  ...,  6.3362e-03,
         -2.9240e-03, -3.5744e-03],
        [ 5.7297e-03,  4.5471e-03,  3.0853e-02,  ...,  4.5204e-04,
          2.2163e-03,  2.4414e-03],
        ...,
        [ 5.1193e-03, -5.0049e-03,  9.2411e-04,  ...,  4.8492e-02,
         -1.4076e-03,  3.0117e-03],
        [-1.9150e-03,  8.8577e-03, -2.1477e-03,  ...,  3.9139e-03,
          3.2593e-02,  3.4370e-03],
        [-2.3651e-03, -1.5202e-03, -7.2746e-03,  ..., -2.7466e-04,
         -5.4512e-03,  2.7222e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5605, -4.2969, -0.4080,  ...,  1.5547, -1.4619, -2.4336]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 09:22:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for operating is the active form of operate
creating is the active form of create
providing is the active form of provide
enjoying is the active form of enjoy
seeming is the active form of seem
attending is the active form of attend
maintaining is the active form of maintain
ensuring is the active form of
2024-07-28 09:22:37 root INFO     [order_1_approx] starting weight calculation for maintaining is the active form of maintain
creating is the active form of create
providing is the active form of provide
ensuring is the active form of ensure
seeming is the active form of seem
attending is the active form of attend
operating is the active form of operate
enjoying is the active form of
2024-07-28 09:22:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 09:24:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0260, -0.3818, -0.0900,  ..., -0.2666, -0.1108,  0.2666],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0547, -3.2695, -0.6245,  ...,  1.3340, -2.0508, -2.4219],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0640, -0.0031, -0.0048,  ...,  0.0014,  0.0078,  0.0152],
        [ 0.0046,  0.0492, -0.0097,  ...,  0.0059, -0.0021,  0.0009],
        [ 0.0155, -0.0048,  0.0363,  ...,  0.0026, -0.0056, -0.0046],
        ...,
        [-0.0120,  0.0004,  0.0026,  ...,  0.0398,  0.0014, -0.0040],
        [-0.0039,  0.0093,  0.0197,  ...,  0.0086,  0.0325, -0.0063],
        [-0.0013, -0.0024, -0.0020,  ...,  0.0031, -0.0059,  0.0396]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1084, -3.5508, -0.7285,  ...,  1.6221, -1.9102, -2.4336]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 09:25:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for maintaining is the active form of maintain
creating is the active form of create
providing is the active form of provide
ensuring is the active form of ensure
seeming is the active form of seem
attending is the active form of attend
operating is the active form of operate
enjoying is the active form of
2024-07-28 09:25:00 root INFO     [order_1_approx] starting weight calculation for attending is the active form of attend
ensuring is the active form of ensure
seeming is the active form of seem
operating is the active form of operate
enjoying is the active form of enjoy
maintaining is the active form of maintain
providing is the active form of provide
creating is the active form of
2024-07-28 09:25:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 09:27:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2087, -0.2097,  0.0133,  ..., -0.1505, -0.0291,  0.1178],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0000, -4.0039,  1.5703,  ...,  2.6797, -2.6270, -0.6338],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0551, -0.0023,  0.0107,  ...,  0.0130, -0.0058,  0.0073],
        [ 0.0104,  0.0461,  0.0033,  ...,  0.0233, -0.0074, -0.0097],
        [ 0.0136, -0.0073,  0.0338,  ..., -0.0018,  0.0156, -0.0027],
        ...,
        [ 0.0091,  0.0040, -0.0002,  ...,  0.0326, -0.0047,  0.0006],
        [-0.0176,  0.0126, -0.0108,  ..., -0.0022,  0.0371, -0.0043],
        [-0.0085,  0.0025, -0.0046,  ..., -0.0037, -0.0122,  0.0297]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0160, -4.0625,  1.3789,  ...,  2.5664, -2.5781, -0.6025]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 09:27:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for attending is the active form of attend
ensuring is the active form of ensure
seeming is the active form of seem
operating is the active form of operate
enjoying is the active form of enjoy
maintaining is the active form of maintain
providing is the active form of provide
creating is the active form of
2024-07-28 09:27:22 root INFO     [order_1_approx] starting weight calculation for providing is the active form of provide
creating is the active form of create
operating is the active form of operate
attending is the active form of attend
maintaining is the active form of maintain
ensuring is the active form of ensure
enjoying is the active form of enjoy
seeming is the active form of
2024-07-28 09:27:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 09:29:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3125, -0.3625,  0.0835,  ..., -0.0566, -0.2505, -0.0773],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2178, -3.8242, -0.6074,  ...,  2.3711, -0.5630, -3.6758],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0591, -0.0164,  0.0108,  ..., -0.0029, -0.0018,  0.0147],
        [-0.0068,  0.0533,  0.0069,  ...,  0.0164,  0.0101, -0.0113],
        [ 0.0288, -0.0063,  0.0493,  ...,  0.0052,  0.0031, -0.0090],
        ...,
        [ 0.0155, -0.0019, -0.0197,  ...,  0.0524, -0.0186,  0.0019],
        [ 0.0031, -0.0036,  0.0015,  ..., -0.0108,  0.0315,  0.0137],
        [ 0.0031, -0.0104,  0.0034,  ..., -0.0045, -0.0084,  0.0395]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8657, -3.9512, -0.7896,  ...,  2.5371, -0.4446, -3.3359]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 09:29:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for providing is the active form of provide
creating is the active form of create
operating is the active form of operate
attending is the active form of attend
maintaining is the active form of maintain
ensuring is the active form of ensure
enjoying is the active form of enjoy
seeming is the active form of
2024-07-28 09:29:45 root INFO     total operator prediction time: 1140.702968120575 seconds
2024-07-28 09:29:45 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun - plural_irreg
2024-07-28 09:29:45 root INFO     building operator noun - plural_irreg
2024-07-28 09:29:45 root INFO     [order_1_approx] starting weight calculation for The plural form of authority is authorities
The plural form of formula is formulae
The plural form of story is stories
The plural form of secretary is secretaries
The plural form of city is cities
The plural form of ability is abilities
The plural form of academy is academies
The plural form of strategy is
2024-07-28 09:29:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 09:32:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2057, -0.1014,  0.0404,  ..., -0.0083,  0.0710, -0.2854],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5625, -2.1328,  1.0771,  ...,  0.8599, -2.2031, -3.2617],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0274, -0.0032, -0.0162,  ..., -0.0073,  0.0197,  0.0047],
        [ 0.0139,  0.0643,  0.0144,  ...,  0.0034, -0.0088,  0.0163],
        [-0.0014,  0.0141,  0.0354,  ..., -0.0032, -0.0022,  0.0156],
        ...,
        [-0.0132,  0.0067,  0.0140,  ...,  0.0491, -0.0019,  0.0199],
        [-0.0561,  0.0192,  0.0168,  ...,  0.0103,  0.0823, -0.0160],
        [ 0.0444, -0.0013,  0.0100,  ..., -0.0177, -0.0214,  0.0419]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3027, -2.0273,  1.1445,  ...,  0.9883, -1.4707, -2.7051]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 09:32:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of authority is authorities
The plural form of formula is formulae
The plural form of story is stories
The plural form of secretary is secretaries
The plural form of city is cities
The plural form of ability is abilities
The plural form of academy is academies
The plural form of strategy is
2024-07-28 09:32:08 root INFO     [order_1_approx] starting weight calculation for The plural form of story is stories
The plural form of ability is abilities
The plural form of city is cities
The plural form of strategy is strategies
The plural form of authority is authorities
The plural form of formula is formulae
The plural form of secretary is secretaries
The plural form of academy is
2024-07-28 09:32:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 09:34:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2408,  0.3433, -0.7715,  ...,  0.0257, -0.3403,  0.0205],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6323, -1.2207,  2.1992,  ...,  1.5088, -2.1172, -1.5010],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0833, -0.0076,  0.0072,  ...,  0.0006, -0.0132,  0.0109],
        [-0.0098,  0.0916, -0.0043,  ...,  0.0016, -0.0220,  0.0088],
        [ 0.0044,  0.0053,  0.0933,  ...,  0.0050, -0.0165, -0.0049],
        ...,
        [-0.0255,  0.0217,  0.0164,  ...,  0.0699, -0.0291, -0.0034],
        [-0.0266,  0.0451,  0.0369,  ...,  0.0005,  0.0511, -0.0182],
        [ 0.0320, -0.0107, -0.0313,  ..., -0.0086, -0.0228,  0.0690]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0405, -1.1279,  1.7588,  ...,  1.6162, -2.0527, -0.9873]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 09:34:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of story is stories
The plural form of ability is abilities
The plural form of city is cities
The plural form of strategy is strategies
The plural form of authority is authorities
The plural form of formula is formulae
The plural form of secretary is secretaries
The plural form of academy is
2024-07-28 09:34:30 root INFO     [order_1_approx] starting weight calculation for The plural form of city is cities
The plural form of strategy is strategies
The plural form of authority is authorities
The plural form of story is stories
The plural form of secretary is secretaries
The plural form of academy is academies
The plural form of ability is abilities
The plural form of formula is
2024-07-28 09:34:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 09:36:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4890,  0.0204, -0.2502,  ..., -0.0692, -0.3621,  0.0736],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0596, -1.0820,  4.2266,  ..., -0.4248, -2.4277, -0.2441],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0775, -0.0060, -0.0161,  ..., -0.0119, -0.0226,  0.0040],
        [-0.0044,  0.1002,  0.0151,  ...,  0.0231, -0.0165,  0.0366],
        [ 0.0036, -0.0271,  0.0481,  ..., -0.0050,  0.0076,  0.0259],
        ...,
        [ 0.0173,  0.0052, -0.0003,  ...,  0.0791,  0.0023,  0.0080],
        [-0.0217, -0.0125, -0.0036,  ..., -0.0061,  0.0638,  0.0014],
        [ 0.0163,  0.0170,  0.0034,  ...,  0.0192, -0.0233,  0.0670]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3259, -1.6758,  4.8516,  ..., -0.2438, -2.0449, -0.5391]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 09:36:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of city is cities
The plural form of strategy is strategies
The plural form of authority is authorities
The plural form of story is stories
The plural form of secretary is secretaries
The plural form of academy is academies
The plural form of ability is abilities
The plural form of formula is
2024-07-28 09:36:52 root INFO     [order_1_approx] starting weight calculation for The plural form of academy is academies
The plural form of city is cities
The plural form of story is stories
The plural form of authority is authorities
The plural form of formula is formulae
The plural form of strategy is strategies
The plural form of ability is abilities
The plural form of secretary is
2024-07-28 09:36:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 09:39:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6411,  0.0691, -0.4619,  ..., -0.3083, -0.2456,  0.2068],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2549, -1.8242,  3.0391,  ..., -0.9609, -0.9673, -3.6582],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0676,  0.0074,  0.0054,  ...,  0.0117, -0.0020,  0.0120],
        [ 0.0296,  0.0676,  0.0058,  ...,  0.0101,  0.0148,  0.0114],
        [-0.0014,  0.0086,  0.0842,  ..., -0.0068, -0.0255, -0.0058],
        ...,
        [ 0.0242,  0.0049,  0.0300,  ...,  0.0937, -0.0067,  0.0137],
        [-0.0357,  0.0330,  0.0076,  ...,  0.0209,  0.0358, -0.0061],
        [ 0.0315, -0.0023, -0.0245,  ...,  0.0006, -0.0110,  0.0655]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3984, -2.2207,  3.2148,  ..., -1.6465, -0.3013, -3.3027]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 09:39:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of academy is academies
The plural form of city is cities
The plural form of story is stories
The plural form of authority is authorities
The plural form of formula is formulae
The plural form of strategy is strategies
The plural form of ability is abilities
The plural form of secretary is
2024-07-28 09:39:15 root INFO     [order_1_approx] starting weight calculation for The plural form of formula is formulae
The plural form of story is stories
The plural form of strategy is strategies
The plural form of ability is abilities
The plural form of academy is academies
The plural form of city is cities
The plural form of secretary is secretaries
The plural form of authority is
2024-07-28 09:39:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 09:41:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0503,  0.3740, -0.2849,  ..., -0.1345, -0.1315,  0.0686],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1118, -2.6094,  1.1523,  ..., -0.9639, -1.4219, -3.1445],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0484,  0.0121, -0.0009,  ...,  0.0064, -0.0095,  0.0167],
        [-0.0069,  0.0569,  0.0053,  ...,  0.0221,  0.0077,  0.0169],
        [ 0.0142,  0.0165,  0.0285,  ...,  0.0010, -0.0099,  0.0097],
        ...,
        [ 0.0063,  0.0234,  0.0015,  ...,  0.0374, -0.0003,  0.0063],
        [-0.0173,  0.0143,  0.0043,  ..., -0.0039,  0.0283, -0.0092],
        [ 0.0197, -0.0082, -0.0079,  ...,  0.0115, -0.0020,  0.0340]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0359, -2.4746,  1.1104,  ..., -0.8271, -1.1797, -3.3105]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 09:41:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of formula is formulae
The plural form of story is stories
The plural form of strategy is strategies
The plural form of ability is abilities
The plural form of academy is academies
The plural form of city is cities
The plural form of secretary is secretaries
The plural form of authority is
2024-07-28 09:41:37 root INFO     [order_1_approx] starting weight calculation for The plural form of secretary is secretaries
The plural form of academy is academies
The plural form of story is stories
The plural form of strategy is strategies
The plural form of ability is abilities
The plural form of authority is authorities
The plural form of formula is formulae
The plural form of city is
2024-07-28 09:41:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 09:43:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2257,  0.0414, -0.4390,  ..., -0.2539, -0.2988, -0.1229],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.7188, -6.0781,  1.8154,  ..., -1.2891,  1.5918, -0.8262],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.5439e-02,  9.5367e-04,  1.5526e-02,  ..., -1.6037e-02,
          7.0114e-03,  2.1439e-02],
        [ 2.4338e-02,  5.0598e-02, -1.1353e-02,  ...,  4.4518e-03,
          2.2400e-02, -1.2436e-02],
        [-5.5084e-03,  1.4290e-02,  8.1604e-02,  ...,  1.7776e-02,
         -3.0228e-02,  1.9577e-02],
        ...,
        [ 3.4447e-03,  1.7197e-02,  8.4610e-03,  ...,  4.8553e-02,
          1.9623e-02,  8.3389e-03],
        [-2.7054e-02,  1.5015e-02, -2.0737e-02,  ...,  2.4963e-02,
          2.7832e-02, -1.2703e-02],
        [ 1.3535e-02, -8.8959e-03, -2.8214e-02,  ..., -1.1246e-02,
         -2.5749e-05,  5.6335e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.4932, -6.1797,  1.6094,  ..., -1.6016,  1.7285, -0.6201]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 09:44:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of secretary is secretaries
The plural form of academy is academies
The plural form of story is stories
The plural form of strategy is strategies
The plural form of ability is abilities
The plural form of authority is authorities
The plural form of formula is formulae
The plural form of city is
2024-07-28 09:44:00 root INFO     [order_1_approx] starting weight calculation for The plural form of formula is formulae
The plural form of academy is academies
The plural form of story is stories
The plural form of city is cities
The plural form of strategy is strategies
The plural form of secretary is secretaries
The plural form of authority is authorities
The plural form of ability is
2024-07-28 09:44:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 09:46:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2463, -0.0143, -0.0649,  ..., -0.3843, -0.0218,  0.0756],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9609, -1.2422,  0.8037,  ..., -0.6328, -2.4238, -1.1816],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0628,  0.0047,  0.0094,  ..., -0.0083,  0.0163,  0.0337],
        [ 0.0090,  0.0674,  0.0057,  ...,  0.0379,  0.0005,  0.0068],
        [-0.0038,  0.0026,  0.0455,  ..., -0.0131, -0.0048,  0.0267],
        ...,
        [ 0.0043,  0.0337, -0.0214,  ...,  0.0468, -0.0020,  0.0165],
        [-0.0116,  0.0248,  0.0105,  ..., -0.0003,  0.0248, -0.0096],
        [-0.0028, -0.0065, -0.0029,  ...,  0.0055,  0.0042,  0.0345]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2793, -1.2666,  0.8726,  ..., -0.5806, -1.8350, -1.3672]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 09:46:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of formula is formulae
The plural form of academy is academies
The plural form of story is stories
The plural form of city is cities
The plural form of strategy is strategies
The plural form of secretary is secretaries
The plural form of authority is authorities
The plural form of ability is
2024-07-28 09:46:22 root INFO     [order_1_approx] starting weight calculation for The plural form of academy is academies
The plural form of strategy is strategies
The plural form of ability is abilities
The plural form of secretary is secretaries
The plural form of city is cities
The plural form of formula is formulae
The plural form of authority is authorities
The plural form of story is
2024-07-28 09:46:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 09:48:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1354,  0.1295, -0.1192,  ..., -0.3672, -0.2935, -0.0959],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8418, -1.7773,  1.1689,  ..., -0.4204, -1.5195, -2.4609],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0246,  0.0168, -0.0322,  ..., -0.0158, -0.0029, -0.0241],
        [ 0.0477,  0.0605,  0.0287,  ...,  0.0312,  0.0058,  0.0392],
        [ 0.0109,  0.0130,  0.0570,  ..., -0.0092, -0.0330,  0.0007],
        ...,
        [ 0.0394,  0.0234,  0.0024,  ...,  0.0597, -0.0167,  0.0291],
        [-0.0211,  0.0156,  0.0033,  ...,  0.0216,  0.0213,  0.0053],
        [ 0.0496,  0.0048,  0.0211,  ..., -0.0050, -0.0060,  0.0805]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1250, -2.2871,  1.7529,  ..., -0.3909, -1.5449, -2.2969]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 09:48:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of academy is academies
The plural form of strategy is strategies
The plural form of ability is abilities
The plural form of secretary is secretaries
The plural form of city is cities
The plural form of formula is formulae
The plural form of authority is authorities
The plural form of story is
2024-07-28 09:48:45 root INFO     total operator prediction time: 1139.7467687129974 seconds
2024-07-28 09:48:45 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - member
2024-07-28 09:48:45 root INFO     building operator meronyms - member
2024-07-28 09:48:45 root INFO     [order_1_approx] starting weight calculation for A cow is a member of a herd
A lion is a member of a pride
A senator is a member of a senate
A soldier is a member of a army
A book is a member of a library
A student is a member of a class
A tree is a member of a forest
A galaxy is a member of a
2024-07-28 09:48:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 09:51:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5117,  0.3845, -0.2510,  ..., -0.2039, -0.2081,  0.0394],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7529, -1.6504,  5.6055,  ..., -3.9785, -1.4648, -2.3047],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.0757e-02, -7.4844e-03,  6.5689e-03,  ...,  8.1062e-04,
         -2.1057e-03,  9.8114e-03],
        [-4.7607e-03,  1.3306e-02,  8.2626e-03,  ...,  1.4725e-02,
          4.8828e-03, -2.3460e-03],
        [-5.5504e-03,  9.2392e-03,  1.7075e-02,  ..., -1.2833e-02,
         -4.1046e-03, -1.1826e-04],
        ...,
        [ 4.8256e-03, -2.1000e-03, -2.1210e-03,  ...,  2.1683e-02,
          6.6452e-03,  1.1148e-03],
        [ 5.5313e-03,  5.7220e-03, -2.9659e-04,  ..., -9.2468e-03,
          2.1332e-02,  1.0300e-03],
        [ 3.0766e-03,  1.7567e-03,  9.1553e-05,  ..., -7.9956e-03,
         -1.7700e-03,  1.0406e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.9062, -1.7012,  5.4453,  ..., -3.7441, -1.3691, -2.2188]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 09:51:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A cow is a member of a herd
A lion is a member of a pride
A senator is a member of a senate
A soldier is a member of a army
A book is a member of a library
A student is a member of a class
A tree is a member of a forest
A galaxy is a member of a
2024-07-28 09:51:08 root INFO     [order_1_approx] starting weight calculation for A lion is a member of a pride
A soldier is a member of a army
A student is a member of a class
A senator is a member of a senate
A tree is a member of a forest
A book is a member of a library
A galaxy is a member of a universe
A cow is a member of a
2024-07-28 09:51:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 09:53:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3105, -0.0540,  0.1273,  ..., -0.0327, -0.1973,  0.2991],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.0352, -5.0859,  3.9434,  ..., -3.7773, -0.7139, -1.8818],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0455,  0.0068, -0.0083,  ...,  0.0058, -0.0281,  0.0006],
        [ 0.0158,  0.0549,  0.0159,  ...,  0.0061, -0.0226, -0.0068],
        [ 0.0048, -0.0034,  0.0469,  ..., -0.0075,  0.0063, -0.0126],
        ...,
        [-0.0088, -0.0006,  0.0217,  ...,  0.0623,  0.0193, -0.0181],
        [ 0.0089,  0.0227, -0.0245,  ...,  0.0038,  0.0595, -0.0154],
        [-0.0100, -0.0201, -0.0144,  ..., -0.0316, -0.0078,  0.0534]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.2227, -5.3594,  3.7676,  ..., -3.7422, -0.9121, -1.3857]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 09:53:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A lion is a member of a pride
A soldier is a member of a army
A student is a member of a class
A senator is a member of a senate
A tree is a member of a forest
A book is a member of a library
A galaxy is a member of a universe
A cow is a member of a
2024-07-28 09:53:28 root INFO     [order_1_approx] starting weight calculation for A galaxy is a member of a universe
A senator is a member of a senate
A book is a member of a library
A soldier is a member of a army
A tree is a member of a forest
A cow is a member of a herd
A lion is a member of a pride
A student is a member of a
2024-07-28 09:53:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 09:55:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2235,  0.0995, -0.1362,  ...,  0.3562, -0.2527, -0.0186],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5430, -4.6406,  3.5371,  ..., -0.9482, -0.0820, -3.1309],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0456,  0.0002,  0.0032,  ...,  0.0208, -0.0127,  0.0111],
        [ 0.0032,  0.0423,  0.0083,  ..., -0.0104, -0.0032, -0.0098],
        [ 0.0092, -0.0176,  0.0391,  ...,  0.0052,  0.0170, -0.0018],
        ...,
        [-0.0054,  0.0154,  0.0115,  ...,  0.0486, -0.0242,  0.0023],
        [ 0.0090,  0.0139, -0.0089,  ..., -0.0054,  0.0372,  0.0034],
        [ 0.0171, -0.0120, -0.0135,  ..., -0.0189, -0.0024,  0.0390]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7363, -4.6016,  3.2559,  ..., -0.8994, -0.2401, -2.4199]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 09:55:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A galaxy is a member of a universe
A senator is a member of a senate
A book is a member of a library
A soldier is a member of a army
A tree is a member of a forest
A cow is a member of a herd
A lion is a member of a pride
A student is a member of a
2024-07-28 09:55:51 root INFO     [order_1_approx] starting weight calculation for A lion is a member of a pride
A book is a member of a library
A galaxy is a member of a universe
A senator is a member of a senate
A cow is a member of a herd
A tree is a member of a forest
A student is a member of a class
A soldier is a member of a
2024-07-28 09:55:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 09:58:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2480,  0.2341, -0.1832,  ...,  0.1328, -0.4614,  0.2283],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0341, -6.0312,  2.9062,  ..., -2.1777, -0.0063, -2.5430],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0450,  0.0124, -0.0026,  ...,  0.0212, -0.0105, -0.0016],
        [ 0.0040,  0.0663,  0.0079,  ..., -0.0036,  0.0052,  0.0068],
        [-0.0020, -0.0027,  0.0457,  ..., -0.0110,  0.0211, -0.0093],
        ...,
        [-0.0036,  0.0223,  0.0043,  ...,  0.0329,  0.0110,  0.0013],
        [ 0.0005,  0.0059, -0.0073,  ..., -0.0162,  0.0411, -0.0020],
        [ 0.0132,  0.0018, -0.0116,  ..., -0.0019, -0.0043,  0.0502]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1317, -5.9961,  2.7383,  ..., -2.1133, -0.0849, -2.3574]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 09:58:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A lion is a member of a pride
A book is a member of a library
A galaxy is a member of a universe
A senator is a member of a senate
A cow is a member of a herd
A tree is a member of a forest
A student is a member of a class
A soldier is a member of a
2024-07-28 09:58:14 root INFO     [order_1_approx] starting weight calculation for A lion is a member of a pride
A student is a member of a class
A senator is a member of a senate
A soldier is a member of a army
A book is a member of a library
A cow is a member of a herd
A galaxy is a member of a universe
A tree is a member of a
2024-07-28 09:58:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 10:00:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0031,  0.0781, -0.1799,  ..., -0.1007, -0.2808, -0.1423],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5508, -6.0430,  1.6035,  ..., -3.9004, -0.9531, -3.7422],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0609, -0.0223,  0.0110,  ...,  0.0122, -0.0402,  0.0130],
        [ 0.0102,  0.0419,  0.0150,  ...,  0.0003, -0.0023, -0.0148],
        [-0.0130,  0.0048,  0.0679,  ..., -0.0427,  0.0010,  0.0099],
        ...,
        [-0.0185, -0.0062,  0.0015,  ...,  0.0623,  0.0133, -0.0162],
        [ 0.0131,  0.0155, -0.0046,  ..., -0.0267,  0.0758,  0.0189],
        [ 0.0080, -0.0388,  0.0016,  ..., -0.0060, -0.0158,  0.0656]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8584, -5.7734,  1.3242,  ..., -3.8496, -1.6523, -3.3516]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 10:00:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A lion is a member of a pride
A student is a member of a class
A senator is a member of a senate
A soldier is a member of a army
A book is a member of a library
A cow is a member of a herd
A galaxy is a member of a universe
A tree is a member of a
2024-07-28 10:00:36 root INFO     [order_1_approx] starting weight calculation for A soldier is a member of a army
A galaxy is a member of a universe
A senator is a member of a senate
A tree is a member of a forest
A book is a member of a library
A student is a member of a class
A cow is a member of a herd
A lion is a member of a
2024-07-28 10:00:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 10:02:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6729,  0.1469,  0.0891,  ...,  0.0389, -0.3750,  0.0247],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.2500, -7.2578,  1.4707,  ..., -0.9209, -0.7549, -1.5771],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0431,  0.0191,  0.0179,  ...,  0.0118, -0.0117,  0.0130],
        [ 0.0057,  0.0258,  0.0098,  ..., -0.0101, -0.0040, -0.0087],
        [ 0.0041, -0.0048,  0.0555,  ..., -0.0245, -0.0030, -0.0229],
        ...,
        [ 0.0061, -0.0011,  0.0219,  ...,  0.0532,  0.0171, -0.0163],
        [ 0.0243,  0.0016, -0.0085,  ..., -0.0023,  0.0168, -0.0199],
        [ 0.0065, -0.0171, -0.0172,  ..., -0.0177, -0.0084,  0.0482]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.8945, -6.8828,  1.3730,  ..., -0.6807, -0.9834, -1.3506]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 10:02:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A soldier is a member of a army
A galaxy is a member of a universe
A senator is a member of a senate
A tree is a member of a forest
A book is a member of a library
A student is a member of a class
A cow is a member of a herd
A lion is a member of a
2024-07-28 10:02:59 root INFO     [order_1_approx] starting weight calculation for A cow is a member of a herd
A tree is a member of a forest
A lion is a member of a pride
A soldier is a member of a army
A senator is a member of a senate
A student is a member of a class
A galaxy is a member of a universe
A book is a member of a
2024-07-28 10:02:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 10:05:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0461, -0.1306, -0.0208,  ...,  0.3105, -0.1990, -0.0467],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6016, -5.0000,  0.9912,  ..., -1.7012, -1.7266, -3.7793],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0519,  0.0081, -0.0012,  ...,  0.0103, -0.0043,  0.0154],
        [-0.0023,  0.0569,  0.0120,  ...,  0.0113, -0.0017,  0.0008],
        [-0.0019, -0.0138,  0.0479,  ..., -0.0063, -0.0113,  0.0010],
        ...,
        [-0.0019,  0.0072, -0.0207,  ...,  0.0721, -0.0183, -0.0289],
        [-0.0125,  0.0010, -0.0218,  ..., -0.0005,  0.0587, -0.0094],
        [-0.0138,  0.0020,  0.0142,  ..., -0.0116, -0.0306,  0.0498]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9902, -5.3789,  1.1533,  ..., -1.6016, -1.9043, -3.2793]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 10:05:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A cow is a member of a herd
A tree is a member of a forest
A lion is a member of a pride
A soldier is a member of a army
A senator is a member of a senate
A student is a member of a class
A galaxy is a member of a universe
A book is a member of a
2024-07-28 10:05:19 root INFO     [order_1_approx] starting weight calculation for A lion is a member of a pride
A galaxy is a member of a universe
A student is a member of a class
A cow is a member of a herd
A tree is a member of a forest
A book is a member of a library
A soldier is a member of a army
A senator is a member of a
2024-07-28 10:05:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 10:07:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4995,  0.7871, -0.3359,  ...,  0.3262, -0.4490, -0.1121],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0742, -5.7969,  4.6953,  ..., -3.9453,  2.6621, -0.5732],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0258, -0.0095,  0.0054,  ...,  0.0157, -0.0261,  0.0068],
        [ 0.0176,  0.0331,  0.0085,  ...,  0.0098,  0.0145, -0.0075],
        [-0.0079, -0.0059,  0.0319,  ..., -0.0220, -0.0144, -0.0049],
        ...,
        [ 0.0125,  0.0143,  0.0148,  ...,  0.0438,  0.0110, -0.0116],
        [-0.0137, -0.0035, -0.0065,  ..., -0.0011,  0.0225,  0.0150],
        [ 0.0009, -0.0143, -0.0109,  ..., -0.0073, -0.0004,  0.0340]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9414, -5.6602,  4.5117,  ..., -3.7207,  2.2324, -0.3276]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 10:07:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A lion is a member of a pride
A galaxy is a member of a universe
A student is a member of a class
A cow is a member of a herd
A tree is a member of a forest
A book is a member of a library
A soldier is a member of a army
A senator is a member of a
2024-07-28 10:07:44 root INFO     total operator prediction time: 1139.1661517620087 seconds
2024-07-28 10:07:44 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on antonyms - binary
2024-07-28 10:07:44 root INFO     building operator antonyms - binary
2024-07-28 10:07:44 root INFO     [order_1_approx] starting weight calculation for The opposite of dead is alive
The opposite of interior is exterior
The opposite of beginning is end
The opposite of downslope is upslope
The opposite of outward is upward
The opposite of inbound is outbound
The opposite of down is up
The opposite of southeast is
2024-07-28 10:07:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 10:10:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1873,  0.0771,  0.0194,  ...,  0.0317,  0.2032, -0.3574],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8213, -2.5762,  2.8301,  ..., -0.7661, -1.6602, -1.1367],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0522, -0.0266,  0.0164,  ..., -0.0023,  0.0022, -0.0136],
        [ 0.0042,  0.0328,  0.0238,  ..., -0.0058,  0.0050, -0.0219],
        [-0.0240, -0.0241,  0.0042,  ...,  0.0118, -0.0297,  0.0107],
        ...,
        [ 0.0065, -0.0129,  0.0136,  ...,  0.0388,  0.0040, -0.0187],
        [ 0.0056, -0.0272,  0.0120,  ...,  0.0193,  0.0366,  0.0163],
        [ 0.0002,  0.0027,  0.0263,  ..., -0.0066,  0.0093,  0.0436]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7212, -3.0391,  2.2012,  ..., -0.5396, -1.5156, -1.1777]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 10:10:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of dead is alive
The opposite of interior is exterior
The opposite of beginning is end
The opposite of downslope is upslope
The opposite of outward is upward
The opposite of inbound is outbound
The opposite of down is up
The opposite of southeast is
2024-07-28 10:10:05 root INFO     [order_1_approx] starting weight calculation for The opposite of dead is alive
The opposite of southeast is southwest
The opposite of down is up
The opposite of downslope is upslope
The opposite of outward is upward
The opposite of inbound is outbound
The opposite of interior is exterior
The opposite of beginning is
2024-07-28 10:10:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 10:12:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3687,  0.0946, -0.1864,  ..., -0.1737, -0.3999, -0.0493],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0781, -2.9688, -0.4041,  ...,  0.7534, -2.1094, -2.0820],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.6255e-02, -2.4414e-04,  1.3718e-02,  ...,  2.3499e-02,
         -4.3671e-02,  1.4458e-03],
        [-2.4395e-03,  8.9417e-02,  4.5128e-03,  ...,  1.5907e-03,
          1.1597e-02, -7.7934e-03],
        [-2.7275e-04, -2.7405e-02,  7.7820e-03,  ..., -1.0624e-03,
         -2.6581e-02, -4.8065e-03],
        ...,
        [ 8.5526e-03,  2.2232e-02, -1.8494e-02,  ...,  3.0716e-02,
          2.2888e-05, -1.7761e-02],
        [ 1.6403e-03, -1.4160e-02,  2.5131e-02,  ..., -7.5874e-03,
          6.8848e-02, -2.1305e-03],
        [ 7.1602e-03, -1.1742e-02, -1.5068e-02,  ..., -2.5208e-02,
         -8.6441e-03,  3.4088e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8467, -2.9766,  0.3694,  ...,  0.8008, -1.7168, -1.4766]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 10:12:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of dead is alive
The opposite of southeast is southwest
The opposite of down is up
The opposite of downslope is upslope
The opposite of outward is upward
The opposite of inbound is outbound
The opposite of interior is exterior
The opposite of beginning is
2024-07-28 10:12:28 root INFO     [order_1_approx] starting weight calculation for The opposite of beginning is end
The opposite of downslope is upslope
The opposite of interior is exterior
The opposite of outward is upward
The opposite of dead is alive
The opposite of southeast is southwest
The opposite of inbound is outbound
The opposite of down is
2024-07-28 10:12:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 10:14:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0771, -0.3804,  0.2186,  ..., -0.2279, -0.1230,  0.0704],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0762, -4.9492,  1.8389,  ..., -0.0093, -0.1528, -3.5879],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0410,  0.0082,  0.0056,  ..., -0.0077,  0.0267,  0.0085],
        [ 0.0012,  0.0190, -0.0011,  ...,  0.0112, -0.0104,  0.0005],
        [-0.0051,  0.0024,  0.0008,  ...,  0.0026,  0.0070,  0.0028],
        ...,
        [ 0.0180,  0.0025, -0.0001,  ...,  0.0125,  0.0115, -0.0134],
        [-0.0059, -0.0012,  0.0083,  ...,  0.0114,  0.0167,  0.0016],
        [ 0.0075, -0.0024,  0.0100,  ...,  0.0025,  0.0042,  0.0195]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6709, -4.5469,  1.8545,  ...,  0.1930, -0.1653, -3.7285]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 10:14:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of beginning is end
The opposite of downslope is upslope
The opposite of interior is exterior
The opposite of outward is upward
The opposite of dead is alive
The opposite of southeast is southwest
The opposite of inbound is outbound
The opposite of down is
2024-07-28 10:14:50 root INFO     [order_1_approx] starting weight calculation for The opposite of beginning is end
The opposite of dead is alive
The opposite of southeast is southwest
The opposite of interior is exterior
The opposite of downslope is upslope
The opposite of outward is upward
The opposite of down is up
The opposite of inbound is
2024-07-28 10:14:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 10:17:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2225,  0.4097,  0.1392,  ..., -0.2595,  0.2935,  0.0080],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8965, -1.4697,  0.1117,  ..., -0.9536, -0.1758, -1.7725],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0919,  0.0126,  0.0099,  ...,  0.0199, -0.0316,  0.0040],
        [-0.0137,  0.0958,  0.0069,  ...,  0.0074,  0.0443,  0.0044],
        [ 0.0087, -0.0124,  0.0230,  ..., -0.0175, -0.0038,  0.0070],
        ...,
        [ 0.0002,  0.0089, -0.0451,  ...,  0.0742, -0.0156, -0.0311],
        [-0.0094,  0.0043, -0.0025,  ...,  0.0206,  0.0659,  0.0170],
        [ 0.0139, -0.0143,  0.0135,  ..., -0.0162, -0.0168,  0.0806]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0752, -1.9287,  0.0128,  ..., -0.7656,  0.2708, -1.8564]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 10:17:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of beginning is end
The opposite of dead is alive
The opposite of southeast is southwest
The opposite of interior is exterior
The opposite of downslope is upslope
The opposite of outward is upward
The opposite of down is up
The opposite of inbound is
2024-07-28 10:17:11 root INFO     [order_1_approx] starting weight calculation for The opposite of dead is alive
The opposite of southeast is southwest
The opposite of outward is upward
The opposite of down is up
The opposite of inbound is outbound
The opposite of beginning is end
The opposite of interior is exterior
The opposite of downslope is
2024-07-28 10:17:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 10:19:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0598,  0.3784, -0.2329,  ..., -0.1772, -0.7603, -0.1539],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2783, -1.1895, -4.1719,  ..., -1.4092, -2.1211, -2.6309],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0458,  0.0097,  0.0060,  ...,  0.0260, -0.0132, -0.0005],
        [-0.0038,  0.0852,  0.0109,  ...,  0.0323,  0.0202, -0.0073],
        [ 0.0407,  0.0023, -0.0255,  ...,  0.0121, -0.0484, -0.0065],
        ...,
        [ 0.0078,  0.0167,  0.0038,  ...,  0.0386, -0.0070,  0.0277],
        [ 0.0245,  0.0201, -0.0012,  ..., -0.0121,  0.0612,  0.0165],
        [-0.0021, -0.0016,  0.0143,  ...,  0.0084, -0.0117,  0.0133]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1099, -1.0195, -3.9805,  ..., -0.8130, -2.2637, -2.8320]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 10:19:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of dead is alive
The opposite of southeast is southwest
The opposite of outward is upward
The opposite of down is up
The opposite of inbound is outbound
The opposite of beginning is end
The opposite of interior is exterior
The opposite of downslope is
2024-07-28 10:19:33 root INFO     [order_1_approx] starting weight calculation for The opposite of down is up
The opposite of inbound is outbound
The opposite of downslope is upslope
The opposite of dead is alive
The opposite of beginning is end
The opposite of southeast is southwest
The opposite of outward is upward
The opposite of interior is
2024-07-28 10:19:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 10:21:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1082,  0.0061,  0.1115,  ..., -0.3777, -0.0070,  0.3948],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2422, -2.5625,  3.4512,  ..., -1.3105, -1.3818, -2.8496],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0536,  0.0204,  0.0111,  ..., -0.0087, -0.0422, -0.0248],
        [ 0.0092,  0.0823, -0.0178,  ..., -0.0016,  0.0103,  0.0030],
        [-0.0052, -0.0111,  0.0329,  ..., -0.0090, -0.0205, -0.0017],
        ...,
        [ 0.0093,  0.0023, -0.0099,  ...,  0.0471,  0.0455, -0.0254],
        [ 0.0122,  0.0029, -0.0207,  ...,  0.0415,  0.0781,  0.0089],
        [ 0.0061,  0.0017, -0.0361,  ...,  0.0035, -0.0165,  0.0745]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4600, -2.5176,  3.1055,  ..., -0.8677, -1.0996, -2.7969]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 10:21:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of down is up
The opposite of inbound is outbound
The opposite of downslope is upslope
The opposite of dead is alive
The opposite of beginning is end
The opposite of southeast is southwest
The opposite of outward is upward
The opposite of interior is
2024-07-28 10:21:55 root INFO     [order_1_approx] starting weight calculation for The opposite of beginning is end
The opposite of outward is upward
The opposite of southeast is southwest
The opposite of inbound is outbound
The opposite of interior is exterior
The opposite of down is up
The opposite of downslope is upslope
The opposite of dead is
2024-07-28 10:21:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 10:24:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2083, -0.1791,  0.1456,  ..., -0.3372,  0.1240,  0.1670],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0469, -2.4434,  2.0859,  ..., -3.1699, -3.3398, -2.3438],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0232,  0.0032, -0.0010,  ...,  0.0142, -0.0242,  0.0048],
        [-0.0006,  0.0604,  0.0010,  ...,  0.0120,  0.0075,  0.0046],
        [ 0.0231,  0.0064,  0.0576,  ..., -0.0151, -0.0203, -0.0064],
        ...,
        [-0.0158,  0.0195, -0.0115,  ...,  0.0305,  0.0039, -0.0393],
        [-0.0109, -0.0123,  0.0351,  ...,  0.0038,  0.0533, -0.0071],
        [ 0.0120,  0.0013, -0.0074,  ..., -0.0188, -0.0141,  0.0345]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4180, -2.2266,  1.5059,  ..., -2.5781, -3.0488, -2.4082]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 10:24:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of beginning is end
The opposite of outward is upward
The opposite of southeast is southwest
The opposite of inbound is outbound
The opposite of interior is exterior
The opposite of down is up
The opposite of downslope is upslope
The opposite of dead is
2024-07-28 10:24:17 root INFO     [order_1_approx] starting weight calculation for The opposite of southeast is southwest
The opposite of down is up
The opposite of downslope is upslope
The opposite of interior is exterior
The opposite of inbound is outbound
The opposite of dead is alive
The opposite of beginning is end
The opposite of outward is
2024-07-28 10:24:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 10:26:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2712, -0.0483, -0.2356,  ...,  0.0520,  0.1530,  0.0629],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.1045, -1.4209,  1.1064,  ..., -0.6797,  0.7803, -3.4375],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1065,  0.0071,  0.0016,  ..., -0.0121,  0.0257, -0.0021],
        [-0.0262,  0.0969,  0.0124,  ...,  0.0100, -0.0081,  0.0319],
        [ 0.0171, -0.0206,  0.0449,  ...,  0.0049, -0.0850,  0.0246],
        ...,
        [ 0.0068,  0.0316,  0.0078,  ...,  0.1220,  0.0266, -0.0331],
        [-0.0218,  0.0182,  0.0269,  ...,  0.0449,  0.0859, -0.0258],
        [-0.0008, -0.0011,  0.0103,  ..., -0.0218,  0.0438,  0.1027]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1963, -1.8945, -0.0049,  ..., -0.4895,  0.6133, -3.3477]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 10:26:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of southeast is southwest
The opposite of down is up
The opposite of downslope is upslope
The opposite of interior is exterior
The opposite of inbound is outbound
The opposite of dead is alive
The opposite of beginning is end
The opposite of outward is
2024-07-28 10:26:39 root INFO     total operator prediction time: 1135.1772525310516 seconds
2024-07-28 10:26:39 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hyponyms - misc
2024-07-28 10:26:39 root INFO     building operator hyponyms - misc
2024-07-28 10:26:39 root INFO     [order_1_approx] starting weight calculation for A more specific term for a mixer is blender
A more specific term for a container is bag
A more specific term for a tool is rake
A more specific term for a shelf is bookshelf
A more specific term for a painting is watercolor
A more specific term for a drum is tambourine
A more specific term for a seat is chair
A more specific term for a spice is
2024-07-28 10:26:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 10:28:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2335,  0.0958, -0.2932,  ...,  0.3691, -0.0626, -0.5518],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6680, -4.4961, -1.8877,  ..., -0.0859, -2.4980, -2.6934],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0613, -0.0070, -0.0055,  ..., -0.0056,  0.0149, -0.0023],
        [-0.0203,  0.0517, -0.0165,  ...,  0.0163,  0.0175, -0.0069],
        [ 0.0008, -0.0150,  0.0402,  ..., -0.0012, -0.0057,  0.0057],
        ...,
        [-0.0006,  0.0389,  0.0078,  ...,  0.0481,  0.0172, -0.0015],
        [ 0.0018,  0.0096, -0.0047,  ..., -0.0180,  0.0543, -0.0312],
        [ 0.0241, -0.0044,  0.0099,  ..., -0.0268,  0.0040,  0.0406]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3789, -4.4180, -1.8076,  ..., -0.1099, -2.6387, -2.9121]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 10:29:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a mixer is blender
A more specific term for a container is bag
A more specific term for a tool is rake
A more specific term for a shelf is bookshelf
A more specific term for a painting is watercolor
A more specific term for a drum is tambourine
A more specific term for a seat is chair
A more specific term for a spice is
2024-07-28 10:29:00 root INFO     [order_1_approx] starting weight calculation for A more specific term for a seat is chair
A more specific term for a tool is rake
A more specific term for a container is bag
A more specific term for a mixer is blender
A more specific term for a shelf is bookshelf
A more specific term for a drum is tambourine
A more specific term for a spice is pepper
A more specific term for a painting is
2024-07-28 10:29:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 10:31:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1530, -0.0487, -0.1797,  ...,  0.1831, -0.2944,  0.2610],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8955, -4.7891,  0.0171,  ...,  0.5586, -2.0117,  0.6455],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.1045e-02,  2.7191e-02, -2.0676e-03,  ..., -1.1978e-02,
         -9.3613e-03,  3.9856e-02],
        [-1.5030e-02,  5.3162e-02,  5.8289e-03,  ...,  4.5128e-03,
          3.6621e-02, -3.5492e-02],
        [ 2.0142e-02, -1.3161e-02,  7.4585e-02,  ...,  1.3638e-04,
         -1.2512e-02,  4.0245e-03],
        ...,
        [ 2.8366e-02, -6.4240e-03, -1.7872e-03,  ...,  9.2773e-02,
         -1.4248e-03, -4.1443e-02],
        [-2.0645e-02,  7.8430e-03, -5.4665e-03,  ...,  7.8583e-03,
          7.3181e-02, -3.8513e-02],
        [ 9.5367e-05, -3.3875e-03,  6.5536e-03,  ..., -7.7133e-03,
          1.0666e-02,  6.4331e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9243, -5.1250, -0.0261,  ...,  0.5869, -1.9326,  0.3967]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 10:31:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a seat is chair
A more specific term for a tool is rake
A more specific term for a container is bag
A more specific term for a mixer is blender
A more specific term for a shelf is bookshelf
A more specific term for a drum is tambourine
A more specific term for a spice is pepper
A more specific term for a painting is
2024-07-28 10:31:21 root INFO     [order_1_approx] starting weight calculation for A more specific term for a painting is watercolor
A more specific term for a tool is rake
A more specific term for a drum is tambourine
A more specific term for a mixer is blender
A more specific term for a seat is chair
A more specific term for a shelf is bookshelf
A more specific term for a spice is pepper
A more specific term for a container is
2024-07-28 10:31:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 10:33:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1798, -0.4314, -0.3101,  ...,  0.4617, -0.3701, -0.1542],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.5273, -4.4062, -1.0557,  ..., -0.5703, -0.3950, -0.3086],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0541,  0.0074, -0.0163,  ...,  0.0220,  0.0014,  0.0103],
        [-0.0006,  0.0211,  0.0021,  ..., -0.0095, -0.0041, -0.0124],
        [ 0.0044,  0.0006,  0.0685,  ...,  0.0103, -0.0160,  0.0004],
        ...,
        [ 0.0193,  0.0148,  0.0087,  ...,  0.0380,  0.0012, -0.0147],
        [-0.0115, -0.0154, -0.0058,  ..., -0.0126,  0.0163, -0.0073],
        [ 0.0026,  0.0079,  0.0023,  ..., -0.0124, -0.0157,  0.0549]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.2461, -4.6484, -0.6924,  ..., -0.3252, -0.7637, -0.3086]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 10:33:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a painting is watercolor
A more specific term for a tool is rake
A more specific term for a drum is tambourine
A more specific term for a mixer is blender
A more specific term for a seat is chair
A more specific term for a shelf is bookshelf
A more specific term for a spice is pepper
A more specific term for a container is
2024-07-28 10:33:42 root INFO     [order_1_approx] starting weight calculation for A more specific term for a container is bag
A more specific term for a spice is pepper
A more specific term for a tool is rake
A more specific term for a shelf is bookshelf
A more specific term for a drum is tambourine
A more specific term for a painting is watercolor
A more specific term for a seat is chair
A more specific term for a mixer is
2024-07-28 10:33:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 10:36:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0725,  0.1035,  0.0074,  ...,  0.6538, -0.7158, -0.0194],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5635, -4.7031, -0.5352,  ...,  0.6113, -3.1445, -0.0098],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0630,  0.0168, -0.0243,  ...,  0.0275, -0.0043, -0.0197],
        [ 0.0189,  0.0592,  0.0077,  ...,  0.0007, -0.0058, -0.0005],
        [-0.0024, -0.0304,  0.0665,  ..., -0.0066,  0.0132,  0.0190],
        ...,
        [ 0.0358,  0.0383,  0.0038,  ...,  0.0772, -0.0265,  0.0014],
        [-0.0568, -0.0082, -0.0334,  ...,  0.0195,  0.0889, -0.0219],
        [ 0.0100,  0.0296,  0.0127,  ..., -0.0232, -0.0195,  0.0564]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8379, -4.7734, -0.6689,  ...,  0.8521, -2.5391, -0.4338]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 10:36:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a container is bag
A more specific term for a spice is pepper
A more specific term for a tool is rake
A more specific term for a shelf is bookshelf
A more specific term for a drum is tambourine
A more specific term for a painting is watercolor
A more specific term for a seat is chair
A more specific term for a mixer is
2024-07-28 10:36:03 root INFO     [order_1_approx] starting weight calculation for A more specific term for a shelf is bookshelf
A more specific term for a seat is chair
A more specific term for a painting is watercolor
A more specific term for a tool is rake
A more specific term for a container is bag
A more specific term for a mixer is blender
A more specific term for a spice is pepper
A more specific term for a drum is
2024-07-28 10:36:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 10:38:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2954,  0.3545,  0.0883,  ..., -0.1206, -0.3286,  0.2773],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0625, -6.3477,  0.2334,  ...,  0.6299, -0.0791,  0.6309],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0553,  0.0022, -0.0175,  ...,  0.0048,  0.0124, -0.0093],
        [ 0.0166,  0.0519,  0.0037,  ...,  0.0084,  0.0138, -0.0050],
        [ 0.0157,  0.0118,  0.0679,  ...,  0.0118,  0.0047,  0.0259],
        ...,
        [ 0.0178,  0.0140,  0.0173,  ...,  0.0481,  0.0140, -0.0181],
        [-0.0417, -0.0171,  0.0017,  ...,  0.0065,  0.0376, -0.0137],
        [-0.0152,  0.0142,  0.0162,  ..., -0.0057, -0.0097,  0.0497]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2324, -6.1094, -0.1750,  ...,  0.5522, -0.3291,  0.5195]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 10:38:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a shelf is bookshelf
A more specific term for a seat is chair
A more specific term for a painting is watercolor
A more specific term for a tool is rake
A more specific term for a container is bag
A more specific term for a mixer is blender
A more specific term for a spice is pepper
A more specific term for a drum is
2024-07-28 10:38:24 root INFO     [order_1_approx] starting weight calculation for A more specific term for a mixer is blender
A more specific term for a spice is pepper
A more specific term for a tool is rake
A more specific term for a drum is tambourine
A more specific term for a container is bag
A more specific term for a shelf is bookshelf
A more specific term for a painting is watercolor
A more specific term for a seat is
2024-07-28 10:38:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 10:40:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3315, -0.2269, -0.2002,  ...,  0.4348, -0.2952,  0.0101],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3672, -4.8477,  3.3672,  ...,  2.8926, -2.4863,  1.9297],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0878, -0.0061,  0.0008,  ...,  0.0093, -0.0268, -0.0152],
        [-0.0025,  0.0709, -0.0039,  ...,  0.0109,  0.0331, -0.0114],
        [-0.0124, -0.0066,  0.0716,  ..., -0.0004, -0.0159,  0.0089],
        ...,
        [ 0.0202,  0.0277,  0.0124,  ...,  0.0918,  0.0215, -0.0043],
        [-0.0063,  0.0016, -0.0226,  ...,  0.0118, -0.0248, -0.0215],
        [ 0.0029,  0.0107,  0.0065,  ..., -0.0115,  0.0005,  0.0570]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5361, -4.9102,  3.0742,  ...,  2.9590, -2.5312,  1.4531]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 10:40:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a mixer is blender
A more specific term for a spice is pepper
A more specific term for a tool is rake
A more specific term for a drum is tambourine
A more specific term for a container is bag
A more specific term for a shelf is bookshelf
A more specific term for a painting is watercolor
A more specific term for a seat is
2024-07-28 10:40:44 root INFO     [order_1_approx] starting weight calculation for A more specific term for a tool is rake
A more specific term for a seat is chair
A more specific term for a painting is watercolor
A more specific term for a container is bag
A more specific term for a mixer is blender
A more specific term for a spice is pepper
A more specific term for a drum is tambourine
A more specific term for a shelf is
2024-07-28 10:40:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 10:43:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0917, -0.3818, -0.5166,  ...,  0.3643, -0.2454,  0.0414],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.3281, -4.3125,  1.4971,  ...,  2.9043, -2.9961,  1.9023],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0633,  0.0189,  0.0106,  ...,  0.0134, -0.0199, -0.0062],
        [-0.0180,  0.0646, -0.0213,  ...,  0.0203,  0.0248, -0.0153],
        [ 0.0024,  0.0011,  0.0620,  ..., -0.0019, -0.0049,  0.0164],
        ...,
        [ 0.0140,  0.0224,  0.0038,  ...,  0.0566,  0.0096,  0.0037],
        [-0.0076,  0.0175, -0.0326,  ..., -0.0084,  0.0448, -0.0070],
        [-0.0140,  0.0246, -0.0139,  ..., -0.0056, -0.0068,  0.0559]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.8516, -4.9883,  1.8887,  ...,  2.8477, -2.7773,  1.7861]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 10:43:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a tool is rake
A more specific term for a seat is chair
A more specific term for a painting is watercolor
A more specific term for a container is bag
A more specific term for a mixer is blender
A more specific term for a spice is pepper
A more specific term for a drum is tambourine
A more specific term for a shelf is
2024-07-28 10:43:06 root INFO     [order_1_approx] starting weight calculation for A more specific term for a seat is chair
A more specific term for a painting is watercolor
A more specific term for a spice is pepper
A more specific term for a mixer is blender
A more specific term for a container is bag
A more specific term for a shelf is bookshelf
A more specific term for a drum is tambourine
A more specific term for a tool is
2024-07-28 10:43:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 10:45:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1049, -0.3152, -0.0021,  ...,  0.2793, -0.0831,  0.0073],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5913, -4.1094, -0.4170,  ...,  2.6250, -3.6133,  1.0137],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0756,  0.0063,  0.0059,  ...,  0.0156, -0.0100,  0.0126],
        [-0.0239,  0.0490,  0.0049,  ...,  0.0016,  0.0188, -0.0011],
        [-0.0166,  0.0007,  0.0419,  ..., -0.0176, -0.0091,  0.0092],
        ...,
        [ 0.0207,  0.0049, -0.0018,  ...,  0.0525,  0.0065,  0.0050],
        [ 0.0023,  0.0012, -0.0154,  ..., -0.0091,  0.0428, -0.0160],
        [-0.0149,  0.0310,  0.0111,  ..., -0.0169,  0.0153,  0.0516]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4854, -4.3320, -0.6729,  ...,  2.8359, -3.4668,  1.0859]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 10:45:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a seat is chair
A more specific term for a painting is watercolor
A more specific term for a spice is pepper
A more specific term for a mixer is blender
A more specific term for a container is bag
A more specific term for a shelf is bookshelf
A more specific term for a drum is tambourine
A more specific term for a tool is
2024-07-28 10:45:23 root INFO     total operator prediction time: 1123.8504056930542 seconds
2024-07-28 10:45:23 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hypernyms - animals
2024-07-28 10:45:23 root INFO     building operator hypernyms - animals
2024-07-28 10:45:23 root INFO     [order_1_approx] starting weight calculation for The hawk falls into the category of raptor
The jaguar falls into the category of feline
The rattlesnake falls into the category of snake
The cockroach falls into the category of insect
The vulture falls into the category of raptor
The coyote falls into the category of canine
The eagle falls into the category of raptor
The beaver falls into the category of
2024-07-28 10:45:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 10:47:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3748, -0.2080, -0.0794,  ...,  0.2605, -0.5708,  0.3276],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4609, -4.7969,  2.4668,  ..., -0.9941, -7.0078, -1.5049],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.1779e-02, -1.1932e-02, -1.9867e-02,  ..., -2.7008e-02,
         -2.3468e-02, -2.9583e-03],
        [ 2.5768e-03,  4.0802e-02, -1.1749e-03,  ...,  7.2861e-03,
         -3.1776e-03, -3.5980e-02],
        [-1.8677e-02, -2.0790e-04,  6.5796e-02,  ..., -2.3697e-02,
          1.4046e-02,  9.3231e-03],
        ...,
        [-8.6670e-03,  1.4877e-02,  1.7609e-02,  ...,  5.7770e-02,
          2.5692e-03, -3.0193e-03],
        [-1.1627e-02, -9.1553e-05,  2.3956e-03,  ..., -8.9455e-04,
          5.6885e-02,  6.5842e-03],
        [ 9.2163e-03, -6.7673e-03,  6.4087e-04,  ..., -3.9429e-02,
         -2.0203e-02,  5.3162e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4521, -4.2578,  2.1504,  ..., -0.9399, -7.0781, -1.0723]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 10:47:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The hawk falls into the category of raptor
The jaguar falls into the category of feline
The rattlesnake falls into the category of snake
The cockroach falls into the category of insect
The vulture falls into the category of raptor
The coyote falls into the category of canine
The eagle falls into the category of raptor
The beaver falls into the category of
2024-07-28 10:47:45 root INFO     [order_1_approx] starting weight calculation for The cockroach falls into the category of insect
The vulture falls into the category of raptor
The jaguar falls into the category of feline
The hawk falls into the category of raptor
The rattlesnake falls into the category of snake
The beaver falls into the category of rodent
The coyote falls into the category of canine
The eagle falls into the category of
2024-07-28 10:47:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 10:50:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5796, -0.3467, -0.0410,  ...,  0.5703, -0.1707,  0.0377],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6387, -2.8359,  1.3418,  ..., -1.2568, -6.4922,  0.9141],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0475,  0.0037, -0.0259,  ...,  0.0121, -0.0027,  0.0047],
        [-0.0072,  0.0224,  0.0055,  ...,  0.0011,  0.0169, -0.0190],
        [-0.0005,  0.0049,  0.0541,  ...,  0.0137, -0.0129, -0.0159],
        ...,
        [ 0.0168, -0.0094,  0.0083,  ...,  0.0388,  0.0140,  0.0029],
        [-0.0040,  0.0013, -0.0134,  ...,  0.0237,  0.0325, -0.0007],
        [ 0.0124, -0.0186,  0.0069,  ..., -0.0172, -0.0190,  0.0392]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0000, -3.2148,  0.8306,  ..., -0.8447, -6.6992,  1.0547]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 10:50:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The cockroach falls into the category of insect
The vulture falls into the category of raptor
The jaguar falls into the category of feline
The hawk falls into the category of raptor
The rattlesnake falls into the category of snake
The beaver falls into the category of rodent
The coyote falls into the category of canine
The eagle falls into the category of
2024-07-28 10:50:07 root INFO     [order_1_approx] starting weight calculation for The cockroach falls into the category of insect
The jaguar falls into the category of feline
The beaver falls into the category of rodent
The vulture falls into the category of raptor
The hawk falls into the category of raptor
The coyote falls into the category of canine
The eagle falls into the category of raptor
The rattlesnake falls into the category of
2024-07-28 10:50:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 10:52:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2708,  0.2003, -0.2228,  ...,  0.4548, -0.3303, -0.0930],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2266, -4.3438,  1.6094,  ..., -2.6621, -2.9473, -0.6289],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0301, -0.0049, -0.0144,  ..., -0.0141, -0.0088, -0.0059],
        [-0.0078,  0.0292,  0.0005,  ..., -0.0012,  0.0092, -0.0020],
        [ 0.0104,  0.0078,  0.0735,  ..., -0.0165, -0.0019, -0.0104],
        ...,
        [ 0.0109,  0.0012,  0.0048,  ...,  0.0411,  0.0227, -0.0098],
        [-0.0029, -0.0026,  0.0078,  ..., -0.0006,  0.0429,  0.0038],
        [ 0.0005, -0.0151, -0.0227,  ..., -0.0080, -0.0026,  0.0409]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2490, -4.2305,  1.3115,  ..., -2.2148, -3.3457, -0.3281]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 10:52:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The cockroach falls into the category of insect
The jaguar falls into the category of feline
The beaver falls into the category of rodent
The vulture falls into the category of raptor
The hawk falls into the category of raptor
The coyote falls into the category of canine
The eagle falls into the category of raptor
The rattlesnake falls into the category of
2024-07-28 10:52:18 root INFO     [order_1_approx] starting weight calculation for The rattlesnake falls into the category of snake
The hawk falls into the category of raptor
The coyote falls into the category of canine
The jaguar falls into the category of feline
The cockroach falls into the category of insect
The beaver falls into the category of rodent
The eagle falls into the category of raptor
The vulture falls into the category of
2024-07-28 10:52:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 10:54:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4980, -0.2065, -0.1175,  ...,  0.0190, -0.2783,  0.1854],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8994, -1.3018,  3.6074,  ..., -2.4180, -4.4609,  1.4580],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0508,  0.0035, -0.0333,  ..., -0.0031,  0.0052, -0.0046],
        [-0.0144,  0.0553, -0.0117,  ...,  0.0151,  0.0322, -0.0162],
        [-0.0016, -0.0204,  0.0673,  ...,  0.0338,  0.0074,  0.0050],
        ...,
        [ 0.0178,  0.0054,  0.0212,  ...,  0.0435,  0.0182, -0.0114],
        [-0.0335,  0.0089, -0.0046,  ...,  0.0043,  0.0573, -0.0143],
        [ 0.0262, -0.0094, -0.0133,  ...,  0.0234,  0.0063,  0.0555]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1152, -1.7227,  2.9453,  ..., -2.1211, -4.8125,  1.1123]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 10:54:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The rattlesnake falls into the category of snake
The hawk falls into the category of raptor
The coyote falls into the category of canine
The jaguar falls into the category of feline
The cockroach falls into the category of insect
The beaver falls into the category of rodent
The eagle falls into the category of raptor
The vulture falls into the category of
2024-07-28 10:54:34 root INFO     [order_1_approx] starting weight calculation for The vulture falls into the category of raptor
The coyote falls into the category of canine
The jaguar falls into the category of feline
The beaver falls into the category of rodent
The eagle falls into the category of raptor
The cockroach falls into the category of insect
The rattlesnake falls into the category of snake
The hawk falls into the category of
2024-07-28 10:54:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 10:56:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1506, -0.2117, -0.0875,  ...,  0.3835, -0.0341, -0.3398],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6270, -3.4727,  2.4609,  ..., -1.4629, -4.5312,  0.5068],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0474,  0.0132, -0.0069,  ..., -0.0043, -0.0205,  0.0007],
        [ 0.0167,  0.0238,  0.0111,  ...,  0.0056,  0.0118, -0.0039],
        [ 0.0043, -0.0024,  0.0482,  ...,  0.0054, -0.0077, -0.0104],
        ...,
        [ 0.0130,  0.0043,  0.0034,  ...,  0.0325,  0.0144,  0.0005],
        [ 0.0037, -0.0058, -0.0125,  ...,  0.0084,  0.0395, -0.0033],
        [ 0.0094, -0.0173,  0.0049,  ..., -0.0181, -0.0221,  0.0387]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8242, -3.5957,  2.1035,  ..., -1.3291, -4.5625,  0.6543]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 10:56:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The vulture falls into the category of raptor
The coyote falls into the category of canine
The jaguar falls into the category of feline
The beaver falls into the category of rodent
The eagle falls into the category of raptor
The cockroach falls into the category of insect
The rattlesnake falls into the category of snake
The hawk falls into the category of
2024-07-28 10:56:51 root INFO     [order_1_approx] starting weight calculation for The hawk falls into the category of raptor
The vulture falls into the category of raptor
The rattlesnake falls into the category of snake
The jaguar falls into the category of feline
The eagle falls into the category of raptor
The beaver falls into the category of rodent
The coyote falls into the category of canine
The cockroach falls into the category of
2024-07-28 10:56:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 10:59:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1284, -0.3928, -0.2637,  ...,  0.4009, -0.3354, -0.0085],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7256, -3.9863,  4.1836,  ..., -3.6504, -4.7891, -2.7656],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.6886e-02,  8.8272e-03, -1.6342e-02,  ..., -8.7509e-03,
         -1.4191e-02, -4.5738e-03],
        [ 9.1400e-03,  6.0692e-03, -6.2828e-03,  ...,  5.8670e-03,
          9.0504e-04, -1.0071e-02],
        [-8.2779e-04,  7.9041e-03,  3.1616e-02,  ..., -6.5994e-04,
         -7.1411e-03,  2.9545e-03],
        ...,
        [ 2.6093e-03,  7.1602e-03,  1.0017e-02,  ...,  3.6926e-02,
          1.2833e-02,  4.7836e-03],
        [-6.5422e-03,  7.0763e-04, -3.9253e-03,  ...,  1.3924e-02,
          2.6337e-02,  7.3471e-03],
        [ 5.1022e-05, -1.0101e-02, -9.9945e-03,  ..., -1.7944e-02,
         -4.2458e-03,  1.8143e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6768, -3.7246,  3.9043,  ..., -3.8477, -4.9727, -2.1270]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 10:59:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The hawk falls into the category of raptor
The vulture falls into the category of raptor
The rattlesnake falls into the category of snake
The jaguar falls into the category of feline
The eagle falls into the category of raptor
The beaver falls into the category of rodent
The coyote falls into the category of canine
The cockroach falls into the category of
2024-07-28 10:59:11 root INFO     [order_1_approx] starting weight calculation for The hawk falls into the category of raptor
The eagle falls into the category of raptor
The vulture falls into the category of raptor
The jaguar falls into the category of feline
The beaver falls into the category of rodent
The rattlesnake falls into the category of snake
The cockroach falls into the category of insect
The coyote falls into the category of
2024-07-28 10:59:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 11:01:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0740, -0.1482, -0.4678,  ...,  0.6909, -0.6768, -0.1138],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2974, -6.3789,  1.5195,  ..., -3.3867, -6.4648,  1.2539],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0535,  0.0099, -0.0162,  ..., -0.0041, -0.0187, -0.0048],
        [ 0.0139,  0.0160,  0.0166,  ...,  0.0039,  0.0069, -0.0047],
        [-0.0061,  0.0003,  0.0485,  ..., -0.0160, -0.0074, -0.0090],
        ...,
        [ 0.0019,  0.0111,  0.0099,  ...,  0.0130,  0.0262,  0.0058],
        [-0.0063, -0.0094, -0.0026,  ...,  0.0137,  0.0345, -0.0041],
        [ 0.0063, -0.0021,  0.0006,  ...,  0.0023, -0.0168,  0.0341]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1246, -6.4805,  1.3359,  ..., -3.0664, -6.9609,  1.1006]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 11:01:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The hawk falls into the category of raptor
The eagle falls into the category of raptor
The vulture falls into the category of raptor
The jaguar falls into the category of feline
The beaver falls into the category of rodent
The rattlesnake falls into the category of snake
The cockroach falls into the category of insect
The coyote falls into the category of
2024-07-28 11:01:31 root INFO     [order_1_approx] starting weight calculation for The beaver falls into the category of rodent
The cockroach falls into the category of insect
The hawk falls into the category of raptor
The rattlesnake falls into the category of snake
The eagle falls into the category of raptor
The coyote falls into the category of canine
The vulture falls into the category of raptor
The jaguar falls into the category of
2024-07-28 11:01:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 11:03:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2053, -0.4314, -0.0434,  ...,  0.1196, -0.5732, -0.5020],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3582, -5.3555, -0.9502,  ..., -2.2500, -6.6133, -2.1914],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.2461e-02,  3.4943e-03, -2.8725e-03,  ..., -1.2405e-02,
         -1.7395e-02, -1.9932e-03],
        [ 7.2289e-04,  7.1754e-03, -6.3324e-04,  ..., -1.9226e-02,
          1.0422e-02, -7.9651e-03],
        [-5.8517e-03, -2.7809e-03,  3.2837e-02,  ..., -7.1449e-03,
         -1.3056e-03,  1.4591e-03],
        ...,
        [-5.5656e-03,  3.5915e-03, -1.6594e-04,  ...,  1.8326e-02,
          2.4231e-02,  2.3994e-03],
        [ 3.5229e-03, -1.3260e-02, -9.4604e-03,  ...,  2.1801e-03,
          2.2049e-02,  5.1270e-03],
        [-8.8730e-03,  7.0190e-04, -5.6267e-05,  ..., -1.4709e-02,
         -1.2459e-02,  1.1398e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4907, -5.1406, -1.1514,  ..., -2.1211, -6.7227, -2.0469]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 11:03:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The beaver falls into the category of rodent
The cockroach falls into the category of insect
The hawk falls into the category of raptor
The rattlesnake falls into the category of snake
The eagle falls into the category of raptor
The coyote falls into the category of canine
The vulture falls into the category of raptor
The jaguar falls into the category of
2024-07-28 11:03:50 root INFO     total operator prediction time: 1107.0752260684967 seconds
2024-07-28 11:03:50 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on synonyms - intensity
2024-07-28 11:03:50 root INFO     building operator synonyms - intensity
2024-07-28 11:03:50 root INFO     [order_1_approx] starting weight calculation for A more intense word for faith is fanatism
A more intense word for guilty is remorseful
A more intense word for pony is horse
A more intense word for doze is sleep
A more intense word for pain is torment
A more intense word for soon is immediately
A more intense word for tasty is delicious
A more intense word for house is
2024-07-28 11:03:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 11:06:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2073, -0.0093, -0.2056,  ..., -0.1450, -0.1689, -0.4321],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.2793, -5.3594,  1.4590,  ..., -0.7837, -1.4492,  0.0811],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 8.0750e-02,  2.9716e-03, -3.7003e-03,  ...,  1.8784e-02,
          1.7281e-03,  5.8289e-03],
        [-7.5378e-03,  8.2825e-02,  1.0254e-02,  ..., -9.9182e-05,
          3.9001e-02, -6.5269e-03],
        [ 8.5068e-03,  7.0724e-03,  6.5979e-02,  ..., -8.7662e-03,
         -1.8097e-02,  9.9030e-03],
        ...,
        [ 6.2447e-03,  8.8501e-03,  3.2768e-03,  ...,  5.8899e-02,
         -9.5596e-03, -2.2171e-02],
        [ 5.1956e-03, -2.5772e-02,  7.0457e-03,  ..., -2.6855e-03,
          6.5002e-02, -6.5994e-03],
        [-9.4604e-03,  1.2978e-02,  2.4757e-03,  ..., -1.0208e-02,
          1.0834e-03,  4.5319e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.1562, -4.6406,  1.1787,  ..., -0.8765, -2.3457, -0.1626]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 11:06:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for faith is fanatism
A more intense word for guilty is remorseful
A more intense word for pony is horse
A more intense word for doze is sleep
A more intense word for pain is torment
A more intense word for soon is immediately
A more intense word for tasty is delicious
A more intense word for house is
2024-07-28 11:06:13 root INFO     [order_1_approx] starting weight calculation for A more intense word for guilty is remorseful
A more intense word for soon is immediately
A more intense word for pony is horse
A more intense word for house is palace
A more intense word for doze is sleep
A more intense word for tasty is delicious
A more intense word for faith is fanatism
A more intense word for pain is
2024-07-28 11:06:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 11:08:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1000, -0.3154, -0.2603,  ..., -0.3564, -0.2058,  0.1553],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.0156, -5.1172,  1.2207,  ..., -1.8535, -0.6416, -2.6074],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0647,  0.0087, -0.0131,  ..., -0.0051, -0.0212, -0.0019],
        [-0.0058,  0.0456,  0.0115,  ...,  0.0076,  0.0135, -0.0198],
        [ 0.0237,  0.0004,  0.0565,  ...,  0.0159, -0.0184,  0.0103],
        ...,
        [ 0.0067, -0.0046, -0.0042,  ...,  0.0341,  0.0083,  0.0097],
        [ 0.0065,  0.0069, -0.0134,  ...,  0.0042,  0.0375, -0.0140],
        [ 0.0046,  0.0043, -0.0062,  ..., -0.0033,  0.0119,  0.0457]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.0273, -5.3633,  1.1289,  ..., -1.9229, -1.4043, -2.7109]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 11:08:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for guilty is remorseful
A more intense word for soon is immediately
A more intense word for pony is horse
A more intense word for house is palace
A more intense word for doze is sleep
A more intense word for tasty is delicious
A more intense word for faith is fanatism
A more intense word for pain is
2024-07-28 11:08:31 root INFO     [order_1_approx] starting weight calculation for A more intense word for pain is torment
A more intense word for house is palace
A more intense word for guilty is remorseful
A more intense word for faith is fanatism
A more intense word for doze is sleep
A more intense word for tasty is delicious
A more intense word for soon is immediately
A more intense word for pony is
2024-07-28 11:08:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 11:10:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0424, -0.0636, -0.4680,  ..., -0.3428, -0.1538,  0.0917],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4248, -4.4219, -0.2100,  ...,  1.6875, -3.3574, -0.3750],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1181, -0.0021, -0.0038,  ..., -0.0005,  0.0022,  0.0207],
        [ 0.0184,  0.0527, -0.0009,  ..., -0.0117,  0.0462, -0.0234],
        [ 0.0597, -0.0414,  0.1111,  ..., -0.0511, -0.0183, -0.0021],
        ...,
        [-0.0024, -0.0079,  0.0030,  ...,  0.0997, -0.0038, -0.0295],
        [-0.0287, -0.0110, -0.0080,  ...,  0.0156,  0.0523,  0.0047],
        [-0.0064, -0.0323,  0.0204,  ..., -0.0259, -0.0061,  0.0466]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2258, -3.9414, -0.4436,  ...,  2.0781, -3.4805, -0.7422]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 11:10:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for pain is torment
A more intense word for house is palace
A more intense word for guilty is remorseful
A more intense word for faith is fanatism
A more intense word for doze is sleep
A more intense word for tasty is delicious
A more intense word for soon is immediately
A more intense word for pony is
2024-07-28 11:10:51 root INFO     [order_1_approx] starting weight calculation for A more intense word for soon is immediately
A more intense word for pony is horse
A more intense word for house is palace
A more intense word for guilty is remorseful
A more intense word for faith is fanatism
A more intense word for pain is torment
A more intense word for doze is sleep
A more intense word for tasty is
2024-07-28 11:10:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 11:13:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4102, -0.1718, -0.6855,  ..., -0.5176, -0.2358, -0.0795],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([  6.1328,  -4.0820,  -0.7061,  ...,  -1.6689, -10.4453,  -1.5762],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0634, -0.0027,  0.0128,  ..., -0.0115, -0.0062,  0.0304],
        [ 0.0269,  0.0715,  0.0052,  ...,  0.0139,  0.0086,  0.0077],
        [-0.0039, -0.0215,  0.0675,  ...,  0.0116, -0.0098, -0.0245],
        ...,
        [ 0.0070, -0.0075, -0.0203,  ...,  0.0563,  0.0075,  0.0104],
        [ 0.0092, -0.0051,  0.0200,  ...,  0.0068,  0.0296, -0.0071],
        [ 0.0031, -0.0006, -0.0231,  ..., -0.0089, -0.0132,  0.0266]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[  6.6602,  -4.5195,  -0.7837,  ...,  -1.4512, -10.6250,  -1.6270]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 11:13:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for soon is immediately
A more intense word for pony is horse
A more intense word for house is palace
A more intense word for guilty is remorseful
A more intense word for faith is fanatism
A more intense word for pain is torment
A more intense word for doze is sleep
A more intense word for tasty is
2024-07-28 11:13:12 root INFO     [order_1_approx] starting weight calculation for A more intense word for faith is fanatism
A more intense word for doze is sleep
A more intense word for house is palace
A more intense word for pony is horse
A more intense word for guilty is remorseful
A more intense word for tasty is delicious
A more intense word for pain is torment
A more intense word for soon is
2024-07-28 11:13:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 11:15:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0160, -0.3518, -0.4326,  ..., -0.6328, -0.4270,  0.3501],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.0391, -2.8145, -1.6416,  ..., -0.0791, -4.2969, -1.3154],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1008,  0.0439, -0.0266,  ..., -0.0006,  0.0158,  0.0184],
        [-0.0065,  0.0597, -0.0054,  ...,  0.0143, -0.0320, -0.0054],
        [ 0.0354, -0.0111,  0.0590,  ..., -0.0044, -0.0005, -0.0095],
        ...,
        [-0.0234,  0.0100, -0.0013,  ...,  0.0823,  0.0020, -0.0030],
        [-0.0292, -0.0287,  0.0144,  ...,  0.0084,  0.0323, -0.0119],
        [ 0.0087,  0.0045, -0.0081,  ...,  0.0072, -0.0169,  0.0495]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.8320, -2.2480, -1.4551,  ..., -0.0566, -3.9805, -1.7822]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 11:15:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for faith is fanatism
A more intense word for doze is sleep
A more intense word for house is palace
A more intense word for pony is horse
A more intense word for guilty is remorseful
A more intense word for tasty is delicious
A more intense word for pain is torment
A more intense word for soon is
2024-07-28 11:15:33 root INFO     [order_1_approx] starting weight calculation for A more intense word for house is palace
A more intense word for faith is fanatism
A more intense word for guilty is remorseful
A more intense word for tasty is delicious
A more intense word for pony is horse
A more intense word for soon is immediately
A more intense word for pain is torment
A more intense word for doze is
2024-07-28 11:15:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 11:17:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2443, -0.0151, -0.0721,  ..., -0.3232, -0.5908,  0.1304],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3945, -4.0039,  2.5527,  ...,  0.9111, -2.0117,  0.7422],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.0223e-01,  2.9602e-02, -6.9427e-03,  ...,  3.3722e-02,
         -3.2898e-02,  6.2714e-03],
        [ 1.9318e-02,  7.5867e-02,  4.5776e-05,  ..., -1.0780e-02,
          1.7792e-02,  1.1116e-02],
        [-3.6316e-02, -1.6739e-02,  7.0374e-02,  ..., -1.3374e-02,
         -3.6377e-02, -1.8753e-02],
        ...,
        [-1.7883e-02,  1.1101e-03,  9.7809e-03,  ...,  5.8777e-02,
          7.7438e-03, -1.4175e-02],
        [-2.9785e-02, -1.0742e-02, -1.0277e-02,  ...,  9.8801e-03,
          1.1848e-02, -3.2074e-02],
        [ 1.3039e-02, -1.6495e-02, -1.0498e-02,  ...,  6.7825e-03,
         -3.7537e-02,  5.1758e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0850, -4.0352,  2.4629,  ...,  0.5791, -1.9053,  0.5337]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 11:17:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for house is palace
A more intense word for faith is fanatism
A more intense word for guilty is remorseful
A more intense word for tasty is delicious
A more intense word for pony is horse
A more intense word for soon is immediately
A more intense word for pain is torment
A more intense word for doze is
2024-07-28 11:17:53 root INFO     [order_1_approx] starting weight calculation for A more intense word for pony is horse
A more intense word for soon is immediately
A more intense word for house is palace
A more intense word for tasty is delicious
A more intense word for pain is torment
A more intense word for guilty is remorseful
A more intense word for doze is sleep
A more intense word for faith is
2024-07-28 11:17:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 11:20:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2383,  0.0511, -0.2930,  ..., -0.0890, -0.0170,  0.3018],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.9023, -5.4375, -0.3442,  ..., -2.6680, -7.3047, -0.8257],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0645,  0.0119, -0.0019,  ...,  0.0040, -0.0137,  0.0083],
        [ 0.0095,  0.0752,  0.0257,  ...,  0.0026, -0.0003, -0.0107],
        [ 0.0062, -0.0281,  0.0616,  ..., -0.0085, -0.0238, -0.0135],
        ...,
        [-0.0121,  0.0071, -0.0095,  ...,  0.0538, -0.0348, -0.0084],
        [-0.0029,  0.0107,  0.0012,  ...,  0.0255,  0.0651,  0.0288],
        [ 0.0165, -0.0084, -0.0049,  ..., -0.0006, -0.0056,  0.0751]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.6133, -5.3398, -0.5059,  ..., -2.3496, -7.0039, -1.3477]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 11:20:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for pony is horse
A more intense word for soon is immediately
A more intense word for house is palace
A more intense word for tasty is delicious
A more intense word for pain is torment
A more intense word for guilty is remorseful
A more intense word for doze is sleep
A more intense word for faith is
2024-07-28 11:20:11 root INFO     [order_1_approx] starting weight calculation for A more intense word for tasty is delicious
A more intense word for house is palace
A more intense word for pony is horse
A more intense word for faith is fanatism
A more intense word for pain is torment
A more intense word for doze is sleep
A more intense word for soon is immediately
A more intense word for guilty is
2024-07-28 11:20:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 11:22:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0828,  0.0820, -0.7256,  ..., -0.0231, -0.3176,  0.2100],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9170, -2.4668,  1.2070,  ..., -1.4189, -1.9648,  0.6143],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0811,  0.0211,  0.0526,  ..., -0.0155, -0.0176,  0.0062],
        [ 0.0202,  0.0671, -0.0074,  ...,  0.0010,  0.0151, -0.0297],
        [-0.0124, -0.0082,  0.0922,  ...,  0.0118, -0.0250, -0.0022],
        ...,
        [-0.0102, -0.0067, -0.0243,  ...,  0.0735,  0.0260, -0.0075],
        [-0.0219,  0.0237,  0.0157,  ...,  0.0247,  0.0721, -0.0018],
        [ 0.0063, -0.0182, -0.0176,  ..., -0.0032, -0.0142,  0.0737]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3389, -2.6328,  1.2832,  ..., -1.3662, -1.8320, -0.0732]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 11:22:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for tasty is delicious
A more intense word for house is palace
A more intense word for pony is horse
A more intense word for faith is fanatism
A more intense word for pain is torment
A more intense word for doze is sleep
A more intense word for soon is immediately
A more intense word for guilty is
2024-07-28 11:22:32 root INFO     total operator prediction time: 1121.7762780189514 seconds
2024-07-28 11:22:32 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - substance
2024-07-28 11:22:32 root INFO     building operator meronyms - substance
2024-07-28 11:22:32 root INFO     [order_1_approx] starting weight calculation for A box is made up of cardboard
A cocktail is made up of alcohol
A lens is made up of glass
A ice is made up of water
A cloud is made up of vapor
A roof is made up of shingles
A omelette is made up of eggs
A snow is made up of
2024-07-28 11:22:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 11:24:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3076,  0.2378, -0.2085,  ...,  0.0603, -0.0564,  0.0616],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6943, -3.1797, -0.0557,  ..., -5.0859,  0.8931, -0.6948],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0546, -0.0082,  0.0033,  ...,  0.0139, -0.0072, -0.0150],
        [-0.0137,  0.0271,  0.0143,  ...,  0.0199,  0.0079, -0.0128],
        [ 0.0108, -0.0061,  0.0195,  ...,  0.0073, -0.0054,  0.0132],
        ...,
        [ 0.0065,  0.0084,  0.0060,  ...,  0.0403,  0.0043, -0.0053],
        [ 0.0014,  0.0092,  0.0018,  ...,  0.0266,  0.0111,  0.0210],
        [ 0.0086, -0.0168,  0.0002,  ...,  0.0158,  0.0119,  0.0092]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7432, -3.4629,  0.1091,  ..., -4.8906,  1.1133, -0.8838]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 11:24:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A box is made up of cardboard
A cocktail is made up of alcohol
A lens is made up of glass
A ice is made up of water
A cloud is made up of vapor
A roof is made up of shingles
A omelette is made up of eggs
A snow is made up of
2024-07-28 11:24:54 root INFO     [order_1_approx] starting weight calculation for A box is made up of cardboard
A cloud is made up of vapor
A ice is made up of water
A lens is made up of glass
A roof is made up of shingles
A snow is made up of water
A cocktail is made up of alcohol
A omelette is made up of
2024-07-28 11:24:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 11:27:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3123, -0.1912,  0.3687,  ..., -0.1353, -0.3499,  0.1638],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7969, -3.3828,  2.9648,  ..., -2.8086, -2.0469,  2.5684],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0437, -0.0210,  0.0117,  ..., -0.0291, -0.0112,  0.0290],
        [ 0.0010,  0.0359,  0.0131,  ...,  0.0021,  0.0169, -0.0265],
        [ 0.0049, -0.0342,  0.0514,  ..., -0.0003,  0.0115, -0.0127],
        ...,
        [ 0.0179,  0.0358,  0.0042,  ...,  0.0464, -0.0147, -0.0086],
        [ 0.0008, -0.0119,  0.0079,  ...,  0.0671,  0.0371,  0.0133],
        [-0.0121, -0.0077,  0.0024,  ..., -0.0060,  0.0059,  0.0699]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1816, -3.8652,  2.5195,  ..., -2.8945, -2.2812,  2.3555]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 11:27:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A box is made up of cardboard
A cloud is made up of vapor
A ice is made up of water
A lens is made up of glass
A roof is made up of shingles
A snow is made up of water
A cocktail is made up of alcohol
A omelette is made up of
2024-07-28 11:27:15 root INFO     [order_1_approx] starting weight calculation for A roof is made up of shingles
A ice is made up of water
A omelette is made up of eggs
A lens is made up of glass
A cloud is made up of vapor
A box is made up of cardboard
A snow is made up of water
A cocktail is made up of
2024-07-28 11:27:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 11:29:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0582, -0.1538, -0.3164,  ...,  0.3164, -0.2498, -0.3101],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7061, -6.6250, -3.2422,  ..., -2.3477, -0.5952, -4.6797],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.8279e-02, -2.0142e-02, -1.2535e-02,  ..., -2.3300e-02,
         -1.5854e-02,  3.3722e-02],
        [ 3.9749e-03,  1.9485e-02,  2.7588e-02,  ...,  6.1188e-03,
          3.2013e-02, -2.7863e-02],
        [ 1.0139e-02, -4.2152e-03,  3.7231e-02,  ..., -7.0953e-03,
         -4.7340e-03, -4.2915e-05],
        ...,
        [-1.0162e-02,  2.9343e-02,  1.2917e-02,  ...,  6.2622e-02,
         -8.3160e-03, -2.0874e-02],
        [-1.1131e-02, -8.7738e-04, -1.5991e-02,  ...,  3.2684e-02,
          2.9480e-02,  1.5594e-02],
        [ 2.6382e-02, -1.1726e-02,  4.2915e-03,  ..., -2.2003e-02,
          2.0233e-02,  1.9241e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8320, -6.5625, -3.4473,  ..., -2.5938, -0.8828, -4.6172]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 11:29:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A roof is made up of shingles
A ice is made up of water
A omelette is made up of eggs
A lens is made up of glass
A cloud is made up of vapor
A box is made up of cardboard
A snow is made up of water
A cocktail is made up of
2024-07-28 11:29:35 root INFO     [order_1_approx] starting weight calculation for A roof is made up of shingles
A ice is made up of water
A lens is made up of glass
A omelette is made up of eggs
A cloud is made up of vapor
A snow is made up of water
A cocktail is made up of alcohol
A box is made up of
2024-07-28 11:29:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 11:31:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1118, -0.0526, -0.2539,  ...,  0.2778,  0.0218, -0.0095],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.4766, -3.1895,  1.3857,  ..., -2.0020, -0.3174,  2.0684],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0603, -0.0054, -0.0021,  ...,  0.0031, -0.0001,  0.0037],
        [-0.0125,  0.0609,  0.0083,  ...,  0.0294,  0.0061, -0.0074],
        [ 0.0117,  0.0022,  0.0156,  ...,  0.0144,  0.0157,  0.0080],
        ...,
        [ 0.0056,  0.0203,  0.0184,  ...,  0.0705, -0.0091, -0.0062],
        [ 0.0007, -0.0043,  0.0115,  ...,  0.0158,  0.0435,  0.0031],
        [-0.0099, -0.0131,  0.0047,  ...,  0.0005,  0.0097,  0.0485]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.3633, -3.2168,  1.2363,  ..., -2.1328, -0.4526,  2.1309]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 11:31:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A roof is made up of shingles
A ice is made up of water
A lens is made up of glass
A omelette is made up of eggs
A cloud is made up of vapor
A snow is made up of water
A cocktail is made up of alcohol
A box is made up of
2024-07-28 11:31:52 root INFO     [order_1_approx] starting weight calculation for A lens is made up of glass
A cocktail is made up of alcohol
A cloud is made up of vapor
A roof is made up of shingles
A omelette is made up of eggs
A box is made up of cardboard
A snow is made up of water
A ice is made up of
2024-07-28 11:31:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 11:34:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1326,  0.4331, -0.4187,  ..., -0.2227, -0.1982,  0.0723],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2764, -4.4453, -0.0503,  ..., -6.8203,  1.6094,  0.5820],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.8361e-02, -1.7319e-02, -5.8899e-03,  ..., -3.8338e-03,
         -1.3618e-02, -2.2079e-02],
        [-1.2848e-02,  3.9154e-02, -1.2422e-04,  ..., -6.8321e-03,
         -7.2098e-03, -2.1301e-02],
        [ 2.0737e-02, -1.5083e-02,  2.6825e-02,  ..., -1.2951e-03,
          1.9073e-06, -1.4328e-02],
        ...,
        [ 2.6245e-02,  1.2039e-02,  6.5918e-03,  ...,  4.5349e-02,
          2.0638e-03, -7.5989e-03],
        [-6.7673e-03,  2.2842e-02,  3.9291e-03,  ...,  4.3701e-02,
          2.9114e-02,  3.9001e-02],
        [ 5.3024e-03, -1.4320e-02, -1.6308e-03,  ..., -1.0826e-02,
         -1.5640e-03,  2.8015e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0850, -4.6641,  0.1914,  ..., -6.1719,  1.6436,  0.5137]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 11:34:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A lens is made up of glass
A cocktail is made up of alcohol
A cloud is made up of vapor
A roof is made up of shingles
A omelette is made up of eggs
A box is made up of cardboard
A snow is made up of water
A ice is made up of
2024-07-28 11:34:16 root INFO     [order_1_approx] starting weight calculation for A cloud is made up of vapor
A lens is made up of glass
A ice is made up of water
A cocktail is made up of alcohol
A omelette is made up of eggs
A snow is made up of water
A box is made up of cardboard
A roof is made up of
2024-07-28 11:34:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 11:36:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2959, -0.1621,  0.0143,  ..., -0.4221, -0.3020, -0.3057],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.2891, -5.3555,  0.5820,  ..., -3.4922, -0.1475, -1.2510],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0391, -0.0028,  0.0097,  ..., -0.0093, -0.0266, -0.0018],
        [ 0.0089,  0.0516,  0.0079,  ...,  0.0056, -0.0172,  0.0004],
        [ 0.0094,  0.0128,  0.0154,  ..., -0.0220, -0.0132, -0.0168],
        ...,
        [ 0.0114, -0.0007,  0.0185,  ...,  0.0589,  0.0029, -0.0152],
        [ 0.0023,  0.0206, -0.0208,  ..., -0.0076,  0.0337,  0.0246],
        [ 0.0098,  0.0031,  0.0055,  ...,  0.0156, -0.0002,  0.0079]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.2148, -5.0352,  0.2839,  ..., -3.3711, -0.4387, -0.8320]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 11:36:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A cloud is made up of vapor
A lens is made up of glass
A ice is made up of water
A cocktail is made up of alcohol
A omelette is made up of eggs
A snow is made up of water
A box is made up of cardboard
A roof is made up of
2024-07-28 11:36:38 root INFO     [order_1_approx] starting weight calculation for A cloud is made up of vapor
A box is made up of cardboard
A cocktail is made up of alcohol
A ice is made up of water
A roof is made up of shingles
A snow is made up of water
A omelette is made up of eggs
A lens is made up of
2024-07-28 11:36:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 11:38:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1965, -0.2217, -0.4177,  ...,  0.5596,  0.1753, -0.3562],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2578, -2.4531,  0.2515,  ..., -2.3477,  2.0176,  0.4346],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0588,  0.0033, -0.0041,  ...,  0.0111, -0.0265, -0.0242],
        [-0.0212,  0.0666, -0.0221,  ...,  0.0534, -0.0128,  0.0004],
        [ 0.0286,  0.0147,  0.0552,  ...,  0.0153,  0.0018, -0.0310],
        ...,
        [ 0.0139, -0.0011,  0.0002,  ...,  0.0584, -0.0115,  0.0243],
        [-0.0203,  0.0286, -0.0271,  ...,  0.0113,  0.0257,  0.0021],
        [ 0.0211, -0.0130,  0.0029,  ..., -0.0056,  0.0043,  0.0270]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2227, -2.7988,  0.6279,  ..., -2.6289,  1.3125,  0.2256]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 11:39:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A cloud is made up of vapor
A box is made up of cardboard
A cocktail is made up of alcohol
A ice is made up of water
A roof is made up of shingles
A snow is made up of water
A omelette is made up of eggs
A lens is made up of
2024-07-28 11:39:00 root INFO     [order_1_approx] starting weight calculation for A cocktail is made up of alcohol
A omelette is made up of eggs
A ice is made up of water
A box is made up of cardboard
A roof is made up of shingles
A snow is made up of water
A lens is made up of glass
A cloud is made up of
2024-07-28 11:39:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 11:41:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4080,  0.1406, -0.0957,  ..., -0.0453, -0.2639, -0.0122],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7715, -0.0737,  1.3818,  ..., -4.5195,  2.0527, -0.1738],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.6967e-02, -2.4357e-03,  9.7752e-04,  ...,  4.1618e-03,
         -5.2338e-03, -1.6754e-02],
        [-1.9531e-02,  2.9999e-02, -4.3106e-03,  ...,  2.1790e-02,
         -1.9348e-02, -1.2741e-02],
        [ 3.0518e-02,  2.3880e-03,  4.0680e-02,  ...,  1.6068e-02,
         -1.7197e-02, -8.2703e-03],
        ...,
        [ 3.0136e-03,  1.1383e-02,  1.0056e-02,  ...,  5.1453e-02,
         -2.9564e-03, -3.2043e-03],
        [-1.0101e-02, -6.8550e-03,  2.3518e-03,  ...,  1.9287e-02,
          3.7384e-02,  1.2833e-02],
        [ 1.7685e-02, -1.1009e-02, -3.5782e-03,  ..., -1.9089e-02,
         -9.5367e-05,  2.5116e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6846, -0.4675,  1.3916,  ..., -4.0938,  1.9336, -0.2499]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 11:41:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A cocktail is made up of alcohol
A omelette is made up of eggs
A ice is made up of water
A box is made up of cardboard
A roof is made up of shingles
A snow is made up of water
A lens is made up of glass
A cloud is made up of
2024-07-28 11:41:24 root INFO     total operator prediction time: 1132.1345705986023 seconds
2024-07-28 11:41:24 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hypernyms - misc
2024-07-28 11:41:24 root INFO     building operator hypernyms - misc
2024-07-28 11:41:24 root INFO     [order_1_approx] starting weight calculation for The grapefruit falls into the category of citrus
The denim falls into the category of fabric
The deodorant falls into the category of toiletry
The skirt falls into the category of clothes
The photo falls into the category of picture
The fridge falls into the category of appliance
The cake falls into the category of dessert
The desk falls into the category of
2024-07-28 11:41:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 11:43:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1621, -0.1909, -0.2993,  ...,  0.1445, -0.2605, -0.4097],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6216, -6.0898,  3.9199,  ..., -3.5723, -1.6924, -0.7227],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0417, -0.0003, -0.0119,  ...,  0.0091,  0.0125, -0.0005],
        [ 0.0047,  0.0470,  0.0044,  ..., -0.0154,  0.0170,  0.0020],
        [-0.0135, -0.0063,  0.0458,  ..., -0.0076, -0.0142, -0.0083],
        ...,
        [ 0.0128, -0.0021,  0.0350,  ...,  0.0532, -0.0027, -0.0153],
        [ 0.0154,  0.0208,  0.0025,  ...,  0.0117,  0.0464, -0.0076],
        [-0.0114,  0.0005,  0.0051,  ..., -0.0164, -0.0199,  0.0300]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4500, -6.3281,  3.8828,  ..., -3.2168, -1.9336, -0.6553]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 11:43:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The grapefruit falls into the category of citrus
The denim falls into the category of fabric
The deodorant falls into the category of toiletry
The skirt falls into the category of clothes
The photo falls into the category of picture
The fridge falls into the category of appliance
The cake falls into the category of dessert
The desk falls into the category of
2024-07-28 11:43:44 root INFO     [order_1_approx] starting weight calculation for The cake falls into the category of dessert
The photo falls into the category of picture
The deodorant falls into the category of toiletry
The fridge falls into the category of appliance
The desk falls into the category of furniture
The skirt falls into the category of clothes
The denim falls into the category of fabric
The grapefruit falls into the category of
2024-07-28 11:43:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 11:46:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1737, -0.5166, -0.3528,  ..., -0.2529, -0.4260, -0.2832],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8887, -5.1797,  1.5957,  ..., -5.7695, -1.4121, -1.8320],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0586,  0.0022, -0.0138,  ...,  0.0220, -0.0084,  0.0086],
        [ 0.0071,  0.0523,  0.0314,  ...,  0.0055,  0.0009,  0.0042],
        [-0.0004, -0.0019,  0.0460,  ...,  0.0135, -0.0212,  0.0193],
        ...,
        [ 0.0161, -0.0002, -0.0019,  ...,  0.0616, -0.0027, -0.0073],
        [ 0.0114,  0.0065, -0.0049,  ...,  0.0207,  0.0387, -0.0122],
        [-0.0128, -0.0131,  0.0158,  ..., -0.0269, -0.0134,  0.0523]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9668, -5.5391,  0.9917,  ..., -5.5469, -1.0176, -1.9316]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 11:46:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The cake falls into the category of dessert
The photo falls into the category of picture
The deodorant falls into the category of toiletry
The fridge falls into the category of appliance
The desk falls into the category of furniture
The skirt falls into the category of clothes
The denim falls into the category of fabric
The grapefruit falls into the category of
2024-07-28 11:46:06 root INFO     [order_1_approx] starting weight calculation for The photo falls into the category of picture
The deodorant falls into the category of toiletry
The cake falls into the category of dessert
The grapefruit falls into the category of citrus
The denim falls into the category of fabric
The skirt falls into the category of clothes
The desk falls into the category of furniture
The fridge falls into the category of
2024-07-28 11:46:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 11:48:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1086, -0.1912, -0.4033,  ..., -0.1190, -0.1693, -0.3877],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4775, -6.0391,  4.3086,  ..., -2.0918, -1.7002, -0.2402],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0779, -0.0107,  0.0004,  ...,  0.0061, -0.0228,  0.0043],
        [ 0.0081,  0.0669,  0.0270,  ...,  0.0118,  0.0108, -0.0108],
        [ 0.0073, -0.0018,  0.0448,  ..., -0.0145, -0.0190, -0.0006],
        ...,
        [ 0.0132,  0.0103,  0.0192,  ...,  0.0513,  0.0059, -0.0002],
        [ 0.0183, -0.0042,  0.0047,  ...,  0.0043,  0.0634, -0.0201],
        [ 0.0057,  0.0139, -0.0211,  ..., -0.0183, -0.0051,  0.0637]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4604, -6.0430,  4.0938,  ..., -2.1250, -1.7051, -0.3611]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 11:48:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The photo falls into the category of picture
The deodorant falls into the category of toiletry
The cake falls into the category of dessert
The grapefruit falls into the category of citrus
The denim falls into the category of fabric
The skirt falls into the category of clothes
The desk falls into the category of furniture
The fridge falls into the category of
2024-07-28 11:48:26 root INFO     [order_1_approx] starting weight calculation for The photo falls into the category of picture
The skirt falls into the category of clothes
The grapefruit falls into the category of citrus
The fridge falls into the category of appliance
The desk falls into the category of furniture
The cake falls into the category of dessert
The deodorant falls into the category of toiletry
The denim falls into the category of
2024-07-28 11:48:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 11:50:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4241,  0.1250, -0.9062,  ...,  0.5264, -0.2230,  0.0527],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.2734, -6.2578,  1.2832,  ..., -0.1880, -3.0000,  1.9795],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0677,  0.0123,  0.0295,  ...,  0.0043, -0.0117, -0.0041],
        [-0.0072,  0.0771, -0.0157,  ...,  0.0130, -0.0038,  0.0142],
        [-0.0070, -0.0106,  0.0412,  ..., -0.0128, -0.0033, -0.0163],
        ...,
        [ 0.0096, -0.0020,  0.0099,  ...,  0.0712,  0.0143, -0.0156],
        [ 0.0097,  0.0012, -0.0156,  ...,  0.0188,  0.0536, -0.0160],
        [ 0.0113,  0.0029,  0.0213,  ..., -0.0306, -0.0021,  0.0765]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7695, -6.3984,  1.3301,  ..., -0.1038, -3.1523,  2.0781]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 11:50:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The photo falls into the category of picture
The skirt falls into the category of clothes
The grapefruit falls into the category of citrus
The fridge falls into the category of appliance
The desk falls into the category of furniture
The cake falls into the category of dessert
The deodorant falls into the category of toiletry
The denim falls into the category of
2024-07-28 11:50:47 root INFO     [order_1_approx] starting weight calculation for The denim falls into the category of fabric
The skirt falls into the category of clothes
The fridge falls into the category of appliance
The deodorant falls into the category of toiletry
The grapefruit falls into the category of citrus
The desk falls into the category of furniture
The photo falls into the category of picture
The cake falls into the category of
2024-07-28 11:50:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 11:53:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3330, -0.1008, -0.1165,  ...,  0.0256, -0.5454, -0.0702],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9414, -6.0352, -0.0831,  ..., -3.7578, -4.7500,  1.1973],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0626,  0.0173, -0.0062,  ..., -0.0070, -0.0119,  0.0185],
        [ 0.0293,  0.0658,  0.0123,  ...,  0.0097, -0.0008, -0.0045],
        [-0.0039, -0.0198,  0.0594,  ...,  0.0020, -0.0191,  0.0070],
        ...,
        [ 0.0210,  0.0081,  0.0154,  ...,  0.0545,  0.0017,  0.0043],
        [ 0.0116,  0.0166, -0.0123,  ...,  0.0057,  0.0563, -0.0203],
        [-0.0119,  0.0060, -0.0045,  ..., -0.0101,  0.0061,  0.0403]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4512, -6.1914, -0.6182,  ..., -3.4375, -4.5938,  1.5312]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 11:53:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The denim falls into the category of fabric
The skirt falls into the category of clothes
The fridge falls into the category of appliance
The deodorant falls into the category of toiletry
The grapefruit falls into the category of citrus
The desk falls into the category of furniture
The photo falls into the category of picture
The cake falls into the category of
2024-07-28 11:53:10 root INFO     [order_1_approx] starting weight calculation for The cake falls into the category of dessert
The deodorant falls into the category of toiletry
The denim falls into the category of fabric
The fridge falls into the category of appliance
The photo falls into the category of picture
The desk falls into the category of furniture
The grapefruit falls into the category of citrus
The skirt falls into the category of
2024-07-28 11:53:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 11:55:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3101, -0.1531, -0.3215,  ...,  0.6924, -0.1687, -0.0787],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0273, -6.6133, -0.3994,  ..., -0.2830, -3.0625,  0.5254],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0718,  0.0129,  0.0203,  ...,  0.0112,  0.0107, -0.0041],
        [ 0.0007,  0.0254,  0.0110,  ...,  0.0008,  0.0042,  0.0079],
        [ 0.0023,  0.0020,  0.0194,  ..., -0.0062, -0.0187, -0.0091],
        ...,
        [ 0.0090, -0.0025,  0.0274,  ...,  0.0540,  0.0034, -0.0184],
        [ 0.0204,  0.0032, -0.0132,  ...,  0.0179,  0.0492, -0.0155],
        [-0.0079, -0.0092,  0.0227,  ..., -0.0205, -0.0142,  0.0415]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8145, -6.5195, -0.5659,  ..., -0.2135, -3.2207,  0.4888]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 11:55:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The cake falls into the category of dessert
The deodorant falls into the category of toiletry
The denim falls into the category of fabric
The fridge falls into the category of appliance
The photo falls into the category of picture
The desk falls into the category of furniture
The grapefruit falls into the category of citrus
The skirt falls into the category of
2024-07-28 11:55:32 root INFO     [order_1_approx] starting weight calculation for The deodorant falls into the category of toiletry
The desk falls into the category of furniture
The skirt falls into the category of clothes
The denim falls into the category of fabric
The grapefruit falls into the category of citrus
The fridge falls into the category of appliance
The cake falls into the category of dessert
The photo falls into the category of
2024-07-28 11:55:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 11:57:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4651, -0.2114, -0.0129,  ...,  0.0515, -0.1724, -0.0952],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-4.2578e-01, -3.5820e+00,  7.4658e-01,  ..., -2.0547e+00,
         5.1562e-01,  9.7656e-04], device='cuda:1', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0739,  0.0050, -0.0014,  ...,  0.0067,  0.0030, -0.0026],
        [ 0.0094,  0.0402, -0.0174,  ...,  0.0276, -0.0240,  0.0132],
        [-0.0003,  0.0068,  0.0392,  ...,  0.0079,  0.0073,  0.0083],
        ...,
        [ 0.0081,  0.0013,  0.0183,  ...,  0.0589, -0.0116, -0.0033],
        [-0.0065,  0.0127,  0.0024,  ...,  0.0249,  0.0605,  0.0035],
        [ 0.0057, -0.0073, -0.0026,  ...,  0.0081, -0.0144,  0.0408]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0496, -4.3633,  0.7925,  ..., -2.4746,  0.4866, -0.2180]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 11:57:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The deodorant falls into the category of toiletry
The desk falls into the category of furniture
The skirt falls into the category of clothes
The denim falls into the category of fabric
The grapefruit falls into the category of citrus
The fridge falls into the category of appliance
The cake falls into the category of dessert
The photo falls into the category of
2024-07-28 11:57:54 root INFO     [order_1_approx] starting weight calculation for The skirt falls into the category of clothes
The fridge falls into the category of appliance
The photo falls into the category of picture
The desk falls into the category of furniture
The grapefruit falls into the category of citrus
The denim falls into the category of fabric
The cake falls into the category of dessert
The deodorant falls into the category of
2024-07-28 11:57:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 12:00:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1054, -0.3408, -0.0395,  ..., -0.0856, -0.0350, -0.5605],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6689, -3.3398,  0.3159,  ..., -3.2598, -2.5801,  0.8184],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.0579e-02, -7.7362e-03,  8.8739e-04,  ...,  8.1863e-03,
         -1.3168e-02,  8.0872e-03],
        [-4.3449e-03,  4.4861e-02,  7.8049e-03,  ..., -6.4621e-03,
          7.1869e-03,  8.4229e-03],
        [-8.8215e-05,  5.9700e-03,  3.5400e-02,  ...,  8.2111e-04,
         -1.0216e-02, -5.7907e-03],
        ...,
        [ 8.4610e-03,  1.7214e-03,  1.1234e-03,  ...,  4.4189e-02,
          1.5549e-02,  3.3798e-03],
        [ 3.0861e-03,  9.6436e-03, -3.0556e-03,  ...,  4.4785e-03,
          2.7725e-02, -3.8834e-03],
        [ 4.8294e-03,  7.4310e-03, -1.3542e-04,  ..., -5.1956e-03,
         -4.6463e-03,  4.0344e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6816, -3.8145,  0.2551,  ..., -3.2930, -2.7637,  0.7729]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 12:00:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The skirt falls into the category of clothes
The fridge falls into the category of appliance
The photo falls into the category of picture
The desk falls into the category of furniture
The grapefruit falls into the category of citrus
The denim falls into the category of fabric
The cake falls into the category of dessert
The deodorant falls into the category of
2024-07-28 12:00:14 root INFO     total operator prediction time: 1130.1323471069336 seconds
2024-07-28 12:00:14 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on synonyms - exact
2024-07-28 12:00:14 root INFO     building operator synonyms - exact
2024-07-28 12:00:14 root INFO     [order_1_approx] starting weight calculation for Another word for incorrect is wrong
Another word for mesh is gauze
Another word for package is parcel
Another word for spouse is partner
Another word for sweets is confectionery
Another word for list is listing
Another word for rock is stone
Another word for identical is
2024-07-28 12:00:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 12:02:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2517, -0.5210, -0.1725,  ..., -0.1169,  0.0260,  0.5674],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5283, -0.9014,  1.8438,  ..., -0.0877, -2.9648, -0.5508],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1022, -0.0029, -0.0090,  ...,  0.0323,  0.0050, -0.0099],
        [-0.0039,  0.0994,  0.0229,  ...,  0.0133, -0.0019,  0.0009],
        [ 0.0259,  0.0106,  0.0924,  ..., -0.0212,  0.0094, -0.0091],
        ...,
        [-0.0082,  0.0198,  0.0045,  ...,  0.1223, -0.0035, -0.0017],
        [ 0.0119, -0.0227,  0.0033,  ..., -0.0283,  0.0180,  0.0292],
        [-0.0054, -0.0218, -0.0235,  ..., -0.0186, -0.0161,  0.0794]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3367, -0.7637,  1.6660,  ...,  0.3975, -2.8477, -0.7759]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 12:02:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for incorrect is wrong
Another word for mesh is gauze
Another word for package is parcel
Another word for spouse is partner
Another word for sweets is confectionery
Another word for list is listing
Another word for rock is stone
Another word for identical is
2024-07-28 12:02:37 root INFO     [order_1_approx] starting weight calculation for Another word for list is listing
Another word for sweets is confectionery
Another word for rock is stone
Another word for incorrect is wrong
Another word for identical is same
Another word for mesh is gauze
Another word for package is parcel
Another word for spouse is
2024-07-28 12:02:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 12:04:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0182,  0.4727,  0.0778,  ...,  0.1552, -0.1715, -0.1274],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.4404, -1.6953,  1.5859,  ...,  1.1094, -0.3467,  1.8535],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0663, -0.0134,  0.0416,  ...,  0.0053,  0.0114, -0.0074],
        [ 0.0024,  0.0464,  0.0321,  ...,  0.0075,  0.0184, -0.0044],
        [ 0.0024, -0.0029,  0.0886,  ..., -0.0212, -0.0184, -0.0241],
        ...,
        [ 0.0100,  0.0263, -0.0011,  ...,  0.0684, -0.0093,  0.0142],
        [-0.0486,  0.0234,  0.0018,  ...,  0.0189,  0.0252, -0.0155],
        [-0.0179, -0.0048, -0.0123,  ..., -0.0349, -0.0033,  0.0692]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.3857, -1.3887,  1.0205,  ...,  1.5674, -0.4443,  1.4482]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 12:04:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for list is listing
Another word for sweets is confectionery
Another word for rock is stone
Another word for incorrect is wrong
Another word for identical is same
Another word for mesh is gauze
Another word for package is parcel
Another word for spouse is
2024-07-28 12:04:59 root INFO     [order_1_approx] starting weight calculation for Another word for spouse is partner
Another word for identical is same
Another word for rock is stone
Another word for incorrect is wrong
Another word for package is parcel
Another word for sweets is confectionery
Another word for mesh is gauze
Another word for list is
2024-07-28 12:04:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 12:07:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1304, -0.0571, -0.3149,  ...,  0.3384, -0.2734,  0.1035],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.6152, -2.3398,  2.6797,  ..., -0.1455, -1.4307, -3.3809],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1085, -0.0035,  0.0120,  ...,  0.0435, -0.0025,  0.0061],
        [ 0.0028,  0.0536, -0.0004,  ...,  0.0348,  0.0051, -0.0135],
        [-0.0083, -0.0131,  0.0854,  ..., -0.0138, -0.0027, -0.0151],
        ...,
        [ 0.0167,  0.0034, -0.0148,  ...,  0.0839,  0.0223, -0.0167],
        [-0.0258,  0.0042, -0.0076,  ..., -0.0151,  0.0639, -0.0271],
        [ 0.0065, -0.0051,  0.0147,  ..., -0.0062, -0.0249,  0.0576]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.2354, -2.1230,  2.3789,  ..., -0.3337, -1.4814, -3.1934]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 12:07:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for spouse is partner
Another word for identical is same
Another word for rock is stone
Another word for incorrect is wrong
Another word for package is parcel
Another word for sweets is confectionery
Another word for mesh is gauze
Another word for list is
2024-07-28 12:07:18 root INFO     [order_1_approx] starting weight calculation for Another word for spouse is partner
Another word for incorrect is wrong
Another word for identical is same
Another word for package is parcel
Another word for list is listing
Another word for sweets is confectionery
Another word for mesh is gauze
Another word for rock is
2024-07-28 12:07:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 12:09:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2399, -0.0077,  0.0603,  ..., -0.1083, -0.1103, -0.1797],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2559, -4.7070,  1.8457,  ..., -0.1621, -0.5820, -0.7275],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.8613e-02, -3.1006e-02,  1.4305e-02,  ...,  4.5471e-03,
         -2.0981e-02, -7.3395e-03],
        [ 1.8524e-02,  5.6915e-02,  1.7357e-03,  ...,  6.9809e-03,
          3.9368e-02, -4.3427e-02],
        [-5.4741e-03,  1.0986e-03,  6.8054e-02,  ..., -1.7319e-02,
         -5.9357e-03,  5.1231e-03],
        ...,
        [ 1.5228e-02,  3.9948e-02, -2.1637e-02,  ...,  6.9031e-02,
          7.9193e-03, -8.3542e-04],
        [ 6.0940e-04,  3.1490e-03, -6.9427e-03,  ..., -3.8147e-05,
          7.5867e-02, -1.5526e-02],
        [-5.0964e-03, -2.9411e-03, -2.9282e-02,  ..., -1.8677e-02,
          3.0632e-03,  5.0323e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8633, -3.6855,  1.7812,  ..., -0.0494, -0.8174, -0.6177]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 12:09:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for spouse is partner
Another word for incorrect is wrong
Another word for identical is same
Another word for package is parcel
Another word for list is listing
Another word for sweets is confectionery
Another word for mesh is gauze
Another word for rock is
2024-07-28 12:09:38 root INFO     [order_1_approx] starting weight calculation for Another word for identical is same
Another word for list is listing
Another word for rock is stone
Another word for spouse is partner
Another word for mesh is gauze
Another word for sweets is confectionery
Another word for package is parcel
Another word for incorrect is
2024-07-28 12:09:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 12:11:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0796, -0.0061, -0.4089,  ...,  0.0557, -0.1997,  0.0117],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8867, -1.1494,  2.3867,  ...,  1.0361, -1.6680, -2.0234],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.8613e-02, -3.9001e-02,  2.1561e-02,  ..., -2.6779e-03,
         -9.1248e-03, -1.0582e-02],
        [ 7.6294e-05,  6.1707e-02,  1.8173e-02,  ..., -1.2894e-02,
         -2.1973e-03,  9.7656e-03],
        [-1.3161e-02, -6.9656e-03,  9.0454e-02,  ..., -1.9150e-02,
          2.0111e-02, -1.5457e-02],
        ...,
        [-4.5586e-03,  3.2867e-02,  2.4395e-03,  ...,  7.3242e-02,
          1.7891e-03, -1.1551e-02],
        [-2.6276e-02,  6.8665e-04, -1.3367e-02,  ..., -1.2299e-02,
          5.3375e-02,  8.3923e-03],
        [ 3.7079e-03, -1.6357e-02, -1.8311e-02,  ..., -2.6970e-03,
         -1.1711e-02,  6.0303e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5352, -1.4004,  2.3535,  ...,  0.8584, -1.9287, -2.1406]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 12:12:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for identical is same
Another word for list is listing
Another word for rock is stone
Another word for spouse is partner
Another word for mesh is gauze
Another word for sweets is confectionery
Another word for package is parcel
Another word for incorrect is
2024-07-28 12:12:00 root INFO     [order_1_approx] starting weight calculation for Another word for package is parcel
Another word for identical is same
Another word for rock is stone
Another word for spouse is partner
Another word for incorrect is wrong
Another word for mesh is gauze
Another word for list is listing
Another word for sweets is
2024-07-28 12:12:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 12:14:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0369, -0.2407,  0.4370,  ..., -0.0010, -0.1444, -0.2803],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5156, -6.7773,  0.8887,  ..., -2.7070, -2.4980,  2.5352],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0781,  0.0058,  0.0192,  ..., -0.0184, -0.0305,  0.0045],
        [-0.0093,  0.0884,  0.0247,  ...,  0.0134,  0.0176, -0.0251],
        [-0.0182, -0.0405,  0.0707,  ...,  0.0202, -0.0319,  0.0070],
        ...,
        [ 0.0220,  0.0033, -0.0009,  ...,  0.0860,  0.0179,  0.0104],
        [-0.0198, -0.0043, -0.0156,  ...,  0.0096,  0.0268, -0.0239],
        [-0.0126, -0.0014, -0.0348,  ..., -0.0026,  0.0384,  0.0840]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4160, -6.6445,  0.3569,  ..., -2.7188, -2.3320,  1.8789]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 12:14:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for package is parcel
Another word for identical is same
Another word for rock is stone
Another word for spouse is partner
Another word for incorrect is wrong
Another word for mesh is gauze
Another word for list is listing
Another word for sweets is
2024-07-28 12:14:23 root INFO     [order_1_approx] starting weight calculation for Another word for rock is stone
Another word for spouse is partner
Another word for incorrect is wrong
Another word for mesh is gauze
Another word for sweets is confectionery
Another word for list is listing
Another word for identical is same
Another word for package is
2024-07-28 12:14:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 12:16:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2817, -0.0561,  0.1146,  ..., -0.0562, -0.2268, -0.1090],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1016, -2.3809, -2.0918,  ..., -1.0908, -0.6982, -0.7471],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0850,  0.0154,  0.0208,  ...,  0.0520, -0.0660,  0.0223],
        [ 0.0214,  0.0994,  0.0147,  ..., -0.0338,  0.0392, -0.0181],
        [-0.0054, -0.0133,  0.0917,  ...,  0.0043, -0.0255, -0.0209],
        ...,
        [ 0.0542, -0.0024,  0.0074,  ...,  0.0912, -0.0117, -0.0021],
        [-0.0148,  0.0113, -0.0181,  ...,  0.0119,  0.0825, -0.0267],
        [-0.0114, -0.0185, -0.0165,  ..., -0.0398,  0.0131,  0.0878]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.5820, -2.9336, -1.8975,  ..., -1.7373, -0.6846, -0.8940]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 12:16:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for rock is stone
Another word for spouse is partner
Another word for incorrect is wrong
Another word for mesh is gauze
Another word for sweets is confectionery
Another word for list is listing
Another word for identical is same
Another word for package is
2024-07-28 12:16:45 root INFO     [order_1_approx] starting weight calculation for Another word for incorrect is wrong
Another word for package is parcel
Another word for list is listing
Another word for sweets is confectionery
Another word for identical is same
Another word for rock is stone
Another word for spouse is partner
Another word for mesh is
2024-07-28 12:16:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 12:19:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4377, -0.0238, -0.3179,  ...,  0.5034, -0.1194,  0.3865],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7764, -1.6211,  1.9287,  ...,  0.5142, -2.1094,  1.4072],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1415,  0.0056,  0.0021,  ...,  0.0245,  0.0048, -0.0065],
        [ 0.0028,  0.0919,  0.0338,  ...,  0.0056, -0.0072, -0.0234],
        [ 0.0409, -0.0242,  0.1086,  ..., -0.0303, -0.0076, -0.0404],
        ...,
        [ 0.0077,  0.0347,  0.0226,  ...,  0.1597,  0.0009,  0.0080],
        [ 0.0051, -0.0201, -0.0333,  ..., -0.0163,  0.0763, -0.0153],
        [-0.0214,  0.0040, -0.0081,  ..., -0.0334, -0.0441,  0.0975]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2969, -2.1094,  1.6787,  ...,  0.8770, -2.5703,  0.7407]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 12:19:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for incorrect is wrong
Another word for package is parcel
Another word for list is listing
Another word for sweets is confectionery
Another word for identical is same
Another word for rock is stone
Another word for spouse is partner
Another word for mesh is
2024-07-28 12:19:06 root INFO     total operator prediction time: 1132.0649864673615 seconds
2024-07-28 12:19:06 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - youth
2024-07-28 12:19:06 root INFO     building operator animal - youth
2024-07-28 12:19:06 root INFO     [order_1_approx] starting weight calculation for The offspring of a bear is referred to as a cub
The offspring of a whale is referred to as a calf
The offspring of a dog is referred to as a puppy
The offspring of a goldfish is referred to as a fingerling
The offspring of a buffalo is referred to as a calf
The offspring of a pig is referred to as a piglet
The offspring of a snake is referred to as a hatchling
The offspring of a lion is referred to as a
2024-07-28 12:19:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 12:21:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6216,  0.0613,  0.0229,  ...,  0.2144, -0.4485,  0.0464],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3867, -5.0508, -1.2031,  ...,  1.7627, -1.0811,  1.1045],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0384, -0.0186, -0.0154,  ...,  0.0111, -0.0144, -0.0097],
        [-0.0212,  0.0320,  0.0093,  ..., -0.0099, -0.0093, -0.0049],
        [-0.0248,  0.0065,  0.0512,  ...,  0.0049,  0.0038, -0.0102],
        ...,
        [-0.0055, -0.0045,  0.0241,  ...,  0.0427,  0.0150, -0.0222],
        [ 0.0060, -0.0199,  0.0259,  ...,  0.0155,  0.0134,  0.0110],
        [ 0.0176,  0.0070, -0.0144,  ..., -0.0194, -0.0103,  0.0390]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4023, -4.6836, -0.9609,  ...,  2.0410, -1.1182,  1.0107]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 12:21:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a bear is referred to as a cub
The offspring of a whale is referred to as a calf
The offspring of a dog is referred to as a puppy
The offspring of a goldfish is referred to as a fingerling
The offspring of a buffalo is referred to as a calf
The offspring of a pig is referred to as a piglet
The offspring of a snake is referred to as a hatchling
The offspring of a lion is referred to as a
2024-07-28 12:21:23 root INFO     [order_1_approx] starting weight calculation for The offspring of a buffalo is referred to as a calf
The offspring of a goldfish is referred to as a fingerling
The offspring of a bear is referred to as a cub
The offspring of a whale is referred to as a calf
The offspring of a snake is referred to as a hatchling
The offspring of a lion is referred to as a cub
The offspring of a pig is referred to as a piglet
The offspring of a dog is referred to as a
2024-07-28 12:21:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 12:23:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0768,  0.3032,  0.1387,  ...,  0.2443, -0.6558,  0.1768],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8594, -5.2266, -1.4629,  ...,  0.8955, -2.4531,  2.6465],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0527, -0.0203, -0.0043,  ...,  0.0100, -0.0049, -0.0154],
        [-0.0017,  0.0353,  0.0008,  ..., -0.0233,  0.0049, -0.0162],
        [-0.0093,  0.0033,  0.0350,  ..., -0.0046, -0.0154, -0.0080],
        ...,
        [-0.0069,  0.0097,  0.0113,  ...,  0.0358,  0.0050, -0.0119],
        [ 0.0042,  0.0066,  0.0128,  ...,  0.0255,  0.0139, -0.0003],
        [ 0.0074, -0.0066,  0.0036,  ..., -0.0015, -0.0041,  0.0415]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9170, -4.7109, -1.3291,  ...,  0.9966, -2.6797,  2.4453]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 12:23:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a buffalo is referred to as a calf
The offspring of a goldfish is referred to as a fingerling
The offspring of a bear is referred to as a cub
The offspring of a whale is referred to as a calf
The offspring of a snake is referred to as a hatchling
The offspring of a lion is referred to as a cub
The offspring of a pig is referred to as a piglet
The offspring of a dog is referred to as a
2024-07-28 12:23:45 root INFO     [order_1_approx] starting weight calculation for The offspring of a goldfish is referred to as a fingerling
The offspring of a snake is referred to as a hatchling
The offspring of a bear is referred to as a cub
The offspring of a whale is referred to as a calf
The offspring of a buffalo is referred to as a calf
The offspring of a lion is referred to as a cub
The offspring of a dog is referred to as a puppy
The offspring of a pig is referred to as a
2024-07-28 12:23:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 12:25:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2117,  0.3579,  0.0043,  ...,  0.1243, -0.2311, -0.0127],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7969, -1.0869, -0.9595,  ..., -0.0469, -1.9258,  1.8789],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0602, -0.0286, -0.0085,  ..., -0.0078, -0.0050, -0.0131],
        [ 0.0007,  0.0529,  0.0073,  ..., -0.0087, -0.0079, -0.0288],
        [ 0.0043,  0.0120,  0.0412,  ...,  0.0121, -0.0250, -0.0287],
        ...,
        [ 0.0090, -0.0022,  0.0038,  ...,  0.0356,  0.0128, -0.0103],
        [ 0.0169,  0.0050,  0.0278,  ...,  0.0193,  0.0032, -0.0046],
        [ 0.0139,  0.0015, -0.0033,  ..., -0.0154,  0.0176,  0.0192]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5127, -1.1084, -0.8516,  ...,  0.2312, -2.1133,  1.8320]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 12:26:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a goldfish is referred to as a fingerling
The offspring of a snake is referred to as a hatchling
The offspring of a bear is referred to as a cub
The offspring of a whale is referred to as a calf
The offspring of a buffalo is referred to as a calf
The offspring of a lion is referred to as a cub
The offspring of a dog is referred to as a puppy
The offspring of a pig is referred to as a
2024-07-28 12:26:00 root INFO     [order_1_approx] starting weight calculation for The offspring of a goldfish is referred to as a fingerling
The offspring of a bear is referred to as a cub
The offspring of a dog is referred to as a puppy
The offspring of a snake is referred to as a hatchling
The offspring of a whale is referred to as a calf
The offspring of a lion is referred to as a cub
The offspring of a pig is referred to as a piglet
The offspring of a buffalo is referred to as a
2024-07-28 12:26:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 12:28:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7139,  0.0713,  0.3149,  ...,  0.5044, -0.7402,  0.0178],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0332, -3.3125,  0.3584,  ...,  1.1348, -1.5234,  0.0713],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0350, -0.0165, -0.0040,  ...,  0.0041,  0.0003, -0.0113],
        [ 0.0127,  0.0271,  0.0193,  ..., -0.0074, -0.0146, -0.0271],
        [ 0.0123, -0.0067,  0.0480,  ...,  0.0095, -0.0145, -0.0256],
        ...,
        [ 0.0055,  0.0048,  0.0155,  ...,  0.0579,  0.0216, -0.0139],
        [ 0.0267,  0.0125,  0.0313,  ..., -0.0362,  0.0140, -0.0273],
        [-0.0017,  0.0021, -0.0193,  ..., -0.0082,  0.0152,  0.0391]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7754, -3.2031,  0.2148,  ...,  0.9453, -1.4033,  0.2842]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 12:28:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a goldfish is referred to as a fingerling
The offspring of a bear is referred to as a cub
The offspring of a dog is referred to as a puppy
The offspring of a snake is referred to as a hatchling
The offspring of a whale is referred to as a calf
The offspring of a lion is referred to as a cub
The offspring of a pig is referred to as a piglet
The offspring of a buffalo is referred to as a
2024-07-28 12:28:20 root INFO     [order_1_approx] starting weight calculation for The offspring of a goldfish is referred to as a fingerling
The offspring of a buffalo is referred to as a calf
The offspring of a whale is referred to as a calf
The offspring of a lion is referred to as a cub
The offspring of a pig is referred to as a piglet
The offspring of a dog is referred to as a puppy
The offspring of a bear is referred to as a cub
The offspring of a snake is referred to as a
2024-07-28 12:28:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 12:30:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2803,  0.2334, -0.0774,  ...,  0.1420, -0.0207,  0.1637],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7017, -2.4648, -2.0312,  ..., -0.5537, -3.8438,  0.2842],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0349, -0.0130, -0.0049,  ...,  0.0067,  0.0097, -0.0249],
        [-0.0080,  0.0513,  0.0096,  ..., -0.0170,  0.0113, -0.0060],
        [ 0.0058,  0.0030,  0.0501,  ..., -0.0035, -0.0037, -0.0295],
        ...,
        [ 0.0073,  0.0116, -0.0059,  ...,  0.0447,  0.0062, -0.0025],
        [ 0.0009, -0.0037,  0.0061,  ...,  0.0033, -0.0004,  0.0024],
        [ 0.0041,  0.0080, -0.0150,  ..., -0.0254,  0.0095,  0.0404]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4387, -2.0625, -2.0840,  ..., -0.6602, -3.7383,  0.7959]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 12:30:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a goldfish is referred to as a fingerling
The offspring of a buffalo is referred to as a calf
The offspring of a whale is referred to as a calf
The offspring of a lion is referred to as a cub
The offspring of a pig is referred to as a piglet
The offspring of a dog is referred to as a puppy
The offspring of a bear is referred to as a cub
The offspring of a snake is referred to as a
2024-07-28 12:30:42 root INFO     [order_1_approx] starting weight calculation for The offspring of a snake is referred to as a hatchling
The offspring of a lion is referred to as a cub
The offspring of a dog is referred to as a puppy
The offspring of a pig is referred to as a piglet
The offspring of a buffalo is referred to as a calf
The offspring of a whale is referred to as a calf
The offspring of a bear is referred to as a cub
The offspring of a goldfish is referred to as a
2024-07-28 12:30:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 12:33:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4868,  0.0292, -0.1411,  ...,  0.3115, -0.5747,  0.3972],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3047, -3.0293, -5.2734,  ...,  0.0869, -5.2422,  1.0352],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0607,  0.0027, -0.0117,  ...,  0.0003, -0.0074, -0.0257],
        [ 0.0021,  0.0681, -0.0148,  ..., -0.0124,  0.0098, -0.0084],
        [ 0.0100,  0.0184,  0.0554,  ...,  0.0164, -0.0082, -0.0097],
        ...,
        [ 0.0034,  0.0123, -0.0198,  ...,  0.0374,  0.0020,  0.0009],
        [ 0.0081,  0.0226,  0.0142,  ...,  0.0040,  0.0394, -0.0007],
        [-0.0146, -0.0202, -0.0086,  ..., -0.0088,  0.0010,  0.0211]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5596, -2.7227, -5.2461,  ...,  0.5601, -5.0508,  0.3438]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 12:33:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a snake is referred to as a hatchling
The offspring of a lion is referred to as a cub
The offspring of a dog is referred to as a puppy
The offspring of a pig is referred to as a piglet
The offspring of a buffalo is referred to as a calf
The offspring of a whale is referred to as a calf
The offspring of a bear is referred to as a cub
The offspring of a goldfish is referred to as a
2024-07-28 12:33:03 root INFO     [order_1_approx] starting weight calculation for The offspring of a buffalo is referred to as a calf
The offspring of a lion is referred to as a cub
The offspring of a dog is referred to as a puppy
The offspring of a pig is referred to as a piglet
The offspring of a goldfish is referred to as a fingerling
The offspring of a bear is referred to as a cub
The offspring of a snake is referred to as a hatchling
The offspring of a whale is referred to as a
2024-07-28 12:33:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 12:35:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7061, -0.0822,  0.0712,  ..., -0.1536, -0.5059,  0.0145],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5171, -2.9043, -2.0566,  ..., -1.0371, -4.7656,  2.9258],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0422, -0.0188, -0.0123,  ...,  0.0198,  0.0009, -0.0108],
        [-0.0069,  0.0480,  0.0109,  ..., -0.0224, -0.0043, -0.0200],
        [ 0.0127, -0.0014,  0.0637,  ...,  0.0142, -0.0043, -0.0170],
        ...,
        [ 0.0026, -0.0010,  0.0344,  ...,  0.0376,  0.0194, -0.0091],
        [ 0.0168,  0.0024,  0.0228,  ...,  0.0259,  0.0029,  0.0012],
        [-0.0164,  0.0053, -0.0006,  ..., -0.0242, -0.0056,  0.0242]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6162, -2.7402, -2.4492,  ..., -1.1152, -4.8594,  2.8203]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 12:35:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a buffalo is referred to as a calf
The offspring of a lion is referred to as a cub
The offspring of a dog is referred to as a puppy
The offspring of a pig is referred to as a piglet
The offspring of a goldfish is referred to as a fingerling
The offspring of a bear is referred to as a cub
The offspring of a snake is referred to as a hatchling
The offspring of a whale is referred to as a
2024-07-28 12:35:24 root INFO     [order_1_approx] starting weight calculation for The offspring of a buffalo is referred to as a calf
The offspring of a snake is referred to as a hatchling
The offspring of a whale is referred to as a calf
The offspring of a lion is referred to as a cub
The offspring of a goldfish is referred to as a fingerling
The offspring of a dog is referred to as a puppy
The offspring of a pig is referred to as a piglet
The offspring of a bear is referred to as a
2024-07-28 12:35:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 12:37:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7031, -0.0459,  0.1186,  ...,  0.1284, -0.7393,  0.1426],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0508, -3.5645, -1.4102,  ...,  0.3652, -1.2637,  1.7793],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.2948e-02, -3.2043e-02, -2.4719e-02,  ..., -3.6240e-05,
         -3.9291e-03, -1.6800e-02],
        [-1.8784e-02,  4.4708e-02,  9.5520e-03,  ..., -9.4681e-03,
         -6.0654e-03, -2.2827e-02],
        [-2.2583e-02,  9.3842e-03,  2.5711e-02,  ...,  1.1856e-02,
          8.5449e-04, -1.9363e-02],
        ...,
        [ 4.6005e-03, -4.3182e-03,  5.5618e-03,  ...,  4.4708e-02,
          2.6276e-02, -8.2169e-03],
        [ 1.3763e-02, -1.2550e-03,  3.2471e-02,  ...,  1.6479e-02,
          8.7433e-03,  1.0605e-03],
        [-9.8572e-03, -1.6909e-03, -7.0610e-03,  ..., -1.8265e-02,
         -1.8448e-02,  3.5767e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1270, -3.2637, -0.8813,  ...,  0.7173, -1.5254,  1.7188]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 12:37:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a buffalo is referred to as a calf
The offspring of a snake is referred to as a hatchling
The offspring of a whale is referred to as a calf
The offspring of a lion is referred to as a cub
The offspring of a goldfish is referred to as a fingerling
The offspring of a dog is referred to as a puppy
The offspring of a pig is referred to as a piglet
The offspring of a bear is referred to as a
2024-07-28 12:37:45 root INFO     total operator prediction time: 1119.336405992508 seconds
2024-07-28 12:37:45 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - sound
2024-07-28 12:37:45 root INFO     building operator animal - sound
2024-07-28 12:37:46 root INFO     [order_1_approx] starting weight calculation for The sound that a pig makes is called a oink
The sound that a horse makes is called a neigh
The sound that a cat makes is called a meow
The sound that a sheep makes is called a baa
The sound that a hyena makes is called a laugh
The sound that a toad makes is called a ribbit
The sound that a raven makes is called a caw
The sound that a wasp makes is called a
2024-07-28 12:37:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 12:40:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0266, -0.2417,  0.2383,  ...,  0.4131, -0.3506,  0.0252],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5791, -1.5117,  1.8691,  ..., -1.1582,  0.6299,  1.3516],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0445, -0.0182, -0.0163,  ...,  0.0083, -0.0455,  0.0038],
        [-0.0201,  0.0591, -0.0054,  ...,  0.0048, -0.0130,  0.0023],
        [-0.0025,  0.0138,  0.0501,  ...,  0.0201, -0.0191, -0.0158],
        ...,
        [-0.0037, -0.0021,  0.0262,  ...,  0.0385, -0.0099, -0.0159],
        [-0.0210, -0.0046,  0.0095,  ..., -0.0065,  0.0101,  0.0050],
        [-0.0056,  0.0022, -0.0135,  ..., -0.0244, -0.0285,  0.0355]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5488, -1.5967,  1.4736,  ..., -1.3799,  0.0684,  1.1455]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 12:40:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a pig makes is called a oink
The sound that a horse makes is called a neigh
The sound that a cat makes is called a meow
The sound that a sheep makes is called a baa
The sound that a hyena makes is called a laugh
The sound that a toad makes is called a ribbit
The sound that a raven makes is called a caw
The sound that a wasp makes is called a
2024-07-28 12:40:07 root INFO     [order_1_approx] starting weight calculation for The sound that a raven makes is called a caw
The sound that a toad makes is called a ribbit
The sound that a cat makes is called a meow
The sound that a horse makes is called a neigh
The sound that a wasp makes is called a buzz
The sound that a pig makes is called a oink
The sound that a hyena makes is called a laugh
The sound that a sheep makes is called a
2024-07-28 12:40:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 12:42:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1917, -0.4055,  0.1628,  ...,  0.2927, -0.3538,  0.5317],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4502, -0.6187,  1.7539,  ...,  1.0420, -0.2705, -0.5752],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0690, -0.0217,  0.0032,  ..., -0.0033, -0.0352, -0.0078],
        [-0.0154,  0.0486, -0.0231,  ...,  0.0091,  0.0377, -0.0316],
        [-0.0126, -0.0033,  0.0369,  ..., -0.0125, -0.0283, -0.0130],
        ...,
        [ 0.0144,  0.0355,  0.0144,  ...,  0.0534,  0.0064, -0.0264],
        [ 0.0111,  0.0260, -0.0048,  ...,  0.0091,  0.0314, -0.0097],
        [ 0.0024, -0.0046, -0.0013,  ..., -0.0095,  0.0001,  0.0336]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0037, -0.1736,  1.8096,  ...,  0.6719, -0.5874, -0.8525]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 12:42:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a raven makes is called a caw
The sound that a toad makes is called a ribbit
The sound that a cat makes is called a meow
The sound that a horse makes is called a neigh
The sound that a wasp makes is called a buzz
The sound that a pig makes is called a oink
The sound that a hyena makes is called a laugh
The sound that a sheep makes is called a
2024-07-28 12:42:27 root INFO     [order_1_approx] starting weight calculation for The sound that a pig makes is called a oink
The sound that a hyena makes is called a laugh
The sound that a cat makes is called a meow
The sound that a sheep makes is called a baa
The sound that a toad makes is called a ribbit
The sound that a raven makes is called a caw
The sound that a wasp makes is called a buzz
The sound that a horse makes is called a
2024-07-28 12:42:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 12:44:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2251, -0.2915,  0.4155,  ...,  0.1187,  0.0933,  0.2416],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6348, -2.3633, -2.4023,  ...,  0.8579, -0.1670,  1.2090],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0598, -0.0049, -0.0100,  ..., -0.0128, -0.0006, -0.0065],
        [-0.0029,  0.0402, -0.0060,  ...,  0.0069,  0.0300, -0.0172],
        [-0.0044, -0.0116,  0.0596,  ..., -0.0128, -0.0027,  0.0029],
        ...,
        [ 0.0132,  0.0066, -0.0008,  ...,  0.0214,  0.0056, -0.0147],
        [-0.0139,  0.0110,  0.0107,  ...,  0.0130,  0.0304, -0.0088],
        [ 0.0074, -0.0065,  0.0179,  ..., -0.0153, -0.0089, -0.0037]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5161, -1.7520, -2.6055,  ...,  0.8911, -0.7617,  0.8496]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 12:44:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a pig makes is called a oink
The sound that a hyena makes is called a laugh
The sound that a cat makes is called a meow
The sound that a sheep makes is called a baa
The sound that a toad makes is called a ribbit
The sound that a raven makes is called a caw
The sound that a wasp makes is called a buzz
The sound that a horse makes is called a
2024-07-28 12:44:49 root INFO     [order_1_approx] starting weight calculation for The sound that a cat makes is called a meow
The sound that a wasp makes is called a buzz
The sound that a pig makes is called a oink
The sound that a sheep makes is called a baa
The sound that a horse makes is called a neigh
The sound that a raven makes is called a caw
The sound that a hyena makes is called a laugh
The sound that a toad makes is called a
2024-07-28 12:44:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 12:47:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0837, -0.2046,  0.4785,  ..., -0.2869, -0.0806,  0.0322],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7163, -0.8325, -0.3359,  ...,  1.6768, -1.3926,  4.1445],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0593, -0.0426,  0.0101,  ...,  0.0182, -0.0243, -0.0186],
        [-0.0141,  0.0475, -0.0104,  ..., -0.0248,  0.0143, -0.0114],
        [-0.0079,  0.0028,  0.0806,  ..., -0.0316, -0.0116, -0.0233],
        ...,
        [ 0.0098,  0.0258, -0.0113,  ...,  0.0367, -0.0074, -0.0279],
        [-0.0031, -0.0048,  0.0023,  ...,  0.0032,  0.0242, -0.0250],
        [ 0.0186, -0.0064,  0.0159,  ..., -0.0099, -0.0220,  0.0345]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2280, -1.3848,  0.1880,  ...,  1.1816, -1.5352,  3.7656]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 12:47:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a cat makes is called a meow
The sound that a wasp makes is called a buzz
The sound that a pig makes is called a oink
The sound that a sheep makes is called a baa
The sound that a horse makes is called a neigh
The sound that a raven makes is called a caw
The sound that a hyena makes is called a laugh
The sound that a toad makes is called a
2024-07-28 12:47:10 root INFO     [order_1_approx] starting weight calculation for The sound that a horse makes is called a neigh
The sound that a toad makes is called a ribbit
The sound that a sheep makes is called a baa
The sound that a hyena makes is called a laugh
The sound that a cat makes is called a meow
The sound that a raven makes is called a caw
The sound that a wasp makes is called a buzz
The sound that a pig makes is called a
2024-07-28 12:47:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 12:49:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0820, -0.0676,  0.2734,  ...,  0.0376, -0.3130,  0.1545],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0742, -1.9629,  3.0527,  ..., -3.0234,  0.7163,  1.3496],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0493, -0.0104, -0.0021,  ..., -0.0204, -0.0100, -0.0260],
        [-0.0013,  0.0231,  0.0074,  ..., -0.0219,  0.0044, -0.0202],
        [ 0.0095,  0.0059,  0.0688,  ..., -0.0134, -0.0282, -0.0148],
        ...,
        [ 0.0168,  0.0066,  0.0156,  ...,  0.0180, -0.0099, -0.0123],
        [ 0.0009,  0.0124,  0.0052,  ...,  0.0112,  0.0287,  0.0090],
        [ 0.0019, -0.0213,  0.0018,  ..., -0.0204,  0.0131,  0.0190]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1445, -1.9658,  2.7109,  ..., -3.3223,  0.6938,  1.0225]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 12:49:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a horse makes is called a neigh
The sound that a toad makes is called a ribbit
The sound that a sheep makes is called a baa
The sound that a hyena makes is called a laugh
The sound that a cat makes is called a meow
The sound that a raven makes is called a caw
The sound that a wasp makes is called a buzz
The sound that a pig makes is called a
2024-07-28 12:49:29 root INFO     [order_1_approx] starting weight calculation for The sound that a wasp makes is called a buzz
The sound that a sheep makes is called a baa
The sound that a horse makes is called a neigh
The sound that a hyena makes is called a laugh
The sound that a pig makes is called a oink
The sound that a toad makes is called a ribbit
The sound that a cat makes is called a meow
The sound that a raven makes is called a
2024-07-28 12:49:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 12:51:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2024, -0.0215,  0.0850,  ...,  0.3447, -0.4795, -0.0984],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2998, -3.4492, -0.3398,  ..., -1.9668,  0.3115,  2.0352],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0632,  0.0041, -0.0122,  ..., -0.0118, -0.0522, -0.0219],
        [-0.0387,  0.0417,  0.0116,  ...,  0.0158,  0.0488, -0.0523],
        [-0.0156, -0.0125,  0.0593,  ...,  0.0016, -0.0359, -0.0217],
        ...,
        [ 0.0159,  0.0069, -0.0061,  ...,  0.0525,  0.0244, -0.0265],
        [-0.0395, -0.0098, -0.0160,  ...,  0.0091,  0.0215, -0.0353],
        [ 0.0167, -0.0115, -0.0012,  ..., -0.0178, -0.0204,  0.0288]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9277, -3.1797, -0.5327,  ..., -2.7578, -0.0803,  2.0684]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 12:51:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a wasp makes is called a buzz
The sound that a sheep makes is called a baa
The sound that a horse makes is called a neigh
The sound that a hyena makes is called a laugh
The sound that a pig makes is called a oink
The sound that a toad makes is called a ribbit
The sound that a cat makes is called a meow
The sound that a raven makes is called a
2024-07-28 12:51:49 root INFO     [order_1_approx] starting weight calculation for The sound that a sheep makes is called a baa
The sound that a raven makes is called a caw
The sound that a toad makes is called a ribbit
The sound that a horse makes is called a neigh
The sound that a hyena makes is called a laugh
The sound that a pig makes is called a oink
The sound that a wasp makes is called a buzz
The sound that a cat makes is called a
2024-07-28 12:51:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 12:54:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2170, -0.0895,  0.4062,  ...,  0.1895, -0.2703,  0.0197],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0615, -3.7598, -2.4297,  ..., -2.6855, -0.1006,  2.6250],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0302, -0.0022, -0.0029,  ..., -0.0146, -0.0273,  0.0075],
        [-0.0062,  0.0392,  0.0115,  ..., -0.0191,  0.0306, -0.0230],
        [-0.0246, -0.0073,  0.0560,  ..., -0.0107,  0.0083,  0.0019],
        ...,
        [ 0.0025,  0.0183,  0.0114,  ...,  0.0231,  0.0085, -0.0231],
        [ 0.0201,  0.0092, -0.0067,  ...,  0.0056,  0.0092, -0.0002],
        [-0.0025, -0.0173, -0.0211,  ..., -0.0210, -0.0220,  0.0226]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1537, -3.7969, -1.9990,  ..., -2.7578, -0.3535,  2.2090]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 12:54:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a sheep makes is called a baa
The sound that a raven makes is called a caw
The sound that a toad makes is called a ribbit
The sound that a horse makes is called a neigh
The sound that a hyena makes is called a laugh
The sound that a pig makes is called a oink
The sound that a wasp makes is called a buzz
The sound that a cat makes is called a
2024-07-28 12:54:08 root INFO     [order_1_approx] starting weight calculation for The sound that a cat makes is called a meow
The sound that a horse makes is called a neigh
The sound that a toad makes is called a ribbit
The sound that a sheep makes is called a baa
The sound that a pig makes is called a oink
The sound that a raven makes is called a caw
The sound that a wasp makes is called a buzz
The sound that a hyena makes is called a
2024-07-28 12:54:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 12:56:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3301, -0.0123,  0.6606,  ...,  0.6367, -0.5190, -0.0809],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3706, -4.8594,  0.9629,  ..., -1.7412, -0.9092, -0.3750],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0570, -0.0033,  0.0043,  ..., -0.0010, -0.0357, -0.0141],
        [-0.0204,  0.0314, -0.0225,  ...,  0.0064,  0.0242, -0.0122],
        [-0.0064,  0.0277,  0.0659,  ..., -0.0777, -0.0162, -0.0292],
        ...,
        [-0.0013,  0.0181,  0.0327,  ...,  0.0493,  0.0282,  0.0013],
        [ 0.0091, -0.0031,  0.0077,  ..., -0.0301,  0.0267, -0.0142],
        [-0.0012, -0.0414, -0.0294,  ..., -0.0252, -0.0245,  0.0292]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2051, -4.1719,  1.0254,  ..., -1.4111, -1.1025, -0.8008]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 12:56:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a cat makes is called a meow
The sound that a horse makes is called a neigh
The sound that a toad makes is called a ribbit
The sound that a sheep makes is called a baa
The sound that a pig makes is called a oink
The sound that a raven makes is called a caw
The sound that a wasp makes is called a buzz
The sound that a hyena makes is called a
2024-07-28 12:56:24 root INFO     total operator prediction time: 1118.7527422904968 seconds
2024-07-28 12:56:24 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on things - color
2024-07-28 12:56:24 root INFO     building operator things - color
2024-07-28 12:56:24 root INFO     [order_1_approx] starting weight calculation for The soil is colored black
The sky is colored blue
The toothpaste is colored white
The grapes is colored black
The raven is colored black
The crow is colored black
The celery is colored green
The peony is colored
2024-07-28 12:56:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 12:58:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1410, -0.0355, -0.2678,  ..., -0.0585, -0.3340, -0.1702],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.1465, -5.1914,  1.8877,  ..., -0.5146, -2.1914, -0.0713],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.0150e-02, -8.6517e-03,  4.7035e-03,  ..., -2.1667e-03,
          1.1513e-02,  1.2619e-02],
        [-1.4877e-04,  4.0253e-02,  2.8809e-02,  ...,  3.4695e-03,
          2.4357e-03, -1.6052e-02],
        [-1.1002e-02,  5.2872e-03,  5.7373e-02,  ...,  1.7990e-02,
         -9.9335e-03,  8.5983e-03],
        ...,
        [ 1.4091e-02,  6.9237e-03, -2.4557e-05,  ...,  5.2551e-02,
         -1.5762e-02, -8.0872e-03],
        [ 3.2654e-03,  2.4433e-03, -1.0399e-02,  ...,  1.0033e-02,
          5.9631e-02, -1.6373e-02],
        [-2.1423e-02, -4.4632e-03, -3.4237e-03,  ...,  7.6056e-04,
          1.6060e-03,  3.6743e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7427, -5.0391,  1.5820,  ..., -0.1584, -2.2930, -0.2362]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 12:58:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The soil is colored black
The sky is colored blue
The toothpaste is colored white
The grapes is colored black
The raven is colored black
The crow is colored black
The celery is colored green
The peony is colored
2024-07-28 12:58:45 root INFO     [order_1_approx] starting weight calculation for The toothpaste is colored white
The raven is colored black
The grapes is colored black
The peony is colored red
The sky is colored blue
The celery is colored green
The crow is colored black
The soil is colored
2024-07-28 12:58:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 13:01:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0923,  0.0415, -0.5947,  ...,  0.2029, -0.4771, -0.0248],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3560, -5.9883,  0.8115,  ..., -1.6768,  0.2988, -2.2227],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0519,  0.0088, -0.0044,  ...,  0.0107,  0.0071,  0.0032],
        [-0.0009,  0.0375,  0.0201,  ...,  0.0030, -0.0204, -0.0129],
        [-0.0164, -0.0002,  0.0467,  ...,  0.0127, -0.0078,  0.0133],
        ...,
        [-0.0007, -0.0100,  0.0156,  ...,  0.0524,  0.0007, -0.0184],
        [ 0.0055,  0.0017, -0.0014,  ...,  0.0173,  0.0450, -0.0026],
        [-0.0250, -0.0097, -0.0118,  ..., -0.0052, -0.0102,  0.0309]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3948, -5.6406,  0.7505,  ..., -1.4512,  0.1439, -2.0156]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 13:01:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The toothpaste is colored white
The raven is colored black
The grapes is colored black
The peony is colored red
The sky is colored blue
The celery is colored green
The crow is colored black
The soil is colored
2024-07-28 13:01:07 root INFO     [order_1_approx] starting weight calculation for The grapes is colored black
The celery is colored green
The peony is colored red
The raven is colored black
The crow is colored black
The soil is colored black
The sky is colored blue
The toothpaste is colored
2024-07-28 13:01:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 13:03:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1040, -0.4768,  0.0356,  ..., -0.1008, -0.1531, -0.0974],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.0410, -2.5234,  0.5620,  ..., -0.2354, -3.3984, -0.8203],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0691,  0.0146,  0.0123,  ...,  0.0014, -0.0191,  0.0089],
        [ 0.0201,  0.0569,  0.0166,  ...,  0.0006, -0.0066,  0.0044],
        [-0.0127, -0.0063,  0.0705,  ...,  0.0109, -0.0195,  0.0191],
        ...,
        [ 0.0019,  0.0083, -0.0007,  ...,  0.0468, -0.0116, -0.0055],
        [ 0.0153,  0.0141, -0.0143,  ...,  0.0286,  0.0432, -0.0345],
        [ 0.0013, -0.0107,  0.0037,  ...,  0.0021, -0.0016,  0.0451]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.8203, -2.9922,  0.0283,  ...,  0.1072, -3.4395, -0.9385]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 13:03:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The grapes is colored black
The celery is colored green
The peony is colored red
The raven is colored black
The crow is colored black
The soil is colored black
The sky is colored blue
The toothpaste is colored
2024-07-28 13:03:26 root INFO     [order_1_approx] starting weight calculation for The soil is colored black
The grapes is colored black
The celery is colored green
The sky is colored blue
The peony is colored red
The crow is colored black
The toothpaste is colored white
The raven is colored
2024-07-28 13:03:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 13:05:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0318, -0.0175, -0.1335,  ...,  0.0383, -0.2627, -0.0775],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5547, -3.4609,  2.0430,  ..., -0.0303,  2.6309, -1.4844],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0717,  0.0088, -0.0048,  ...,  0.0094,  0.0132, -0.0094],
        [ 0.0082,  0.0509,  0.0354,  ...,  0.0255,  0.0021, -0.0231],
        [-0.0053, -0.0269,  0.0661,  ...,  0.0112, -0.0072,  0.0059],
        ...,
        [ 0.0077,  0.0077,  0.0228,  ...,  0.0735, -0.0014, -0.0047],
        [ 0.0188,  0.0066,  0.0065,  ...,  0.0397,  0.0461, -0.0082],
        [-0.0072, -0.0067, -0.0129,  ...,  0.0008, -0.0310,  0.0410]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3672, -3.9023,  1.5137,  ..., -0.2323,  1.9336, -1.4189]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 13:05:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The soil is colored black
The grapes is colored black
The celery is colored green
The sky is colored blue
The peony is colored red
The crow is colored black
The toothpaste is colored white
The raven is colored
2024-07-28 13:05:48 root INFO     [order_1_approx] starting weight calculation for The grapes is colored black
The peony is colored red
The sky is colored blue
The raven is colored black
The soil is colored black
The toothpaste is colored white
The celery is colored green
The crow is colored
2024-07-28 13:05:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 13:08:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0316, -0.1908,  0.1119,  ..., -0.1118, -0.3550,  0.3945],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5586, -3.9766,  2.4023,  ..., -0.7607,  1.2598, -0.7402],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.6772e-02, -1.7920e-03,  9.3613e-03,  ...,  6.6757e-04,
         -4.0054e-05,  3.1719e-03],
        [ 1.3943e-03,  5.3040e-02,  1.2779e-02,  ...,  3.0609e-02,
         -4.9057e-03, -5.8594e-03],
        [-4.6387e-03, -1.9852e-02,  6.1310e-02,  ...,  2.3788e-02,
         -7.0343e-03,  1.2115e-02],
        ...,
        [ 7.9880e-03,  1.0433e-03,  1.4259e-02,  ...,  7.2510e-02,
         -6.1455e-03,  4.7417e-03],
        [ 1.7990e-02, -7.3242e-04, -8.9874e-03,  ...,  1.4816e-02,
          4.7852e-02,  4.0627e-04],
        [ 9.8877e-03, -4.6349e-04, -1.4923e-02,  ..., -1.0567e-03,
         -2.4490e-02,  3.9551e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5039, -4.4062,  1.7373,  ..., -0.6274,  0.8823, -0.8896]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 13:08:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The grapes is colored black
The peony is colored red
The sky is colored blue
The raven is colored black
The soil is colored black
The toothpaste is colored white
The celery is colored green
The crow is colored
2024-07-28 13:08:07 root INFO     [order_1_approx] starting weight calculation for The soil is colored black
The raven is colored black
The peony is colored red
The celery is colored green
The crow is colored black
The grapes is colored black
The toothpaste is colored white
The sky is colored
2024-07-28 13:08:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 13:10:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1686, -0.5122, -0.1785,  ...,  0.1776,  0.1863, -0.2024],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.0664, -6.2930,  2.6465,  ..., -0.8921,  0.3433, -0.8252],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0502,  0.0046, -0.0089,  ..., -0.0077,  0.0061, -0.0038],
        [ 0.0022,  0.0457,  0.0113,  ..., -0.0038, -0.0091, -0.0120],
        [ 0.0011, -0.0131,  0.0388,  ...,  0.0125, -0.0120,  0.0219],
        ...,
        [-0.0061,  0.0067,  0.0172,  ...,  0.0564,  0.0083, -0.0102],
        [-0.0021, -0.0169,  0.0098,  ...,  0.0352,  0.0480,  0.0045],
        [-0.0121, -0.0144,  0.0024,  ..., -0.0016, -0.0126,  0.0325]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.2832, -6.2734,  2.5469,  ..., -0.6401,  0.5117, -0.8560]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 13:10:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The soil is colored black
The raven is colored black
The peony is colored red
The celery is colored green
The crow is colored black
The grapes is colored black
The toothpaste is colored white
The sky is colored
2024-07-28 13:10:28 root INFO     [order_1_approx] starting weight calculation for The crow is colored black
The toothpaste is colored white
The soil is colored black
The grapes is colored black
The raven is colored black
The sky is colored blue
The peony is colored red
The celery is colored
2024-07-28 13:10:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 13:12:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0374, -0.1748, -0.3030,  ..., -0.4551, -0.4253, -0.0881],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7324, -4.3555, -2.3594,  ..., -2.7988, -2.2344, -3.2539],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0725, -0.0056, -0.0025,  ..., -0.0063,  0.0119,  0.0031],
        [ 0.0046,  0.0522,  0.0305,  ...,  0.0264,  0.0180, -0.0063],
        [-0.0236, -0.0153,  0.0594,  ...,  0.0295, -0.0172,  0.0051],
        ...,
        [ 0.0100, -0.0253,  0.0115,  ...,  0.0987,  0.0138, -0.0191],
        [ 0.0021,  0.0241, -0.0148,  ...,  0.0089,  0.0657, -0.0078],
        [-0.0136, -0.0130, -0.0021,  ..., -0.0040,  0.0128,  0.0525]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.9331, -4.9023, -2.2266,  ..., -2.2930, -2.6582, -2.5977]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 13:12:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The crow is colored black
The toothpaste is colored white
The soil is colored black
The grapes is colored black
The raven is colored black
The sky is colored blue
The peony is colored red
The celery is colored
2024-07-28 13:12:50 root INFO     [order_1_approx] starting weight calculation for The celery is colored green
The peony is colored red
The toothpaste is colored white
The sky is colored blue
The raven is colored black
The crow is colored black
The soil is colored black
The grapes is colored
2024-07-28 13:12:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 13:15:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0336, -0.6982, -0.1781,  ..., -0.0450, -0.2786, -0.0610],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3877, -8.0000, -2.0547,  ..., -2.2402, -1.0381, -2.7812],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0494,  0.0039,  0.0070,  ..., -0.0029,  0.0024,  0.0087],
        [-0.0044,  0.0269,  0.0100,  ...,  0.0161,  0.0280, -0.0306],
        [ 0.0066, -0.0082,  0.0375,  ...,  0.0053, -0.0143, -0.0047],
        ...,
        [-0.0011, -0.0072,  0.0071,  ...,  0.0480, -0.0094,  0.0036],
        [ 0.0059, -0.0032, -0.0086,  ...,  0.0158,  0.0281, -0.0075],
        [-0.0096, -0.0085, -0.0043,  ...,  0.0007,  0.0034,  0.0315]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4944, -7.8281, -2.0879,  ..., -2.1562, -0.9951, -2.6133]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 13:15:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The celery is colored green
The peony is colored red
The toothpaste is colored white
The sky is colored blue
The raven is colored black
The crow is colored black
The soil is colored black
The grapes is colored
2024-07-28 13:15:12 root INFO     total operator prediction time: 1127.4542028903961 seconds
2024-07-28 13:15:12 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on country - capital
2024-07-28 13:15:12 root INFO     building operator country - capital
2024-07-28 13:15:12 root INFO     [order_1_approx] starting weight calculation for The country with bangkok as its capital is known as thailand
The country with madrid as its capital is known as spain
The country with athens as its capital is known as greece
The country with budapest as its capital is known as hungary
The country with taipei as its capital is known as taiwan
The country with tbilisi as its capital is known as georgia
The country with dublin as its capital is known as ireland
The country with beirut as its capital is known as
2024-07-28 13:15:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 13:17:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0507, -0.2190, -0.3718,  ...,  0.5366,  0.0664,  0.0847],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0364, -7.0742,  0.5850,  ...,  0.1064,  0.8730, -3.7695],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0231, -0.0063, -0.0115,  ...,  0.0081, -0.0114, -0.0036],
        [-0.0151,  0.0243,  0.0004,  ..., -0.0091,  0.0146, -0.0024],
        [ 0.0013,  0.0088,  0.0323,  ..., -0.0036, -0.0020, -0.0072],
        ...,
        [-0.0093,  0.0099,  0.0041,  ...,  0.0186,  0.0093, -0.0099],
        [ 0.0004, -0.0035,  0.0048,  ...,  0.0012,  0.0220, -0.0019],
        [-0.0198,  0.0051, -0.0041,  ...,  0.0095,  0.0023,  0.0173]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1968, -7.1797,  0.6035,  ...,  0.1510,  0.8979, -3.8477]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 13:17:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with bangkok as its capital is known as thailand
The country with madrid as its capital is known as spain
The country with athens as its capital is known as greece
The country with budapest as its capital is known as hungary
The country with taipei as its capital is known as taiwan
The country with tbilisi as its capital is known as georgia
The country with dublin as its capital is known as ireland
The country with beirut as its capital is known as
2024-07-28 13:17:26 root INFO     [order_1_approx] starting weight calculation for The country with beirut as its capital is known as lebanon
The country with athens as its capital is known as greece
The country with taipei as its capital is known as taiwan
The country with dublin as its capital is known as ireland
The country with budapest as its capital is known as hungary
The country with bangkok as its capital is known as thailand
The country with tbilisi as its capital is known as georgia
The country with madrid as its capital is known as
2024-07-28 13:17:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 13:19:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5806, -0.2325, -0.7437,  ...,  0.8379,  0.4915,  0.0396],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7227, -4.3516, -1.6504,  ...,  1.1992,  0.4707, -5.0781],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0245,  0.0114, -0.0196,  ...,  0.0188, -0.0134,  0.0130],
        [-0.0018,  0.0255,  0.0140,  ..., -0.0038,  0.0013, -0.0123],
        [ 0.0012,  0.0145,  0.0524,  ...,  0.0134,  0.0223, -0.0156],
        ...,
        [-0.0031,  0.0170,  0.0037,  ...,  0.0298,  0.0144, -0.0174],
        [ 0.0122,  0.0017, -0.0137,  ..., -0.0054,  0.0024, -0.0108],
        [-0.0169, -0.0142,  0.0036,  ...,  0.0136, -0.0076,  0.0059]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7842, -4.2539, -1.8574,  ...,  1.0586,  0.6548, -4.9570]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 13:19:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with beirut as its capital is known as lebanon
The country with athens as its capital is known as greece
The country with taipei as its capital is known as taiwan
The country with dublin as its capital is known as ireland
The country with budapest as its capital is known as hungary
The country with bangkok as its capital is known as thailand
The country with tbilisi as its capital is known as georgia
The country with madrid as its capital is known as
2024-07-28 13:19:43 root INFO     [order_1_approx] starting weight calculation for The country with budapest as its capital is known as hungary
The country with taipei as its capital is known as taiwan
The country with madrid as its capital is known as spain
The country with dublin as its capital is known as ireland
The country with athens as its capital is known as greece
The country with bangkok as its capital is known as thailand
The country with beirut as its capital is known as lebanon
The country with tbilisi as its capital is known as
2024-07-28 13:19:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 13:21:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3445,  0.0165, -0.4492,  ...,  0.3542,  0.1528,  0.3403],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5234, -5.3281, -0.7974,  ..., -2.8184,  0.1426, -2.6934],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0227, -0.0091, -0.0060,  ...,  0.0129, -0.0029,  0.0038],
        [ 0.0139,  0.0165,  0.0052,  ...,  0.0057,  0.0156, -0.0204],
        [-0.0054,  0.0066,  0.0211,  ...,  0.0152, -0.0051, -0.0028],
        ...,
        [ 0.0013,  0.0100, -0.0003,  ...,  0.0426,  0.0134, -0.0041],
        [ 0.0091,  0.0082, -0.0046,  ...,  0.0151,  0.0155, -0.0053],
        [-0.0138, -0.0036, -0.0059,  ...,  0.0020,  0.0055,  0.0028]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1035, -5.3672, -0.9004,  ..., -2.9961,  0.2822, -2.5703]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 13:21:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with budapest as its capital is known as hungary
The country with taipei as its capital is known as taiwan
The country with madrid as its capital is known as spain
The country with dublin as its capital is known as ireland
The country with athens as its capital is known as greece
The country with bangkok as its capital is known as thailand
The country with beirut as its capital is known as lebanon
The country with tbilisi as its capital is known as
2024-07-28 13:21:59 root INFO     [order_1_approx] starting weight calculation for The country with athens as its capital is known as greece
The country with madrid as its capital is known as spain
The country with taipei as its capital is known as taiwan
The country with bangkok as its capital is known as thailand
The country with beirut as its capital is known as lebanon
The country with tbilisi as its capital is known as georgia
The country with dublin as its capital is known as ireland
The country with budapest as its capital is known as
2024-07-28 13:21:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 13:24:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3230,  0.0291, -0.0367,  ...,  0.5552,  0.0172,  0.0963],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0977, -5.2852, -2.7305,  ...,  0.2847,  0.5752, -4.1328],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0208, -0.0170, -0.0031,  ...,  0.0014, -0.0036, -0.0024],
        [-0.0042,  0.0126,  0.0127,  ...,  0.0030,  0.0042, -0.0125],
        [ 0.0007,  0.0107,  0.0484,  ...,  0.0007, -0.0122, -0.0034],
        ...,
        [-0.0020,  0.0117, -0.0011,  ...,  0.0361,  0.0248, -0.0177],
        [ 0.0021,  0.0059, -0.0144,  ...,  0.0085,  0.0165,  0.0012],
        [-0.0215,  0.0012,  0.0042,  ..., -0.0003,  0.0092,  0.0143]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1465, -5.1367, -2.8262,  ...,  0.5903,  0.3374, -3.8438]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 13:24:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with athens as its capital is known as greece
The country with madrid as its capital is known as spain
The country with taipei as its capital is known as taiwan
The country with bangkok as its capital is known as thailand
The country with beirut as its capital is known as lebanon
The country with tbilisi as its capital is known as georgia
The country with dublin as its capital is known as ireland
The country with budapest as its capital is known as
2024-07-28 13:24:18 root INFO     [order_1_approx] starting weight calculation for The country with taipei as its capital is known as taiwan
The country with beirut as its capital is known as lebanon
The country with budapest as its capital is known as hungary
The country with tbilisi as its capital is known as georgia
The country with madrid as its capital is known as spain
The country with athens as its capital is known as greece
The country with bangkok as its capital is known as thailand
The country with dublin as its capital is known as
2024-07-28 13:24:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 13:26:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3958, -0.1394, -0.4419,  ...,  0.8193,  0.1460, -0.0543],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4590, -5.6289, -1.0195,  ...,  2.0215, -1.6943, -6.6875],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0471, -0.0092, -0.0213,  ...,  0.0170, -0.0031,  0.0008],
        [-0.0083,  0.0286, -0.0185,  ..., -0.0004, -0.0072, -0.0127],
        [-0.0037,  0.0172,  0.0437,  ...,  0.0153, -0.0059, -0.0159],
        ...,
        [-0.0092,  0.0028,  0.0125,  ...,  0.0280,  0.0210, -0.0168],
        [ 0.0049, -0.0004, -0.0065,  ...,  0.0049,  0.0216, -0.0020],
        [-0.0043, -0.0057,  0.0017,  ...,  0.0024, -0.0011,  0.0181]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3145, -5.8867, -1.0195,  ...,  1.8086, -1.6279, -6.1875]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 13:26:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with taipei as its capital is known as taiwan
The country with beirut as its capital is known as lebanon
The country with budapest as its capital is known as hungary
The country with tbilisi as its capital is known as georgia
The country with madrid as its capital is known as spain
The country with athens as its capital is known as greece
The country with bangkok as its capital is known as thailand
The country with dublin as its capital is known as
2024-07-28 13:26:36 root INFO     [order_1_approx] starting weight calculation for The country with beirut as its capital is known as lebanon
The country with tbilisi as its capital is known as georgia
The country with athens as its capital is known as greece
The country with budapest as its capital is known as hungary
The country with taipei as its capital is known as taiwan
The country with madrid as its capital is known as spain
The country with dublin as its capital is known as ireland
The country with bangkok as its capital is known as
2024-07-28 13:26:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 13:28:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2427,  0.0708, -0.4077,  ...,  0.6060,  0.1167,  0.1714],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6421, -4.9219,  1.4580,  ..., -0.4648, -1.9766, -3.5469],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0210, -0.0039,  0.0057,  ...,  0.0152, -0.0062, -0.0007],
        [ 0.0036,  0.0118,  0.0081,  ..., -0.0057,  0.0083, -0.0230],
        [ 0.0059,  0.0058,  0.0359,  ...,  0.0116, -0.0031, -0.0149],
        ...,
        [-0.0017,  0.0048,  0.0119,  ...,  0.0254,  0.0158, -0.0194],
        [-0.0014, -0.0057, -0.0070,  ..., -0.0012,  0.0107,  0.0015],
        [-0.0024, -0.0076, -0.0181,  ..., -0.0006,  0.0090,  0.0225]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6982, -4.6953,  1.3672,  ..., -0.2773, -1.8799, -3.4902]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 13:28:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with beirut as its capital is known as lebanon
The country with tbilisi as its capital is known as georgia
The country with athens as its capital is known as greece
The country with budapest as its capital is known as hungary
The country with taipei as its capital is known as taiwan
The country with madrid as its capital is known as spain
The country with dublin as its capital is known as ireland
The country with bangkok as its capital is known as
2024-07-28 13:28:54 root INFO     [order_1_approx] starting weight calculation for The country with beirut as its capital is known as lebanon
The country with dublin as its capital is known as ireland
The country with tbilisi as its capital is known as georgia
The country with budapest as its capital is known as hungary
The country with madrid as its capital is known as spain
The country with taipei as its capital is known as taiwan
The country with bangkok as its capital is known as thailand
The country with athens as its capital is known as
2024-07-28 13:28:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 13:31:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4812, -0.1534, -0.5669,  ...,  0.6201,  0.0543, -0.3872],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3867, -5.3516, -2.8691,  ..., -0.0122,  1.1426, -2.7266],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.4698e-02, -3.2997e-04, -8.9035e-03,  ...,  4.1199e-03,
         -1.3733e-02, -4.5853e-03],
        [-7.3528e-04,  2.5986e-02,  4.0932e-03,  ...,  4.8180e-03,
          3.9177e-03, -1.9272e-02],
        [-2.0386e-02,  2.9068e-03,  5.3192e-02,  ...,  4.1580e-03,
          3.5610e-03, -5.5962e-03],
        ...,
        [-6.0616e-03,  6.0272e-03,  7.2937e-03,  ...,  2.8336e-02,
          2.8961e-02, -1.2527e-02],
        [ 5.0812e-03, -1.7719e-03, -8.4839e-03,  ...,  9.1248e-03,
          1.7639e-02, -5.3024e-03],
        [-2.0355e-02, -8.7585e-03, -8.1482e-03,  ..., -8.0585e-04,
         -7.6294e-06,  1.7807e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3613, -5.3828, -2.7461,  ..., -0.1528,  1.0938, -2.4258]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 13:31:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with beirut as its capital is known as lebanon
The country with dublin as its capital is known as ireland
The country with tbilisi as its capital is known as georgia
The country with budapest as its capital is known as hungary
The country with madrid as its capital is known as spain
The country with taipei as its capital is known as taiwan
The country with bangkok as its capital is known as thailand
The country with athens as its capital is known as
2024-07-28 13:31:15 root INFO     [order_1_approx] starting weight calculation for The country with tbilisi as its capital is known as georgia
The country with madrid as its capital is known as spain
The country with bangkok as its capital is known as thailand
The country with beirut as its capital is known as lebanon
The country with dublin as its capital is known as ireland
The country with athens as its capital is known as greece
The country with budapest as its capital is known as hungary
The country with taipei as its capital is known as
2024-07-28 13:31:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 13:33:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3870, -0.1477, -0.2134,  ...,  0.5703,  0.1492,  0.2186],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5576, -3.2344,  0.4631,  ..., -0.6914, -1.7559, -1.2402],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0113,  0.0062, -0.0031,  ...,  0.0029, -0.0059,  0.0009],
        [ 0.0046,  0.0155,  0.0156,  ..., -0.0048,  0.0023, -0.0043],
        [ 0.0066,  0.0108,  0.0248,  ...,  0.0112, -0.0059, -0.0078],
        ...,
        [-0.0050,  0.0022,  0.0042,  ...,  0.0255,  0.0116, -0.0062],
        [ 0.0068, -0.0003, -0.0029,  ..., -0.0047,  0.0086,  0.0051],
        [-0.0049, -0.0058, -0.0121,  ..., -0.0014,  0.0034,  0.0061]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2949, -3.2637,  0.1018,  ..., -0.9243, -1.6064, -1.4492]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 13:33:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with tbilisi as its capital is known as georgia
The country with madrid as its capital is known as spain
The country with bangkok as its capital is known as thailand
The country with beirut as its capital is known as lebanon
The country with dublin as its capital is known as ireland
The country with athens as its capital is known as greece
The country with budapest as its capital is known as hungary
The country with taipei as its capital is known as
2024-07-28 13:33:35 root INFO     total operator prediction time: 1103.0515661239624 seconds
2024-07-28 13:33:35 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on name - occupation
2024-07-28 13:33:35 root INFO     building operator name - occupation
2024-07-28 13:33:35 root INFO     [order_1_approx] starting weight calculation for mozart was known for their work as a  composer
moses was known for their work as a  prophet
confucius was known for their work as a  philosopher
pascal was known for their work as a  mathematician
goethe was known for their work as a  poet
plato was known for their work as a  philosopher
caesar was known for their work as a  emperor
pacino was known for their work as a 
2024-07-28 13:33:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 13:35:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0474, -0.0588, -0.5596,  ...,  0.4812, -0.3472, -0.2432],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9336, -5.5625,  2.7305,  ..., -5.2539, -0.1348, -0.7256],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0361, -0.0210,  0.0275,  ...,  0.0221, -0.0108, -0.0013],
        [ 0.0123,  0.0708,  0.0049,  ..., -0.0061,  0.0182, -0.0200],
        [ 0.0315, -0.0194,  0.0809,  ...,  0.0026, -0.0097,  0.0143],
        ...,
        [ 0.0027,  0.0454, -0.0110,  ...,  0.0655, -0.0004,  0.0030],
        [-0.0032, -0.0137,  0.0047,  ..., -0.0033,  0.0281,  0.0335],
        [ 0.0248,  0.0245, -0.0008,  ..., -0.0276, -0.0043,  0.0431]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7754, -5.3164,  2.5098,  ..., -4.9727, -0.2615, -0.1138]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 13:35:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for mozart was known for their work as a  composer
moses was known for their work as a  prophet
confucius was known for their work as a  philosopher
pascal was known for their work as a  mathematician
goethe was known for their work as a  poet
plato was known for their work as a  philosopher
caesar was known for their work as a  emperor
pacino was known for their work as a 
2024-07-28 13:35:55 root INFO     [order_1_approx] starting weight calculation for confucius was known for their work as a  philosopher
pacino was known for their work as a  actor
goethe was known for their work as a  poet
moses was known for their work as a  prophet
plato was known for their work as a  philosopher
caesar was known for their work as a  emperor
pascal was known for their work as a  mathematician
mozart was known for their work as a 
2024-07-28 13:35:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 13:38:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0161, -0.0924, -0.1997,  ...,  0.3445, -0.3345, -0.0707],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0703, -4.9453,  1.7881,  ..., -2.3574,  0.8994,  0.0254],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0127, -0.0021,  0.0062,  ...,  0.0059, -0.0061, -0.0043],
        [-0.0011,  0.0166,  0.0022,  ...,  0.0097, -0.0043, -0.0051],
        [ 0.0135, -0.0031,  0.0345,  ..., -0.0096, -0.0005,  0.0010],
        ...,
        [ 0.0120, -0.0052, -0.0011,  ...,  0.0321,  0.0072,  0.0013],
        [ 0.0031,  0.0074,  0.0011,  ...,  0.0007,  0.0161,  0.0004],
        [-0.0086,  0.0027, -0.0045,  ...,  0.0083, -0.0098,  0.0176]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8750, -4.5391,  1.9062,  ..., -2.1289,  0.9863,  0.0961]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 13:38:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for confucius was known for their work as a  philosopher
pacino was known for their work as a  actor
goethe was known for their work as a  poet
moses was known for their work as a  prophet
plato was known for their work as a  philosopher
caesar was known for their work as a  emperor
pascal was known for their work as a  mathematician
mozart was known for their work as a 
2024-07-28 13:38:15 root INFO     [order_1_approx] starting weight calculation for pascal was known for their work as a  mathematician
plato was known for their work as a  philosopher
moses was known for their work as a  prophet
goethe was known for their work as a  poet
pacino was known for their work as a  actor
mozart was known for their work as a  composer
caesar was known for their work as a  emperor
confucius was known for their work as a 
2024-07-28 13:38:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 13:40:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0997, -0.3120, -0.9551,  ...,  0.2607, -0.1501,  0.1467],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1289, -4.6641,  4.1094,  ..., -6.9688, -0.1514,  0.6289],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0345,  0.0063,  0.0074,  ..., -0.0070, -0.0091,  0.0004],
        [-0.0044,  0.0338,  0.0044,  ..., -0.0063, -0.0105,  0.0028],
        [ 0.0078, -0.0105,  0.0337,  ...,  0.0008,  0.0006,  0.0038],
        ...,
        [ 0.0173,  0.0122, -0.0076,  ...,  0.0378, -0.0004, -0.0015],
        [-0.0039,  0.0044,  0.0028,  ..., -0.0004,  0.0157,  0.0021],
        [-0.0195,  0.0074,  0.0008,  ...,  0.0034, -0.0070,  0.0217]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2352, -4.7461,  3.8242,  ..., -6.7422, -0.0755,  0.9053]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 13:40:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for pascal was known for their work as a  mathematician
plato was known for their work as a  philosopher
moses was known for their work as a  prophet
goethe was known for their work as a  poet
pacino was known for their work as a  actor
mozart was known for their work as a  composer
caesar was known for their work as a  emperor
confucius was known for their work as a 
2024-07-28 13:40:36 root INFO     [order_1_approx] starting weight calculation for plato was known for their work as a  philosopher
moses was known for their work as a  prophet
confucius was known for their work as a  philosopher
caesar was known for their work as a  emperor
mozart was known for their work as a  composer
goethe was known for their work as a  poet
pacino was known for their work as a  actor
pascal was known for their work as a 
2024-07-28 13:40:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 13:42:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0756, -0.4138, -0.1525,  ..., -0.0103,  0.0558,  0.6650],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5938, -2.5234,  2.2539,  ..., -6.1250,  0.2197,  1.1426],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0695, -0.0184,  0.0098,  ..., -0.0044, -0.0119, -0.0048],
        [ 0.0237,  0.0588, -0.0118,  ...,  0.0118, -0.0051,  0.0241],
        [ 0.0225, -0.0134,  0.1074,  ..., -0.0031,  0.0198,  0.0083],
        ...,
        [ 0.0203,  0.0212, -0.0092,  ...,  0.0874,  0.0161, -0.0137],
        [-0.0063, -0.0039,  0.0168,  ...,  0.0262,  0.0390,  0.0168],
        [-0.0095,  0.0231, -0.0073,  ...,  0.0008, -0.0045,  0.0651]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4009, -2.5664,  2.5312,  ..., -6.0938,  0.3921,  1.1475]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 13:42:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for plato was known for their work as a  philosopher
moses was known for their work as a  prophet
confucius was known for their work as a  philosopher
caesar was known for their work as a  emperor
mozart was known for their work as a  composer
goethe was known for their work as a  poet
pacino was known for their work as a  actor
pascal was known for their work as a 
2024-07-28 13:42:50 root INFO     [order_1_approx] starting weight calculation for moses was known for their work as a  prophet
pacino was known for their work as a  actor
plato was known for their work as a  philosopher
confucius was known for their work as a  philosopher
mozart was known for their work as a  composer
goethe was known for their work as a  poet
pascal was known for their work as a  mathematician
caesar was known for their work as a 
2024-07-28 13:42:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 13:45:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2231, -0.1416, -0.4348,  ...,  0.3760, -0.6860,  0.4224],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.3232, -6.2891,  1.8496,  ..., -2.1367,  1.0117, -0.3115],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.5359e-02,  1.2341e-03,  5.7411e-04,  ..., -2.3556e-03,
         -1.4603e-02,  1.2871e-02],
        [-4.6768e-03,  4.2969e-02, -1.9836e-03,  ..., -4.5090e-03,
         -5.3024e-04,  9.4376e-03],
        [ 3.8361e-02, -2.7512e-02,  8.1177e-02,  ..., -2.1114e-03,
          1.4175e-02,  1.2459e-02],
        ...,
        [ 1.8585e-02,  1.6754e-02, -6.4468e-03,  ...,  9.6436e-02,
          2.4567e-03, -1.6327e-02],
        [-4.2839e-03,  1.2375e-02,  2.5955e-02,  ..., -3.9577e-05,
          3.1036e-02,  7.0992e-03],
        [-6.9771e-03,  7.0419e-03, -6.4125e-03,  ..., -4.3259e-03,
          1.2115e-02,  3.3081e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.0117, -6.1172,  1.7607,  ..., -2.3750,  1.0293, -0.4526]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 13:45:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for moses was known for their work as a  prophet
pacino was known for their work as a  actor
plato was known for their work as a  philosopher
confucius was known for their work as a  philosopher
mozart was known for their work as a  composer
goethe was known for their work as a  poet
pascal was known for their work as a  mathematician
caesar was known for their work as a 
2024-07-28 13:45:12 root INFO     [order_1_approx] starting weight calculation for goethe was known for their work as a  poet
pascal was known for their work as a  mathematician
mozart was known for their work as a  composer
moses was known for their work as a  prophet
pacino was known for their work as a  actor
caesar was known for their work as a  emperor
confucius was known for their work as a  philosopher
plato was known for their work as a 
2024-07-28 13:45:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 13:47:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1338, -0.2808, -0.3232,  ...,  0.2993,  0.0383,  0.2384],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6914, -5.5234,  2.3086,  ..., -6.1328, -1.0293, -0.5010],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.1321e-02,  3.8330e-02, -5.3635e-03,  ...,  1.7487e-02,
         -5.2643e-03, -2.4452e-03],
        [ 5.2567e-03,  7.8812e-03,  5.4436e-03,  ..., -3.5217e-02,
         -7.8201e-03,  7.1259e-03],
        [ 1.5411e-02,  1.9073e-06,  5.4504e-02,  ..., -8.0643e-03,
          8.6670e-03,  5.4321e-03],
        ...,
        [ 2.1698e-02, -3.4790e-02,  9.3307e-03,  ...,  2.8320e-02,
          1.3504e-02, -1.8616e-03],
        [ 9.4681e-03,  3.6987e-02, -3.4790e-03,  ...,  2.2186e-02,
          3.5461e-02,  1.4839e-03],
        [ 3.3264e-03, -2.9526e-03, -8.6594e-03,  ..., -1.7939e-03,
         -1.8890e-02,  4.3762e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5967, -5.4570,  2.3301,  ..., -6.0781, -0.8022, -0.5098]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 13:47:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for goethe was known for their work as a  poet
pascal was known for their work as a  mathematician
mozart was known for their work as a  composer
moses was known for their work as a  prophet
pacino was known for their work as a  actor
caesar was known for their work as a  emperor
confucius was known for their work as a  philosopher
plato was known for their work as a 
2024-07-28 13:47:35 root INFO     [order_1_approx] starting weight calculation for confucius was known for their work as a  philosopher
pacino was known for their work as a  actor
moses was known for their work as a  prophet
caesar was known for their work as a  emperor
plato was known for their work as a  philosopher
pascal was known for their work as a  mathematician
mozart was known for their work as a  composer
goethe was known for their work as a 
2024-07-28 13:47:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 13:49:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0486,  0.1389, -0.2239,  ...,  0.1471, -0.1118, -0.2351],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8447, -6.8125,  4.7188,  ..., -1.3975, -0.8843, -0.2881],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0470, -0.0055,  0.0165,  ..., -0.0010, -0.0148, -0.0052],
        [ 0.0130,  0.0567, -0.0042,  ...,  0.0017,  0.0006, -0.0078],
        [ 0.0228, -0.0085,  0.0645,  ..., -0.0016,  0.0022, -0.0022],
        ...,
        [ 0.0215,  0.0163, -0.0096,  ...,  0.0899,  0.0128, -0.0030],
        [ 0.0064,  0.0308,  0.0009,  ..., -0.0008,  0.0455, -0.0075],
        [-0.0289,  0.0067, -0.0054,  ...,  0.0129, -0.0189,  0.0652]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0645, -6.4648,  4.3477,  ..., -1.4922, -0.3970, -0.1973]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 13:49:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for confucius was known for their work as a  philosopher
pacino was known for their work as a  actor
moses was known for their work as a  prophet
caesar was known for their work as a  emperor
plato was known for their work as a  philosopher
pascal was known for their work as a  mathematician
mozart was known for their work as a  composer
goethe was known for their work as a 
2024-07-28 13:49:57 root INFO     [order_1_approx] starting weight calculation for confucius was known for their work as a  philosopher
plato was known for their work as a  philosopher
pascal was known for their work as a  mathematician
caesar was known for their work as a  emperor
goethe was known for their work as a  poet
mozart was known for their work as a  composer
pacino was known for their work as a  actor
moses was known for their work as a 
2024-07-28 13:49:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 13:52:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0837,  0.0292, -0.4395,  ...,  0.0536, -0.0676,  0.4839],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1064, -4.5781,  0.3081,  ..., -5.8164,  3.9043, -0.5410],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.7481e-02, -6.1302e-03,  7.6065e-03,  ..., -6.1455e-03,
         -1.1215e-02, -8.7738e-05],
        [ 9.4757e-03,  2.7222e-02, -2.6131e-03,  ..., -4.4727e-04,
          2.4738e-03, -3.3073e-03],
        [ 1.5930e-02,  5.4169e-04,  3.8177e-02,  ..., -1.6327e-02,
         -4.8294e-03, -4.7684e-04],
        ...,
        [ 2.4368e-02,  1.8570e-02,  7.5569e-03,  ...,  3.7109e-02,
          1.7195e-03,  8.2588e-04],
        [ 2.1362e-03,  1.7487e-02,  9.8038e-03,  ...,  9.8495e-03,
          2.2644e-02,  9.8343e-03],
        [-7.2365e-03,  1.4133e-03,  3.4809e-03,  ..., -3.5458e-03,
         -5.5923e-03,  2.2110e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0020, -4.5742,  0.4690,  ..., -5.7930,  3.7754, -0.3857]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 13:52:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for confucius was known for their work as a  philosopher
plato was known for their work as a  philosopher
pascal was known for their work as a  mathematician
caesar was known for their work as a  emperor
goethe was known for their work as a  poet
mozart was known for their work as a  composer
pacino was known for their work as a  actor
moses was known for their work as a 
2024-07-28 13:52:17 root INFO     total operator prediction time: 1122.461908340454 seconds
2024-07-28 13:52:17 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on male - female
2024-07-28 13:52:17 root INFO     building operator male - female
2024-07-28 13:52:17 root INFO     [order_1_approx] starting weight calculation for A female son is known as a daughter
A female ram is known as a ewe
A female father is known as a mother
A female headmaster is known as a headmistress
A female stepfather is known as a stepmother
A female hound is known as a bitch
A female manager is known as a manageress
A female batman is known as a
2024-07-28 13:52:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 13:54:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6650,  0.5361, -0.1587,  ..., -0.3367, -0.1578,  0.0862],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1797, -2.3926,  2.7051,  ..., -0.7178, -2.1055,  0.1611],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0538, -0.0308,  0.0117,  ...,  0.0396,  0.0047,  0.0006],
        [ 0.0201,  0.0640, -0.0194,  ..., -0.0067,  0.0211, -0.0064],
        [ 0.0121,  0.0323,  0.0721,  ..., -0.0044, -0.0133, -0.0172],
        ...,
        [ 0.0229,  0.0191, -0.0256,  ...,  0.0611, -0.0107,  0.0123],
        [-0.0292, -0.0055, -0.0220,  ...,  0.0043,  0.0312, -0.0002],
        [ 0.0137,  0.0154, -0.0006,  ..., -0.0182,  0.0112,  0.0454]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8086, -2.5625,  2.8242,  ..., -0.4990, -1.7100, -0.2375]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 13:54:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female son is known as a daughter
A female ram is known as a ewe
A female father is known as a mother
A female headmaster is known as a headmistress
A female stepfather is known as a stepmother
A female hound is known as a bitch
A female manager is known as a manageress
A female batman is known as a
2024-07-28 13:54:38 root INFO     [order_1_approx] starting weight calculation for A female batman is known as a batwoman
A female ram is known as a ewe
A female hound is known as a bitch
A female son is known as a daughter
A female manager is known as a manageress
A female headmaster is known as a headmistress
A female father is known as a mother
A female stepfather is known as a
2024-07-28 13:54:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 13:56:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6348,  0.5859,  0.4348,  ...,  0.0768, -0.6274,  0.0496],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9102, -0.6670, -1.7793,  ...,  0.9146, -2.0664,  0.1547],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0357, -0.0072,  0.0007,  ...,  0.0318, -0.0158,  0.0259],
        [ 0.0058,  0.0297,  0.0079,  ...,  0.0172,  0.0088,  0.0063],
        [ 0.0033, -0.0023,  0.0551,  ..., -0.0011, -0.0079,  0.0020],
        ...,
        [-0.0057, -0.0036, -0.0174,  ...,  0.0323,  0.0163, -0.0093],
        [ 0.0019, -0.0013,  0.0096,  ...,  0.0118,  0.0322, -0.0027],
        [-0.0129, -0.0065, -0.0049,  ..., -0.0170,  0.0059,  0.0322]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8965, -0.6572, -1.8643,  ...,  1.3350, -2.1621,  0.0846]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 13:56:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female batman is known as a batwoman
A female ram is known as a ewe
A female hound is known as a bitch
A female son is known as a daughter
A female manager is known as a manageress
A female headmaster is known as a headmistress
A female father is known as a mother
A female stepfather is known as a
2024-07-28 13:56:59 root INFO     [order_1_approx] starting weight calculation for A female hound is known as a bitch
A female stepfather is known as a stepmother
A female headmaster is known as a headmistress
A female son is known as a daughter
A female manager is known as a manageress
A female father is known as a mother
A female batman is known as a batwoman
A female ram is known as a
2024-07-28 13:56:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 13:59:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4355, -0.0687, -0.3176,  ...,  0.2710, -0.4170,  0.3672],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.2344, -2.2051,  0.8369,  ...,  2.6406, -3.1641, -1.4785],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0652, -0.0043, -0.0291,  ...,  0.0001,  0.0121, -0.0220],
        [ 0.0148,  0.0646,  0.0051,  ...,  0.0355,  0.0286, -0.0190],
        [-0.0034,  0.0010,  0.0738,  ..., -0.0198,  0.0013, -0.0434],
        ...,
        [-0.0212, -0.0072, -0.0031,  ...,  0.0580,  0.0092, -0.0371],
        [ 0.0432,  0.0208, -0.0263,  ..., -0.0406,  0.0285, -0.0235],
        [ 0.0104, -0.0337,  0.0026,  ..., -0.0321, -0.0058,  0.0388]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.6328, -1.9785,  0.5825,  ...,  2.9805, -3.5996, -1.4434]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 13:59:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female hound is known as a bitch
A female stepfather is known as a stepmother
A female headmaster is known as a headmistress
A female son is known as a daughter
A female manager is known as a manageress
A female father is known as a mother
A female batman is known as a batwoman
A female ram is known as a
2024-07-28 13:59:20 root INFO     [order_1_approx] starting weight calculation for A female manager is known as a manageress
A female batman is known as a batwoman
A female headmaster is known as a headmistress
A female hound is known as a bitch
A female stepfather is known as a stepmother
A female son is known as a daughter
A female ram is known as a ewe
A female father is known as a
2024-07-28 13:59:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 14:01:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4219,  0.4941, -0.0784,  ..., -0.2993, -0.4526,  0.1093],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.7656, -2.1113, -1.7520,  ...,  0.7598, -3.9766, -0.6802],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0379, -0.0190,  0.0179,  ...,  0.0164, -0.0002,  0.0241],
        [ 0.0008,  0.0422, -0.0040,  ...,  0.0166,  0.0057, -0.0144],
        [-0.0197, -0.0184,  0.0486,  ...,  0.0137, -0.0172,  0.0005],
        ...,
        [ 0.0097,  0.0096, -0.0159,  ...,  0.0308,  0.0092, -0.0146],
        [ 0.0177, -0.0033,  0.0113,  ...,  0.0103,  0.0195, -0.0102],
        [ 0.0209,  0.0015, -0.0149,  ..., -0.0283,  0.0145,  0.0140]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.5664, -2.1562, -1.6670,  ...,  1.1504, -3.5469,  0.1729]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 14:01:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female manager is known as a manageress
A female batman is known as a batwoman
A female headmaster is known as a headmistress
A female hound is known as a bitch
A female stepfather is known as a stepmother
A female son is known as a daughter
A female ram is known as a ewe
A female father is known as a
2024-07-28 14:01:40 root INFO     [order_1_approx] starting weight calculation for A female ram is known as a ewe
A female father is known as a mother
A female headmaster is known as a headmistress
A female stepfather is known as a stepmother
A female batman is known as a batwoman
A female son is known as a daughter
A female manager is known as a manageress
A female hound is known as a
2024-07-28 14:01:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 14:04:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3684,  0.3799,  0.0894,  ...,  0.0333, -0.3364,  0.0656],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0312, -6.1914, -0.8662,  ..., -0.2500, -3.3477,  3.3496],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0467,  0.0145,  0.0097,  ...,  0.0276, -0.0176,  0.0030],
        [-0.0176,  0.0684, -0.0163,  ..., -0.0133,  0.0524, -0.0258],
        [ 0.0057, -0.0023,  0.0607,  ..., -0.0205, -0.0299, -0.0498],
        ...,
        [-0.0039,  0.0095,  0.0107,  ...,  0.0401,  0.0117, -0.0019],
        [ 0.0332, -0.0046,  0.0035,  ...,  0.0143,  0.0116, -0.0309],
        [ 0.0033, -0.0226,  0.0093,  ..., -0.0011,  0.0048,  0.0558]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0703, -5.7656, -0.9229,  ..., -0.7607, -3.5566,  3.2402]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 14:04:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female ram is known as a ewe
A female father is known as a mother
A female headmaster is known as a headmistress
A female stepfather is known as a stepmother
A female batman is known as a batwoman
A female son is known as a daughter
A female manager is known as a manageress
A female hound is known as a
2024-07-28 14:04:01 root INFO     [order_1_approx] starting weight calculation for A female father is known as a mother
A female son is known as a daughter
A female batman is known as a batwoman
A female ram is known as a ewe
A female hound is known as a bitch
A female manager is known as a manageress
A female stepfather is known as a stepmother
A female headmaster is known as a
2024-07-28 14:04:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 14:06:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.8237,  0.8906, -0.2009,  ...,  0.0988, -0.5420, -0.0699],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.3906, -4.8203, -0.6680,  ..., -0.0845, -4.8750, -0.5146],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0527, -0.0211,  0.0184,  ...,  0.0195, -0.0124, -0.0086],
        [ 0.0192,  0.0284, -0.0012,  ...,  0.0013,  0.0237, -0.0203],
        [ 0.0080,  0.0030,  0.0480,  ...,  0.0011, -0.0155,  0.0035],
        ...,
        [-0.0007,  0.0094,  0.0038,  ...,  0.0381,  0.0139, -0.0076],
        [ 0.0048,  0.0220,  0.0171,  ..., -0.0023,  0.0225, -0.0212],
        [ 0.0042, -0.0013,  0.0007,  ..., -0.0123,  0.0073,  0.0439]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 6.3984, -4.6367, -0.7866,  ...,  0.3076, -5.1562, -0.3340]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 14:06:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female father is known as a mother
A female son is known as a daughter
A female batman is known as a batwoman
A female ram is known as a ewe
A female hound is known as a bitch
A female manager is known as a manageress
A female stepfather is known as a stepmother
A female headmaster is known as a
2024-07-28 14:06:24 root INFO     [order_1_approx] starting weight calculation for A female batman is known as a batwoman
A female hound is known as a bitch
A female manager is known as a manageress
A female ram is known as a ewe
A female father is known as a mother
A female headmaster is known as a headmistress
A female stepfather is known as a stepmother
A female son is known as a
2024-07-28 14:06:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 14:08:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2227,  0.6943,  0.2820,  ...,  0.1431,  0.1157, -0.0168],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.4141, -1.6348, -2.5254,  ...,  2.5312, -2.5312,  0.4453],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0443, -0.0370,  0.0149,  ..., -0.0065, -0.0110,  0.0228],
        [ 0.0219,  0.0532, -0.0065,  ...,  0.0033, -0.0022, -0.0438],
        [-0.0070, -0.0053,  0.0575,  ..., -0.0307, -0.0172, -0.0234],
        ...,
        [-0.0148, -0.0033, -0.0045,  ...,  0.0564, -0.0004, -0.0026],
        [ 0.0026,  0.0003,  0.0093,  ...,  0.0023,  0.0284,  0.0088],
        [ 0.0179,  0.0051, -0.0131,  ...,  0.0069, -0.0039,  0.0348]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.0820, -1.3516, -2.5625,  ...,  2.7559, -2.5176,  0.3057]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 14:08:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female batman is known as a batwoman
A female hound is known as a bitch
A female manager is known as a manageress
A female ram is known as a ewe
A female father is known as a mother
A female headmaster is known as a headmistress
A female stepfather is known as a stepmother
A female son is known as a
2024-07-28 14:08:44 root INFO     [order_1_approx] starting weight calculation for A female ram is known as a ewe
A female son is known as a daughter
A female headmaster is known as a headmistress
A female hound is known as a bitch
A female batman is known as a batwoman
A female stepfather is known as a stepmother
A female father is known as a mother
A female manager is known as a
2024-07-28 14:08:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 14:11:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4509,  0.2734, -0.2122,  ...,  0.3701, -0.4131, -0.4839],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.3906, -4.9102,  0.9434,  ...,  1.6240, -0.7964, -2.7676],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0700, -0.0274, -0.0157,  ...,  0.0153,  0.0157,  0.0172],
        [ 0.0126,  0.0778, -0.0146,  ...,  0.0068, -0.0068, -0.0288],
        [ 0.0122,  0.0044,  0.0773,  ..., -0.0215, -0.0246, -0.0084],
        ...,
        [ 0.0007,  0.0122,  0.0064,  ...,  0.0660,  0.0076, -0.0151],
        [ 0.0006,  0.0191,  0.0060,  ..., -0.0014,  0.0212, -0.0152],
        [ 0.0312, -0.0088, -0.0184,  ..., -0.0042,  0.0164,  0.0451]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.4570, -4.7344,  0.8115,  ...,  1.7773, -0.8506, -2.4961]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 14:11:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female ram is known as a ewe
A female son is known as a daughter
A female headmaster is known as a headmistress
A female hound is known as a bitch
A female batman is known as a batwoman
A female stepfather is known as a stepmother
A female father is known as a mother
A female manager is known as a
2024-07-28 14:11:04 root INFO     total operator prediction time: 1127.026820898056 seconds
2024-07-28 14:11:04 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - shelter
2024-07-28 14:11:04 root INFO     building operator animal - shelter
2024-07-28 14:11:04 root INFO     [order_1_approx] starting weight calculation for The place goldfish lives in is called pond
The place mole lives in is called hole
The place rat lives in is called nest
The place baboon lives in is called grove
The place wasp lives in is called nest
The place beaver lives in is called dam
The place mallard lives in is called nest
The place rabbit lives in is called
2024-07-28 14:11:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 14:13:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3450, -0.4246, -0.1378,  ...,  0.2275, -0.3479, -0.0222],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1602, -4.6094,  0.3008,  ..., -0.7920, -0.6230, -1.1152],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.4210e-02,  7.8011e-03, -7.4816e-04,  ...,  1.6022e-02,
         -4.8790e-03,  1.1311e-03],
        [-2.3651e-02,  3.0701e-02,  5.9986e-04,  ...,  7.2060e-03,
          5.0735e-04, -1.2749e-02],
        [-7.2021e-03,  1.2253e-02,  3.2532e-02,  ...,  9.4147e-03,
         -4.4365e-03,  1.8282e-03],
        ...,
        [ 4.5166e-03, -1.1017e-02,  6.7635e-03,  ...,  2.6886e-02,
          3.4275e-03, -1.1911e-03],
        [ 1.0857e-02,  6.9427e-03,  7.2241e-05,  ..., -5.0201e-03,
          1.9882e-02,  4.1046e-03],
        [ 2.1515e-03,  3.2310e-03, -4.0054e-03,  ..., -7.3891e-03,
         -2.1973e-02,  2.8320e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.1133, -4.6523,  0.2034,  ..., -0.8945, -0.5845, -1.1377]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 14:13:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place goldfish lives in is called pond
The place mole lives in is called hole
The place rat lives in is called nest
The place baboon lives in is called grove
The place wasp lives in is called nest
The place beaver lives in is called dam
The place mallard lives in is called nest
The place rabbit lives in is called
2024-07-28 14:13:27 root INFO     [order_1_approx] starting weight calculation for The place rabbit lives in is called burrow
The place goldfish lives in is called pond
The place mole lives in is called hole
The place rat lives in is called nest
The place wasp lives in is called nest
The place baboon lives in is called grove
The place mallard lives in is called nest
The place beaver lives in is called
2024-07-28 14:13:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 14:15:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5718, -0.4219,  0.1208,  ...,  0.2305, -0.3464,  0.2751],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2266, -5.7422, -2.2773,  ..., -2.4121, -0.1650, -0.3398],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0674, -0.0189, -0.0167,  ...,  0.0253, -0.0275, -0.0357],
        [-0.0056,  0.0611,  0.0024,  ...,  0.0148,  0.0010, -0.0220],
        [ 0.0018,  0.0063,  0.0539,  ..., -0.0156, -0.0255, -0.0100],
        ...,
        [-0.0046,  0.0234,  0.0220,  ...,  0.0673,  0.0022,  0.0020],
        [ 0.0180, -0.0047,  0.0253,  ...,  0.0195,  0.0457, -0.0233],
        [ 0.0064, -0.0069, -0.0210,  ..., -0.0127, -0.0264,  0.0613]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0801, -5.5781, -2.4043,  ..., -2.2539, -0.5791,  0.1167]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 14:15:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place rabbit lives in is called burrow
The place goldfish lives in is called pond
The place mole lives in is called hole
The place rat lives in is called nest
The place wasp lives in is called nest
The place baboon lives in is called grove
The place mallard lives in is called nest
The place beaver lives in is called
2024-07-28 14:15:49 root INFO     [order_1_approx] starting weight calculation for The place rabbit lives in is called burrow
The place baboon lives in is called grove
The place rat lives in is called nest
The place goldfish lives in is called pond
The place beaver lives in is called dam
The place mole lives in is called hole
The place mallard lives in is called nest
The place wasp lives in is called
2024-07-28 14:15:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 14:18:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2423, -0.7144,  0.0837,  ...,  0.7212, -0.0816,  0.1177],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9473, -4.0273,  3.2188,  ..., -1.9004, -0.5840,  0.2021],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0444, -0.0082, -0.0161,  ...,  0.0288, -0.0082,  0.0139],
        [-0.0197,  0.0537,  0.0337,  ...,  0.0196,  0.0004, -0.0174],
        [-0.0073,  0.0241,  0.0757,  ...,  0.0130, -0.0378,  0.0067],
        ...,
        [-0.0023,  0.0006,  0.0241,  ...,  0.0534,  0.0188, -0.0214],
        [ 0.0021,  0.0097, -0.0140,  ...,  0.0293, -0.0021,  0.0073],
        [-0.0228, -0.0151, -0.0211,  ...,  0.0074, -0.0171,  0.0489]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.5078, -4.1445,  3.0938,  ..., -2.0723, -0.3752,  0.8657]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 14:18:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place rabbit lives in is called burrow
The place baboon lives in is called grove
The place rat lives in is called nest
The place goldfish lives in is called pond
The place beaver lives in is called dam
The place mole lives in is called hole
The place mallard lives in is called nest
The place wasp lives in is called
2024-07-28 14:18:12 root INFO     [order_1_approx] starting weight calculation for The place baboon lives in is called grove
The place rabbit lives in is called burrow
The place beaver lives in is called dam
The place mole lives in is called hole
The place wasp lives in is called nest
The place mallard lives in is called nest
The place goldfish lives in is called pond
The place rat lives in is called
2024-07-28 14:18:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 14:20:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1543, -0.4807,  0.1250,  ..., -0.0293, -0.2676,  0.0400],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9453, -3.8027,  3.2578,  ..., -0.6191, -0.7622, -0.1934],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0692, -0.0088, -0.0040,  ...,  0.0224, -0.0284, -0.0078],
        [-0.0352,  0.0667,  0.0033,  ..., -0.0128,  0.0072, -0.0168],
        [-0.0103,  0.0255,  0.0654,  ..., -0.0249, -0.0055,  0.0276],
        ...,
        [-0.0025, -0.0165,  0.0057,  ...,  0.0460,  0.0178, -0.0174],
        [ 0.0270,  0.0041, -0.0210,  ...,  0.0133,  0.0446,  0.0146],
        [ 0.0025,  0.0198, -0.0188,  ..., -0.0050, -0.0297,  0.0443]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4160, -3.3359,  2.7676,  ..., -0.7266, -1.0059, -0.2048]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 14:20:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place baboon lives in is called grove
The place rabbit lives in is called burrow
The place beaver lives in is called dam
The place mole lives in is called hole
The place wasp lives in is called nest
The place mallard lives in is called nest
The place goldfish lives in is called pond
The place rat lives in is called
2024-07-28 14:20:35 root INFO     [order_1_approx] starting weight calculation for The place beaver lives in is called dam
The place rat lives in is called nest
The place goldfish lives in is called pond
The place baboon lives in is called grove
The place rabbit lives in is called burrow
The place mallard lives in is called nest
The place wasp lives in is called nest
The place mole lives in is called
2024-07-28 14:20:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 14:22:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6748, -0.3572,  0.1260,  ...,  0.0967, -0.4390,  0.0914],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7812, -0.5801,  2.0703,  ..., -1.7363, -0.0621,  0.6094],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0776, -0.0200, -0.0028,  ...,  0.0436, -0.0069,  0.0159],
        [ 0.0010,  0.0576,  0.0215,  ...,  0.0150,  0.0120, -0.0238],
        [-0.0112, -0.0088,  0.0753,  ..., -0.0048,  0.0025,  0.0053],
        ...,
        [ 0.0044,  0.0162,  0.0006,  ...,  0.0537,  0.0108,  0.0132],
        [ 0.0057, -0.0067,  0.0028,  ...,  0.0133,  0.0311,  0.0226],
        [-0.0012,  0.0106, -0.0062,  ..., -0.0044, -0.0204,  0.0568]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2715, -0.5400,  1.9316,  ..., -2.2383,  0.0665,  0.1128]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 14:22:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place beaver lives in is called dam
The place rat lives in is called nest
The place goldfish lives in is called pond
The place baboon lives in is called grove
The place rabbit lives in is called burrow
The place mallard lives in is called nest
The place wasp lives in is called nest
The place mole lives in is called
2024-07-28 14:22:52 root INFO     [order_1_approx] starting weight calculation for The place rat lives in is called nest
The place goldfish lives in is called pond
The place mole lives in is called hole
The place wasp lives in is called nest
The place rabbit lives in is called burrow
The place beaver lives in is called dam
The place mallard lives in is called nest
The place baboon lives in is called
2024-07-28 14:22:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 14:25:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5176, -0.3982,  0.0667,  ...,  0.5474, -0.8506,  0.2124],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.7773, -4.1953, -0.1934,  ...,  0.1904, -1.9785, -0.8477],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0261,  0.0090, -0.0478,  ...,  0.0185,  0.0041,  0.0044],
        [-0.0273,  0.0447,  0.0287,  ...,  0.0414,  0.0060, -0.0199],
        [-0.0195,  0.0129,  0.0495,  ..., -0.0110, -0.0213, -0.0076],
        ...,
        [-0.0053,  0.0057,  0.0424,  ...,  0.0709,  0.0132,  0.0066],
        [ 0.0083, -0.0040, -0.0077,  ..., -0.0089,  0.0197,  0.0021],
        [-0.0056,  0.0217, -0.0314,  ..., -0.0098, -0.0098,  0.0698]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.7148, -4.0703, -0.7891,  ...,  0.4106, -2.0430, -0.9219]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 14:25:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place rat lives in is called nest
The place goldfish lives in is called pond
The place mole lives in is called hole
The place wasp lives in is called nest
The place rabbit lives in is called burrow
The place beaver lives in is called dam
The place mallard lives in is called nest
The place baboon lives in is called
2024-07-28 14:25:12 root INFO     [order_1_approx] starting weight calculation for The place beaver lives in is called dam
The place wasp lives in is called nest
The place mole lives in is called hole
The place goldfish lives in is called pond
The place rabbit lives in is called burrow
The place baboon lives in is called grove
The place rat lives in is called nest
The place mallard lives in is called
2024-07-28 14:25:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 14:27:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2554, -0.1306, -0.4702,  ...,  0.4497, -0.3311, -0.1899],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7324, -6.9844,  0.5557,  ..., -0.5664, -1.7725,  0.3711],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0209, -0.0072, -0.0311,  ...,  0.0103, -0.0088,  0.0010],
        [ 0.0007,  0.0525,  0.0065,  ..., -0.0134, -0.0083, -0.0417],
        [-0.0018, -0.0026,  0.0390,  ...,  0.0097, -0.0058, -0.0303],
        ...,
        [ 0.0068,  0.0049,  0.0285,  ...,  0.0662,  0.0249, -0.0029],
        [ 0.0218,  0.0148,  0.0073,  ...,  0.0085,  0.0339, -0.0044],
        [-0.0171, -0.0003,  0.0001,  ..., -0.0084, -0.0076,  0.0410]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9199, -6.6641,  0.4087,  ..., -0.7734, -1.9658, -0.0276]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 14:27:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place beaver lives in is called dam
The place wasp lives in is called nest
The place mole lives in is called hole
The place goldfish lives in is called pond
The place rabbit lives in is called burrow
The place baboon lives in is called grove
The place rat lives in is called nest
The place mallard lives in is called
2024-07-28 14:27:35 root INFO     [order_1_approx] starting weight calculation for The place mole lives in is called hole
The place beaver lives in is called dam
The place mallard lives in is called nest
The place baboon lives in is called grove
The place wasp lives in is called nest
The place rat lives in is called nest
The place rabbit lives in is called burrow
The place goldfish lives in is called
2024-07-28 14:27:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 14:29:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4922, -0.3555, -0.2266,  ...,  0.3923, -0.6060,  0.4504],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2773, -2.9961, -0.7402,  ..., -2.8047, -1.9023, -0.3564],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0689,  0.0077, -0.0121,  ...,  0.0124, -0.0476, -0.0011],
        [ 0.0066,  0.0487, -0.0198,  ..., -0.0022,  0.0076, -0.0047],
        [ 0.0041, -0.0128,  0.0625,  ...,  0.0094, -0.0200,  0.0013],
        ...,
        [-0.0195,  0.0190,  0.0094,  ...,  0.0326,  0.0059, -0.0179],
        [ 0.0085,  0.0095,  0.0040,  ...,  0.0340,  0.0575, -0.0007],
        [-0.0059,  0.0026, -0.0065,  ..., -0.0134,  0.0031,  0.0520]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9434, -3.2559, -0.8164,  ..., -2.5859, -2.4102, -0.9482]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 14:29:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place mole lives in is called hole
The place beaver lives in is called dam
The place mallard lives in is called nest
The place baboon lives in is called grove
The place wasp lives in is called nest
The place rat lives in is called nest
The place rabbit lives in is called burrow
The place goldfish lives in is called
2024-07-28 14:29:57 root INFO     total operator prediction time: 1133.165090560913 seconds
2024-07-28 14:29:57 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on country - language
2024-07-28 14:29:57 root INFO     building operator country - language
2024-07-28 14:29:58 root INFO     [order_1_approx] starting weight calculation for The country of ireland primarily speaks the language of english
The country of guyana primarily speaks the language of english
The country of netherlands primarily speaks the language of dutch
The country of argentina primarily speaks the language of spanish
The country of iran primarily speaks the language of persian
The country of moldova primarily speaks the language of moldovan
The country of chile primarily speaks the language of spanish
The country of israel primarily speaks the language of
2024-07-28 14:29:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 14:32:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2253,  0.0413,  0.0074,  ...,  0.3909, -0.1302,  0.4326],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.9385, -5.0977,  1.8184,  ..., -3.5430, -0.4590, -3.1855],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0325, -0.0136,  0.0074,  ..., -0.0020, -0.0007, -0.0251],
        [-0.0024,  0.0195,  0.0091,  ..., -0.0033,  0.0068, -0.0101],
        [-0.0077,  0.0033,  0.0551,  ..., -0.0011,  0.0025, -0.0050],
        ...,
        [-0.0125,  0.0024,  0.0029,  ...,  0.0266,  0.0207,  0.0053],
        [ 0.0158, -0.0085,  0.0015,  ...,  0.0028,  0.0183, -0.0189],
        [-0.0011, -0.0057, -0.0039,  ...,  0.0139, -0.0111,  0.0303]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.8408, -4.6289,  1.7432,  ..., -3.4570, -0.4224, -3.1230]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 14:32:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of ireland primarily speaks the language of english
The country of guyana primarily speaks the language of english
The country of netherlands primarily speaks the language of dutch
The country of argentina primarily speaks the language of spanish
The country of iran primarily speaks the language of persian
The country of moldova primarily speaks the language of moldovan
The country of chile primarily speaks the language of spanish
The country of israel primarily speaks the language of
2024-07-28 14:32:19 root INFO     [order_1_approx] starting weight calculation for The country of netherlands primarily speaks the language of dutch
The country of israel primarily speaks the language of hebrew
The country of ireland primarily speaks the language of english
The country of chile primarily speaks the language of spanish
The country of argentina primarily speaks the language of spanish
The country of iran primarily speaks the language of persian
The country of guyana primarily speaks the language of english
The country of moldova primarily speaks the language of
2024-07-28 14:32:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 14:34:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6362, -0.2234, -0.2886,  ...,  0.3936, -0.2239, -0.1166],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.3359, -4.7578, -0.3589,  ..., -4.3477, -0.3164, -1.9863],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0285, -0.0087, -0.0157,  ...,  0.0059, -0.0020, -0.0247],
        [-0.0016,  0.0314,  0.0108,  ..., -0.0006, -0.0013, -0.0103],
        [-0.0088, -0.0059,  0.0357,  ...,  0.0164, -0.0085,  0.0085],
        ...,
        [-0.0014,  0.0006, -0.0161,  ...,  0.0177,  0.0129,  0.0068],
        [ 0.0080, -0.0033,  0.0176,  ...,  0.0042,  0.0078, -0.0011],
        [ 0.0072, -0.0063,  0.0012,  ...,  0.0011, -0.0032,  0.0016]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.1797, -4.8164, -0.4092,  ..., -4.1797, -0.4219, -2.0195]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 14:34:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of netherlands primarily speaks the language of dutch
The country of israel primarily speaks the language of hebrew
The country of ireland primarily speaks the language of english
The country of chile primarily speaks the language of spanish
The country of argentina primarily speaks the language of spanish
The country of iran primarily speaks the language of persian
The country of guyana primarily speaks the language of english
The country of moldova primarily speaks the language of
2024-07-28 14:34:38 root INFO     [order_1_approx] starting weight calculation for The country of chile primarily speaks the language of spanish
The country of netherlands primarily speaks the language of dutch
The country of moldova primarily speaks the language of moldovan
The country of argentina primarily speaks the language of spanish
The country of ireland primarily speaks the language of english
The country of israel primarily speaks the language of hebrew
The country of iran primarily speaks the language of persian
The country of guyana primarily speaks the language of
2024-07-28 14:34:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 14:36:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1475, -0.0554,  0.2937,  ...,  0.3154, -0.7109,  0.1107],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7490, -0.3164,  1.9883,  ...,  0.9868,  0.4688, -3.0918],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0247,  0.0059, -0.0194,  ...,  0.0007, -0.0127, -0.0112],
        [ 0.0038,  0.0332,  0.0063,  ..., -0.0048, -0.0022, -0.0176],
        [-0.0066,  0.0052,  0.0450,  ...,  0.0156,  0.0050,  0.0156],
        ...,
        [-0.0092, -0.0080, -0.0042,  ...,  0.0249, -0.0005,  0.0116],
        [ 0.0101,  0.0071, -0.0136,  ..., -0.0090,  0.0231, -0.0180],
        [ 0.0212, -0.0049,  0.0026,  ..., -0.0007,  0.0017,  0.0219]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5078, -0.3662,  1.8633,  ...,  0.7207,  0.5488, -2.7559]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 14:36:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of chile primarily speaks the language of spanish
The country of netherlands primarily speaks the language of dutch
The country of moldova primarily speaks the language of moldovan
The country of argentina primarily speaks the language of spanish
The country of ireland primarily speaks the language of english
The country of israel primarily speaks the language of hebrew
The country of iran primarily speaks the language of persian
The country of guyana primarily speaks the language of
2024-07-28 14:36:59 root INFO     [order_1_approx] starting weight calculation for The country of israel primarily speaks the language of hebrew
The country of chile primarily speaks the language of spanish
The country of netherlands primarily speaks the language of dutch
The country of argentina primarily speaks the language of spanish
The country of ireland primarily speaks the language of english
The country of guyana primarily speaks the language of english
The country of moldova primarily speaks the language of moldovan
The country of iran primarily speaks the language of
2024-07-28 14:36:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 14:39:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2421,  0.3101,  0.1974,  ...,  0.0242, -0.0642,  0.3145],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4209, -4.8203,  0.9434,  ...,  0.7163, -1.1914, -3.8008],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0215, -0.0088, -0.0047,  ...,  0.0069, -0.0031, -0.0020],
        [ 0.0029,  0.0338,  0.0268,  ...,  0.0065,  0.0051, -0.0107],
        [-0.0112,  0.0009,  0.0522,  ...,  0.0006,  0.0135,  0.0045],
        ...,
        [-0.0012,  0.0113,  0.0049,  ...,  0.0345,  0.0101,  0.0046],
        [ 0.0059, -0.0049,  0.0031,  ..., -0.0078,  0.0332, -0.0085],
        [-0.0038, -0.0050, -0.0135,  ...,  0.0106, -0.0056,  0.0235]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2627, -4.4336,  0.7920,  ...,  0.8516, -1.1494, -3.7383]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 14:39:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of israel primarily speaks the language of hebrew
The country of chile primarily speaks the language of spanish
The country of netherlands primarily speaks the language of dutch
The country of argentina primarily speaks the language of spanish
The country of ireland primarily speaks the language of english
The country of guyana primarily speaks the language of english
The country of moldova primarily speaks the language of moldovan
The country of iran primarily speaks the language of
2024-07-28 14:39:20 root INFO     [order_1_approx] starting weight calculation for The country of netherlands primarily speaks the language of dutch
The country of israel primarily speaks the language of hebrew
The country of ireland primarily speaks the language of english
The country of guyana primarily speaks the language of english
The country of argentina primarily speaks the language of spanish
The country of iran primarily speaks the language of persian
The country of moldova primarily speaks the language of moldovan
The country of chile primarily speaks the language of
2024-07-28 14:39:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 14:41:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0350, -0.0525, -0.4568,  ...,  0.4207, -0.1245, -0.0657],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3130, -2.6875,  2.6406,  ...,  0.3357, -1.6689, -2.6699],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.0131e-02,  4.2915e-03, -4.8981e-03,  ...,  2.6474e-03,
          2.8458e-03, -2.3102e-02],
        [ 6.4163e-03,  3.3722e-02,  1.3062e-02,  ...,  6.1378e-03,
         -1.0284e-02, -1.4858e-03],
        [-1.1597e-02, -7.4234e-03,  3.2104e-02,  ...,  2.1698e-02,
          1.3657e-02,  1.6312e-02],
        ...,
        [-2.6428e-02,  7.8506e-03,  1.1902e-02,  ...,  3.1677e-02,
          1.6571e-02,  2.0203e-02],
        [ 2.3926e-02, -3.0479e-03, -6.4850e-04,  ...,  7.3624e-04,
          1.6830e-02, -2.0721e-02],
        [-5.8632e-03, -1.2497e-02, -2.8343e-03,  ..., -9.9106e-03,
          3.3855e-05,  1.4633e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2224, -2.6270,  2.3926,  ...,  0.2222, -1.6445, -2.6270]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 14:41:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of netherlands primarily speaks the language of dutch
The country of israel primarily speaks the language of hebrew
The country of ireland primarily speaks the language of english
The country of guyana primarily speaks the language of english
The country of argentina primarily speaks the language of spanish
The country of iran primarily speaks the language of persian
The country of moldova primarily speaks the language of moldovan
The country of chile primarily speaks the language of
2024-07-28 14:41:42 root INFO     [order_1_approx] starting weight calculation for The country of chile primarily speaks the language of spanish
The country of argentina primarily speaks the language of spanish
The country of guyana primarily speaks the language of english
The country of israel primarily speaks the language of hebrew
The country of iran primarily speaks the language of persian
The country of moldova primarily speaks the language of moldovan
The country of ireland primarily speaks the language of english
The country of netherlands primarily speaks the language of
2024-07-28 14:41:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 14:44:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([0.3535, 0.0908, 0.1095,  ..., 0.4336, 0.0433, 0.0558], device='cuda:1',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1318, -3.1172,  2.0234,  ..., -0.4976, -1.3691, -3.4355],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0319,  0.0016, -0.0018,  ...,  0.0072,  0.0024, -0.0183],
        [ 0.0017,  0.0254,  0.0206,  ...,  0.0070, -0.0022, -0.0100],
        [-0.0124, -0.0043,  0.0440,  ...,  0.0118,  0.0173,  0.0124],
        ...,
        [-0.0246, -0.0149, -0.0012,  ...,  0.0255,  0.0083, -0.0025],
        [ 0.0016, -0.0107,  0.0021,  ...,  0.0075,  0.0268, -0.0160],
        [-0.0008, -0.0106, -0.0045,  ...,  0.0047, -0.0053,  0.0252]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0860, -3.0410,  1.9600,  ..., -0.5098, -1.0938, -3.4238]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 14:44:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of chile primarily speaks the language of spanish
The country of argentina primarily speaks the language of spanish
The country of guyana primarily speaks the language of english
The country of israel primarily speaks the language of hebrew
The country of iran primarily speaks the language of persian
The country of moldova primarily speaks the language of moldovan
The country of ireland primarily speaks the language of english
The country of netherlands primarily speaks the language of
2024-07-28 14:44:04 root INFO     [order_1_approx] starting weight calculation for The country of guyana primarily speaks the language of english
The country of iran primarily speaks the language of persian
The country of ireland primarily speaks the language of english
The country of moldova primarily speaks the language of moldovan
The country of chile primarily speaks the language of spanish
The country of israel primarily speaks the language of hebrew
The country of netherlands primarily speaks the language of dutch
The country of argentina primarily speaks the language of
2024-07-28 14:44:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 14:46:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2681, -0.1278, -0.1351,  ...,  0.3525, -0.2991, -0.0091],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7812, -3.5586,  0.8945,  ...,  1.3242,  0.0117, -2.4648],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0244, -0.0122, -0.0061,  ...,  0.0005, -0.0074, -0.0173],
        [ 0.0021,  0.0107,  0.0140,  ...,  0.0058, -0.0084, -0.0092],
        [-0.0055,  0.0066,  0.0286,  ...,  0.0108,  0.0150,  0.0104],
        ...,
        [-0.0091,  0.0039,  0.0080,  ...,  0.0217,  0.0127,  0.0159],
        [ 0.0173, -0.0114, -0.0030,  ..., -0.0009,  0.0148, -0.0128],
        [ 0.0035, -0.0094, -0.0081,  ...,  0.0022,  0.0014,  0.0079]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7998, -3.5801,  0.6729,  ...,  1.2441,  0.1113, -2.3926]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 14:46:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of guyana primarily speaks the language of english
The country of iran primarily speaks the language of persian
The country of ireland primarily speaks the language of english
The country of moldova primarily speaks the language of moldovan
The country of chile primarily speaks the language of spanish
The country of israel primarily speaks the language of hebrew
The country of netherlands primarily speaks the language of dutch
The country of argentina primarily speaks the language of
2024-07-28 14:46:25 root INFO     [order_1_approx] starting weight calculation for The country of netherlands primarily speaks the language of dutch
The country of chile primarily speaks the language of spanish
The country of israel primarily speaks the language of hebrew
The country of guyana primarily speaks the language of english
The country of argentina primarily speaks the language of spanish
The country of moldova primarily speaks the language of moldovan
The country of iran primarily speaks the language of persian
The country of ireland primarily speaks the language of
2024-07-28 14:46:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 14:48:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1348, -0.0176, -0.1069,  ...,  0.3140,  0.1667,  0.2006],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6729, -2.6719,  0.7617,  ...,  1.3174, -0.1084, -3.2363],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.3274e-02,  3.1204e-03,  8.7662e-03,  ...,  1.3496e-02,
         -1.7303e-02, -2.0538e-02],
        [ 2.1496e-03,  3.9520e-02,  1.6022e-02,  ..., -5.4169e-03,
         -8.1787e-03, -3.2997e-03],
        [-1.1177e-02,  1.7868e-02,  4.7119e-02,  ...,  1.2115e-02,
          5.2757e-03,  5.3673e-03],
        ...,
        [-2.8931e-02,  9.9792e-03,  7.9346e-04,  ...,  2.9266e-02,
          2.9182e-03,  1.8723e-02],
        [ 8.5297e-03, -1.1902e-03,  5.0545e-03,  ...,  9.6741e-03,
          2.6352e-02, -4.5700e-03],
        [-3.0518e-05, -2.0905e-02, -1.7405e-03,  ...,  1.7033e-03,
          2.4452e-03,  1.7670e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5864, -2.6289,  0.5615,  ...,  1.1455, -0.1708, -3.0977]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 14:48:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of netherlands primarily speaks the language of dutch
The country of chile primarily speaks the language of spanish
The country of israel primarily speaks the language of hebrew
The country of guyana primarily speaks the language of english
The country of argentina primarily speaks the language of spanish
The country of moldova primarily speaks the language of moldovan
The country of iran primarily speaks the language of persian
The country of ireland primarily speaks the language of
2024-07-28 14:48:45 root INFO     total operator prediction time: 1127.3205955028534 seconds
2024-07-28 14:48:45 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on name - nationality
2024-07-28 14:48:45 root INFO     building operator name - nationality
2024-07-28 14:48:45 root INFO     [order_1_approx] starting weight calculation for hegel was german
locke was english
beethoven was german
lenin was soviet
aristotle was greek
stalin was soviet
mencius was chinese
edison was
2024-07-28 14:48:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 14:51:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1511,  0.4116, -0.2196,  ...,  0.0343,  0.0008,  0.1417],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7227, -4.1875,  0.3945,  ..., -3.4531,  1.2803, -2.1094],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0638,  0.0125,  0.0046,  ...,  0.0125, -0.0103, -0.0221],
        [ 0.0128,  0.0511,  0.0171,  ...,  0.0007,  0.0257, -0.0164],
        [-0.0189,  0.0025,  0.0468,  ...,  0.0247,  0.0023,  0.0303],
        ...,
        [ 0.0112,  0.0089, -0.0242,  ...,  0.0706, -0.0032,  0.0079],
        [-0.0039,  0.0004, -0.0149,  ...,  0.0220,  0.0559,  0.0106],
        [-0.0117,  0.0096, -0.0095,  ...,  0.0068, -0.0198,  0.0789]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0566, -4.2578,  0.4807,  ..., -2.9453,  1.3125, -1.6855]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 14:51:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for hegel was german
locke was english
beethoven was german
lenin was soviet
aristotle was greek
stalin was soviet
mencius was chinese
edison was
2024-07-28 14:51:06 root INFO     [order_1_approx] starting weight calculation for aristotle was greek
locke was english
hegel was german
stalin was soviet
edison was american
lenin was soviet
mencius was chinese
beethoven was
2024-07-28 14:51:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 14:53:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1558, -0.2754, -0.4033,  ...,  0.1688, -0.2744, -0.0756],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2695, -7.0508, -0.9771,  ..., -2.6680, -0.4092, -2.1211],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0630,  0.0140, -0.0198,  ..., -0.0305,  0.0187, -0.0079],
        [ 0.0132,  0.0497,  0.0495,  ...,  0.0101, -0.0209, -0.0279],
        [-0.0075, -0.0099,  0.0491,  ...,  0.0017,  0.0104,  0.0257],
        ...,
        [ 0.0160,  0.0090,  0.0072,  ...,  0.0593, -0.0110, -0.0192],
        [ 0.0065,  0.0195, -0.0011,  ...,  0.0073,  0.0426, -0.0071],
        [-0.0272,  0.0001,  0.0142,  ...,  0.0007, -0.0132,  0.0386]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2383, -6.9922, -1.0234,  ..., -2.6660, -0.4146, -2.2363]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 14:53:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for aristotle was greek
locke was english
hegel was german
stalin was soviet
edison was american
lenin was soviet
mencius was chinese
beethoven was
2024-07-28 14:53:28 root INFO     [order_1_approx] starting weight calculation for aristotle was greek
hegel was german
edison was american
stalin was soviet
beethoven was german
lenin was soviet
locke was english
mencius was
2024-07-28 14:53:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 14:55:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0106,  0.0093, -0.3728,  ...,  0.4517, -0.1423,  0.3599],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4199, -1.7646,  1.7930,  ..., -5.3086,  0.1699,  1.9824],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0605,  0.0196,  0.0055,  ..., -0.0169, -0.0191, -0.0151],
        [ 0.0107,  0.0526,  0.0210,  ..., -0.0098, -0.0015, -0.0137],
        [-0.0048,  0.0103,  0.0323,  ..., -0.0027,  0.0100,  0.0468],
        ...,
        [ 0.0284, -0.0107,  0.0032,  ...,  0.0227,  0.0027, -0.0683],
        [-0.0071,  0.0083, -0.0051,  ..., -0.0152,  0.0550,  0.0166],
        [-0.0172,  0.0064, -0.0274,  ...,  0.0366, -0.0182,  0.0818]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3018, -1.9219,  1.3369,  ..., -4.8125, -0.0424,  2.0586]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 14:55:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for aristotle was greek
hegel was german
edison was american
stalin was soviet
beethoven was german
lenin was soviet
locke was english
mencius was
2024-07-28 14:55:50 root INFO     [order_1_approx] starting weight calculation for stalin was soviet
locke was english
edison was american
beethoven was german
aristotle was greek
mencius was chinese
lenin was soviet
hegel was
2024-07-28 14:55:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 14:58:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1026,  0.2998,  0.1021,  ...,  0.4053,  0.2681, -0.0155],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8613, -5.1289,  0.4219,  ..., -2.9414, -1.5303, -0.5498],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0521, -0.0131, -0.0183,  ..., -0.0139,  0.0034, -0.0022],
        [-0.0148,  0.0422,  0.0179,  ...,  0.0066,  0.0016, -0.0169],
        [ 0.0176, -0.0001,  0.0601,  ..., -0.0183,  0.0089,  0.0146],
        ...,
        [ 0.0071,  0.0135,  0.0139,  ...,  0.0699,  0.0003,  0.0107],
        [ 0.0124,  0.0056, -0.0323,  ..., -0.0140,  0.0540, -0.0174],
        [-0.0021,  0.0011,  0.0062,  ..., -0.0025, -0.0053,  0.0580]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7119, -4.8594,  0.3062,  ..., -2.8555, -1.2959, -0.7495]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 14:58:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for stalin was soviet
locke was english
edison was american
beethoven was german
aristotle was greek
mencius was chinese
lenin was soviet
hegel was
2024-07-28 14:58:11 root INFO     [order_1_approx] starting weight calculation for aristotle was greek
lenin was soviet
beethoven was german
locke was english
edison was american
mencius was chinese
hegel was german
stalin was
2024-07-28 14:58:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 15:00:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1957, -0.6431, -0.2996,  ...,  0.3936, -0.1312,  0.2096],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4902, -3.5234, -0.5098,  ..., -4.6328,  1.0391, -0.3374],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.5267e-02,  3.1185e-03, -4.8981e-03,  ...,  6.9466e-03,
          3.8795e-03,  1.0742e-02],
        [-5.3139e-03,  4.2114e-02,  2.7557e-02,  ...,  9.1171e-03,
         -1.5144e-03, -2.1851e-02],
        [ 1.3130e-02, -2.3289e-03,  4.8706e-02,  ..., -1.3618e-03,
          1.9257e-02,  1.9028e-02],
        ...,
        [ 1.6384e-03, -9.5367e-06, -1.1536e-02,  ...,  7.7148e-02,
         -1.2222e-02, -4.5624e-03],
        [ 3.0746e-03,  1.6724e-02, -4.0588e-03,  ...,  2.2964e-03,
          3.9185e-02, -7.0572e-03],
        [-9.7198e-03,  1.3962e-02, -9.1553e-05,  ...,  7.8888e-03,
         -1.8799e-02,  4.2358e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4922, -3.8965, -0.4587,  ..., -4.9414,  1.1914, -0.0442]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 15:00:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for aristotle was greek
lenin was soviet
beethoven was german
locke was english
edison was american
mencius was chinese
hegel was german
stalin was
2024-07-28 15:00:32 root INFO     [order_1_approx] starting weight calculation for stalin was soviet
lenin was soviet
edison was american
mencius was chinese
hegel was german
locke was english
beethoven was german
aristotle was
2024-07-28 15:00:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 15:02:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0583, -0.3591, -0.6958,  ...,  0.1394, -0.3848, -0.0337],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3984, -5.6328, -1.1465,  ..., -4.2500, -0.6035, -0.8408],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0556,  0.0080, -0.0023,  ..., -0.0118, -0.0036, -0.0073],
        [-0.0058,  0.0263,  0.0174,  ...,  0.0237, -0.0044, -0.0130],
        [ 0.0074, -0.0107,  0.0541,  ...,  0.0025,  0.0069,  0.0042],
        ...,
        [ 0.0119,  0.0045, -0.0072,  ...,  0.0477,  0.0019, -0.0156],
        [-0.0001,  0.0136,  0.0041,  ..., -0.0092,  0.0395, -0.0131],
        [-0.0014, -0.0027,  0.0015,  ...,  0.0091, -0.0068,  0.0318]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4609, -5.7031, -1.6143,  ..., -3.8691, -0.4966, -1.0400]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 15:02:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for stalin was soviet
lenin was soviet
edison was american
mencius was chinese
hegel was german
locke was english
beethoven was german
aristotle was
2024-07-28 15:02:54 root INFO     [order_1_approx] starting weight calculation for lenin was soviet
mencius was chinese
beethoven was german
hegel was german
edison was american
stalin was soviet
aristotle was greek
locke was
2024-07-28 15:02:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 15:05:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3645, -0.1238, -0.5552,  ..., -0.0348, -0.2396,  0.0754],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2070, -2.8008,  0.8379,  ..., -4.9102,  0.1729, -3.4492],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0525,  0.0092, -0.0145,  ..., -0.0042,  0.0021, -0.0175],
        [ 0.0237,  0.0461,  0.0153,  ...,  0.0120, -0.0099, -0.0120],
        [ 0.0086, -0.0031,  0.0340,  ..., -0.0054,  0.0154,  0.0331],
        ...,
        [ 0.0139, -0.0029, -0.0021,  ...,  0.0690,  0.0028, -0.0010],
        [-0.0112,  0.0043,  0.0047,  ..., -0.0200,  0.0573, -0.0134],
        [ 0.0152,  0.0049, -0.0260,  ...,  0.0091, -0.0105,  0.0943]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2324, -3.4531,  0.4512,  ..., -4.6016,  0.7427, -3.2695]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 15:05:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for lenin was soviet
mencius was chinese
beethoven was german
hegel was german
edison was american
stalin was soviet
aristotle was greek
locke was
2024-07-28 15:05:16 root INFO     [order_1_approx] starting weight calculation for locke was english
stalin was soviet
aristotle was greek
beethoven was german
edison was american
hegel was german
mencius was chinese
lenin was
2024-07-28 15:05:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 15:07:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1521, -0.3672, -0.3652,  ...,  0.1566, -0.3464, -0.0635],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9414, -4.1328, -0.2922,  ..., -5.4453,  0.2168, -0.7329],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0566,  0.0077,  0.0004,  ...,  0.0046,  0.0092, -0.0002],
        [-0.0051,  0.0340,  0.0150,  ..., -0.0094, -0.0019, -0.0295],
        [ 0.0112, -0.0029,  0.0472,  ...,  0.0039,  0.0022,  0.0189],
        ...,
        [ 0.0035,  0.0010, -0.0095,  ...,  0.0728, -0.0108, -0.0068],
        [ 0.0050,  0.0036,  0.0022,  ..., -0.0023,  0.0341, -0.0027],
        [-0.0088,  0.0262, -0.0073,  ...,  0.0023, -0.0113,  0.0523]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0469, -4.1953, -0.3936,  ..., -5.6992,  0.1324, -0.3411]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 15:07:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for locke was english
stalin was soviet
aristotle was greek
beethoven was german
edison was american
hegel was german
mencius was chinese
lenin was
2024-07-28 15:07:36 root INFO     total operator prediction time: 1130.9556078910828 seconds
2024-07-28 15:07:36 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on UK_city - county
2024-07-28 15:07:36 root INFO     building operator UK_city - county
2024-07-28 15:07:36 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of bath is in the county of somerset
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of liverpool is in the county of lancashire
In the United Kingdom, the city of hull is in the county of yorkshire
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of glasgow is in the county of
2024-07-28 15:07:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 15:10:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4692,  0.6187, -0.0430,  ...,  0.4573, -0.0596,  0.1665],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8887, -3.3789,  0.6797,  ..., -3.7715,  0.9609, -1.7100],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0075,  0.0028,  0.0048,  ...,  0.0095, -0.0088, -0.0075],
        [-0.0006, -0.0011,  0.0098,  ...,  0.0034,  0.0107,  0.0133],
        [ 0.0047,  0.0100,  0.0256,  ...,  0.0203,  0.0138, -0.0091],
        ...,
        [ 0.0123, -0.0141, -0.0121,  ...,  0.0208,  0.0045, -0.0014],
        [ 0.0091, -0.0143, -0.0056,  ..., -0.0014,  0.0042, -0.0051],
        [-0.0029, -0.0060, -0.0150,  ...,  0.0005,  0.0024,  0.0219]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9746, -3.6660,  0.3772,  ..., -3.5938,  0.9775, -1.9062]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 15:10:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of bath is in the county of somerset
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of liverpool is in the county of lancashire
In the United Kingdom, the city of hull is in the county of yorkshire
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of glasgow is in the county of
2024-07-28 15:10:06 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of glasgow is in the county of lowlands
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of liverpool is in the county of lancashire
In the United Kingdom, the city of hull is in the county of yorkshire
In the United Kingdom, the city of bath is in the county of
2024-07-28 15:10:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 15:12:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5078, -0.1693,  0.5000,  ...,  0.4553, -0.5625, -0.0234],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6016, -2.9531, -1.4209,  ..., -1.0508, -1.2842, -2.3691],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.8839e-02,  9.7198e-03, -1.3588e-02,  ...,  6.4011e-03,
          1.4030e-02, -3.1586e-02],
        [ 9.9182e-05,  3.6316e-02,  3.9816e-04,  ...,  6.8817e-03,
         -1.7715e-02,  7.7362e-03],
        [-3.2806e-02, -9.0256e-03,  4.1901e-02,  ...,  1.2123e-02,
          7.8812e-03, -1.4114e-02],
        ...,
        [ 2.8748e-02, -1.2543e-02, -2.5654e-03,  ...,  4.4983e-02,
          1.7715e-02, -2.0996e-02],
        [ 1.8433e-02, -1.7151e-02,  6.2704e-04,  ..., -3.9482e-03,
          1.8646e-02,  2.8198e-02],
        [-1.9436e-03, -1.2825e-02,  7.5951e-03,  ..., -1.1635e-04,
         -1.8606e-03,  2.6093e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6250, -3.3105, -1.4307,  ..., -1.6152, -0.8501, -2.7305]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 15:12:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of glasgow is in the county of lowlands
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of liverpool is in the county of lancashire
In the United Kingdom, the city of hull is in the county of yorkshire
In the United Kingdom, the city of bath is in the county of
2024-07-28 15:12:36 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of hull is in the county of yorkshire
In the United Kingdom, the city of bath is in the county of somerset
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of glasgow is in the county of lowlands
In the United Kingdom, the city of liverpool is in the county of lancashire
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of aberdeen is in the county of
2024-07-28 15:12:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 15:14:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2793,  0.0186, -0.1971,  ...,  0.1058, -0.0480,  0.2212],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4614, -4.9648,  0.8950,  ..., -4.5547, -1.9961, -2.2227],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0041, -0.0032,  0.0074,  ...,  0.0061,  0.0045, -0.0008],
        [ 0.0060,  0.0115,  0.0064,  ...,  0.0016,  0.0046, -0.0036],
        [-0.0018, -0.0021,  0.0250,  ...,  0.0101,  0.0050, -0.0006],
        ...,
        [ 0.0070,  0.0018, -0.0160,  ...,  0.0117,  0.0063, -0.0008],
        [-0.0003, -0.0143,  0.0007,  ..., -0.0088, -0.0040,  0.0054],
        [ 0.0036, -0.0061, -0.0095,  ..., -0.0008, -0.0018,  0.0171]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6274, -5.2656,  0.7378,  ..., -4.4727, -1.7949, -2.1641]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 15:14:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of hull is in the county of yorkshire
In the United Kingdom, the city of bath is in the county of somerset
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of glasgow is in the county of lowlands
In the United Kingdom, the city of liverpool is in the county of lancashire
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of aberdeen is in the county of
2024-07-28 15:15:00 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of bath is in the county of somerset
In the United Kingdom, the city of glasgow is in the county of lowlands
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of liverpool is in the county of lancashire
In the United Kingdom, the city of hull is in the county of
2024-07-28 15:15:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 15:17:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3137, -0.0734,  0.0358,  ...,  0.2236, -0.1428,  0.0720],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8364, -3.4434, -1.1543,  ..., -4.3281, -0.2656,  0.1299],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0147,  0.0008,  0.0211,  ...,  0.0001,  0.0014, -0.0079],
        [-0.0117,  0.0146,  0.0114,  ..., -0.0133, -0.0014, -0.0202],
        [-0.0071, -0.0317,  0.0406,  ...,  0.0020,  0.0032, -0.0190],
        ...,
        [ 0.0270,  0.0070, -0.0048,  ...,  0.0432,  0.0027,  0.0117],
        [ 0.0291, -0.0150, -0.0127,  ...,  0.0240,  0.0213,  0.0082],
        [ 0.0020,  0.0047, -0.0115,  ..., -0.0099, -0.0012,  0.0221]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4473, -3.3965, -1.6172,  ..., -4.3633, -0.0652,  0.3633]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 15:17:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of bath is in the county of somerset
In the United Kingdom, the city of glasgow is in the county of lowlands
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of liverpool is in the county of lancashire
In the United Kingdom, the city of hull is in the county of
2024-07-28 15:17:24 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of liverpool is in the county of lancashire
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of hull is in the county of yorkshire
In the United Kingdom, the city of bath is in the county of somerset
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of glasgow is in the county of lowlands
In the United Kingdom, the city of belfast is in the county of
2024-07-28 15:17:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 15:19:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6523, -0.0537, -0.5581,  ...,  0.3784, -0.0638,  0.2284],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.9531, -6.6094,  1.8857,  ..., -3.3633, -1.3018, -2.4863],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0076,  0.0026,  0.0067,  ...,  0.0054,  0.0013, -0.0028],
        [-0.0019,  0.0116,  0.0099,  ..., -0.0030, -0.0034, -0.0096],
        [ 0.0068,  0.0049,  0.0107,  ...,  0.0134,  0.0012, -0.0058],
        ...,
        [-0.0062, -0.0013, -0.0094,  ...,  0.0146, -0.0049,  0.0017],
        [ 0.0014, -0.0175,  0.0058,  ..., -0.0002, -0.0046,  0.0013],
        [ 0.0012, -0.0077,  0.0037,  ...,  0.0026, -0.0015,  0.0133]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 7.0742, -6.7461,  1.6133,  ..., -3.4219, -1.0742, -2.4297]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 15:19:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of liverpool is in the county of lancashire
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of hull is in the county of yorkshire
In the United Kingdom, the city of bath is in the county of somerset
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of glasgow is in the county of lowlands
In the United Kingdom, the city of belfast is in the county of
2024-07-28 15:19:54 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of hull is in the county of yorkshire
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of bath is in the county of somerset
In the United Kingdom, the city of glasgow is in the county of lowlands
In the United Kingdom, the city of liverpool is in the county of lancashire
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of stirling is in the county of
2024-07-28 15:19:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 15:22:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4497,  0.4395, -0.4392,  ...,  0.4944, -0.2344,  0.4268],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9473, -5.0039,  0.6074,  ..., -3.9902, -2.7305, -2.1367],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0021,  0.0061,  0.0051,  ...,  0.0050, -0.0045, -0.0063],
        [ 0.0126,  0.0098,  0.0290,  ...,  0.0190,  0.0125,  0.0036],
        [ 0.0136,  0.0065,  0.0261,  ...,  0.0172, -0.0023, -0.0060],
        ...,
        [ 0.0304, -0.0245, -0.0140,  ...,  0.0529,  0.0246, -0.0059],
        [-0.0213, -0.0165, -0.0157,  ...,  0.0116,  0.0094, -0.0172],
        [-0.0016, -0.0010, -0.0223,  ..., -0.0167, -0.0154,  0.0412]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9355, -4.9570,  0.4170,  ..., -3.5488, -2.3145, -1.9756]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 15:22:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of hull is in the county of yorkshire
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of bath is in the county of somerset
In the United Kingdom, the city of glasgow is in the county of lowlands
In the United Kingdom, the city of liverpool is in the county of lancashire
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of stirling is in the county of
2024-07-28 15:22:18 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of liverpool is in the county of lancashire
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of bath is in the county of somerset
In the United Kingdom, the city of glasgow is in the county of lowlands
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of hull is in the county of yorkshire
In the United Kingdom, the city of newcastle is in the county of
2024-07-28 15:22:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 15:24:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4673,  0.2983, -0.2281,  ...,  0.5190, -0.2407,  0.3005],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5859, -3.4453,  2.1738,  ..., -2.8555, -2.9434, -1.2949],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0387, -0.0084,  0.0048,  ..., -0.0025, -0.0109, -0.0197],
        [ 0.0069,  0.0159,  0.0185,  ...,  0.0035,  0.0147, -0.0083],
        [-0.0093, -0.0038,  0.0383,  ...,  0.0294, -0.0007, -0.0191],
        ...,
        [ 0.0034, -0.0092, -0.0101,  ...,  0.0290, -0.0019, -0.0022],
        [ 0.0246, -0.0117, -0.0228,  ...,  0.0053,  0.0161,  0.0023],
        [ 0.0100, -0.0046, -0.0174,  ..., -0.0208, -0.0221,  0.0231]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9570, -3.3594,  1.6055,  ..., -2.9551, -2.4316, -1.3242]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 15:24:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of liverpool is in the county of lancashire
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of bath is in the county of somerset
In the United Kingdom, the city of glasgow is in the county of lowlands
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of hull is in the county of yorkshire
In the United Kingdom, the city of newcastle is in the county of
2024-07-28 15:24:43 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of glasgow is in the county of lowlands
In the United Kingdom, the city of bath is in the county of somerset
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of hull is in the county of yorkshire
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of liverpool is in the county of
2024-07-28 15:24:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.12
2024-07-28 15:27:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7295, -0.0869,  0.0240,  ...,  0.4534, -0.1853,  0.2039],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1797, -5.9297,  0.9980,  ..., -4.3281,  0.4336, -2.9219],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0140,  0.0186,  0.0166,  ...,  0.0163, -0.0060, -0.0186],
        [-0.0001, -0.0070,  0.0056,  ..., -0.0047,  0.0033,  0.0055],
        [-0.0213,  0.0080,  0.0199,  ...,  0.0201,  0.0063, -0.0004],
        ...,
        [ 0.0062, -0.0123, -0.0077,  ...,  0.0235, -0.0013,  0.0024],
        [ 0.0004, -0.0197,  0.0078,  ...,  0.0061,  0.0098, -0.0061],
        [ 0.0058, -0.0181, -0.0213,  ..., -0.0058, -0.0155,  0.0232]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0977, -5.8867,  0.6719,  ..., -4.3750,  0.6509, -2.6562]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 15:27:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of glasgow is in the county of lowlands
In the United Kingdom, the city of bath is in the county of somerset
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of hull is in the county of yorkshire
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of liverpool is in the county of
2024-07-28 15:27:07 root INFO     total operator prediction time: 1170.978375196457 seconds
