2024-07-31 17:09:17 root INFO     loading model + tokenizer
2024-07-31 17:09:20 root INFO     model + tokenizer loaded
2024-07-31 17:09:20 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - part
2024-07-31 17:09:20 root INFO     building operator meronyms - part
2024-07-31 17:09:21 root INFO     [order_1_approx] starting weight calculation for A part of a shirt is a button
A part of a harbor is a dock
A part of a orthography is a hyphenation
A part of a teapot is a spout
A part of a table is a tabletop
A part of a seafront is a harbor
A part of a deer is a antler
A part of a bird is a
2024-07-31 17:09:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 17:12:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1040,  0.0425,  0.0352,  ..., -0.1628, -0.2129, -0.1177],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8047, -4.1680, -2.2930,  ...,  0.9248, -3.0078,  1.0566],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0046, -0.0249,  0.0344,  ...,  0.0109, -0.0507,  0.0207],
        [ 0.0015, -0.0194,  0.0170,  ..., -0.0130,  0.0119,  0.0141],
        [-0.0233, -0.0190,  0.0312,  ...,  0.0228, -0.0483, -0.0150],
        ...,
        [ 0.0059, -0.0331,  0.0190,  ...,  0.0585, -0.0136,  0.0156],
        [ 0.0228,  0.0067, -0.0110,  ...,  0.0425,  0.0383, -0.0072],
        [ 0.0023, -0.0145,  0.0187,  ..., -0.0257, -0.0122,  0.0138]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8477, -3.3594, -2.4727,  ...,  1.5078, -3.3730,  1.3457]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:12:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a shirt is a button
A part of a harbor is a dock
A part of a orthography is a hyphenation
A part of a teapot is a spout
A part of a table is a tabletop
A part of a seafront is a harbor
A part of a deer is a antler
A part of a bird is a
2024-07-31 17:12:22 root INFO     [order_1_approx] starting weight calculation for A part of a orthography is a hyphenation
A part of a bird is a feathers
A part of a shirt is a button
A part of a deer is a antler
A part of a teapot is a spout
A part of a table is a tabletop
A part of a harbor is a dock
A part of a seafront is a
2024-07-31 17:12:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 17:15:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0178,  0.1597,  0.0451,  ...,  0.0502, -0.2708, -0.1058],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0840, -3.9531, -2.1895,  ...,  6.3555, -1.9453, -0.6660],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0425, -0.0228, -0.0001,  ...,  0.0283, -0.0026,  0.0110],
        [ 0.0156,  0.0020, -0.0054,  ...,  0.0235,  0.0254,  0.0166],
        [-0.0226,  0.0266,  0.0296,  ...,  0.0042,  0.0167,  0.0099],
        ...,
        [ 0.0305, -0.0222, -0.0104,  ...,  0.0065, -0.0441, -0.0166],
        [-0.0174,  0.0057,  0.0094,  ...,  0.0020,  0.0321, -0.0084],
        [-0.0013, -0.0252, -0.0345,  ...,  0.0162, -0.0028,  0.0327]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6992, -3.5156, -1.8809,  ...,  5.4219, -1.6260, -0.3401]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:15:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a orthography is a hyphenation
A part of a bird is a feathers
A part of a shirt is a button
A part of a deer is a antler
A part of a teapot is a spout
A part of a table is a tabletop
A part of a harbor is a dock
A part of a seafront is a
2024-07-31 17:15:23 root INFO     [order_1_approx] starting weight calculation for A part of a orthography is a hyphenation
A part of a teapot is a spout
A part of a deer is a antler
A part of a bird is a feathers
A part of a shirt is a button
A part of a table is a tabletop
A part of a seafront is a harbor
A part of a harbor is a
2024-07-31 17:15:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 17:18:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1832,  0.0091,  0.1947,  ..., -0.0874, -0.2939,  0.0278],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7969, -6.7734,  0.0587,  ...,  2.7012,  0.2988,  1.7705],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0366, -0.0120,  0.0004,  ..., -0.0233, -0.0145,  0.0072],
        [-0.0170, -0.0024, -0.0090,  ..., -0.0172, -0.0222, -0.0003],
        [-0.0068,  0.0461,  0.0190,  ...,  0.0131,  0.0252,  0.0151],
        ...,
        [ 0.0153, -0.0252, -0.0263,  ...,  0.0047, -0.0030, -0.0120],
        [-0.0191,  0.0047, -0.0063,  ...,  0.0069,  0.0174, -0.0117],
        [-0.0022, -0.0361,  0.0116,  ...,  0.0160, -0.0435,  0.0147]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0605, -6.2500,  0.0260,  ...,  2.5020,  0.3274,  2.0684]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:18:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a orthography is a hyphenation
A part of a teapot is a spout
A part of a deer is a antler
A part of a bird is a feathers
A part of a shirt is a button
A part of a table is a tabletop
A part of a seafront is a harbor
A part of a harbor is a
2024-07-31 17:18:24 root INFO     [order_1_approx] starting weight calculation for A part of a orthography is a hyphenation
A part of a harbor is a dock
A part of a teapot is a spout
A part of a shirt is a button
A part of a seafront is a harbor
A part of a bird is a feathers
A part of a table is a tabletop
A part of a deer is a
2024-07-31 17:18:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 17:21:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0224,  0.1422, -0.0967,  ..., -0.0880, -0.1619,  0.1503],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1348, -1.8516, -1.8701,  ...,  1.3799, -4.7617, -1.0195],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0146, -0.0528, -0.0059,  ..., -0.0851,  0.0119, -0.0298],
        [ 0.0215,  0.0094, -0.0383,  ...,  0.0194, -0.0131,  0.0462],
        [ 0.0117,  0.0300,  0.0864,  ...,  0.0200, -0.0347, -0.0207],
        ...,
        [-0.0009,  0.0183,  0.0095,  ...,  0.1016, -0.0315,  0.0435],
        [ 0.0294,  0.0343,  0.0104,  ...,  0.0383,  0.0777, -0.0246],
        [-0.0174,  0.0166, -0.0065,  ..., -0.0155, -0.0117, -0.0011]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7617, -1.6641, -1.8945,  ...,  2.1719, -5.3906, -1.2344]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:21:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a orthography is a hyphenation
A part of a harbor is a dock
A part of a teapot is a spout
A part of a shirt is a button
A part of a seafront is a harbor
A part of a bird is a feathers
A part of a table is a tabletop
A part of a deer is a
2024-07-31 17:21:26 root INFO     [order_1_approx] starting weight calculation for A part of a bird is a feathers
A part of a seafront is a harbor
A part of a shirt is a button
A part of a deer is a antler
A part of a orthography is a hyphenation
A part of a harbor is a dock
A part of a teapot is a spout
A part of a table is a
2024-07-31 17:21:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 17:24:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0312, -0.0527, -0.1082,  ..., -0.0885, -0.2573, -0.0861],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8398, -3.9375,  0.1777,  ...,  0.7285, -2.0195,  0.2666],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0164, -0.0529,  0.0274,  ...,  0.0176, -0.0135, -0.0147],
        [-0.0009, -0.0483, -0.0256,  ...,  0.0312, -0.0002,  0.0106],
        [-0.0146,  0.0229,  0.0253,  ..., -0.0411, -0.0580,  0.0222],
        ...,
        [ 0.0244, -0.0211, -0.0028,  ...,  0.0267, -0.0229,  0.0175],
        [-0.0244,  0.0179,  0.0062,  ...,  0.0479,  0.0549, -0.0208],
        [ 0.0077, -0.0243, -0.0022,  ...,  0.0025,  0.0114,  0.0384]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3496, -2.9375, -0.3687,  ...,  0.2776, -1.5547,  0.2295]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:24:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a bird is a feathers
A part of a seafront is a harbor
A part of a shirt is a button
A part of a deer is a antler
A part of a orthography is a hyphenation
A part of a harbor is a dock
A part of a teapot is a spout
A part of a table is a
2024-07-31 17:24:27 root INFO     [order_1_approx] starting weight calculation for A part of a teapot is a spout
A part of a bird is a feathers
A part of a harbor is a dock
A part of a deer is a antler
A part of a table is a tabletop
A part of a shirt is a button
A part of a seafront is a harbor
A part of a orthography is a
2024-07-31 17:24:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 17:27:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0986, -0.0900,  0.1542,  ..., -0.1167, -0.1193, -0.3379],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.1289, -3.0898,  0.8960,  ...,  3.6270, -0.0303, -1.9668],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0649, -0.0387,  0.0234,  ..., -0.0050,  0.0022,  0.0012],
        [ 0.0690,  0.0179, -0.0182,  ...,  0.0743, -0.0080, -0.0370],
        [-0.0457,  0.0464, -0.0117,  ..., -0.0129, -0.0078,  0.0230],
        ...,
        [ 0.0377, -0.0003, -0.0023,  ...,  0.0528, -0.0015, -0.0314],
        [-0.0166,  0.0133, -0.0197,  ...,  0.0296,  0.0207,  0.0070],
        [ 0.0707, -0.0504, -0.0126,  ...,  0.0553,  0.0070, -0.0116]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.7725, -2.7227,  0.9966,  ...,  3.4785, -0.5327, -1.1680]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:27:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a teapot is a spout
A part of a bird is a feathers
A part of a harbor is a dock
A part of a deer is a antler
A part of a table is a tabletop
A part of a shirt is a button
A part of a seafront is a harbor
A part of a orthography is a
2024-07-31 17:27:27 root INFO     [order_1_approx] starting weight calculation for A part of a bird is a feathers
A part of a table is a tabletop
A part of a orthography is a hyphenation
A part of a deer is a antler
A part of a teapot is a spout
A part of a seafront is a harbor
A part of a harbor is a dock
A part of a shirt is a
2024-07-31 17:27:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 17:30:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1646, -0.1759, -0.1427,  ...,  0.0921, -0.3047,  0.0473],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7148, -3.6797,  0.1221,  ...,  2.3926,  3.1055,  1.9541],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0130, -0.1200, -0.0090,  ..., -0.0104,  0.1022,  0.0354],
        [-0.0134, -0.0080, -0.0003,  ...,  0.0564, -0.0276,  0.0037],
        [-0.0299, -0.0449,  0.0292,  ..., -0.0339, -0.0118,  0.0016],
        ...,
        [ 0.0390,  0.0399, -0.0060,  ...,  0.0250, -0.0051, -0.0270],
        [ 0.0060,  0.0322, -0.0288,  ..., -0.0160,  0.0377, -0.0773],
        [-0.0112, -0.0075, -0.0202,  ...,  0.0173,  0.0371,  0.0264]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6328, -3.1680,  0.2429,  ...,  2.2129,  2.6191,  1.3203]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:30:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a bird is a feathers
A part of a table is a tabletop
A part of a orthography is a hyphenation
A part of a deer is a antler
A part of a teapot is a spout
A part of a seafront is a harbor
A part of a harbor is a dock
A part of a shirt is a
2024-07-31 17:30:26 root INFO     [order_1_approx] starting weight calculation for A part of a table is a tabletop
A part of a bird is a feathers
A part of a deer is a antler
A part of a seafront is a harbor
A part of a shirt is a button
A part of a orthography is a hyphenation
A part of a harbor is a dock
A part of a teapot is a
2024-07-31 17:30:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 17:33:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2695, -0.0889,  0.1389,  ..., -0.0176, -0.2067, -0.1610],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1875,  0.4707, -0.8906,  ...,  0.0684, -1.1582,  0.9404],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0198, -0.0975,  0.0246,  ..., -0.0479,  0.0093,  0.0660],
        [ 0.0353,  0.1220, -0.0057,  ...,  0.0413, -0.0354, -0.0132],
        [ 0.0221,  0.0052,  0.0089,  ...,  0.0131,  0.0005, -0.0037],
        ...,
        [ 0.0226,  0.0863, -0.0041,  ...,  0.0705, -0.0329, -0.0477],
        [-0.1324, -0.2249, -0.0280,  ..., -0.0297,  0.0598,  0.1051],
        [ 0.0072, -0.0081, -0.0102,  ..., -0.0130,  0.0062,  0.0147]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6094,  0.8281, -1.2754,  ..., -0.3264, -1.0205,  0.9741]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:33:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a table is a tabletop
A part of a bird is a feathers
A part of a deer is a antler
A part of a seafront is a harbor
A part of a shirt is a button
A part of a orthography is a hyphenation
A part of a harbor is a dock
A part of a teapot is a
2024-07-31 17:33:29 root INFO     total operator prediction time: 1448.833675146103 seconds
2024-07-31 17:33:29 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on synonyms - exact
2024-07-31 17:33:29 root INFO     building operator synonyms - exact
2024-07-31 17:33:29 root INFO     [order_1_approx] starting weight calculation for Another word for dollars is bucks
Another word for spouse is partner
Another word for monument is memorial
Another word for help is aid
Another word for package is parcel
Another word for vocabulary is lexicon
Another word for obsolete is outdated
Another word for lad is
2024-07-31 17:33:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 17:36:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3052,  0.0463, -0.1234,  ..., -0.0088, -0.1838, -0.0354],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9619, -1.8779, -3.4648,  ...,  2.9297, -0.1328, -1.4727],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1165, -0.0735,  0.0012,  ...,  0.0768,  0.0715, -0.0105],
        [ 0.0023,  0.0018, -0.0671,  ..., -0.0399, -0.0237, -0.0105],
        [ 0.0077, -0.0927,  0.0315,  ...,  0.0130,  0.0253,  0.0094],
        ...,
        [-0.0577, -0.0634, -0.0476,  ..., -0.0829, -0.0970, -0.0258],
        [ 0.0158, -0.0770,  0.0561,  ...,  0.0192, -0.0273,  0.0343],
        [ 0.0178,  0.0466, -0.0624,  ..., -0.0361,  0.0144, -0.0511]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2578, -1.9385, -2.9141,  ...,  3.2500, -0.4663, -1.2363]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:36:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for dollars is bucks
Another word for spouse is partner
Another word for monument is memorial
Another word for help is aid
Another word for package is parcel
Another word for vocabulary is lexicon
Another word for obsolete is outdated
Another word for lad is
2024-07-31 17:36:33 root INFO     [order_1_approx] starting weight calculation for Another word for obsolete is outdated
Another word for lad is chap
Another word for dollars is bucks
Another word for package is parcel
Another word for help is aid
Another word for spouse is partner
Another word for vocabulary is lexicon
Another word for monument is
2024-07-31 17:36:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 17:39:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0243,  0.1980,  0.2144,  ...,  0.0179, -0.2913, -0.0240],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.7383, -3.7754,  1.4199,  ...,  0.2080, -4.3203, -1.7217],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0889,  0.0173,  0.0109,  ..., -0.0290, -0.0047,  0.0064],
        [ 0.0147, -0.0087, -0.0001,  ..., -0.0059,  0.0296, -0.0331],
        [ 0.0828, -0.0457,  0.0598,  ...,  0.0485, -0.0423,  0.0113],
        ...,
        [-0.0739,  0.0113, -0.0723,  ...,  0.0425,  0.0817, -0.0412],
        [-0.0005,  0.0022, -0.0128,  ...,  0.0211,  0.0111, -0.0444],
        [-0.0107,  0.0410,  0.0148,  ...,  0.0012,  0.0366,  0.0300]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.2012, -4.1797,  1.1963,  ..., -0.1526, -4.5117, -1.7393]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:39:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for obsolete is outdated
Another word for lad is chap
Another word for dollars is bucks
Another word for package is parcel
Another word for help is aid
Another word for spouse is partner
Another word for vocabulary is lexicon
Another word for monument is
2024-07-31 17:39:35 root INFO     [order_1_approx] starting weight calculation for Another word for dollars is bucks
Another word for obsolete is outdated
Another word for lad is chap
Another word for vocabulary is lexicon
Another word for monument is memorial
Another word for help is aid
Another word for spouse is partner
Another word for package is
2024-07-31 17:39:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 17:42:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2130, -0.1217,  0.0073,  ..., -0.1014, -0.1841,  0.1195],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8906, -1.4961, -1.7148,  ..., -1.3955, -0.9761, -0.6792],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0657,  0.0845,  0.0320,  ..., -0.0357,  0.0092, -0.0143],
        [-0.0048,  0.0571,  0.0727,  ...,  0.0569, -0.0058, -0.0369],
        [-0.0165, -0.0292,  0.0518,  ...,  0.0192, -0.0479, -0.0031],
        ...,
        [ 0.0151, -0.0681, -0.0372,  ...,  0.0622, -0.0153,  0.0118],
        [ 0.0093, -0.0200, -0.0110,  ...,  0.0833,  0.0287,  0.0186],
        [-0.0095, -0.0565, -0.0093,  ...,  0.0130, -0.0136,  0.0662]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.2227, -2.5273, -1.7402,  ..., -1.4844, -1.0039, -0.9497]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:42:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for dollars is bucks
Another word for obsolete is outdated
Another word for lad is chap
Another word for vocabulary is lexicon
Another word for monument is memorial
Another word for help is aid
Another word for spouse is partner
Another word for package is
2024-07-31 17:42:38 root INFO     [order_1_approx] starting weight calculation for Another word for vocabulary is lexicon
Another word for monument is memorial
Another word for dollars is bucks
Another word for spouse is partner
Another word for package is parcel
Another word for lad is chap
Another word for help is aid
Another word for obsolete is
2024-07-31 17:42:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 17:45:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1438, -0.0431, -0.0064,  ..., -0.1643, -0.1965, -0.0506],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7559, -4.5625,  3.3125,  ..., -1.8770, -3.1914,  1.3223],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0185,  0.0175, -0.0019,  ..., -0.0433, -0.0483,  0.0715],
        [-0.0225,  0.0121,  0.0517,  ...,  0.0090,  0.0014,  0.0025],
        [ 0.0015,  0.0235,  0.0191,  ...,  0.0334, -0.0138,  0.0055],
        ...,
        [ 0.0452,  0.0289,  0.0270,  ...,  0.0222, -0.0190, -0.0037],
        [ 0.0103,  0.0089,  0.0213,  ...,  0.0057, -0.0052, -0.0142],
        [ 0.0152,  0.0005, -0.0070,  ...,  0.0167, -0.0256,  0.0193]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6626, -3.9980,  2.5781,  ..., -1.8652, -3.3066,  1.2080]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:45:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for vocabulary is lexicon
Another word for monument is memorial
Another word for dollars is bucks
Another word for spouse is partner
Another word for package is parcel
Another word for lad is chap
Another word for help is aid
Another word for obsolete is
2024-07-31 17:45:36 root INFO     [order_1_approx] starting weight calculation for Another word for help is aid
Another word for obsolete is outdated
Another word for lad is chap
Another word for monument is memorial
Another word for vocabulary is lexicon
Another word for dollars is bucks
Another word for package is parcel
Another word for spouse is
2024-07-31 17:45:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 17:48:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0457,  0.2258,  0.0979,  ...,  0.0256, -0.1039, -0.1180],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.7686, -1.6611,  1.7744,  ...,  0.5874, -0.8530,  1.7588],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.8600e-02, -1.5327e-02,  3.2349e-02,  ..., -7.4829e-02,
         -2.4597e-02,  5.4245e-03],
        [-2.3468e-02,  2.0752e-02,  2.5314e-02,  ...,  2.3605e-02,
          3.3417e-02,  2.0950e-02],
        [ 1.0376e-03, -3.1860e-02,  8.1787e-02,  ...,  5.9280e-03,
          2.8641e-02, -2.5467e-02],
        ...,
        [-8.9798e-03,  4.6112e-02,  8.3160e-03,  ...,  4.1847e-03,
         -1.0895e-02,  4.9171e-03],
        [ 9.4986e-03,  7.0906e-04,  5.2246e-02,  ...,  5.3040e-02,
          1.5015e-02, -8.5831e-05],
        [-1.0834e-03,  1.2787e-02, -1.9836e-02,  ..., -3.4332e-02,
          1.7662e-03, -4.3755e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8130, -1.7383,  1.6162,  ...,  0.5459, -1.0879,  1.2871]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:48:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for help is aid
Another word for obsolete is outdated
Another word for lad is chap
Another word for monument is memorial
Another word for vocabulary is lexicon
Another word for dollars is bucks
Another word for package is parcel
Another word for spouse is
2024-07-31 17:48:42 root INFO     [order_1_approx] starting weight calculation for Another word for package is parcel
Another word for spouse is partner
Another word for monument is memorial
Another word for dollars is bucks
Another word for obsolete is outdated
Another word for help is aid
Another word for lad is chap
Another word for vocabulary is
2024-07-31 17:48:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 17:51:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2327,  0.1061, -0.1229,  ...,  0.2200, -0.1117,  0.0183],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6494, -2.3926,  5.2383,  ..., -2.0820, -0.9814,  0.9570],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0249, -0.0297,  0.0235,  ..., -0.0334, -0.0360,  0.0244],
        [ 0.0565,  0.0253, -0.0239,  ...,  0.0641,  0.0367, -0.0302],
        [-0.0020, -0.0379,  0.0312,  ..., -0.0223, -0.0274,  0.0221],
        ...,
        [ 0.0370, -0.0058, -0.0625,  ...,  0.0661,  0.0363, -0.0294],
        [-0.0154, -0.0080,  0.0044,  ..., -0.0148,  0.0076,  0.0191],
        [-0.0006,  0.0225, -0.0027,  ...,  0.0241,  0.0054, -0.0060]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5278, -1.8926,  4.7695,  ..., -1.5283, -1.1934,  0.8584]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:51:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for package is parcel
Another word for spouse is partner
Another word for monument is memorial
Another word for dollars is bucks
Another word for obsolete is outdated
Another word for help is aid
Another word for lad is chap
Another word for vocabulary is
2024-07-31 17:51:45 root INFO     [order_1_approx] starting weight calculation for Another word for vocabulary is lexicon
Another word for spouse is partner
Another word for obsolete is outdated
Another word for monument is memorial
Another word for package is parcel
Another word for dollars is bucks
Another word for lad is chap
Another word for help is
2024-07-31 17:51:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 17:54:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1455, -0.1412,  0.1290,  ...,  0.0011, -0.2512,  0.0742],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.0312, -6.2539,  1.7549,  ...,  2.2891, -3.3164, -1.1055],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-1.3649e-02, -2.5574e-02,  3.2768e-03,  ...,  9.0714e-03,
         -4.6539e-03,  1.3023e-02],
        [-1.1040e-02, -1.7700e-02,  1.4877e-02,  ...,  5.7373e-03,
         -2.7634e-02, -5.2185e-02],
        [ 8.8959e-03, -1.3412e-02,  1.6222e-03,  ...,  2.5620e-02,
         -3.6163e-02, -6.1035e-04],
        ...,
        [-1.0223e-03, -2.9968e-02, -1.0872e-03,  ...,  8.2169e-03,
         -3.8239e-02, -9.5062e-03],
        [ 3.6011e-02,  5.8746e-04,  3.9978e-03,  ..., -3.2013e-02,
         -2.2919e-02, -1.7609e-02],
        [ 6.1035e-05, -1.2871e-02,  1.3752e-03,  ...,  2.6581e-02,
         -5.0690e-02, -7.3738e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.2969, -5.0430,  1.0791,  ...,  2.5000, -2.4688, -1.1943]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:54:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for vocabulary is lexicon
Another word for spouse is partner
Another word for obsolete is outdated
Another word for monument is memorial
Another word for package is parcel
Another word for dollars is bucks
Another word for lad is chap
Another word for help is
2024-07-31 17:54:49 root INFO     [order_1_approx] starting weight calculation for Another word for lad is chap
Another word for spouse is partner
Another word for monument is memorial
Another word for package is parcel
Another word for help is aid
Another word for vocabulary is lexicon
Another word for obsolete is outdated
Another word for dollars is
2024-07-31 17:54:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 17:57:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0388, -0.0949, -0.0145,  ..., -0.0304, -0.0538, -0.0416],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7080, -1.9375,  1.8164,  ..., -2.7129,  0.4902, -2.1426],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.4424e-02, -2.6413e-02, -7.0457e-03,  ..., -3.8330e-02,
         -8.9874e-03,  3.6743e-02],
        [ 4.5624e-02,  5.8655e-02, -3.4760e-02,  ..., -2.3178e-02,
          1.7197e-02,  2.9831e-03],
        [-2.5223e-02, -2.7557e-02,  8.7509e-03,  ..., -1.0529e-03,
          5.6000e-02, -1.1520e-03],
        ...,
        [ 2.2263e-02,  9.7351e-03,  1.2352e-02,  ...,  6.1005e-02,
          8.7585e-03, -5.6427e-02],
        [-5.6610e-02, -6.8054e-02,  5.7220e-03,  ...,  3.0197e-02,
          4.6631e-02,  8.3923e-05],
        [ 4.8248e-02,  1.6129e-02, -8.2779e-03,  ...,  1.1711e-02,
         -3.9856e-02,  2.1179e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2122, -1.8994,  1.4180,  ..., -2.0293,  0.1558, -2.1465]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:57:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for lad is chap
Another word for spouse is partner
Another word for monument is memorial
Another word for package is parcel
Another word for help is aid
Another word for vocabulary is lexicon
Another word for obsolete is outdated
Another word for dollars is
2024-07-31 17:57:52 root INFO     total operator prediction time: 1463.1639065742493 seconds
2024-07-31 17:57:52 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hypernyms - misc
2024-07-31 17:57:52 root INFO     building operator hypernyms - misc
2024-07-31 17:57:52 root INFO     [order_1_approx] starting weight calculation for The croissant falls into the category of pastry
The bracelet falls into the category of jewelry
The dress falls into the category of clothes
The peach falls into the category of fruit
The jacket falls into the category of clothes
The computer falls into the category of device
The toaster falls into the category of appliance
The hairnet falls into the category of
2024-07-31 17:57:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 18:00:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0685, -0.0794, -0.2050,  ..., -0.0495, -0.0085, -0.2817],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5547, -2.8379,  1.5684,  ..., -1.5586, -3.0586,  4.6719],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0643,  0.0134,  0.0017,  ...,  0.0205, -0.0210,  0.0080],
        [-0.0432, -0.0316, -0.0659,  ..., -0.0162,  0.0153,  0.0421],
        [ 0.0275,  0.0200,  0.0219,  ...,  0.0003, -0.0419, -0.0164],
        ...,
        [-0.0440, -0.0318,  0.0107,  ...,  0.0056,  0.0227,  0.0084],
        [-0.0043, -0.0244,  0.0005,  ...,  0.0132,  0.0097,  0.0277],
        [-0.0094, -0.0249,  0.0023,  ..., -0.0235,  0.0297,  0.0219]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7695, -2.9688,  1.8154,  ..., -1.1416, -2.8633,  4.1719]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:00:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The croissant falls into the category of pastry
The bracelet falls into the category of jewelry
The dress falls into the category of clothes
The peach falls into the category of fruit
The jacket falls into the category of clothes
The computer falls into the category of device
The toaster falls into the category of appliance
The hairnet falls into the category of
2024-07-31 18:00:50 root INFO     [order_1_approx] starting weight calculation for The bracelet falls into the category of jewelry
The hairnet falls into the category of net
The dress falls into the category of clothes
The croissant falls into the category of pastry
The computer falls into the category of device
The toaster falls into the category of appliance
The jacket falls into the category of clothes
The peach falls into the category of
2024-07-31 18:00:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 18:03:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0544,  0.0243, -0.1854,  ...,  0.2610, -0.1144, -0.2197],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1172, -6.0781,  1.1211,  ..., -3.4883, -0.3354, -1.7900],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0301,  0.0288, -0.0115,  ...,  0.0258, -0.0239,  0.0220],
        [ 0.0434, -0.0593,  0.0230,  ..., -0.0244,  0.0012,  0.0003],
        [-0.0531,  0.0092,  0.0029,  ...,  0.0004, -0.0497,  0.0033],
        ...,
        [ 0.0567, -0.0438, -0.0108,  ...,  0.0008,  0.0384, -0.0225],
        [-0.0055, -0.0240, -0.0096,  ...,  0.0046, -0.0010, -0.0086],
        [ 0.0096, -0.0927,  0.0388,  ..., -0.0551,  0.0135,  0.0087]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9072, -6.5977,  1.2510,  ..., -3.5918, -0.0818, -1.4082]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:03:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The bracelet falls into the category of jewelry
The hairnet falls into the category of net
The dress falls into the category of clothes
The croissant falls into the category of pastry
The computer falls into the category of device
The toaster falls into the category of appliance
The jacket falls into the category of clothes
The peach falls into the category of
2024-07-31 18:03:53 root INFO     [order_1_approx] starting weight calculation for The toaster falls into the category of appliance
The peach falls into the category of fruit
The computer falls into the category of device
The hairnet falls into the category of net
The croissant falls into the category of pastry
The jacket falls into the category of clothes
The bracelet falls into the category of jewelry
The dress falls into the category of
2024-07-31 18:03:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 18:06:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1183, -0.2008, -0.2180,  ...,  0.1665, -0.1532, -0.1349],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7695, -6.3125, -0.0265,  ..., -0.2605, -2.7617, -0.3584],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0230,  0.0032, -0.0169,  ..., -0.0087, -0.0071,  0.0062],
        [-0.0338, -0.0291,  0.0174,  ...,  0.0097,  0.0002, -0.0346],
        [ 0.0107, -0.0014,  0.0212,  ...,  0.0066, -0.0149,  0.0231],
        ...,
        [-0.0056, -0.0139,  0.0180,  ...,  0.0288,  0.0291, -0.0309],
        [-0.0037, -0.0180, -0.0008,  ...,  0.0070,  0.0215, -0.0126],
        [-0.0216, -0.0248,  0.0139,  ...,  0.0116,  0.0181, -0.0259]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5234, -5.8359, -0.0868,  ...,  0.1860, -3.1094,  0.2520]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:06:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The toaster falls into the category of appliance
The peach falls into the category of fruit
The computer falls into the category of device
The hairnet falls into the category of net
The croissant falls into the category of pastry
The jacket falls into the category of clothes
The bracelet falls into the category of jewelry
The dress falls into the category of
2024-07-31 18:06:56 root INFO     [order_1_approx] starting weight calculation for The dress falls into the category of clothes
The peach falls into the category of fruit
The jacket falls into the category of clothes
The toaster falls into the category of appliance
The bracelet falls into the category of jewelry
The croissant falls into the category of pastry
The hairnet falls into the category of net
The computer falls into the category of
2024-07-31 18:06:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 18:09:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0366, -0.1378, -0.0248,  ...,  0.2109, -0.0516, -0.0317],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5312, -4.5273,  0.0390,  ..., -2.1914, -1.6816, -1.5039],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0044, -0.0376,  0.0061,  ..., -0.0127,  0.0216,  0.0057],
        [ 0.0217,  0.0022, -0.0148,  ...,  0.0198, -0.0388,  0.0146],
        [-0.0362,  0.0088,  0.0389,  ..., -0.0247, -0.0072,  0.0232],
        ...,
        [ 0.0211, -0.0175, -0.0250,  ...,  0.0251,  0.0043, -0.0041],
        [-0.0292, -0.0383,  0.0046,  ..., -0.0183,  0.0345, -0.0110],
        [ 0.0539, -0.0081, -0.0244,  ..., -0.0274,  0.0251,  0.0179]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.9360, -4.1641, -0.1125,  ..., -1.8105, -1.5156, -1.4824]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:09:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The dress falls into the category of clothes
The peach falls into the category of fruit
The jacket falls into the category of clothes
The toaster falls into the category of appliance
The bracelet falls into the category of jewelry
The croissant falls into the category of pastry
The hairnet falls into the category of net
The computer falls into the category of
2024-07-31 18:09:57 root INFO     [order_1_approx] starting weight calculation for The croissant falls into the category of pastry
The peach falls into the category of fruit
The jacket falls into the category of clothes
The toaster falls into the category of appliance
The dress falls into the category of clothes
The computer falls into the category of device
The hairnet falls into the category of net
The bracelet falls into the category of
2024-07-31 18:09:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 18:13:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1229,  0.0214, -0.0968,  ...,  0.0925, -0.1646, -0.2434],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4570, -5.6562, -2.9922,  ..., -1.0820, -3.0391,  1.7256],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0079, -0.0246, -0.0417,  ..., -0.0210,  0.0044,  0.0305],
        [-0.0208, -0.0108, -0.0650,  ..., -0.0271,  0.0131,  0.0557],
        [ 0.0243, -0.0096,  0.0645,  ...,  0.0123, -0.0466, -0.0384],
        ...,
        [ 0.0044, -0.0038,  0.0046,  ...,  0.0258,  0.0109,  0.0117],
        [ 0.0094, -0.0098,  0.0097,  ...,  0.0288, -0.0051,  0.0055],
        [-0.0150, -0.0063, -0.0421,  ..., -0.0303,  0.0097,  0.0453]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7383, -6.1680, -2.4199,  ..., -1.3750, -2.9902,  1.7715]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:13:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The croissant falls into the category of pastry
The peach falls into the category of fruit
The jacket falls into the category of clothes
The toaster falls into the category of appliance
The dress falls into the category of clothes
The computer falls into the category of device
The hairnet falls into the category of net
The bracelet falls into the category of
2024-07-31 18:13:01 root INFO     [order_1_approx] starting weight calculation for The bracelet falls into the category of jewelry
The hairnet falls into the category of net
The croissant falls into the category of pastry
The computer falls into the category of device
The peach falls into the category of fruit
The jacket falls into the category of clothes
The dress falls into the category of clothes
The toaster falls into the category of
2024-07-31 18:13:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 18:16:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2754, -0.0263, -0.0555,  ..., -0.0734, -0.3926, -0.0743],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0859, -2.9785,  0.3740,  ..., -1.2227, -1.4355,  3.4258],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0247,  0.0158, -0.0306,  ..., -0.0185, -0.0051,  0.0575],
        [ 0.0201,  0.0411,  0.0308,  ...,  0.0319, -0.0267, -0.0103],
        [ 0.0010, -0.0284, -0.0222,  ...,  0.0021, -0.0170,  0.0573],
        ...,
        [ 0.0190, -0.0246,  0.0003,  ...,  0.0257,  0.0027,  0.0025],
        [-0.0151, -0.0111,  0.0186,  ...,  0.0139, -0.0004, -0.0348],
        [ 0.0403,  0.0071,  0.0031,  ..., -0.0020,  0.0129,  0.0211]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6699, -3.5430,  0.7637,  ..., -1.1045, -1.2822,  3.3359]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:16:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The bracelet falls into the category of jewelry
The hairnet falls into the category of net
The croissant falls into the category of pastry
The computer falls into the category of device
The peach falls into the category of fruit
The jacket falls into the category of clothes
The dress falls into the category of clothes
The toaster falls into the category of
2024-07-31 18:16:07 root INFO     [order_1_approx] starting weight calculation for The bracelet falls into the category of jewelry
The toaster falls into the category of appliance
The computer falls into the category of device
The hairnet falls into the category of net
The peach falls into the category of fruit
The dress falls into the category of clothes
The croissant falls into the category of pastry
The jacket falls into the category of
2024-07-31 18:16:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 18:19:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2324, -0.2627, -0.0056,  ...,  0.1682, -0.0902, -0.1077],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.2539, -7.4414,  0.5635,  ...,  1.1504, -3.3281,  2.3242],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0025,  0.0015, -0.0609,  ...,  0.0382, -0.0334,  0.0090],
        [-0.0145, -0.0359, -0.0499,  ..., -0.0013,  0.0163,  0.0204],
        [ 0.0186, -0.0184,  0.0950,  ..., -0.0338, -0.0186, -0.0074],
        ...,
        [ 0.0096,  0.0096, -0.0015,  ..., -0.0108,  0.0154, -0.0441],
        [-0.0031,  0.0219, -0.0441,  ...,  0.0256,  0.0082,  0.0042],
        [-0.0055, -0.0245, -0.0260,  ..., -0.0289,  0.0140,  0.0058]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8555, -7.1484,  0.7324,  ...,  1.0430, -3.4766,  2.7891]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:19:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The bracelet falls into the category of jewelry
The toaster falls into the category of appliance
The computer falls into the category of device
The hairnet falls into the category of net
The peach falls into the category of fruit
The dress falls into the category of clothes
The croissant falls into the category of pastry
The jacket falls into the category of
2024-07-31 18:19:07 root INFO     [order_1_approx] starting weight calculation for The toaster falls into the category of appliance
The dress falls into the category of clothes
The bracelet falls into the category of jewelry
The jacket falls into the category of clothes
The computer falls into the category of device
The peach falls into the category of fruit
The hairnet falls into the category of net
The croissant falls into the category of
2024-07-31 18:19:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 18:22:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2515,  0.0266, -0.3882,  ...,  0.0370, -0.2083, -0.0682],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8730, -5.7227, -0.5898,  ..., -1.6211, -3.3555,  1.2314],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0408, -0.0394, -0.0525,  ..., -0.0199, -0.0030, -0.0037],
        [ 0.0538, -0.0021, -0.0320,  ...,  0.0123, -0.0113,  0.0014],
        [-0.0008, -0.0388,  0.0227,  ...,  0.0027, -0.0007, -0.0117],
        ...,
        [ 0.0049,  0.0253, -0.0073,  ...,  0.0867, -0.0325, -0.0318],
        [ 0.0183,  0.0028,  0.0137,  ...,  0.0232,  0.0379,  0.0233],
        [ 0.0305, -0.0205, -0.0044,  ..., -0.0363,  0.0106,  0.0365]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7266, -6.1602, -0.2581,  ..., -1.2041, -2.8145,  1.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:22:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The toaster falls into the category of appliance
The dress falls into the category of clothes
The bracelet falls into the category of jewelry
The jacket falls into the category of clothes
The computer falls into the category of device
The peach falls into the category of fruit
The hairnet falls into the category of net
The croissant falls into the category of
2024-07-31 18:22:12 root INFO     total operator prediction time: 1460.2290453910828 seconds
2024-07-31 18:22:12 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - substance
2024-07-31 18:22:12 root INFO     building operator meronyms - substance
2024-07-31 18:22:13 root INFO     [order_1_approx] starting weight calculation for A bread is made up of flour
A body is made up of flesh
A bag is made up of leather
A ice is made up of water
A water is made up of oxygen
A cocktail is made up of alcohol
A house is made up of bricks
A yogurt is made up of
2024-07-31 18:22:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 18:25:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0413, -0.0177, -0.1415,  ...,  0.1486, -0.2340, -0.0419],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2930, -3.8672,  2.8125,  ..., -3.4707, -1.3545, -0.0566],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0699,  0.0665, -0.0273,  ...,  0.0462,  0.0105, -0.0217],
        [-0.0366, -0.0097, -0.0203,  ...,  0.0065,  0.0026,  0.0118],
        [ 0.0172,  0.0222, -0.0113,  ...,  0.0192,  0.0096, -0.0073],
        ...,
        [ 0.0070, -0.0162,  0.0121,  ...,  0.0191,  0.0026, -0.0193],
        [ 0.0014,  0.0540, -0.0494,  ...,  0.0482,  0.0397,  0.0222],
        [-0.0441, -0.0732,  0.0288,  ..., -0.0311, -0.0116,  0.0550]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5859, -4.0859,  2.8496,  ..., -3.3672, -1.6650,  0.1794]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:25:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A bread is made up of flour
A body is made up of flesh
A bag is made up of leather
A ice is made up of water
A water is made up of oxygen
A cocktail is made up of alcohol
A house is made up of bricks
A yogurt is made up of
2024-07-31 18:25:16 root INFO     [order_1_approx] starting weight calculation for A house is made up of bricks
A yogurt is made up of milk
A cocktail is made up of alcohol
A bag is made up of leather
A body is made up of flesh
A water is made up of oxygen
A bread is made up of flour
A ice is made up of
2024-07-31 18:25:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 18:28:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1138,  0.3955, -0.0197,  ..., -0.0164, -0.1514, -0.1322],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0947, -4.2500,  0.1777,  ..., -6.7969,  1.0322, -0.2051],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0155, -0.0247,  0.0101,  ..., -0.0002,  0.0301,  0.0107],
        [-0.0388,  0.0271, -0.0151,  ..., -0.0014,  0.0404, -0.0125],
        [ 0.0358, -0.0223, -0.0080,  ...,  0.0235, -0.0074, -0.0178],
        ...,
        [ 0.0735, -0.0185,  0.0207,  ...,  0.0559, -0.0363, -0.0107],
        [-0.0795,  0.0243,  0.0306,  ..., -0.0023,  0.0381,  0.0165],
        [ 0.0012, -0.0088, -0.0102,  ..., -0.0144, -0.0077,  0.0145]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1445, -4.6250,  0.3352,  ..., -6.4297,  0.8506,  0.1267]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:28:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A house is made up of bricks
A yogurt is made up of milk
A cocktail is made up of alcohol
A bag is made up of leather
A body is made up of flesh
A water is made up of oxygen
A bread is made up of flour
A ice is made up of
2024-07-31 18:28:19 root INFO     [order_1_approx] starting weight calculation for A body is made up of flesh
A house is made up of bricks
A water is made up of oxygen
A ice is made up of water
A yogurt is made up of milk
A cocktail is made up of alcohol
A bread is made up of flour
A bag is made up of
2024-07-31 18:28:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 18:31:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2600,  0.1875, -0.0790,  ...,  0.1310, -0.1819, -0.0149],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.6992, -5.9336,  1.2441,  ..., -1.1650, -0.5811,  3.1250],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0102, -0.0026,  0.0150,  ...,  0.0140, -0.0143,  0.0155],
        [-0.0291, -0.0051,  0.0208,  ..., -0.0170, -0.0365, -0.0003],
        [ 0.0056, -0.0208,  0.0009,  ..., -0.0271,  0.0207, -0.0414],
        ...,
        [ 0.0580, -0.0389, -0.0224,  ...,  0.0248, -0.0038, -0.0482],
        [-0.0108,  0.0163,  0.0102,  ..., -0.0594,  0.0513,  0.0338],
        [-0.0279,  0.0324,  0.0128,  ...,  0.0041, -0.0233,  0.0735]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.7305, -6.2578,  1.2041,  ..., -1.6309, -0.5078,  3.1367]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:31:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A body is made up of flesh
A house is made up of bricks
A water is made up of oxygen
A ice is made up of water
A yogurt is made up of milk
A cocktail is made up of alcohol
A bread is made up of flour
A bag is made up of
2024-07-31 18:31:22 root INFO     [order_1_approx] starting weight calculation for A bread is made up of flour
A body is made up of flesh
A water is made up of oxygen
A bag is made up of leather
A yogurt is made up of milk
A ice is made up of water
A cocktail is made up of alcohol
A house is made up of
2024-07-31 18:31:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 18:34:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0620,  0.2203, -0.1602,  ...,  0.0620, -0.1472, -0.1078],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.8125, -8.4453,  1.2861,  ..., -2.8770, -0.3516, -0.0977],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0043, -0.0529, -0.0349,  ..., -0.0549,  0.0128,  0.0010],
        [ 0.0004,  0.0280,  0.0750,  ...,  0.0055, -0.0374,  0.0095],
        [-0.0291, -0.0031, -0.0280,  ..., -0.0087,  0.0032, -0.0124],
        ...,
        [ 0.0020, -0.0276, -0.0567,  ...,  0.0282,  0.0210, -0.0328],
        [-0.0281,  0.0218,  0.0108,  ..., -0.0077, -0.0111,  0.0088],
        [-0.0022, -0.0064,  0.0238,  ...,  0.0038, -0.0029,  0.0354]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.8008, -8.5312,  1.0195,  ..., -3.3047, -0.0344,  0.2092]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:34:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A bread is made up of flour
A body is made up of flesh
A water is made up of oxygen
A bag is made up of leather
A yogurt is made up of milk
A ice is made up of water
A cocktail is made up of alcohol
A house is made up of
2024-07-31 18:34:25 root INFO     [order_1_approx] starting weight calculation for A yogurt is made up of milk
A bag is made up of leather
A ice is made up of water
A house is made up of bricks
A cocktail is made up of alcohol
A water is made up of oxygen
A bread is made up of flour
A body is made up of
2024-07-31 18:34:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 18:37:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2905, -0.0150,  0.0442,  ..., -0.1556, -0.2202, -0.1398],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7715, -7.0547,  2.1406,  ..., -3.5527, -3.4316,  0.2012],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0326, -0.0491,  0.0326,  ..., -0.0345, -0.0328,  0.0200],
        [-0.0080,  0.0107, -0.0206,  ...,  0.0090, -0.0032, -0.0237],
        [-0.0557, -0.0218,  0.0246,  ..., -0.0051, -0.0337, -0.0006],
        ...,
        [-0.0092, -0.0237,  0.0158,  ...,  0.0116, -0.0170, -0.0260],
        [ 0.0042,  0.0263,  0.0044,  ...,  0.0296,  0.0036, -0.0007],
        [-0.0021,  0.0085,  0.0131,  ...,  0.0205,  0.0060,  0.0303]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3984, -6.9219,  1.7568,  ..., -3.9746, -3.3301,  0.4795]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:37:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A yogurt is made up of milk
A bag is made up of leather
A ice is made up of water
A house is made up of bricks
A cocktail is made up of alcohol
A water is made up of oxygen
A bread is made up of flour
A body is made up of
2024-07-31 18:37:29 root INFO     [order_1_approx] starting weight calculation for A body is made up of flesh
A yogurt is made up of milk
A water is made up of oxygen
A ice is made up of water
A bag is made up of leather
A cocktail is made up of alcohol
A house is made up of bricks
A bread is made up of
2024-07-31 18:37:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 18:40:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2024,  0.0869, -0.0668,  ..., -0.0494, -0.4526,  0.0086],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8770, -3.1094, -0.2900,  ..., -0.0571, -0.9199,  0.3232],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0122, -0.0192,  0.0005,  ..., -0.0370, -0.0056,  0.0019],
        [-0.0054, -0.0004, -0.0072,  ...,  0.0205,  0.0238,  0.0009],
        [-0.0035, -0.0243, -0.0028,  ..., -0.0035, -0.0185, -0.0161],
        ...,
        [ 0.0407,  0.0033, -0.0219,  ...,  0.0634,  0.0436, -0.0230],
        [-0.0574,  0.0554, -0.0155,  ...,  0.0142,  0.0268,  0.0499],
        [ 0.0010, -0.0292,  0.0180,  ..., -0.0118, -0.0031,  0.0225]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8438, -3.1504, -0.4939,  ..., -0.3960, -0.6841,  0.4441]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:40:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A body is made up of flesh
A yogurt is made up of milk
A water is made up of oxygen
A ice is made up of water
A bag is made up of leather
A cocktail is made up of alcohol
A house is made up of bricks
A bread is made up of
2024-07-31 18:40:35 root INFO     [order_1_approx] starting weight calculation for A body is made up of flesh
A bag is made up of leather
A water is made up of oxygen
A yogurt is made up of milk
A bread is made up of flour
A house is made up of bricks
A ice is made up of water
A cocktail is made up of
2024-07-31 18:40:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 18:43:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0698, -0.0978, -0.1219,  ...,  0.1409, -0.1868, -0.0594],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0156, -6.7344, -2.9863,  ..., -3.1211, -0.4893, -5.6328],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0014,  0.0034,  0.0007,  ..., -0.0103, -0.0381, -0.0425],
        [-0.0134,  0.0430,  0.0223,  ...,  0.0234,  0.0486,  0.0526],
        [ 0.0062, -0.0349,  0.0174,  ...,  0.0207, -0.0447,  0.0293],
        ...,
        [ 0.0343,  0.0001, -0.0146,  ...,  0.0220, -0.0161,  0.0249],
        [ 0.0090,  0.0462, -0.0133,  ...,  0.0351,  0.0113,  0.0067],
        [ 0.0262, -0.0851, -0.0123,  ..., -0.0250,  0.0430,  0.0262]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6348, -7.0898, -2.8145,  ..., -3.2891, -0.1379, -5.7891]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:43:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A body is made up of flesh
A bag is made up of leather
A water is made up of oxygen
A yogurt is made up of milk
A bread is made up of flour
A house is made up of bricks
A ice is made up of water
A cocktail is made up of
2024-07-31 18:43:37 root INFO     [order_1_approx] starting weight calculation for A house is made up of bricks
A body is made up of flesh
A yogurt is made up of milk
A ice is made up of water
A cocktail is made up of alcohol
A bag is made up of leather
A bread is made up of flour
A water is made up of
2024-07-31 18:43:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 18:46:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0318,  0.1787, -0.0605,  ..., -0.1379, -0.2209, -0.0867],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1631, -2.6016,  1.0244,  ..., -4.1406,  2.2461,  0.9199],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0247,  0.0203,  0.0202,  ..., -0.0004, -0.0034, -0.0456],
        [-0.0274, -0.0538, -0.0045,  ...,  0.0164, -0.0181,  0.0090],
        [ 0.0107,  0.0513,  0.0036,  ..., -0.0114, -0.0212,  0.0140],
        ...,
        [ 0.0133, -0.0506,  0.0211,  ...,  0.0348, -0.0102, -0.0009],
        [-0.0092,  0.0363, -0.0195,  ..., -0.0264,  0.0289, -0.0161],
        [ 0.0099, -0.0060,  0.0057,  ...,  0.0041, -0.0110,  0.0143]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0273, -2.0332,  1.2031,  ..., -4.0000,  1.7578,  0.8511]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:46:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A house is made up of bricks
A body is made up of flesh
A yogurt is made up of milk
A ice is made up of water
A cocktail is made up of alcohol
A bag is made up of leather
A bread is made up of flour
A water is made up of
2024-07-31 18:46:40 root INFO     total operator prediction time: 1468.059176683426 seconds
2024-07-31 18:46:40 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on synonyms - intensity
2024-07-31 18:46:40 root INFO     building operator synonyms - intensity
2024-07-31 18:46:41 root INFO     [order_1_approx] starting weight calculation for A more intense word for unhappy is miserable
A more intense word for unfortunate is tragic
A more intense word for chuckle is laugh
A more intense word for lake is sea
A more intense word for pony is horse
A more intense word for nap is sleep
A more intense word for angry is furious
A more intense word for sea is
2024-07-31 18:46:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 18:49:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0507, -0.1644,  0.0568,  ..., -0.1135, -0.2454,  0.0434],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3486, -6.5547,  0.7446,  ..., -2.9922, -0.4756,  0.7168],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.2751e-02, -1.9669e-02, -1.5656e-02,  ...,  2.0050e-02,
          2.2766e-02,  2.1545e-02],
        [ 2.1332e-02,  2.1133e-02,  5.5267e-02,  ...,  3.8055e-02,
         -1.3397e-02, -3.0346e-03],
        [ 2.8305e-03, -1.8219e-02,  2.0325e-02,  ...,  1.7090e-02,
         -1.1703e-02,  3.9398e-02],
        ...,
        [ 7.8278e-03,  4.5013e-03, -2.1935e-03,  ...,  3.7415e-02,
          6.0768e-03,  3.1528e-03],
        [-2.3590e-02, -1.6266e-02, -5.1117e-03,  ...,  3.8452e-02,
          3.2532e-02, -1.6754e-02],
        [-1.1719e-02, -3.1311e-02, -6.1035e-05,  ..., -1.2573e-02,
          1.1024e-02,  1.6632e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2854, -6.2852,  1.4053,  ..., -2.6641, -0.5059,  0.5547]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:49:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for unhappy is miserable
A more intense word for unfortunate is tragic
A more intense word for chuckle is laugh
A more intense word for lake is sea
A more intense word for pony is horse
A more intense word for nap is sleep
A more intense word for angry is furious
A more intense word for sea is
2024-07-31 18:49:43 root INFO     [order_1_approx] starting weight calculation for A more intense word for sea is ocean
A more intense word for angry is furious
A more intense word for unfortunate is tragic
A more intense word for chuckle is laugh
A more intense word for unhappy is miserable
A more intense word for pony is horse
A more intense word for nap is sleep
A more intense word for lake is
2024-07-31 18:49:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 18:52:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0455,  0.0530,  0.0170,  ..., -0.3921, -0.2163, -0.0864],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.2412, -3.9531,  0.9946,  ..., -2.6250, -0.2174, -0.3008],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0351, -0.0527, -0.0053,  ..., -0.0099, -0.0406,  0.0231],
        [ 0.0198,  0.0657,  0.0249,  ...,  0.0439,  0.0187, -0.0142],
        [-0.0179, -0.0134,  0.0231,  ..., -0.0014,  0.0009,  0.0166],
        ...,
        [-0.0320,  0.0196,  0.0285,  ...,  0.0334,  0.0295, -0.0163],
        [ 0.0107, -0.0460,  0.0005,  ...,  0.0028, -0.0118,  0.0134],
        [ 0.0300, -0.0299,  0.0251,  ..., -0.0088,  0.0042,  0.0149]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.9771, -4.2266,  1.0615,  ..., -2.7031, -0.3384, -0.5161]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:52:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for sea is ocean
A more intense word for angry is furious
A more intense word for unfortunate is tragic
A more intense word for chuckle is laugh
A more intense word for unhappy is miserable
A more intense word for pony is horse
A more intense word for nap is sleep
A more intense word for lake is
2024-07-31 18:52:46 root INFO     [order_1_approx] starting weight calculation for A more intense word for lake is sea
A more intense word for pony is horse
A more intense word for nap is sleep
A more intense word for sea is ocean
A more intense word for unhappy is miserable
A more intense word for angry is furious
A more intense word for chuckle is laugh
A more intense word for unfortunate is
2024-07-31 18:52:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 18:55:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0703,  0.1969,  0.0016,  ..., -0.0692, -0.3977, -0.3479],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0156, -2.1504,  2.0098,  ..., -0.9453,  0.1631, -3.5078],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0561,  0.0544, -0.0041,  ...,  0.0120,  0.0312,  0.0016],
        [-0.0185, -0.0234,  0.0018,  ...,  0.0247, -0.0237,  0.0034],
        [ 0.0158, -0.0042,  0.0026,  ...,  0.0178, -0.0085,  0.0017],
        ...,
        [ 0.0009,  0.0273,  0.0030,  ...,  0.0030, -0.0298, -0.0468],
        [ 0.0259, -0.0257, -0.0162,  ...,  0.0028,  0.0012, -0.0102],
        [ 0.0318, -0.0580,  0.0035,  ..., -0.0141, -0.0694,  0.0366]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8125, -2.1055,  1.7383,  ..., -0.7402, -0.2744, -3.4316]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:55:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for lake is sea
A more intense word for pony is horse
A more intense word for nap is sleep
A more intense word for sea is ocean
A more intense word for unhappy is miserable
A more intense word for angry is furious
A more intense word for chuckle is laugh
A more intense word for unfortunate is
2024-07-31 18:55:47 root INFO     [order_1_approx] starting weight calculation for A more intense word for unhappy is miserable
A more intense word for pony is horse
A more intense word for angry is furious
A more intense word for lake is sea
A more intense word for chuckle is laugh
A more intense word for sea is ocean
A more intense word for unfortunate is tragic
A more intense word for nap is
2024-07-31 18:55:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 18:58:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0279, -0.0760,  0.1249,  ...,  0.0880, -0.4233,  0.0048],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.9219, -3.7363,  4.3672,  ...,  1.1494, -0.6445, -1.0166],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0283, -0.1165, -0.0002,  ...,  0.0064, -0.0771, -0.0029],
        [-0.0323, -0.0336,  0.0576,  ..., -0.0306, -0.0204, -0.0260],
        [-0.0358, -0.0618,  0.0328,  ...,  0.0171, -0.0262,  0.0177],
        ...,
        [ 0.0324,  0.0117,  0.0482,  ...,  0.0406,  0.0050, -0.0378],
        [ 0.0166,  0.0041,  0.0070,  ...,  0.0211, -0.0313, -0.0326],
        [-0.0058, -0.0004,  0.0212,  ...,  0.0137,  0.0208,  0.0072]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3359, -2.1406,  5.0234,  ...,  1.0869, -1.2168, -1.0898]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:58:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for unhappy is miserable
A more intense word for pony is horse
A more intense word for angry is furious
A more intense word for lake is sea
A more intense word for chuckle is laugh
A more intense word for sea is ocean
A more intense word for unfortunate is tragic
A more intense word for nap is
2024-07-31 18:58:51 root INFO     [order_1_approx] starting weight calculation for A more intense word for chuckle is laugh
A more intense word for angry is furious
A more intense word for unfortunate is tragic
A more intense word for lake is sea
A more intense word for pony is horse
A more intense word for sea is ocean
A more intense word for nap is sleep
A more intense word for unhappy is
2024-07-31 18:58:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 19:01:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1271,  0.0340,  0.0547,  ..., -0.1296, -0.1638,  0.0933],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6562, -3.5938,  2.1152,  ..., -2.9062, -0.9688, -1.6348],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0159,  0.0249, -0.0351,  ..., -0.0078,  0.0271,  0.0302],
        [-0.0222, -0.0008,  0.0768,  ..., -0.0069, -0.0356, -0.0377],
        [-0.0451,  0.0037,  0.0074,  ...,  0.0300, -0.0139,  0.0308],
        ...,
        [-0.0504, -0.0154,  0.0350,  ..., -0.0138, -0.0416, -0.0440],
        [ 0.0216,  0.0125, -0.0394,  ..., -0.0156, -0.0012, -0.0322],
        [-0.0099, -0.0263,  0.0264,  ..., -0.0005, -0.0615, -0.0152]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1895, -3.2871,  1.5977,  ..., -2.4160, -1.0537, -1.4541]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:01:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for chuckle is laugh
A more intense word for angry is furious
A more intense word for unfortunate is tragic
A more intense word for lake is sea
A more intense word for pony is horse
A more intense word for sea is ocean
A more intense word for nap is sleep
A more intense word for unhappy is
2024-07-31 19:01:53 root INFO     [order_1_approx] starting weight calculation for A more intense word for unfortunate is tragic
A more intense word for nap is sleep
A more intense word for unhappy is miserable
A more intense word for sea is ocean
A more intense word for chuckle is laugh
A more intense word for lake is sea
A more intense word for pony is horse
A more intense word for angry is
2024-07-31 19:01:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 19:04:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0037,  0.1534, -0.2085,  ...,  0.0787, -0.3298, -0.0656],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8574, -6.1562, -0.2537,  ..., -2.6562, -1.6250, -0.1006],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0198, -0.0336,  0.0134,  ..., -0.0122,  0.0179, -0.0666],
        [ 0.0373, -0.0106,  0.0075,  ...,  0.0004, -0.0112, -0.0045],
        [-0.0253, -0.0052,  0.0312,  ..., -0.0167, -0.0196,  0.0035],
        ...,
        [ 0.0030,  0.0072, -0.0017,  ...,  0.0179, -0.0041, -0.0347],
        [-0.0225,  0.0018,  0.0191,  ...,  0.0156,  0.0414, -0.0246],
        [ 0.0210,  0.0145, -0.0187,  ..., -0.0033, -0.0123,  0.0206]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5879, -5.7422, -0.4229,  ..., -2.5566, -2.0371, -0.1841]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:04:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for unfortunate is tragic
A more intense word for nap is sleep
A more intense word for unhappy is miserable
A more intense word for sea is ocean
A more intense word for chuckle is laugh
A more intense word for lake is sea
A more intense word for pony is horse
A more intense word for angry is
2024-07-31 19:04:56 root INFO     [order_1_approx] starting weight calculation for A more intense word for unhappy is miserable
A more intense word for angry is furious
A more intense word for pony is horse
A more intense word for sea is ocean
A more intense word for unfortunate is tragic
A more intense word for lake is sea
A more intense word for nap is sleep
A more intense word for chuckle is
2024-07-31 19:04:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 19:07:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2031, -0.0469, -0.0746,  ..., -0.0304, -0.5449,  0.0837],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5889, -1.7715,  4.7852,  ...,  3.0391,  0.1182, -0.3770],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0192, -0.0402, -0.0600,  ..., -0.0054,  0.0255,  0.0026],
        [ 0.0052,  0.0468,  0.0145,  ...,  0.0183, -0.0151,  0.0427],
        [-0.0220, -0.0072, -0.0319,  ..., -0.0043, -0.0101, -0.0147],
        ...,
        [-0.0049, -0.0068, -0.0090,  ..., -0.0066,  0.0138, -0.0281],
        [-0.0180, -0.0314, -0.0349,  ..., -0.0152, -0.0091,  0.0206],
        [ 0.0103,  0.0296, -0.0077,  ..., -0.0148,  0.0043,  0.0124]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9492, -2.3867,  5.0469,  ...,  2.7773,  0.0864, -0.5952]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:08:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for unhappy is miserable
A more intense word for angry is furious
A more intense word for pony is horse
A more intense word for sea is ocean
A more intense word for unfortunate is tragic
A more intense word for lake is sea
A more intense word for nap is sleep
A more intense word for chuckle is
2024-07-31 19:08:01 root INFO     [order_1_approx] starting weight calculation for A more intense word for lake is sea
A more intense word for sea is ocean
A more intense word for chuckle is laugh
A more intense word for angry is furious
A more intense word for unfortunate is tragic
A more intense word for nap is sleep
A more intense word for unhappy is miserable
A more intense word for pony is
2024-07-31 19:08:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 19:11:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0520,  0.0233, -0.1158,  ..., -0.1780, -0.1373,  0.1870],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5693, -3.9160, -0.5547,  ...,  2.1426, -3.1797, -0.8701],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0779, -0.1284,  0.0009,  ..., -0.0415, -0.0511,  0.0586],
        [ 0.0353,  0.0309,  0.0070,  ...,  0.0725, -0.0057,  0.0103],
        [-0.0017,  0.0036,  0.1064,  ..., -0.0564,  0.0245,  0.0297],
        ...,
        [ 0.0513, -0.0675, -0.0383,  ...,  0.0312, -0.0488, -0.0415],
        [-0.0431,  0.0057, -0.0757,  ...,  0.0067,  0.0232, -0.0358],
        [ 0.0100, -0.0419,  0.0370,  ..., -0.0444, -0.0805,  0.0352]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7163, -3.2188, -0.3140,  ...,  1.7031, -2.7871, -0.4124]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:11:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for lake is sea
A more intense word for sea is ocean
A more intense word for chuckle is laugh
A more intense word for angry is furious
A more intense word for unfortunate is tragic
A more intense word for nap is sleep
A more intense word for unhappy is miserable
A more intense word for pony is
2024-07-31 19:11:05 root INFO     total operator prediction time: 1464.1841871738434 seconds
2024-07-31 19:11:05 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hypernyms - animals
2024-07-31 19:11:05 root INFO     building operator hypernyms - animals
2024-07-31 19:11:05 root INFO     [order_1_approx] starting weight calculation for The leopard falls into the category of feline
The triceratops falls into the category of dinosaur
The buffalo falls into the category of bovid
The beetle falls into the category of insect
The deer falls into the category of bovid
The allosaurus falls into the category of dinosaur
The wolf falls into the category of canine
The viper falls into the category of
2024-07-31 19:11:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 19:14:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0410,  0.3203,  0.1735,  ..., -0.1606, -0.0712,  0.1257],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3960, -6.0195,  1.5264,  ..., -0.5200, -3.7207, -0.3901],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0426, -0.0353, -0.0596,  ..., -0.0163,  0.0222,  0.0062],
        [ 0.0201, -0.0154, -0.0460,  ...,  0.0237, -0.0646,  0.0352],
        [ 0.0019,  0.0168,  0.0629,  ..., -0.0274, -0.0055, -0.0242],
        ...,
        [-0.0032,  0.0083, -0.0063,  ...,  0.0306, -0.0267,  0.0037],
        [-0.0159,  0.0497, -0.0024,  ...,  0.0184,  0.0388,  0.0052],
        [ 0.0517,  0.0108,  0.0092,  ..., -0.0171,  0.0056, -0.0163]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4473, -6.1953,  1.5371,  ..., -0.2661, -3.7285, -0.4609]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:14:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The leopard falls into the category of feline
The triceratops falls into the category of dinosaur
The buffalo falls into the category of bovid
The beetle falls into the category of insect
The deer falls into the category of bovid
The allosaurus falls into the category of dinosaur
The wolf falls into the category of canine
The viper falls into the category of
2024-07-31 19:14:05 root INFO     [order_1_approx] starting weight calculation for The leopard falls into the category of feline
The deer falls into the category of bovid
The buffalo falls into the category of bovid
The triceratops falls into the category of dinosaur
The allosaurus falls into the category of dinosaur
The beetle falls into the category of insect
The viper falls into the category of snake
The wolf falls into the category of
2024-07-31 19:14:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 19:17:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2532, -0.0195, -0.0264,  ..., -0.0262,  0.0081, -0.1625],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2690, -6.4648,  1.5264,  ..., -3.1289, -5.7578,  1.2520],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0081, -0.0461, -0.0065,  ...,  0.0026, -0.0108,  0.0157],
        [-0.0346, -0.0527,  0.0049,  ...,  0.0116,  0.0177,  0.0339],
        [ 0.0231,  0.0075,  0.0338,  ..., -0.0102, -0.0418, -0.0200],
        ...,
        [-0.0223, -0.0060,  0.0142,  ..., -0.0012, -0.0027,  0.0032],
        [ 0.0082, -0.0033, -0.0061,  ...,  0.0027,  0.0366,  0.0134],
        [-0.0257, -0.0443, -0.0196,  ..., -0.0121,  0.0239,  0.0093]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2026, -6.1055,  1.4170,  ..., -2.8945, -5.8477,  1.6055]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:17:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The leopard falls into the category of feline
The deer falls into the category of bovid
The buffalo falls into the category of bovid
The triceratops falls into the category of dinosaur
The allosaurus falls into the category of dinosaur
The beetle falls into the category of insect
The viper falls into the category of snake
The wolf falls into the category of
2024-07-31 19:17:11 root INFO     [order_1_approx] starting weight calculation for The wolf falls into the category of canine
The deer falls into the category of bovid
The buffalo falls into the category of bovid
The triceratops falls into the category of dinosaur
The leopard falls into the category of feline
The viper falls into the category of snake
The beetle falls into the category of insect
The allosaurus falls into the category of
2024-07-31 19:17:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 19:20:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0057, -0.0649, -0.3215,  ..., -0.0956, -0.2620, -0.0200],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9404, -3.5234,  2.7188,  ..., -1.6387, -5.5156, -0.9829],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0450, -0.0487, -0.0256,  ..., -0.0028,  0.0432, -0.0229],
        [ 0.0015,  0.0137,  0.0257,  ...,  0.0165,  0.0153,  0.0132],
        [ 0.0059, -0.0102,  0.0071,  ...,  0.0005, -0.0256,  0.0068],
        ...,
        [-0.0145,  0.0021,  0.0232,  ...,  0.0263, -0.0132,  0.0149],
        [-0.0014,  0.0167,  0.0008,  ..., -0.0204,  0.0026, -0.0072],
        [ 0.0085, -0.0218,  0.0100,  ...,  0.0259,  0.0028,  0.0341]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1523, -3.8633,  2.8242,  ..., -1.4746, -5.8398, -0.5645]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:20:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The wolf falls into the category of canine
The deer falls into the category of bovid
The buffalo falls into the category of bovid
The triceratops falls into the category of dinosaur
The leopard falls into the category of feline
The viper falls into the category of snake
The beetle falls into the category of insect
The allosaurus falls into the category of
2024-07-31 19:20:19 root INFO     [order_1_approx] starting weight calculation for The viper falls into the category of snake
The wolf falls into the category of canine
The leopard falls into the category of feline
The buffalo falls into the category of bovid
The allosaurus falls into the category of dinosaur
The triceratops falls into the category of dinosaur
The beetle falls into the category of insect
The deer falls into the category of
2024-07-31 19:20:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 19:23:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1135,  0.1351, -0.1775,  ...,  0.1055, -0.0660,  0.0472],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1195, -4.7266,  0.2832,  ..., -0.0249, -9.1250, -1.2412],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0152, -0.0238, -0.0003,  ...,  0.0033, -0.0126,  0.0051],
        [-0.0662, -0.0125, -0.0252,  ...,  0.0394, -0.0461,  0.0129],
        [ 0.0197,  0.0211,  0.0572,  ..., -0.0720, -0.0040, -0.0038],
        ...,
        [-0.0399, -0.0031, -0.0163,  ...,  0.0146, -0.0108,  0.0009],
        [ 0.0241, -0.0043,  0.0008,  ..., -0.0293,  0.0609, -0.0014],
        [-0.0392, -0.0228,  0.0198,  ..., -0.0153,  0.0056, -0.0096]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2030, -3.4414, -0.3345,  ...,  0.6055, -9.0625, -1.0615]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:23:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The viper falls into the category of snake
The wolf falls into the category of canine
The leopard falls into the category of feline
The buffalo falls into the category of bovid
The allosaurus falls into the category of dinosaur
The triceratops falls into the category of dinosaur
The beetle falls into the category of insect
The deer falls into the category of
2024-07-31 19:23:20 root INFO     [order_1_approx] starting weight calculation for The buffalo falls into the category of bovid
The leopard falls into the category of feline
The wolf falls into the category of canine
The deer falls into the category of bovid
The beetle falls into the category of insect
The allosaurus falls into the category of dinosaur
The viper falls into the category of snake
The triceratops falls into the category of
2024-07-31 19:23:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 19:26:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0405,  0.0478, -0.0312,  ..., -0.0168, -0.2440, -0.0455],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1211, -3.3867,  1.0352,  ..., -1.3447, -4.7422, -2.5859],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0112, -0.0732, -0.0316,  ..., -0.0083, -0.0076, -0.0074],
        [ 0.0364, -0.0374,  0.0304,  ...,  0.0475,  0.0202,  0.0698],
        [ 0.0010,  0.0864,  0.0344,  ..., -0.0453, -0.0781, -0.0594],
        ...,
        [-0.0020, -0.0078,  0.0294,  ...,  0.0397, -0.0215, -0.0009],
        [ 0.0279,  0.0923,  0.0247,  ...,  0.0140,  0.0188, -0.0218],
        [-0.0301, -0.1615, -0.0017,  ...,  0.0128,  0.0451,  0.0600]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3535, -3.0664,  0.8242,  ..., -0.8823, -4.7969, -1.8555]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:26:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The buffalo falls into the category of bovid
The leopard falls into the category of feline
The wolf falls into the category of canine
The deer falls into the category of bovid
The beetle falls into the category of insect
The allosaurus falls into the category of dinosaur
The viper falls into the category of snake
The triceratops falls into the category of
2024-07-31 19:26:26 root INFO     [order_1_approx] starting weight calculation for The allosaurus falls into the category of dinosaur
The beetle falls into the category of insect
The viper falls into the category of snake
The triceratops falls into the category of dinosaur
The wolf falls into the category of canine
The deer falls into the category of bovid
The buffalo falls into the category of bovid
The leopard falls into the category of
2024-07-31 19:26:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 19:29:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2520,  0.0718, -0.3252,  ..., -0.0615, -0.0736,  0.0060],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0811, -6.6758, -0.6621,  ..., -3.9316, -6.6523, -0.6045],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0018, -0.0223, -0.0158,  ...,  0.0019,  0.0116,  0.0163],
        [ 0.0071,  0.0005,  0.0015,  ...,  0.0040, -0.0060,  0.0043],
        [-0.0304, -0.0753, -0.0219,  ..., -0.0063,  0.0001,  0.0400],
        ...,
        [-0.0097,  0.0052, -0.0048,  ..., -0.0052, -0.0083, -0.0021],
        [ 0.0311,  0.0332,  0.0164,  ...,  0.0132,  0.0287, -0.0226],
        [-0.0035,  0.0045, -0.0034,  ..., -0.0249,  0.0069,  0.0042]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1152, -6.7148, -0.3003,  ..., -3.8379, -6.8555, -0.3933]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:29:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The allosaurus falls into the category of dinosaur
The beetle falls into the category of insect
The viper falls into the category of snake
The triceratops falls into the category of dinosaur
The wolf falls into the category of canine
The deer falls into the category of bovid
The buffalo falls into the category of bovid
The leopard falls into the category of
2024-07-31 19:29:27 root INFO     [order_1_approx] starting weight calculation for The beetle falls into the category of insect
The wolf falls into the category of canine
The triceratops falls into the category of dinosaur
The leopard falls into the category of feline
The deer falls into the category of bovid
The allosaurus falls into the category of dinosaur
The viper falls into the category of snake
The buffalo falls into the category of
2024-07-31 19:29:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 19:32:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1879, -0.0123, -0.0042,  ...,  0.0230, -0.1632, -0.0402],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1057, -6.7422,  2.9023,  ..., -0.2998, -6.9961, -1.8281],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0429, -0.0770, -0.0082,  ..., -0.0354,  0.0202,  0.0678],
        [-0.0480, -0.0754, -0.0187,  ..., -0.0204,  0.0308,  0.0959],
        [ 0.0173, -0.0067,  0.0432,  ...,  0.0344, -0.0688, -0.0419],
        ...,
        [-0.0203, -0.0201, -0.0163,  ...,  0.0351,  0.0062,  0.0173],
        [ 0.0069,  0.0791,  0.0346,  ...,  0.0256,  0.0218, -0.0659],
        [-0.0084, -0.0634, -0.0033,  ..., -0.0541,  0.0565,  0.0287]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3159, -6.1875,  2.7969,  ...,  0.1953, -7.4102, -1.5713]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:32:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The beetle falls into the category of insect
The wolf falls into the category of canine
The triceratops falls into the category of dinosaur
The leopard falls into the category of feline
The deer falls into the category of bovid
The allosaurus falls into the category of dinosaur
The viper falls into the category of snake
The buffalo falls into the category of
2024-07-31 19:32:31 root INFO     [order_1_approx] starting weight calculation for The allosaurus falls into the category of dinosaur
The viper falls into the category of snake
The wolf falls into the category of canine
The leopard falls into the category of feline
The triceratops falls into the category of dinosaur
The buffalo falls into the category of bovid
The deer falls into the category of bovid
The beetle falls into the category of
2024-07-31 19:32:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 19:35:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0037,  0.1553,  0.0414,  ...,  0.0259, -0.1444, -0.0594],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5098, -3.3633,  2.6211,  ..., -0.8750, -2.9238, -2.7168],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0096, -0.0278, -0.0142,  ..., -0.0226,  0.0041,  0.0306],
        [ 0.0087,  0.0106, -0.0363,  ...,  0.0417,  0.0333,  0.0115],
        [-0.0150, -0.0198,  0.0172,  ..., -0.0093, -0.0373,  0.0008],
        ...,
        [ 0.0052,  0.0186, -0.0223,  ...,  0.0271, -0.0077, -0.0022],
        [-0.0120,  0.0108,  0.0169,  ...,  0.0146,  0.0147, -0.0061],
        [ 0.0115,  0.0087, -0.0134,  ..., -0.0125,  0.0220,  0.0226]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6738, -3.5430,  2.8184,  ..., -0.6177, -3.0488, -2.5957]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:35:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The allosaurus falls into the category of dinosaur
The viper falls into the category of snake
The wolf falls into the category of canine
The leopard falls into the category of feline
The triceratops falls into the category of dinosaur
The buffalo falls into the category of bovid
The deer falls into the category of bovid
The beetle falls into the category of
2024-07-31 19:35:30 root INFO     total operator prediction time: 1465.103132724762 seconds
2024-07-31 19:35:30 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hyponyms - misc
2024-07-31 19:35:30 root INFO     building operator hyponyms - misc
2024-07-31 19:35:30 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a collar is choker
A more specific term for a cookware is pot
A more specific term for a bag is pouch
A more specific term for a shelf is bookshelf
A more specific term for a shirt is polo
A more specific term for a burger is hamburger
A more specific term for a dress is
2024-07-31 19:35:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 19:38:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0298, -0.1947, -0.1532,  ...,  0.2229, -0.1675, -0.0488],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0166, -4.0664, -1.6943,  ...,  1.7148, -3.4609,  0.9082],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0303, -0.0359, -0.0376,  ..., -0.0277,  0.0608, -0.0004],
        [-0.0079, -0.0054,  0.0289,  ...,  0.0157,  0.0049, -0.0374],
        [ 0.0308,  0.0037,  0.0436,  ..., -0.0104, -0.0374, -0.0132],
        ...,
        [-0.0243, -0.0059, -0.0182,  ...,  0.0013,  0.0637, -0.0211],
        [-0.0077, -0.0258, -0.0067,  ...,  0.0401,  0.0692, -0.0289],
        [-0.0009, -0.0397,  0.0162,  ...,  0.0059, -0.0010,  0.0190]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5396, -3.2578, -1.9346,  ...,  2.4473, -3.5371,  1.6309]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:38:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a bed is bunk
A more specific term for a collar is choker
A more specific term for a cookware is pot
A more specific term for a bag is pouch
A more specific term for a shelf is bookshelf
A more specific term for a shirt is polo
A more specific term for a burger is hamburger
A more specific term for a dress is
2024-07-31 19:38:32 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a shelf is bookshelf
A more specific term for a cookware is pot
A more specific term for a shirt is polo
A more specific term for a collar is choker
A more specific term for a burger is hamburger
A more specific term for a dress is gown
A more specific term for a bag is
2024-07-31 19:38:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 19:41:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1975,  0.1586, -0.0323,  ...,  0.2217, -0.2852, -0.1027],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1211, -4.4922, -3.2930,  ...,  0.5830,  1.0205,  1.5371],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0127, -0.0277, -0.0087,  ...,  0.0107, -0.0584,  0.0109],
        [-0.0368, -0.0242,  0.0291,  ..., -0.0147, -0.0137,  0.0037],
        [-0.0021, -0.0219,  0.0367,  ...,  0.0058, -0.0326,  0.0063],
        ...,
        [-0.0220, -0.0346, -0.0101,  ...,  0.0241, -0.0252, -0.0197],
        [-0.0268,  0.0172,  0.0108,  ..., -0.0158,  0.0287, -0.0011],
        [ 0.0027,  0.0078, -0.0006,  ...,  0.0080,  0.0183,  0.0232]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.1758, -4.2305, -3.1250,  ...,  1.1328,  0.5483,  1.6152]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:41:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a bed is bunk
A more specific term for a shelf is bookshelf
A more specific term for a cookware is pot
A more specific term for a shirt is polo
A more specific term for a collar is choker
A more specific term for a burger is hamburger
A more specific term for a dress is gown
A more specific term for a bag is
2024-07-31 19:41:27 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bag is pouch
A more specific term for a dress is gown
A more specific term for a collar is choker
A more specific term for a cookware is pot
A more specific term for a bed is bunk
A more specific term for a burger is hamburger
A more specific term for a shirt is polo
A more specific term for a shelf is
2024-07-31 19:41:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 19:44:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0552,  0.0709, -0.1014,  ...,  0.1654, -0.1346, -0.0725],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.8438, -3.5762,  1.3223,  ...,  3.0781, -3.0508,  1.7383],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0753, -0.0258, -0.0033,  ...,  0.0214,  0.0323, -0.0142],
        [-0.0186,  0.0248,  0.0267,  ..., -0.0094, -0.0428,  0.0157],
        [ 0.0185, -0.0258,  0.0405,  ...,  0.0090,  0.0075,  0.0086],
        ...,
        [-0.0016,  0.0041, -0.0038,  ...,  0.0028, -0.0389,  0.0122],
        [ 0.0363,  0.0605,  0.0160,  ..., -0.0003, -0.0004, -0.0365],
        [-0.0021, -0.0131, -0.0111,  ..., -0.0276, -0.0077,  0.0139]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.7383, -3.7480,  1.2090,  ...,  2.8320, -3.4238,  1.8330]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:44:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a bag is pouch
A more specific term for a dress is gown
A more specific term for a collar is choker
A more specific term for a cookware is pot
A more specific term for a bed is bunk
A more specific term for a burger is hamburger
A more specific term for a shirt is polo
A more specific term for a shelf is
2024-07-31 19:44:28 root INFO     [order_1_approx] starting weight calculation for A more specific term for a burger is hamburger
A more specific term for a collar is choker
A more specific term for a dress is gown
A more specific term for a bed is bunk
A more specific term for a bag is pouch
A more specific term for a cookware is pot
A more specific term for a shelf is bookshelf
A more specific term for a shirt is
2024-07-31 19:44:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 19:47:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1602, -0.1161, -0.1846,  ...,  0.1200, -0.2659, -0.0435],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5020, -2.1973,  0.1519,  ...,  0.8242, -1.2256, -1.1094],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0101, -0.0436,  0.0263,  ..., -0.0152,  0.0069, -0.0175],
        [ 0.0055,  0.0332,  0.0044,  ...,  0.0310, -0.0108,  0.0196],
        [ 0.0133, -0.0435,  0.0419,  ..., -0.0308, -0.0050, -0.0332],
        ...,
        [ 0.0213, -0.0061, -0.0309,  ...,  0.0029,  0.0562, -0.0196],
        [-0.0054,  0.0054, -0.0022,  ...,  0.0083,  0.0139,  0.0018],
        [-0.0013, -0.0494,  0.0010,  ..., -0.0246,  0.0848, -0.0099]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4629, -2.1836,  0.6133,  ...,  0.3506, -1.6738, -0.0762]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:47:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a burger is hamburger
A more specific term for a collar is choker
A more specific term for a dress is gown
A more specific term for a bed is bunk
A more specific term for a bag is pouch
A more specific term for a cookware is pot
A more specific term for a shelf is bookshelf
A more specific term for a shirt is
2024-07-31 19:47:33 root INFO     [order_1_approx] starting weight calculation for A more specific term for a dress is gown
A more specific term for a shelf is bookshelf
A more specific term for a bed is bunk
A more specific term for a shirt is polo
A more specific term for a bag is pouch
A more specific term for a collar is choker
A more specific term for a burger is hamburger
A more specific term for a cookware is
2024-07-31 19:47:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 19:50:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0220, -0.1527,  0.0499,  ..., -0.2163, -0.1047, -0.1681],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1094, -2.8652,  2.7539,  ..., -3.0527, -4.2891, -0.5386],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0176, -0.0083, -0.0141,  ..., -0.0019,  0.0182,  0.0080],
        [ 0.0114,  0.0449, -0.0024,  ..., -0.0341, -0.0022,  0.0108],
        [ 0.0152, -0.0759, -0.0051,  ..., -0.0045,  0.0136, -0.0654],
        ...,
        [ 0.0049, -0.0163, -0.0089,  ...,  0.0212,  0.0034,  0.0343],
        [-0.0046, -0.0200, -0.0155,  ..., -0.0133,  0.0266,  0.0016],
        [ 0.0286, -0.0015, -0.0057,  ..., -0.0089,  0.0018,  0.0179]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0586, -2.6621,  2.4336,  ..., -2.1387, -4.2539, -0.4531]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:50:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a dress is gown
A more specific term for a shelf is bookshelf
A more specific term for a bed is bunk
A more specific term for a shirt is polo
A more specific term for a bag is pouch
A more specific term for a collar is choker
A more specific term for a burger is hamburger
A more specific term for a cookware is
2024-07-31 19:50:36 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a dress is gown
A more specific term for a shelf is bookshelf
A more specific term for a burger is hamburger
A more specific term for a cookware is pot
A more specific term for a bag is pouch
A more specific term for a shirt is polo
A more specific term for a collar is
2024-07-31 19:50:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 19:53:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2080,  0.0026,  0.1637,  ...,  0.1941, -0.1543, -0.3032],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5547, -3.6367, -1.7324,  ...,  2.9492,  5.3711,  1.1484],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0425, -0.0320, -0.0841,  ...,  0.0330,  0.0402,  0.0278],
        [-0.0076,  0.0691, -0.0489,  ...,  0.0401,  0.0419,  0.0571],
        [ 0.0198, -0.0120,  0.0495,  ..., -0.0390, -0.0271,  0.0033],
        ...,
        [ 0.0305,  0.0073, -0.0014,  ...,  0.0161, -0.0381, -0.0196],
        [ 0.0120, -0.0083, -0.0635,  ...,  0.0230,  0.1097,  0.0075],
        [ 0.0183,  0.0666, -0.0553,  ...,  0.0150,  0.0436,  0.0858]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5195, -3.1152, -1.7070,  ...,  3.3477,  4.3906,  1.6992]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:53:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a bed is bunk
A more specific term for a dress is gown
A more specific term for a shelf is bookshelf
A more specific term for a burger is hamburger
A more specific term for a cookware is pot
A more specific term for a bag is pouch
A more specific term for a shirt is polo
A more specific term for a collar is
2024-07-31 19:53:31 root INFO     [order_1_approx] starting weight calculation for A more specific term for a shirt is polo
A more specific term for a dress is gown
A more specific term for a cookware is pot
A more specific term for a bed is bunk
A more specific term for a bag is pouch
A more specific term for a collar is choker
A more specific term for a shelf is bookshelf
A more specific term for a burger is
2024-07-31 19:53:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 19:56:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1545,  0.3730, -0.0269,  ...,  0.0894, -0.1913, -0.0105],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1279, -5.2500,  1.6191,  ..., -1.1172, -5.2109, -1.8311],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.4404e-02, -2.1591e-02, -9.5749e-03,  ..., -1.2634e-02,
         -4.1580e-03,  4.4342e-02],
        [ 7.0190e-04,  2.5421e-02, -1.0498e-02,  ..., -1.9440e-02,
         -8.3923e-05, -1.3664e-02],
        [-2.0390e-03, -2.1744e-03,  6.1798e-02,  ...,  4.1237e-03,
         -1.7105e-02, -1.0597e-02],
        ...,
        [ 3.3630e-02,  1.6937e-02, -1.7319e-02,  ...,  1.9531e-02,
         -1.7395e-03, -6.3599e-02],
        [ 4.9133e-02, -4.1809e-02,  1.4336e-02,  ...,  5.0278e-03,
          6.4026e-02,  1.3145e-02],
        [ 3.1860e-02,  2.0203e-02, -2.7481e-02,  ..., -6.1607e-03,
         -3.5950e-02,  6.4819e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1785, -5.1719,  1.1279,  ..., -1.2275, -4.8867, -1.7539]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:56:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a shirt is polo
A more specific term for a dress is gown
A more specific term for a cookware is pot
A more specific term for a bed is bunk
A more specific term for a bag is pouch
A more specific term for a collar is choker
A more specific term for a shelf is bookshelf
A more specific term for a burger is
2024-07-31 19:56:31 root INFO     [order_1_approx] starting weight calculation for A more specific term for a burger is hamburger
A more specific term for a shelf is bookshelf
A more specific term for a bag is pouch
A more specific term for a cookware is pot
A more specific term for a dress is gown
A more specific term for a shirt is polo
A more specific term for a collar is choker
A more specific term for a bed is
2024-07-31 19:56:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 19:59:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0839,  0.0508, -0.2454,  ...,  0.0731, -0.5059,  0.0428],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2722, -4.9531,  1.6211,  ...,  0.9707,  0.1604,  1.6641],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-8.6212e-03, -3.9886e-02,  6.3782e-03,  ...,  4.0375e-02,
          2.1648e-03, -1.3420e-02],
        [-3.7048e-02,  2.6184e-02, -1.2878e-02,  ..., -1.5503e-02,
         -1.0071e-03,  3.2257e-02],
        [ 3.9429e-02,  8.1253e-03,  4.9652e-02,  ...,  2.3575e-03,
          3.2597e-03, -2.4368e-02],
        ...,
        [-1.1887e-02, -9.5367e-07, -2.8412e-02,  ..., -4.7493e-03,
         -3.3875e-02,  2.4582e-02],
        [-2.3178e-02, -3.7231e-02,  7.9346e-03,  ..., -3.7872e-02,
          2.0447e-02, -7.5760e-03],
        [-8.3313e-03, -2.1210e-03, -2.0004e-02,  ..., -4.0161e-02,
         -2.3422e-02,  1.9623e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6553, -4.6016,  1.0195,  ...,  1.4805,  0.4880,  1.8145]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:59:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a burger is hamburger
A more specific term for a shelf is bookshelf
A more specific term for a bag is pouch
A more specific term for a cookware is pot
A more specific term for a dress is gown
A more specific term for a shirt is polo
A more specific term for a collar is choker
A more specific term for a bed is
2024-07-31 19:59:32 root INFO     total operator prediction time: 1442.5839037895203 seconds
2024-07-31 19:59:32 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on antonyms - binary
2024-07-31 19:59:32 root INFO     building operator antonyms - binary
2024-07-31 19:59:33 root INFO     [order_1_approx] starting weight calculation for The opposite of downslope is upslope
The opposite of after is before
The opposite of backward is forward
The opposite of down is up
The opposite of descend is ascend
The opposite of off is on
The opposite of anterior is posterior
The opposite of toward is
2024-07-31 19:59:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 20:02:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0559, -0.0584, -0.1741,  ..., -0.1736, -0.1375,  0.0235],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.7324, -3.0430,  1.2266,  ..., -1.5938, -0.6484, -4.3398],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0412, -0.0282,  0.0185,  ...,  0.0717,  0.0157,  0.0470],
        [-0.0059,  0.0060,  0.0437,  ...,  0.0297,  0.0227,  0.0121],
        [ 0.0386,  0.0371, -0.0327,  ...,  0.0264, -0.0156,  0.0006],
        ...,
        [ 0.0204,  0.0306,  0.0775,  ...,  0.0033,  0.0014, -0.0147],
        [ 0.0403, -0.0556,  0.0148,  ...,  0.0251,  0.0218,  0.0093],
        [ 0.0225,  0.0177, -0.0232,  ...,  0.0266,  0.0148, -0.0120]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7905, -2.1543,  1.2656,  ..., -0.5039, -1.0146, -4.7305]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:02:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of downslope is upslope
The opposite of after is before
The opposite of backward is forward
The opposite of down is up
The opposite of descend is ascend
The opposite of off is on
The opposite of anterior is posterior
The opposite of toward is
2024-07-31 20:02:35 root INFO     [order_1_approx] starting weight calculation for The opposite of backward is forward
The opposite of after is before
The opposite of descend is ascend
The opposite of anterior is posterior
The opposite of toward is away
The opposite of down is up
The opposite of downslope is upslope
The opposite of off is
2024-07-31 20:02:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 20:05:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0475,  0.0414,  0.0304,  ..., -0.1379, -0.2678, -0.2134],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0264, -4.5078, -0.3301,  ...,  0.0389, -1.1035, -1.6289],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0299, -0.0371, -0.0207,  ..., -0.0189, -0.0178,  0.1417],
        [-0.0054, -0.0540, -0.0266,  ..., -0.0059,  0.1257,  0.1385],
        [-0.0135, -0.0242,  0.0043,  ...,  0.0391, -0.0410,  0.0160],
        ...,
        [ 0.0229, -0.0636, -0.0881,  ...,  0.0268,  0.0035, -0.0337],
        [-0.0216,  0.0464,  0.0930,  ..., -0.0578,  0.0501, -0.0853],
        [ 0.0132,  0.0493, -0.0162,  ...,  0.0155, -0.0480, -0.0152]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6313, -2.9648, -0.9912,  ...,  0.5254, -1.2539, -2.1875]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:05:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of backward is forward
The opposite of after is before
The opposite of descend is ascend
The opposite of anterior is posterior
The opposite of toward is away
The opposite of down is up
The opposite of downslope is upslope
The opposite of off is
2024-07-31 20:05:38 root INFO     [order_1_approx] starting weight calculation for The opposite of after is before
The opposite of anterior is posterior
The opposite of downslope is upslope
The opposite of off is on
The opposite of backward is forward
The opposite of toward is away
The opposite of descend is ascend
The opposite of down is
2024-07-31 20:05:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 20:08:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0078, -0.0514, -0.0967,  ..., -0.0386, -0.2130, -0.1722],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0693, -4.5039,  0.4453,  ...,  0.0090, -0.2070, -3.5762],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0136, -0.0486,  0.0286,  ..., -0.0078,  0.0461,  0.0246],
        [-0.0388,  0.0167, -0.0388,  ..., -0.0353, -0.0236, -0.0100],
        [ 0.0139,  0.0301, -0.0078,  ...,  0.0065, -0.0042,  0.0339],
        ...,
        [ 0.0610, -0.0112, -0.0237,  ...,  0.0310,  0.0109, -0.0231],
        [ 0.0892, -0.0259,  0.0364,  ...,  0.0479,  0.0540,  0.0334],
        [-0.0325, -0.0113, -0.0226,  ..., -0.0391, -0.0155, -0.0164]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5918, -4.0664,  0.6396,  ..., -0.5352, -0.9551, -2.9492]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:08:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of after is before
The opposite of anterior is posterior
The opposite of downslope is upslope
The opposite of off is on
The opposite of backward is forward
The opposite of toward is away
The opposite of descend is ascend
The opposite of down is
2024-07-31 20:08:40 root INFO     [order_1_approx] starting weight calculation for The opposite of down is up
The opposite of descend is ascend
The opposite of off is on
The opposite of downslope is upslope
The opposite of after is before
The opposite of toward is away
The opposite of anterior is posterior
The opposite of backward is
2024-07-31 20:08:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 20:11:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1357,  0.0735, -0.3936,  ...,  0.0018, -0.0703, -0.0851],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3789, -1.8877,  1.7676,  ..., -0.5107, -1.9463, -1.0391],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0091,  0.0251, -0.0006,  ..., -0.0366, -0.0402,  0.0214],
        [ 0.0158,  0.0693, -0.0468,  ...,  0.0441,  0.0153, -0.0280],
        [ 0.0698, -0.0656,  0.0429,  ...,  0.0895,  0.0592, -0.0433],
        ...,
        [-0.0142,  0.0273, -0.0083,  ..., -0.0102,  0.0255,  0.0262],
        [-0.0059, -0.0469,  0.0166,  ...,  0.0264,  0.0151,  0.0300],
        [-0.0442, -0.0287, -0.0170,  ...,  0.0720,  0.0064, -0.0609]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4648, -1.9893,  1.6455,  ..., -0.2100, -2.2344, -0.8154]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:11:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of down is up
The opposite of descend is ascend
The opposite of off is on
The opposite of downslope is upslope
The opposite of after is before
The opposite of toward is away
The opposite of anterior is posterior
The opposite of backward is
2024-07-31 20:11:43 root INFO     [order_1_approx] starting weight calculation for The opposite of toward is away
The opposite of descend is ascend
The opposite of down is up
The opposite of off is on
The opposite of backward is forward
The opposite of downslope is upslope
The opposite of after is before
The opposite of anterior is
2024-07-31 20:11:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 20:14:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1841, -0.0284, -0.1411,  ..., -0.0804, -0.4287, -0.0725],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8340, -2.2227,  2.7832,  ..., -3.9473, -2.9258, -4.5703],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0740, -0.0008, -0.0053,  ...,  0.0119, -0.0249,  0.0340],
        [ 0.0933,  0.0156,  0.0027,  ..., -0.0237,  0.0327,  0.0411],
        [ 0.0434,  0.0137,  0.0095,  ..., -0.0204,  0.0110, -0.0230],
        ...,
        [ 0.0517,  0.0588, -0.0320,  ...,  0.0324,  0.0359, -0.0106],
        [ 0.0389, -0.0140,  0.0066,  ...,  0.0061, -0.0064, -0.0251],
        [-0.0256,  0.0392, -0.0006,  ...,  0.0521, -0.0538,  0.0756]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7402, -1.2217,  3.0098,  ..., -3.5332, -3.0547, -3.9102]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:14:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of toward is away
The opposite of descend is ascend
The opposite of down is up
The opposite of off is on
The opposite of backward is forward
The opposite of downslope is upslope
The opposite of after is before
The opposite of anterior is
2024-07-31 20:14:46 root INFO     [order_1_approx] starting weight calculation for The opposite of off is on
The opposite of descend is ascend
The opposite of down is up
The opposite of downslope is upslope
The opposite of backward is forward
The opposite of toward is away
The opposite of anterior is posterior
The opposite of after is
2024-07-31 20:14:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 20:17:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0809, -0.0108, -0.1519,  ..., -0.2354, -0.2605, -0.0501],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5859, -2.9922, -0.5347,  ...,  1.4893, -1.2344, -5.1094],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0153, -0.0342,  0.0021,  ...,  0.0007, -0.0014,  0.0038],
        [ 0.0211,  0.0889,  0.0381,  ...,  0.0080,  0.0082,  0.0186],
        [ 0.0062, -0.0284, -0.0407,  ...,  0.0365, -0.0141,  0.0154],
        ...,
        [ 0.0454, -0.0467,  0.0068,  ...,  0.0142,  0.0384, -0.0054],
        [ 0.0181, -0.0021,  0.0270,  ..., -0.0045,  0.0445, -0.0079],
        [ 0.0154, -0.0154, -0.0199,  ..., -0.0175,  0.0031, -0.0009]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2754, -1.8135, -0.7886,  ...,  1.7441, -1.3018, -4.8477]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:17:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of off is on
The opposite of descend is ascend
The opposite of down is up
The opposite of downslope is upslope
The opposite of backward is forward
The opposite of toward is away
The opposite of anterior is posterior
The opposite of after is
2024-07-31 20:17:46 root INFO     [order_1_approx] starting weight calculation for The opposite of after is before
The opposite of anterior is posterior
The opposite of down is up
The opposite of toward is away
The opposite of off is on
The opposite of backward is forward
The opposite of descend is ascend
The opposite of downslope is
2024-07-31 20:17:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 20:20:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0209,  0.2002, -0.0587,  ..., -0.0337, -0.4258, -0.1691],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6377, -1.3008, -3.9688,  ..., -1.5684, -1.4873, -2.9629],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0534, -0.0501, -0.0070,  ..., -0.0406,  0.0507,  0.0538],
        [ 0.0361,  0.0492,  0.0061,  ...,  0.0422,  0.0288,  0.0220],
        [ 0.0616, -0.0239,  0.0066,  ...,  0.0151, -0.0643, -0.0067],
        ...,
        [ 0.0360,  0.0287,  0.0494,  ...,  0.0321, -0.0120,  0.0110],
        [-0.0312,  0.0262, -0.0023,  ..., -0.0067,  0.0247,  0.0093],
        [-0.0225, -0.0067, -0.0261,  ..., -0.0023, -0.0107,  0.0230]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7515, -1.7100, -3.5371,  ..., -1.0156, -1.9365, -2.7305]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:20:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of after is before
The opposite of anterior is posterior
The opposite of down is up
The opposite of toward is away
The opposite of off is on
The opposite of backward is forward
The opposite of descend is ascend
The opposite of downslope is
2024-07-31 20:20:48 root INFO     [order_1_approx] starting weight calculation for The opposite of anterior is posterior
The opposite of after is before
The opposite of down is up
The opposite of off is on
The opposite of toward is away
The opposite of downslope is upslope
The opposite of backward is forward
The opposite of descend is
2024-07-31 20:20:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 20:23:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0894,  0.0350, -0.1289,  ..., -0.0522, -0.2686, -0.1945],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2373, -0.8516,  0.8086,  ...,  0.5288, -3.8711, -3.0293],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0740, -0.0363, -0.0111,  ..., -0.0014,  0.0253, -0.0051],
        [ 0.0190,  0.0613,  0.0076,  ..., -0.0099,  0.0283, -0.0019],
        [-0.0580,  0.0254,  0.0092,  ..., -0.0042, -0.0398, -0.0128],
        ...,
        [ 0.0501,  0.0281, -0.0047,  ..., -0.0170,  0.0364, -0.0401],
        [ 0.0565, -0.0677, -0.0135,  ...,  0.0263, -0.0565,  0.0668],
        [ 0.0323,  0.0010, -0.0126,  ...,  0.0369, -0.0050,  0.0194]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1792, -0.4712,  0.5723,  ...,  0.3584, -3.1992, -2.7285]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:23:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of anterior is posterior
The opposite of after is before
The opposite of down is up
The opposite of off is on
The opposite of toward is away
The opposite of downslope is upslope
The opposite of backward is forward
The opposite of descend is
2024-07-31 20:23:49 root INFO     total operator prediction time: 1456.706646680832 seconds
2024-07-31 20:23:49 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - member
2024-07-31 20:23:49 root INFO     building operator meronyms - member
2024-07-31 20:23:49 root INFO     [order_1_approx] starting weight calculation for A book is a member of a library
A wolf is a member of a pack
A person is a member of a society
A musician is a member of a orchestra
A elephant is a member of a herd
A song is a member of a album
A cow is a member of a herd
A spouse is a member of a
2024-07-31 20:23:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 20:26:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2090,  0.2988,  0.1262,  ...,  0.2067, -0.0791, -0.2064],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7578, -3.0273,  3.3262,  ..., -2.4180, -1.2285,  2.0586],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0543, -0.0242, -0.0073,  ...,  0.0340, -0.0388, -0.0004],
        [-0.0446,  0.0279,  0.0307,  ...,  0.0371,  0.0448, -0.0166],
        [ 0.0740,  0.0286, -0.0109,  ..., -0.0470, -0.0201, -0.0239],
        ...,
        [-0.0093, -0.0112, -0.0019,  ...,  0.0033,  0.0193,  0.0396],
        [ 0.0325,  0.0053, -0.0151,  ..., -0.0323, -0.0043, -0.0213],
        [ 0.0158, -0.0001, -0.0011,  ...,  0.0326,  0.0060,  0.0077]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3496, -2.9785,  3.1719,  ..., -2.8125, -1.0439,  2.1816]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:26:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A book is a member of a library
A wolf is a member of a pack
A person is a member of a society
A musician is a member of a orchestra
A elephant is a member of a herd
A song is a member of a album
A cow is a member of a herd
A spouse is a member of a
2024-07-31 20:26:54 root INFO     [order_1_approx] starting weight calculation for A wolf is a member of a pack
A cow is a member of a herd
A musician is a member of a orchestra
A elephant is a member of a herd
A person is a member of a society
A spouse is a member of a couple
A book is a member of a library
A song is a member of a
2024-07-31 20:26:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 20:29:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0684,  0.2803, -0.0260,  ...,  0.0970, -0.2188, -0.1776],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6929, -6.4531,  2.8906,  ..., -0.9668,  0.7729, -2.1309],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0092, -0.0618,  0.0054,  ...,  0.0056,  0.0212,  0.0288],
        [-0.0207,  0.0115,  0.0027,  ..., -0.0084,  0.0106, -0.0028],
        [-0.0017, -0.0054,  0.0324,  ...,  0.0133, -0.0467, -0.0118],
        ...,
        [-0.0188,  0.0182,  0.0126,  ...,  0.0330, -0.0188,  0.0076],
        [-0.0016,  0.0270, -0.0448,  ...,  0.0062,  0.0396,  0.0049],
        [-0.0099, -0.0118,  0.0027,  ..., -0.0265, -0.0062,  0.0297]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6816, -6.0820,  3.1328,  ..., -0.4238,  0.6577, -2.0254]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:29:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A wolf is a member of a pack
A cow is a member of a herd
A musician is a member of a orchestra
A elephant is a member of a herd
A person is a member of a society
A spouse is a member of a couple
A book is a member of a library
A song is a member of a
2024-07-31 20:29:58 root INFO     [order_1_approx] starting weight calculation for A song is a member of a album
A wolf is a member of a pack
A musician is a member of a orchestra
A cow is a member of a herd
A spouse is a member of a couple
A elephant is a member of a herd
A book is a member of a library
A person is a member of a
2024-07-31 20:29:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 20:33:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0596,  0.0682,  0.0543,  ...,  0.1022, -0.0635, -0.3477],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8359, -4.0195,  3.9355,  ..., -3.9453, -1.0830, -3.2188],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0112, -0.0098,  0.0037,  ..., -0.0077, -0.0174, -0.0105],
        [-0.0190, -0.0107, -0.0081,  ...,  0.0463,  0.0366,  0.0533],
        [ 0.0074,  0.0037,  0.0082,  ..., -0.0218,  0.0083, -0.0161],
        ...,
        [ 0.0074,  0.0086, -0.0070,  ...,  0.0344, -0.0081,  0.0345],
        [ 0.0187, -0.0062, -0.0103,  ..., -0.0405,  0.0342, -0.0230],
        [-0.0120, -0.0114,  0.0078,  ...,  0.0508,  0.0026,  0.0447]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0195, -3.9336,  3.9688,  ..., -3.8691, -0.7441, -2.9766]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:33:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A song is a member of a album
A wolf is a member of a pack
A musician is a member of a orchestra
A cow is a member of a herd
A spouse is a member of a couple
A elephant is a member of a herd
A book is a member of a library
A person is a member of a
2024-07-31 20:33:01 root INFO     [order_1_approx] starting weight calculation for A person is a member of a society
A wolf is a member of a pack
A cow is a member of a herd
A song is a member of a album
A spouse is a member of a couple
A elephant is a member of a herd
A musician is a member of a orchestra
A book is a member of a
2024-07-31 20:33:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 20:36:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0258,  0.1536, -0.2229,  ...,  0.0459, -0.1440, -0.0895],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7344, -5.1094,  0.9219,  ..., -2.1895,  0.4919, -4.4805],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0246,  0.0393, -0.0132,  ...,  0.0019,  0.0107, -0.0170],
        [ 0.0287, -0.0503,  0.0176,  ..., -0.0075,  0.0050,  0.0592],
        [-0.0352, -0.0119,  0.0175,  ..., -0.0116, -0.0081,  0.0064],
        ...,
        [ 0.0125,  0.0114,  0.0022,  ...,  0.0080, -0.0014, -0.0159],
        [-0.0055,  0.0266, -0.0082,  ...,  0.0014,  0.0357, -0.0171],
        [ 0.0431, -0.0786,  0.0298,  ..., -0.0142, -0.0059,  0.1006]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8652, -5.0586,  1.0674,  ..., -2.1816,  1.1631, -4.6719]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:36:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A person is a member of a society
A wolf is a member of a pack
A cow is a member of a herd
A song is a member of a album
A spouse is a member of a couple
A elephant is a member of a herd
A musician is a member of a orchestra
A book is a member of a
2024-07-31 20:36:05 root INFO     [order_1_approx] starting weight calculation for A spouse is a member of a couple
A elephant is a member of a herd
A person is a member of a society
A song is a member of a album
A cow is a member of a herd
A book is a member of a library
A musician is a member of a orchestra
A wolf is a member of a
2024-07-31 20:36:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 20:39:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1635,  0.0806,  0.0333,  ..., -0.0910, -0.0853, -0.1917],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.7969, -8.0703,  2.4062,  ..., -3.9258, -2.2227,  0.3604],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0567,  0.0601, -0.0956,  ..., -0.0071,  0.0480, -0.0300],
        [-0.0219, -0.0528,  0.0509,  ...,  0.0079, -0.0595,  0.0311],
        [ 0.0091, -0.0193,  0.0274,  ..., -0.0340,  0.0065, -0.0160],
        ...,
        [ 0.0270,  0.0305,  0.0058,  ...,  0.0594, -0.0020, -0.0244],
        [ 0.0113, -0.0029, -0.0472,  ...,  0.0061, -0.0042, -0.0277],
        [-0.0065, -0.0385,  0.0147,  ..., -0.0381,  0.0073,  0.0453]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.7656, -6.8281,  2.6973,  ..., -3.7383, -2.5781,  0.6973]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:39:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A spouse is a member of a couple
A elephant is a member of a herd
A person is a member of a society
A song is a member of a album
A cow is a member of a herd
A book is a member of a library
A musician is a member of a orchestra
A wolf is a member of a
2024-07-31 20:39:09 root INFO     [order_1_approx] starting weight calculation for A book is a member of a library
A musician is a member of a orchestra
A song is a member of a album
A wolf is a member of a pack
A elephant is a member of a herd
A spouse is a member of a couple
A person is a member of a society
A cow is a member of a
2024-07-31 20:39:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 20:42:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0387,  0.1465,  0.0557,  ...,  0.0331, -0.0544, -0.1467],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.1328, -3.9062,  2.5664,  ..., -4.5898, -0.6055, -2.8027],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0411,  0.0349, -0.0767,  ..., -0.0038,  0.0427,  0.0268],
        [ 0.0059, -0.0197,  0.0812,  ..., -0.0104, -0.0712, -0.0024],
        [-0.0027,  0.0172, -0.0044,  ...,  0.0205,  0.0408,  0.0006],
        ...,
        [-0.0022, -0.0091,  0.0232,  ...,  0.0309, -0.0516, -0.0140],
        [ 0.0166,  0.0596, -0.0545,  ...,  0.0141,  0.0733, -0.0110],
        [-0.0186, -0.0341,  0.0384,  ..., -0.0048, -0.0057,  0.0123]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.4297, -3.4746,  2.6367,  ..., -4.0469, -0.7271, -2.6113]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:42:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A book is a member of a library
A musician is a member of a orchestra
A song is a member of a album
A wolf is a member of a pack
A elephant is a member of a herd
A spouse is a member of a couple
A person is a member of a society
A cow is a member of a
2024-07-31 20:42:13 root INFO     [order_1_approx] starting weight calculation for A spouse is a member of a couple
A musician is a member of a orchestra
A song is a member of a album
A wolf is a member of a pack
A cow is a member of a herd
A person is a member of a society
A book is a member of a library
A elephant is a member of a
2024-07-31 20:42:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 20:45:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0293,  0.0453, -0.0453,  ..., -0.0902, -0.3137, -0.2581],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.8359, -5.4922,  2.2129,  ..., -2.6152, -2.8848, -1.6621],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.2013e-02, -4.0466e-02, -3.8910e-04,  ..., -1.2947e-02,
         -9.6054e-03,  8.8501e-03],
        [-1.5594e-02, -9.3750e-02, -1.7242e-02,  ..., -1.6937e-02,
         -6.3095e-03,  4.4891e-02],
        [-1.5915e-02,  6.7505e-02,  1.9806e-02,  ...,  7.6370e-03,
         -8.3466e-03, -3.2501e-02],
        ...,
        [-5.6877e-03, -8.6212e-03, -1.9989e-02,  ..., -6.3858e-03,
         -2.3155e-03,  2.7504e-03],
        [-5.3406e-05,  3.3844e-02, -3.6621e-03,  ...,  1.9379e-02,
          3.7651e-03, -5.6458e-03],
        [-1.2970e-03, -1.0071e-01, -1.2238e-02,  ..., -4.0710e-02,
          5.8479e-03,  4.6692e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 7.2070, -5.0078,  1.9512,  ..., -2.2988, -3.0195, -1.2100]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:45:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A spouse is a member of a couple
A musician is a member of a orchestra
A song is a member of a album
A wolf is a member of a pack
A cow is a member of a herd
A person is a member of a society
A book is a member of a library
A elephant is a member of a
2024-07-31 20:45:15 root INFO     [order_1_approx] starting weight calculation for A elephant is a member of a herd
A cow is a member of a herd
A spouse is a member of a couple
A person is a member of a society
A wolf is a member of a pack
A song is a member of a album
A book is a member of a library
A musician is a member of a
2024-07-31 20:45:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 20:48:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0085,  0.2247,  0.2236,  ..., -0.1190, -0.0453, -0.1810],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0039, -6.8555,  3.6582,  ..., -4.3281,  0.1855, -4.6875],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0088, -0.0281, -0.0038,  ..., -0.0169, -0.0173,  0.0331],
        [-0.0129, -0.0268, -0.0303,  ..., -0.0405, -0.0286, -0.0153],
        [-0.0263, -0.0076,  0.0330,  ..., -0.0085, -0.0022,  0.0002],
        ...,
        [ 0.0220, -0.0020, -0.0161,  ..., -0.0053, -0.0364,  0.0056],
        [ 0.0036,  0.0370, -0.0202,  ...,  0.0154,  0.0421, -0.0031],
        [ 0.0267, -0.0518, -0.0165,  ..., -0.0395, -0.0417,  0.0244]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7627, -6.6250,  3.7188,  ..., -4.4062,  0.2837, -4.7344]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:48:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A elephant is a member of a herd
A cow is a member of a herd
A spouse is a member of a couple
A person is a member of a society
A wolf is a member of a pack
A song is a member of a album
A book is a member of a library
A musician is a member of a
2024-07-31 20:48:17 root INFO     total operator prediction time: 1468.116807460785 seconds
2024-07-31 20:48:17 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun - plural_irreg
2024-07-31 20:48:17 root INFO     building operator noun - plural_irreg
2024-07-31 20:48:17 root INFO     [order_1_approx] starting weight calculation for The plural form of library is libraries
The plural form of country is countries
The plural form of strategy is strategies
The plural form of opportunity is opportunities
The plural form of child is children
The plural form of species is species
The plural form of army is armies
The plural form of community is
2024-07-31 20:48:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 20:51:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0813,  0.1329, -0.1160,  ..., -0.1669, -0.2439, -0.0694],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3965, -4.4844,  2.2383,  ..., -3.6055,  0.5034, -2.0234],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0506, -0.0335,  0.0280,  ...,  0.0372, -0.0456, -0.0063],
        [ 0.0101,  0.0421,  0.0083,  ...,  0.0390, -0.0092,  0.0004],
        [-0.0076,  0.0214, -0.0057,  ..., -0.0003, -0.0568,  0.0046],
        ...,
        [ 0.0240,  0.0646, -0.0370,  ...,  0.0120, -0.0327, -0.0017],
        [-0.0035, -0.0232, -0.0453,  ..., -0.0472,  0.0429, -0.0041],
        [ 0.0335,  0.0445, -0.0322,  ...,  0.0176, -0.0411, -0.0224]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1094, -3.5273,  2.3770,  ..., -2.5312, -0.0347, -0.8555]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:51:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of library is libraries
The plural form of country is countries
The plural form of strategy is strategies
The plural form of opportunity is opportunities
The plural form of child is children
The plural form of species is species
The plural form of army is armies
The plural form of community is
2024-07-31 20:51:21 root INFO     [order_1_approx] starting weight calculation for The plural form of library is libraries
The plural form of opportunity is opportunities
The plural form of child is children
The plural form of species is species
The plural form of army is armies
The plural form of strategy is strategies
The plural form of community is communities
The plural form of country is
2024-07-31 20:51:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 20:54:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0652, -0.2676, -0.2080,  ..., -0.2732, -0.2786,  0.0464],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3066, -5.5586,  1.5879,  ..., -1.2422,  1.2734, -2.9219],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0480, -0.0847,  0.0421,  ...,  0.0485, -0.0509,  0.0155],
        [-0.0087, -0.0384,  0.0107,  ...,  0.0377,  0.0107, -0.0070],
        [-0.0265,  0.0566,  0.0036,  ...,  0.0256, -0.0468,  0.0428],
        ...,
        [-0.0158, -0.0112,  0.0040,  ...,  0.0002,  0.0153, -0.0046],
        [ 0.0143,  0.0100,  0.0060,  ..., -0.0246,  0.0229, -0.0054],
        [-0.0174, -0.0042,  0.0129,  ...,  0.0184,  0.0074, -0.0216]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3491, -5.2305,  1.4307,  ..., -1.5156,  0.9062, -2.2734]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:54:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of library is libraries
The plural form of opportunity is opportunities
The plural form of child is children
The plural form of species is species
The plural form of army is armies
The plural form of strategy is strategies
The plural form of community is communities
The plural form of country is
2024-07-31 20:54:29 root INFO     [order_1_approx] starting weight calculation for The plural form of country is countries
The plural form of army is armies
The plural form of opportunity is opportunities
The plural form of library is libraries
The plural form of community is communities
The plural form of strategy is strategies
The plural form of child is children
The plural form of species is
2024-07-31 20:54:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 20:57:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0997, -0.2751, -0.1064,  ..., -0.2266, -0.1943, -0.0144],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6436, -3.3340,  0.0396,  ..., -0.3662, -3.5391, -2.8633],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0491, -0.0369,  0.0432,  ...,  0.0161,  0.0428, -0.0021],
        [ 0.0365,  0.0420,  0.0072,  ...,  0.0374, -0.0072, -0.0087],
        [-0.0033,  0.0152, -0.0106,  ..., -0.0190, -0.0504,  0.0154],
        ...,
        [-0.0431,  0.0027,  0.0011,  ...,  0.0671,  0.0471,  0.0234],
        [ 0.0028,  0.0080, -0.0100,  ...,  0.0166,  0.0218,  0.0100],
        [ 0.0576,  0.0145, -0.0142,  ...,  0.0704,  0.0101,  0.0516]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2324, -4.0625,  0.0504,  ..., -0.5762, -3.6445, -3.0234]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:57:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of country is countries
The plural form of army is armies
The plural form of opportunity is opportunities
The plural form of library is libraries
The plural form of community is communities
The plural form of strategy is strategies
The plural form of child is children
The plural form of species is
2024-07-31 20:57:33 root INFO     [order_1_approx] starting weight calculation for The plural form of library is libraries
The plural form of child is children
The plural form of community is communities
The plural form of opportunity is opportunities
The plural form of strategy is strategies
The plural form of country is countries
The plural form of species is species
The plural form of army is
2024-07-31 20:57:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 21:00:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0631, -0.0916, -0.1244,  ..., -0.2542, -0.2056,  0.0089],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7402, -5.6562,  2.6641,  ..., -1.5127, -1.6504, -2.7695],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0286, -0.0266, -0.0094,  ..., -0.0281, -0.0574, -0.0197],
        [ 0.0040,  0.0435, -0.0244,  ...,  0.0342, -0.0132, -0.0016],
        [-0.0079, -0.0119,  0.0141,  ..., -0.0016, -0.0236,  0.0178],
        ...,
        [-0.0553,  0.0454,  0.0195,  ..., -0.0101,  0.0241, -0.0249],
        [ 0.0088,  0.0112, -0.0426,  ..., -0.0178,  0.0056, -0.0098],
        [ 0.0063,  0.0275,  0.0105,  ...,  0.0638,  0.0096,  0.0255]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8154, -5.6602,  2.4062,  ..., -1.3789, -1.6328, -2.7812]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:00:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of library is libraries
The plural form of child is children
The plural form of community is communities
The plural form of opportunity is opportunities
The plural form of strategy is strategies
The plural form of country is countries
The plural form of species is species
The plural form of army is
2024-07-31 21:00:38 root INFO     [order_1_approx] starting weight calculation for The plural form of community is communities
The plural form of opportunity is opportunities
The plural form of species is species
The plural form of country is countries
The plural form of strategy is strategies
The plural form of child is children
The plural form of army is armies
The plural form of library is
2024-07-31 21:00:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 21:03:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0437, -0.1000, -0.2484,  ..., -0.0220, -0.0975,  0.0239],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6729, -4.8281,  1.3516,  ...,  0.1299, -1.2373, -3.5273],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0734, -0.0554, -0.0179,  ..., -0.0182,  0.0254, -0.0186],
        [ 0.0084,  0.0254, -0.0482,  ...,  0.0091, -0.0085,  0.0006],
        [-0.0182, -0.0104,  0.0158,  ..., -0.0322, -0.0109, -0.0092],
        ...,
        [ 0.0275, -0.0260,  0.0019,  ..., -0.0272, -0.0231, -0.0053],
        [ 0.0361, -0.0305, -0.0844,  ..., -0.0382,  0.0315,  0.0402],
        [ 0.0096,  0.0052, -0.0061,  ...,  0.0439, -0.0085, -0.0090]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0508, -4.3711,  1.3848,  ...,  0.2045, -1.2686, -3.1836]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:03:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of community is communities
The plural form of opportunity is opportunities
The plural form of species is species
The plural form of country is countries
The plural form of strategy is strategies
The plural form of child is children
The plural form of army is armies
The plural form of library is
2024-07-31 21:03:47 root INFO     [order_1_approx] starting weight calculation for The plural form of strategy is strategies
The plural form of community is communities
The plural form of child is children
The plural form of species is species
The plural form of country is countries
The plural form of library is libraries
The plural form of army is armies
The plural form of opportunity is
2024-07-31 21:03:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 21:06:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1278, -0.0592,  0.0377,  ...,  0.0450, -0.1470,  0.0253],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1172, -0.2522, -0.2208,  ..., -0.5859, -1.4922, -0.2783],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0190, -0.0226,  0.0339,  ..., -0.0240, -0.0359, -0.0518],
        [-0.0021,  0.0333, -0.0119,  ...,  0.0203, -0.0382,  0.0280],
        [-0.0127, -0.0046, -0.0268,  ...,  0.0142, -0.0114,  0.0017],
        ...,
        [ 0.0026,  0.0281, -0.0033,  ...,  0.0256, -0.0204,  0.0184],
        [-0.0047, -0.0104,  0.0101,  ...,  0.0019, -0.0014,  0.0031],
        [-0.0008, -0.0166,  0.0423,  ...,  0.0154, -0.0261, -0.0160]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6802, -0.5386, -0.0638,  ..., -0.8784, -1.7510, -0.1183]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:06:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of strategy is strategies
The plural form of community is communities
The plural form of child is children
The plural form of species is species
The plural form of country is countries
The plural form of library is libraries
The plural form of army is armies
The plural form of opportunity is
2024-07-31 21:06:50 root INFO     [order_1_approx] starting weight calculation for The plural form of library is libraries
The plural form of strategy is strategies
The plural form of country is countries
The plural form of army is armies
The plural form of species is species
The plural form of community is communities
The plural form of opportunity is opportunities
The plural form of child is
2024-07-31 21:06:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 21:09:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0827, -0.2915,  0.0060,  ..., -0.1567, -0.5366, -0.0022],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6758, -2.6406,  1.7793,  ..., -1.1699, -0.7959, -2.2070],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0327, -0.0773, -0.0080,  ...,  0.0227, -0.0457,  0.0255],
        [ 0.0101,  0.0342,  0.0072,  ...,  0.0348, -0.0149, -0.0131],
        [-0.0139, -0.0346,  0.0036,  ...,  0.0134, -0.0415,  0.0325],
        ...,
        [ 0.0390, -0.0240, -0.0268,  ...,  0.0309, -0.0396,  0.0526],
        [-0.0713,  0.0791, -0.0108,  ..., -0.0176,  0.0500, -0.0454],
        [ 0.0170, -0.0830,  0.0177,  ...,  0.0225, -0.0536,  0.0315]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4414, -2.7012,  1.6504,  ..., -1.1650, -0.7651, -2.4102]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:09:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of library is libraries
The plural form of strategy is strategies
The plural form of country is countries
The plural form of army is armies
The plural form of species is species
The plural form of community is communities
The plural form of opportunity is opportunities
The plural form of child is
2024-07-31 21:09:57 root INFO     [order_1_approx] starting weight calculation for The plural form of army is armies
The plural form of species is species
The plural form of child is children
The plural form of country is countries
The plural form of community is communities
The plural form of opportunity is opportunities
The plural form of library is libraries
The plural form of strategy is
2024-07-31 21:09:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 21:12:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2166, -0.0702,  0.0909,  ..., -0.1299, -0.1477, -0.1129],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1855, -2.2969,  1.1494,  ...,  0.1621, -2.1094, -3.4746],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0330, -0.0536, -0.0077,  ..., -0.0198,  0.0216, -0.0035],
        [-0.0233,  0.0635,  0.0236,  ..., -0.0072, -0.0417,  0.0147],
        [-0.0092,  0.0042, -0.0075,  ..., -0.0098, -0.0076,  0.0140],
        ...,
        [-0.0253,  0.0105,  0.0209,  ...,  0.0225,  0.0335, -0.0060],
        [ 0.0058,  0.0264, -0.0303,  ...,  0.0040,  0.0260, -0.0066],
        [ 0.0188,  0.0009, -0.0041,  ...,  0.0167, -0.0113, -0.0087]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7559, -2.4629,  1.1523,  ...,  0.2686, -2.0137, -3.2676]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:12:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of army is armies
The plural form of species is species
The plural form of child is children
The plural form of country is countries
The plural form of community is communities
The plural form of opportunity is opportunities
The plural form of library is libraries
The plural form of strategy is
2024-07-31 21:12:57 root INFO     total operator prediction time: 1480.0930342674255 seconds
2024-07-31 21:12:57 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on Ving - verb_inf
2024-07-31 21:12:57 root INFO     building operator Ving - verb_inf
2024-07-31 21:12:58 root INFO     [order_1_approx] starting weight calculation for sitting is the active form of sit
continuing is the active form of continue
managing is the active form of manage
seeming is the active form of seem
avoiding is the active form of avoid
improving is the active form of improve
ensuring is the active form of ensure
enjoying is the active form of
2024-07-31 21:12:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 21:16:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0900,  0.1720,  0.1433,  ..., -0.0752, -0.2068, -0.0852],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0645, -3.3555, -0.7700,  ...,  1.7207, -2.5566, -2.6289],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0286,  0.0109, -0.0167,  ...,  0.0013,  0.0105,  0.0323],
        [-0.0040,  0.0497, -0.0048,  ..., -0.0121,  0.0036, -0.0024],
        [ 0.0253,  0.0134, -0.0111,  ..., -0.0045, -0.0071,  0.0009],
        ...,
        [-0.0227,  0.0186,  0.0144,  ...,  0.0049,  0.0166, -0.0405],
        [ 0.0366,  0.0543, -0.0167,  ..., -0.0013,  0.0535,  0.0161],
        [ 0.0204,  0.0279,  0.0120,  ...,  0.0100,  0.0228,  0.0029]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3801, -3.2051, -0.6372,  ...,  1.7344, -2.1738, -2.7734]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:16:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for sitting is the active form of sit
continuing is the active form of continue
managing is the active form of manage
seeming is the active form of seem
avoiding is the active form of avoid
improving is the active form of improve
ensuring is the active form of ensure
enjoying is the active form of
2024-07-31 21:16:02 root INFO     [order_1_approx] starting weight calculation for improving is the active form of improve
sitting is the active form of sit
enjoying is the active form of enjoy
ensuring is the active form of ensure
managing is the active form of manage
seeming is the active form of seem
avoiding is the active form of avoid
continuing is the active form of
2024-07-31 21:16:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 21:19:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1792,  0.0298, -0.0945,  ...,  0.0016, -0.2236, -0.0555],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0518, -3.9219,  1.7559,  ...,  0.7529,  1.6836, -1.7383],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0171, -0.0085, -0.0244,  ..., -0.0179,  0.0340,  0.0331],
        [-0.0133,  0.0450,  0.0063,  ...,  0.0069, -0.0371, -0.0423],
        [ 0.0054,  0.0096,  0.0189,  ...,  0.0118, -0.0445, -0.0193],
        ...,
        [ 0.0007,  0.0306,  0.0013,  ...,  0.0268, -0.0109, -0.0025],
        [ 0.0117, -0.0333, -0.0127,  ..., -0.0153,  0.0675,  0.0480],
        [ 0.0088, -0.0058, -0.0205,  ..., -0.0172,  0.0410,  0.0320]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2666, -4.2461,  1.4600,  ...,  0.7817,  2.3301, -1.3584]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:19:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for improving is the active form of improve
sitting is the active form of sit
enjoying is the active form of enjoy
ensuring is the active form of ensure
managing is the active form of manage
seeming is the active form of seem
avoiding is the active form of avoid
continuing is the active form of
2024-07-31 21:19:05 root INFO     [order_1_approx] starting weight calculation for avoiding is the active form of avoid
continuing is the active form of continue
enjoying is the active form of enjoy
ensuring is the active form of ensure
seeming is the active form of seem
improving is the active form of improve
sitting is the active form of sit
managing is the active form of
2024-07-31 21:19:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 21:22:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0391,  0.5220,  0.0999,  ..., -0.0388, -0.2708, -0.1191],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9131, -3.7207,  0.3384,  ...,  2.0566, -1.3613, -3.0098],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0174, -0.0061,  0.0099,  ..., -0.0223,  0.0015,  0.0047],
        [ 0.0065,  0.0507,  0.0065,  ..., -0.0170,  0.0133,  0.0040],
        [-0.0151, -0.0274,  0.0036,  ..., -0.0025, -0.0218, -0.0059],
        ...,
        [-0.0217, -0.0187,  0.0078,  ...,  0.0005,  0.0030, -0.0333],
        [ 0.0210,  0.0480, -0.0047,  ...,  0.0017,  0.0045,  0.0237],
        [ 0.0363,  0.0614,  0.0105,  ...,  0.0264,  0.0117,  0.0363]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0137, -3.5098,  0.0464,  ...,  1.7383, -0.9531, -2.7285]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:22:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for avoiding is the active form of avoid
continuing is the active form of continue
enjoying is the active form of enjoy
ensuring is the active form of ensure
seeming is the active form of seem
improving is the active form of improve
sitting is the active form of sit
managing is the active form of
2024-07-31 21:22:10 root INFO     [order_1_approx] starting weight calculation for continuing is the active form of continue
improving is the active form of improve
avoiding is the active form of avoid
enjoying is the active form of enjoy
ensuring is the active form of ensure
managing is the active form of manage
seeming is the active form of seem
sitting is the active form of
2024-07-31 21:22:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 21:25:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0772, -0.0940, -0.0586,  ...,  0.0644, -0.2004, -0.0138],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8516, -2.9922, -1.0293,  ..., -0.6826,  0.3936, -3.3164],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0672, -0.0109,  0.0274,  ...,  0.0417,  0.0117,  0.0175],
        [-0.0246,  0.0649, -0.0164,  ..., -0.0226,  0.0107, -0.0273],
        [ 0.0124,  0.0064,  0.0168,  ..., -0.0009, -0.0058,  0.0288],
        ...,
        [-0.0061,  0.0011, -0.0179,  ...,  0.0360,  0.0317, -0.0105],
        [-0.0297, -0.0169, -0.0329,  ..., -0.0477,  0.0233,  0.0005],
        [ 0.0091,  0.0422,  0.0488,  ...,  0.0120,  0.0388,  0.0206]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6885, -3.0156, -1.1328,  ..., -0.4453,  0.4155, -3.4297]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:25:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for continuing is the active form of continue
improving is the active form of improve
avoiding is the active form of avoid
enjoying is the active form of enjoy
ensuring is the active form of ensure
managing is the active form of manage
seeming is the active form of seem
sitting is the active form of
2024-07-31 21:25:12 root INFO     [order_1_approx] starting weight calculation for ensuring is the active form of ensure
continuing is the active form of continue
managing is the active form of manage
enjoying is the active form of enjoy
seeming is the active form of seem
improving is the active form of improve
sitting is the active form of sit
avoiding is the active form of
2024-07-31 21:25:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 21:28:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2135,  0.0743,  0.0674,  ..., -0.0072, -0.0457,  0.0153],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4482, -3.5977, -2.4590,  ...,  3.1113, -0.4556, -1.9727],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0027,  0.0048, -0.0335,  ..., -0.0265,  0.0464,  0.0028],
        [ 0.0059,  0.0264,  0.0162,  ...,  0.0148,  0.0153,  0.0003],
        [ 0.0105, -0.0023, -0.0118,  ..., -0.0099, -0.0046, -0.0066],
        ...,
        [-0.0066, -0.0020,  0.0280,  ...,  0.0179, -0.0170, -0.0031],
        [ 0.0131, -0.0168,  0.0058,  ..., -0.0087,  0.0011,  0.0066],
        [-0.0052,  0.0102, -0.0175,  ..., -0.0045,  0.0020,  0.0027]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6621, -4.1406, -2.1699,  ...,  2.9199, -0.4749, -1.8438]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:28:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for ensuring is the active form of ensure
continuing is the active form of continue
managing is the active form of manage
enjoying is the active form of enjoy
seeming is the active form of seem
improving is the active form of improve
sitting is the active form of sit
avoiding is the active form of
2024-07-31 21:28:15 root INFO     [order_1_approx] starting weight calculation for ensuring is the active form of ensure
improving is the active form of improve
managing is the active form of manage
enjoying is the active form of enjoy
sitting is the active form of sit
continuing is the active form of continue
avoiding is the active form of avoid
seeming is the active form of
2024-07-31 21:28:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 21:31:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0491,  0.0966,  0.1741,  ..., -0.0305, -0.2605,  0.0300],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2832, -3.9160, -0.8613,  ...,  2.7422, -0.7061, -4.2891],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0068, -0.0147,  0.0106,  ...,  0.0121, -0.0088,  0.0128],
        [-0.0320,  0.0352, -0.0176,  ...,  0.0016,  0.0258, -0.0062],
        [ 0.0154, -0.0100,  0.0014,  ..., -0.0100,  0.0054, -0.0114],
        ...,
        [-0.0144,  0.0218, -0.0113,  ...,  0.0206,  0.0248, -0.0001],
        [ 0.0120, -0.0139, -0.0063,  ..., -0.0038,  0.0161,  0.0216],
        [-0.0331,  0.0311, -0.0027,  ..., -0.0156,  0.0305, -0.0011]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3086, -3.9902, -0.6689,  ...,  2.7500, -0.5737, -3.7129]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:31:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for ensuring is the active form of ensure
improving is the active form of improve
managing is the active form of manage
enjoying is the active form of enjoy
sitting is the active form of sit
continuing is the active form of continue
avoiding is the active form of avoid
seeming is the active form of
2024-07-31 21:31:19 root INFO     [order_1_approx] starting weight calculation for ensuring is the active form of ensure
sitting is the active form of sit
continuing is the active form of continue
managing is the active form of manage
avoiding is the active form of avoid
enjoying is the active form of enjoy
seeming is the active form of seem
improving is the active form of
2024-07-31 21:31:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 21:34:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0168,  0.1434,  0.2446,  ..., -0.0576, -0.0480, -0.0032],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1445, -4.1562, -0.7637,  ...,  2.9355, -0.7236, -2.6934],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0131, -0.0134, -0.0019,  ..., -0.0090, -0.0143,  0.0059],
        [-0.0022,  0.0113, -0.0124,  ...,  0.0020, -0.0027,  0.0043],
        [ 0.0226,  0.0142,  0.0033,  ...,  0.0147, -0.0042, -0.0248],
        ...,
        [-0.0072,  0.0157,  0.0249,  ...,  0.0227, -0.0178, -0.0357],
        [-0.0132, -0.0160,  0.0007,  ...,  0.0246,  0.0120, -0.0086],
        [-0.0179, -0.0023,  0.0083,  ...,  0.0353, -0.0194, -0.0529]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2109, -4.1875, -0.8584,  ...,  2.6621, -0.6948, -2.6758]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:34:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for ensuring is the active form of ensure
sitting is the active form of sit
continuing is the active form of continue
managing is the active form of manage
avoiding is the active form of avoid
enjoying is the active form of enjoy
seeming is the active form of seem
improving is the active form of
2024-07-31 21:34:21 root INFO     [order_1_approx] starting weight calculation for continuing is the active form of continue
seeming is the active form of seem
sitting is the active form of sit
avoiding is the active form of avoid
improving is the active form of improve
managing is the active form of manage
enjoying is the active form of enjoy
ensuring is the active form of
2024-07-31 21:34:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 21:37:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0620,  0.2649,  0.0934,  ...,  0.1256, -0.0454, -0.2722],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4297, -3.5293, -0.4785,  ...,  1.5703, -2.0469, -3.2949],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.5099e-02, -2.0081e-02, -8.2855e-03,  ..., -3.0365e-03,
          6.1768e-02, -1.1589e-02],
        [-3.6316e-02,  1.3176e-02,  3.8177e-02,  ..., -7.2479e-05,
         -2.2278e-03, -1.4565e-02],
        [ 9.0942e-03,  5.9929e-03, -1.7883e-02,  ..., -1.2894e-02,
         -1.0155e-02,  8.2397e-03],
        ...,
        [ 2.9144e-03,  7.4997e-03, -1.8311e-04,  ...,  2.4200e-02,
          5.2872e-03,  9.0637e-03],
        [ 4.8141e-03,  9.9869e-03, -6.4087e-03,  ...,  4.7073e-03,
          2.1545e-02,  1.9302e-02],
        [ 4.7150e-03,  1.4175e-02, -1.2115e-02,  ..., -3.4561e-03,
          2.0767e-02, -9.3384e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3313, -3.6152, -0.5928,  ...,  1.4912, -2.0254, -3.3047]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:37:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for continuing is the active form of continue
seeming is the active form of seem
sitting is the active form of sit
avoiding is the active form of avoid
improving is the active form of improve
managing is the active form of manage
enjoying is the active form of enjoy
ensuring is the active form of
2024-07-31 21:37:24 root INFO     total operator prediction time: 1467.0486164093018 seconds
2024-07-31 21:37:24 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_Ving - Ved
2024-07-31 21:37:24 root INFO     building operator verb_Ving - Ved
2024-07-31 21:37:25 root INFO     [order_1_approx] starting weight calculation for After something is relating, it has related
After something is remaining, it has remained
After something is improving, it has improved
After something is becoming, it has became
After something is publishing, it has published
After something is involving, it has involved
After something is following, it has followed
After something is marrying, it has
2024-07-31 21:37:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 21:40:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0228,  0.1814,  0.0383,  ..., -0.0676, -0.1523, -0.2197],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2812, -3.3164,  1.0889,  ..., -0.4106, -1.8223, -2.1523],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0016, -0.0426,  0.0087,  ...,  0.0209,  0.0189, -0.0153],
        [-0.0273,  0.0319,  0.0192,  ..., -0.0331,  0.0434,  0.0482],
        [ 0.0037, -0.0076,  0.0030,  ..., -0.0154, -0.0124, -0.0415],
        ...,
        [-0.0021,  0.0207, -0.0093,  ...,  0.0016,  0.0496,  0.0427],
        [-0.0082,  0.0218, -0.0024,  ..., -0.0162, -0.0219,  0.0294],
        [ 0.0021,  0.0384,  0.0363,  ..., -0.0001, -0.0323,  0.0175]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2324, -2.9805,  1.2852,  ..., -0.4692, -1.3379, -2.2422]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:40:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is relating, it has related
After something is remaining, it has remained
After something is improving, it has improved
After something is becoming, it has became
After something is publishing, it has published
After something is involving, it has involved
After something is following, it has followed
After something is marrying, it has
2024-07-31 21:40:27 root INFO     [order_1_approx] starting weight calculation for After something is improving, it has improved
After something is publishing, it has published
After something is marrying, it has married
After something is following, it has followed
After something is relating, it has related
After something is involving, it has involved
After something is becoming, it has became
After something is remaining, it has
2024-07-31 21:40:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 21:43:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0034,  0.0905,  0.2961,  ..., -0.1895, -0.1628, -0.1565],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4229, -2.8359,  1.5410,  ..., -2.5176, -1.0791, -4.1016],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0233, -0.0787, -0.0359,  ...,  0.0129, -0.0055,  0.0692],
        [-0.0213,  0.0094, -0.0776,  ..., -0.0206,  0.0146,  0.0024],
        [-0.0133, -0.0065,  0.0060,  ..., -0.0351, -0.0253, -0.0228],
        ...,
        [-0.0129, -0.0278, -0.0116,  ..., -0.0330,  0.0367,  0.0230],
        [ 0.0166,  0.0248, -0.0337,  ...,  0.0056, -0.0052, -0.0261],
        [-0.0060,  0.0335, -0.0107,  ..., -0.0228,  0.0098, -0.0386]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4561, -3.4180,  2.9688,  ..., -3.6973, -0.2822, -3.8496]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:43:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is improving, it has improved
After something is publishing, it has published
After something is marrying, it has married
After something is following, it has followed
After something is relating, it has related
After something is involving, it has involved
After something is becoming, it has became
After something is remaining, it has
2024-07-31 21:43:31 root INFO     [order_1_approx] starting weight calculation for After something is improving, it has improved
After something is publishing, it has published
After something is following, it has followed
After something is relating, it has related
After something is becoming, it has became
After something is marrying, it has married
After something is remaining, it has remained
After something is involving, it has
2024-07-31 21:43:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 21:46:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0363,  0.0080,  0.0612,  ..., -0.0154, -0.0916, -0.2810],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0273, -0.2119,  2.8477,  ..., -0.7188,  0.0753, -3.8965],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0419, -0.0121,  0.0414,  ...,  0.0244, -0.0015,  0.0014],
        [-0.0457,  0.0952,  0.0190,  ..., -0.0204, -0.0079, -0.0632],
        [ 0.0363, -0.0414, -0.0213,  ..., -0.0397, -0.0277, -0.1068],
        ...,
        [-0.0141, -0.0200, -0.0069,  ...,  0.0009,  0.0420, -0.0446],
        [ 0.0258,  0.0594, -0.0145,  ...,  0.0346, -0.0182,  0.0249],
        [ 0.0333,  0.0681,  0.0686,  ...,  0.0164, -0.0302,  0.0444]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3164, -0.5449,  2.1953,  ..., -1.7051,  0.4775, -3.6523]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:46:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is improving, it has improved
After something is publishing, it has published
After something is following, it has followed
After something is relating, it has related
After something is becoming, it has became
After something is marrying, it has married
After something is remaining, it has remained
After something is involving, it has
2024-07-31 21:46:36 root INFO     [order_1_approx] starting weight calculation for After something is remaining, it has remained
After something is becoming, it has became
After something is marrying, it has married
After something is publishing, it has published
After something is relating, it has related
After something is improving, it has improved
After something is involving, it has involved
After something is following, it has
2024-07-31 21:46:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 21:49:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0728, -0.0497,  0.0452,  ..., -0.0993,  0.0173, -0.1318],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2539, -2.5000,  3.5898,  ...,  0.1082, -3.0664, -0.8574],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0085, -0.0145,  0.0084,  ..., -0.0414,  0.0131, -0.0042],
        [-0.0092,  0.0667,  0.0011,  ...,  0.0869,  0.0060,  0.0251],
        [-0.0056, -0.0029,  0.0055,  ..., -0.0178, -0.0443, -0.0316],
        ...,
        [-0.0191, -0.0048,  0.0113,  ..., -0.0177,  0.0399,  0.0067],
        [ 0.0152, -0.0076, -0.0063,  ...,  0.0134,  0.0275,  0.0055],
        [-0.0012,  0.0194,  0.0191,  ..., -0.0357, -0.0177,  0.0110]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0312, -2.3984,  3.1445,  ...,  0.4419, -2.5703, -1.1660]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:49:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is remaining, it has remained
After something is becoming, it has became
After something is marrying, it has married
After something is publishing, it has published
After something is relating, it has related
After something is improving, it has improved
After something is involving, it has involved
After something is following, it has
2024-07-31 21:49:40 root INFO     [order_1_approx] starting weight calculation for After something is improving, it has improved
After something is marrying, it has married
After something is involving, it has involved
After something is publishing, it has published
After something is following, it has followed
After something is remaining, it has remained
After something is relating, it has related
After something is becoming, it has
2024-07-31 21:49:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 21:52:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0134,  0.1803,  0.2666,  ..., -0.0169, -0.2028, -0.1443],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3242, -0.0708,  2.8770,  ..., -0.4014,  0.7671, -1.1758],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0211, -0.0020, -0.0081,  ...,  0.0325,  0.0374,  0.0324],
        [-0.0197,  0.0367,  0.0076,  ..., -0.0313,  0.0084, -0.0359],
        [-0.0062, -0.0372, -0.0377,  ..., -0.0026, -0.0170,  0.0158],
        ...,
        [-0.0108,  0.0081,  0.0093,  ...,  0.0236,  0.0129, -0.0017],
        [ 0.0305, -0.0153, -0.0290,  ..., -0.0127, -0.0074, -0.0289],
        [ 0.0183,  0.0062,  0.0070,  ...,  0.0256, -0.0019,  0.0087]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3359, -0.6641,  2.9160,  ..., -0.5527,  0.7837, -1.5176]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:52:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is improving, it has improved
After something is marrying, it has married
After something is involving, it has involved
After something is publishing, it has published
After something is following, it has followed
After something is remaining, it has remained
After something is relating, it has related
After something is becoming, it has
2024-07-31 21:52:39 root INFO     [order_1_approx] starting weight calculation for After something is publishing, it has published
After something is marrying, it has married
After something is relating, it has related
After something is remaining, it has remained
After something is involving, it has involved
After something is following, it has followed
After something is becoming, it has became
After something is improving, it has
2024-07-31 21:52:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 21:55:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0143, -0.0298,  0.2671,  ..., -0.0594, -0.0151,  0.0151],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.6250, -1.9932,  0.8428,  ..., -0.9741, -2.4707, -3.3184],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0203, -0.0134,  0.0329,  ...,  0.0448, -0.0161, -0.0700],
        [-0.0649,  0.0168,  0.0600,  ...,  0.0169,  0.0329, -0.1633],
        [ 0.0046, -0.0084, -0.0031,  ..., -0.0156, -0.0120, -0.0474],
        ...,
        [-0.0086, -0.0075,  0.0493,  ..., -0.0035,  0.0583, -0.0415],
        [ 0.0483,  0.0434, -0.0952,  ..., -0.0177, -0.0406,  0.2632],
        [ 0.0021,  0.0233,  0.0129,  ...,  0.0009, -0.0216,  0.0587]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.1797, -2.3066,  0.6265,  ..., -1.3867, -0.8584, -3.2188]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:55:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is publishing, it has published
After something is marrying, it has married
After something is relating, it has related
After something is remaining, it has remained
After something is involving, it has involved
After something is following, it has followed
After something is becoming, it has became
After something is improving, it has
2024-07-31 21:55:43 root INFO     [order_1_approx] starting weight calculation for After something is improving, it has improved
After something is becoming, it has became
After something is marrying, it has married
After something is following, it has followed
After something is involving, it has involved
After something is remaining, it has remained
After something is publishing, it has published
After something is relating, it has
2024-07-31 21:55:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 21:58:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0993, -0.0105,  0.0257,  ..., -0.0359, -0.3269, -0.3081],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0996, -0.2739,  1.4941,  ...,  0.9692, -2.3652, -0.5039],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0224, -0.0656, -0.0064,  ...,  0.0455,  0.0065,  0.0317],
        [-0.0269,  0.0740,  0.0248,  ...,  0.0010,  0.0069, -0.0347],
        [ 0.0049,  0.0144,  0.0327,  ...,  0.0432, -0.0286, -0.0574],
        ...,
        [-0.0173,  0.0183, -0.0036,  ..., -0.0096,  0.0462,  0.0174],
        [ 0.0432, -0.0088, -0.0345,  ..., -0.0066, -0.0246,  0.0030],
        [ 0.0202,  0.0407,  0.0665,  ...,  0.0034, -0.0395,  0.0007]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1709,  0.0361,  1.0742,  ...,  0.3521, -1.6582, -0.5859]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:58:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is improving, it has improved
After something is becoming, it has became
After something is marrying, it has married
After something is following, it has followed
After something is involving, it has involved
After something is remaining, it has remained
After something is publishing, it has published
After something is relating, it has
2024-07-31 21:58:47 root INFO     [order_1_approx] starting weight calculation for After something is involving, it has involved
After something is marrying, it has married
After something is improving, it has improved
After something is following, it has followed
After something is becoming, it has became
After something is relating, it has related
After something is remaining, it has remained
After something is publishing, it has
2024-07-31 21:58:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 22:01:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0458,  0.1271,  0.2554,  ...,  0.0093, -0.0869, -0.0459],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4453, -3.7324,  0.5811,  ..., -2.3359, -2.2324,  0.4609],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0184, -0.0072, -0.0160,  ...,  0.0181,  0.0742,  0.0216],
        [-0.0657,  0.0615,  0.0084,  ...,  0.0121,  0.0286, -0.0247],
        [ 0.0473, -0.0548, -0.0027,  ..., -0.0063, -0.0218, -0.0110],
        ...,
        [-0.1009,  0.0522,  0.1252,  ...,  0.0731,  0.0551, -0.0981],
        [ 0.0859, -0.0278, -0.1431,  ..., -0.0659, -0.0512,  0.1219],
        [ 0.0188,  0.0368,  0.0437,  ..., -0.0050, -0.0900, -0.0073]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0508, -3.3301,  0.9575,  ..., -3.7988, -0.8545, -0.4175]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:01:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is involving, it has involved
After something is marrying, it has married
After something is improving, it has improved
After something is following, it has followed
After something is becoming, it has became
After something is relating, it has related
After something is remaining, it has remained
After something is publishing, it has
2024-07-31 22:01:53 root INFO     total operator prediction time: 1468.3810274600983 seconds
2024-07-31 22:01:53 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_inf - Ved
2024-07-31 22:01:53 root INFO     building operator verb_inf - Ved
2024-07-31 22:01:53 root INFO     [order_1_approx] starting weight calculation for If the present form is attend, the past form is attended
If the present form is enjoy, the past form is enjoyed
If the present form is understand, the past form is understood
If the present form is add, the past form is added
If the present form is allow, the past form is allowed
If the present form is create, the past form is created
If the present form is send, the past form is sent
If the present form is replace, the past form is
2024-07-31 22:01:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 22:04:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0924,  0.0114, -0.1076,  ..., -0.2133, -0.1360, -0.1395],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.1699,  0.0684, -0.6436,  ..., -2.3516, -0.1167,  0.6514],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0210,  0.0281, -0.0116,  ..., -0.0051, -0.0175, -0.0459],
        [ 0.0240,  0.0291,  0.0187,  ...,  0.0132, -0.0014,  0.0537],
        [ 0.0176,  0.0229, -0.0276,  ..., -0.0508, -0.0292, -0.0228],
        ...,
        [-0.0129, -0.0004,  0.0002,  ...,  0.0085, -0.0157,  0.0030],
        [ 0.0481, -0.0332,  0.0019,  ..., -0.0070,  0.0259,  0.0551],
        [ 0.0434,  0.0040,  0.0116,  ...,  0.0353,  0.0213,  0.0616]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.9824,  0.7065, -0.4976,  ..., -2.9277,  0.4756,  1.4531]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:04:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is attend, the past form is attended
If the present form is enjoy, the past form is enjoyed
If the present form is understand, the past form is understood
If the present form is add, the past form is added
If the present form is allow, the past form is allowed
If the present form is create, the past form is created
If the present form is send, the past form is sent
If the present form is replace, the past form is
2024-07-31 22:04:56 root INFO     [order_1_approx] starting weight calculation for If the present form is understand, the past form is understood
If the present form is add, the past form is added
If the present form is replace, the past form is replaced
If the present form is allow, the past form is allowed
If the present form is create, the past form is created
If the present form is attend, the past form is attended
If the present form is send, the past form is sent
If the present form is enjoy, the past form is
2024-07-31 22:04:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 22:08:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0000e+00,  1.1230e-01,  1.6617e-02,  ...,  1.0681e-04,
        -3.4961e-01, -2.2949e-02], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3379, -0.1282,  1.0908,  ..., -2.1914, -4.1562, -0.7383],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0453, -0.0667, -0.0789,  ...,  0.0130,  0.0387, -0.0397],
        [ 0.0293,  0.0909,  0.0452,  ..., -0.0038, -0.0160,  0.0238],
        [ 0.0103,  0.0036,  0.0081,  ..., -0.0013, -0.0338, -0.0044],
        ...,
        [ 0.0012, -0.0321, -0.0062,  ..., -0.0131,  0.0319, -0.0318],
        [ 0.0538,  0.0312,  0.0381,  ..., -0.0122, -0.0386, -0.0073],
        [ 0.0382,  0.0248,  0.0417,  ...,  0.0221, -0.0097,  0.0080]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1953,  0.6621,  1.4150,  ..., -2.0957, -3.3086, -0.1450]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:08:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is understand, the past form is understood
If the present form is add, the past form is added
If the present form is replace, the past form is replaced
If the present form is allow, the past form is allowed
If the present form is create, the past form is created
If the present form is attend, the past form is attended
If the present form is send, the past form is sent
If the present form is enjoy, the past form is
2024-07-31 22:08:01 root INFO     [order_1_approx] starting weight calculation for If the present form is send, the past form is sent
If the present form is add, the past form is added
If the present form is understand, the past form is understood
If the present form is create, the past form is created
If the present form is enjoy, the past form is enjoyed
If the present form is attend, the past form is attended
If the present form is replace, the past form is replaced
If the present form is allow, the past form is
2024-07-31 22:08:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 22:10:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0812, -0.0287,  0.1807,  ..., -0.1285, -0.3135, -0.1207],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1475, -2.6387, -0.6411,  ..., -0.9917, -2.2773,  0.8662],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0108, -0.0220, -0.0526,  ..., -0.0050,  0.0346, -0.0464],
        [ 0.0124,  0.0711,  0.0205,  ..., -0.0257, -0.0525,  0.0138],
        [ 0.0176, -0.0062, -0.0126,  ..., -0.0184, -0.0285, -0.0019],
        ...,
        [ 0.0185, -0.0634,  0.0002,  ...,  0.0114,  0.0313,  0.0193],
        [ 0.0417,  0.0380, -0.0004,  ..., -0.0030, -0.0596,  0.0414],
        [ 0.0164,  0.0695,  0.0347,  ..., -0.0178, -0.0519,  0.0159]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2314, -1.8203, -0.6558,  ..., -0.9199, -2.0176,  1.4238]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:11:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is send, the past form is sent
If the present form is add, the past form is added
If the present form is understand, the past form is understood
If the present form is create, the past form is created
If the present form is enjoy, the past form is enjoyed
If the present form is attend, the past form is attended
If the present form is replace, the past form is replaced
If the present form is allow, the past form is
2024-07-31 22:11:00 root INFO     [order_1_approx] starting weight calculation for If the present form is attend, the past form is attended
If the present form is create, the past form is created
If the present form is replace, the past form is replaced
If the present form is send, the past form is sent
If the present form is enjoy, the past form is enjoyed
If the present form is allow, the past form is allowed
If the present form is add, the past form is added
If the present form is understand, the past form is
2024-07-31 22:11:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 22:14:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0726,  0.1366, -0.0512,  ..., -0.0073, -0.3232, -0.0800],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5820,  1.7236,  0.9004,  ..., -0.7881, -1.9795,  0.9434],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0297, -0.0546, -0.0370,  ..., -0.0293, -0.0086, -0.0155],
        [ 0.0024,  0.0385,  0.0450,  ..., -0.0019, -0.0038, -0.0030],
        [-0.0013, -0.0131, -0.0118,  ..., -0.0389, -0.0156, -0.0186],
        ...,
        [ 0.0225, -0.0151,  0.0062,  ...,  0.0224, -0.0010, -0.0046],
        [ 0.0321, -0.0083, -0.0017,  ..., -0.0090, -0.0263, -0.0070],
        [-0.0229,  0.0137,  0.0467,  ..., -0.0097,  0.0151,  0.0204]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4746,  2.0801,  0.9058,  ..., -0.6455, -1.9541,  0.5322]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:14:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is attend, the past form is attended
If the present form is create, the past form is created
If the present form is replace, the past form is replaced
If the present form is send, the past form is sent
If the present form is enjoy, the past form is enjoyed
If the present form is allow, the past form is allowed
If the present form is add, the past form is added
If the present form is understand, the past form is
2024-07-31 22:14:04 root INFO     [order_1_approx] starting weight calculation for If the present form is understand, the past form is understood
If the present form is replace, the past form is replaced
If the present form is create, the past form is created
If the present form is attend, the past form is attended
If the present form is allow, the past form is allowed
If the present form is enjoy, the past form is enjoyed
If the present form is add, the past form is added
If the present form is send, the past form is
2024-07-31 22:14:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 22:17:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0816,  0.0803,  0.1423,  ..., -0.0996, -0.3323, -0.1333],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1777, -0.9888, -1.8789,  ..., -2.2090, -0.6143, -3.4629],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0116, -0.0380, -0.0197,  ..., -0.0309,  0.0406, -0.0769],
        [ 0.0050,  0.0041,  0.0848,  ...,  0.0784,  0.0224,  0.0618],
        [ 0.0112, -0.0231, -0.0260,  ..., -0.0540, -0.0444, -0.0150],
        ...,
        [ 0.0022, -0.0116, -0.0141,  ..., -0.0031, -0.0023, -0.0102],
        [ 0.0057,  0.0135, -0.0120,  ..., -0.0083, -0.0022,  0.0160],
        [ 0.0336,  0.0162,  0.0551,  ...,  0.0191, -0.0128,  0.0541]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1593, -0.0640, -1.4014,  ..., -2.3770, -0.3621, -2.8965]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:17:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is understand, the past form is understood
If the present form is replace, the past form is replaced
If the present form is create, the past form is created
If the present form is attend, the past form is attended
If the present form is allow, the past form is allowed
If the present form is enjoy, the past form is enjoyed
If the present form is add, the past form is added
If the present form is send, the past form is
2024-07-31 22:17:11 root INFO     [order_1_approx] starting weight calculation for If the present form is replace, the past form is replaced
If the present form is understand, the past form is understood
If the present form is enjoy, the past form is enjoyed
If the present form is allow, the past form is allowed
If the present form is add, the past form is added
If the present form is create, the past form is created
If the present form is send, the past form is sent
If the present form is attend, the past form is
2024-07-31 22:17:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 22:20:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0171,  0.2656, -0.2754,  ..., -0.1478, -0.3257, -0.1328],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9834,  2.4434, -0.3960,  ..., -0.6787, -4.4609, -1.2842],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0280, -0.0258, -0.0613,  ..., -0.0154,  0.0163, -0.0487],
        [-0.0354,  0.0320,  0.0787,  ...,  0.0014,  0.0314,  0.0116],
        [ 0.0258,  0.0219, -0.0045,  ..., -0.0114, -0.0389, -0.0180],
        ...,
        [-0.0020, -0.0125,  0.0370,  ...,  0.0164,  0.0148, -0.0072],
        [ 0.0155, -0.0123, -0.0330,  ..., -0.0064, -0.0334, -0.0078],
        [ 0.0307,  0.0576,  0.0316,  ...,  0.0497, -0.0014,  0.0253]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3164,  3.3105, -0.2656,  ..., -0.4780, -3.4062, -0.4810]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:20:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is replace, the past form is replaced
If the present form is understand, the past form is understood
If the present form is enjoy, the past form is enjoyed
If the present form is allow, the past form is allowed
If the present form is add, the past form is added
If the present form is create, the past form is created
If the present form is send, the past form is sent
If the present form is attend, the past form is
2024-07-31 22:20:15 root INFO     [order_1_approx] starting weight calculation for If the present form is attend, the past form is attended
If the present form is add, the past form is added
If the present form is understand, the past form is understood
If the present form is send, the past form is sent
If the present form is allow, the past form is allowed
If the present form is enjoy, the past form is enjoyed
If the present form is replace, the past form is replaced
If the present form is create, the past form is
2024-07-31 22:20:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 22:23:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0191,  0.1010, -0.0032,  ..., -0.0078, -0.3921, -0.1395],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0830, -1.1201,  1.3447,  ..., -1.0469, -2.2598,  0.7637],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0023, -0.0445, -0.0267,  ..., -0.0012, -0.0079, -0.0113],
        [ 0.0600,  0.0209, -0.0075,  ..., -0.0172,  0.0351,  0.0065],
        [-0.0021,  0.0047,  0.0283,  ..., -0.0108, -0.0550, -0.0165],
        ...,
        [ 0.0198, -0.0055, -0.0068,  ...,  0.0166,  0.0152,  0.0217],
        [ 0.0208,  0.0037, -0.0106,  ..., -0.0166, -0.0346,  0.0236],
        [ 0.0414,  0.0113,  0.0010,  ...,  0.0065,  0.0081,  0.0444]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1553, -0.2251,  1.2266,  ..., -1.5547, -1.6797,  1.5508]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:23:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is attend, the past form is attended
If the present form is add, the past form is added
If the present form is understand, the past form is understood
If the present form is send, the past form is sent
If the present form is allow, the past form is allowed
If the present form is enjoy, the past form is enjoyed
If the present form is replace, the past form is replaced
If the present form is create, the past form is
2024-07-31 22:23:16 root INFO     [order_1_approx] starting weight calculation for If the present form is understand, the past form is understood
If the present form is allow, the past form is allowed
If the present form is create, the past form is created
If the present form is attend, the past form is attended
If the present form is enjoy, the past form is enjoyed
If the present form is replace, the past form is replaced
If the present form is send, the past form is sent
If the present form is add, the past form is
2024-07-31 22:23:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 22:26:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-1.2207e-04,  4.1199e-03, -7.6294e-03,  ..., -7.7637e-02,
        -5.1758e-01, -1.1481e-01], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2012,  0.4473, -1.1484,  ...,  0.7832, -3.9414, -0.5645],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0287, -0.0225, -0.0215,  ..., -0.0003,  0.0211, -0.0240],
        [-0.0322,  0.0255,  0.0284,  ...,  0.0268, -0.0132,  0.0120],
        [ 0.0350, -0.0054,  0.0105,  ..., -0.0342, -0.0698,  0.0040],
        ...,
        [ 0.0308, -0.0252,  0.0215,  ...,  0.0199,  0.0115,  0.0122],
        [ 0.0314, -0.0034, -0.0113,  ..., -0.0561, -0.0095,  0.0309],
        [ 0.0082,  0.0085,  0.0129,  ...,  0.0023,  0.0020,  0.0266]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1864,  1.5273, -1.4756,  ...,  0.4392, -3.6250, -0.0322]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:26:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is understand, the past form is understood
If the present form is allow, the past form is allowed
If the present form is create, the past form is created
If the present form is attend, the past form is attended
If the present form is enjoy, the past form is enjoyed
If the present form is replace, the past form is replaced
If the present form is send, the past form is sent
If the present form is add, the past form is
2024-07-31 22:26:16 root INFO     total operator prediction time: 1463.0756356716156 seconds
2024-07-31 22:26:16 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_inf - 3pSg
2024-07-31 22:26:16 root INFO     building operator verb_inf - 3pSg
2024-07-31 22:26:16 root INFO     [order_1_approx] starting weight calculation for I consist, he consists
I agree, he agrees
I describe, he describes
I add, he adds
I apply, he applies
I understand, he understands
I remember, he remembers
I develop, he
2024-07-31 22:26:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 22:29:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1642,  0.2783,  0.1155,  ..., -0.1166,  0.0514, -0.2123],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2617, -4.7617,  0.7070,  ...,  0.0801, -6.4219, -0.7764],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0165,  0.0292, -0.0156,  ...,  0.0101,  0.0037,  0.0399],
        [-0.0616, -0.0115, -0.0211,  ..., -0.0130,  0.0033, -0.0159],
        [ 0.0035,  0.0526, -0.0173,  ...,  0.0287, -0.0313, -0.0214],
        ...,
        [ 0.0112, -0.0403,  0.0217,  ...,  0.0262, -0.0044,  0.0109],
        [-0.0385,  0.0230,  0.0109,  ..., -0.0792, -0.0432, -0.0144],
        [-0.0083,  0.0288,  0.0237,  ..., -0.0148, -0.0021, -0.0100]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8203, -4.0156, -0.6943,  ...,  0.8418, -7.2578, -0.6963]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:29:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I consist, he consists
I agree, he agrees
I describe, he describes
I add, he adds
I apply, he applies
I understand, he understands
I remember, he remembers
I develop, he
2024-07-31 22:29:20 root INFO     [order_1_approx] starting weight calculation for I remember, he remembers
I agree, he agrees
I add, he adds
I consist, he consists
I understand, he understands
I describe, he describes
I develop, he develops
I apply, he
2024-07-31 22:29:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 22:32:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1494,  0.1938,  0.0590,  ..., -0.0647, -0.1741, -0.1613],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6230, -3.3633, -0.8262,  ..., -0.4326, -7.5859, -0.1055],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.6947e-02, -2.8931e-02, -1.8890e-02,  ...,  8.4915e-03,
         -1.8921e-02,  4.9835e-02],
        [-3.6377e-02,  2.1103e-02,  2.1606e-02,  ..., -2.3621e-02,
          6.3400e-03,  3.4714e-03],
        [ 7.6523e-03,  1.6800e-02, -2.5482e-02,  ..., -3.4332e-05,
         -2.9907e-02, -1.1688e-02],
        ...,
        [ 1.4473e-02, -2.7802e-02,  7.1869e-03,  ...,  1.2177e-02,
          3.3997e-02,  1.4565e-02],
        [-4.0222e-02,  1.2939e-02, -1.5823e-02,  ..., -5.1605e-02,
          1.6998e-02, -7.3814e-03],
        [-1.1200e-02,  1.0681e-02,  1.3420e-02,  ..., -2.4612e-02,
         -5.5962e-03,  1.3794e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6689, -3.3496, -0.8037,  ...,  0.3198, -8.2344, -0.3728]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:32:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I remember, he remembers
I agree, he agrees
I add, he adds
I consist, he consists
I understand, he understands
I describe, he describes
I develop, he develops
I apply, he
2024-07-31 22:32:19 root INFO     [order_1_approx] starting weight calculation for I remember, he remembers
I apply, he applies
I agree, he agrees
I understand, he understands
I consist, he consists
I develop, he develops
I add, he adds
I describe, he
2024-07-31 22:32:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 22:35:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0861,  0.1794,  0.0359,  ..., -0.2101,  0.0370, -0.3130],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5020, -3.9297,  3.3945,  ...,  0.1865, -5.2031, -0.4023],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0341, -0.0061,  0.0110,  ...,  0.0267,  0.0062, -0.0022],
        [-0.0454,  0.0209, -0.0622,  ...,  0.0293,  0.0008,  0.0502],
        [ 0.0078,  0.0343,  0.0060,  ..., -0.0356,  0.0189, -0.0719],
        ...,
        [ 0.0227, -0.0622, -0.0411,  ...,  0.0283,  0.0075,  0.0280],
        [-0.0242,  0.0873, -0.0081,  ..., -0.0228,  0.0244,  0.0422],
        [ 0.0404,  0.0363, -0.0033,  ...,  0.0288,  0.0096,  0.0271]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2441, -3.2520,  2.4141,  ...,  1.3145, -6.0000, -0.5322]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:35:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I remember, he remembers
I apply, he applies
I agree, he agrees
I understand, he understands
I consist, he consists
I develop, he develops
I add, he adds
I describe, he
2024-07-31 22:35:19 root INFO     [order_1_approx] starting weight calculation for I develop, he develops
I apply, he applies
I consist, he consists
I understand, he understands
I describe, he describes
I remember, he remembers
I agree, he agrees
I add, he
2024-07-31 22:35:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 22:38:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0562,  0.0065,  0.1046,  ..., -0.1313, -0.2361, -0.2042],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2227, -2.3594, -2.4453,  ...,  1.5820, -9.0469,  1.1211],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0411, -0.0032,  0.0073,  ...,  0.0147,  0.0139, -0.0084],
        [-0.0376,  0.0165,  0.0081,  ..., -0.0300,  0.0286, -0.0198],
        [-0.0289,  0.0017, -0.0209,  ...,  0.0027, -0.0010, -0.0128],
        ...,
        [-0.0179, -0.0137,  0.0274,  ...,  0.0006, -0.0022,  0.0195],
        [-0.0024,  0.0149,  0.0495,  ..., -0.0715, -0.0399,  0.0364],
        [ 0.0158,  0.0170,  0.0063,  ..., -0.0232,  0.0141,  0.0039]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2383, -1.9834, -2.6562,  ...,  1.1484, -8.9844,  1.4082]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:38:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I develop, he develops
I apply, he applies
I consist, he consists
I understand, he understands
I describe, he describes
I remember, he remembers
I agree, he agrees
I add, he
2024-07-31 22:38:22 root INFO     [order_1_approx] starting weight calculation for I remember, he remembers
I agree, he agrees
I add, he adds
I apply, he applies
I consist, he consists
I develop, he develops
I describe, he describes
I understand, he
2024-07-31 22:38:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 22:41:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0341,  0.2421, -0.0200,  ..., -0.0823, -0.1354, -0.0909],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2578, -2.8711,  0.0273,  ..., -1.1924, -5.1406,  2.3203],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.6129e-02, -1.4313e-02,  5.6267e-03,  ...,  7.7324e-03,
         -9.1629e-03,  2.0233e-02],
        [-4.4800e-02,  2.7481e-02,  5.1880e-03,  ..., -1.1925e-02,
          9.6054e-03,  1.1406e-02],
        [ 5.3406e-05, -3.7689e-03, -5.2338e-03,  ...,  9.3460e-03,
          7.5912e-03, -6.8588e-03],
        ...,
        [-9.0866e-03,  9.7656e-04, -1.7975e-02,  ..., -2.1515e-03,
          4.3411e-03,  1.3344e-02],
        [ 3.2806e-02,  2.1149e-02,  1.6022e-03,  ..., -1.9791e-02,
          2.0584e-02, -1.4702e-02],
        [ 1.2024e-02,  2.0706e-02,  1.5091e-02,  ...,  9.5978e-03,
         -4.2915e-03,  4.3793e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8926, -2.8145, -0.3083,  ..., -0.2583, -5.8633,  1.5488]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:41:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I remember, he remembers
I agree, he agrees
I add, he adds
I apply, he applies
I consist, he consists
I develop, he develops
I describe, he describes
I understand, he
2024-07-31 22:41:26 root INFO     [order_1_approx] starting weight calculation for I add, he adds
I understand, he understands
I develop, he develops
I apply, he applies
I remember, he remembers
I describe, he describes
I agree, he agrees
I consist, he
2024-07-31 22:41:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 22:44:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1384,  0.1385, -0.1844,  ..., -0.1598, -0.0399, -0.1888],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.4570, -3.3008, -0.0723,  ..., -1.7432, -5.5391,  0.4766],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0436,  0.0110,  0.0504,  ..., -0.0139, -0.0428,  0.0065],
        [-0.0406,  0.0039, -0.0274,  ...,  0.0165,  0.0327, -0.0078],
        [-0.0023,  0.0170,  0.0276,  ..., -0.0083, -0.0142, -0.0179],
        ...,
        [-0.0294, -0.0336, -0.0385,  ...,  0.0106,  0.0515,  0.0108],
        [-0.0284, -0.0274,  0.0160,  ..., -0.0418, -0.0256, -0.0062],
        [-0.0087,  0.0273,  0.0467,  ..., -0.0291, -0.0002,  0.0028]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4727, -2.7109, -0.7642,  ..., -0.4258, -6.6992,  0.2502]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:44:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I add, he adds
I understand, he understands
I develop, he develops
I apply, he applies
I remember, he remembers
I describe, he describes
I agree, he agrees
I consist, he
2024-07-31 22:44:30 root INFO     [order_1_approx] starting weight calculation for I apply, he applies
I describe, he describes
I agree, he agrees
I add, he adds
I develop, he develops
I understand, he understands
I consist, he consists
I remember, he
2024-07-31 22:44:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 22:47:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1863,  0.1956,  0.0328,  ..., -0.0200,  0.0325, -0.1093],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2920, -3.0762, -0.8027,  ..., -0.7520, -5.6562, -1.2666],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.0106e-02, -8.8272e-03,  2.7222e-02,  ...,  2.8107e-02,
         -8.0109e-05,  2.6474e-02],
        [-6.7932e-02,  3.8361e-02, -2.5635e-02,  ..., -4.1351e-03,
         -1.6205e-02, -2.7733e-03],
        [-4.3373e-03,  1.5221e-02, -2.6794e-02,  ..., -1.0986e-02,
          8.3618e-03, -4.4769e-02],
        ...,
        [ 8.8654e-03, -4.0283e-03, -1.2817e-03,  ..., -2.4155e-02,
         -7.8430e-03,  3.4088e-02],
        [ 1.3344e-02,  3.3966e-02, -4.5135e-02,  ...,  7.6218e-03,
         -6.5536e-03, -1.2169e-03],
        [ 1.7395e-02,  1.9394e-02, -2.2339e-02,  ...,  1.5549e-02,
          1.1299e-02, -2.7557e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3108, -2.7441, -0.2974,  ...,  0.1509, -5.3281, -1.1055]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:47:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I apply, he applies
I describe, he describes
I agree, he agrees
I add, he adds
I develop, he develops
I understand, he understands
I consist, he consists
I remember, he
2024-07-31 22:47:35 root INFO     [order_1_approx] starting weight calculation for I apply, he applies
I consist, he consists
I describe, he describes
I remember, he remembers
I develop, he develops
I understand, he understands
I add, he adds
I agree, he
2024-07-31 22:47:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 22:50:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0564,  0.0484, -0.0120,  ..., -0.0731, -0.2019, -0.2063],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4121, -4.7734,  0.5332,  ..., -0.2949, -4.8281,  2.5820],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.8727e-02, -1.9424e-02, -2.6276e-02,  ...,  1.0910e-02,
          3.8971e-02,  2.7039e-02],
        [-5.2795e-02,  6.2744e-02,  6.3629e-03,  ...,  1.6113e-02,
         -1.7761e-02, -2.8824e-02],
        [ 2.7008e-02,  3.2257e-02,  2.9877e-02,  ..., -9.0942e-03,
          6.9885e-03, -9.1934e-04],
        ...,
        [ 4.9210e-03, -1.9897e-02, -3.4424e-02,  ...,  1.2680e-02,
          6.1512e-05,  8.4686e-03],
        [-3.1677e-02,  6.4880e-02, -3.5919e-02,  ...,  5.9052e-03,
         -2.4292e-02, -3.3813e-02],
        [-1.9348e-02,  7.3303e-02,  2.5406e-02,  ...,  3.5706e-02,
         -5.1270e-02,  1.0612e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0547, -4.3516,  0.1633,  ...,  0.3091, -4.9648,  2.8027]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:50:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I apply, he applies
I consist, he consists
I describe, he describes
I remember, he remembers
I develop, he develops
I understand, he understands
I add, he adds
I agree, he
2024-07-31 22:50:34 root INFO     total operator prediction time: 1458.403329372406 seconds
2024-07-31 22:50:34 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_Ving - 3pSg
2024-07-31 22:50:34 root INFO     building operator verb_Ving - 3pSg
2024-07-31 22:50:35 root INFO     [order_1_approx] starting weight calculation for When something is developing, it develops
When something is remaining, it remains
When something is discovering, it discovers
When something is suggesting, it suggests
When something is operating, it operates
When something is including, it includes
When something is performing, it performs
When something is advertising, it
2024-07-31 22:50:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 22:53:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1527,  0.1146, -0.0679,  ...,  0.1221,  0.0227, -0.3577],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.9844,  1.1250,  1.9492,  ...,  1.8096, -9.9844, -2.7090],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0233,  0.0032,  0.0477,  ...,  0.0100, -0.0175,  0.0139],
        [-0.0133,  0.0443,  0.0154,  ...,  0.0141, -0.0012,  0.0181],
        [ 0.0030,  0.0130,  0.0382,  ...,  0.0104, -0.0361,  0.0006],
        ...,
        [-0.0175,  0.0004, -0.0202,  ...,  0.0204,  0.0222,  0.0025],
        [-0.0084,  0.0350, -0.0241,  ..., -0.0305, -0.0102, -0.0247],
        [-0.0046,  0.0117,  0.0284,  ...,  0.0039, -0.0287,  0.0310]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 6.4727,  1.0391,  1.9756,  ...,  1.5742, -9.4219, -2.9395]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:53:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is developing, it develops
When something is remaining, it remains
When something is discovering, it discovers
When something is suggesting, it suggests
When something is operating, it operates
When something is including, it includes
When something is performing, it performs
When something is advertising, it
2024-07-31 22:53:38 root INFO     [order_1_approx] starting weight calculation for When something is performing, it performs
When something is including, it includes
When something is developing, it develops
When something is advertising, it advertises
When something is operating, it operates
When something is suggesting, it suggests
When something is remaining, it remains
When something is discovering, it
2024-07-31 22:53:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 22:56:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1377,  0.0042, -0.0448,  ...,  0.0433, -0.0231, -0.1580],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.7188, -4.4062,  0.0098,  ...,  0.2837, -9.5234,  0.4434],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0165, -0.0150,  0.0310,  ..., -0.0562, -0.1489, -0.0594],
        [-0.0220,  0.0247, -0.0137,  ...,  0.0187,  0.0076,  0.0370],
        [ 0.0105, -0.0085, -0.0199,  ..., -0.0126, -0.0156,  0.0052],
        ...,
        [ 0.0346,  0.0013,  0.0120,  ...,  0.0353, -0.0115, -0.0042],
        [ 0.0192, -0.0346, -0.0213,  ..., -0.0021,  0.1212,  0.0885],
        [ 0.0040,  0.0195,  0.0378,  ..., -0.0524, -0.0723, -0.0588]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 6.4102, -4.1445, -0.1940,  ...,  0.4197, -9.7422,  0.5498]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:56:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is performing, it performs
When something is including, it includes
When something is developing, it develops
When something is advertising, it advertises
When something is operating, it operates
When something is suggesting, it suggests
When something is remaining, it remains
When something is discovering, it
2024-07-31 22:56:41 root INFO     [order_1_approx] starting weight calculation for When something is remaining, it remains
When something is including, it includes
When something is suggesting, it suggests
When something is advertising, it advertises
When something is operating, it operates
When something is developing, it develops
When something is discovering, it discovers
When something is performing, it
2024-07-31 22:56:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 22:59:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0508,  0.1270,  0.0162,  ..., -0.0341, -0.1956, -0.1466],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.9922, -3.1348,  1.8379,  ...,  0.1592, -7.4297, -3.8477],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0476,  0.0043,  0.0185,  ...,  0.0605,  0.0723, -0.1165],
        [ 0.0075,  0.0970, -0.0599,  ...,  0.0767,  0.0787, -0.0690],
        [-0.0023,  0.0187, -0.0424,  ...,  0.0515,  0.0392, -0.0676],
        ...,
        [-0.0286, -0.0244,  0.0255,  ...,  0.0178,  0.0501, -0.0277],
        [-0.0009, -0.0192,  0.0322,  ..., -0.0751, -0.1018,  0.1021],
        [ 0.0364, -0.0113,  0.0037,  ...,  0.0026,  0.0117, -0.0524]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6250, -4.0352,  0.7158,  ...,  0.1417, -5.9727, -3.7715]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:59:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is remaining, it remains
When something is including, it includes
When something is suggesting, it suggests
When something is advertising, it advertises
When something is operating, it operates
When something is developing, it develops
When something is discovering, it discovers
When something is performing, it
2024-07-31 22:59:44 root INFO     [order_1_approx] starting weight calculation for When something is performing, it performs
When something is remaining, it remains
When something is suggesting, it suggests
When something is advertising, it advertises
When something is discovering, it discovers
When something is operating, it operates
When something is developing, it develops
When something is including, it
2024-07-31 22:59:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 23:02:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0207, -0.0048,  0.0251,  ...,  0.1993, -0.1289, -0.1602],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([  3.6172,   0.6411,   0.5293,  ...,   1.1572, -11.2344,  -1.3984],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0596, -0.0148,  0.0930,  ...,  0.0693, -0.0064,  0.0022],
        [-0.0457,  0.0713,  0.0650,  ...,  0.0994,  0.0102, -0.1087],
        [-0.0091,  0.0258,  0.0192,  ...,  0.0667, -0.0645,  0.0056],
        ...,
        [ 0.0608, -0.0195,  0.0564,  ..., -0.0070,  0.0032,  0.0523],
        [ 0.0588,  0.0027, -0.0846,  ..., -0.0713, -0.0632,  0.1112],
        [ 0.0259, -0.0363,  0.0267,  ..., -0.0280, -0.0117,  0.0110]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4336, -1.2090, -0.0273,  ...,  1.0020, -9.5156, -1.7168]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:02:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is performing, it performs
When something is remaining, it remains
When something is suggesting, it suggests
When something is advertising, it advertises
When something is discovering, it discovers
When something is operating, it operates
When something is developing, it develops
When something is including, it
2024-07-31 23:02:47 root INFO     [order_1_approx] starting weight calculation for When something is including, it includes
When something is performing, it performs
When something is discovering, it discovers
When something is advertising, it advertises
When something is operating, it operates
When something is suggesting, it suggests
When something is developing, it develops
When something is remaining, it
2024-07-31 23:02:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 23:05:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1836,  0.3923,  0.0155,  ...,  0.0008, -0.1088,  0.0446],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1406, -2.2617, -1.3066,  ..., -0.6992, -5.5820, -1.2080],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0105, -0.0644, -0.0152,  ..., -0.0014, -0.0109,  0.0227],
        [-0.0523, -0.0006,  0.0247,  ...,  0.0149, -0.0222, -0.0150],
        [ 0.0016, -0.0404,  0.0157,  ..., -0.0228, -0.0200, -0.0140],
        ...,
        [ 0.0315, -0.0319, -0.0292,  ...,  0.0174,  0.0259,  0.0035],
        [ 0.0249,  0.0354, -0.0576,  ..., -0.0026,  0.0054,  0.0265],
        [-0.0115, -0.0517,  0.0008,  ...,  0.0045, -0.0044, -0.0032]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9297, -2.5508, -1.0225,  ..., -0.5464, -5.3125, -0.8896]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:05:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is including, it includes
When something is performing, it performs
When something is discovering, it discovers
When something is advertising, it advertises
When something is operating, it operates
When something is suggesting, it suggests
When something is developing, it develops
When something is remaining, it
2024-07-31 23:05:49 root INFO     [order_1_approx] starting weight calculation for When something is including, it includes
When something is advertising, it advertises
When something is performing, it performs
When something is operating, it operates
When something is discovering, it discovers
When something is developing, it develops
When something is remaining, it remains
When something is suggesting, it
2024-07-31 23:05:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 23:08:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1609,  0.1890,  0.1636,  ...,  0.1134, -0.1039, -0.3135],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.0156, -1.4531,  0.9941,  ...,  2.0898, -7.4414, -0.6016],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0649, -0.0608,  0.0204,  ..., -0.0704,  0.0264,  0.0149],
        [ 0.0288,  0.1526,  0.0014,  ...,  0.1244,  0.0960, -0.0392],
        [-0.0104, -0.0434,  0.0103,  ..., -0.0400, -0.0229,  0.0491],
        ...,
        [-0.0321,  0.0988,  0.0597,  ...,  0.0979,  0.0165,  0.0231],
        [ 0.0148,  0.0469, -0.0528,  ..., -0.0563, -0.0580, -0.0366],
        [ 0.0367,  0.0219,  0.0640,  ..., -0.0023,  0.0152, -0.0007]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.8672, -5.2617,  0.0088,  ...,  0.8896, -5.8438, -1.8857]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:08:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is including, it includes
When something is advertising, it advertises
When something is performing, it performs
When something is operating, it operates
When something is discovering, it discovers
When something is developing, it develops
When something is remaining, it remains
When something is suggesting, it
2024-07-31 23:08:53 root INFO     [order_1_approx] starting weight calculation for When something is developing, it develops
When something is discovering, it discovers
When something is remaining, it remains
When something is performing, it performs
When something is suggesting, it suggests
When something is including, it includes
When something is advertising, it advertises
When something is operating, it
2024-07-31 23:08:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 23:11:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0104,  0.0371, -0.0090,  ..., -0.0791, -0.0050, -0.1260],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.4648, -2.4141,  2.0020,  ..., -0.0269, -4.0469, -2.7285],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0079,  0.0160, -0.0260,  ...,  0.0609,  0.0131, -0.0255],
        [-0.0139,  0.0762, -0.0418,  ...,  0.0237,  0.0320, -0.0092],
        [ 0.0074,  0.0192, -0.0100,  ...,  0.0266, -0.0232, -0.0460],
        ...,
        [-0.0161, -0.0092,  0.0298,  ...,  0.0460, -0.0003, -0.0139],
        [-0.0376, -0.0175, -0.0216,  ..., -0.0050, -0.0180, -0.0169],
        [ 0.0109, -0.0362,  0.0231,  ...,  0.0190, -0.0270,  0.0060]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.1562, -2.7188,  1.3535,  ...,  0.0136, -4.8711, -2.6855]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:11:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is developing, it develops
When something is discovering, it discovers
When something is remaining, it remains
When something is performing, it performs
When something is suggesting, it suggests
When something is including, it includes
When something is advertising, it advertises
When something is operating, it
2024-07-31 23:11:56 root INFO     [order_1_approx] starting weight calculation for When something is advertising, it advertises
When something is suggesting, it suggests
When something is performing, it performs
When something is discovering, it discovers
When something is including, it includes
When something is remaining, it remains
When something is operating, it operates
When something is developing, it
2024-07-31 23:11:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 23:14:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0042,  0.1675, -0.1311,  ...,  0.0020,  0.0231, -0.2240],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([  5.5000,  -2.9336,   2.3477,  ...,   2.2520, -12.0469,   0.8066],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0477, -0.0287,  0.0098,  ...,  0.0337, -0.0385,  0.0046],
        [-0.0033,  0.0544, -0.0345,  ...,  0.0468, -0.0078,  0.0027],
        [ 0.0213, -0.0244, -0.0162,  ...,  0.0287, -0.0795, -0.0106],
        ...,
        [ 0.0075, -0.0350,  0.0581,  ...,  0.0748, -0.0375, -0.0053],
        [-0.0135,  0.0394, -0.0039,  ..., -0.0728,  0.0118,  0.0229],
        [-0.0311, -0.0226,  0.0643,  ...,  0.0024, -0.0728, -0.0125]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[  4.7344,  -3.2031,   1.9189,  ...,   1.3291, -11.8125,   0.2227]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:14:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is advertising, it advertises
When something is suggesting, it suggests
When something is performing, it performs
When something is discovering, it discovers
When something is including, it includes
When something is remaining, it remains
When something is operating, it operates
When something is developing, it
2024-07-31 23:14:59 root INFO     total operator prediction time: 1464.552871465683 seconds
2024-07-31 23:14:59 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun - plural_reg
2024-07-31 23:14:59 root INFO     building operator noun - plural_reg
2024-07-31 23:14:59 root INFO     [order_1_approx] starting weight calculation for The plural form of hour is hours
The plural form of song is songs
The plural form of death is deaths
The plural form of thing is things
The plural form of website is websites
The plural form of player is players
The plural form of office is offices
The plural form of population is
2024-07-31 23:14:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 23:18:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0963, -0.2766,  0.0502,  ..., -0.0570, -0.0336, -0.1648],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6445, -4.1328,  1.3633,  ..., -1.4551, -2.8086, -2.0391],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0251, -0.0709, -0.0030,  ...,  0.0282, -0.0589, -0.0209],
        [ 0.0535,  0.0266,  0.0744,  ...,  0.0862,  0.0155,  0.0301],
        [ 0.0374,  0.0034,  0.0157,  ...,  0.0157, -0.0166, -0.0034],
        ...,
        [ 0.0044, -0.0115,  0.0310,  ...,  0.0194,  0.0190,  0.0020],
        [-0.0244,  0.0117,  0.0043,  ...,  0.0069,  0.0218,  0.0111],
        [ 0.0398,  0.0275,  0.0598,  ...,  0.0862,  0.0021,  0.0238]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5332, -3.6992,  1.8125,  ..., -0.6841, -2.6582, -1.0078]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:18:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of hour is hours
The plural form of song is songs
The plural form of death is deaths
The plural form of thing is things
The plural form of website is websites
The plural form of player is players
The plural form of office is offices
The plural form of population is
2024-07-31 23:18:02 root INFO     [order_1_approx] starting weight calculation for The plural form of player is players
The plural form of death is deaths
The plural form of song is songs
The plural form of population is populations
The plural form of thing is things
The plural form of website is websites
The plural form of office is offices
The plural form of hour is
2024-07-31 23:18:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 23:21:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1857, -0.1926,  0.1989,  ...,  0.1010, -0.1484,  0.0059],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3181, -2.6836,  1.0508,  ..., -1.5020,  0.7188, -2.5723],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0043, -0.0143, -0.0221,  ..., -0.0184, -0.0005,  0.0188],
        [ 0.0427,  0.0007,  0.0257,  ...,  0.0206, -0.0649, -0.0284],
        [-0.0069, -0.0095,  0.0157,  ..., -0.0157,  0.0044,  0.0206],
        ...,
        [-0.0002,  0.0058,  0.0193,  ...,  0.0353,  0.0193,  0.0194],
        [ 0.0403, -0.0054,  0.0356,  ...,  0.0533, -0.0224, -0.0077],
        [ 0.0136, -0.0228,  0.0345,  ..., -0.0016, -0.0453, -0.0129]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4600, -2.0293,  1.0771,  ..., -1.5020,  0.5537, -1.8711]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:21:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of player is players
The plural form of death is deaths
The plural form of song is songs
The plural form of population is populations
The plural form of thing is things
The plural form of website is websites
The plural form of office is offices
The plural form of hour is
2024-07-31 23:21:05 root INFO     [order_1_approx] starting weight calculation for The plural form of player is players
The plural form of thing is things
The plural form of death is deaths
The plural form of song is songs
The plural form of population is populations
The plural form of website is websites
The plural form of hour is hours
The plural form of office is
2024-07-31 23:21:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 23:24:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0743, -0.0654, -0.0494,  ..., -0.1256, -0.3013, -0.1272],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1035, -3.0977,  1.5840,  ..., -0.2070,  0.2725, -1.0264],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0110, -0.0382,  0.0069,  ...,  0.0138, -0.0161,  0.0236],
        [ 0.0465,  0.0328, -0.0216,  ...,  0.0272,  0.0103, -0.0153],
        [ 0.0186,  0.0157, -0.0293,  ...,  0.0151, -0.0267,  0.0163],
        ...,
        [ 0.0223,  0.0095,  0.0115,  ...,  0.0024, -0.0331,  0.0339],
        [ 0.0272,  0.0074, -0.0134,  ..., -0.0008,  0.0058,  0.0040],
        [ 0.0190, -0.0061,  0.0364,  ..., -0.0026, -0.0009, -0.0074]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9150, -2.6074,  1.3613,  ...,  0.0243,  0.3760, -0.5820]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:24:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of player is players
The plural form of thing is things
The plural form of death is deaths
The plural form of song is songs
The plural form of population is populations
The plural form of website is websites
The plural form of hour is hours
The plural form of office is
2024-07-31 23:24:07 root INFO     [order_1_approx] starting weight calculation for The plural form of song is songs
The plural form of office is offices
The plural form of hour is hours
The plural form of population is populations
The plural form of death is deaths
The plural form of website is websites
The plural form of thing is things
The plural form of player is
2024-07-31 23:24:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 23:27:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0062, -0.2467,  0.1704,  ..., -0.0219, -0.1880, -0.1215],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2690, -5.2891,  0.5156,  ..., -0.4741, -1.8848, -2.0762],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0271, -0.0257,  0.0095,  ..., -0.0156,  0.0048, -0.0035],
        [ 0.0044,  0.0343, -0.0213,  ...,  0.0536,  0.0038, -0.0075],
        [-0.0071, -0.0075,  0.0206,  ..., -0.0472,  0.0055, -0.0079],
        ...,
        [ 0.0159,  0.0167,  0.0031,  ...,  0.0169,  0.0169,  0.0078],
        [ 0.0093,  0.0386, -0.0010,  ..., -0.0494, -0.0070,  0.0081],
        [ 0.0240,  0.0187,  0.0123,  ...,  0.0122,  0.0150,  0.0138]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7139, -4.9844,  0.6270,  ..., -0.3135, -2.2871, -1.8125]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:27:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of song is songs
The plural form of office is offices
The plural form of hour is hours
The plural form of population is populations
The plural form of death is deaths
The plural form of website is websites
The plural form of thing is things
The plural form of player is
2024-07-31 23:27:10 root INFO     [order_1_approx] starting weight calculation for The plural form of hour is hours
The plural form of website is websites
The plural form of office is offices
The plural form of player is players
The plural form of population is populations
The plural form of song is songs
The plural form of thing is things
The plural form of death is
2024-07-31 23:27:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 23:30:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0433, -0.2278,  0.0836,  ..., -0.1609, -0.3047,  0.0495],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3877, -3.0898,  2.3477,  ..., -2.0508, -1.1270, -2.8125],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0286, -0.0701, -0.0145,  ...,  0.0443, -0.0018, -0.0048],
        [ 0.0192,  0.0159,  0.0456,  ...,  0.0124,  0.0079, -0.0418],
        [ 0.0011,  0.0430, -0.0189,  ..., -0.0019, -0.0360,  0.0276],
        ...,
        [ 0.0019, -0.0257, -0.0098,  ...,  0.0081, -0.0102, -0.0099],
        [ 0.0150,  0.0336,  0.0291,  ...,  0.0285,  0.0236,  0.0048],
        [ 0.0267, -0.0448,  0.0145,  ...,  0.0905,  0.0174,  0.0269]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1914, -2.3809,  2.7129,  ..., -2.1348, -1.0332, -2.2520]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:30:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of hour is hours
The plural form of website is websites
The plural form of office is offices
The plural form of player is players
The plural form of population is populations
The plural form of song is songs
The plural form of thing is things
The plural form of death is
2024-07-31 23:30:14 root INFO     [order_1_approx] starting weight calculation for The plural form of website is websites
The plural form of death is deaths
The plural form of population is populations
The plural form of office is offices
The plural form of song is songs
The plural form of hour is hours
The plural form of player is players
The plural form of thing is
2024-07-31 23:30:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 23:33:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1196, -0.0657,  0.0129,  ..., -0.3220, -0.0659, -0.1015],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3672, -2.9629,  1.8223,  ..., -0.2808, -2.0195, -2.3555],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0013, -0.0487,  0.0156,  ...,  0.0312, -0.0249, -0.0104],
        [ 0.0303,  0.0253,  0.0614,  ...,  0.0351,  0.0221, -0.0245],
        [-0.0400,  0.0115,  0.0258,  ..., -0.0317, -0.0080,  0.0392],
        ...,
        [-0.0477, -0.0285,  0.0066,  ..., -0.0234,  0.0295,  0.0215],
        [-0.0386,  0.0245, -0.0401,  ..., -0.0240,  0.0018, -0.0050],
        [-0.0187, -0.0147, -0.0146,  ...,  0.0776, -0.0119, -0.0253]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4883, -2.7285,  2.0684,  ..., -0.6797, -1.5508, -2.0566]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:33:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of website is websites
The plural form of death is deaths
The plural form of population is populations
The plural form of office is offices
The plural form of song is songs
The plural form of hour is hours
The plural form of player is players
The plural form of thing is
2024-07-31 23:33:18 root INFO     [order_1_approx] starting weight calculation for The plural form of player is players
The plural form of population is populations
The plural form of thing is things
The plural form of death is deaths
The plural form of hour is hours
The plural form of song is songs
The plural form of office is offices
The plural form of website is
2024-07-31 23:33:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 23:36:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0549,  0.0809, -0.0606,  ..., -0.0792, -0.1042, -0.0182],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5254, -3.4199,  1.7725,  ...,  1.1445, -1.1104, -0.8628],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0318, -0.0269, -0.0007,  ...,  0.0097, -0.0157,  0.0019],
        [-0.0226,  0.0196,  0.0147,  ...,  0.0312, -0.0070, -0.0258],
        [ 0.0389,  0.0348, -0.0393,  ...,  0.0113, -0.0291,  0.0503],
        ...,
        [-0.0113, -0.0182,  0.0346,  ..., -0.0186, -0.0195, -0.0076],
        [ 0.0387, -0.0060, -0.0408,  ..., -0.0230, -0.0017,  0.0314],
        [-0.0106,  0.0102,  0.0356,  ...,  0.0174, -0.0102, -0.0085]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5312, -2.9590,  2.0000,  ...,  1.8037, -1.1426, -0.5449]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:36:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of player is players
The plural form of population is populations
The plural form of thing is things
The plural form of death is deaths
The plural form of hour is hours
The plural form of song is songs
The plural form of office is offices
The plural form of website is
2024-07-31 23:36:20 root INFO     [order_1_approx] starting weight calculation for The plural form of website is websites
The plural form of death is deaths
The plural form of hour is hours
The plural form of population is populations
The plural form of office is offices
The plural form of player is players
The plural form of thing is things
The plural form of song is
2024-07-31 23:36:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 23:39:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0159, -0.0319,  0.0998,  ...,  0.0602, -0.2573, -0.0045],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3965, -4.0156,  2.1836,  ..., -2.4883, -1.0664, -2.6328],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0187, -0.0494,  0.0116,  ..., -0.0124,  0.0082,  0.0107],
        [ 0.0427,  0.0322, -0.0079,  ...,  0.0320, -0.0136, -0.0188],
        [-0.0213,  0.0110, -0.0105,  ..., -0.0119, -0.0142, -0.0017],
        ...,
        [ 0.0040, -0.0368, -0.0188,  ...,  0.0095,  0.0195, -0.0017],
        [ 0.0263,  0.0177, -0.0069,  ..., -0.0130, -0.0324,  0.0089],
        [ 0.0203,  0.0124,  0.0191,  ...,  0.0027, -0.0044, -0.0047]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1113, -3.6367,  2.1328,  ..., -2.1074, -1.3438, -2.2930]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:39:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of website is websites
The plural form of death is deaths
The plural form of hour is hours
The plural form of population is populations
The plural form of office is offices
The plural form of player is players
The plural form of thing is things
The plural form of song is
2024-07-31 23:39:23 root INFO     total operator prediction time: 1464.6211965084076 seconds
2024-07-31 23:39:23 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_3pSg - Ved
2024-07-31 23:39:23 root INFO     building operator verb_3pSg - Ved
2024-07-31 23:39:24 root INFO     [order_1_approx] starting weight calculation for When he announces something, something has been announced
When he continues something, something has been continued
When he applies something, something has been applied
When he tells something, something has been told
When he introduces something, something has been introduced
When he consists something, something has been consisted
When he loses something, something has been lost
When he receives something, something has been
2024-07-31 23:39:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 23:42:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0717,  0.2004, -0.0018,  ..., -0.0332, -0.1753, -0.1895],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2930, -0.3379, -1.4150,  ..., -3.1875, -3.0430, -1.1523],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0543, -0.0028, -0.0191,  ...,  0.0019, -0.0051,  0.0606],
        [-0.0590,  0.0121,  0.0258,  ...,  0.0104, -0.0024,  0.0225],
        [ 0.0138, -0.0102, -0.0245,  ..., -0.0056, -0.0076, -0.0305],
        ...,
        [ 0.0244,  0.0399,  0.0356,  ...,  0.0115,  0.0264,  0.0396],
        [ 0.0046, -0.0219, -0.0138,  ..., -0.0352,  0.0074, -0.0398],
        [ 0.0018, -0.0020,  0.0081,  ...,  0.0205,  0.0087,  0.0076]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2803, -0.4487, -1.2520,  ..., -3.4512, -2.9531, -1.2070]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:42:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he announces something, something has been announced
When he continues something, something has been continued
When he applies something, something has been applied
When he tells something, something has been told
When he introduces something, something has been introduced
When he consists something, something has been consisted
When he loses something, something has been lost
When he receives something, something has been
2024-07-31 23:42:27 root INFO     [order_1_approx] starting weight calculation for When he introduces something, something has been introduced
When he continues something, something has been continued
When he tells something, something has been told
When he consists something, something has been consisted
When he announces something, something has been announced
When he loses something, something has been lost
When he receives something, something has been received
When he applies something, something has been
2024-07-31 23:42:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 23:45:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0239,  0.0750, -0.0106,  ...,  0.1372, -0.1005, -0.0495],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9844, -0.0876,  0.7920,  ..., -0.6138, -1.3398, -0.4941],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0133, -0.0193, -0.0041,  ...,  0.0032, -0.0028,  0.0540],
        [-0.0058, -0.0016,  0.0071,  ...,  0.0071,  0.0017,  0.0273],
        [ 0.0261,  0.0222,  0.0028,  ..., -0.0135, -0.0094, -0.0266],
        ...,
        [ 0.0108,  0.0322,  0.0115,  ...,  0.0156,  0.0211,  0.0057],
        [ 0.0095, -0.0022, -0.0144,  ...,  0.0042, -0.0144, -0.0278],
        [ 0.0130,  0.0327,  0.0131,  ..., -0.0210, -0.0208, -0.0030]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1084, -0.0362,  1.0176,  ..., -0.8940, -1.0352, -0.6216]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:45:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he introduces something, something has been introduced
When he continues something, something has been continued
When he tells something, something has been told
When he consists something, something has been consisted
When he announces something, something has been announced
When he loses something, something has been lost
When he receives something, something has been received
When he applies something, something has been
2024-07-31 23:45:32 root INFO     [order_1_approx] starting weight calculation for When he loses something, something has been lost
When he introduces something, something has been introduced
When he receives something, something has been received
When he consists something, something has been consisted
When he continues something, something has been continued
When he applies something, something has been applied
When he tells something, something has been told
When he announces something, something has been
2024-07-31 23:45:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 23:48:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0375,  0.3730, -0.0257,  ...,  0.1512, -0.1085, -0.2255],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1084, -0.5234,  2.5215,  ...,  0.8564, -2.2266,  0.5273],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0063,  0.0126, -0.0247,  ...,  0.0055,  0.0017,  0.0259],
        [-0.0064,  0.0084, -0.0069,  ..., -0.0055,  0.0131, -0.0059],
        [-0.0034,  0.0010, -0.0349,  ..., -0.0136, -0.0051, -0.0140],
        ...,
        [ 0.0070,  0.0094, -0.0128,  ..., -0.0019,  0.0079,  0.0116],
        [ 0.0114,  0.0104, -0.0144,  ..., -0.0001, -0.0154, -0.0031],
        [-0.0052, -0.0026,  0.0054,  ...,  0.0085,  0.0061, -0.0043]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0762, -0.5503,  2.6758,  ...,  0.9785, -2.1484,  0.5596]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:48:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he loses something, something has been lost
When he introduces something, something has been introduced
When he receives something, something has been received
When he consists something, something has been consisted
When he continues something, something has been continued
When he applies something, something has been applied
When he tells something, something has been told
When he announces something, something has been
2024-07-31 23:48:36 root INFO     [order_1_approx] starting weight calculation for When he tells something, something has been told
When he introduces something, something has been introduced
When he applies something, something has been applied
When he consists something, something has been consisted
When he announces something, something has been announced
When he receives something, something has been received
When he continues something, something has been continued
When he loses something, something has been
2024-07-31 23:48:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 23:51:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0330,  0.2576,  0.0928,  ...,  0.0301,  0.1115, -0.1542],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7529, -1.5898,  1.1631,  ..., -0.7744,  0.3271, -2.2031],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0180, -0.0321,  0.0231,  ...,  0.0031,  0.0003, -0.0002],
        [ 0.0062,  0.0261,  0.0247,  ...,  0.0201, -0.0068,  0.0205],
        [ 0.0127,  0.0200, -0.0150,  ..., -0.0109,  0.0107, -0.0252],
        ...,
        [ 0.0074,  0.0135, -0.0403,  ...,  0.0055, -0.0003,  0.0305],
        [ 0.0115,  0.0573, -0.0527,  ...,  0.0018, -0.0127,  0.0088],
        [-0.0130,  0.0117,  0.0478,  ...,  0.0143, -0.0021, -0.0110]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1953, -1.9502,  1.2773,  ..., -0.8179, -0.3726, -2.0254]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:51:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he tells something, something has been told
When he introduces something, something has been introduced
When he applies something, something has been applied
When he consists something, something has been consisted
When he announces something, something has been announced
When he receives something, something has been received
When he continues something, something has been continued
When he loses something, something has been
2024-07-31 23:51:40 root INFO     [order_1_approx] starting weight calculation for When he consists something, something has been consisted
When he continues something, something has been continued
When he introduces something, something has been introduced
When he applies something, something has been applied
When he loses something, something has been lost
When he receives something, something has been received
When he announces something, something has been announced
When he tells something, something has been
2024-07-31 23:51:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 23:54:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0523,  0.1827,  0.0999,  ...,  0.1023, -0.0331, -0.1560],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0703,  1.2227,  4.7656,  ...,  1.4268, -4.3867, -0.8867],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0030, -0.0099, -0.0188,  ..., -0.0003, -0.0089,  0.0169],
        [-0.0095,  0.0375,  0.0067,  ..., -0.0251,  0.0175, -0.0169],
        [ 0.0022, -0.0145, -0.0037,  ...,  0.0071, -0.0174, -0.0127],
        ...,
        [ 0.0139,  0.0043, -0.0147,  ..., -0.0266, -0.0073,  0.0172],
        [-0.0023,  0.0104, -0.0089,  ...,  0.0294,  0.0142,  0.0177],
        [ 0.0191,  0.0331,  0.0016,  ...,  0.0036,  0.0458,  0.0067]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0430,  1.1914,  4.7695,  ...,  1.3535, -4.4414, -0.9883]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:54:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he consists something, something has been consisted
When he continues something, something has been continued
When he introduces something, something has been introduced
When he applies something, something has been applied
When he loses something, something has been lost
When he receives something, something has been received
When he announces something, something has been announced
When he tells something, something has been
2024-07-31 23:54:45 root INFO     [order_1_approx] starting weight calculation for When he consists something, something has been consisted
When he continues something, something has been continued
When he tells something, something has been told
When he applies something, something has been applied
When he announces something, something has been announced
When he loses something, something has been lost
When he receives something, something has been received
When he introduces something, something has been
2024-07-31 23:54:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-07-31 23:57:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0025,  0.1421,  0.0523,  ...,  0.1650, -0.0052,  0.0954],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8125,  1.4883,  2.7441,  ...,  1.4180, -1.7773,  0.0137],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0063, -0.0097,  0.0045,  ...,  0.0053, -0.0178,  0.0168],
        [-0.0117,  0.0104,  0.0048,  ...,  0.0008, -0.0086, -0.0110],
        [ 0.0117,  0.0125,  0.0071,  ..., -0.0082, -0.0017, -0.0307],
        ...,
        [ 0.0002, -0.0006,  0.0170,  ...,  0.0100,  0.0061,  0.0189],
        [ 0.0132,  0.0076,  0.0103,  ..., -0.0102,  0.0032, -0.0093],
        [ 0.0130,  0.0132,  0.0207,  ...,  0.0042,  0.0093, -0.0013]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3984,  1.5449,  2.8789,  ...,  1.4023, -1.6689,  0.0299]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:57:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he consists something, something has been consisted
When he continues something, something has been continued
When he tells something, something has been told
When he applies something, something has been applied
When he announces something, something has been announced
When he loses something, something has been lost
When he receives something, something has been received
When he introduces something, something has been
2024-07-31 23:57:50 root INFO     [order_1_approx] starting weight calculation for When he loses something, something has been lost
When he announces something, something has been announced
When he applies something, something has been applied
When he introduces something, something has been introduced
When he tells something, something has been told
When he continues something, something has been continued
When he receives something, something has been received
When he consists something, something has been
2024-07-31 23:57:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 00:00:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0147,  0.1015, -0.1009,  ...,  0.0775, -0.2393,  0.0076],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([2.8574, 2.1602, 2.0078,  ..., 0.0516, 0.2332, 0.1602], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0119, -0.0430, -0.0116,  ...,  0.0230,  0.0002,  0.0156],
        [-0.0436,  0.0601,  0.0470,  ...,  0.0177, -0.0285, -0.0178],
        [ 0.0114,  0.0238,  0.0029,  ..., -0.0443, -0.0398, -0.0682],
        ...,
        [ 0.0071,  0.0092,  0.0319,  ...,  0.0018,  0.0309, -0.0212],
        [ 0.0136, -0.0307,  0.0448,  ...,  0.0166, -0.0120,  0.0299],
        [ 0.0064,  0.0302,  0.0428,  ..., -0.0173,  0.0212, -0.0271]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3809,  2.4121,  1.8428,  ..., -0.3926, -0.1338,  0.2306]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:00:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he loses something, something has been lost
When he announces something, something has been announced
When he applies something, something has been applied
When he introduces something, something has been introduced
When he tells something, something has been told
When he continues something, something has been continued
When he receives something, something has been received
When he consists something, something has been
2024-08-01 00:00:53 root INFO     [order_1_approx] starting weight calculation for When he consists something, something has been consisted
When he loses something, something has been lost
When he introduces something, something has been introduced
When he announces something, something has been announced
When he tells something, something has been told
When he receives something, something has been received
When he applies something, something has been applied
When he continues something, something has been
2024-08-01 00:00:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 00:03:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0812, -0.0685, -0.1459,  ...,  0.1917, -0.1357,  0.0624],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0449, -1.4629,  2.0586,  ..., -0.7236,  0.7993, -1.4355],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.9547e-02, -2.3300e-02,  1.8101e-03,  ..., -3.1357e-03,
          1.1215e-02,  3.0121e-02],
        [-1.4862e-02,  2.5223e-02,  3.6499e-02,  ..., -5.7335e-03,
         -1.6441e-03,  1.7609e-02],
        [ 1.7181e-02, -7.4387e-04, -4.1885e-03,  ..., -5.1270e-03,
         -2.9488e-03, -2.6642e-02],
        ...,
        [ 5.6877e-03,  1.2115e-02,  4.3121e-02,  ...,  1.1047e-02,
         -2.8629e-03,  1.3611e-02],
        [ 7.1182e-03,  2.1042e-02, -5.5359e-02,  ...,  7.0496e-03,
         -1.2787e-02, -1.3733e-02],
        [-4.9438e-03, -1.4706e-03, -1.4046e-02,  ..., -2.5192e-02,
          1.6251e-03, -1.0490e-05]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6621, -0.9370,  2.0332,  ..., -0.3633,  0.2329, -1.9365]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:03:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he consists something, something has been consisted
When he loses something, something has been lost
When he introduces something, something has been introduced
When he announces something, something has been announced
When he tells something, something has been told
When he receives something, something has been received
When he applies something, something has been applied
When he continues something, something has been
2024-08-01 00:03:57 root INFO     total operator prediction time: 1473.2360734939575 seconds
2024-08-01 00:03:57 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj - superlative
2024-08-01 00:03:57 root INFO     building operator adj - superlative
2024-08-01 00:03:57 root INFO     [order_1_approx] starting weight calculation for If something is the most scary, it is scariest
If something is the most sad, it is saddest
If something is the most neat, it is neatest
If something is the most nasty, it is nastiest
If something is the most dumb, it is dumbest
If something is the most costly, it is costliest
If something is the most weird, it is weirdest
If something is the most healthy, it is
2024-08-01 00:03:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 00:07:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1185,  0.0018,  0.1174,  ..., -0.1516, -0.0812, -0.2739],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1055, -6.7695,  0.3062,  ..., -0.5752, -2.7773, -2.6562],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-7.7324e-03, -2.2068e-03,  2.5543e-02,  ..., -2.1454e-02,
         -8.4000e-03,  3.9787e-03],
        [-2.4155e-02,  7.7934e-03, -2.7428e-03,  ..., -8.7509e-03,
          2.3346e-02, -8.7433e-03],
        [ 1.4435e-02, -9.0027e-03,  2.1935e-04,  ...,  1.9821e-02,
          6.8474e-03, -3.0384e-03],
        ...,
        [ 9.4757e-03, -2.7847e-04,  3.2043e-04,  ...,  8.5754e-03,
          8.4076e-03,  2.0050e-02],
        [-2.1667e-03,  2.5826e-03, -1.5793e-02,  ...,  5.3711e-03,
         -8.8348e-03, -1.5717e-02],
        [-7.7209e-03, -9.7275e-05, -2.4166e-03,  ...,  1.7761e-02,
         -1.1635e-02, -1.1002e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0859, -6.7734,  0.5527,  ..., -0.9375, -2.8262, -2.7266]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:07:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most scary, it is scariest
If something is the most sad, it is saddest
If something is the most neat, it is neatest
If something is the most nasty, it is nastiest
If something is the most dumb, it is dumbest
If something is the most costly, it is costliest
If something is the most weird, it is weirdest
If something is the most healthy, it is
2024-08-01 00:07:01 root INFO     [order_1_approx] starting weight calculation for If something is the most scary, it is scariest
If something is the most healthy, it is healthiest
If something is the most neat, it is neatest
If something is the most sad, it is saddest
If something is the most nasty, it is nastiest
If something is the most weird, it is weirdest
If something is the most costly, it is costliest
If something is the most dumb, it is
2024-08-01 00:07:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 00:10:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0252,  0.0917,  0.0817,  ..., -0.0021, -0.0956,  0.0970],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8740, -2.6523,  2.8105,  ..., -4.2227, -1.3975, -1.1338],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0447, -0.0540,  0.0004,  ..., -0.0089, -0.0053, -0.0005],
        [-0.0028, -0.0050,  0.0151,  ..., -0.0300,  0.0221,  0.0211],
        [ 0.0102,  0.0042,  0.0045,  ...,  0.0193, -0.0316, -0.0012],
        ...,
        [ 0.0049, -0.0218,  0.0082,  ..., -0.0079, -0.0175,  0.0416],
        [ 0.0135,  0.0120,  0.0118,  ...,  0.0078, -0.0238, -0.0089],
        [-0.0227,  0.0119,  0.0191,  ..., -0.0027,  0.0195, -0.0025]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4775, -2.7227,  2.2949,  ..., -4.3789, -1.3389, -1.2803]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:10:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most scary, it is scariest
If something is the most healthy, it is healthiest
If something is the most neat, it is neatest
If something is the most sad, it is saddest
If something is the most nasty, it is nastiest
If something is the most weird, it is weirdest
If something is the most costly, it is costliest
If something is the most dumb, it is
2024-08-01 00:10:05 root INFO     [order_1_approx] starting weight calculation for If something is the most dumb, it is dumbest
If something is the most weird, it is weirdest
If something is the most nasty, it is nastiest
If something is the most costly, it is costliest
If something is the most healthy, it is healthiest
If something is the most scary, it is scariest
If something is the most sad, it is saddest
If something is the most neat, it is
2024-08-01 00:10:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 00:13:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0319, -0.1846,  0.0611,  ...,  0.0012, -0.2166, -0.0158],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9175, -1.0879, -1.8633,  ..., -1.6387, -2.7578, -2.6133],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0124, -0.0212, -0.0294,  ..., -0.0130, -0.0341,  0.0013],
        [-0.0276,  0.0123,  0.0004,  ..., -0.0149,  0.0018,  0.0006],
        [ 0.0160, -0.0290,  0.0245,  ..., -0.0211, -0.0140,  0.0094],
        ...,
        [-0.0102, -0.0005,  0.0004,  ...,  0.0194,  0.0092, -0.0024],
        [-0.0341, -0.0148,  0.0046,  ..., -0.0036,  0.0016,  0.0138],
        [ 0.0128, -0.0088, -0.0098,  ...,  0.0281,  0.0072,  0.0270]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5889, -1.5488, -1.6309,  ..., -1.3623, -2.3711, -2.9297]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:13:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most dumb, it is dumbest
If something is the most weird, it is weirdest
If something is the most nasty, it is nastiest
If something is the most costly, it is costliest
If something is the most healthy, it is healthiest
If something is the most scary, it is scariest
If something is the most sad, it is saddest
If something is the most neat, it is
2024-08-01 00:13:09 root INFO     [order_1_approx] starting weight calculation for If something is the most nasty, it is nastiest
If something is the most scary, it is scariest
If something is the most healthy, it is healthiest
If something is the most neat, it is neatest
If something is the most sad, it is saddest
If something is the most costly, it is costliest
If something is the most dumb, it is dumbest
If something is the most weird, it is
2024-08-01 00:13:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 00:16:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0181,  0.0378,  0.1998,  ..., -0.1359,  0.0111, -0.0975],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8652, -4.9609, -0.2236,  ..., -2.2051, -0.4941, -2.3203],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0115, -0.0070, -0.0112,  ...,  0.0034,  0.0050, -0.0044],
        [-0.0059,  0.0047,  0.0132,  ...,  0.0161,  0.0030, -0.0025],
        [ 0.0060, -0.0235,  0.0111,  ...,  0.0076, -0.0124, -0.0233],
        ...,
        [-0.0058, -0.0048,  0.0184,  ...,  0.0265, -0.0033,  0.0127],
        [-0.0024,  0.0092, -0.0006,  ...,  0.0059, -0.0007, -0.0053],
        [ 0.0125,  0.0139, -0.0098,  ...,  0.0183,  0.0035, -0.0109]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.6445e-01, -4.9844e+00, -1.8311e-03,  ..., -1.9463e+00,
         -4.7852e-02, -2.0156e+00]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SubBackward0>) 

                    
2024-08-01 00:16:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most nasty, it is nastiest
If something is the most scary, it is scariest
If something is the most healthy, it is healthiest
If something is the most neat, it is neatest
If something is the most sad, it is saddest
If something is the most costly, it is costliest
If something is the most dumb, it is dumbest
If something is the most weird, it is
2024-08-01 00:16:16 root INFO     [order_1_approx] starting weight calculation for If something is the most costly, it is costliest
If something is the most weird, it is weirdest
If something is the most nasty, it is nastiest
If something is the most scary, it is scariest
If something is the most neat, it is neatest
If something is the most dumb, it is dumbest
If something is the most healthy, it is healthiest
If something is the most sad, it is
2024-08-01 00:16:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 00:19:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0484,  0.0242, -0.1316,  ..., -0.0383, -0.3699, -0.0437],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9414, -6.2422, -2.3652,  ..., -5.6641,  0.2354, -3.0215],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-3.6163e-02,  5.8289e-03,  2.7054e-02,  ...,  1.2695e-02,
          2.0935e-02, -2.5757e-02],
        [-3.4088e-02, -2.2446e-02,  8.7280e-03,  ..., -4.9591e-05,
         -1.8570e-02, -2.6367e-02],
        [ 6.6605e-03,  6.2704e-04,  2.9449e-02,  ...,  5.7259e-03,
          5.0354e-03, -1.3527e-02],
        ...,
        [-3.7964e-02, -3.6926e-02,  4.1443e-02,  ..., -7.2479e-04,
         -2.9266e-02, -2.3605e-02],
        [-1.2054e-02,  2.5986e-02, -2.3224e-02,  ...,  3.9368e-03,
         -5.1384e-03,  3.7727e-03],
        [ 2.5940e-04, -3.2562e-02,  4.5700e-03,  ..., -2.6962e-02,
         -2.7466e-02, -1.7395e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3696, -5.8438, -2.3984,  ..., -5.4219,  0.8257, -2.9414]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:19:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most costly, it is costliest
If something is the most weird, it is weirdest
If something is the most nasty, it is nastiest
If something is the most scary, it is scariest
If something is the most neat, it is neatest
If something is the most dumb, it is dumbest
If something is the most healthy, it is healthiest
If something is the most sad, it is
2024-08-01 00:19:18 root INFO     [order_1_approx] starting weight calculation for If something is the most neat, it is neatest
If something is the most weird, it is weirdest
If something is the most dumb, it is dumbest
If something is the most healthy, it is healthiest
If something is the most sad, it is saddest
If something is the most scary, it is scariest
If something is the most costly, it is costliest
If something is the most nasty, it is
2024-08-01 00:19:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 00:22:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0195,  0.1075,  0.0154,  ..., -0.1667,  0.0135, -0.0944],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9600, -6.4180, -3.2617,  ..., -4.5742, -2.5977, -0.3750],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0339, -0.0350,  0.0368,  ..., -0.0143, -0.0071, -0.0174],
        [ 0.0116,  0.0047,  0.0074,  ..., -0.0102, -0.0098,  0.0165],
        [-0.0132,  0.0114,  0.0142,  ...,  0.0185, -0.0132, -0.0054],
        ...,
        [ 0.0216,  0.0006,  0.0016,  ...,  0.0103,  0.0133,  0.0009],
        [-0.0003,  0.0211,  0.0052,  ...,  0.0213, -0.0023,  0.0015],
        [-0.0053,  0.0024, -0.0022,  ..., -0.0072, -0.0011, -0.0117]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5742, -6.0508, -3.1094,  ..., -4.5117, -2.5781, -0.1810]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:22:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most neat, it is neatest
If something is the most weird, it is weirdest
If something is the most dumb, it is dumbest
If something is the most healthy, it is healthiest
If something is the most sad, it is saddest
If something is the most scary, it is scariest
If something is the most costly, it is costliest
If something is the most nasty, it is
2024-08-01 00:22:20 root INFO     [order_1_approx] starting weight calculation for If something is the most neat, it is neatest
If something is the most dumb, it is dumbest
If something is the most scary, it is scariest
If something is the most weird, it is weirdest
If something is the most nasty, it is nastiest
If something is the most healthy, it is healthiest
If something is the most sad, it is saddest
If something is the most costly, it is
2024-08-01 00:22:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 00:25:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0800,  0.2585, -0.1410,  ...,  0.1494, -0.1190, -0.1173],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.4121, -5.5000, -0.3311,  ..., -3.3242,  0.4189,  1.7305],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0150, -0.0432,  0.0165,  ..., -0.0225, -0.0146,  0.0097],
        [-0.0247, -0.0173, -0.0213,  ..., -0.0417,  0.0179,  0.0277],
        [ 0.0171,  0.0182,  0.0119,  ...,  0.0349, -0.0341, -0.0122],
        ...,
        [ 0.0063,  0.0029, -0.0018,  ...,  0.0068,  0.0147,  0.0213],
        [-0.0242, -0.0271, -0.0242,  ..., -0.0034,  0.0286, -0.0122],
        [-0.0088, -0.0014, -0.0207,  ..., -0.0060,  0.0154,  0.0123]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6792, -5.2070, -0.6758,  ..., -3.2656,  0.2014,  1.8467]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:25:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most neat, it is neatest
If something is the most dumb, it is dumbest
If something is the most scary, it is scariest
If something is the most weird, it is weirdest
If something is the most nasty, it is nastiest
If something is the most healthy, it is healthiest
If something is the most sad, it is saddest
If something is the most costly, it is
2024-08-01 00:25:22 root INFO     [order_1_approx] starting weight calculation for If something is the most weird, it is weirdest
If something is the most healthy, it is healthiest
If something is the most neat, it is neatest
If something is the most dumb, it is dumbest
If something is the most costly, it is costliest
If something is the most sad, it is saddest
If something is the most nasty, it is nastiest
If something is the most scary, it is
2024-08-01 00:25:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 00:28:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0151,  0.2229, -0.0257,  ...,  0.1937, -0.1099, -0.1138],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.6699, -4.1406, -1.1162,  ..., -2.5273, -1.0020, -1.9365],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0156, -0.0056,  0.0178,  ...,  0.0031, -0.0100,  0.0035],
        [ 0.0038, -0.0157,  0.0005,  ..., -0.0006,  0.0062,  0.0206],
        [ 0.0277,  0.0248,  0.0142,  ...,  0.0302, -0.0110,  0.0273],
        ...,
        [ 0.0103, -0.0196, -0.0275,  ..., -0.0083,  0.0109,  0.0262],
        [-0.0044,  0.0008,  0.0169,  ..., -0.0083, -0.0072, -0.0129],
        [-0.0042, -0.0077, -0.0152,  ..., -0.0026, -0.0049, -0.0315]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.8291, -4.0781, -1.5996,  ..., -2.1953, -1.2246, -2.0742]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:28:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most weird, it is weirdest
If something is the most healthy, it is healthiest
If something is the most neat, it is neatest
If something is the most dumb, it is dumbest
If something is the most costly, it is costliest
If something is the most sad, it is saddest
If something is the most nasty, it is nastiest
If something is the most scary, it is
2024-08-01 00:28:26 root INFO     total operator prediction time: 1469.3533833026886 seconds
2024-08-01 00:28:26 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+er_irreg
2024-08-01 00:28:26 root INFO     building operator verb+er_irreg
2024-08-01 00:28:26 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you offend something, you are a offender
If you suffer something, you are a sufferer
If you mourn something, you are a mourner
If you teach something, you are a teacher
If you eat something, you are a eater
If you write something, you are a writer
If you defend something, you are a
2024-08-01 00:28:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 00:31:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1466, -0.0955, -0.0564,  ..., -0.0354,  0.1620, -0.1061],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9375, -5.3438,  2.6562,  ..., -3.8359, -3.5566, -3.1621],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0233, -0.0071,  0.0344,  ..., -0.0318, -0.0017, -0.0338],
        [-0.0164, -0.0069, -0.0132,  ...,  0.0138,  0.0366,  0.0121],
        [ 0.0260, -0.0206, -0.0019,  ..., -0.0321,  0.0012, -0.0211],
        ...,
        [ 0.0254,  0.0077, -0.0064,  ...,  0.0104,  0.0305,  0.0278],
        [ 0.0032, -0.0034, -0.0218,  ...,  0.0025,  0.0149,  0.0160],
        [ 0.0073,  0.0101, -0.0042,  ...,  0.0026, -0.0167, -0.0071]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6523, -5.0859,  2.7363,  ..., -3.7285, -3.3516, -3.2871]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:31:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you deliver something, you are a deliverer
If you offend something, you are a offender
If you suffer something, you are a sufferer
If you mourn something, you are a mourner
If you teach something, you are a teacher
If you eat something, you are a eater
If you write something, you are a writer
If you defend something, you are a
2024-08-01 00:31:29 root INFO     [order_1_approx] starting weight calculation for If you eat something, you are a eater
If you write something, you are a writer
If you offend something, you are a offender
If you defend something, you are a defender
If you mourn something, you are a mourner
If you deliver something, you are a deliverer
If you suffer something, you are a sufferer
If you teach something, you are a
2024-08-01 00:31:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 00:34:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0376,  0.3599,  0.0108,  ...,  0.0831, -0.0802, -0.0656],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0430, -3.0742,  5.0000,  ...,  2.3320, -5.0938, -5.1211],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0004, -0.0205, -0.0037,  ..., -0.0021,  0.0195,  0.0028],
        [-0.0011,  0.0298, -0.0085,  ...,  0.0083, -0.0111, -0.0131],
        [-0.0024,  0.0018, -0.0189,  ...,  0.0010,  0.0215, -0.0006],
        ...,
        [ 0.0229,  0.0155,  0.0118,  ..., -0.0174,  0.0065, -0.0165],
        [ 0.0082,  0.0085, -0.0062,  ...,  0.0063, -0.0077,  0.0186],
        [ 0.0185,  0.0110,  0.0003,  ...,  0.0152, -0.0155,  0.0029]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7754, -2.8594,  5.3477,  ...,  2.5488, -5.1875, -4.9922]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:34:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you eat something, you are a eater
If you write something, you are a writer
If you offend something, you are a offender
If you defend something, you are a defender
If you mourn something, you are a mourner
If you deliver something, you are a deliverer
If you suffer something, you are a sufferer
If you teach something, you are a
2024-08-01 00:34:32 root INFO     [order_1_approx] starting weight calculation for If you teach something, you are a teacher
If you offend something, you are a offender
If you defend something, you are a defender
If you deliver something, you are a deliverer
If you suffer something, you are a sufferer
If you write something, you are a writer
If you mourn something, you are a mourner
If you eat something, you are a
2024-08-01 00:34:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 00:37:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0836,  0.1080,  0.0135,  ...,  0.1235, -0.1171, -0.0123],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7090, -0.3975, -0.0891,  ...,  0.4189, -6.3047, -3.2676],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0003, -0.0217, -0.0202,  ...,  0.0008,  0.0360,  0.0058],
        [-0.0203,  0.0027,  0.0124,  ...,  0.0136,  0.0063, -0.0024],
        [ 0.0275, -0.0153,  0.0076,  ...,  0.0141,  0.0146,  0.0214],
        ...,
        [ 0.0279, -0.0065, -0.0006,  ..., -0.0126,  0.0142, -0.0155],
        [ 0.0084, -0.0085, -0.0052,  ..., -0.0051, -0.0322,  0.0070],
        [ 0.0017,  0.0073,  0.0164,  ...,  0.0163, -0.0105,  0.0298]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7480,  0.0361, -0.3230,  ...,  0.2671, -6.2227, -3.1055]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:37:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you teach something, you are a teacher
If you offend something, you are a offender
If you defend something, you are a defender
If you deliver something, you are a deliverer
If you suffer something, you are a sufferer
If you write something, you are a writer
If you mourn something, you are a mourner
If you eat something, you are a
2024-08-01 00:37:36 root INFO     [order_1_approx] starting weight calculation for If you eat something, you are a eater
If you mourn something, you are a mourner
If you teach something, you are a teacher
If you write something, you are a writer
If you suffer something, you are a sufferer
If you defend something, you are a defender
If you deliver something, you are a deliverer
If you offend something, you are a
2024-08-01 00:37:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 00:40:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1232,  0.2085,  0.1239,  ..., -0.0785, -0.2200, -0.0959],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5508, -2.4375,  1.2432,  ..., -1.4111, -3.4141,  0.6025],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0498, -0.0224,  0.0656,  ...,  0.0087,  0.0164,  0.0316],
        [-0.0358,  0.0242,  0.0219,  ...,  0.0133, -0.0370,  0.0320],
        [-0.0067, -0.0210,  0.0409,  ..., -0.0420,  0.0428,  0.0341],
        ...,
        [ 0.0173, -0.0102, -0.0449,  ...,  0.0129,  0.0682, -0.0152],
        [-0.0147,  0.0076,  0.0590,  ..., -0.0085, -0.0460,  0.0514],
        [-0.0037,  0.0002, -0.0090,  ..., -0.0100,  0.0092, -0.0225]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4805, -2.4277,  1.3037,  ..., -1.2861, -3.9062,  0.9082]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:40:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you eat something, you are a eater
If you mourn something, you are a mourner
If you teach something, you are a teacher
If you write something, you are a writer
If you suffer something, you are a sufferer
If you defend something, you are a defender
If you deliver something, you are a deliverer
If you offend something, you are a
2024-08-01 00:40:39 root INFO     [order_1_approx] starting weight calculation for If you write something, you are a writer
If you teach something, you are a teacher
If you offend something, you are a offender
If you eat something, you are a eater
If you defend something, you are a defender
If you mourn something, you are a mourner
If you suffer something, you are a sufferer
If you deliver something, you are a
2024-08-01 00:40:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 00:43:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1247,  0.2549,  0.1129,  ..., -0.0260, -0.0649, -0.1010],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.3086, -4.1055,  1.2520,  ..., -0.0195, -4.5312, -1.5625],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0291, -0.0317,  0.0245,  ...,  0.0130, -0.0177, -0.0045],
        [-0.0126,  0.0505,  0.0003,  ..., -0.0061,  0.0151,  0.0058],
        [ 0.0440, -0.0225,  0.0254,  ...,  0.0210, -0.0383, -0.0246],
        ...,
        [ 0.0408,  0.0025,  0.0351,  ...,  0.0465,  0.0172,  0.0285],
        [ 0.0082,  0.0149,  0.0090,  ..., -0.0414, -0.0075,  0.0189],
        [-0.0009, -0.0030, -0.0197,  ..., -0.0207,  0.0196,  0.0037]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.8594, -4.1445,  0.7573,  ..., -0.1934, -4.5195, -2.0078]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:43:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you write something, you are a writer
If you teach something, you are a teacher
If you offend something, you are a offender
If you eat something, you are a eater
If you defend something, you are a defender
If you mourn something, you are a mourner
If you suffer something, you are a sufferer
If you deliver something, you are a
2024-08-01 00:43:41 root INFO     [order_1_approx] starting weight calculation for If you teach something, you are a teacher
If you offend something, you are a offender
If you eat something, you are a eater
If you deliver something, you are a deliverer
If you defend something, you are a defender
If you suffer something, you are a sufferer
If you write something, you are a writer
If you mourn something, you are a
2024-08-01 00:43:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 00:46:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0315,  0.3491,  0.0841,  ...,  0.0476, -0.2705, -0.1409],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2266, -2.5684, -0.0098,  ..., -1.7666, -1.7676,  0.6777],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0264, -0.0303,  0.0548,  ...,  0.0026,  0.0305, -0.0060],
        [ 0.0006,  0.0137, -0.0185,  ...,  0.0118,  0.0192,  0.0107],
        [-0.0067, -0.0122,  0.0302,  ...,  0.0128,  0.0031, -0.0069],
        ...,
        [ 0.0242, -0.0033,  0.0397,  ..., -0.0162, -0.0021,  0.0063],
        [ 0.0238, -0.0302, -0.0210,  ..., -0.0205, -0.0156, -0.0116],
        [-0.0060,  0.0539,  0.0139,  ..., -0.0068, -0.0123, -0.0186]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9316, -3.2578, -0.0356,  ..., -1.2666, -2.0527,  0.4658]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:46:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you teach something, you are a teacher
If you offend something, you are a offender
If you eat something, you are a eater
If you deliver something, you are a deliverer
If you defend something, you are a defender
If you suffer something, you are a sufferer
If you write something, you are a writer
If you mourn something, you are a
2024-08-01 00:46:42 root INFO     [order_1_approx] starting weight calculation for If you suffer something, you are a sufferer
If you eat something, you are a eater
If you mourn something, you are a mourner
If you teach something, you are a teacher
If you offend something, you are a offender
If you deliver something, you are a deliverer
If you defend something, you are a defender
If you write something, you are a
2024-08-01 00:46:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 00:49:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0471,  0.0909, -0.0226,  ..., -0.0498, -0.1268, -0.1002],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3906, -4.6328,  1.0381,  ...,  0.5342, -5.0078, -0.6753],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-5.3291e-03, -1.7578e-02, -9.8343e-03,  ...,  1.7181e-02,
          1.4267e-02, -2.4300e-03],
        [-8.3923e-05,  7.6294e-03,  1.6159e-02,  ...,  2.9755e-03,
          1.4267e-03,  2.0203e-02],
        [ 1.5244e-02,  1.1482e-03, -1.1147e-02,  ..., -1.4458e-02,
          7.2327e-03, -9.0179e-03],
        ...,
        [ 4.0985e-02,  1.9501e-02,  1.1902e-03,  ...,  1.4137e-02,
          5.0926e-03,  1.0551e-02],
        [-6.5613e-03,  2.8915e-03, -1.6068e-02,  ..., -9.4376e-03,
         -1.0483e-02,  1.7014e-02],
        [ 1.0124e-02,  1.9409e-02, -2.4204e-03,  ..., -1.4328e-02,
         -4.8409e-03, -2.1782e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4102, -4.5430,  1.3359,  ...,  0.6729, -4.7930, -0.7886]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:49:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you suffer something, you are a sufferer
If you eat something, you are a eater
If you mourn something, you are a mourner
If you teach something, you are a teacher
If you offend something, you are a offender
If you deliver something, you are a deliverer
If you defend something, you are a defender
If you write something, you are a
2024-08-01 00:49:45 root INFO     [order_1_approx] starting weight calculation for If you defend something, you are a defender
If you eat something, you are a eater
If you mourn something, you are a mourner
If you deliver something, you are a deliverer
If you write something, you are a writer
If you teach something, you are a teacher
If you offend something, you are a offender
If you suffer something, you are a
2024-08-01 00:49:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 00:52:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0972,  0.1858, -0.0066,  ..., -0.1331, -0.0928, -0.0839],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.8711, -3.2949,  0.6904,  ..., -2.8242, -0.8506,  0.6836],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0204, -0.0526,  0.0197,  ...,  0.0211,  0.0227,  0.0212],
        [-0.0010,  0.0294,  0.0199,  ...,  0.0177,  0.0017,  0.0025],
        [ 0.0046, -0.0037, -0.0135,  ...,  0.0044,  0.0038, -0.0169],
        ...,
        [ 0.0401, -0.0007,  0.0045,  ..., -0.0236, -0.0032,  0.0070],
        [ 0.0215, -0.0210, -0.0374,  ..., -0.0435,  0.0124, -0.0117],
        [-0.0079,  0.0320,  0.0422,  ..., -0.0033, -0.0100,  0.0109]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.4258, -3.4062,  0.7119,  ..., -2.4609, -0.9316,  0.7783]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:52:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you defend something, you are a defender
If you eat something, you are a eater
If you mourn something, you are a mourner
If you deliver something, you are a deliverer
If you write something, you are a writer
If you teach something, you are a teacher
If you offend something, you are a offender
If you suffer something, you are a
2024-08-01 00:52:46 root INFO     total operator prediction time: 1459.706464290619 seconds
2024-08-01 00:52:46 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on over+adj_reg
2024-08-01 00:52:46 root INFO     building operator over+adj_reg
2024-08-01 00:52:46 root INFO     [order_1_approx] starting weight calculation for If something is too heard, it is overheard
If something is too populated, it is overpopulated
If something is too sold, it is oversold
If something is too booked, it is overbooked
If something is too used, it is overused
If something is too subscribed, it is oversubscribed
If something is too charged, it is overcharged
If something is too protective, it is
2024-08-01 00:52:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 00:55:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1736, -0.3027, -0.0718,  ..., -0.0621, -0.0440, -0.0919],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4082, -4.7773,  2.4570,  ...,  1.2471, -1.8262, -2.0469],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0122, -0.0079,  0.0135,  ..., -0.0250, -0.0177,  0.0356],
        [-0.0184,  0.0172,  0.0265,  ..., -0.0176,  0.0157,  0.0253],
        [-0.0322,  0.0175,  0.0504,  ...,  0.0335, -0.0300, -0.0028],
        ...,
        [ 0.0076,  0.0075,  0.0345,  ...,  0.0076,  0.0003, -0.0079],
        [ 0.0299,  0.0106,  0.0145,  ...,  0.0047, -0.0060, -0.0445],
        [ 0.0132,  0.0260, -0.0387,  ...,  0.0252, -0.0073,  0.0202]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9883, -4.7812,  2.3398,  ...,  1.0303, -1.7598, -2.0508]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:55:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too heard, it is overheard
If something is too populated, it is overpopulated
If something is too sold, it is oversold
If something is too booked, it is overbooked
If something is too used, it is overused
If something is too subscribed, it is oversubscribed
If something is too charged, it is overcharged
If something is too protective, it is
2024-08-01 00:55:49 root INFO     [order_1_approx] starting weight calculation for If something is too sold, it is oversold
If something is too subscribed, it is oversubscribed
If something is too booked, it is overbooked
If something is too populated, it is overpopulated
If something is too used, it is overused
If something is too heard, it is overheard
If something is too protective, it is overprotective
If something is too charged, it is
2024-08-01 00:55:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 00:58:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0272, -0.2524,  0.0253,  ...,  0.0656, -0.1252, -0.0534],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8467, -2.9883,  0.6030,  ..., -0.0344,  0.1516, -1.3193],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.9103e-02,  1.0307e-02, -1.5266e-02,  ..., -3.2959e-02,
         -4.1534e-02,  7.2632e-02],
        [-7.6904e-02,  2.7893e-02,  1.3138e-02,  ..., -5.0926e-03,
          3.2043e-03,  1.7151e-02],
        [ 5.2185e-02,  1.7395e-02,  1.7303e-02,  ..., -1.1787e-03,
          6.8207e-03, -1.0376e-02],
        ...,
        [ 1.5900e-02, -2.4323e-02, -2.6352e-02,  ...,  3.1464e-02,
          2.3773e-02, -2.4750e-02],
        [ 9.1553e-05,  1.4664e-02, -2.8320e-02,  ..., -1.0048e-02,
          2.5284e-02,  9.8724e-03],
        [-1.4938e-02,  8.0261e-03, -3.5522e-02,  ..., -7.6675e-03,
          5.4550e-03,  2.7420e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0254, -2.8438,  0.3728,  ...,  0.1458,  0.2507, -1.5371]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:58:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too sold, it is oversold
If something is too subscribed, it is oversubscribed
If something is too booked, it is overbooked
If something is too populated, it is overpopulated
If something is too used, it is overused
If something is too heard, it is overheard
If something is too protective, it is overprotective
If something is too charged, it is
2024-08-01 00:58:50 root INFO     [order_1_approx] starting weight calculation for If something is too charged, it is overcharged
If something is too used, it is overused
If something is too booked, it is overbooked
If something is too protective, it is overprotective
If something is too populated, it is overpopulated
If something is too heard, it is overheard
If something is too subscribed, it is oversubscribed
If something is too sold, it is
2024-08-01 00:58:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 01:01:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0459, -0.1479,  0.0042,  ..., -0.0326,  0.0079,  0.0974],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1094, -2.6738,  0.0093,  ..., -1.6279, -2.7324, -0.2793],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0619,  0.0016,  0.0189,  ...,  0.0139, -0.0554,  0.0097],
        [-0.0211,  0.0129, -0.0042,  ..., -0.0126,  0.0033, -0.0178],
        [ 0.0131, -0.0065,  0.0172,  ...,  0.0042, -0.0058,  0.0153],
        ...,
        [-0.0040, -0.0193,  0.0103,  ...,  0.0120,  0.0538,  0.0562],
        [-0.0126, -0.0024, -0.0003,  ...,  0.0037,  0.0175, -0.0093],
        [ 0.0006,  0.0133, -0.0071,  ...,  0.0094,  0.0234,  0.0194]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2256, -2.6895,  0.1707,  ..., -1.3027, -2.3281, -0.8140]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:01:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too charged, it is overcharged
If something is too used, it is overused
If something is too booked, it is overbooked
If something is too protective, it is overprotective
If something is too populated, it is overpopulated
If something is too heard, it is overheard
If something is too subscribed, it is oversubscribed
If something is too sold, it is
2024-08-01 01:01:52 root INFO     [order_1_approx] starting weight calculation for If something is too protective, it is overprotective
If something is too charged, it is overcharged
If something is too heard, it is overheard
If something is too booked, it is overbooked
If something is too sold, it is oversold
If something is too subscribed, it is oversubscribed
If something is too populated, it is overpopulated
If something is too used, it is
2024-08-01 01:01:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 01:04:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0450, -0.1664,  0.0972,  ...,  0.0038, -0.3474, -0.0564],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1699, -3.3652,  1.2793,  ..., -0.4487, -1.5898, -1.6973],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0428, -0.0116, -0.0381,  ..., -0.0294, -0.0221,  0.0363],
        [-0.0366,  0.0066, -0.0186,  ..., -0.0307, -0.0107, -0.0002],
        [ 0.0495,  0.0025,  0.0641,  ...,  0.0166,  0.0028, -0.0195],
        ...,
        [ 0.0082, -0.0059,  0.0073,  ...,  0.0049,  0.0069,  0.0023],
        [-0.0079, -0.0138,  0.0079,  ...,  0.0101,  0.0198, -0.0096],
        [ 0.0318, -0.0374,  0.0018,  ...,  0.0110,  0.0081,  0.0269]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5205, -2.7480,  1.1846,  ..., -0.7178, -1.0879, -1.9785]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:04:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too protective, it is overprotective
If something is too charged, it is overcharged
If something is too heard, it is overheard
If something is too booked, it is overbooked
If something is too sold, it is oversold
If something is too subscribed, it is oversubscribed
If something is too populated, it is overpopulated
If something is too used, it is
2024-08-01 01:04:56 root INFO     [order_1_approx] starting weight calculation for If something is too charged, it is overcharged
If something is too protective, it is overprotective
If something is too sold, it is oversold
If something is too subscribed, it is oversubscribed
If something is too populated, it is overpopulated
If something is too used, it is overused
If something is too heard, it is overheard
If something is too booked, it is
2024-08-01 01:04:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 01:07:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1344, -0.0709, -0.0594,  ...,  0.0053, -0.1921, -0.1240],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2505, -3.4453,  0.5415,  ...,  1.3232,  0.4180, -3.2148],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0194, -0.0086,  0.0198,  ..., -0.0043,  0.0074,  0.0098],
        [-0.0044,  0.0135, -0.0020,  ..., -0.0170, -0.0263,  0.0250],
        [ 0.0153, -0.0043,  0.0218,  ...,  0.0091,  0.0208, -0.0076],
        ...,
        [ 0.0148, -0.0142,  0.0041,  ...,  0.0070,  0.0235, -0.0111],
        [ 0.0011,  0.0045, -0.0013,  ...,  0.0235,  0.0051, -0.0065],
        [ 0.0124, -0.0068, -0.0011,  ...,  0.0073,  0.0046,  0.0049]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1531, -3.3027,  0.3457,  ...,  1.7217,  0.2983, -3.2422]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:07:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too charged, it is overcharged
If something is too protective, it is overprotective
If something is too sold, it is oversold
If something is too subscribed, it is oversubscribed
If something is too populated, it is overpopulated
If something is too used, it is overused
If something is too heard, it is overheard
If something is too booked, it is
2024-08-01 01:07:54 root INFO     [order_1_approx] starting weight calculation for If something is too sold, it is oversold
If something is too subscribed, it is oversubscribed
If something is too populated, it is overpopulated
If something is too charged, it is overcharged
If something is too used, it is overused
If something is too booked, it is overbooked
If something is too protective, it is overprotective
If something is too heard, it is
2024-08-01 01:07:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 01:10:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0297,  0.0013,  0.0762,  ...,  0.0640, -0.2347, -0.0217],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8184, -2.1680,  0.9219,  ...,  0.4180, -1.7471, -3.0508],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0394,  0.0235,  0.0837,  ..., -0.0009, -0.0215, -0.0014],
        [-0.0528,  0.0676, -0.0370,  ..., -0.0372,  0.0024, -0.0182],
        [ 0.0524,  0.0193,  0.0914,  ...,  0.0506, -0.0312,  0.0329],
        ...,
        [ 0.0450, -0.0185,  0.0057,  ...,  0.0235, -0.0140,  0.0073],
        [-0.0197, -0.0281, -0.0702,  ..., -0.0208,  0.0101,  0.0271],
        [-0.0077,  0.0342,  0.0491,  ...,  0.0320,  0.0273,  0.0312]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4590, -2.0605,  0.6768,  ...,  0.7520, -0.6836, -2.6680]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:11:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too sold, it is oversold
If something is too subscribed, it is oversubscribed
If something is too populated, it is overpopulated
If something is too charged, it is overcharged
If something is too used, it is overused
If something is too booked, it is overbooked
If something is too protective, it is overprotective
If something is too heard, it is
2024-08-01 01:11:00 root INFO     [order_1_approx] starting weight calculation for If something is too charged, it is overcharged
If something is too sold, it is oversold
If something is too protective, it is overprotective
If something is too used, it is overused
If something is too heard, it is overheard
If something is too subscribed, it is oversubscribed
If something is too booked, it is overbooked
If something is too populated, it is
2024-08-01 01:11:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 01:14:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0864, -0.1553, -0.0202,  ...,  0.1621, -0.1880, -0.0022],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8594, -2.6836,  1.0566,  ..., -0.1116, -0.5405, -1.5977],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0351, -0.0030,  0.0224,  ..., -0.0027, -0.0219,  0.0256],
        [-0.0143,  0.0260,  0.0303,  ...,  0.0083, -0.0501,  0.0432],
        [ 0.0585,  0.0111,  0.0095,  ...,  0.0188,  0.0520,  0.0246],
        ...,
        [-0.0312,  0.0117,  0.0614,  ...,  0.0019,  0.0382,  0.0022],
        [-0.0118,  0.0115,  0.0539,  ...,  0.0010, -0.0202,  0.0038],
        [-0.0036,  0.0444,  0.0345,  ...,  0.0301,  0.0136, -0.0246]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8281, -2.1543,  0.4380,  ...,  0.5703, -0.1555, -1.7773]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:14:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too charged, it is overcharged
If something is too sold, it is oversold
If something is too protective, it is overprotective
If something is too used, it is overused
If something is too heard, it is overheard
If something is too subscribed, it is oversubscribed
If something is too booked, it is overbooked
If something is too populated, it is
2024-08-01 01:14:01 root INFO     [order_1_approx] starting weight calculation for If something is too populated, it is overpopulated
If something is too sold, it is oversold
If something is too used, it is overused
If something is too heard, it is overheard
If something is too charged, it is overcharged
If something is too booked, it is overbooked
If something is too protective, it is overprotective
If something is too subscribed, it is
2024-08-01 01:14:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 01:17:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1473, -0.1101, -0.0147,  ..., -0.0168, -0.1729, -0.0913],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8042, -3.1250,  0.9663,  ...,  0.4207, -1.6309, -1.6250],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.2725e-02,  5.7220e-06,  5.3223e-02,  ...,  5.9986e-04,
         -1.2331e-03,  1.7899e-02],
        [ 1.0010e-02,  1.8646e-02,  1.6800e-02,  ...,  1.9867e-02,
         -1.7181e-02,  2.2812e-02],
        [ 7.1777e-02, -1.2711e-02,  1.2032e-02,  ...,  1.3130e-02,
         -2.6886e-02, -9.4604e-03],
        ...,
        [-1.4740e-02, -3.4180e-03, -1.5289e-02,  ...,  2.2278e-02,
          5.3955e-02, -1.8250e-02],
        [-3.0518e-02, -1.8311e-02, -2.1484e-02,  ...,  1.7532e-02,
         -2.2156e-02, -7.8583e-03],
        [ 1.4297e-02,  2.2125e-03,  1.6556e-02,  ..., -3.5675e-02,
          3.6316e-03,  1.9394e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9912, -3.3184,  1.1787,  ...,  0.9531, -1.9795, -1.5303]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:17:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too populated, it is overpopulated
If something is too sold, it is oversold
If something is too used, it is overused
If something is too heard, it is overheard
If something is too charged, it is overcharged
If something is too booked, it is overbooked
If something is too protective, it is overprotective
If something is too subscribed, it is
2024-08-01 01:17:02 root INFO     total operator prediction time: 1456.2893161773682 seconds
2024-08-01 01:17:02 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj+ly_reg
2024-08-01 01:17:02 root INFO     building operator adj+ly_reg
2024-08-01 01:17:02 root INFO     [order_1_approx] starting weight calculation for The adjective form of important is importantly
The adjective form of increasing is increasingly
The adjective form of serious is seriously
The adjective form of subsequent is subsequently
The adjective form of digital is digitally
The adjective form of strong is strongly
The adjective form of financial is financially
The adjective form of nice is
2024-08-01 01:17:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 01:20:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0704, -0.0924, -0.0224,  ..., -0.0517, -0.0809, -0.0494],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4277, -1.9922, -2.3438,  ..., -0.1631, -7.0547, -1.2705],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0032,  0.0026,  0.0144,  ...,  0.0082,  0.0197, -0.0462],
        [-0.0284, -0.0052, -0.0510,  ..., -0.0117, -0.0235, -0.0365],
        [-0.0149, -0.0126,  0.0374,  ..., -0.0323, -0.0189,  0.0254],
        ...,
        [ 0.0359, -0.0179,  0.0046,  ...,  0.0253,  0.0432,  0.0134],
        [ 0.0419,  0.0346,  0.0116,  ...,  0.0353,  0.0472,  0.0781],
        [-0.0118,  0.0069, -0.0060,  ...,  0.0078, -0.0497, -0.0024]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2656, -1.3740, -2.6445,  ...,  0.3726, -6.7109, -0.6279]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:20:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of important is importantly
The adjective form of increasing is increasingly
The adjective form of serious is seriously
The adjective form of subsequent is subsequently
The adjective form of digital is digitally
The adjective form of strong is strongly
The adjective form of financial is financially
The adjective form of nice is
2024-08-01 01:20:06 root INFO     [order_1_approx] starting weight calculation for The adjective form of strong is strongly
The adjective form of increasing is increasingly
The adjective form of subsequent is subsequently
The adjective form of nice is nicely
The adjective form of digital is digitally
The adjective form of important is importantly
The adjective form of financial is financially
The adjective form of serious is
2024-08-01 01:20:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 01:23:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0278, -0.0567, -0.2803,  ..., -0.1661, -0.3186,  0.0497],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9053, -2.0312, -0.2568,  ..., -2.0039, -0.6323, -4.0430],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0615,  0.0229,  0.0280,  ...,  0.0565, -0.0534,  0.0274],
        [-0.0095, -0.0029,  0.0064,  ..., -0.0309,  0.0395, -0.0235],
        [-0.0173,  0.0291,  0.0372,  ..., -0.0010, -0.0367,  0.0216],
        ...,
        [ 0.0240,  0.0086, -0.0368,  ..., -0.0152,  0.0305,  0.0025],
        [-0.0176, -0.0072, -0.0787,  ..., -0.0208,  0.0723, -0.0806],
        [-0.0039,  0.0020, -0.0481,  ...,  0.0743, -0.0296,  0.0545]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9160, -1.4268,  0.1536,  ..., -1.5254, -0.5264, -3.6523]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:23:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of strong is strongly
The adjective form of increasing is increasingly
The adjective form of subsequent is subsequently
The adjective form of nice is nicely
The adjective form of digital is digitally
The adjective form of important is importantly
The adjective form of financial is financially
The adjective form of serious is
2024-08-01 01:23:10 root INFO     [order_1_approx] starting weight calculation for The adjective form of subsequent is subsequently
The adjective form of important is importantly
The adjective form of nice is nicely
The adjective form of financial is financially
The adjective form of digital is digitally
The adjective form of serious is seriously
The adjective form of strong is strongly
The adjective form of increasing is
2024-08-01 01:23:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 01:26:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1317, -0.0168, -0.0686,  ..., -0.1027, -0.1176, -0.1088],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0977, -2.4863,  0.0698,  ..., -0.1309, -2.0645, -1.3691],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0232, -0.0067, -0.0145,  ..., -0.0042, -0.0116, -0.0027],
        [ 0.0063, -0.0156, -0.0228,  ...,  0.0046, -0.0201, -0.0508],
        [ 0.0353,  0.0086, -0.0163,  ..., -0.0388, -0.0547,  0.0037],
        ...,
        [ 0.0404,  0.0060,  0.0158,  ...,  0.0776,  0.0129, -0.0179],
        [-0.0107,  0.0707,  0.0409,  ...,  0.0242,  0.0652, -0.0105],
        [ 0.0042, -0.0070,  0.0002,  ...,  0.0334, -0.0340, -0.0316]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4619, -2.3867,  0.0618,  ..., -0.0470, -1.4473, -0.8467]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:26:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of subsequent is subsequently
The adjective form of important is importantly
The adjective form of nice is nicely
The adjective form of financial is financially
The adjective form of digital is digitally
The adjective form of serious is seriously
The adjective form of strong is strongly
The adjective form of increasing is
2024-08-01 01:26:16 root INFO     [order_1_approx] starting weight calculation for The adjective form of increasing is increasingly
The adjective form of subsequent is subsequently
The adjective form of financial is financially
The adjective form of digital is digitally
The adjective form of nice is nicely
The adjective form of strong is strongly
The adjective form of serious is seriously
The adjective form of important is
2024-08-01 01:26:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 01:29:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0950,  0.0054, -0.0723,  ..., -0.0079, -0.2837, -0.0168],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.8633, -0.1729, -0.8081,  ..., -3.4902, -1.0859, -2.5098],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0242, -0.0588,  0.0327,  ..., -0.0464, -0.0199, -0.0003],
        [-0.0403, -0.0176,  0.0037,  ..., -0.0002,  0.0047, -0.0399],
        [ 0.0032,  0.0164, -0.0002,  ..., -0.0309, -0.0102, -0.0034],
        ...,
        [ 0.0141,  0.0054, -0.0138,  ..., -0.0135,  0.0127,  0.0415],
        [ 0.0206, -0.0247, -0.0294,  ..., -0.0308, -0.0033,  0.0228],
        [ 0.0100, -0.0331,  0.0074,  ...,  0.0038, -0.0257,  0.0365]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.8633,  0.7607, -0.5537,  ..., -3.4043, -1.0654, -2.0000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:29:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of increasing is increasingly
The adjective form of subsequent is subsequently
The adjective form of financial is financially
The adjective form of digital is digitally
The adjective form of nice is nicely
The adjective form of strong is strongly
The adjective form of serious is seriously
The adjective form of important is
2024-08-01 01:29:22 root INFO     [order_1_approx] starting weight calculation for The adjective form of nice is nicely
The adjective form of increasing is increasingly
The adjective form of financial is financially
The adjective form of serious is seriously
The adjective form of strong is strongly
The adjective form of important is importantly
The adjective form of subsequent is subsequently
The adjective form of digital is
2024-08-01 01:29:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 01:32:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2330, -0.1082, -0.0292,  ...,  0.0812, -0.1604,  0.0092],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2832, -0.7490,  0.2288,  ..., -2.0234, -2.5000, -0.6699],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0172, -0.0206, -0.0104,  ..., -0.0137, -0.0212, -0.0074],
        [ 0.0149,  0.0905,  0.0926,  ..., -0.0030, -0.0439,  0.0092],
        [ 0.0610, -0.0411, -0.0162,  ..., -0.0292,  0.0146,  0.0322],
        ...,
        [-0.0052,  0.0211, -0.0148,  ...,  0.0663,  0.0447, -0.0556],
        [-0.0098, -0.0356, -0.0144,  ...,  0.0155,  0.0684, -0.0218],
        [ 0.0232, -0.0359, -0.0255,  ..., -0.0113,  0.0089,  0.0303]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0596, -1.0088,  0.8838,  ..., -1.5098, -1.8496,  0.0327]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:32:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of nice is nicely
The adjective form of increasing is increasingly
The adjective form of financial is financially
The adjective form of serious is seriously
The adjective form of strong is strongly
The adjective form of important is importantly
The adjective form of subsequent is subsequently
The adjective form of digital is
2024-08-01 01:32:27 root INFO     [order_1_approx] starting weight calculation for The adjective form of increasing is increasingly
The adjective form of financial is financially
The adjective form of serious is seriously
The adjective form of nice is nicely
The adjective form of digital is digitally
The adjective form of subsequent is subsequently
The adjective form of important is importantly
The adjective form of strong is
2024-08-01 01:32:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 01:35:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0160, -0.3018,  0.1005,  ..., -0.1372, -0.1387,  0.1610],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0820, -3.0742, -0.5254,  ...,  0.2188, -3.9785, -4.2812],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0220,  0.0027,  0.0066,  ..., -0.0453, -0.0486, -0.0164],
        [ 0.0087,  0.0013, -0.0513,  ...,  0.0278,  0.0026,  0.0049],
        [-0.0005,  0.0211, -0.0278,  ...,  0.0510, -0.0016, -0.0222],
        ...,
        [-0.0031, -0.0245, -0.0065,  ...,  0.0028, -0.0176,  0.0260],
        [ 0.0428, -0.0220,  0.0743,  ..., -0.0524,  0.0157, -0.0019],
        [-0.0276,  0.0080,  0.0084,  ...,  0.0569,  0.0234, -0.0048]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3242, -3.3340, -0.4348,  ...,  0.8271, -3.8359, -3.9238]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:35:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of increasing is increasingly
The adjective form of financial is financially
The adjective form of serious is seriously
The adjective form of nice is nicely
The adjective form of digital is digitally
The adjective form of subsequent is subsequently
The adjective form of important is importantly
The adjective form of strong is
2024-08-01 01:35:32 root INFO     [order_1_approx] starting weight calculation for The adjective form of financial is financially
The adjective form of serious is seriously
The adjective form of nice is nicely
The adjective form of strong is strongly
The adjective form of digital is digitally
The adjective form of important is importantly
The adjective form of increasing is increasingly
The adjective form of subsequent is
2024-08-01 01:35:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 01:38:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0237,  0.0709, -0.0278,  ..., -0.0822, -0.2913,  0.1473],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8984,  0.9668,  1.5068,  ..., -0.3464,  0.8965, -3.2539],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0077,  0.0021,  0.0246,  ...,  0.0295,  0.0389,  0.0123],
        [-0.0536, -0.0157,  0.0407,  ..., -0.0446, -0.0205,  0.0218],
        [ 0.0707, -0.0568, -0.0311,  ..., -0.0114, -0.1335,  0.1040],
        ...,
        [ 0.0273,  0.0010,  0.0484,  ...,  0.0267,  0.0287,  0.0318],
        [ 0.0566,  0.0506,  0.0375,  ...,  0.0450, -0.0193, -0.0323],
        [-0.0164,  0.0203, -0.0161,  ..., -0.0437, -0.0320,  0.0031]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7686,  0.6143,  1.2607,  ...,  0.8721,  0.8125, -3.4453]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:38:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of financial is financially
The adjective form of serious is seriously
The adjective form of nice is nicely
The adjective form of strong is strongly
The adjective form of digital is digitally
The adjective form of important is importantly
The adjective form of increasing is increasingly
The adjective form of subsequent is
2024-08-01 01:38:33 root INFO     [order_1_approx] starting weight calculation for The adjective form of digital is digitally
The adjective form of increasing is increasingly
The adjective form of serious is seriously
The adjective form of important is importantly
The adjective form of nice is nicely
The adjective form of strong is strongly
The adjective form of subsequent is subsequently
The adjective form of financial is
2024-08-01 01:38:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 01:41:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0569, -0.0917, -0.0898,  ..., -0.1349, -0.0439, -0.0010],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9766, -1.1641,  1.7969,  ..., -2.2227, -3.3320, -1.5137],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0282, -0.0367,  0.0167,  ...,  0.0164, -0.0107,  0.0068],
        [-0.0305,  0.0282,  0.0576,  ...,  0.0118, -0.0173, -0.0123],
        [ 0.0632, -0.0353, -0.0212,  ..., -0.0340, -0.0692,  0.0433],
        ...,
        [-0.0062,  0.0384, -0.0106,  ...,  0.0431,  0.0223,  0.0083],
        [-0.0259, -0.0261, -0.0232,  ..., -0.0189,  0.0476, -0.0108],
        [-0.0210,  0.0020,  0.0099,  ...,  0.0718, -0.0476, -0.0379]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9189, -1.0693,  2.2520,  ..., -2.2012, -2.9062, -2.4375]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:41:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of digital is digitally
The adjective form of increasing is increasingly
The adjective form of serious is seriously
The adjective form of important is importantly
The adjective form of nice is nicely
The adjective form of strong is strongly
The adjective form of subsequent is subsequently
The adjective form of financial is
2024-08-01 01:41:35 root INFO     total operator prediction time: 1473.064165353775 seconds
2024-08-01 01:41:35 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+tion_irreg
2024-08-01 01:41:35 root INFO     building operator verb+tion_irreg
2024-08-01 01:41:35 root INFO     [order_1_approx] starting weight calculation for To deprive results in deprivation
To customize results in customization
To colonize results in colonization
To observe results in observation
To oblige results in obligation
To aspire results in aspiration
To accuse results in accusation
To characterize results in
2024-08-01 01:41:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 01:44:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0520,  0.1467,  0.1487,  ...,  0.1595, -0.1978, -0.1359],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.8535, -1.1250,  3.7520,  ...,  3.7617, -2.4141, -2.8340],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-5.5542e-03,  5.9280e-03,  5.3009e-02,  ..., -6.6711e-02,
         -4.8096e-02, -2.6436e-03],
        [-1.4359e-02, -4.8447e-03, -4.0222e-02,  ...,  1.0034e-01,
          6.3477e-02,  7.5684e-03],
        [-1.0231e-02, -1.5945e-02,  3.8635e-02,  ..., -1.4275e-02,
         -4.5532e-02, -4.1016e-02],
        ...,
        [-2.4719e-03, -4.6387e-02,  7.2479e-05,  ...,  5.0446e-02,
          5.7434e-02,  1.6144e-02],
        [ 8.7219e-02, -2.6123e-02, -8.2275e-02,  ..., -6.7749e-03,
          1.3672e-02,  5.5573e-02],
        [ 2.5192e-02, -2.3590e-02, -5.0354e-02,  ...,  4.3030e-02,
          3.6255e-02,  4.6448e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.0859, -1.0156,  3.7500,  ...,  3.5742, -1.9131, -2.6680]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:44:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To deprive results in deprivation
To customize results in customization
To colonize results in colonization
To observe results in observation
To oblige results in obligation
To aspire results in aspiration
To accuse results in accusation
To characterize results in
2024-08-01 01:44:37 root INFO     [order_1_approx] starting weight calculation for To colonize results in colonization
To accuse results in accusation
To characterize results in characterization
To aspire results in aspiration
To oblige results in obligation
To deprive results in deprivation
To customize results in customization
To observe results in
2024-08-01 01:44:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 01:47:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0432,  0.3589,  0.0970,  ...,  0.0755, -0.1677, -0.1680],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.3828, -4.0273,  2.4746,  ...,  1.1875, -1.5293, -1.0156],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0261, -0.0026,  0.0009,  ...,  0.0102, -0.0153,  0.0335],
        [-0.0296,  0.0285,  0.0450,  ...,  0.0059,  0.0134, -0.0112],
        [ 0.0187, -0.0080,  0.0040,  ...,  0.0382, -0.0247, -0.0193],
        ...,
        [-0.0049,  0.0122,  0.0417,  ..., -0.0060,  0.0249,  0.0071],
        [ 0.0174, -0.0065, -0.0445,  ...,  0.0283,  0.0141, -0.0015],
        [ 0.0002, -0.0152,  0.0500,  ...,  0.0405, -0.0095,  0.0407]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.9277, -3.0664,  2.4824,  ...,  1.0635, -2.0469, -0.7432]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:47:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To colonize results in colonization
To accuse results in accusation
To characterize results in characterization
To aspire results in aspiration
To oblige results in obligation
To deprive results in deprivation
To customize results in customization
To observe results in
2024-08-01 01:47:39 root INFO     [order_1_approx] starting weight calculation for To customize results in customization
To aspire results in aspiration
To accuse results in accusation
To deprive results in deprivation
To characterize results in characterization
To observe results in observation
To colonize results in colonization
To oblige results in
2024-08-01 01:47:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 01:50:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1729,  0.5171, -0.0439,  ..., -0.2212, -0.2786, -0.0050],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4941, -4.5000,  1.3672,  ...,  2.9727, -2.4531, -0.9258],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0382,  0.0025,  0.0251,  ..., -0.0026, -0.0290,  0.0476],
        [-0.0266,  0.0345,  0.0088,  ...,  0.0238, -0.0404,  0.0195],
        [-0.0286,  0.0171, -0.0197,  ...,  0.0064,  0.0151, -0.0548],
        ...,
        [ 0.0311, -0.0182,  0.0007,  ..., -0.0011,  0.0532,  0.0347],
        [-0.0012, -0.0172, -0.0490,  ...,  0.0263, -0.0161,  0.0147],
        [ 0.0089,  0.0241,  0.0397,  ...,  0.0271, -0.0196,  0.0323]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7192, -4.2656,  1.4092,  ...,  2.8457, -2.2109, -0.7026]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:50:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To customize results in customization
To aspire results in aspiration
To accuse results in accusation
To deprive results in deprivation
To characterize results in characterization
To observe results in observation
To colonize results in colonization
To oblige results in
2024-08-01 01:50:42 root INFO     [order_1_approx] starting weight calculation for To colonize results in colonization
To observe results in observation
To deprive results in deprivation
To customize results in customization
To oblige results in obligation
To accuse results in accusation
To characterize results in characterization
To aspire results in
2024-08-01 01:50:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 01:53:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1067,  0.1859, -0.1394,  ..., -0.0743, -0.1567,  0.0680],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9980, -2.7969,  0.0791,  ...,  2.3770, -3.2969, -1.4297],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0153,  0.0034,  0.0174,  ..., -0.0132,  0.0165,  0.0348],
        [-0.0309,  0.0168, -0.0142,  ..., -0.0110,  0.0145, -0.0041],
        [-0.0016,  0.0057,  0.0176,  ..., -0.0062, -0.0277, -0.0509],
        ...,
        [ 0.0076,  0.0201, -0.0148,  ..., -0.0093,  0.0295,  0.0319],
        [ 0.0172, -0.0331, -0.0023,  ..., -0.0065,  0.0039, -0.0502],
        [-0.0126, -0.0147, -0.0176,  ...,  0.0213, -0.0201,  0.0186]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9229, -2.8496,  0.5977,  ...,  2.1465, -2.8047, -0.7930]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:53:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To colonize results in colonization
To observe results in observation
To deprive results in deprivation
To customize results in customization
To oblige results in obligation
To accuse results in accusation
To characterize results in characterization
To aspire results in
2024-08-01 01:53:45 root INFO     [order_1_approx] starting weight calculation for To oblige results in obligation
To colonize results in colonization
To aspire results in aspiration
To characterize results in characterization
To customize results in customization
To observe results in observation
To accuse results in accusation
To deprive results in
2024-08-01 01:53:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 01:56:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2062,  0.0338, -0.1289,  ...,  0.0152, -0.0119, -0.0261],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2949, -3.5312,  2.0977,  ...,  1.2041, -1.9746, -1.2393],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0258,  0.0386, -0.0416,  ..., -0.0779,  0.0132,  0.0494],
        [-0.0236, -0.0098,  0.0651,  ...,  0.0598, -0.0106,  0.0217],
        [-0.0160,  0.0079, -0.0012,  ...,  0.0139,  0.0057, -0.0106],
        ...,
        [ 0.0121, -0.0238,  0.0209,  ...,  0.0194,  0.0193, -0.0020],
        [-0.0169,  0.0018, -0.0542,  ...,  0.0029,  0.0044,  0.0055],
        [ 0.0263, -0.0518,  0.0370,  ...,  0.0383, -0.0244, -0.0263]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0957, -3.1465,  2.0000,  ...,  1.4023, -1.9785, -0.9038]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:56:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To oblige results in obligation
To colonize results in colonization
To aspire results in aspiration
To characterize results in characterization
To customize results in customization
To observe results in observation
To accuse results in accusation
To deprive results in
2024-08-01 01:56:48 root INFO     [order_1_approx] starting weight calculation for To observe results in observation
To deprive results in deprivation
To aspire results in aspiration
To customize results in customization
To oblige results in obligation
To characterize results in characterization
To accuse results in accusation
To colonize results in
2024-08-01 01:56:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 01:59:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0155,  0.1365, -0.0150,  ..., -0.2703,  0.0127,  0.0030],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.9316, -3.2051,  3.7656,  ...,  1.3535, -1.2510, -2.9707],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0363, -0.0423,  0.0456,  ...,  0.0156,  0.0078,  0.0186],
        [-0.0437, -0.0290,  0.0211,  ...,  0.0503, -0.0196,  0.0934],
        [ 0.0123, -0.0044,  0.0059,  ..., -0.0096, -0.0353, -0.0461],
        ...,
        [ 0.0065, -0.0308, -0.0224,  ..., -0.0359,  0.0160,  0.0493],
        [ 0.0667,  0.0196,  0.0016,  ..., -0.0046,  0.0407,  0.0333],
        [-0.0278, -0.0382,  0.0220,  ...,  0.0729, -0.0452,  0.0486]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.0664, -2.6719,  3.5508,  ...,  1.4600, -1.5469, -2.2910]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:59:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To observe results in observation
To deprive results in deprivation
To aspire results in aspiration
To customize results in customization
To oblige results in obligation
To characterize results in characterization
To accuse results in accusation
To colonize results in
2024-08-01 01:59:52 root INFO     [order_1_approx] starting weight calculation for To oblige results in obligation
To colonize results in colonization
To characterize results in characterization
To aspire results in aspiration
To observe results in observation
To customize results in customization
To deprive results in deprivation
To accuse results in
2024-08-01 01:59:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 02:02:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2517,  0.2751, -0.1142,  ...,  0.0806, -0.1572, -0.0431],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.9844, -5.3984,  0.9531,  ...,  5.2617,  0.4863, -1.0166],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0189,  0.0310, -0.0262,  ..., -0.0073, -0.0487,  0.0261],
        [-0.0360, -0.0167,  0.0073,  ...,  0.0047,  0.0394,  0.0108],
        [-0.0052, -0.0263,  0.0052,  ...,  0.0057, -0.0085,  0.0090],
        ...,
        [-0.0016,  0.0099,  0.0291,  ...,  0.0044,  0.0453, -0.0017],
        [ 0.0118, -0.0001, -0.0168,  ...,  0.0337, -0.0267,  0.0089],
        [ 0.0102, -0.0219,  0.0582,  ..., -0.0030, -0.0095,  0.0180]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.9458, -5.6680,  0.7529,  ...,  4.6250,  0.5420, -0.9336]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:02:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To oblige results in obligation
To colonize results in colonization
To characterize results in characterization
To aspire results in aspiration
To observe results in observation
To customize results in customization
To deprive results in deprivation
To accuse results in
2024-08-01 02:02:56 root INFO     [order_1_approx] starting weight calculation for To oblige results in obligation
To accuse results in accusation
To colonize results in colonization
To observe results in observation
To characterize results in characterization
To deprive results in deprivation
To aspire results in aspiration
To customize results in
2024-08-01 02:02:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 02:05:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0473,  0.0467, -0.0721,  ..., -0.0139, -0.1272,  0.0635],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3057, -3.3477,  0.9854,  ...,  2.0000, -3.1562, -1.1719],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0314, -0.0052,  0.0234,  ..., -0.0086, -0.0274,  0.0310],
        [-0.0371,  0.0061,  0.0253,  ...,  0.0840,  0.0859,  0.0080],
        [-0.0029,  0.0106,  0.0191,  ..., -0.0159, -0.0031, -0.0037],
        ...,
        [-0.0083, -0.0318,  0.0002,  ...,  0.0531,  0.0895,  0.0399],
        [ 0.0218,  0.0052, -0.0327,  ..., -0.0180,  0.0159,  0.0273],
        [-0.0085, -0.0181,  0.0007,  ...,  0.0600,  0.0227,  0.0189]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3350, -2.6484,  1.3223,  ...,  2.7930, -3.0430, -0.6099]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:05:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To oblige results in obligation
To accuse results in accusation
To colonize results in colonization
To observe results in observation
To characterize results in characterization
To deprive results in deprivation
To aspire results in aspiration
To customize results in
2024-08-01 02:05:58 root INFO     total operator prediction time: 1463.0680623054504 seconds
2024-08-01 02:05:58 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+able_reg
2024-08-01 02:05:58 root INFO     building operator verb+able_reg
2024-08-01 02:05:59 root INFO     [order_1_approx] starting weight calculation for If you can learn something, that thing is learnable
If you can publish something, that thing is publishable
If you can recommend something, that thing is recommendable
If you can perform something, that thing is performable
If you can contain something, that thing is containable
If you can consider something, that thing is considerable
If you can prefer something, that thing is preferable
If you can admire something, that thing is
2024-08-01 02:05:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 02:09:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0750,  0.2333,  0.1084,  ...,  0.1008, -0.0306, -0.0492],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.8555, -1.1191, -2.4102,  ..., -1.6348, -6.3672, -1.4434],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0048, -0.0058, -0.0234,  ..., -0.0131,  0.0042,  0.0067],
        [-0.0418,  0.0259,  0.0267,  ...,  0.0058,  0.0058, -0.0109],
        [-0.0101, -0.0016,  0.0032,  ..., -0.0150, -0.0205, -0.0291],
        ...,
        [ 0.0086,  0.0306,  0.0125,  ..., -0.0093,  0.0104, -0.0231],
        [ 0.0536, -0.0133, -0.0046,  ..., -0.0361,  0.0027,  0.0407],
        [ 0.0117,  0.0221, -0.0025,  ...,  0.0380, -0.0065, -0.0129]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.2930, -1.8682, -2.1270,  ..., -1.8291, -6.0156, -1.7910]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:09:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can learn something, that thing is learnable
If you can publish something, that thing is publishable
If you can recommend something, that thing is recommendable
If you can perform something, that thing is performable
If you can contain something, that thing is containable
If you can consider something, that thing is considerable
If you can prefer something, that thing is preferable
If you can admire something, that thing is
2024-08-01 02:09:01 root INFO     [order_1_approx] starting weight calculation for If you can consider something, that thing is considerable
If you can admire something, that thing is admirable
If you can prefer something, that thing is preferable
If you can learn something, that thing is learnable
If you can perform something, that thing is performable
If you can publish something, that thing is publishable
If you can recommend something, that thing is recommendable
If you can contain something, that thing is
2024-08-01 02:09:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 02:12:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1696, -0.0851,  0.0389,  ...,  0.1167, -0.1309, -0.2791],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0938,  0.5977,  0.5151,  ..., -5.1484, -5.0391, -3.4941],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0072, -0.0284,  0.0177,  ...,  0.0339,  0.0404,  0.0870],
        [-0.0045,  0.0471,  0.0196,  ...,  0.0249,  0.0064,  0.0305],
        [ 0.0075,  0.0283,  0.0450,  ..., -0.0280, -0.0015, -0.0537],
        ...,
        [ 0.0146,  0.0042,  0.0248,  ...,  0.0045, -0.0062, -0.0225],
        [-0.0046, -0.1097, -0.0801,  ..., -0.0501, -0.0033,  0.0044],
        [-0.0195, -0.0007, -0.0440,  ...,  0.0059, -0.0104, -0.0244]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8428,  1.5635, -0.2080,  ..., -5.0820, -4.2852, -3.3457]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:12:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can consider something, that thing is considerable
If you can admire something, that thing is admirable
If you can prefer something, that thing is preferable
If you can learn something, that thing is learnable
If you can perform something, that thing is performable
If you can publish something, that thing is publishable
If you can recommend something, that thing is recommendable
If you can contain something, that thing is
2024-08-01 02:12:04 root INFO     [order_1_approx] starting weight calculation for If you can admire something, that thing is admirable
If you can contain something, that thing is containable
If you can consider something, that thing is considerable
If you can publish something, that thing is publishable
If you can prefer something, that thing is preferable
If you can learn something, that thing is learnable
If you can recommend something, that thing is recommendable
If you can perform something, that thing is
2024-08-01 02:12:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 02:15:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0529,  0.0966,  0.0848,  ...,  0.0015, -0.2170, -0.1433],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8164, -1.9033,  2.0801,  ..., -2.8613, -7.8008, -3.0879],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0009, -0.0247,  0.0092,  ..., -0.0068, -0.0283,  0.0268],
        [ 0.0058,  0.0273, -0.0045,  ...,  0.0102,  0.0030,  0.0190],
        [ 0.0160, -0.0098, -0.0193,  ...,  0.0125, -0.0123,  0.0058],
        ...,
        [ 0.0082,  0.0032,  0.0058,  ..., -0.0287,  0.0195, -0.0390],
        [ 0.0302, -0.0215,  0.0080,  ..., -0.0575, -0.0098, -0.0169],
        [-0.0275, -0.0075,  0.0160,  ...,  0.0281, -0.0111, -0.0199]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0977, -1.7881,  2.0117,  ..., -3.0098, -7.6562, -3.2363]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:15:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can admire something, that thing is admirable
If you can contain something, that thing is containable
If you can consider something, that thing is considerable
If you can publish something, that thing is publishable
If you can prefer something, that thing is preferable
If you can learn something, that thing is learnable
If you can recommend something, that thing is recommendable
If you can perform something, that thing is
2024-08-01 02:15:02 root INFO     [order_1_approx] starting weight calculation for If you can contain something, that thing is containable
If you can learn something, that thing is learnable
If you can publish something, that thing is publishable
If you can perform something, that thing is performable
If you can recommend something, that thing is recommendable
If you can consider something, that thing is considerable
If you can admire something, that thing is admirable
If you can prefer something, that thing is
2024-08-01 02:15:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 02:18:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0645,  0.0191,  0.0506,  ..., -0.0803, -0.1001,  0.0686],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1055,  1.1836, -2.4043,  ..., -1.8877, -7.4844, -4.0586],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0138,  0.0013, -0.0430,  ...,  0.0274,  0.0134,  0.0734],
        [ 0.0075,  0.0648,  0.0085,  ...,  0.0397,  0.0278,  0.0419],
        [-0.0062, -0.0205, -0.0151,  ..., -0.0535, -0.0273, -0.0482],
        ...,
        [-0.0166, -0.0046,  0.0260,  ...,  0.0058,  0.0272, -0.0291],
        [ 0.0708,  0.0376,  0.0418,  ..., -0.0218,  0.0062,  0.0030],
        [ 0.0105,  0.0276, -0.0074,  ...,  0.0234,  0.0149, -0.0251]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0508,  0.8369, -2.2324,  ..., -1.4570, -6.4961, -3.7734]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:18:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can contain something, that thing is containable
If you can learn something, that thing is learnable
If you can publish something, that thing is publishable
If you can perform something, that thing is performable
If you can recommend something, that thing is recommendable
If you can consider something, that thing is considerable
If you can admire something, that thing is admirable
If you can prefer something, that thing is
2024-08-01 02:18:01 root INFO     [order_1_approx] starting weight calculation for If you can publish something, that thing is publishable
If you can learn something, that thing is learnable
If you can contain something, that thing is containable
If you can admire something, that thing is admirable
If you can prefer something, that thing is preferable
If you can consider something, that thing is considerable
If you can perform something, that thing is performable
If you can recommend something, that thing is
2024-08-01 02:18:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 02:21:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0943,  0.3181,  0.0028,  ...,  0.0921, -0.0608, -0.1085],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2891,  0.3564, -0.9590,  ..., -1.7617, -7.6953, -4.7500],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0123, -0.0176,  0.0166,  ...,  0.0065, -0.0104, -0.0045],
        [-0.0386, -0.0079,  0.0408,  ...,  0.0314,  0.0141,  0.0154],
        [ 0.0465,  0.0094, -0.0407,  ..., -0.0235, -0.0399, -0.0092],
        ...,
        [-0.0307,  0.0222,  0.0230,  ...,  0.0372,  0.0094,  0.0352],
        [ 0.0405,  0.0259, -0.0332,  ..., -0.0396, -0.0395, -0.0175],
        [-0.0130, -0.0084, -0.0069,  ...,  0.0135,  0.0090, -0.0122]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0186,  0.1331, -0.7402,  ..., -2.3203, -6.9375, -5.2031]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:21:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can publish something, that thing is publishable
If you can learn something, that thing is learnable
If you can contain something, that thing is containable
If you can admire something, that thing is admirable
If you can prefer something, that thing is preferable
If you can consider something, that thing is considerable
If you can perform something, that thing is performable
If you can recommend something, that thing is
2024-08-01 02:21:04 root INFO     [order_1_approx] starting weight calculation for If you can recommend something, that thing is recommendable
If you can prefer something, that thing is preferable
If you can admire something, that thing is admirable
If you can perform something, that thing is performable
If you can learn something, that thing is learnable
If you can publish something, that thing is publishable
If you can contain something, that thing is containable
If you can consider something, that thing is
2024-08-01 02:21:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 02:24:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0005,  0.0959,  0.1120,  ...,  0.0851, -0.0878, -0.0995],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1328, -1.4590,  1.1123,  ..., -3.1602, -5.9727, -1.3213],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0187,  0.0228, -0.0364,  ...,  0.0396, -0.0024,  0.0200],
        [-0.0118,  0.0304,  0.0313,  ...,  0.0335, -0.0036,  0.0282],
        [-0.0055, -0.0014,  0.0375,  ..., -0.0581, -0.0234, -0.0154],
        ...,
        [ 0.0273,  0.0165,  0.0054,  ...,  0.0012,  0.0330,  0.0012],
        [ 0.0115, -0.0421, -0.0190,  ..., -0.0263, -0.0312,  0.0213],
        [ 0.0304,  0.0116,  0.0203,  ..., -0.0303, -0.0102, -0.0542]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7612, -0.6235,  1.3418,  ..., -3.1289, -5.7930, -2.0625]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:24:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can recommend something, that thing is recommendable
If you can prefer something, that thing is preferable
If you can admire something, that thing is admirable
If you can perform something, that thing is performable
If you can learn something, that thing is learnable
If you can publish something, that thing is publishable
If you can contain something, that thing is containable
If you can consider something, that thing is
2024-08-01 02:24:06 root INFO     [order_1_approx] starting weight calculation for If you can publish something, that thing is publishable
If you can consider something, that thing is considerable
If you can perform something, that thing is performable
If you can contain something, that thing is containable
If you can prefer something, that thing is preferable
If you can admire something, that thing is admirable
If you can recommend something, that thing is recommendable
If you can learn something, that thing is
2024-08-01 02:24:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 02:27:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0472,  0.0281,  0.1569,  ..., -0.0956, -0.2094, -0.1835],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.6348, -0.8545,  0.5532,  ..., -0.8071, -8.1250, -5.1328],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.7684e-03, -1.6357e-02,  3.4546e-02,  ..., -2.1698e-02,
          1.5579e-02,  2.7039e-02],
        [-2.4475e-02,  1.5121e-02, -1.6037e-02,  ...,  2.7466e-03,
         -1.3504e-02,  6.9199e-03],
        [ 2.7790e-03, -5.8327e-03,  1.1147e-02,  ..., -6.1035e-05,
         -1.0323e-02, -2.1133e-02],
        ...,
        [ 2.3994e-03,  2.7618e-03,  6.4697e-03,  ...,  5.4169e-03,
          1.6800e-02,  1.1501e-03],
        [ 1.7181e-02,  6.4926e-03, -2.2308e-02,  ..., -3.0334e-02,
          3.6926e-03, -7.2479e-03],
        [-1.2398e-03,  1.1108e-02,  1.0483e-02,  ..., -1.1597e-03,
         -1.3580e-02, -3.3234e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1816, -0.9219,  0.4570,  ..., -1.2168, -7.8242, -5.1094]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:27:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can publish something, that thing is publishable
If you can consider something, that thing is considerable
If you can perform something, that thing is performable
If you can contain something, that thing is containable
If you can prefer something, that thing is preferable
If you can admire something, that thing is admirable
If you can recommend something, that thing is recommendable
If you can learn something, that thing is
2024-08-01 02:27:07 root INFO     [order_1_approx] starting weight calculation for If you can perform something, that thing is performable
If you can learn something, that thing is learnable
If you can consider something, that thing is considerable
If you can contain something, that thing is containable
If you can prefer something, that thing is preferable
If you can admire something, that thing is admirable
If you can recommend something, that thing is recommendable
If you can publish something, that thing is
2024-08-01 02:27:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 02:30:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0989,  0.2319,  0.1859,  ...,  0.1228,  0.0036, -0.0236],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2070, -2.4727, -0.3525,  ..., -2.7109, -8.7188, -0.6846],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0342, -0.0258, -0.0096,  ...,  0.0022,  0.0207,  0.0178],
        [-0.0163,  0.0233,  0.0157,  ..., -0.0205, -0.0125,  0.0132],
        [ 0.0743, -0.0405, -0.0394,  ..., -0.0320, -0.0205, -0.0053],
        ...,
        [-0.0599,  0.0547,  0.0145,  ...,  0.0695, -0.0140, -0.0284],
        [ 0.0088, -0.0248, -0.0361,  ..., -0.0126, -0.0196, -0.0013],
        [-0.0303,  0.0497, -0.0184,  ..., -0.0245, -0.0158, -0.0247]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5776, -2.1641, -0.0120,  ..., -3.4102, -8.4297, -1.3418]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:30:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can perform something, that thing is performable
If you can learn something, that thing is learnable
If you can consider something, that thing is considerable
If you can contain something, that thing is containable
If you can prefer something, that thing is preferable
If you can admire something, that thing is admirable
If you can recommend something, that thing is recommendable
If you can publish something, that thing is
2024-08-01 02:30:06 root INFO     total operator prediction time: 1447.6816775798798 seconds
2024-08-01 02:30:06 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on un+adj_reg
2024-08-01 02:30:06 root INFO     building operator un+adj_reg
2024-08-01 02:30:06 root INFO     [order_1_approx] starting weight calculation for The opposite of successful is unsuccessful
The opposite of interrupted is uninterrupted
The opposite of restricted is unrestricted
The opposite of specified is unspecified
The opposite of suitable is unsuitable
The opposite of acceptable is unacceptable
The opposite of related is unrelated
The opposite of affected is
2024-08-01 02:30:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 02:33:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0897,  0.0591, -0.1962,  ..., -0.1840, -0.3486, -0.1003],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3516, -0.3516, -0.3428,  ..., -1.4082, -1.5508, -3.0234],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0061, -0.0808, -0.0071,  ..., -0.0133, -0.0424,  0.0447],
        [ 0.0082, -0.0003,  0.0275,  ...,  0.0218,  0.0646, -0.0099],
        [-0.0015, -0.0522,  0.0126,  ...,  0.0286,  0.0088,  0.0336],
        ...,
        [ 0.0215,  0.0155, -0.0806,  ...,  0.0025,  0.0221, -0.0346],
        [ 0.0954,  0.0455, -0.0056,  ..., -0.0306,  0.0254,  0.0288],
        [ 0.0057,  0.0333, -0.0117,  ...,  0.0496, -0.0347,  0.0148]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.2656, -0.6113,  0.1763,  ..., -0.9482, -3.4102, -2.7363]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:33:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of successful is unsuccessful
The opposite of interrupted is uninterrupted
The opposite of restricted is unrestricted
The opposite of specified is unspecified
The opposite of suitable is unsuitable
The opposite of acceptable is unacceptable
The opposite of related is unrelated
The opposite of affected is
2024-08-01 02:33:09 root INFO     [order_1_approx] starting weight calculation for The opposite of acceptable is unacceptable
The opposite of suitable is unsuitable
The opposite of successful is unsuccessful
The opposite of specified is unspecified
The opposite of related is unrelated
The opposite of affected is unaffected
The opposite of restricted is unrestricted
The opposite of interrupted is
2024-08-01 02:33:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 02:36:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0721,  0.0649, -0.1147,  ..., -0.0177, -0.2817,  0.1704],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6104,  1.2158,  0.3354,  ...,  0.3716, -1.9941, -1.8965],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0047, -0.0019, -0.0127,  ..., -0.0096, -0.0314,  0.0449],
        [-0.0307, -0.0056, -0.0054,  ...,  0.0416, -0.0062, -0.0164],
        [ 0.0239,  0.0316,  0.0023,  ...,  0.0626, -0.0012,  0.0119],
        ...,
        [-0.0092,  0.0224, -0.0169,  ..., -0.0518, -0.0019,  0.0334],
        [-0.0171, -0.0123,  0.0019,  ..., -0.0148,  0.0750,  0.0734],
        [ 0.0112,  0.0256, -0.0017,  ...,  0.0265,  0.0028, -0.0048]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1504,  1.6309, -0.1763,  ...,  0.9023, -1.1650, -1.8291]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:36:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of acceptable is unacceptable
The opposite of suitable is unsuitable
The opposite of successful is unsuccessful
The opposite of specified is unspecified
The opposite of related is unrelated
The opposite of affected is unaffected
The opposite of restricted is unrestricted
The opposite of interrupted is
2024-08-01 02:36:13 root INFO     [order_1_approx] starting weight calculation for The opposite of restricted is unrestricted
The opposite of specified is unspecified
The opposite of successful is unsuccessful
The opposite of interrupted is uninterrupted
The opposite of affected is unaffected
The opposite of suitable is unsuitable
The opposite of acceptable is unacceptable
The opposite of related is
2024-08-01 02:36:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 02:39:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0626,  0.0461, -0.2072,  ..., -0.0312, -0.2285, -0.1509],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.2158,  1.0605, -0.5117,  ..., -0.5977, -0.0127, -2.9531],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.9793e-03, -4.3274e-02,  1.7433e-03,  ...,  2.6749e-02,
         -2.3041e-03,  9.2773e-03],
        [-2.2934e-02, -1.0162e-02,  9.9792e-03,  ..., -6.8665e-05,
          1.2558e-02,  6.0921e-03],
        [ 2.4872e-02, -2.9938e-02,  2.1057e-02,  ...,  3.1433e-02,
         -4.4830e-02,  3.0411e-02],
        ...,
        [ 3.0075e-02, -9.9030e-03, -3.4729e-02,  ..., -1.5915e-02,
          2.6794e-02, -1.3199e-02],
        [ 6.5430e-02, -5.3955e-02, -2.2583e-03,  ...,  1.8188e-02,
          2.8046e-02,  9.5764e-02],
        [-3.5339e-02, -1.3344e-02, -1.2245e-02,  ..., -3.6835e-02,
         -2.1393e-02,  1.3947e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.6084,  2.3047, -0.1189,  ..., -0.4207,  0.5054, -3.0078]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:39:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of restricted is unrestricted
The opposite of specified is unspecified
The opposite of successful is unsuccessful
The opposite of interrupted is uninterrupted
The opposite of affected is unaffected
The opposite of suitable is unsuitable
The opposite of acceptable is unacceptable
The opposite of related is
2024-08-01 02:39:15 root INFO     [order_1_approx] starting weight calculation for The opposite of suitable is unsuitable
The opposite of successful is unsuccessful
The opposite of restricted is unrestricted
The opposite of interrupted is uninterrupted
The opposite of affected is unaffected
The opposite of related is unrelated
The opposite of acceptable is unacceptable
The opposite of specified is
2024-08-01 02:39:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 02:42:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1041,  0.0090, -0.2321,  ..., -0.0998, -0.2693, -0.1868],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1523,  2.0195,  0.0469,  ...,  1.5293, -0.0801, -0.4785],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.2471e-02,  2.1667e-03, -5.0598e-02,  ..., -2.4567e-03,
          2.7313e-02,  4.8828e-02],
        [-1.5312e-02, -1.7502e-02,  4.0588e-02,  ...,  1.9760e-02,
         -5.0354e-03, -9.4223e-03],
        [ 8.3923e-05, -2.2614e-02,  1.5259e-03,  ..., -1.0414e-02,
         -2.5482e-03,  4.1199e-02],
        ...,
        [-2.8763e-03,  4.8676e-03,  2.6093e-03,  ..., -4.0466e-02,
          3.2806e-02, -4.7577e-02],
        [ 2.1713e-02, -6.0272e-04,  4.8157e-02,  ...,  4.3716e-03,
         -2.7466e-02, -2.9663e-02],
        [-2.2430e-02,  6.9519e-02,  5.3925e-02,  ..., -1.2085e-02,
         -2.0706e-02, -4.5380e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8750,  1.5820,  0.2466,  ...,  1.9756, -0.3357, -1.1025]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:42:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of suitable is unsuitable
The opposite of successful is unsuccessful
The opposite of restricted is unrestricted
The opposite of interrupted is uninterrupted
The opposite of affected is unaffected
The opposite of related is unrelated
The opposite of acceptable is unacceptable
The opposite of specified is
2024-08-01 02:42:12 root INFO     [order_1_approx] starting weight calculation for The opposite of successful is unsuccessful
The opposite of affected is unaffected
The opposite of specified is unspecified
The opposite of related is unrelated
The opposite of interrupted is uninterrupted
The opposite of acceptable is unacceptable
The opposite of suitable is unsuitable
The opposite of restricted is
2024-08-01 02:42:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 02:45:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0685, -0.0693, -0.3228,  ..., -0.0856,  0.0182, -0.1122],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5576,  0.7979,  1.5303,  ...,  0.8823, -1.3613, -1.3799],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-2.4567e-03, -4.6265e-02, -3.6682e-02,  ...,  6.9809e-04,
          3.2166e-02,  1.4847e-02],
        [-4.1016e-02, -1.4648e-03,  1.5259e-05,  ...,  2.9354e-03,
          2.5879e-02, -6.4774e-03],
        [ 5.1147e-02, -2.1225e-02,  2.6810e-02,  ...,  1.1658e-02,
         -2.4216e-02, -2.9663e-02],
        ...,
        [ 9.2163e-03, -2.2079e-02, -4.9973e-03,  ...,  4.8828e-03,
          3.2471e-02,  8.3618e-03],
        [ 2.7695e-03, -3.0258e-02, -1.1154e-02,  ..., -4.8218e-03,
         -3.7262e-02,  4.0314e-02],
        [-3.6346e-02,  5.5786e-02,  1.1765e-02,  ..., -6.5422e-03,
          1.7242e-02,  6.1005e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0879,  1.2061,  1.3584,  ...,  1.1104, -1.0098, -1.2773]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:45:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of successful is unsuccessful
The opposite of affected is unaffected
The opposite of specified is unspecified
The opposite of related is unrelated
The opposite of interrupted is uninterrupted
The opposite of acceptable is unacceptable
The opposite of suitable is unsuitable
The opposite of restricted is
2024-08-01 02:45:16 root INFO     [order_1_approx] starting weight calculation for The opposite of affected is unaffected
The opposite of specified is unspecified
The opposite of interrupted is uninterrupted
The opposite of related is unrelated
The opposite of acceptable is unacceptable
The opposite of restricted is unrestricted
The opposite of successful is unsuccessful
The opposite of suitable is
2024-08-01 02:45:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 02:48:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0015,  0.1096, -0.0586,  ..., -0.0948, -0.1724,  0.0049],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7510, -0.7148,  0.4785,  ...,  0.8003, -1.7539,  0.8682],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0456, -0.0023,  0.0050,  ..., -0.0237,  0.0051,  0.0435],
        [ 0.0393,  0.0233, -0.0070,  ...,  0.0361,  0.0134,  0.0155],
        [-0.0294, -0.0037,  0.0230,  ..., -0.0126, -0.0349, -0.0254],
        ...,
        [ 0.0166,  0.0034,  0.0315,  ...,  0.0263,  0.0200,  0.0198],
        [-0.1582,  0.0337, -0.0307,  ..., -0.0467,  0.0131, -0.0258],
        [ 0.0665,  0.0091, -0.0128,  ...,  0.0668, -0.0099,  0.0138]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9609, -0.2437,  1.0625,  ...,  1.0625, -0.5605,  0.2822]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:48:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of affected is unaffected
The opposite of specified is unspecified
The opposite of interrupted is uninterrupted
The opposite of related is unrelated
The opposite of acceptable is unacceptable
The opposite of restricted is unrestricted
The opposite of successful is unsuccessful
The opposite of suitable is
2024-08-01 02:48:18 root INFO     [order_1_approx] starting weight calculation for The opposite of specified is unspecified
The opposite of suitable is unsuitable
The opposite of related is unrelated
The opposite of interrupted is uninterrupted
The opposite of acceptable is unacceptable
The opposite of restricted is unrestricted
The opposite of affected is unaffected
The opposite of successful is
2024-08-01 02:48:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 02:51:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1284,  0.1460,  0.0599,  ..., -0.0106, -0.2754, -0.0285],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6074,  0.8018, -0.5225,  ..., -0.5322,  0.6128, -2.1445],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0103, -0.0544,  0.0223,  ...,  0.0153,  0.0168,  0.0381],
        [-0.0086, -0.0122,  0.0028,  ...,  0.0139,  0.0261,  0.0022],
        [-0.0184,  0.0088,  0.0035,  ...,  0.0120, -0.0049,  0.0013],
        ...,
        [-0.0164,  0.0157,  0.0135,  ..., -0.0012,  0.0064,  0.0144],
        [-0.0370,  0.0130,  0.0245,  ..., -0.0673, -0.0156, -0.0306],
        [ 0.0284,  0.0199, -0.0255,  ...,  0.0304, -0.0108, -0.0371]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6045,  0.8687, -0.6348,  ...,  0.1528,  0.4380, -2.6641]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:51:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of specified is unspecified
The opposite of suitable is unsuitable
The opposite of related is unrelated
The opposite of interrupted is uninterrupted
The opposite of acceptable is unacceptable
The opposite of restricted is unrestricted
The opposite of affected is unaffected
The opposite of successful is
2024-08-01 02:51:21 root INFO     [order_1_approx] starting weight calculation for The opposite of successful is unsuccessful
The opposite of suitable is unsuitable
The opposite of related is unrelated
The opposite of restricted is unrestricted
The opposite of affected is unaffected
The opposite of interrupted is uninterrupted
The opposite of specified is unspecified
The opposite of acceptable is
2024-08-01 02:51:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 02:54:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0206,  0.0845, -0.1470,  ..., -0.0643, -0.4541, -0.0768],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8916, -2.6270,  2.0957,  ...,  0.1206, -2.4414, -2.5195],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0120,  0.0403, -0.0495,  ...,  0.0141, -0.0048,  0.0130],
        [-0.0005,  0.0186, -0.0148,  ...,  0.0008,  0.0509,  0.0211],
        [ 0.0149,  0.0327, -0.0105,  ...,  0.0308, -0.0518, -0.0289],
        ...,
        [ 0.0020, -0.0161,  0.0080,  ..., -0.0210,  0.0198, -0.0075],
        [-0.0342,  0.0294, -0.0319,  ...,  0.0198, -0.0153, -0.0421],
        [-0.0197, -0.0103,  0.0071,  ...,  0.0152, -0.0228,  0.0120]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0645, -3.2500,  2.9590,  ..., -0.2983, -2.1426, -3.1953]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:54:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of successful is unsuccessful
The opposite of suitable is unsuitable
The opposite of related is unrelated
The opposite of restricted is unrestricted
The opposite of affected is unaffected
The opposite of interrupted is uninterrupted
The opposite of specified is unspecified
The opposite of acceptable is
2024-08-01 02:54:21 root INFO     total operator prediction time: 1455.352157831192 seconds
2024-08-01 02:54:21 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on re+verb_reg
2024-08-01 02:54:21 root INFO     building operator re+verb_reg
2024-08-01 02:54:22 root INFO     [order_1_approx] starting weight calculation for To distribute again is to redistribute
To create again is to recreate
To negotiate again is to renegotiate
To unite again is to reunite
To confirm again is to reconfirm
To tell again is to retell
To develop again is to redevelop
To organize again is to
2024-08-01 02:54:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 02:57:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2490,  0.4658,  0.0704,  ..., -0.0911, -0.0141, -0.0115],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.8369, -4.1602,  1.6543,  ...,  1.1113, -2.5156, -4.6797],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0223, -0.0096,  0.0274,  ...,  0.0013,  0.0006,  0.0272],
        [ 0.0018,  0.0086, -0.0158,  ...,  0.0021, -0.0282,  0.0357],
        [-0.0340,  0.0399,  0.0095,  ...,  0.0052, -0.0013, -0.1354],
        ...,
        [ 0.0229, -0.0008,  0.0068,  ...,  0.0021,  0.0125,  0.0330],
        [-0.0151, -0.0133, -0.0198,  ..., -0.0124,  0.0079, -0.0197],
        [-0.0136,  0.0022,  0.0028,  ...,  0.0103,  0.0036, -0.0516]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.6934, -4.0547,  1.7578,  ...,  1.1543, -2.2695, -4.6250]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:57:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To distribute again is to redistribute
To create again is to recreate
To negotiate again is to renegotiate
To unite again is to reunite
To confirm again is to reconfirm
To tell again is to retell
To develop again is to redevelop
To organize again is to
2024-08-01 02:57:21 root INFO     [order_1_approx] starting weight calculation for To tell again is to retell
To organize again is to reorganize
To distribute again is to redistribute
To create again is to recreate
To confirm again is to reconfirm
To negotiate again is to renegotiate
To unite again is to reunite
To develop again is to
2024-08-01 02:57:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 03:00:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2881,  0.2864,  0.0972,  ...,  0.0319, -0.0494, -0.0479],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2188, -4.2852,  0.2397,  ...,  1.5801, -5.2578, -2.9707],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0140, -0.0414,  0.0243,  ...,  0.0095, -0.0309,  0.0196],
        [-0.0133, -0.0137, -0.0188,  ...,  0.0151,  0.0111,  0.0280],
        [ 0.0095, -0.0037,  0.0052,  ...,  0.0319, -0.0028, -0.0065],
        ...,
        [ 0.0133, -0.0137,  0.0400,  ...,  0.0204, -0.0072,  0.0048],
        [-0.0236,  0.0316, -0.0162,  ..., -0.0108, -0.0025, -0.0014],
        [ 0.0126,  0.0175, -0.0133,  ..., -0.0004,  0.0135,  0.0276]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5137, -3.7422, -0.2178,  ...,  1.6670, -5.1172, -2.0664]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:00:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To tell again is to retell
To organize again is to reorganize
To distribute again is to redistribute
To create again is to recreate
To confirm again is to reconfirm
To negotiate again is to renegotiate
To unite again is to reunite
To develop again is to
2024-08-01 03:00:24 root INFO     [order_1_approx] starting weight calculation for To develop again is to redevelop
To unite again is to reunite
To organize again is to reorganize
To confirm again is to reconfirm
To create again is to recreate
To distribute again is to redistribute
To tell again is to retell
To negotiate again is to
2024-08-01 03:00:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 03:03:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3335,  0.3218, -0.0764,  ..., -0.1895, -0.3181, -0.0513],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2920, -2.2812,  1.8477,  ..., -1.6562, -4.4297, -3.8496],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0063, -0.0499,  0.0122,  ...,  0.0131,  0.0039,  0.0265],
        [ 0.0042,  0.0268,  0.0207,  ...,  0.0067,  0.0082, -0.0025],
        [ 0.0022,  0.0473,  0.0391,  ..., -0.0271, -0.0063, -0.0752],
        ...,
        [-0.0198, -0.0441, -0.0347,  ...,  0.0391,  0.0365,  0.0524],
        [-0.0165, -0.0014, -0.0133,  ..., -0.0026, -0.0115, -0.0086],
        [ 0.0139,  0.0129,  0.0046,  ..., -0.0115, -0.0154, -0.0102]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5386, -2.0996,  2.4180,  ..., -1.5596, -4.3086, -3.5000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:03:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To develop again is to redevelop
To unite again is to reunite
To organize again is to reorganize
To confirm again is to reconfirm
To create again is to recreate
To distribute again is to redistribute
To tell again is to retell
To negotiate again is to
2024-08-01 03:03:26 root INFO     [order_1_approx] starting weight calculation for To negotiate again is to renegotiate
To organize again is to reorganize
To unite again is to reunite
To distribute again is to redistribute
To tell again is to retell
To create again is to recreate
To develop again is to redevelop
To confirm again is to
2024-08-01 03:03:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 03:06:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0465,  0.3301, -0.0136,  ...,  0.1555, -0.3354, -0.0742],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7085, -3.9805,  2.1602,  ...,  2.6016, -3.9805, -3.2266],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0029, -0.0541,  0.0519,  ..., -0.0404,  0.0459,  0.0258],
        [ 0.0081,  0.0415,  0.0360,  ...,  0.0260,  0.0175,  0.0127],
        [ 0.0012,  0.0379,  0.0431,  ...,  0.0295, -0.0222, -0.0137],
        ...,
        [ 0.0180,  0.0442, -0.0013,  ...,  0.0452, -0.0065,  0.0300],
        [-0.0195,  0.0008, -0.0279,  ..., -0.0264, -0.0349, -0.0090],
        [-0.0313, -0.0076,  0.0224,  ..., -0.0259, -0.0471, -0.0254]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.9404, -3.6211,  2.0234,  ...,  2.7812, -4.4219, -3.4883]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:06:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To negotiate again is to renegotiate
To organize again is to reorganize
To unite again is to reunite
To distribute again is to redistribute
To tell again is to retell
To create again is to recreate
To develop again is to redevelop
To confirm again is to
2024-08-01 03:06:30 root INFO     [order_1_approx] starting weight calculation for To confirm again is to reconfirm
To unite again is to reunite
To tell again is to retell
To create again is to recreate
To develop again is to redevelop
To organize again is to reorganize
To negotiate again is to renegotiate
To distribute again is to
2024-08-01 03:06:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 03:09:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2448,  0.3198,  0.1102,  ..., -0.0232, -0.0459,  0.1956],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1495, -3.5625,  0.7593,  ...,  0.2969, -5.1641, -3.2656],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0142, -0.0428,  0.0337,  ...,  0.0050, -0.0251,  0.0439],
        [-0.0017,  0.0356,  0.0164,  ...,  0.0002, -0.0053, -0.0002],
        [ 0.0289,  0.0387,  0.0163,  ...,  0.0053, -0.0135, -0.0623],
        ...,
        [-0.0051, -0.0056,  0.0244,  ...,  0.0515,  0.0096,  0.0260],
        [-0.0084,  0.0060, -0.0063,  ..., -0.0213,  0.0065, -0.0075],
        [-0.0108,  0.0128,  0.0041,  ...,  0.0132, -0.0098,  0.0185]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0916, -3.6641,  1.0625,  ...,  0.1394, -4.9492, -3.4141]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:09:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To confirm again is to reconfirm
To unite again is to reunite
To tell again is to retell
To create again is to recreate
To develop again is to redevelop
To organize again is to reorganize
To negotiate again is to renegotiate
To distribute again is to
2024-08-01 03:09:28 root INFO     [order_1_approx] starting weight calculation for To tell again is to retell
To develop again is to redevelop
To negotiate again is to renegotiate
To confirm again is to reconfirm
To distribute again is to redistribute
To organize again is to reorganize
To unite again is to reunite
To create again is to
2024-08-01 03:09:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 03:12:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2161,  0.2424,  0.0624,  ...,  0.0342, -0.2286, -0.1232],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.9609, -5.3008,  1.4219,  ...,  2.8945, -3.9531, -0.8281],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0338, -0.0251, -0.0020,  ...,  0.0159,  0.0258,  0.0396],
        [ 0.0130,  0.0113, -0.0038,  ..., -0.0067,  0.0128,  0.0381],
        [ 0.0075, -0.0002,  0.0364,  ...,  0.0197, -0.0179, -0.0270],
        ...,
        [-0.0014, -0.0035, -0.0006,  ...,  0.0064,  0.0253,  0.0240],
        [-0.0044,  0.0288,  0.0137,  ..., -0.0185, -0.0192,  0.0067],
        [-0.0175, -0.0012, -0.0073,  ..., -0.0019, -0.0465, -0.0073]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.9092, -5.3359,  1.8428,  ...,  2.8691, -3.5098, -0.9849]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:12:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To tell again is to retell
To develop again is to redevelop
To negotiate again is to renegotiate
To confirm again is to reconfirm
To distribute again is to redistribute
To organize again is to reorganize
To unite again is to reunite
To create again is to
2024-08-01 03:12:26 root INFO     [order_1_approx] starting weight calculation for To develop again is to redevelop
To organize again is to reorganize
To confirm again is to reconfirm
To create again is to recreate
To distribute again is to redistribute
To negotiate again is to renegotiate
To tell again is to retell
To unite again is to
2024-08-01 03:12:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 03:15:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3015,  0.1332,  0.0525,  ..., -0.0027, -0.1761,  0.0626],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.6084, -4.2500,  1.6670,  ...,  1.4502, -3.6172, -2.6523],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0279, -0.0293,  0.0397,  ..., -0.0051, -0.0121,  0.0226],
        [-0.0280,  0.0045, -0.0006,  ..., -0.0012, -0.0244,  0.0149],
        [ 0.0291,  0.0031,  0.0022,  ...,  0.0215, -0.0220, -0.0659],
        ...,
        [-0.0232, -0.0321,  0.0113,  ...,  0.0007, -0.0132,  0.0182],
        [-0.0014, -0.0080, -0.0039,  ..., -0.0186, -0.0121, -0.0146],
        [-0.0279, -0.0294, -0.0190,  ..., -0.0015, -0.0112, -0.0128]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.0371, -4.3945,  2.1758,  ...,  0.9458, -3.5352, -2.2402]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:15:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To develop again is to redevelop
To organize again is to reorganize
To confirm again is to reconfirm
To create again is to recreate
To distribute again is to redistribute
To negotiate again is to renegotiate
To tell again is to retell
To unite again is to
2024-08-01 03:15:28 root INFO     [order_1_approx] starting weight calculation for To create again is to recreate
To distribute again is to redistribute
To negotiate again is to renegotiate
To confirm again is to reconfirm
To develop again is to redevelop
To unite again is to reunite
To organize again is to reorganize
To tell again is to
2024-08-01 03:15:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 03:18:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0294,  0.2195,  0.1326,  ..., -0.0810, -0.0469, -0.0656],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2383, -3.2441,  2.2344,  ...,  0.9194, -4.6406, -2.7109],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0240,  0.0111,  0.0158,  ..., -0.0081, -0.0290,  0.0157],
        [-0.0154, -0.0205, -0.0405,  ...,  0.0242,  0.0256, -0.0060],
        [ 0.0360,  0.0576,  0.0158,  ...,  0.0094, -0.0090, -0.0133],
        ...,
        [-0.0152, -0.0410, -0.0312,  ...,  0.0293,  0.0307,  0.0107],
        [ 0.0264,  0.0468, -0.0013,  ..., -0.0136, -0.0071,  0.0154],
        [-0.0172, -0.0377,  0.0035,  ...,  0.0070,  0.0302,  0.0306]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2156, -2.5898,  1.7363,  ...,  1.4570, -4.9375, -2.6426]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:18:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To create again is to recreate
To distribute again is to redistribute
To negotiate again is to renegotiate
To confirm again is to reconfirm
To develop again is to redevelop
To unite again is to reunite
To organize again is to reorganize
To tell again is to
2024-08-01 03:18:27 root INFO     total operator prediction time: 1445.6044685840607 seconds
2024-08-01 03:18:27 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj+ness_reg
2024-08-01 03:18:27 root INFO     building operator adj+ness_reg
2024-08-01 03:18:27 root INFO     [order_1_approx] starting weight calculation for The state of being distinct is distinctness
The state of being hot is hotness
The state of being careful is carefulness
The state of being related is relatedness
The state of being interesting is interestingness
The state of being aware is awareness
The state of being prepared is preparedness
The state of being innovative is
2024-08-01 03:18:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 03:21:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1025,  0.0044,  0.0858,  ..., -0.0378, -0.1781, -0.1472],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8535, -3.2793, -0.5454,  ...,  1.0176, -0.3901, -2.3789],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0027,  0.0096,  0.0137,  ..., -0.0032, -0.0109,  0.0128],
        [ 0.0032,  0.0075, -0.0087,  ..., -0.0091, -0.0053, -0.0065],
        [ 0.0025, -0.0128,  0.0144,  ...,  0.0089, -0.0056, -0.0358],
        ...,
        [-0.0209, -0.0081,  0.0314,  ...,  0.0152,  0.0159,  0.0091],
        [-0.0094,  0.0296,  0.0175,  ...,  0.0182,  0.0119, -0.0304],
        [ 0.0236, -0.0074,  0.0054,  ..., -0.0033, -0.0125,  0.0014]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8828, -3.1445, -0.7148,  ...,  0.8755, -0.8887, -2.6836]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:21:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being distinct is distinctness
The state of being hot is hotness
The state of being careful is carefulness
The state of being related is relatedness
The state of being interesting is interestingness
The state of being aware is awareness
The state of being prepared is preparedness
The state of being innovative is
2024-08-01 03:21:24 root INFO     [order_1_approx] starting weight calculation for The state of being distinct is distinctness
The state of being prepared is preparedness
The state of being related is relatedness
The state of being aware is awareness
The state of being innovative is innovativeness
The state of being careful is carefulness
The state of being interesting is interestingness
The state of being hot is
2024-08-01 03:21:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 03:24:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0458, -0.1169,  0.1670,  ...,  0.0674, -0.2014, -0.0983],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5435, -2.2969, -0.8262,  ..., -4.0312, -6.6797, -1.0488],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0105, -0.0398,  0.0015,  ..., -0.0459, -0.0100,  0.0405],
        [-0.0106, -0.0031,  0.0481,  ..., -0.0265, -0.0046,  0.0054],
        [ 0.0003,  0.0228, -0.0179,  ...,  0.0163, -0.0089,  0.0183],
        ...,
        [-0.0013, -0.0127,  0.0314,  ...,  0.0193,  0.0083, -0.0391],
        [ 0.0194,  0.0129,  0.0040,  ..., -0.0099,  0.0263,  0.0380],
        [ 0.0199,  0.0268,  0.0107,  ...,  0.0194, -0.0089,  0.0654]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4297, -2.4082, -0.8574,  ..., -3.6348, -6.8203, -1.3867]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:24:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being distinct is distinctness
The state of being prepared is preparedness
The state of being related is relatedness
The state of being aware is awareness
The state of being innovative is innovativeness
The state of being careful is carefulness
The state of being interesting is interestingness
The state of being hot is
2024-08-01 03:24:21 root INFO     [order_1_approx] starting weight calculation for The state of being hot is hotness
The state of being prepared is preparedness
The state of being careful is carefulness
The state of being innovative is innovativeness
The state of being aware is awareness
The state of being interesting is interestingness
The state of being related is relatedness
The state of being distinct is
2024-08-01 03:24:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 03:27:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2029, -0.0338,  0.0934,  ...,  0.1349, -0.0104, -0.0373],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1406, -2.2539, -0.3345,  ..., -3.4883, -4.6953, -0.8872],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0203,  0.0058, -0.0052,  ..., -0.0223,  0.0167, -0.0061],
        [ 0.0048, -0.0005,  0.0154,  ...,  0.0135, -0.0105,  0.0156],
        [ 0.0167, -0.0079,  0.0212,  ..., -0.0488, -0.0277, -0.0314],
        ...,
        [-0.0241,  0.0011,  0.0347,  ..., -0.0138,  0.0046, -0.0231],
        [ 0.0249, -0.0317,  0.0164,  ...,  0.0086,  0.0041,  0.0408],
        [-0.0012,  0.0206,  0.0294,  ...,  0.0239,  0.0157,  0.0202]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0342, -2.2246,  0.0176,  ..., -3.2480, -4.1016, -0.9775]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:27:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being hot is hotness
The state of being prepared is preparedness
The state of being careful is carefulness
The state of being innovative is innovativeness
The state of being aware is awareness
The state of being interesting is interestingness
The state of being related is relatedness
The state of being distinct is
2024-08-01 03:27:25 root INFO     [order_1_approx] starting weight calculation for The state of being interesting is interestingness
The state of being innovative is innovativeness
The state of being aware is awareness
The state of being distinct is distinctness
The state of being related is relatedness
The state of being careful is carefulness
The state of being hot is hotness
The state of being prepared is
2024-08-01 03:27:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 03:30:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1479, -0.0581,  0.0157,  ...,  0.0498, -0.0665,  0.0836],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.2266, -5.9375, -1.0527,  ...,  0.7354, -2.3828, -2.3477],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0209, -0.0121,  0.0011,  ..., -0.0197, -0.0280, -0.0039],
        [-0.0186,  0.0003, -0.0161,  ..., -0.0080, -0.0283,  0.0171],
        [ 0.0078, -0.0152,  0.0097,  ...,  0.0070,  0.0126,  0.0082],
        ...,
        [ 0.0127, -0.0114,  0.0065,  ...,  0.0214, -0.0046,  0.0033],
        [-0.0393, -0.0014,  0.0356,  ..., -0.0318,  0.0609, -0.0347],
        [ 0.0156, -0.0258, -0.0008,  ...,  0.0493, -0.0012,  0.0253]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.0273, -5.8125, -0.8545,  ...,  1.0107, -1.9375, -2.4609]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:30:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being interesting is interestingness
The state of being innovative is innovativeness
The state of being aware is awareness
The state of being distinct is distinctness
The state of being related is relatedness
The state of being careful is carefulness
The state of being hot is hotness
The state of being prepared is
2024-08-01 03:30:27 root INFO     [order_1_approx] starting weight calculation for The state of being hot is hotness
The state of being distinct is distinctness
The state of being careful is carefulness
The state of being aware is awareness
The state of being related is relatedness
The state of being innovative is innovativeness
The state of being prepared is preparedness
The state of being interesting is
2024-08-01 03:30:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 03:33:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1049,  0.0895,  0.0679,  ...,  0.1521, -0.2396, -0.1384],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0078, -2.4824, -0.0912,  ..., -0.7759, -2.4844, -2.3340],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0151,  0.0094, -0.0129,  ..., -0.0103,  0.0055,  0.0190],
        [-0.0233,  0.0332, -0.0057,  ...,  0.0200,  0.0047, -0.0329],
        [ 0.0077,  0.0135,  0.0052,  ..., -0.0248, -0.0328, -0.0075],
        ...,
        [-0.0103, -0.0043,  0.0233,  ...,  0.0155, -0.0052,  0.0026],
        [ 0.0124,  0.0067,  0.0351,  ..., -0.0242,  0.0297, -0.0180],
        [ 0.0156,  0.0291, -0.0025,  ..., -0.0052, -0.0050,  0.0113]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5557, -2.1934, -0.2144,  ..., -0.5962, -2.2051, -1.7598]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:33:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being hot is hotness
The state of being distinct is distinctness
The state of being careful is carefulness
The state of being aware is awareness
The state of being related is relatedness
The state of being innovative is innovativeness
The state of being prepared is preparedness
The state of being interesting is
2024-08-01 03:33:31 root INFO     [order_1_approx] starting weight calculation for The state of being related is relatedness
The state of being hot is hotness
The state of being prepared is preparedness
The state of being aware is awareness
The state of being interesting is interestingness
The state of being distinct is distinctness
The state of being innovative is innovativeness
The state of being careful is
2024-08-01 03:33:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 03:36:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4060,  0.0363, -0.1159,  ...,  0.0048, -0.1932,  0.0602],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2012, -4.4258, -0.4858,  ..., -2.6172, -1.8213, -1.2861],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0094, -0.0111, -0.0176,  ..., -0.0375, -0.0099,  0.0090],
        [-0.0016,  0.0025,  0.0234,  ...,  0.0217,  0.0337,  0.0331],
        [-0.0203, -0.0175, -0.0084,  ...,  0.0492, -0.0213, -0.0502],
        ...,
        [-0.0280, -0.0093,  0.0526,  ..., -0.0253,  0.0124,  0.0167],
        [ 0.0220, -0.0138, -0.0042,  ...,  0.0007,  0.0002, -0.0292],
        [ 0.0015, -0.0259, -0.0127,  ...,  0.0338,  0.0050, -0.0340]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0986, -4.2461, -0.2134,  ..., -2.1777, -1.3613, -0.6719]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:36:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being related is relatedness
The state of being hot is hotness
The state of being prepared is preparedness
The state of being aware is awareness
The state of being interesting is interestingness
The state of being distinct is distinctness
The state of being innovative is innovativeness
The state of being careful is
2024-08-01 03:36:30 root INFO     [order_1_approx] starting weight calculation for The state of being interesting is interestingness
The state of being innovative is innovativeness
The state of being hot is hotness
The state of being careful is carefulness
The state of being distinct is distinctness
The state of being prepared is preparedness
The state of being aware is awareness
The state of being related is
2024-08-01 03:36:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 03:39:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0254, -0.0067, -0.0651,  ..., -0.0258, -0.2966, -0.1560],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7158, -2.2500, -1.0664,  ...,  0.8184, -2.9590, -2.3984],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0111, -0.0339, -0.0051,  ..., -0.0378,  0.0262,  0.0082],
        [ 0.0021,  0.0088,  0.0016,  ...,  0.0819,  0.0228, -0.0072],
        [-0.0210,  0.0028,  0.0509,  ..., -0.0071, -0.0276, -0.0109],
        ...,
        [-0.0166,  0.0274,  0.0041,  ...,  0.0337,  0.0066, -0.0169],
        [ 0.0411,  0.0414,  0.0364,  ..., -0.0956, -0.0420,  0.0220],
        [-0.0289, -0.0016, -0.0442,  ...,  0.0682,  0.0167,  0.0022]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5615, -2.5410, -0.5049,  ...,  0.5889, -2.0938, -2.8691]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:39:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being interesting is interestingness
The state of being innovative is innovativeness
The state of being hot is hotness
The state of being careful is carefulness
The state of being distinct is distinctness
The state of being prepared is preparedness
The state of being aware is awareness
The state of being related is
2024-08-01 03:39:33 root INFO     [order_1_approx] starting weight calculation for The state of being related is relatedness
The state of being prepared is preparedness
The state of being innovative is innovativeness
The state of being interesting is interestingness
The state of being careful is carefulness
The state of being hot is hotness
The state of being distinct is distinctness
The state of being aware is
2024-08-01 03:39:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 03:42:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1046,  0.1619, -0.1273,  ...,  0.1602, -0.1289, -0.1957],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3142, -2.4961, -0.2280,  ..., -0.8271, -4.3359,  0.8779],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0411, -0.0033, -0.0028,  ..., -0.0276, -0.0180, -0.0200],
        [ 0.0277,  0.0249,  0.0172,  ...,  0.0573,  0.0359, -0.0450],
        [ 0.0036,  0.0314,  0.0391,  ...,  0.0114, -0.0199, -0.0172],
        ...,
        [ 0.0048,  0.0134,  0.0054,  ...,  0.0133, -0.0099, -0.0073],
        [ 0.0042, -0.0019, -0.0033,  ...,  0.0033,  0.0279, -0.0003],
        [ 0.0214,  0.0037,  0.0338,  ...,  0.0381, -0.0143,  0.0094]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3716, -2.2949, -0.2898,  ..., -0.7573, -4.5273,  1.1113]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:42:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being related is relatedness
The state of being prepared is preparedness
The state of being innovative is innovativeness
The state of being interesting is interestingness
The state of being careful is carefulness
The state of being hot is hotness
The state of being distinct is distinctness
The state of being aware is
2024-08-01 03:42:36 root INFO     total operator prediction time: 1448.9933726787567 seconds
2024-08-01 03:42:36 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun+less_reg
2024-08-01 03:42:36 root INFO     building operator noun+less_reg
2024-08-01 03:42:36 root INFO     [order_1_approx] starting weight calculation for Something without luck is luckless
Something without leg is legless
Something without defence is defenceless
Something without expression is expressionless
Something without art is artless
Something without heart is heartless
Something without friction is frictionless
Something without path is
2024-08-01 03:42:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 03:45:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0594, -0.1904,  0.2231,  ..., -0.0942, -0.2205,  0.0176],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.4102, -4.8398, -3.1133,  ..., -0.1825, -4.6484, -1.4834],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-6.6147e-03, -2.0874e-02, -2.2873e-02,  ..., -2.8763e-02,
          3.5400e-03,  4.2023e-02],
        [ 6.9122e-03, -7.4348e-03,  5.1453e-02,  ...,  3.4546e-02,
         -2.6901e-02, -1.6357e-02],
        [ 2.1622e-02, -1.6785e-04,  6.4735e-03,  ...,  2.0782e-02,
         -3.5767e-02, -2.8748e-02],
        ...,
        [-1.2436e-03, -8.6594e-03,  1.9272e-02,  ...,  2.7969e-02,
         -8.7509e-03, -3.6255e-02],
        [-5.7907e-03, -5.0964e-03,  1.5358e-02,  ..., -6.4888e-03,
          8.8959e-03,  2.6398e-02],
        [ 8.9874e-03, -1.0025e-02, -1.0025e-02,  ..., -9.1434e-05,
         -3.9459e-02,  8.5449e-04]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8594, -3.2520, -2.4941,  ...,  0.3970, -4.4453, -1.0469]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:45:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without luck is luckless
Something without leg is legless
Something without defence is defenceless
Something without expression is expressionless
Something without art is artless
Something without heart is heartless
Something without friction is frictionless
Something without path is
2024-08-01 03:45:39 root INFO     [order_1_approx] starting weight calculation for Something without leg is legless
Something without expression is expressionless
Something without defence is defenceless
Something without friction is frictionless
Something without path is pathless
Something without art is artless
Something without heart is heartless
Something without luck is
2024-08-01 03:45:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 03:48:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0941,  0.0559,  0.1726,  ...,  0.0490, -0.0519, -0.0465],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3281, -3.1953, -0.6318,  ..., -1.4961, -1.2021, -1.4746],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0068, -0.0597, -0.0122,  ..., -0.0108, -0.0115,  0.0208],
        [ 0.0004,  0.0129, -0.0077,  ..., -0.0277, -0.0311, -0.0138],
        [-0.0095, -0.0525, -0.0084,  ..., -0.0135, -0.0097, -0.0204],
        ...,
        [ 0.0278, -0.0324, -0.0110,  ..., -0.0133, -0.0247,  0.0029],
        [-0.0635,  0.0018,  0.0710,  ..., -0.0226, -0.0050, -0.0105],
        [-0.0138,  0.0004, -0.0054,  ...,  0.0096,  0.0178, -0.0219]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1943, -2.6406, -0.6167,  ..., -1.1787, -1.4053, -1.4131]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:48:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without leg is legless
Something without expression is expressionless
Something without defence is defenceless
Something without friction is frictionless
Something without path is pathless
Something without art is artless
Something without heart is heartless
Something without luck is
2024-08-01 03:48:43 root INFO     [order_1_approx] starting weight calculation for Something without leg is legless
Something without friction is frictionless
Something without defence is defenceless
Something without path is pathless
Something without luck is luckless
Something without heart is heartless
Something without expression is expressionless
Something without art is
2024-08-01 03:48:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 03:51:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0466, -0.1405,  0.1046,  ..., -0.1639, -0.1113, -0.0961],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5352, -3.5664,  0.5781,  ..., -2.2109, -4.8945, -0.0303],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0139,  0.0414, -0.0029,  ..., -0.0367, -0.0206,  0.0212],
        [ 0.0428, -0.0291,  0.0004,  ...,  0.0387,  0.0263, -0.0145],
        [ 0.0044,  0.0007, -0.0083,  ..., -0.0074, -0.0065, -0.0176],
        ...,
        [ 0.0203, -0.0607, -0.0067,  ...,  0.0087,  0.0327,  0.0081],
        [ 0.0172, -0.0058,  0.0064,  ..., -0.0180,  0.0004, -0.0162],
        [ 0.0106, -0.0363, -0.0248,  ...,  0.0277,  0.0178, -0.0017]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5537, -2.4805,  0.5156,  ..., -1.8301, -4.8164, -0.1101]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:51:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without leg is legless
Something without friction is frictionless
Something without defence is defenceless
Something without path is pathless
Something without luck is luckless
Something without heart is heartless
Something without expression is expressionless
Something without art is
2024-08-01 03:51:43 root INFO     [order_1_approx] starting weight calculation for Something without art is artless
Something without defence is defenceless
Something without friction is frictionless
Something without expression is expressionless
Something without luck is luckless
Something without path is pathless
Something without heart is heartless
Something without leg is
2024-08-01 03:51:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 03:54:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1829, -0.0609,  0.1375,  ...,  0.0299, -0.0165, -0.1058],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8369, -4.8516,  0.5684,  ..., -0.8813, -1.3760, -1.6904],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0128, -0.0325,  0.0400,  ..., -0.0071, -0.0247, -0.0058],
        [ 0.0393, -0.0109, -0.0274,  ...,  0.0413, -0.0338,  0.0696],
        [-0.0237, -0.0082, -0.0161,  ..., -0.0293,  0.0066,  0.0272],
        ...,
        [ 0.0450,  0.0053, -0.0219,  ...,  0.0226, -0.0049,  0.0351],
        [ 0.0071,  0.0304,  0.0589,  ...,  0.0282,  0.0231, -0.0181],
        [ 0.0250,  0.0027, -0.0076,  ...,  0.0269,  0.0104,  0.0233]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0464, -4.1562,  0.5840,  ..., -0.7261, -2.1855, -1.6934]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:54:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without art is artless
Something without defence is defenceless
Something without friction is frictionless
Something without expression is expressionless
Something without luck is luckless
Something without path is pathless
Something without heart is heartless
Something without leg is
2024-08-01 03:54:45 root INFO     [order_1_approx] starting weight calculation for Something without path is pathless
Something without heart is heartless
Something without friction is frictionless
Something without art is artless
Something without leg is legless
Something without luck is luckless
Something without defence is defenceless
Something without expression is
2024-08-01 03:54:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 03:57:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0237,  0.0471,  0.1344,  ...,  0.0579, -0.1104, -0.0226],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0117, -3.2500,  2.0977,  ..., -3.0508, -2.9355, -1.3447],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0004,  0.0411, -0.0185,  ..., -0.0304,  0.0056,  0.0046],
        [-0.0030, -0.0114,  0.0279,  ...,  0.0269, -0.0180, -0.0169],
        [-0.0074,  0.0154, -0.0223,  ..., -0.0237,  0.0132, -0.0584],
        ...,
        [ 0.0147, -0.0124, -0.0199,  ...,  0.0242,  0.0022, -0.0059],
        [ 0.0046, -0.0119, -0.0244,  ...,  0.0216, -0.0054,  0.0128],
        [ 0.0238, -0.0264,  0.0195,  ...,  0.0605, -0.0031,  0.0042]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5605, -2.7266,  1.7695,  ..., -2.6562, -2.6055, -1.1855]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:57:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without path is pathless
Something without heart is heartless
Something without friction is frictionless
Something without art is artless
Something without leg is legless
Something without luck is luckless
Something without defence is defenceless
Something without expression is
2024-08-01 03:57:48 root INFO     [order_1_approx] starting weight calculation for Something without path is pathless
Something without art is artless
Something without heart is heartless
Something without luck is luckless
Something without expression is expressionless
Something without defence is defenceless
Something without leg is legless
Something without friction is
2024-08-01 03:57:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 04:00:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0951, -0.1412, -0.1245,  ...,  0.0165,  0.1121,  0.0365],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.4688, -2.1719,  2.0059,  ..., -1.8506, -3.0547, -0.3076],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0197, -0.0138,  0.0395,  ..., -0.0121,  0.0217,  0.0102],
        [-0.0380, -0.0069, -0.0158,  ..., -0.0142,  0.0244,  0.0190],
        [-0.0043,  0.0461,  0.0246,  ..., -0.0124, -0.0424, -0.0262],
        ...,
        [ 0.0215, -0.0210, -0.0232,  ...,  0.0659,  0.0088, -0.0026],
        [-0.0129,  0.0274, -0.0043,  ..., -0.0343,  0.0779,  0.0063],
        [-0.0070,  0.0248, -0.0048,  ...,  0.0421,  0.0125, -0.0012]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.3906, -1.7266,  2.0527,  ..., -1.9336, -2.8340, -0.2288]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:00:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without path is pathless
Something without art is artless
Something without heart is heartless
Something without luck is luckless
Something without expression is expressionless
Something without defence is defenceless
Something without leg is legless
Something without friction is
2024-08-01 04:00:53 root INFO     [order_1_approx] starting weight calculation for Something without friction is frictionless
Something without art is artless
Something without heart is heartless
Something without luck is luckless
Something without expression is expressionless
Something without leg is legless
Something without path is pathless
Something without defence is
2024-08-01 04:00:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 04:03:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0258, -0.1183,  0.1726,  ...,  0.0087,  0.0162, -0.0084],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7988, -4.8125,  0.9189,  ..., -2.1484, -2.1992, -2.0547],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0022,  0.0319, -0.0257,  ..., -0.0118,  0.0053, -0.0076],
        [-0.0096, -0.0302, -0.0127,  ..., -0.0182,  0.0011, -0.0172],
        [-0.0141,  0.0209, -0.0085,  ..., -0.0064, -0.0292, -0.0269],
        ...,
        [-0.0090, -0.0027,  0.0083,  ..., -0.0566,  0.0096,  0.0005],
        [-0.0167,  0.0075,  0.0063,  ..., -0.0065,  0.0160, -0.0149],
        [-0.0175, -0.0527, -0.0306,  ..., -0.0316,  0.0005,  0.0023]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0742, -4.5117,  1.4668,  ..., -2.1699, -2.1035, -2.0176]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:03:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without friction is frictionless
Something without art is artless
Something without heart is heartless
Something without luck is luckless
Something without expression is expressionless
Something without leg is legless
Something without path is pathless
Something without defence is
2024-08-01 04:03:57 root INFO     [order_1_approx] starting weight calculation for Something without path is pathless
Something without defence is defenceless
Something without art is artless
Something without expression is expressionless
Something without friction is frictionless
Something without leg is legless
Something without luck is luckless
Something without heart is
2024-08-01 04:03:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 04:07:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0742,  0.0037,  0.1187,  ..., -0.1194, -0.2260, -0.1543],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7949, -3.8438, -0.4482,  ..., -3.1680, -3.1250, -2.6426],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0051, -0.0062,  0.0054,  ..., -0.0055, -0.0026,  0.0152],
        [ 0.0242,  0.0183,  0.0280,  ..., -0.0052, -0.0069,  0.0264],
        [-0.0315, -0.0296,  0.0106,  ..., -0.0278,  0.0146,  0.0043],
        ...,
        [ 0.0356,  0.0148,  0.0340,  ...,  0.0035,  0.0020,  0.0167],
        [-0.0090,  0.0320, -0.0164,  ...,  0.0026,  0.0028, -0.0162],
        [ 0.0137, -0.0089,  0.0345,  ...,  0.0061, -0.0158,  0.0273]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6660, -2.6016, -0.2607,  ..., -2.8223, -3.9531, -1.8066]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:07:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without path is pathless
Something without defence is defenceless
Something without art is artless
Something without expression is expressionless
Something without friction is frictionless
Something without leg is legless
Something without luck is luckless
Something without heart is
2024-08-01 04:07:01 root INFO     total operator prediction time: 1464.8136274814606 seconds
2024-08-01 04:07:01 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+ment_irreg
2024-08-01 04:07:01 root INFO     building operator verb+ment_irreg
2024-08-01 04:07:01 root INFO     [order_1_approx] starting weight calculation for To improve results in a improvement
To encourage results in a encouragement
To amuse results in a amusement
To invest results in a investment
To enroll results in a enrollment
To fulfil results in a fulfilment
To redevelop results in a redevelopment
To enhance results in a
2024-08-01 04:07:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 04:10:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0127,  0.1189,  0.0809,  ...,  0.1771, -0.1521, -0.0200],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2949, -0.6504,  0.3931,  ...,  4.2344, -5.3203, -2.5703],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0042,  0.0011,  0.0515,  ..., -0.0087, -0.0016,  0.0182],
        [-0.0258,  0.0409, -0.0396,  ...,  0.0430, -0.0298, -0.0013],
        [ 0.0155, -0.0047,  0.0756,  ...,  0.0252,  0.0612, -0.0040],
        ...,
        [-0.0022, -0.0241, -0.0163,  ...,  0.0107, -0.0230, -0.0170],
        [ 0.0081,  0.0210,  0.0185,  ..., -0.0112,  0.0445,  0.0168],
        [ 0.0054, -0.0265,  0.0295,  ...,  0.0288, -0.0235,  0.0488]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7900, -1.3125,  0.7842,  ...,  3.8047, -4.8594, -2.3848]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:10:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To improve results in a improvement
To encourage results in a encouragement
To amuse results in a amusement
To invest results in a investment
To enroll results in a enrollment
To fulfil results in a fulfilment
To redevelop results in a redevelopment
To enhance results in a
2024-08-01 04:10:01 root INFO     [order_1_approx] starting weight calculation for To amuse results in a amusement
To improve results in a improvement
To fulfil results in a fulfilment
To invest results in a investment
To redevelop results in a redevelopment
To enroll results in a enrollment
To enhance results in a enhancement
To encourage results in a
2024-08-01 04:10:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 04:13:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0891,  0.2495, -0.2732,  ..., -0.0020, -0.1726, -0.0763],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3008, -3.2266,  0.0720,  ...,  4.3672, -1.3438, -1.5234],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.2186e-02, -3.4676e-03,  3.4302e-02,  ...,  8.1100e-03,
         -2.3468e-02,  4.2084e-02],
        [-5.0537e-02,  3.3569e-02, -5.5161e-03,  ...,  2.8397e-02,
          1.9501e-02, -1.7273e-02],
        [ 5.4291e-02,  2.2659e-02,  3.8147e-06,  ...,  1.1444e-02,
         -2.0126e-02, -1.5869e-02],
        ...,
        [-1.0849e-02, -4.0161e-02, -3.2959e-03,  ...,  2.5742e-02,
          1.8883e-03,  2.2079e-02],
        [ 2.5894e-02, -2.2339e-02, -8.8272e-03,  ..., -3.7323e-02,
         -6.7329e-03,  1.3611e-02],
        [ 2.0264e-02, -4.0527e-02,  1.7090e-02,  ...,  6.0120e-02,
         -5.4077e-02,  6.8787e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4629, -3.3047,  0.1348,  ...,  4.2656, -1.3193, -1.4121]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:13:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To amuse results in a amusement
To improve results in a improvement
To fulfil results in a fulfilment
To invest results in a investment
To redevelop results in a redevelopment
To enroll results in a enrollment
To enhance results in a enhancement
To encourage results in a
2024-08-01 04:13:01 root INFO     [order_1_approx] starting weight calculation for To fulfil results in a fulfilment
To enroll results in a enrollment
To encourage results in a encouragement
To redevelop results in a redevelopment
To enhance results in a enhancement
To improve results in a improvement
To invest results in a investment
To amuse results in a
2024-08-01 04:13:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 04:16:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1151,  0.1799, -0.0934,  ...,  0.1458, -0.0804,  0.0212],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7910, -2.3789,  0.9395,  ...,  2.4609, -0.8057, -1.8438],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0277,  0.0060,  0.0195,  ...,  0.0049,  0.0518,  0.0403],
        [-0.0294,  0.0016, -0.0061,  ...,  0.0061, -0.0010,  0.0337],
        [-0.0331,  0.0009,  0.0329,  ...,  0.0120, -0.0032, -0.0005],
        ...,
        [ 0.1028, -0.0309, -0.0546,  ...,  0.0279, -0.0070, -0.0071],
        [ 0.0054, -0.0207,  0.0351,  ..., -0.0198,  0.0177,  0.0160],
        [ 0.0193,  0.0062,  0.0273,  ...,  0.0379, -0.0551,  0.0520]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1484, -2.3047, -0.2324,  ...,  3.1816, -0.7568, -1.7314]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:16:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To fulfil results in a fulfilment
To enroll results in a enrollment
To encourage results in a encouragement
To redevelop results in a redevelopment
To enhance results in a enhancement
To improve results in a improvement
To invest results in a investment
To amuse results in a
2024-08-01 04:16:04 root INFO     [order_1_approx] starting weight calculation for To enroll results in a enrollment
To amuse results in a amusement
To encourage results in a encouragement
To invest results in a investment
To enhance results in a enhancement
To fulfil results in a fulfilment
To redevelop results in a redevelopment
To improve results in a
2024-08-01 04:16:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 04:19:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0484,  0.1765, -0.0256,  ...,  0.0005, -0.1974, -0.0867],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3574, -2.9727, -0.0917,  ...,  4.6094, -3.8359, -2.9980],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0112, -0.0001,  0.0168,  ..., -0.0047, -0.0234,  0.0135],
        [-0.0110, -0.0069, -0.0025,  ...,  0.0281,  0.0255,  0.0124],
        [ 0.0240, -0.0167,  0.0245,  ...,  0.0061,  0.0019, -0.0017],
        ...,
        [-0.0271, -0.0021, -0.0070,  ...,  0.0067,  0.0314,  0.0109],
        [-0.0234,  0.0536, -0.0009,  ...,  0.0419,  0.0266, -0.0208],
        [ 0.0196, -0.0441,  0.0202,  ...,  0.0269, -0.0488,  0.0418]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9297, -2.1992,  0.0658,  ...,  4.4531, -4.2383, -2.2090]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:19:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To enroll results in a enrollment
To amuse results in a amusement
To encourage results in a encouragement
To invest results in a investment
To enhance results in a enhancement
To fulfil results in a fulfilment
To redevelop results in a redevelopment
To improve results in a
2024-08-01 04:19:07 root INFO     [order_1_approx] starting weight calculation for To improve results in a improvement
To enhance results in a enhancement
To encourage results in a encouragement
To enroll results in a enrollment
To amuse results in a amusement
To fulfil results in a fulfilment
To redevelop results in a redevelopment
To invest results in a
2024-08-01 04:19:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 04:22:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2505,  0.1675, -0.0725,  ...,  0.0352, -0.0884, -0.3130],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2744, -2.7227, -0.8057,  ...,  0.9316, -1.2656, -2.3242],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0063,  0.0068,  0.0349,  ..., -0.0013, -0.0176,  0.0004],
        [-0.0297,  0.0591, -0.0078,  ...,  0.0495,  0.0142,  0.0210],
        [-0.0123,  0.0061,  0.0152,  ..., -0.0131,  0.0073, -0.0301],
        ...,
        [-0.0015, -0.0142, -0.0063,  ...,  0.0359,  0.0015, -0.0006],
        [-0.0104,  0.0046, -0.0009,  ...,  0.0216,  0.0219,  0.0246],
        [ 0.0390, -0.0384, -0.0217,  ...,  0.0164, -0.0093,  0.0474]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5879, -2.7598, -0.3982,  ...,  0.8340, -1.7637, -2.6016]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:22:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To improve results in a improvement
To enhance results in a enhancement
To encourage results in a encouragement
To enroll results in a enrollment
To amuse results in a amusement
To fulfil results in a fulfilment
To redevelop results in a redevelopment
To invest results in a
2024-08-01 04:22:05 root INFO     [order_1_approx] starting weight calculation for To encourage results in a encouragement
To fulfil results in a fulfilment
To invest results in a investment
To improve results in a improvement
To redevelop results in a redevelopment
To enhance results in a enhancement
To amuse results in a amusement
To enroll results in a
2024-08-01 04:22:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 04:25:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0678,  0.1968, -0.2336,  ..., -0.0681,  0.0176, -0.4163],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3398, -2.9844, -0.6113,  ...,  1.5176, -1.4990, -4.7734],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0004, -0.0273,  0.0147,  ..., -0.0039,  0.0196,  0.0301],
        [-0.0267,  0.0385,  0.0029,  ...,  0.0383,  0.0431, -0.0182],
        [-0.0178, -0.0458,  0.0134,  ..., -0.0181, -0.0113, -0.0259],
        ...,
        [ 0.0461,  0.0208,  0.0109,  ...,  0.0159,  0.0280, -0.0179],
        [-0.0004,  0.0057, -0.0038,  ..., -0.0095,  0.0258,  0.0188],
        [-0.0090, -0.0254, -0.0048,  ...,  0.0153, -0.0229,  0.0214]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2681, -3.1758, -0.3262,  ...,  0.3828, -2.3164, -4.9844]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:25:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To encourage results in a encouragement
To fulfil results in a fulfilment
To invest results in a investment
To improve results in a improvement
To redevelop results in a redevelopment
To enhance results in a enhancement
To amuse results in a amusement
To enroll results in a
2024-08-01 04:25:07 root INFO     [order_1_approx] starting weight calculation for To invest results in a investment
To fulfil results in a fulfilment
To improve results in a improvement
To encourage results in a encouragement
To enhance results in a enhancement
To amuse results in a amusement
To enroll results in a enrollment
To redevelop results in a
2024-08-01 04:25:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 04:28:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1790,  0.1591, -0.2399,  ...,  0.0460, -0.0695, -0.1780],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0889, -5.2148, -0.2119,  ...,  1.6553, -1.8965, -3.7109],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0034, -0.0153,  0.0085,  ...,  0.0035,  0.0033,  0.0140],
        [-0.0547,  0.0304,  0.0140,  ...,  0.0065,  0.0312, -0.0259],
        [-0.0007,  0.0209,  0.0163,  ...,  0.0124,  0.0186, -0.0073],
        ...,
        [ 0.0314,  0.0043, -0.0007,  ...,  0.0057, -0.0345,  0.0314],
        [ 0.0163,  0.0451,  0.0349,  ..., -0.0046,  0.0249, -0.0110],
        [ 0.0098,  0.0197, -0.0064,  ...,  0.0052, -0.0150,  0.0273]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1631, -5.0547, -0.0481,  ...,  1.6387, -1.6992, -3.7012]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:28:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To invest results in a investment
To fulfil results in a fulfilment
To improve results in a improvement
To encourage results in a encouragement
To enhance results in a enhancement
To amuse results in a amusement
To enroll results in a enrollment
To redevelop results in a
2024-08-01 04:28:12 root INFO     [order_1_approx] starting weight calculation for To invest results in a investment
To enhance results in a enhancement
To enroll results in a enrollment
To encourage results in a encouragement
To amuse results in a amusement
To redevelop results in a redevelopment
To improve results in a improvement
To fulfil results in a
2024-08-01 04:28:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 04:31:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0627,  0.2861, -0.0886,  ...,  0.0482, -0.2407,  0.1173],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6602, -2.7578,  2.7910,  ...,  1.3320, -4.9297, -1.1562],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0088, -0.0173,  0.0255,  ...,  0.0054, -0.0108,  0.0186],
        [-0.0224,  0.0247,  0.0102,  ...,  0.0128, -0.0007,  0.0206],
        [ 0.0217, -0.0142, -0.0109,  ..., -0.0011, -0.0072, -0.0153],
        ...,
        [ 0.0201, -0.0020,  0.0185,  ...,  0.0223,  0.0190,  0.0258],
        [-0.0003,  0.0011,  0.0100,  ...,  0.0212,  0.0517,  0.0095],
        [-0.0141, -0.0053,  0.0043,  ...,  0.0184, -0.0398,  0.0385]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8320, -2.6348,  2.7480,  ...,  1.1240, -4.6680, -0.9312]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:31:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To invest results in a investment
To enhance results in a enhancement
To enroll results in a enrollment
To encourage results in a encouragement
To amuse results in a amusement
To redevelop results in a redevelopment
To improve results in a improvement
To fulfil results in a
2024-08-01 04:31:15 root INFO     total operator prediction time: 1454.6230194568634 seconds
2024-08-01 04:31:15 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on name - nationality
2024-08-01 04:31:15 root INFO     building operator name - nationality
2024-08-01 04:31:16 root INFO     [order_1_approx] starting weight calculation for fermi was italian
tolstoi was russian
maxwell was scottish
hegel was german
marx was german
darwin was english
galilei was italian
raphael was
2024-08-01 04:31:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 04:34:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1880, -0.0315,  0.1072,  ...,  0.0049, -0.2097, -0.0669],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.6406, -4.4141,  1.7422,  ..., -3.8789, -2.3320, -1.3008],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0303, -0.0479, -0.0356,  ...,  0.0102, -0.0182, -0.0684],
        [-0.0535, -0.0837, -0.0945,  ..., -0.0737,  0.0839,  0.0338],
        [ 0.0048,  0.0736,  0.1392,  ...,  0.0218, -0.0632, -0.0537],
        ...,
        [ 0.0359, -0.0305, -0.0933,  ...,  0.0065,  0.0277,  0.0346],
        [-0.0469, -0.0928, -0.0270,  ..., -0.0353,  0.0786,  0.0187],
        [-0.0108, -0.0340, -0.1238,  ..., -0.0186,  0.0555,  0.0825]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.5547, -3.4102,  1.3633,  ..., -3.1152, -1.2734, -1.0430]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:34:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for fermi was italian
tolstoi was russian
maxwell was scottish
hegel was german
marx was german
darwin was english
galilei was italian
raphael was
2024-08-01 04:34:21 root INFO     [order_1_approx] starting weight calculation for galilei was italian
tolstoi was russian
maxwell was scottish
hegel was german
raphael was italian
marx was german
fermi was italian
darwin was
2024-08-01 04:34:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 04:37:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1836,  0.1037, -0.0939,  ..., -0.1163,  0.1797, -0.0828],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.1289, -1.7637,  0.0278,  ..., -3.0957,  0.0371, -2.6406],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0081, -0.0003,  0.0085,  ..., -0.0216,  0.0355, -0.0288],
        [-0.0042,  0.0321, -0.0035,  ...,  0.0109, -0.0152, -0.0027],
        [ 0.0268,  0.0036,  0.0408,  ..., -0.0055, -0.0209,  0.0008],
        ...,
        [-0.0094, -0.0211, -0.0199,  ...,  0.0281,  0.0266,  0.0195],
        [-0.0248,  0.0113,  0.0228,  ...,  0.0123,  0.0287, -0.0012],
        [-0.0017,  0.0174, -0.0087,  ...,  0.0041, -0.0403,  0.0346]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.0352, -0.9971, -0.5005,  ..., -2.7441,  0.9321, -1.8281]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:37:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for galilei was italian
tolstoi was russian
maxwell was scottish
hegel was german
raphael was italian
marx was german
fermi was italian
darwin was
2024-08-01 04:37:25 root INFO     [order_1_approx] starting weight calculation for darwin was english
marx was german
galilei was italian
raphael was italian
hegel was german
maxwell was scottish
tolstoi was russian
fermi was
2024-08-01 04:37:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 04:40:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1224,  0.0573, -0.1324,  ...,  0.1213, -0.1439,  0.0662],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0273, -3.0410, -0.1228,  ..., -1.5732, -1.3145,  0.7104],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0598, -0.0577, -0.0126,  ...,  0.0767,  0.0244, -0.0736],
        [-0.0174,  0.0755, -0.0268,  ..., -0.0587, -0.0147,  0.0582],
        [ 0.0410, -0.0388,  0.0168,  ...,  0.0312, -0.0064, -0.0349],
        ...,
        [-0.0084,  0.0069,  0.0003,  ...,  0.0233,  0.0197,  0.0347],
        [-0.0219, -0.0037, -0.0207,  ...,  0.0343,  0.0159, -0.0010],
        [ 0.0145,  0.0469,  0.0186,  ..., -0.0456, -0.0150,  0.0330]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6689, -2.4375, -0.0355,  ..., -1.0527, -0.5400,  0.4702]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:40:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for darwin was english
marx was german
galilei was italian
raphael was italian
hegel was german
maxwell was scottish
tolstoi was russian
fermi was
2024-08-01 04:40:29 root INFO     [order_1_approx] starting weight calculation for darwin was english
fermi was italian
galilei was italian
maxwell was scottish
marx was german
raphael was italian
tolstoi was russian
hegel was
2024-08-01 04:40:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 04:43:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0818,  0.1399,  0.0916,  ...,  0.1005,  0.1234, -0.0024],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2041, -4.3789,  1.1895,  ..., -2.1875, -1.6074, -0.2144],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0014,  0.0282,  0.0065,  ..., -0.0310,  0.0008,  0.0206],
        [ 0.0135,  0.0007,  0.0093,  ...,  0.0050, -0.0223, -0.0288],
        [ 0.0201,  0.0245,  0.0339,  ..., -0.0209, -0.0118, -0.0110],
        ...,
        [ 0.0126, -0.0244,  0.0236,  ...,  0.0585, -0.0376,  0.0058],
        [-0.0078,  0.0067, -0.0083,  ...,  0.0043,  0.0119, -0.0042],
        [-0.0230,  0.0029, -0.0075,  ..., -0.0022, -0.0060, -0.0011]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2876, -2.7715,  0.6924,  ..., -1.5332, -1.5225,  0.8950]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:43:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for darwin was english
fermi was italian
galilei was italian
maxwell was scottish
marx was german
raphael was italian
tolstoi was russian
hegel was
2024-08-01 04:43:34 root INFO     [order_1_approx] starting weight calculation for marx was german
maxwell was scottish
darwin was english
raphael was italian
fermi was italian
hegel was german
tolstoi was russian
galilei was
2024-08-01 04:43:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 04:46:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1177, -0.2296, -0.2776,  ...,  0.0397, -0.0953, -0.1079],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7012, -3.5430,  1.4570,  ...,  0.6885, -2.5000,  0.9912],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0302, -0.0331, -0.0354,  ..., -0.0143, -0.0137, -0.0073],
        [ 0.0317,  0.0175, -0.1066,  ...,  0.0721, -0.0057,  0.1166],
        [ 0.0481,  0.0244,  0.1815,  ..., -0.0215,  0.0223, -0.1220],
        ...,
        [ 0.0450,  0.0125, -0.0316,  ...,  0.0138, -0.0097,  0.0753],
        [ 0.0013, -0.0490, -0.1418,  ..., -0.0115,  0.0074,  0.0576],
        [ 0.0039,  0.0276,  0.1833,  ...,  0.0128,  0.0383, -0.0869]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4277, -2.9688,  0.7642,  ...,  1.0312, -1.5713,  0.8198]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:46:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for marx was german
maxwell was scottish
darwin was english
raphael was italian
fermi was italian
hegel was german
tolstoi was russian
galilei was
2024-08-01 04:46:37 root INFO     [order_1_approx] starting weight calculation for tolstoi was russian
fermi was italian
darwin was english
marx was german
galilei was italian
raphael was italian
hegel was german
maxwell was
2024-08-01 04:46:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 04:49:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0139, -0.0821,  0.0339,  ..., -0.1044, -0.1137,  0.0467],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2891, -2.7891, -0.4961,  ..., -3.5859, -0.7852, -2.1055],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0096, -0.0037, -0.0320,  ...,  0.0001, -0.0096,  0.0282],
        [ 0.0075,  0.0295,  0.0179,  ..., -0.0071, -0.0366, -0.0222],
        [-0.0102,  0.0193,  0.0087,  ..., -0.0062,  0.0113,  0.0197],
        ...,
        [-0.0008, -0.0164, -0.0205,  ...,  0.0261, -0.0272,  0.0143],
        [ 0.0103, -0.0029,  0.0122,  ...,  0.0280,  0.0180,  0.0060],
        [-0.0206, -0.0061,  0.0085,  ..., -0.0121, -0.0298,  0.0135]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4570, -2.9297, -0.4109,  ..., -3.1367, -0.7139, -1.8066]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:49:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for tolstoi was russian
fermi was italian
darwin was english
marx was german
galilei was italian
raphael was italian
hegel was german
maxwell was
2024-08-01 04:49:41 root INFO     [order_1_approx] starting weight calculation for fermi was italian
galilei was italian
maxwell was scottish
tolstoi was russian
darwin was english
hegel was german
raphael was italian
marx was
2024-08-01 04:49:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 04:52:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0419,  0.0844, -0.1097,  ...,  0.1482,  0.1584,  0.0720],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4126, -5.5703, -0.1348,  ..., -3.9434,  1.2812, -1.4238],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0102,  0.0009,  0.0289,  ..., -0.0080, -0.0285,  0.0110],
        [ 0.0098, -0.0081,  0.0999,  ...,  0.0186, -0.0931,  0.0641],
        [ 0.0288,  0.0069, -0.0844,  ..., -0.0378,  0.0324, -0.0331],
        ...,
        [ 0.0007, -0.0277,  0.0768,  ...,  0.0287, -0.0489,  0.0521],
        [-0.0099, -0.0130,  0.0474,  ...,  0.0327,  0.0150, -0.0047],
        [ 0.0365,  0.0220, -0.0255,  ..., -0.0016, -0.0352,  0.0407]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7383, -3.8711, -0.9370,  ..., -2.7930,  1.8047, -1.2197]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:52:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for fermi was italian
galilei was italian
maxwell was scottish
tolstoi was russian
darwin was english
hegel was german
raphael was italian
marx was
2024-08-01 04:52:44 root INFO     [order_1_approx] starting weight calculation for maxwell was scottish
raphael was italian
fermi was italian
hegel was german
galilei was italian
marx was german
darwin was english
tolstoi was
2024-08-01 04:52:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 04:55:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2883,  0.1788, -0.2012,  ..., -0.1812, -0.0806, -0.1088],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4033, -3.6309,  0.5400,  ..., -5.7773, -0.2998, -1.9521],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0160, -0.0732, -0.0218,  ..., -0.0214,  0.0312,  0.0271],
        [ 0.0257, -0.0556, -0.0274,  ...,  0.0224,  0.1107, -0.0064],
        [ 0.0474,  0.1665,  0.0936,  ...,  0.0096, -0.1381, -0.0528],
        ...,
        [ 0.0076, -0.0746, -0.0103,  ...,  0.0521,  0.0672,  0.0356],
        [-0.0638, -0.0756, -0.0349,  ...,  0.0039,  0.0708,  0.0171],
        [ 0.0471, -0.0079, -0.0058,  ...,  0.0264,  0.0157, -0.0118]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8110, -2.7617,  0.4441,  ..., -5.4688, -0.7451, -0.9771]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:55:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for maxwell was scottish
raphael was italian
fermi was italian
hegel was german
galilei was italian
marx was german
darwin was english
tolstoi was
2024-08-01 04:55:45 root INFO     total operator prediction time: 1469.395579814911 seconds
2024-08-01 04:55:45 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on country - language
2024-08-01 04:55:45 root INFO     building operator country - language
2024-08-01 04:55:45 root INFO     [order_1_approx] starting weight calculation for The country of jordan primarily speaks the language of arabic
The country of brazil primarily speaks the language of portuguese
The country of mexico primarily speaks the language of spanish
The country of belize primarily speaks the language of english
The country of ethiopia primarily speaks the language of amharic
The country of jamaica primarily speaks the language of english
The country of chile primarily speaks the language of spanish
The country of cuba primarily speaks the language of
2024-08-01 04:55:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 04:58:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0831, -0.2166,  0.0316,  ..., -0.1006, -0.0644, -0.0255],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9561, -2.4727,  1.4883,  ...,  1.2031, -0.1387, -1.7930],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-1.1023e-01, -1.1127e-01,  1.7456e-02,  ..., -7.2388e-02,
         -3.4943e-02, -2.2888e-05],
        [-2.0920e-02,  9.9792e-03,  1.3733e-04,  ..., -2.9663e-02,
         -1.7838e-02,  2.3315e-02],
        [ 6.1218e-02,  1.5552e-01,  7.5684e-02,  ...,  7.3425e-02,
          6.8665e-02, -3.7170e-02],
        ...,
        [ 1.1218e-01,  1.8115e-01,  1.0406e-02,  ...,  1.0541e-01,
          6.1340e-02, -5.0476e-02],
        [-2.1805e-02, -3.8757e-02, -3.0807e-02,  ..., -1.1887e-02,
          4.3762e-02,  4.9805e-02],
        [ 3.9001e-02,  4.9835e-02,  6.1035e-04,  ...,  1.8204e-02,
          2.4811e-02,  4.4327e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0820, -1.6309,  1.4883,  ...,  0.4585, -0.7383, -1.8633]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:58:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of jordan primarily speaks the language of arabic
The country of brazil primarily speaks the language of portuguese
The country of mexico primarily speaks the language of spanish
The country of belize primarily speaks the language of english
The country of ethiopia primarily speaks the language of amharic
The country of jamaica primarily speaks the language of english
The country of chile primarily speaks the language of spanish
The country of cuba primarily speaks the language of
2024-08-01 04:58:46 root INFO     [order_1_approx] starting weight calculation for The country of belize primarily speaks the language of english
The country of chile primarily speaks the language of spanish
The country of brazil primarily speaks the language of portuguese
The country of jamaica primarily speaks the language of english
The country of jordan primarily speaks the language of arabic
The country of mexico primarily speaks the language of spanish
The country of cuba primarily speaks the language of spanish
The country of ethiopia primarily speaks the language of
2024-08-01 04:58:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 05:01:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2744, -0.1495, -0.1772,  ...,  0.1055, -0.1075,  0.1086],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2378, -3.0117,  2.9961,  ..., -2.3398, -1.4648, -2.9180],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0145, -0.0239,  0.0125,  ...,  0.0195,  0.0121,  0.0372],
        [ 0.0091, -0.0084,  0.0029,  ..., -0.0017,  0.0096,  0.0205],
        [-0.0185,  0.0349,  0.0144,  ..., -0.0042, -0.0186, -0.0465],
        ...,
        [ 0.0084,  0.0006, -0.0076,  ..., -0.0070, -0.0052, -0.0014],
        [ 0.0013, -0.0030, -0.0043,  ...,  0.0102,  0.0023,  0.0045],
        [ 0.0104, -0.0342,  0.0019,  ...,  0.0093,  0.0055,  0.0376]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0057, -2.7695,  2.6719,  ..., -2.3633, -1.4590, -2.4258]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:01:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of belize primarily speaks the language of english
The country of chile primarily speaks the language of spanish
The country of brazil primarily speaks the language of portuguese
The country of jamaica primarily speaks the language of english
The country of jordan primarily speaks the language of arabic
The country of mexico primarily speaks the language of spanish
The country of cuba primarily speaks the language of spanish
The country of ethiopia primarily speaks the language of
2024-08-01 05:01:48 root INFO     [order_1_approx] starting weight calculation for The country of jordan primarily speaks the language of arabic
The country of cuba primarily speaks the language of spanish
The country of mexico primarily speaks the language of spanish
The country of brazil primarily speaks the language of portuguese
The country of ethiopia primarily speaks the language of amharic
The country of belize primarily speaks the language of english
The country of chile primarily speaks the language of spanish
The country of jamaica primarily speaks the language of
2024-08-01 05:01:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 05:04:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0709, -0.0208, -0.1780,  ...,  0.0997, -0.1180, -0.1440],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1074,  0.3042,  1.9414,  ...,  0.9956,  0.8848, -1.7705],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0011,  0.0160,  0.0006,  ...,  0.0063, -0.0196,  0.0085],
        [-0.0100,  0.0011,  0.0169,  ..., -0.0121,  0.0095,  0.0008],
        [-0.0083, -0.0086,  0.0532,  ..., -0.0239,  0.0112, -0.0071],
        ...,
        [-0.0034, -0.0228,  0.0557,  ..., -0.0355,  0.0226, -0.0017],
        [-0.0172,  0.0123, -0.0015,  ...,  0.0043,  0.0351, -0.0011],
        [ 0.0122, -0.0266,  0.0070,  ..., -0.0102, -0.0174,  0.0066]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2227,  0.2098,  1.7578,  ...,  0.3232,  0.9604, -1.8008]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:04:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of jordan primarily speaks the language of arabic
The country of cuba primarily speaks the language of spanish
The country of mexico primarily speaks the language of spanish
The country of brazil primarily speaks the language of portuguese
The country of ethiopia primarily speaks the language of amharic
The country of belize primarily speaks the language of english
The country of chile primarily speaks the language of spanish
The country of jamaica primarily speaks the language of
2024-08-01 05:04:55 root INFO     [order_1_approx] starting weight calculation for The country of chile primarily speaks the language of spanish
The country of belize primarily speaks the language of english
The country of mexico primarily speaks the language of spanish
The country of ethiopia primarily speaks the language of amharic
The country of cuba primarily speaks the language of spanish
The country of jamaica primarily speaks the language of english
The country of brazil primarily speaks the language of portuguese
The country of jordan primarily speaks the language of
2024-08-01 05:04:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 05:07:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2688,  0.1986, -0.1116,  ...,  0.1735, -0.2053, -0.0845],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.2207, -2.4297,  0.7837,  ..., -0.6675,  0.6943, -1.1797],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0182,  0.0027, -0.0142,  ...,  0.0371,  0.0130,  0.0027],
        [-0.0022,  0.0213, -0.0002,  ...,  0.0131, -0.0002, -0.0005],
        [-0.0273,  0.0160,  0.0374,  ..., -0.0339,  0.0063,  0.0010],
        ...,
        [-0.0370,  0.0168, -0.0015,  ..., -0.0078, -0.0122, -0.0082],
        [-0.0077, -0.0015,  0.0023,  ..., -0.0073,  0.0244,  0.0057],
        [-0.0071, -0.0078, -0.0026,  ..., -0.0028, -0.0083, -0.0064]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.2441, -2.2832,  1.1006,  ..., -0.3872,  0.7183, -1.0371]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:08:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of chile primarily speaks the language of spanish
The country of belize primarily speaks the language of english
The country of mexico primarily speaks the language of spanish
The country of ethiopia primarily speaks the language of amharic
The country of cuba primarily speaks the language of spanish
The country of jamaica primarily speaks the language of english
The country of brazil primarily speaks the language of portuguese
The country of jordan primarily speaks the language of
2024-08-01 05:08:01 root INFO     [order_1_approx] starting weight calculation for The country of ethiopia primarily speaks the language of amharic
The country of chile primarily speaks the language of spanish
The country of cuba primarily speaks the language of spanish
The country of brazil primarily speaks the language of portuguese
The country of belize primarily speaks the language of english
The country of jordan primarily speaks the language of arabic
The country of jamaica primarily speaks the language of english
The country of mexico primarily speaks the language of
2024-08-01 05:08:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 05:11:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0753,  0.1514, -0.0880,  ...,  0.1611,  0.0423, -0.2223],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6943, -3.1875,  0.8354,  ...,  0.5308, -0.4805, -2.3301],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0160, -0.0055,  0.0162,  ...,  0.0102, -0.0109,  0.0042],
        [ 0.0013,  0.0046,  0.0109,  ..., -0.0070, -0.0201,  0.0077],
        [-0.0011,  0.0168,  0.0092,  ..., -0.0010,  0.0396, -0.0258],
        ...,
        [-0.0220,  0.0127, -0.0120,  ...,  0.0094,  0.0546, -0.0014],
        [-0.0024, -0.0034,  0.0137,  ...,  0.0172,  0.0225,  0.0050],
        [ 0.0099, -0.0120, -0.0148,  ..., -0.0168, -0.0321,  0.0066]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4512, -2.8438,  0.3591,  ..., -0.0073, -0.6030, -1.9307]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:11:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of ethiopia primarily speaks the language of amharic
The country of chile primarily speaks the language of spanish
The country of cuba primarily speaks the language of spanish
The country of brazil primarily speaks the language of portuguese
The country of belize primarily speaks the language of english
The country of jordan primarily speaks the language of arabic
The country of jamaica primarily speaks the language of english
The country of mexico primarily speaks the language of
2024-08-01 05:11:08 root INFO     [order_1_approx] starting weight calculation for The country of jamaica primarily speaks the language of english
The country of jordan primarily speaks the language of arabic
The country of belize primarily speaks the language of english
The country of chile primarily speaks the language of spanish
The country of ethiopia primarily speaks the language of amharic
The country of mexico primarily speaks the language of spanish
The country of cuba primarily speaks the language of spanish
The country of brazil primarily speaks the language of
2024-08-01 05:11:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 05:14:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0923,  0.0051, -0.0883,  ...,  0.1729, -0.0569, -0.1125],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9561, -3.8438,  0.5142,  ...,  0.4829,  0.3213, -2.0391],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0250, -0.0349, -0.0133,  ...,  0.0222,  0.0096,  0.0376],
        [ 0.0134,  0.0132, -0.0067,  ..., -0.0224,  0.0088, -0.0117],
        [-0.0336, -0.0147,  0.0196,  ..., -0.0070,  0.0176, -0.0018],
        ...,
        [-0.0472,  0.0199, -0.0034,  ...,  0.0064,  0.0082, -0.0226],
        [ 0.0178, -0.0061, -0.0051,  ...,  0.0091,  0.0135,  0.0143],
        [ 0.0164, -0.0092,  0.0062,  ...,  0.0030, -0.0165,  0.0045]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3262, -3.3809,  0.6392,  ...,  0.3457, -0.0552, -1.7207]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:14:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of jamaica primarily speaks the language of english
The country of jordan primarily speaks the language of arabic
The country of belize primarily speaks the language of english
The country of chile primarily speaks the language of spanish
The country of ethiopia primarily speaks the language of amharic
The country of mexico primarily speaks the language of spanish
The country of cuba primarily speaks the language of spanish
The country of brazil primarily speaks the language of
2024-08-01 05:14:13 root INFO     [order_1_approx] starting weight calculation for The country of brazil primarily speaks the language of portuguese
The country of jamaica primarily speaks the language of english
The country of jordan primarily speaks the language of arabic
The country of mexico primarily speaks the language of spanish
The country of cuba primarily speaks the language of spanish
The country of ethiopia primarily speaks the language of amharic
The country of chile primarily speaks the language of spanish
The country of belize primarily speaks the language of
2024-08-01 05:14:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 05:17:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0540,  0.0475, -0.1920,  ...,  0.1582, -0.1134,  0.0974],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8711, -1.0020,  0.8159,  ...,  1.1562,  1.8613, -3.4824],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0066, -0.0088, -0.0230,  ..., -0.0017,  0.0307,  0.0137],
        [-0.0021,  0.0693,  0.0291,  ..., -0.0025, -0.0110, -0.0557],
        [-0.0306,  0.0105,  0.0326,  ..., -0.0020, -0.0068, -0.0344],
        ...,
        [ 0.0039,  0.0679,  0.0490,  ...,  0.0003, -0.0478, -0.0539],
        [-0.0013, -0.0004, -0.0154,  ...,  0.0028,  0.0575,  0.0103],
        [ 0.0123, -0.0126, -0.0154,  ..., -0.0213, -0.0181, -0.0028]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0352, -0.7334,  1.1035,  ...,  0.8882,  2.1367, -3.6309]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:17:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of brazil primarily speaks the language of portuguese
The country of jamaica primarily speaks the language of english
The country of jordan primarily speaks the language of arabic
The country of mexico primarily speaks the language of spanish
The country of cuba primarily speaks the language of spanish
The country of ethiopia primarily speaks the language of amharic
The country of chile primarily speaks the language of spanish
The country of belize primarily speaks the language of
2024-08-01 05:17:18 root INFO     [order_1_approx] starting weight calculation for The country of belize primarily speaks the language of english
The country of brazil primarily speaks the language of portuguese
The country of cuba primarily speaks the language of spanish
The country of mexico primarily speaks the language of spanish
The country of jordan primarily speaks the language of arabic
The country of jamaica primarily speaks the language of english
The country of ethiopia primarily speaks the language of amharic
The country of chile primarily speaks the language of
2024-08-01 05:17:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 05:20:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0654, -0.2644, -0.2344,  ...,  0.1073, -0.1171, -0.0471],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2347, -2.8301,  2.1602,  ...,  0.0909, -1.2920, -2.1152],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0662, -0.0962, -0.0423,  ...,  0.0412,  0.0391,  0.0199],
        [ 0.0171, -0.0437, -0.0253,  ...,  0.0258,  0.0214,  0.0243],
        [-0.0746,  0.0676,  0.0646,  ..., -0.0299, -0.0252, -0.0540],
        ...,
        [-0.0236,  0.0533,  0.0205,  ..., -0.0215, -0.0193, -0.0005],
        [ 0.0392, -0.0457, -0.0095,  ...,  0.0352,  0.0486,  0.0215],
        [ 0.0097, -0.0457, -0.0319,  ...,  0.0180, -0.0162,  0.0168]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.3740, -2.5488,  2.3398,  ...,  0.3916, -1.9893, -1.9443]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:20:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of belize primarily speaks the language of english
The country of brazil primarily speaks the language of portuguese
The country of cuba primarily speaks the language of spanish
The country of mexico primarily speaks the language of spanish
The country of jordan primarily speaks the language of arabic
The country of jamaica primarily speaks the language of english
The country of ethiopia primarily speaks the language of amharic
The country of chile primarily speaks the language of
2024-08-01 05:20:18 root INFO     total operator prediction time: 1472.9533529281616 seconds
2024-08-01 05:20:18 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - shelter
2024-08-01 05:20:18 root INFO     building operator animal - shelter
2024-08-01 05:20:18 root INFO     [order_1_approx] starting weight calculation for The place raven lives in is called nest
The place snake lives in is called nest
The place hamster lives in is called nest
The place crow lives in is called nest
The place ape lives in is called grove
The place wasp lives in is called nest
The place baboon lives in is called grove
The place cricket lives in is called
2024-08-01 05:20:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 05:23:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0247,  0.2197,  0.0895,  ...,  0.0958,  0.0885, -0.2095],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5312, -7.3164,  1.9717,  ..., -0.8877, -1.0547, -0.6465],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0222, -0.1624, -0.0151,  ..., -0.0488,  0.0671, -0.0018],
        [ 0.0048, -0.0662, -0.0752,  ..., -0.0204, -0.0195,  0.0515],
        [-0.0313,  0.0450,  0.0687,  ..., -0.0404, -0.0742, -0.0018],
        ...,
        [-0.0374, -0.0610, -0.0324,  ...,  0.0881, -0.0160,  0.0185],
        [ 0.0063,  0.0748,  0.0333,  ...,  0.0620, -0.0282, -0.0320],
        [-0.0315, -0.0318, -0.0270,  ..., -0.0270,  0.0209,  0.0215]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7539, -7.1836,  1.6309,  ..., -0.9819, -1.5098, -0.1599]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:23:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place raven lives in is called nest
The place snake lives in is called nest
The place hamster lives in is called nest
The place crow lives in is called nest
The place ape lives in is called grove
The place wasp lives in is called nest
The place baboon lives in is called grove
The place cricket lives in is called
2024-08-01 05:23:20 root INFO     [order_1_approx] starting weight calculation for The place hamster lives in is called nest
The place baboon lives in is called grove
The place cricket lives in is called nest
The place ape lives in is called grove
The place raven lives in is called nest
The place crow lives in is called nest
The place wasp lives in is called nest
The place snake lives in is called
2024-08-01 05:23:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 05:26:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0158,  0.2656,  0.0052,  ..., -0.0750, -0.1094, -0.0643],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.4648, -7.5391, -0.0098,  ..., -2.7246, -1.1709, -1.2383],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0324,  0.0035, -0.0032,  ..., -0.0364,  0.0027, -0.0060],
        [-0.0056, -0.0715, -0.0602,  ...,  0.0571, -0.0162,  0.0341],
        [-0.0111,  0.0080,  0.0428,  ..., -0.0248, -0.0465,  0.0421],
        ...,
        [ 0.0017, -0.0022, -0.0191,  ...,  0.0442, -0.0192,  0.0128],
        [ 0.0015,  0.0054,  0.0319,  ...,  0.0262,  0.0238,  0.0110],
        [-0.0258, -0.0492, -0.0169,  ...,  0.0096, -0.0144,  0.0169]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.9922, -7.4883,  0.1556,  ..., -2.6934, -1.3281, -1.2041]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:26:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place hamster lives in is called nest
The place baboon lives in is called grove
The place cricket lives in is called nest
The place ape lives in is called grove
The place raven lives in is called nest
The place crow lives in is called nest
The place wasp lives in is called nest
The place snake lives in is called
2024-08-01 05:26:18 root INFO     [order_1_approx] starting weight calculation for The place raven lives in is called nest
The place cricket lives in is called nest
The place snake lives in is called nest
The place baboon lives in is called grove
The place wasp lives in is called nest
The place crow lives in is called nest
The place hamster lives in is called nest
The place ape lives in is called
2024-08-01 05:26:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 05:29:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1954, -0.0468, -0.0730,  ..., -0.0639, -0.3552, -0.2325],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.0391, -8.3984, -0.2520,  ..., -2.5645, -3.4355,  1.8281],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0367,  0.0593,  0.0436,  ...,  0.0390,  0.0607, -0.0598],
        [-0.0279, -0.0813, -0.0833,  ..., -0.0580, -0.0627,  0.0687],
        [-0.0121,  0.0217,  0.0109,  ..., -0.0009,  0.0143, -0.0030],
        ...,
        [-0.0043, -0.0180, -0.0354,  ..., -0.0102, -0.0218,  0.0536],
        [ 0.0065, -0.0084,  0.0027,  ..., -0.0205,  0.0432,  0.0130],
        [-0.0120, -0.0233, -0.0106,  ..., -0.0252, -0.0092,  0.0856]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4023, -6.1953, -0.8530,  ..., -1.4082, -3.5723,  2.3438]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:29:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place raven lives in is called nest
The place cricket lives in is called nest
The place snake lives in is called nest
The place baboon lives in is called grove
The place wasp lives in is called nest
The place crow lives in is called nest
The place hamster lives in is called nest
The place ape lives in is called
2024-08-01 05:29:19 root INFO     [order_1_approx] starting weight calculation for The place snake lives in is called nest
The place ape lives in is called grove
The place hamster lives in is called nest
The place cricket lives in is called nest
The place baboon lives in is called grove
The place raven lives in is called nest
The place wasp lives in is called nest
The place crow lives in is called
2024-08-01 05:29:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 05:32:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3125,  0.0798, -0.0629,  ..., -0.1758, -0.2169,  0.0484],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.9805, -8.3047, -0.7510,  ..., -2.8555, -2.2949, -0.7383],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0064,  0.0261, -0.0692,  ..., -0.0278,  0.0551, -0.0104],
        [ 0.0102, -0.0199,  0.0988,  ...,  0.0285, -0.0633,  0.0136],
        [-0.0105,  0.0065,  0.0157,  ...,  0.0037, -0.0070, -0.0219],
        ...,
        [ 0.0017, -0.0303,  0.0563,  ...,  0.0324, -0.0585, -0.0061],
        [-0.0306, -0.0229, -0.0182,  ...,  0.0052,  0.0272,  0.0193],
        [-0.0150,  0.0052,  0.0041,  ..., -0.0276,  0.0041,  0.0460]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.1562, -7.7539, -0.9170,  ..., -2.2227, -2.0312, -0.9082]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:32:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place snake lives in is called nest
The place ape lives in is called grove
The place hamster lives in is called nest
The place cricket lives in is called nest
The place baboon lives in is called grove
The place raven lives in is called nest
The place wasp lives in is called nest
The place crow lives in is called
2024-08-01 05:32:23 root INFO     [order_1_approx] starting weight calculation for The place cricket lives in is called nest
The place wasp lives in is called nest
The place crow lives in is called nest
The place hamster lives in is called nest
The place snake lives in is called nest
The place ape lives in is called grove
The place raven lives in is called nest
The place baboon lives in is called
2024-08-01 05:32:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 05:35:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4263,  0.0446,  0.1252,  ..., -0.0349, -0.4238, -0.0723],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.9609, -7.5156, -0.2910,  ..., -2.6719, -3.2227,  0.3340],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0625, -0.0050,  0.0143,  ...,  0.0526, -0.0125, -0.0420],
        [-0.0122,  0.0722, -0.0248,  ...,  0.0032, -0.0126,  0.0280],
        [-0.0060, -0.0069,  0.0299,  ...,  0.0229, -0.0109, -0.0481],
        ...,
        [-0.0302,  0.0255, -0.0255,  ...,  0.0683, -0.0042,  0.0040],
        [-0.0092, -0.0089, -0.0099,  ..., -0.0215,  0.0076,  0.0603],
        [-0.0134,  0.0110, -0.0019,  ...,  0.0088, -0.0200,  0.0060]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 6.5625, -8.1250, -0.1760,  ..., -2.8340, -2.8574,  0.1738]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:35:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place cricket lives in is called nest
The place wasp lives in is called nest
The place crow lives in is called nest
The place hamster lives in is called nest
The place snake lives in is called nest
The place ape lives in is called grove
The place raven lives in is called nest
The place baboon lives in is called
2024-08-01 05:35:26 root INFO     [order_1_approx] starting weight calculation for The place snake lives in is called nest
The place hamster lives in is called nest
The place cricket lives in is called nest
The place wasp lives in is called nest
The place crow lives in is called nest
The place baboon lives in is called grove
The place ape lives in is called grove
The place raven lives in is called
2024-08-01 05:35:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 05:38:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1486,  0.0394, -0.1469,  ...,  0.0679, -0.0726, -0.0274],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.6953, -6.9648,  0.9102,  ..., -1.9180, -2.2676, -0.0381],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0335,  0.0087, -0.0150,  ..., -0.0097,  0.0190, -0.0139],
        [-0.0134, -0.0279,  0.0041,  ...,  0.0069, -0.0138,  0.0170],
        [-0.0323, -0.0093,  0.0003,  ..., -0.0457, -0.0088, -0.0405],
        ...,
        [-0.0415, -0.0223,  0.0182,  ...,  0.0383, -0.0201, -0.0433],
        [ 0.0093, -0.0538, -0.0604,  ...,  0.0295,  0.0549,  0.0242],
        [-0.0046,  0.0455,  0.0459,  ..., -0.0173, -0.0040, -0.0031]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.3086, -7.1328,  0.9502,  ..., -2.1289, -2.5918, -0.3928]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:38:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place snake lives in is called nest
The place hamster lives in is called nest
The place cricket lives in is called nest
The place wasp lives in is called nest
The place crow lives in is called nest
The place baboon lives in is called grove
The place ape lives in is called grove
The place raven lives in is called
2024-08-01 05:38:29 root INFO     [order_1_approx] starting weight calculation for The place baboon lives in is called grove
The place ape lives in is called grove
The place cricket lives in is called nest
The place crow lives in is called nest
The place snake lives in is called nest
The place raven lives in is called nest
The place hamster lives in is called nest
The place wasp lives in is called
2024-08-01 05:38:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 05:41:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2468, -0.1665,  0.3174,  ...,  0.0765,  0.0122, -0.0516],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.6797, -7.5312,  2.3789,  ..., -3.0703, -0.5254,  0.9023],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0565, -0.0053, -0.0161,  ...,  0.0118,  0.0188, -0.0039],
        [-0.0682, -0.0447,  0.0160,  ...,  0.0048, -0.0074, -0.0102],
        [ 0.0124,  0.0500, -0.0054,  ...,  0.0236, -0.0446,  0.0287],
        ...,
        [-0.0292, -0.0074,  0.0195,  ..., -0.0062, -0.0125, -0.0122],
        [ 0.0511,  0.0525,  0.0039,  ...,  0.0520,  0.0108,  0.0180],
        [-0.0283, -0.0410, -0.0137,  ..., -0.0238, -0.0001,  0.0186]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.1367, -6.7070,  1.2422,  ..., -2.7363, -1.2637,  1.3555]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:41:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place baboon lives in is called grove
The place ape lives in is called grove
The place cricket lives in is called nest
The place crow lives in is called nest
The place snake lives in is called nest
The place raven lives in is called nest
The place hamster lives in is called nest
The place wasp lives in is called
2024-08-01 05:41:32 root INFO     [order_1_approx] starting weight calculation for The place snake lives in is called nest
The place ape lives in is called grove
The place crow lives in is called nest
The place baboon lives in is called grove
The place wasp lives in is called nest
The place cricket lives in is called nest
The place raven lives in is called nest
The place hamster lives in is called
2024-08-01 05:41:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 05:44:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1521, -0.0895,  0.1497,  ..., -0.0265, -0.1436,  0.0294],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7891, -6.7109,  0.1504,  ..., -2.6172, -2.4805,  1.6660],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0320, -0.0246,  0.0405,  ...,  0.0484, -0.0462, -0.0163],
        [-0.0189,  0.0347,  0.0097,  ..., -0.0180, -0.0071,  0.0010],
        [-0.0179,  0.0018,  0.0329,  ..., -0.0273, -0.0106,  0.0027],
        ...,
        [-0.0332, -0.0103,  0.0021,  ...,  0.0290,  0.0211,  0.0208],
        [ 0.0285,  0.0088, -0.0152,  ...,  0.0228,  0.0237,  0.0358],
        [-0.0518, -0.0103, -0.0081,  ..., -0.0291,  0.0141,  0.0262]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4629, -7.1094,  0.5654,  ..., -2.6113, -2.8359,  1.5439]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:44:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place snake lives in is called nest
The place ape lives in is called grove
The place crow lives in is called nest
The place baboon lives in is called grove
The place wasp lives in is called nest
The place cricket lives in is called nest
The place raven lives in is called nest
The place hamster lives in is called
2024-08-01 05:44:35 root INFO     total operator prediction time: 1457.2350325584412 seconds
2024-08-01 05:44:35 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on male - female
2024-08-01 05:44:35 root INFO     building operator male - female
2024-08-01 05:44:35 root INFO     [order_1_approx] starting weight calculation for A female prince is known as a princess
A female grandfather is known as a grandmother
A female waiter is known as a waitress
A female buck is known as a doe
A female duke is known as a duchess
A female stepfather is known as a stepmother
A female daddy is known as a mommy
A female uncle is known as a
2024-08-01 05:44:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 05:47:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0974,  0.1960,  0.0889,  ..., -0.0134, -0.2339,  0.0599],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8945, -0.5723, -2.0195,  ...,  0.9551, -3.7266, -1.5254],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0498, -0.0871, -0.0097,  ...,  0.0069, -0.0317,  0.0284],
        [ 0.0531,  0.0181,  0.0368,  ...,  0.0237,  0.0692,  0.0047],
        [ 0.0556,  0.0537,  0.0267,  ..., -0.0435,  0.0665, -0.0864],
        ...,
        [-0.0117, -0.0229,  0.0040,  ..., -0.0273, -0.0168,  0.0443],
        [-0.0192, -0.0436, -0.0082,  ..., -0.0200, -0.0255,  0.0314],
        [-0.0264, -0.0147, -0.0076,  ...,  0.0176, -0.0355,  0.0429]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2773, -0.4722, -2.8887,  ...,  0.5938, -3.6367, -1.0879]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:47:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female prince is known as a princess
A female grandfather is known as a grandmother
A female waiter is known as a waitress
A female buck is known as a doe
A female duke is known as a duchess
A female stepfather is known as a stepmother
A female daddy is known as a mommy
A female uncle is known as a
2024-08-01 05:47:38 root INFO     [order_1_approx] starting weight calculation for A female stepfather is known as a stepmother
A female daddy is known as a mommy
A female duke is known as a duchess
A female waiter is known as a waitress
A female uncle is known as a aunt
A female prince is known as a princess
A female grandfather is known as a grandmother
A female buck is known as a
2024-08-01 05:47:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 05:50:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3403,  0.0723,  0.1326,  ...,  0.0333, -0.1177,  0.2167],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5898, -3.3516, -0.5859,  ...,  1.4365, -5.0000,  0.0874],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0377,  0.0369,  0.0214,  ...,  0.0226,  0.0226, -0.0232],
        [ 0.0587,  0.0483, -0.0248,  ...,  0.0483,  0.0331,  0.0285],
        [-0.0116, -0.0196,  0.0452,  ..., -0.0041, -0.0259,  0.0152],
        ...,
        [-0.0215, -0.0311,  0.0246,  ...,  0.0234,  0.0233,  0.0135],
        [-0.0243, -0.0194,  0.0432,  ..., -0.0195,  0.0264, -0.0061],
        [ 0.0352,  0.0404, -0.0632,  ..., -0.0142,  0.0079, -0.0216]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6074, -3.3145, -0.9727,  ...,  1.7832, -4.8359,  0.4614]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:50:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female stepfather is known as a stepmother
A female daddy is known as a mommy
A female duke is known as a duchess
A female waiter is known as a waitress
A female uncle is known as a aunt
A female prince is known as a princess
A female grandfather is known as a grandmother
A female buck is known as a
2024-08-01 05:50:40 root INFO     [order_1_approx] starting weight calculation for A female duke is known as a duchess
A female prince is known as a princess
A female buck is known as a doe
A female uncle is known as a aunt
A female stepfather is known as a stepmother
A female grandfather is known as a grandmother
A female waiter is known as a waitress
A female daddy is known as a
2024-08-01 05:50:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 05:53:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0605, -0.1632, -0.0385,  ...,  0.0358, -0.3901,  0.0016],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.3984, -2.7031, -2.6777,  ...,  1.6758, -3.5098, -1.6338],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0170,  0.0016,  0.0013,  ...,  0.0319, -0.0206, -0.0022],
        [ 0.0466, -0.0328, -0.0634,  ...,  0.0492,  0.0213, -0.0334],
        [-0.0074, -0.0120, -0.0369,  ...,  0.0079,  0.0067, -0.0015],
        ...,
        [ 0.0159, -0.0217,  0.0152,  ..., -0.0122, -0.0155, -0.0327],
        [ 0.0396, -0.0284, -0.0230,  ..., -0.0283,  0.0219, -0.0107],
        [-0.0356,  0.0096,  0.0095,  ...,  0.0019,  0.0408,  0.0348]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8145, -1.0801, -2.1660,  ...,  1.9541, -2.8535, -1.8555]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:53:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female duke is known as a duchess
A female prince is known as a princess
A female buck is known as a doe
A female uncle is known as a aunt
A female stepfather is known as a stepmother
A female grandfather is known as a grandmother
A female waiter is known as a waitress
A female daddy is known as a
2024-08-01 05:53:40 root INFO     [order_1_approx] starting weight calculation for A female daddy is known as a mommy
A female waiter is known as a waitress
A female grandfather is known as a grandmother
A female buck is known as a doe
A female duke is known as a duchess
A female stepfather is known as a stepmother
A female uncle is known as a aunt
A female prince is known as a
2024-08-01 05:53:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 05:56:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0972,  0.0163,  0.0431,  ..., -0.1177, -0.1782,  0.1782],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4922, -4.7734, -1.3633,  ..., -1.9473, -0.5088,  0.7148],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0490,  0.0080,  0.0010,  ..., -0.0277, -0.0032,  0.0017],
        [ 0.0170,  0.0408, -0.0167,  ...,  0.0466,  0.0288, -0.0051],
        [ 0.0068,  0.0275,  0.0444,  ...,  0.0159,  0.0029, -0.0153],
        ...,
        [-0.0155, -0.0035, -0.0399,  ...,  0.0145, -0.0174,  0.0064],
        [-0.0273, -0.0481,  0.0226,  ...,  0.0151,  0.0099,  0.0147],
        [-0.0047, -0.0477,  0.0005,  ..., -0.0300, -0.0285,  0.0479]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2861, -4.1836, -1.7812,  ..., -1.8418, -0.7192,  0.9922]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:56:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female daddy is known as a mommy
A female waiter is known as a waitress
A female grandfather is known as a grandmother
A female buck is known as a doe
A female duke is known as a duchess
A female stepfather is known as a stepmother
A female uncle is known as a aunt
A female prince is known as a
2024-08-01 05:56:45 root INFO     [order_1_approx] starting weight calculation for A female prince is known as a princess
A female duke is known as a duchess
A female stepfather is known as a stepmother
A female waiter is known as a waitress
A female daddy is known as a mommy
A female buck is known as a doe
A female uncle is known as a aunt
A female grandfather is known as a
2024-08-01 05:56:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 05:59:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2302, -0.1547,  0.0687,  ..., -0.0191, -0.0201,  0.0471],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.6719, -1.5781, -1.1045,  ...,  0.3765, -2.7520, -3.0703],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0045, -0.0008,  0.0259,  ...,  0.0114, -0.0166, -0.0042],
        [ 0.0038,  0.0086, -0.0140,  ..., -0.0005,  0.0187,  0.0117],
        [-0.0206, -0.0070,  0.0227,  ...,  0.0052,  0.0083,  0.0039],
        ...,
        [ 0.0103,  0.0066, -0.0168,  ...,  0.0106,  0.0047, -0.0047],
        [ 0.0007, -0.0093,  0.0086,  ..., -0.0062, -0.0034,  0.0062],
        [-0.0243, -0.0028, -0.0012,  ...,  0.0015, -0.0074, -0.0088]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.4492, -1.6738, -1.1475,  ...,  0.2003, -2.6152, -2.8340]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:59:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female prince is known as a princess
A female duke is known as a duchess
A female stepfather is known as a stepmother
A female waiter is known as a waitress
A female daddy is known as a mommy
A female buck is known as a doe
A female uncle is known as a aunt
A female grandfather is known as a
2024-08-01 05:59:42 root INFO     [order_1_approx] starting weight calculation for A female prince is known as a princess
A female buck is known as a doe
A female stepfather is known as a stepmother
A female grandfather is known as a grandmother
A female uncle is known as a aunt
A female daddy is known as a mommy
A female waiter is known as a waitress
A female duke is known as a
2024-08-01 05:59:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 06:02:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0369,  0.2476,  0.0314,  ..., -0.2402, -0.1541,  0.1926],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2754, -2.4727,  0.4387,  ..., -0.5801, -3.0273,  0.9956],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0052, -0.0481,  0.0207,  ..., -0.0013, -0.0260, -0.0350],
        [ 0.0063,  0.0098, -0.0167,  ...,  0.0529,  0.0166,  0.0042],
        [ 0.0287,  0.0114,  0.0481,  ..., -0.0622,  0.0484, -0.0260],
        ...,
        [-0.0150, -0.0055, -0.0024,  ...,  0.0895, -0.0237,  0.0452],
        [-0.0158, -0.0326,  0.0116,  ..., -0.0199,  0.0261, -0.0172],
        [ 0.0327, -0.0652,  0.0695,  ...,  0.0036,  0.0086, -0.0199]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8887, -2.2930,  0.4880,  ..., -0.6704, -2.4961,  1.6445]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:02:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female prince is known as a princess
A female buck is known as a doe
A female stepfather is known as a stepmother
A female grandfather is known as a grandmother
A female uncle is known as a aunt
A female daddy is known as a mommy
A female waiter is known as a waitress
A female duke is known as a
2024-08-01 06:02:44 root INFO     [order_1_approx] starting weight calculation for A female uncle is known as a aunt
A female prince is known as a princess
A female daddy is known as a mommy
A female grandfather is known as a grandmother
A female buck is known as a doe
A female duke is known as a duchess
A female waiter is known as a waitress
A female stepfather is known as a
2024-08-01 06:02:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 06:05:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1036, -0.0794,  0.1080,  ..., -0.0299, -0.2432,  0.2515],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.5156, -1.2197, -2.3496,  ...,  1.4463, -2.1582, -0.6699],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0129, -0.0296, -0.0021,  ..., -0.0134, -0.0071, -0.0002],
        [ 0.0172,  0.0015,  0.0091,  ...,  0.0076,  0.0070,  0.0161],
        [-0.0155,  0.0042,  0.0181,  ..., -0.0289,  0.0088,  0.0131],
        ...,
        [ 0.0075,  0.0001, -0.0041,  ...,  0.0029,  0.0084,  0.0018],
        [ 0.0127, -0.0382,  0.0011,  ..., -0.0275,  0.0126,  0.0137],
        [-0.0018,  0.0014,  0.0025,  ...,  0.0099,  0.0246,  0.0062]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.2031, -1.1543, -2.3730,  ...,  1.2363, -1.5742, -0.5229]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:05:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female uncle is known as a aunt
A female prince is known as a princess
A female daddy is known as a mommy
A female grandfather is known as a grandmother
A female buck is known as a doe
A female duke is known as a duchess
A female waiter is known as a waitress
A female stepfather is known as a
2024-08-01 06:05:42 root INFO     [order_1_approx] starting weight calculation for A female grandfather is known as a grandmother
A female duke is known as a duchess
A female prince is known as a princess
A female uncle is known as a aunt
A female stepfather is known as a stepmother
A female daddy is known as a mommy
A female buck is known as a doe
A female waiter is known as a
2024-08-01 06:05:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 06:08:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1071,  0.0928, -0.0766,  ...,  0.0685, -0.0004, -0.0215],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.8867, -2.0469,  0.8579,  ...,  0.1807, -1.2861, -0.9956],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0086, -0.0186,  0.0278,  ..., -0.0315,  0.0050, -0.0276],
        [ 0.0132,  0.0395,  0.0027,  ...,  0.0313, -0.0375, -0.0094],
        [ 0.0417, -0.0002, -0.0006,  ...,  0.0025, -0.0006,  0.0117],
        ...,
        [ 0.0119,  0.0105,  0.0230,  ..., -0.0042, -0.0034,  0.0160],
        [-0.0301, -0.0136, -0.0355,  ..., -0.0138,  0.0124, -0.0269],
        [-0.0013,  0.0249,  0.0042,  ..., -0.0033, -0.0220,  0.0051]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.6758, -1.9395,  0.6606,  ...,  0.1217, -1.3457, -0.6309]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:08:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female grandfather is known as a grandmother
A female duke is known as a duchess
A female prince is known as a princess
A female uncle is known as a aunt
A female stepfather is known as a stepmother
A female daddy is known as a mommy
A female buck is known as a doe
A female waiter is known as a
2024-08-01 06:08:42 root INFO     total operator prediction time: 1447.131139755249 seconds
2024-08-01 06:08:42 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on name - occupation
2024-08-01 06:08:42 root INFO     building operator name - occupation
2024-08-01 06:08:42 root INFO     [order_1_approx] starting weight calculation for caesar was known for their work as a  emperor
michelangelo was known for their work as a  sculptor
kant was known for their work as a  philosopher
shakespeare was known for their work as a  playwright
napoleon was known for their work as a  emperor
wagner was known for their work as a  composer
marx was known for their work as a  philosopher
raphael was known for their work as a 
2024-08-01 06:08:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 06:11:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2174, -0.1010,  0.0446,  ..., -0.0452, -0.1975, -0.0015],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2832, -5.8477,  2.6016,  ..., -6.7305, -0.4810, -1.8369],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0448, -0.0107,  0.0007,  ...,  0.0443, -0.0148,  0.0076],
        [-0.0273, -0.0386, -0.0074,  ..., -0.0103,  0.0174,  0.0164],
        [ 0.1032,  0.0912,  0.1148,  ..., -0.0160, -0.0594,  0.0285],
        ...,
        [ 0.0466,  0.0464,  0.0336,  ...,  0.0730,  0.0141,  0.0158],
        [-0.0610, -0.1184, -0.0618,  ..., -0.0109,  0.0634,  0.0169],
        [-0.0806, -0.0672, -0.1040,  ...,  0.0116,  0.0764,  0.0298]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8535, -5.7109,  1.8301,  ..., -6.9258,  0.0693, -0.9263]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:11:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for caesar was known for their work as a  emperor
michelangelo was known for their work as a  sculptor
kant was known for their work as a  philosopher
shakespeare was known for their work as a  playwright
napoleon was known for their work as a  emperor
wagner was known for their work as a  composer
marx was known for their work as a  philosopher
raphael was known for their work as a 
2024-08-01 06:11:43 root INFO     [order_1_approx] starting weight calculation for michelangelo was known for their work as a  sculptor
caesar was known for their work as a  emperor
napoleon was known for their work as a  emperor
raphael was known for their work as a  painter
wagner was known for their work as a  composer
kant was known for their work as a  philosopher
marx was known for their work as a  philosopher
shakespeare was known for their work as a 
2024-08-01 06:11:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 06:14:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0505,  0.1848, -0.3813,  ...,  0.0581,  0.1249, -0.0640],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1348, -5.4688,  3.6094,  ..., -3.8535, -1.2773,  0.0752],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0051,  0.0106,  0.0385,  ..., -0.0156, -0.0233,  0.0059],
        [ 0.0013,  0.0071, -0.0055,  ...,  0.0018,  0.0112, -0.0058],
        [ 0.0045,  0.0109,  0.0252,  ..., -0.0130, -0.0018,  0.0067],
        ...,
        [-0.0034, -0.0068, -0.0142,  ...,  0.0278,  0.0085, -0.0017],
        [ 0.0037, -0.0102,  0.0036,  ...,  0.0101,  0.0166,  0.0099],
        [-0.0116,  0.0004,  0.0077,  ...,  0.0023, -0.0095,  0.0012]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5820, -5.3438,  3.5625,  ..., -3.7461, -1.0625, -0.0514]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:14:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for michelangelo was known for their work as a  sculptor
caesar was known for their work as a  emperor
napoleon was known for their work as a  emperor
raphael was known for their work as a  painter
wagner was known for their work as a  composer
kant was known for their work as a  philosopher
marx was known for their work as a  philosopher
shakespeare was known for their work as a 
2024-08-01 06:14:47 root INFO     [order_1_approx] starting weight calculation for shakespeare was known for their work as a  playwright
raphael was known for their work as a  painter
caesar was known for their work as a  emperor
kant was known for their work as a  philosopher
michelangelo was known for their work as a  sculptor
napoleon was known for their work as a  emperor
wagner was known for their work as a  composer
marx was known for their work as a 
2024-08-01 06:14:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 06:17:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0035,  0.0239, -0.1147,  ...,  0.2241,  0.1433,  0.0590],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4795, -8.4531,  3.6172,  ..., -5.7578,  0.9487, -3.0098],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.9531e-02,  9.1982e-04,  5.1880e-03,  ..., -1.4587e-02,
          4.4632e-03,  1.3618e-03],
        [-2.0126e-02,  1.0529e-03,  6.3965e-02,  ...,  2.3407e-02,
         -7.7087e-02,  6.5842e-03],
        [ 3.7537e-02,  2.1332e-02, -3.2990e-02,  ..., -6.1768e-02,
          2.7802e-02, -1.8250e-02],
        ...,
        [-1.6632e-03, -1.2413e-02,  1.8341e-02,  ...,  3.3264e-02,
         -3.2837e-02,  1.8845e-02],
        [-1.2207e-03, -1.2865e-03,  2.1881e-02,  ...,  4.1138e-02,
         -7.0381e-03,  9.2239e-03],
        [ 1.6464e-02, -3.0518e-05,  7.4005e-03,  ...,  2.7618e-03,
          3.5583e-02,  1.5930e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2822, -7.7266,  3.2402,  ..., -5.4414,  1.0811, -3.4082]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:17:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for shakespeare was known for their work as a  playwright
raphael was known for their work as a  painter
caesar was known for their work as a  emperor
kant was known for their work as a  philosopher
michelangelo was known for their work as a  sculptor
napoleon was known for their work as a  emperor
wagner was known for their work as a  composer
marx was known for their work as a 
2024-08-01 06:17:52 root INFO     [order_1_approx] starting weight calculation for kant was known for their work as a  philosopher
wagner was known for their work as a  composer
raphael was known for their work as a  painter
marx was known for their work as a  philosopher
michelangelo was known for their work as a  sculptor
shakespeare was known for their work as a  playwright
caesar was known for their work as a  emperor
napoleon was known for their work as a 
2024-08-01 06:17:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 06:20:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0314, -0.1471, -0.0227,  ...,  0.1345,  0.0023,  0.1428],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.2803, -5.1875, -0.0139,  ..., -0.2920,  1.7734, -0.8652],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0388, -0.0291,  0.0150,  ...,  0.0586, -0.0061,  0.0067],
        [ 0.0045,  0.0159,  0.0025,  ..., -0.0222, -0.0090, -0.0132],
        [ 0.0179, -0.0243,  0.0219,  ..., -0.0119,  0.0030,  0.0175],
        ...,
        [-0.0128,  0.0208, -0.0043,  ...,  0.0080,  0.0027,  0.0095],
        [ 0.0059, -0.0041,  0.0056,  ..., -0.0021,  0.0204,  0.0078],
        [ 0.0116, -0.0280,  0.0029,  ...,  0.0145,  0.0155,  0.0184]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8301, -5.1875, -0.0475,  ..., -0.6313,  1.6680, -0.6743]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:20:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for kant was known for their work as a  philosopher
wagner was known for their work as a  composer
raphael was known for their work as a  painter
marx was known for their work as a  philosopher
michelangelo was known for their work as a  sculptor
shakespeare was known for their work as a  playwright
caesar was known for their work as a  emperor
napoleon was known for their work as a 
2024-08-01 06:20:53 root INFO     [order_1_approx] starting weight calculation for raphael was known for their work as a  painter
napoleon was known for their work as a  emperor
caesar was known for their work as a  emperor
kant was known for their work as a  philosopher
marx was known for their work as a  philosopher
michelangelo was known for their work as a  sculptor
shakespeare was known for their work as a  playwright
wagner was known for their work as a 
2024-08-01 06:20:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 06:24:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([0.3086, 0.3701, 0.0342,  ..., 0.1946, 0.0701, 0.0463], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3457, -6.6211,  2.8281,  ..., -3.1016,  0.0498, -2.3477],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0665,  0.0010, -0.1011,  ..., -0.0443, -0.0035,  0.1083],
        [-0.0302,  0.0102,  0.0152,  ...,  0.0195, -0.0130, -0.0645],
        [-0.0597,  0.0571,  0.0289,  ..., -0.0537, -0.0280,  0.0516],
        ...,
        [-0.0852, -0.0083,  0.0488,  ...,  0.0428, -0.0582, -0.0963],
        [-0.0059,  0.0152,  0.0309,  ...,  0.0211,  0.0103, -0.0282],
        [-0.0238, -0.0233,  0.0727,  ...,  0.0387, -0.0105, -0.0576]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4082, -6.1094,  2.9961,  ..., -2.4141,  0.0260, -1.9414]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:24:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for raphael was known for their work as a  painter
napoleon was known for their work as a  emperor
caesar was known for their work as a  emperor
kant was known for their work as a  philosopher
marx was known for their work as a  philosopher
michelangelo was known for their work as a  sculptor
shakespeare was known for their work as a  playwright
wagner was known for their work as a 
2024-08-01 06:24:01 root INFO     [order_1_approx] starting weight calculation for wagner was known for their work as a  composer
michelangelo was known for their work as a  sculptor
napoleon was known for their work as a  emperor
raphael was known for their work as a  painter
caesar was known for their work as a  emperor
shakespeare was known for their work as a  playwright
marx was known for their work as a  philosopher
kant was known for their work as a 
2024-08-01 06:24:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 06:27:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0532, -0.0922, -0.0810,  ...,  0.2438,  0.1190,  0.0594],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3950, -6.9375,  2.8340,  ..., -6.4062, -0.9429, -3.2695],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0181, -0.0113, -0.0004,  ..., -0.0487, -0.0070,  0.0161],
        [ 0.0405,  0.0209, -0.0149,  ...,  0.0193, -0.0426,  0.0053],
        [ 0.0415,  0.0306,  0.0540,  ...,  0.0053,  0.0209,  0.0396],
        ...,
        [-0.0037, -0.0020, -0.0015,  ...,  0.0255, -0.0327,  0.0132],
        [-0.0373, -0.0037,  0.0037,  ..., -0.0070,  0.0069, -0.0031],
        [ 0.0160,  0.0072,  0.0086,  ...,  0.0319, -0.0273,  0.0372]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5347, -7.1484,  2.6016,  ..., -6.1758, -0.8091, -3.4297]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:27:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for wagner was known for their work as a  composer
michelangelo was known for their work as a  sculptor
napoleon was known for their work as a  emperor
raphael was known for their work as a  painter
caesar was known for their work as a  emperor
shakespeare was known for their work as a  playwright
marx was known for their work as a  philosopher
kant was known for their work as a 
2024-08-01 06:27:05 root INFO     [order_1_approx] starting weight calculation for kant was known for their work as a  philosopher
raphael was known for their work as a  painter
shakespeare was known for their work as a  playwright
napoleon was known for their work as a  emperor
michelangelo was known for their work as a  sculptor
wagner was known for their work as a  composer
marx was known for their work as a  philosopher
caesar was known for their work as a 
2024-08-01 06:27:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 06:30:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0201,  0.1035, -0.2065,  ...,  0.0119, -0.3186,  0.1406],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7153, -6.4141,  1.8467,  ..., -1.8115,  1.1602, -0.5977],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0299, -0.0261, -0.0306,  ...,  0.0520, -0.0385,  0.0365],
        [-0.0080,  0.0076, -0.0087,  ...,  0.0080, -0.0301,  0.0145],
        [ 0.0199,  0.0085,  0.0457,  ...,  0.0036,  0.0128,  0.0268],
        ...,
        [ 0.0118,  0.0062,  0.0087,  ...,  0.0619,  0.0002, -0.0024],
        [-0.0062,  0.0137,  0.0105,  ..., -0.0074,  0.0314,  0.0021],
        [-0.0117, -0.0245,  0.0091,  ...,  0.0103, -0.0230,  0.0132]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5083, -6.0859,  1.5674,  ..., -2.0508,  1.1768, -0.6245]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:30:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for kant was known for their work as a  philosopher
raphael was known for their work as a  painter
shakespeare was known for their work as a  playwright
napoleon was known for their work as a  emperor
michelangelo was known for their work as a  sculptor
wagner was known for their work as a  composer
marx was known for their work as a  philosopher
caesar was known for their work as a 
2024-08-01 06:30:10 root INFO     [order_1_approx] starting weight calculation for shakespeare was known for their work as a  playwright
napoleon was known for their work as a  emperor
wagner was known for their work as a  composer
raphael was known for their work as a  painter
caesar was known for their work as a  emperor
kant was known for their work as a  philosopher
marx was known for their work as a  philosopher
michelangelo was known for their work as a 
2024-08-01 06:30:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 06:33:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1746,  0.0446, -0.1753,  ...,  0.0371, -0.0578, -0.0016],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0918, -7.4961,  2.1523,  ..., -6.1172,  1.0273, -0.7480],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0415, -0.0136, -0.0323,  ...,  0.0203,  0.0021,  0.0332],
        [ 0.0798, -0.0010, -0.0549,  ...,  0.0869,  0.0314,  0.0233],
        [ 0.0031,  0.0095,  0.0164,  ..., -0.0264,  0.0001,  0.0196],
        ...,
        [ 0.0358,  0.0096, -0.0294,  ...,  0.0681,  0.0241,  0.0042],
        [ 0.0029, -0.0169, -0.0034,  ...,  0.0046,  0.0119,  0.0131],
        [ 0.0417,  0.0035, -0.0120,  ...,  0.0388,  0.0170,  0.0209]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0938, -7.3945,  2.3574,  ..., -6.2852,  1.2344, -0.8633]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:33:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for shakespeare was known for their work as a  playwright
napoleon was known for their work as a  emperor
wagner was known for their work as a  composer
raphael was known for their work as a  painter
caesar was known for their work as a  emperor
kant was known for their work as a  philosopher
marx was known for their work as a  philosopher
michelangelo was known for their work as a 
2024-08-01 06:33:15 root INFO     total operator prediction time: 1472.7308423519135 seconds
2024-08-01 06:33:15 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on country - capital
2024-08-01 06:33:15 root INFO     building operator country - capital
2024-08-01 06:33:15 root INFO     [order_1_approx] starting weight calculation for The country with helsinki as its capital is known as finland
The country with cairo as its capital is known as egypt
The country with stockholm as its capital is known as sweden
The country with bangkok as its capital is known as thailand
The country with conakry as its capital is known as guinea
The country with beijing as its capital is known as china
The country with havana as its capital is known as cuba
The country with zagreb as its capital is known as
2024-08-01 06:33:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 06:36:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1611, -0.1031, -0.1904,  ...,  0.1262, -0.0266, -0.0187],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4414, -5.7578, -2.9727,  ..., -2.5625,  2.0840, -1.1807],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0246,  0.0301, -0.0008,  ...,  0.0422, -0.0228, -0.0182],
        [ 0.0305, -0.0086,  0.0283,  ...,  0.0077,  0.0042, -0.0174],
        [ 0.0102,  0.0250, -0.0030,  ..., -0.0365, -0.0071,  0.0041],
        ...,
        [ 0.0029, -0.0286,  0.0026,  ...,  0.0118, -0.0090, -0.0206],
        [ 0.0208,  0.0405, -0.0049,  ..., -0.0299, -0.0046, -0.0053],
        [ 0.0496,  0.0151,  0.0168,  ...,  0.0182,  0.0025, -0.0419]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5293, -5.2852, -3.4355,  ..., -2.2324,  1.1250, -0.5093]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:36:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with helsinki as its capital is known as finland
The country with cairo as its capital is known as egypt
The country with stockholm as its capital is known as sweden
The country with bangkok as its capital is known as thailand
The country with conakry as its capital is known as guinea
The country with beijing as its capital is known as china
The country with havana as its capital is known as cuba
The country with zagreb as its capital is known as
2024-08-01 06:36:16 root INFO     [order_1_approx] starting weight calculation for The country with conakry as its capital is known as guinea
The country with zagreb as its capital is known as croatia
The country with cairo as its capital is known as egypt
The country with havana as its capital is known as cuba
The country with bangkok as its capital is known as thailand
The country with stockholm as its capital is known as sweden
The country with helsinki as its capital is known as finland
The country with beijing as its capital is known as
2024-08-01 06:36:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 06:39:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0239, -0.0441, -0.2793,  ...,  0.1193, -0.2482,  0.0070],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2285, -4.2500,  1.4609,  ...,  0.7441,  2.0371, -2.6367],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.8397e-02, -3.4607e-02, -1.8829e-02,  ...,  5.1994e-03,
          1.8692e-02,  1.4008e-02],
        [ 2.8763e-03,  4.5052e-03,  9.7275e-05,  ..., -4.2877e-03,
         -7.6218e-03, -3.0708e-04],
        [-1.4618e-02,  4.1618e-03,  8.4381e-03,  ..., -1.7334e-02,
         -1.2215e-02, -2.8229e-02],
        ...,
        [-2.3499e-02,  4.6387e-02,  1.0696e-02,  ..., -2.7847e-04,
         -1.4076e-02, -4.0924e-02],
        [ 1.5282e-02, -2.3361e-02, -9.5825e-03,  ...,  6.7787e-03,
          2.0355e-02,  1.1795e-02],
        [-1.3016e-02,  1.6983e-02,  1.4908e-02,  ..., -2.3918e-03,
         -1.6006e-02, -3.4241e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2188, -4.2500,  1.2168,  ...,  0.5488,  2.0977, -2.8594]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:39:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with conakry as its capital is known as guinea
The country with zagreb as its capital is known as croatia
The country with cairo as its capital is known as egypt
The country with havana as its capital is known as cuba
The country with bangkok as its capital is known as thailand
The country with stockholm as its capital is known as sweden
The country with helsinki as its capital is known as finland
The country with beijing as its capital is known as
2024-08-01 06:39:21 root INFO     [order_1_approx] starting weight calculation for The country with conakry as its capital is known as guinea
The country with stockholm as its capital is known as sweden
The country with beijing as its capital is known as china
The country with havana as its capital is known as cuba
The country with bangkok as its capital is known as thailand
The country with zagreb as its capital is known as croatia
The country with helsinki as its capital is known as finland
The country with cairo as its capital is known as
2024-08-01 06:39:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 06:42:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0430, -0.0753, -0.3818,  ...,  0.2739, -0.2079, -0.0050],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5586, -3.0430,  1.5303,  ..., -0.7451,  0.6694, -1.5654],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0852, -0.0608, -0.0360,  ...,  0.0112,  0.0032, -0.0018],
        [-0.0006, -0.0051,  0.0349,  ...,  0.0059,  0.0128, -0.0108],
        [-0.0349,  0.1194,  0.0707,  ..., -0.0122, -0.0083, -0.0516],
        ...,
        [-0.0304,  0.0541,  0.0363,  ...,  0.0374, -0.0133, -0.0450],
        [ 0.0202, -0.0688, -0.0239,  ..., -0.0306,  0.0152, -0.0003],
        [ 0.0094,  0.0411,  0.0244,  ...,  0.0373, -0.0079, -0.0148]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0898, -2.7168,  1.0771,  ..., -0.3726,  0.5078, -1.6660]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:42:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with conakry as its capital is known as guinea
The country with stockholm as its capital is known as sweden
The country with beijing as its capital is known as china
The country with havana as its capital is known as cuba
The country with bangkok as its capital is known as thailand
The country with zagreb as its capital is known as croatia
The country with helsinki as its capital is known as finland
The country with cairo as its capital is known as
2024-08-01 06:42:25 root INFO     [order_1_approx] starting weight calculation for The country with conakry as its capital is known as guinea
The country with bangkok as its capital is known as thailand
The country with beijing as its capital is known as china
The country with cairo as its capital is known as egypt
The country with helsinki as its capital is known as finland
The country with havana as its capital is known as cuba
The country with zagreb as its capital is known as croatia
The country with stockholm as its capital is known as
2024-08-01 06:42:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 06:45:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2192,  0.0886, -0.1597,  ...,  0.3127, -0.0454,  0.0930],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7852, -6.2930, -2.1211,  ..., -0.8789, -1.8252, -3.4258],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0231, -0.0197,  0.0352,  ...,  0.0074, -0.0172,  0.0200],
        [ 0.0108, -0.0079, -0.0024,  ...,  0.0055, -0.0071, -0.0145],
        [ 0.0095,  0.0272,  0.0227,  ..., -0.0113, -0.0116, -0.0211],
        ...,
        [ 0.0092,  0.0210, -0.0025,  ...,  0.0503, -0.0208, -0.0303],
        [-0.0025, -0.0194, -0.0155,  ...,  0.0252,  0.0031, -0.0034],
        [ 0.0069,  0.0078, -0.0231,  ...,  0.0217, -0.0245, -0.0045]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5195, -6.0781, -2.2363,  ..., -0.7256, -1.4180, -3.1523]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:45:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with conakry as its capital is known as guinea
The country with bangkok as its capital is known as thailand
The country with beijing as its capital is known as china
The country with cairo as its capital is known as egypt
The country with helsinki as its capital is known as finland
The country with havana as its capital is known as cuba
The country with zagreb as its capital is known as croatia
The country with stockholm as its capital is known as
2024-08-01 06:45:27 root INFO     [order_1_approx] starting weight calculation for The country with beijing as its capital is known as china
The country with stockholm as its capital is known as sweden
The country with bangkok as its capital is known as thailand
The country with cairo as its capital is known as egypt
The country with havana as its capital is known as cuba
The country with conakry as its capital is known as guinea
The country with zagreb as its capital is known as croatia
The country with helsinki as its capital is known as
2024-08-01 06:45:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 06:48:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0847, -0.1405, -0.1259,  ...,  0.1968, -0.1667, -0.0508],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.3047, -5.6523, -1.2324,  ..., -0.1309, -3.0312, -3.4844],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0151,  0.0024,  0.0067,  ...,  0.0246,  0.0091,  0.0006],
        [ 0.0020, -0.0226, -0.0206,  ..., -0.0100, -0.0042, -0.0099],
        [ 0.0017,  0.0128,  0.0058,  ..., -0.0065,  0.0130,  0.0073],
        ...,
        [ 0.0060, -0.0056, -0.0083,  ...,  0.0048, -0.0180, -0.0194],
        [-0.0072, -0.0359,  0.0043,  ..., -0.0035,  0.0219,  0.0007],
        [ 0.0043, -0.0017, -0.0126,  ...,  0.0036, -0.0157, -0.0082]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.3047, -5.4570, -1.2666,  ..., -0.1647, -2.6289, -3.4785]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:48:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with beijing as its capital is known as china
The country with stockholm as its capital is known as sweden
The country with bangkok as its capital is known as thailand
The country with cairo as its capital is known as egypt
The country with havana as its capital is known as cuba
The country with conakry as its capital is known as guinea
The country with zagreb as its capital is known as croatia
The country with helsinki as its capital is known as
2024-08-01 06:48:30 root INFO     [order_1_approx] starting weight calculation for The country with cairo as its capital is known as egypt
The country with zagreb as its capital is known as croatia
The country with havana as its capital is known as cuba
The country with stockholm as its capital is known as sweden
The country with helsinki as its capital is known as finland
The country with beijing as its capital is known as china
The country with bangkok as its capital is known as thailand
The country with conakry as its capital is known as
2024-08-01 06:48:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 06:51:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0581, -0.0162, -0.4800,  ...,  0.1722, -0.0690,  0.1567],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2656, -5.8984,  2.7148,  ..., -0.9590, -0.2461, -1.0303],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0385,  0.0030, -0.0268,  ...,  0.0310, -0.0004,  0.0025],
        [ 0.0066, -0.0125,  0.0273,  ..., -0.0312, -0.0052, -0.0120],
        [-0.0169,  0.0051,  0.0464,  ..., -0.0301,  0.0068, -0.0459],
        ...,
        [-0.0178,  0.0181,  0.0064,  ..., -0.0268, -0.0232, -0.0303],
        [-0.0179,  0.0468, -0.0282,  ...,  0.0152,  0.0059, -0.0286],
        [-0.0184, -0.0291, -0.0024,  ..., -0.0007, -0.0002, -0.0171]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2676, -5.7812,  2.5430,  ..., -1.1855, -0.2396, -0.9297]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:51:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with cairo as its capital is known as egypt
The country with zagreb as its capital is known as croatia
The country with havana as its capital is known as cuba
The country with stockholm as its capital is known as sweden
The country with helsinki as its capital is known as finland
The country with beijing as its capital is known as china
The country with bangkok as its capital is known as thailand
The country with conakry as its capital is known as
2024-08-01 06:51:35 root INFO     [order_1_approx] starting weight calculation for The country with cairo as its capital is known as egypt
The country with bangkok as its capital is known as thailand
The country with stockholm as its capital is known as sweden
The country with helsinki as its capital is known as finland
The country with conakry as its capital is known as guinea
The country with beijing as its capital is known as china
The country with zagreb as its capital is known as croatia
The country with havana as its capital is known as
2024-08-01 06:51:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 06:54:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1220, -0.0591, -0.2177,  ..., -0.0303, -0.0139, -0.1860],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3750, -3.9844, -1.4004,  ...,  1.3057,  1.5381, -1.9570],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0198, -0.0080, -0.0037,  ..., -0.0027,  0.0077, -0.0166],
        [ 0.0091,  0.0273,  0.0255,  ..., -0.0313, -0.0207,  0.0027],
        [-0.0076,  0.0190,  0.0152,  ..., -0.0057, -0.0063, -0.0111],
        ...,
        [ 0.0276, -0.0068,  0.0115,  ...,  0.0426, -0.0323, -0.0146],
        [ 0.0050, -0.0021, -0.0255,  ..., -0.0064,  0.0186, -0.0125],
        [ 0.0145, -0.0115,  0.0247,  ...,  0.0096, -0.0423, -0.0061]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3242, -3.9941, -1.5205,  ...,  1.3564,  1.3906, -1.5234]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:54:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with cairo as its capital is known as egypt
The country with bangkok as its capital is known as thailand
The country with stockholm as its capital is known as sweden
The country with helsinki as its capital is known as finland
The country with conakry as its capital is known as guinea
The country with beijing as its capital is known as china
The country with zagreb as its capital is known as croatia
The country with havana as its capital is known as
2024-08-01 06:54:39 root INFO     [order_1_approx] starting weight calculation for The country with cairo as its capital is known as egypt
The country with beijing as its capital is known as china
The country with stockholm as its capital is known as sweden
The country with havana as its capital is known as cuba
The country with helsinki as its capital is known as finland
The country with zagreb as its capital is known as croatia
The country with conakry as its capital is known as guinea
The country with bangkok as its capital is known as
2024-08-01 06:54:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 06:57:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1214,  0.1331, -0.2725,  ...,  0.3496, -0.2460, -0.0218],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7642, -5.0156,  1.7139,  ..., -0.2563, -2.0508, -3.8809],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0346, -0.0277,  0.0018,  ...,  0.0306,  0.0154, -0.0053],
        [ 0.0123, -0.0174, -0.0074,  ..., -0.0251, -0.0022, -0.0151],
        [-0.0027, -0.0098,  0.0089,  ..., -0.0045,  0.0149, -0.0131],
        ...,
        [ 0.0020,  0.0094,  0.0168,  ...,  0.0115, -0.0032, -0.0193],
        [ 0.0014, -0.0259, -0.0124,  ..., -0.0003,  0.0162,  0.0038],
        [ 0.0103, -0.0125,  0.0015,  ..., -0.0079, -0.0088,  0.0055]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9004, -4.5430,  1.9463,  ..., -0.1364, -1.7188, -3.9863]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:57:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with cairo as its capital is known as egypt
The country with beijing as its capital is known as china
The country with stockholm as its capital is known as sweden
The country with havana as its capital is known as cuba
The country with helsinki as its capital is known as finland
The country with zagreb as its capital is known as croatia
The country with conakry as its capital is known as guinea
The country with bangkok as its capital is known as
2024-08-01 06:57:43 root INFO     total operator prediction time: 1468.305938243866 seconds
2024-08-01 06:57:43 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on things - color
2024-08-01 06:57:43 root INFO     building operator things - color
2024-08-01 06:57:43 root INFO     [order_1_approx] starting weight calculation for The fridge is colored white
The swan is colored white
The crow is colored black
The spinach is colored green
The cherry is colored red
The emerald is colored green
The snow is colored white
The cream is colored
2024-08-01 06:57:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 07:00:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2393, -0.0456, -0.0154,  ..., -0.0609, -0.1740,  0.0544],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7100, -5.4023,  2.3906,  ..., -2.4043, -0.4863, -0.2080],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0088, -0.0025,  0.0178,  ..., -0.0133, -0.0133,  0.0346],
        [ 0.0018,  0.0182, -0.0169,  ..., -0.0107, -0.0208, -0.0011],
        [-0.0109,  0.0269, -0.0024,  ...,  0.0108, -0.0079,  0.0025],
        ...,
        [ 0.0197,  0.0064, -0.0049,  ...,  0.0360,  0.0071, -0.0161],
        [ 0.0058, -0.0100, -0.0667,  ...,  0.0191,  0.0138,  0.0129],
        [ 0.0145, -0.0070,  0.0020,  ...,  0.0268,  0.0226, -0.0015]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6841, -5.4414,  2.2656,  ..., -2.4395,  0.0073, -0.3745]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:00:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The fridge is colored white
The swan is colored white
The crow is colored black
The spinach is colored green
The cherry is colored red
The emerald is colored green
The snow is colored white
The cream is colored
2024-08-01 07:00:45 root INFO     [order_1_approx] starting weight calculation for The cherry is colored red
The swan is colored white
The emerald is colored green
The snow is colored white
The fridge is colored white
The spinach is colored green
The cream is colored white
The crow is colored
2024-08-01 07:00:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 07:03:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1685,  0.0312, -0.1664,  ..., -0.1752, -0.1188, -0.0317],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9570, -4.4961,  2.9395,  ..., -0.9346,  0.6621, -1.3164],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0710,  0.0014,  0.0235,  ..., -0.0012,  0.0133,  0.0140],
        [-0.0414, -0.0104,  0.0232,  ...,  0.0014,  0.0136,  0.0289],
        [ 0.0310,  0.0617,  0.0241,  ...,  0.0217, -0.0017, -0.0003],
        ...,
        [-0.0037, -0.0256, -0.0003,  ...,  0.0247, -0.0145, -0.0124],
        [ 0.0012,  0.0094, -0.0121,  ...,  0.0542,  0.0117,  0.0171],
        [-0.0110, -0.0050,  0.0312,  ...,  0.0046, -0.0479,  0.0057]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6592, -4.2852,  2.7676,  ..., -0.6206,  0.4575, -1.4531]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:03:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The cherry is colored red
The swan is colored white
The emerald is colored green
The snow is colored white
The fridge is colored white
The spinach is colored green
The cream is colored white
The crow is colored
2024-08-01 07:03:48 root INFO     [order_1_approx] starting weight calculation for The cream is colored white
The fridge is colored white
The cherry is colored red
The spinach is colored green
The crow is colored black
The swan is colored white
The snow is colored white
The emerald is colored
2024-08-01 07:03:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 07:06:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0373,  0.0734, -0.2067,  ...,  0.0504,  0.1868, -0.0716],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1807, -1.4336, -1.8926,  ..., -1.0234,  1.1113, -0.2451],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0264, -0.0140, -0.0099,  ..., -0.0299,  0.0047,  0.0218],
        [-0.0021, -0.0076, -0.0017,  ...,  0.0087,  0.0033, -0.0214],
        [ 0.0063,  0.0009,  0.0313,  ...,  0.0086,  0.0068, -0.0228],
        ...,
        [ 0.0435, -0.0327, -0.0304,  ...,  0.0609,  0.0226, -0.0870],
        [-0.0243, -0.0247,  0.0211,  ...,  0.0143,  0.0213, -0.0196],
        [-0.0185, -0.0148, -0.0088,  ..., -0.0097, -0.0017,  0.0165]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1953, -1.3838, -1.7393,  ..., -0.7900,  0.3530,  0.0457]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:06:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The cream is colored white
The fridge is colored white
The cherry is colored red
The spinach is colored green
The crow is colored black
The swan is colored white
The snow is colored white
The emerald is colored
2024-08-01 07:06:51 root INFO     [order_1_approx] starting weight calculation for The cream is colored white
The swan is colored white
The crow is colored black
The cherry is colored red
The spinach is colored green
The emerald is colored green
The snow is colored white
The fridge is colored
2024-08-01 07:06:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 07:09:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1196,  0.0154,  0.0256,  ...,  0.0698, -0.2671, -0.2037],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1174, -9.0078,  0.9985,  ...,  0.3262, -3.9102, -1.5615],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0662,  0.0184,  0.0246,  ...,  0.0175, -0.0289,  0.0516],
        [-0.0207, -0.0493,  0.0051,  ..., -0.0057, -0.0019, -0.0239],
        [ 0.0451,  0.0326,  0.0362,  ...,  0.0606, -0.0359,  0.0009],
        ...,
        [ 0.0074, -0.0133,  0.0004,  ...,  0.0253,  0.0206, -0.0306],
        [ 0.0195, -0.0568,  0.0177,  ...,  0.0145,  0.0182, -0.0289],
        [-0.0320, -0.0314, -0.0341,  ..., -0.0431,  0.0380, -0.0143]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3335, -9.0312,  1.1729,  ...,  0.0768, -3.6035, -1.7529]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:09:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The cream is colored white
The swan is colored white
The crow is colored black
The cherry is colored red
The spinach is colored green
The emerald is colored green
The snow is colored white
The fridge is colored
2024-08-01 07:09:56 root INFO     [order_1_approx] starting weight calculation for The crow is colored black
The cream is colored white
The emerald is colored green
The fridge is colored white
The spinach is colored green
The swan is colored white
The cherry is colored red
The snow is colored
2024-08-01 07:09:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 07:12:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1757,  0.2236, -0.0743,  ..., -0.0851, -0.1232, -0.1123],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.4453, -5.6875, -0.0696,  ..., -4.9375, -1.0029, -4.2148],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0127, -0.0350,  0.0109,  ...,  0.0350, -0.0094, -0.0335],
        [ 0.0207,  0.0187, -0.0398,  ..., -0.0030,  0.0295,  0.0250],
        [-0.0179,  0.0096, -0.0054,  ...,  0.0250,  0.0237,  0.0083],
        ...,
        [-0.0090, -0.0164,  0.0514,  ...,  0.0329,  0.0090, -0.0233],
        [-0.0058, -0.0360, -0.0110,  ...,  0.0299,  0.0288, -0.0139],
        [-0.0106, -0.0079,  0.0478,  ...,  0.0017,  0.0229, -0.0328]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.3564, -5.6797,  0.0199,  ..., -5.3242, -0.4326, -4.2148]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:12:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The crow is colored black
The cream is colored white
The emerald is colored green
The fridge is colored white
The spinach is colored green
The swan is colored white
The cherry is colored red
The snow is colored
2024-08-01 07:12:59 root INFO     [order_1_approx] starting weight calculation for The fridge is colored white
The emerald is colored green
The crow is colored black
The cream is colored white
The cherry is colored red
The swan is colored white
The snow is colored white
The spinach is colored
2024-08-01 07:12:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 07:16:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0121, -0.0692, -0.3030,  ...,  0.0898, -0.1903, -0.1487],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2852, -4.9141, -0.5518,  ..., -1.0244, -1.5186, -2.8457],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0353,  0.0330, -0.1072,  ..., -0.0485,  0.1326,  0.0804],
        [-0.0010, -0.0413,  0.0177,  ...,  0.0211,  0.0219,  0.0101],
        [ 0.0035,  0.0392,  0.0868,  ..., -0.0298, -0.0934, -0.0519],
        ...,
        [-0.0085, -0.0368, -0.0256,  ...,  0.0271,  0.0093, -0.0133],
        [-0.0061,  0.0017, -0.0390,  ...,  0.0269,  0.0064,  0.0186],
        [-0.0120, -0.0334, -0.0364,  ...,  0.0384,  0.0712,  0.0668]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1895, -5.2500, -0.7246,  ..., -1.7168, -1.5361, -2.4688]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:16:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The fridge is colored white
The emerald is colored green
The crow is colored black
The cream is colored white
The cherry is colored red
The swan is colored white
The snow is colored white
The spinach is colored
2024-08-01 07:16:03 root INFO     [order_1_approx] starting weight calculation for The snow is colored white
The emerald is colored green
The fridge is colored white
The crow is colored black
The cherry is colored red
The cream is colored white
The spinach is colored green
The swan is colored
2024-08-01 07:16:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 07:19:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3513, -0.0214, -0.0823,  ..., -0.0195, -0.0359, -0.2079],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-3.1387e+00, -3.4883e+00,  1.3574e-01,  ...,  1.9531e-03,
        -2.8203e+00,  1.1777e+00], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0665, -0.0150, -0.0011,  ..., -0.0361,  0.0066,  0.0014],
        [-0.0018,  0.0124,  0.0012,  ...,  0.0154,  0.0268,  0.0183],
        [-0.0113, -0.0106,  0.0144,  ...,  0.0126,  0.0246,  0.0030],
        ...,
        [-0.0023,  0.0275, -0.0051,  ...,  0.0110,  0.0015, -0.0221],
        [-0.0391, -0.0166,  0.0109,  ...,  0.0105, -0.0014, -0.0121],
        [-0.0296, -0.0056,  0.0200,  ..., -0.0122,  0.0153, -0.0287]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.6445, -3.3594,  0.0220,  ...,  0.4255, -2.7578,  0.8799]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:19:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The snow is colored white
The emerald is colored green
The fridge is colored white
The crow is colored black
The cherry is colored red
The cream is colored white
The spinach is colored green
The swan is colored
2024-08-01 07:19:06 root INFO     [order_1_approx] starting weight calculation for The fridge is colored white
The spinach is colored green
The emerald is colored green
The swan is colored white
The crow is colored black
The cream is colored white
The snow is colored white
The cherry is colored
2024-08-01 07:19:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 07:22:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0865, -0.1743, -0.1687,  ..., -0.0416, -0.1979,  0.0075],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.4639, -6.7148, -1.5898,  ..., -2.1738, -0.0352, -2.0156],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0034, -0.0498, -0.0233,  ..., -0.0624,  0.0286,  0.0464],
        [-0.0190, -0.0264, -0.0057,  ...,  0.0065,  0.0168,  0.0211],
        [ 0.0258,  0.0600,  0.0180,  ...,  0.0162, -0.0137, -0.0187],
        ...,
        [-0.0075, -0.0569, -0.0306,  ...,  0.0487,  0.0346, -0.0002],
        [-0.0102,  0.0240,  0.0122,  ...,  0.0248, -0.0083, -0.0439],
        [-0.0077, -0.0171,  0.0077,  ..., -0.0119, -0.0140,  0.0129]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.3447, -6.5078, -1.7002,  ..., -2.1113, -0.2393, -2.0195]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:22:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The fridge is colored white
The spinach is colored green
The emerald is colored green
The swan is colored white
The crow is colored black
The cream is colored white
The snow is colored white
The cherry is colored
2024-08-01 07:22:11 root INFO     total operator prediction time: 1467.9312899112701 seconds
2024-08-01 07:22:11 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - sound
2024-08-01 07:22:11 root INFO     building operator animal - sound
2024-08-01 07:22:11 root INFO     [order_1_approx] starting weight calculation for The sound that a fox makes is called a howl
The sound that a hyena makes is called a laugh
The sound that a turkey makes is called a gobble
The sound that a alpaca makes is called a bray
The sound that a rat makes is called a squeak
The sound that a raven makes is called a caw
The sound that a leopard makes is called a growl
The sound that a magpie makes is called a
2024-08-01 07:22:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 07:25:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2568,  0.1965, -0.0757,  ...,  0.2126, -0.2820,  0.0752],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0125,  0.0654,  1.8252,  ...,  0.5908, -1.4395,  0.9756],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0436,  0.0430,  0.0315,  ..., -0.0145,  0.0154, -0.0310],
        [-0.0228,  0.0033, -0.0495,  ...,  0.0410,  0.1265, -0.0411],
        [-0.0042,  0.0299,  0.0945,  ..., -0.0426, -0.0309, -0.0047],
        ...,
        [ 0.0031, -0.0010, -0.0112,  ...,  0.0504,  0.0064, -0.0254],
        [-0.0576, -0.0644, -0.0359,  ..., -0.0098, -0.0217,  0.0574],
        [ 0.0546,  0.0301,  0.0352,  ..., -0.0620, -0.0388,  0.0487]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7012,  0.9683,  1.9453,  ...,  0.6104, -1.8037,  0.5088]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:25:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a fox makes is called a howl
The sound that a hyena makes is called a laugh
The sound that a turkey makes is called a gobble
The sound that a alpaca makes is called a bray
The sound that a rat makes is called a squeak
The sound that a raven makes is called a caw
The sound that a leopard makes is called a growl
The sound that a magpie makes is called a
2024-08-01 07:25:12 root INFO     [order_1_approx] starting weight calculation for The sound that a fox makes is called a howl
The sound that a leopard makes is called a growl
The sound that a raven makes is called a caw
The sound that a magpie makes is called a chatter
The sound that a turkey makes is called a gobble
The sound that a rat makes is called a squeak
The sound that a alpaca makes is called a bray
The sound that a hyena makes is called a
2024-08-01 07:25:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 07:28:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2108, -0.0263,  0.0533,  ...,  0.2235, -0.2201, -0.0234],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2076, -4.1562,  1.7637,  ..., -0.7261, -0.5586, -0.2637],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0606,  0.0068, -0.0073,  ...,  0.0135, -0.0362, -0.0432],
        [-0.0244, -0.0012, -0.0143,  ..., -0.0241,  0.0166,  0.0278],
        [-0.0109,  0.0631, -0.0006,  ..., -0.0531, -0.0450,  0.0060],
        ...,
        [-0.0185,  0.0088, -0.0287,  ...,  0.0608,  0.0069, -0.0045],
        [ 0.0207, -0.0219,  0.0375,  ...,  0.0083, -0.0126,  0.0072],
        [ 0.0064,  0.0119,  0.0047,  ..., -0.0038,  0.0175,  0.0191]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0046, -3.7539,  1.8848,  ..., -0.2385, -0.5474, -0.6699]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:28:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a fox makes is called a howl
The sound that a leopard makes is called a growl
The sound that a raven makes is called a caw
The sound that a magpie makes is called a chatter
The sound that a turkey makes is called a gobble
The sound that a rat makes is called a squeak
The sound that a alpaca makes is called a bray
The sound that a hyena makes is called a
2024-08-01 07:28:14 root INFO     [order_1_approx] starting weight calculation for The sound that a alpaca makes is called a bray
The sound that a rat makes is called a squeak
The sound that a leopard makes is called a growl
The sound that a hyena makes is called a laugh
The sound that a raven makes is called a caw
The sound that a turkey makes is called a gobble
The sound that a magpie makes is called a chatter
The sound that a fox makes is called a
2024-08-01 07:28:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 07:31:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1898,  0.3516,  0.1176,  ..., -0.1025,  0.1736, -0.1326],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5547, -4.6602, -0.3828,  ..., -2.3418, -0.2969,  3.6816],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0164,  0.0347, -0.0010,  ..., -0.0142,  0.0070, -0.0014],
        [-0.0546,  0.0241, -0.0219,  ...,  0.0001,  0.0192, -0.0350],
        [ 0.0002, -0.0342,  0.0421,  ..., -0.0435, -0.0296,  0.0394],
        ...,
        [-0.0106,  0.0354, -0.0099,  ...,  0.0636,  0.0104, -0.0504],
        [-0.0015,  0.0016, -0.0240,  ...,  0.0184, -0.0028,  0.0025],
        [ 0.0039, -0.0298,  0.0106,  ..., -0.0325, -0.0454,  0.0085]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1240, -4.1523, -0.0732,  ..., -2.3262, -0.8369,  3.8516]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:31:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a alpaca makes is called a bray
The sound that a rat makes is called a squeak
The sound that a leopard makes is called a growl
The sound that a hyena makes is called a laugh
The sound that a raven makes is called a caw
The sound that a turkey makes is called a gobble
The sound that a magpie makes is called a chatter
The sound that a fox makes is called a
2024-08-01 07:31:17 root INFO     [order_1_approx] starting weight calculation for The sound that a hyena makes is called a laugh
The sound that a rat makes is called a squeak
The sound that a magpie makes is called a chatter
The sound that a leopard makes is called a growl
The sound that a raven makes is called a caw
The sound that a fox makes is called a howl
The sound that a turkey makes is called a gobble
The sound that a alpaca makes is called a
2024-08-01 07:31:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 07:34:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0085, -0.0430, -0.0773,  ...,  0.0374, -0.1853, -0.0222],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.3115, -2.7656,  3.6953,  ..., -0.6641, -0.3848,  1.2734],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0246, -0.0405,  0.0112,  ..., -0.0316, -0.0208,  0.0011],
        [-0.0155,  0.0724, -0.0568,  ..., -0.0153,  0.0129,  0.0176],
        [ 0.0200, -0.0312,  0.0352,  ..., -0.0485,  0.0067, -0.0281],
        ...,
        [ 0.0130,  0.0321,  0.0047,  ...,  0.0613, -0.0157, -0.0138],
        [-0.0348, -0.0009, -0.0062,  ..., -0.0174, -0.0009,  0.0272],
        [-0.0219, -0.0236,  0.0043,  ..., -0.0352,  0.0075,  0.0367]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.4336, -2.7363,  3.2285,  ...,  0.0610,  0.2729,  1.2217]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:34:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a hyena makes is called a laugh
The sound that a rat makes is called a squeak
The sound that a magpie makes is called a chatter
The sound that a leopard makes is called a growl
The sound that a raven makes is called a caw
The sound that a fox makes is called a howl
The sound that a turkey makes is called a gobble
The sound that a alpaca makes is called a
2024-08-01 07:34:20 root INFO     [order_1_approx] starting weight calculation for The sound that a raven makes is called a caw
The sound that a hyena makes is called a laugh
The sound that a leopard makes is called a growl
The sound that a magpie makes is called a chatter
The sound that a turkey makes is called a gobble
The sound that a alpaca makes is called a bray
The sound that a fox makes is called a howl
The sound that a rat makes is called a
2024-08-01 07:34:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 07:37:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0513,  0.1155,  0.0625,  ..., -0.2288, -0.1274, -0.0923],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4336, -0.6157,  1.5449,  ..., -2.2793, -0.1543,  1.8750],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0450, -0.0022,  0.0047,  ..., -0.0013, -0.0154, -0.0448],
        [ 0.0240,  0.0622, -0.0041,  ...,  0.0242, -0.0145,  0.0033],
        [-0.0563, -0.0589,  0.0134,  ...,  0.0149, -0.0654, -0.0601],
        ...,
        [ 0.0312,  0.0010, -0.0256,  ...,  0.0495, -0.0091, -0.0127],
        [ 0.0177, -0.0013, -0.0239,  ..., -0.0139,  0.0271,  0.0550],
        [-0.0274, -0.0443,  0.0019,  ..., -0.0707, -0.0478, -0.0358]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3848, -0.8926,  1.0928,  ..., -2.7441, -0.3948,  2.2969]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:37:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a raven makes is called a caw
The sound that a hyena makes is called a laugh
The sound that a leopard makes is called a growl
The sound that a magpie makes is called a chatter
The sound that a turkey makes is called a gobble
The sound that a alpaca makes is called a bray
The sound that a fox makes is called a howl
The sound that a rat makes is called a
2024-08-01 07:37:21 root INFO     [order_1_approx] starting weight calculation for The sound that a fox makes is called a howl
The sound that a raven makes is called a caw
The sound that a alpaca makes is called a bray
The sound that a leopard makes is called a growl
The sound that a magpie makes is called a chatter
The sound that a hyena makes is called a laugh
The sound that a rat makes is called a squeak
The sound that a turkey makes is called a
2024-08-01 07:37:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 07:40:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0596,  0.1691,  0.0472,  ...,  0.1247, -0.0627,  0.0311],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1523e+00, -4.1914e+00,  3.7305e+00,  ...,  9.5312e-01,
        -5.6738e-01,  1.9531e-03], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0251,  0.0295,  0.0186,  ..., -0.0106, -0.0137, -0.0275],
        [ 0.0279,  0.0597, -0.0254,  ..., -0.0106, -0.0057,  0.0380],
        [-0.0356, -0.0085,  0.0393,  ...,  0.0053, -0.0046, -0.0114],
        ...,
        [ 0.0140,  0.0173, -0.0178,  ...,  0.0154, -0.0181,  0.0360],
        [ 0.0026,  0.0240, -0.0046,  ..., -0.0003,  0.0254,  0.0102],
        [-0.0113, -0.0333,  0.0328,  ..., -0.0384, -0.0214, -0.0030]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2441, -4.3516,  3.6230,  ...,  0.7627, -1.0918,  0.0175]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:40:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a fox makes is called a howl
The sound that a raven makes is called a caw
The sound that a alpaca makes is called a bray
The sound that a leopard makes is called a growl
The sound that a magpie makes is called a chatter
The sound that a hyena makes is called a laugh
The sound that a rat makes is called a squeak
The sound that a turkey makes is called a
2024-08-01 07:40:25 root INFO     [order_1_approx] starting weight calculation for The sound that a turkey makes is called a gobble
The sound that a rat makes is called a squeak
The sound that a hyena makes is called a laugh
The sound that a leopard makes is called a growl
The sound that a fox makes is called a howl
The sound that a alpaca makes is called a bray
The sound that a magpie makes is called a chatter
The sound that a raven makes is called a
2024-08-01 07:40:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 07:43:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1202,  0.1594, -0.1031,  ...,  0.1177, -0.1045, -0.0272],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5469, -2.6445,  1.6514,  ..., -1.5322,  0.4497,  1.9287],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0298,  0.0410, -0.0088,  ..., -0.0380, -0.0151, -0.0426],
        [ 0.0039,  0.0095, -0.0267,  ..., -0.0134,  0.0874, -0.0025],
        [-0.0078, -0.0085,  0.0984,  ..., -0.0120, -0.0437, -0.0385],
        ...,
        [ 0.0194,  0.0324, -0.0528,  ...,  0.0464, -0.0114, -0.0096],
        [-0.0377, -0.0543, -0.0761,  ...,  0.0226,  0.0418, -0.0222],
        [ 0.0066,  0.0172,  0.0104,  ..., -0.0557, -0.0305, -0.0023]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2891, -1.9150,  1.3643,  ..., -1.6406,  0.5298,  2.1719]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:43:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a turkey makes is called a gobble
The sound that a rat makes is called a squeak
The sound that a hyena makes is called a laugh
The sound that a leopard makes is called a growl
The sound that a fox makes is called a howl
The sound that a alpaca makes is called a bray
The sound that a magpie makes is called a chatter
The sound that a raven makes is called a
2024-08-01 07:43:29 root INFO     [order_1_approx] starting weight calculation for The sound that a magpie makes is called a chatter
The sound that a turkey makes is called a gobble
The sound that a alpaca makes is called a bray
The sound that a raven makes is called a caw
The sound that a hyena makes is called a laugh
The sound that a rat makes is called a squeak
The sound that a fox makes is called a howl
The sound that a leopard makes is called a
2024-08-01 07:43:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 07:46:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1945,  0.1877, -0.0981,  ..., -0.0216, -0.0919,  0.0427],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8008, -4.4336, -2.2578,  ..., -2.3867, -0.3428,  0.8564],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0033, -0.0139, -0.0093,  ..., -0.0296, -0.0133, -0.0020],
        [-0.0091, -0.0301, -0.0295,  ...,  0.0045,  0.0241,  0.0296],
        [-0.0155, -0.0417, -0.0191,  ..., -0.0257,  0.0184,  0.0239],
        ...,
        [ 0.0106,  0.0385, -0.0028,  ...,  0.0120, -0.0168, -0.0084],
        [-0.0142, -0.0346,  0.0069,  ..., -0.0232,  0.0263,  0.0083],
        [-0.0153,  0.0120,  0.0193,  ..., -0.0218,  0.0145, -0.0110]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8281, -4.2461, -2.2090,  ..., -2.1367, -0.4751,  0.7368]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:46:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a magpie makes is called a chatter
The sound that a turkey makes is called a gobble
The sound that a alpaca makes is called a bray
The sound that a raven makes is called a caw
The sound that a hyena makes is called a laugh
The sound that a rat makes is called a squeak
The sound that a fox makes is called a howl
The sound that a leopard makes is called a
2024-08-01 07:46:32 root INFO     total operator prediction time: 1460.9396543502808 seconds
2024-08-01 07:46:32 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - youth
2024-08-01 07:46:32 root INFO     building operator animal - youth
2024-08-01 07:46:32 root INFO     [order_1_approx] starting weight calculation for The offspring of a salmon is referred to as a smolt
The offspring of a duck is referred to as a duckling
The offspring of a fly is referred to as a grub
The offspring of a buffalo is referred to as a calf
The offspring of a rabbit is referred to as a bunny
The offspring of a insect is referred to as a larva
The offspring of a horse is referred to as a foal
The offspring of a cat is referred to as a
2024-08-01 07:46:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 07:49:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0685, -0.0280,  0.0359,  ...,  0.0107, -0.1414, -0.0107],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8008, -3.1758, -2.3242,  ..., -0.3301, -0.4756,  0.2520],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0215, -0.0065,  0.0235,  ..., -0.0096,  0.0105, -0.0152],
        [ 0.0062,  0.0334,  0.0071,  ...,  0.0213,  0.0174,  0.0002],
        [ 0.0121, -0.0111,  0.0194,  ..., -0.0023, -0.0394, -0.0216],
        ...,
        [ 0.0034, -0.0149, -0.0357,  ...,  0.0162,  0.0024,  0.0118],
        [-0.0133,  0.0152, -0.0106,  ...,  0.0107,  0.0139,  0.0325],
        [-0.0053, -0.0278,  0.0105,  ..., -0.0290,  0.0183,  0.0093]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0508, -3.1504, -2.2090,  ...,  0.0254, -0.2029,  0.0492]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:49:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a salmon is referred to as a smolt
The offspring of a duck is referred to as a duckling
The offspring of a fly is referred to as a grub
The offspring of a buffalo is referred to as a calf
The offspring of a rabbit is referred to as a bunny
The offspring of a insect is referred to as a larva
The offspring of a horse is referred to as a foal
The offspring of a cat is referred to as a
2024-08-01 07:49:32 root INFO     [order_1_approx] starting weight calculation for The offspring of a cat is referred to as a kitten
The offspring of a salmon is referred to as a smolt
The offspring of a fly is referred to as a grub
The offspring of a duck is referred to as a duckling
The offspring of a insect is referred to as a larva
The offspring of a horse is referred to as a foal
The offspring of a buffalo is referred to as a calf
The offspring of a rabbit is referred to as a
2024-08-01 07:49:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 07:52:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0190,  0.0418,  0.0181,  ...,  0.0052, -0.1626, -0.0600],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.5000, -1.8633, -0.9116,  ...,  2.4062, -2.1152, -0.2793],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0585,  0.0304, -0.0052,  ...,  0.0273, -0.0078,  0.0094],
        [ 0.0130,  0.0115,  0.0014,  ...,  0.0125, -0.0005,  0.0070],
        [ 0.0043, -0.0036,  0.0093,  ..., -0.0083, -0.0068,  0.0026],
        ...,
        [-0.0064, -0.0047, -0.0117,  ...,  0.0124,  0.0086, -0.0078],
        [ 0.0019,  0.0003,  0.0020,  ..., -0.0009,  0.0169,  0.0092],
        [-0.0096, -0.0011,  0.0076,  ..., -0.0044,  0.0104,  0.0004]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.1836, -1.6641, -1.0703,  ...,  2.5566, -1.9434, -0.2773]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:52:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a cat is referred to as a kitten
The offspring of a salmon is referred to as a smolt
The offspring of a fly is referred to as a grub
The offspring of a duck is referred to as a duckling
The offspring of a insect is referred to as a larva
The offspring of a horse is referred to as a foal
The offspring of a buffalo is referred to as a calf
The offspring of a rabbit is referred to as a
2024-08-01 07:52:36 root INFO     [order_1_approx] starting weight calculation for The offspring of a duck is referred to as a duckling
The offspring of a buffalo is referred to as a calf
The offspring of a cat is referred to as a kitten
The offspring of a fly is referred to as a grub
The offspring of a rabbit is referred to as a bunny
The offspring of a horse is referred to as a foal
The offspring of a insect is referred to as a larva
The offspring of a salmon is referred to as a
2024-08-01 07:52:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 07:55:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0046,  0.0583,  0.0212,  ..., -0.1776, -0.1560,  0.0184],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0425, -2.9727, -6.1172,  ...,  0.0342, -3.7734,  1.9111],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0016, -0.0051,  0.0248,  ..., -0.0005, -0.0250, -0.0248],
        [ 0.0099,  0.0414,  0.0099,  ..., -0.0003,  0.0216,  0.0097],
        [ 0.0404, -0.0507,  0.0641,  ...,  0.0378, -0.0288, -0.0298],
        ...,
        [-0.0017,  0.0312, -0.0406,  ...,  0.0253,  0.0120,  0.0193],
        [-0.0096,  0.0264, -0.0015,  ...,  0.0586,  0.0252, -0.0014],
        [ 0.0161, -0.0220,  0.0309,  ..., -0.0522, -0.0371,  0.0296]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4785, -2.8359, -6.1641,  ...,  0.3591, -3.4512,  1.8281]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:55:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a duck is referred to as a duckling
The offspring of a buffalo is referred to as a calf
The offspring of a cat is referred to as a kitten
The offspring of a fly is referred to as a grub
The offspring of a rabbit is referred to as a bunny
The offspring of a horse is referred to as a foal
The offspring of a insect is referred to as a larva
The offspring of a salmon is referred to as a
2024-08-01 07:55:44 root INFO     [order_1_approx] starting weight calculation for The offspring of a salmon is referred to as a smolt
The offspring of a rabbit is referred to as a bunny
The offspring of a horse is referred to as a foal
The offspring of a fly is referred to as a grub
The offspring of a insect is referred to as a larva
The offspring of a duck is referred to as a duckling
The offspring of a cat is referred to as a kitten
The offspring of a buffalo is referred to as a
2024-08-01 07:55:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 07:58:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1534, -0.0186,  0.1343,  ...,  0.0453, -0.1985, -0.0511],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7656, -3.7422,  0.6670,  ...,  1.9941, -1.2490, -0.7266],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0246, -0.0044,  0.0286,  ..., -0.0003,  0.0161, -0.0457],
        [ 0.0222,  0.0150, -0.0048,  ..., -0.0046,  0.0107,  0.0146],
        [ 0.0556,  0.0066,  0.0285,  ...,  0.0270, -0.0211, -0.0208],
        ...,
        [ 0.0215,  0.0822, -0.0129,  ...,  0.0453,  0.0291, -0.0374],
        [-0.0314,  0.0630,  0.0560,  ..., -0.0002, -0.0018,  0.0147],
        [-0.0053, -0.0272, -0.0155,  ..., -0.0440,  0.0392,  0.0209]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7363, -3.4023,  0.8335,  ...,  2.1602, -1.5010, -0.3740]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:58:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a salmon is referred to as a smolt
The offspring of a rabbit is referred to as a bunny
The offspring of a horse is referred to as a foal
The offspring of a fly is referred to as a grub
The offspring of a insect is referred to as a larva
The offspring of a duck is referred to as a duckling
The offspring of a cat is referred to as a kitten
The offspring of a buffalo is referred to as a
2024-08-01 07:58:48 root INFO     [order_1_approx] starting weight calculation for The offspring of a duck is referred to as a duckling
The offspring of a buffalo is referred to as a calf
The offspring of a cat is referred to as a kitten
The offspring of a fly is referred to as a grub
The offspring of a salmon is referred to as a smolt
The offspring of a rabbit is referred to as a bunny
The offspring of a horse is referred to as a foal
The offspring of a insect is referred to as a
2024-08-01 07:58:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 08:01:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2793,  0.0347,  0.2266,  ...,  0.0214, -0.0872, -0.1018],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7461, -2.3164, -0.3120,  ..., -0.4658, -2.0293,  0.8916],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0267,  0.0042,  0.0123,  ..., -0.0002, -0.0274,  0.0090],
        [ 0.0040,  0.0196,  0.0066,  ...,  0.0076,  0.0164,  0.0009],
        [-0.0204, -0.0020,  0.0396,  ..., -0.0283, -0.0252, -0.0125],
        ...,
        [ 0.0051, -0.0082, -0.0028,  ...,  0.0098,  0.0171,  0.0096],
        [ 0.0098,  0.0277,  0.0054,  ...,  0.0024,  0.0442, -0.0079],
        [-0.0021, -0.0049,  0.0010,  ...,  0.0092, -0.0067,  0.0234]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5840, -2.4102, -0.9907,  ..., -0.1936, -2.1504,  1.1113]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:01:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a duck is referred to as a duckling
The offspring of a buffalo is referred to as a calf
The offspring of a cat is referred to as a kitten
The offspring of a fly is referred to as a grub
The offspring of a salmon is referred to as a smolt
The offspring of a rabbit is referred to as a bunny
The offspring of a horse is referred to as a foal
The offspring of a insect is referred to as a
2024-08-01 08:01:56 root INFO     [order_1_approx] starting weight calculation for The offspring of a cat is referred to as a kitten
The offspring of a rabbit is referred to as a bunny
The offspring of a fly is referred to as a grub
The offspring of a salmon is referred to as a smolt
The offspring of a buffalo is referred to as a calf
The offspring of a horse is referred to as a foal
The offspring of a insect is referred to as a larva
The offspring of a duck is referred to as a
2024-08-01 08:01:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 08:04:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1895, -0.0906,  0.0917,  ..., -0.1367, -0.1124, -0.1375],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1943, -1.5938, -1.6865,  ...,  0.6807, -5.3555,  2.1289],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0541,  0.0153,  0.0141,  ...,  0.0151, -0.0110,  0.0132],
        [-0.0529, -0.0293,  0.0261,  ..., -0.0252,  0.0051,  0.0042],
        [ 0.0226,  0.0085,  0.0180,  ...,  0.0132, -0.0099, -0.0137],
        ...,
        [-0.0207,  0.0082, -0.0026,  ...,  0.0120,  0.0135,  0.0202],
        [-0.0286, -0.0255,  0.0131,  ..., -0.0006,  0.0138,  0.0197],
        [-0.0419, -0.0422,  0.0320,  ..., -0.0241,  0.0089, -0.0257]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7510, -1.3096, -2.0684,  ...,  1.0781, -5.3945,  2.7793]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:04:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a cat is referred to as a kitten
The offspring of a rabbit is referred to as a bunny
The offspring of a fly is referred to as a grub
The offspring of a salmon is referred to as a smolt
The offspring of a buffalo is referred to as a calf
The offspring of a horse is referred to as a foal
The offspring of a insect is referred to as a larva
The offspring of a duck is referred to as a
2024-08-01 08:04:58 root INFO     [order_1_approx] starting weight calculation for The offspring of a horse is referred to as a foal
The offspring of a salmon is referred to as a smolt
The offspring of a rabbit is referred to as a bunny
The offspring of a insect is referred to as a larva
The offspring of a duck is referred to as a duckling
The offspring of a cat is referred to as a kitten
The offspring of a buffalo is referred to as a calf
The offspring of a fly is referred to as a
2024-08-01 08:04:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 08:08:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1616,  0.0013, -0.0269,  ..., -0.0243, -0.1190,  0.1802],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1367, -2.4238, -1.9004,  ...,  0.5684, -2.4766,  0.7422],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0123,  0.0228,  0.0271,  ...,  0.0099, -0.0343, -0.0245],
        [ 0.0131,  0.0255, -0.0051,  ...,  0.0132,  0.0409,  0.0031],
        [-0.0124, -0.0144,  0.0472,  ..., -0.0227, -0.0010, -0.0060],
        ...,
        [ 0.0156,  0.0064, -0.0380,  ..., -0.0066,  0.0300,  0.0329],
        [ 0.0139,  0.0586, -0.0088,  ...,  0.0449,  0.0706, -0.0073],
        [ 0.0031, -0.0152,  0.0334,  ...,  0.0073, -0.0311,  0.0186]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4805, -1.9473, -2.4004,  ...,  1.0254, -2.2617,  0.7783]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:08:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a horse is referred to as a foal
The offspring of a salmon is referred to as a smolt
The offspring of a rabbit is referred to as a bunny
The offspring of a insect is referred to as a larva
The offspring of a duck is referred to as a duckling
The offspring of a cat is referred to as a kitten
The offspring of a buffalo is referred to as a calf
The offspring of a fly is referred to as a
2024-08-01 08:08:04 root INFO     [order_1_approx] starting weight calculation for The offspring of a rabbit is referred to as a bunny
The offspring of a salmon is referred to as a smolt
The offspring of a duck is referred to as a duckling
The offspring of a buffalo is referred to as a calf
The offspring of a cat is referred to as a kitten
The offspring of a insect is referred to as a larva
The offspring of a fly is referred to as a grub
The offspring of a horse is referred to as a
2024-08-01 08:08:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 08:11:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0132,  0.0637,  0.1982,  ...,  0.0299, -0.0343,  0.0547],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5166, -4.7461, -2.8262,  ...,  2.8281, -1.2188,  2.1094],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0168, -0.0102,  0.0333,  ...,  0.0206, -0.0052,  0.0135],
        [-0.0043,  0.0279, -0.0174,  ...,  0.0076,  0.0148,  0.0057],
        [ 0.0117, -0.0091,  0.0311,  ..., -0.0253, -0.0360, -0.0101],
        ...,
        [ 0.0027,  0.0253, -0.0315,  ...,  0.0161,  0.0184, -0.0059],
        [-0.0053,  0.0201, -0.0088,  ..., -0.0012,  0.0180,  0.0028],
        [ 0.0207, -0.0246,  0.0162,  ..., -0.0104, -0.0177, -0.0060]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3965, -4.5039, -2.3379,  ...,  2.4805, -1.2402,  2.2324]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:11:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a rabbit is referred to as a bunny
The offspring of a salmon is referred to as a smolt
The offspring of a duck is referred to as a duckling
The offspring of a buffalo is referred to as a calf
The offspring of a cat is referred to as a kitten
The offspring of a insect is referred to as a larva
The offspring of a fly is referred to as a grub
The offspring of a horse is referred to as a
2024-08-01 08:11:00 root INFO     total operator prediction time: 1468.387733221054 seconds
2024-08-01 08:11:00 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on UK_city - county
2024-08-01 08:11:00 root INFO     building operator UK_city - county
2024-08-01 08:11:01 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of southampton is in the county of hampshire
In the United Kingdom, the city of oxford is in the county of oxfordshire
In the United Kingdom, the city of leeds is in the county of yorkshire
In the United Kingdom, the city of hereford is in the county of herefordshire
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of derby is in the county of derbyshire
In the United Kingdom, the city of gloucester is in the county of gloucestershire
In the United Kingdom, the city of canterbury is in the county of
2024-08-01 08:11:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 08:14:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1073, -0.0078, -0.1448,  ...,  0.1261, -0.2183,  0.1810],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9199, -1.5234, -1.4258,  ..., -1.8682,  1.6855, -0.8555],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0112, -0.0058,  0.0134,  ..., -0.0165,  0.0030,  0.0068],
        [ 0.0314,  0.0650,  0.0342,  ...,  0.0334, -0.0003, -0.1105],
        [-0.0071,  0.0097,  0.0041,  ...,  0.0066,  0.0038, -0.0069],
        ...,
        [ 0.0273,  0.0573,  0.0252,  ...,  0.0219, -0.0137, -0.0807],
        [-0.0173, -0.0489, -0.0235,  ...,  0.0040,  0.0097,  0.0510],
        [ 0.0106,  0.0011, -0.0057,  ...,  0.0123,  0.0017, -0.0291]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9746, -1.7744, -1.4102,  ..., -2.1445,  2.0215, -0.9458]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:14:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of southampton is in the county of hampshire
In the United Kingdom, the city of oxford is in the county of oxfordshire
In the United Kingdom, the city of leeds is in the county of yorkshire
In the United Kingdom, the city of hereford is in the county of herefordshire
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of derby is in the county of derbyshire
In the United Kingdom, the city of gloucester is in the county of gloucestershire
In the United Kingdom, the city of canterbury is in the county of
2024-08-01 08:14:44 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of southampton is in the county of hampshire
In the United Kingdom, the city of hereford is in the county of herefordshire
In the United Kingdom, the city of gloucester is in the county of gloucestershire
In the United Kingdom, the city of canterbury is in the county of kent
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of leeds is in the county of yorkshire
In the United Kingdom, the city of oxford is in the county of oxfordshire
In the United Kingdom, the city of derby is in the county of
2024-08-01 08:14:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 08:18:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1093,  0.0875,  0.0359,  ...,  0.1000, -0.1774,  0.1241],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.9688, -2.0586,  2.1152,  ..., -3.7344, -0.0186, -1.6338],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0129, -0.0090,  0.0356,  ...,  0.0247, -0.0225, -0.0123],
        [-0.0102, -0.0022,  0.0464,  ...,  0.0387,  0.0323, -0.0184],
        [ 0.0344, -0.0080,  0.0216,  ...,  0.0080, -0.0112, -0.0467],
        ...,
        [ 0.0459,  0.0127, -0.0280,  ...,  0.0270, -0.0097, -0.0157],
        [-0.0440, -0.0044, -0.0377,  ...,  0.0523,  0.0383,  0.0271],
        [ 0.0157, -0.0336, -0.0133,  ...,  0.0059, -0.0184, -0.0052]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.0195, -1.7168,  1.8691,  ..., -3.7480,  0.4907, -1.7910]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:18:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of southampton is in the county of hampshire
In the United Kingdom, the city of hereford is in the county of herefordshire
In the United Kingdom, the city of gloucester is in the county of gloucestershire
In the United Kingdom, the city of canterbury is in the county of kent
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of leeds is in the county of yorkshire
In the United Kingdom, the city of oxford is in the county of oxfordshire
In the United Kingdom, the city of derby is in the county of
2024-08-01 08:18:15 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of leeds is in the county of yorkshire
In the United Kingdom, the city of hereford is in the county of herefordshire
In the United Kingdom, the city of derby is in the county of derbyshire
In the United Kingdom, the city of southampton is in the county of hampshire
In the United Kingdom, the city of canterbury is in the county of kent
In the United Kingdom, the city of oxford is in the county of oxfordshire
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of gloucester is in the county of
2024-08-01 08:18:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 08:21:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2174, -0.0784, -0.2039,  ...,  0.1106, -0.0565,  0.2446],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7783, -1.8564,  1.0029,  ..., -3.2070,  2.4219, -0.4519],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0234,  0.0334,  0.0317,  ...,  0.0036, -0.0192, -0.0299],
        [ 0.0339,  0.1181,  0.0246,  ...,  0.0197, -0.0858, -0.0920],
        [ 0.0081,  0.0837,  0.0300,  ...,  0.0418, -0.0585, -0.0740],
        ...,
        [ 0.0487,  0.1794,  0.0657,  ...,  0.0096, -0.1136, -0.1344],
        [-0.0429, -0.1240, -0.0431,  ..., -0.0134,  0.0851,  0.0689],
        [ 0.0236,  0.0583,  0.0229,  ..., -0.0018, -0.0599, -0.0581]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7695, -2.0410,  0.7100,  ..., -3.3125,  2.7344, -0.7168]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:21:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of leeds is in the county of yorkshire
In the United Kingdom, the city of hereford is in the county of herefordshire
In the United Kingdom, the city of derby is in the county of derbyshire
In the United Kingdom, the city of southampton is in the county of hampshire
In the United Kingdom, the city of canterbury is in the county of kent
In the United Kingdom, the city of oxford is in the county of oxfordshire
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of gloucester is in the county of
2024-08-01 08:21:53 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of gloucester is in the county of gloucestershire
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of southampton is in the county of hampshire
In the United Kingdom, the city of canterbury is in the county of kent
In the United Kingdom, the city of derby is in the county of derbyshire
In the United Kingdom, the city of oxford is in the county of oxfordshire
In the United Kingdom, the city of leeds is in the county of yorkshire
In the United Kingdom, the city of hereford is in the county of
2024-08-01 08:21:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 08:25:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1798, -0.1117,  0.0330,  ...,  0.1998, -0.0096,  0.1011],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3125, -4.1797,  1.8633,  ..., -2.4883,  0.5547, -0.0303],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0591, -0.0061,  0.0263,  ...,  0.0124, -0.0212, -0.0324],
        [ 0.0032,  0.0165,  0.0295,  ...,  0.0220,  0.0032, -0.0023],
        [-0.0110,  0.0391,  0.0040,  ...,  0.0274,  0.0016, -0.0769],
        ...,
        [ 0.0995,  0.0064, -0.0029,  ...,  0.0320, -0.0420, -0.0410],
        [-0.0707, -0.0588,  0.0077,  ..., -0.0303,  0.0131,  0.0571],
        [ 0.0586, -0.0143, -0.0213,  ...,  0.0113, -0.0162, -0.0237]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7275, -4.1406,  1.6299,  ..., -2.5508,  1.5977, -0.4778]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:25:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of gloucester is in the county of gloucestershire
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of southampton is in the county of hampshire
In the United Kingdom, the city of canterbury is in the county of kent
In the United Kingdom, the city of derby is in the county of derbyshire
In the United Kingdom, the city of oxford is in the county of oxfordshire
In the United Kingdom, the city of leeds is in the county of yorkshire
In the United Kingdom, the city of hereford is in the county of
2024-08-01 08:25:24 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of hereford is in the county of herefordshire
In the United Kingdom, the city of derby is in the county of derbyshire
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of leeds is in the county of yorkshire
In the United Kingdom, the city of canterbury is in the county of kent
In the United Kingdom, the city of southampton is in the county of hampshire
In the United Kingdom, the city of gloucester is in the county of gloucestershire
In the United Kingdom, the city of oxford is in the county of
2024-08-01 08:25:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 08:28:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0795,  0.1686, -0.1131,  ..., -0.0469, -0.0660,  0.0125],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9785, -3.9844, -0.7080,  ..., -1.0020, -0.1040, -2.1270],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0087, -0.0073,  0.0075,  ...,  0.0060, -0.0210,  0.0089],
        [ 0.0058,  0.0091,  0.0218,  ..., -0.0026, -0.0037, -0.0222],
        [-0.0177, -0.0055,  0.0132,  ..., -0.0070,  0.0031, -0.0071],
        ...,
        [ 0.0241,  0.0132,  0.0059,  ..., -0.0033,  0.0097, -0.0169],
        [-0.0052, -0.0129, -0.0052,  ...,  0.0197,  0.0001,  0.0232],
        [ 0.0060, -0.0075, -0.0117,  ...,  0.0021, -0.0272, -0.0089]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0820, -3.7988, -1.1230,  ..., -1.1377,  0.2151, -2.2598]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:28:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of hereford is in the county of herefordshire
In the United Kingdom, the city of derby is in the county of derbyshire
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of leeds is in the county of yorkshire
In the United Kingdom, the city of canterbury is in the county of kent
In the United Kingdom, the city of southampton is in the county of hampshire
In the United Kingdom, the city of gloucester is in the county of gloucestershire
In the United Kingdom, the city of oxford is in the county of
2024-08-01 08:28:58 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of leeds is in the county of yorkshire
In the United Kingdom, the city of canterbury is in the county of kent
In the United Kingdom, the city of hereford is in the county of herefordshire
In the United Kingdom, the city of oxford is in the county of oxfordshire
In the United Kingdom, the city of gloucester is in the county of gloucestershire
In the United Kingdom, the city of derby is in the county of derbyshire
In the United Kingdom, the city of southampton is in the county of hampshire
In the United Kingdom, the city of stirling is in the county of
2024-08-01 08:28:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 08:32:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0454, -0.0592, -0.2666,  ...,  0.1498, -0.0693,  0.1868],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5703, -3.7344,  0.0000,  ..., -3.3945, -1.7578, -1.5605],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0071, -0.0284, -0.0018,  ...,  0.0124, -0.0211, -0.0118],
        [ 0.0470,  0.0047,  0.0360,  ...,  0.0280, -0.0055, -0.0404],
        [-0.0032,  0.0285,  0.0161,  ...,  0.0076, -0.0372, -0.0362],
        ...,
        [ 0.0436,  0.0523, -0.0219,  ...,  0.0376, -0.0556, -0.0266],
        [-0.0962, -0.0980, -0.0258,  ..., -0.0115,  0.1154,  0.0641],
        [-0.0199, -0.0263, -0.0212,  ..., -0.0094, -0.0040,  0.0436]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6055, -3.8594,  0.0461,  ..., -2.9727, -0.7041, -1.4482]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:32:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of leeds is in the county of yorkshire
In the United Kingdom, the city of canterbury is in the county of kent
In the United Kingdom, the city of hereford is in the county of herefordshire
In the United Kingdom, the city of oxford is in the county of oxfordshire
In the United Kingdom, the city of gloucester is in the county of gloucestershire
In the United Kingdom, the city of derby is in the county of derbyshire
In the United Kingdom, the city of southampton is in the county of hampshire
In the United Kingdom, the city of stirling is in the county of
2024-08-01 08:32:35 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of leeds is in the county of yorkshire
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of oxford is in the county of oxfordshire
In the United Kingdom, the city of canterbury is in the county of kent
In the United Kingdom, the city of hereford is in the county of herefordshire
In the United Kingdom, the city of gloucester is in the county of gloucestershire
In the United Kingdom, the city of derby is in the county of derbyshire
In the United Kingdom, the city of southampton is in the county of
2024-08-01 08:32:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 08:36:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2917,  0.0967, -0.2067,  ...,  0.2002, -0.0604, -0.0532],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7188, -3.8379,  1.2471,  ..., -3.8086,  0.1836,  0.6396],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0045,  0.0047,  0.0084,  ...,  0.0152, -0.0059, -0.0099],
        [-0.0040,  0.0092,  0.0134,  ...,  0.0173,  0.0097, -0.0106],
        [-0.0159, -0.0258,  0.0005,  ..., -0.0053,  0.0131, -0.0221],
        ...,
        [ 0.0113, -0.0082,  0.0046,  ...,  0.0042,  0.0023, -0.0095],
        [-0.0080, -0.0329, -0.0172,  ...,  0.0022,  0.0095,  0.0353],
        [ 0.0088, -0.0057, -0.0002,  ...,  0.0008, -0.0065, -0.0047]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8359, -3.7109,  1.1553,  ..., -3.8223,  0.4089,  0.4551]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:36:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of leeds is in the county of yorkshire
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of oxford is in the county of oxfordshire
In the United Kingdom, the city of canterbury is in the county of kent
In the United Kingdom, the city of hereford is in the county of herefordshire
In the United Kingdom, the city of gloucester is in the county of gloucestershire
In the United Kingdom, the city of derby is in the county of derbyshire
In the United Kingdom, the city of southampton is in the county of
2024-08-01 08:36:07 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of canterbury is in the county of kent
In the United Kingdom, the city of hereford is in the county of herefordshire
In the United Kingdom, the city of oxford is in the county of oxfordshire
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of derby is in the county of derbyshire
In the United Kingdom, the city of southampton is in the county of hampshire
In the United Kingdom, the city of gloucester is in the county of gloucestershire
In the United Kingdom, the city of leeds is in the county of
2024-08-01 08:36:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 08:39:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1340, -0.0983, -0.2117,  ...,  0.0094, -0.1086,  0.1364],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6768, -4.5312, -1.4746,  ..., -1.7773,  0.0791, -0.6572],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.3451e-02,  9.7961e-03,  3.6316e-03,  ...,  7.9346e-03,
         -1.9562e-02, -1.2680e-02],
        [-1.3580e-02, -2.5848e-02,  9.9182e-05,  ...,  1.8585e-02,
         -1.0765e-02, -1.6022e-03],
        [-2.1759e-02, -1.3496e-02, -1.2894e-03,  ...,  1.8280e-02,
         -2.5940e-03, -1.4389e-02],
        ...,
        [ 1.5106e-02,  8.2703e-03, -2.1362e-02,  ...,  2.7756e-02,
         -8.8501e-03, -2.2446e-02],
        [-8.2703e-03, -1.3351e-03, -1.5015e-02,  ...,  3.9948e-02,
         -1.2283e-02,  1.3489e-02],
        [ 1.0529e-03, -4.5288e-02, -3.9124e-02,  ..., -7.8735e-03,
         -4.4785e-03, -1.2047e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5547, -4.3750, -1.3799,  ..., -1.5029, -0.0879, -0.6167]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:39:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of canterbury is in the county of kent
In the United Kingdom, the city of hereford is in the county of herefordshire
In the United Kingdom, the city of oxford is in the county of oxfordshire
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of derby is in the county of derbyshire
In the United Kingdom, the city of southampton is in the county of hampshire
In the United Kingdom, the city of gloucester is in the county of gloucestershire
In the United Kingdom, the city of leeds is in the county of
2024-08-01 08:39:43 root INFO     total operator prediction time: 1722.8394649028778 seconds
2024-08-01 08:39:43 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - part
2024-08-01 08:39:43 root INFO     building operator meronyms - part
2024-08-01 08:39:44 root INFO     [order_1_approx] starting weight calculation for A part of a jewellery is a bead
A part of a poem is a stanza
A part of a day is a hour
A part of a cat is a whiskers
A part of a tonne is a kilogram
A part of a bus is a seats
A part of a telephone is a receiver
A part of a sonata is a
2024-08-01 08:39:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 08:42:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1836,  0.0914,  0.0248,  ..., -0.2502, -0.3516, -0.1860],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3579, -5.0664,  2.7949,  ...,  2.8164,  0.4150,  3.0898],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0302, -0.0524, -0.0384,  ..., -0.0491,  0.0434, -0.0093],
        [ 0.0032, -0.0320, -0.0182,  ...,  0.0215,  0.0231,  0.0537],
        [-0.0077, -0.0297,  0.0410,  ..., -0.0093, -0.0466,  0.0116],
        ...,
        [ 0.0331,  0.0159,  0.0158,  ...,  0.0864,  0.0211, -0.0540],
        [-0.0421,  0.0068, -0.0494,  ...,  0.0152,  0.0147,  0.0388],
        [-0.0283,  0.0396,  0.0874,  ...,  0.0274, -0.0321, -0.0252]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6758, -5.7070,  3.7266,  ...,  2.5195,  0.9067,  2.6777]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:42:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a jewellery is a bead
A part of a poem is a stanza
A part of a day is a hour
A part of a cat is a whiskers
A part of a tonne is a kilogram
A part of a bus is a seats
A part of a telephone is a receiver
A part of a sonata is a
2024-08-01 08:42:46 root INFO     [order_1_approx] starting weight calculation for A part of a sonata is a movement
A part of a poem is a stanza
A part of a day is a hour
A part of a jewellery is a bead
A part of a telephone is a receiver
A part of a bus is a seats
A part of a cat is a whiskers
A part of a tonne is a
2024-08-01 08:42:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 08:45:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1039,  0.1405, -0.0007,  ...,  0.0789, -0.1901,  0.3057],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.7617, -5.5078,  2.4473,  ..., -1.7793, -1.2344,  0.0419],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0750,  0.0360, -0.0284,  ...,  0.0037, -0.0086,  0.0209],
        [ 0.0596, -0.0005,  0.0237,  ..., -0.0220,  0.0319, -0.0229],
        [-0.0298,  0.0110,  0.0800,  ...,  0.0036,  0.0609,  0.0079],
        ...,
        [ 0.0436, -0.0208,  0.0452,  ...,  0.1157,  0.0591,  0.0316],
        [-0.0098,  0.0418, -0.0114,  ..., -0.0166, -0.0020,  0.0193],
        [-0.0182, -0.0167, -0.0303,  ...,  0.0648,  0.0058, -0.0076]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0000, -4.8047,  3.3164,  ..., -1.2939, -1.4863, -0.2583]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:45:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a sonata is a movement
A part of a poem is a stanza
A part of a day is a hour
A part of a jewellery is a bead
A part of a telephone is a receiver
A part of a bus is a seats
A part of a cat is a whiskers
A part of a tonne is a
2024-08-01 08:45:49 root INFO     [order_1_approx] starting weight calculation for A part of a telephone is a receiver
A part of a poem is a stanza
A part of a cat is a whiskers
A part of a sonata is a movement
A part of a day is a hour
A part of a tonne is a kilogram
A part of a jewellery is a bead
A part of a bus is a
2024-08-01 08:45:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 08:48:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0918, -0.0393,  0.2064,  ...,  0.0684, -0.2859,  0.1116],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3125, -2.6719, -2.7617,  ...,  7.2266, -1.1934, -2.4180],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0157,  0.0047, -0.0271,  ...,  0.0181,  0.0131,  0.0149],
        [ 0.0026,  0.0314,  0.0095,  ...,  0.0162,  0.0223, -0.0017],
        [ 0.0078, -0.0342,  0.0331,  ..., -0.0228, -0.0831,  0.0280],
        ...,
        [ 0.0193,  0.0215, -0.0120,  ...,  0.0294,  0.0636, -0.0308],
        [-0.0080,  0.0227, -0.0265,  ...,  0.0015,  0.0310, -0.0034],
        [ 0.0155, -0.0069,  0.0482,  ...,  0.0019,  0.0108,  0.0213]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0819, -2.8594, -2.6426,  ...,  6.2656, -1.7666, -2.3496]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:48:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a telephone is a receiver
A part of a poem is a stanza
A part of a cat is a whiskers
A part of a sonata is a movement
A part of a day is a hour
A part of a tonne is a kilogram
A part of a jewellery is a bead
A part of a bus is a
2024-08-01 08:48:53 root INFO     [order_1_approx] starting weight calculation for A part of a telephone is a receiver
A part of a cat is a whiskers
A part of a tonne is a kilogram
A part of a sonata is a movement
A part of a poem is a stanza
A part of a bus is a seats
A part of a jewellery is a bead
A part of a day is a
2024-08-01 08:48:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 08:51:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1056,  0.0018, -0.0253,  ..., -0.0718, -0.3772,  0.0366],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3867, -4.5469,  2.7305,  ..., -0.2925,  1.6816, -1.4941],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.2786e-02,  1.5091e-02,  9.3765e-03,  ...,  6.0303e-02,
          7.6294e-05,  5.2528e-03],
        [-1.8005e-03, -1.9470e-02, -1.9806e-02,  ..., -3.5492e-02,
         -6.5674e-02, -2.1973e-02],
        [-5.3955e-02, -4.8615e-02,  1.3481e-02,  ..., -4.1443e-02,
         -2.9236e-02,  1.4793e-02],
        ...,
        [-4.3213e-02, -6.6101e-02,  8.4229e-03,  ..., -7.6752e-03,
         -1.7517e-02, -2.7027e-03],
        [ 6.4270e-02,  7.0557e-02, -1.5991e-02,  ...,  5.0476e-02,
          4.1168e-02, -1.3969e-02],
        [-3.7231e-02, -3.2806e-02, -3.5645e-02,  ..., -9.4299e-03,
         -3.0182e-02, -4.3259e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5273, -3.9102,  2.7754,  ...,  0.2378,  1.5146, -0.9155]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:51:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a telephone is a receiver
A part of a cat is a whiskers
A part of a tonne is a kilogram
A part of a sonata is a movement
A part of a poem is a stanza
A part of a bus is a seats
A part of a jewellery is a bead
A part of a day is a
2024-08-01 08:51:57 root INFO     [order_1_approx] starting weight calculation for A part of a bus is a seats
A part of a tonne is a kilogram
A part of a telephone is a receiver
A part of a cat is a whiskers
A part of a jewellery is a bead
A part of a sonata is a movement
A part of a day is a hour
A part of a poem is a
2024-08-01 08:51:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 08:55:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0471,  0.1350, -0.0344,  ..., -0.0217, -0.3523,  0.0335],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7773, -5.8750,  5.2305,  ...,  5.3516,  0.8887, -2.8223],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-1.0452e-02, -1.2375e-02,  3.3142e-02,  ...,  2.7542e-02,
          2.0386e-02,  4.9988e-02],
        [-2.8381e-03, -2.2064e-02, -1.3000e-02,  ...,  2.0370e-03,
         -2.7344e-02,  8.0261e-03],
        [-3.7170e-02,  1.8127e-02,  4.9561e-02,  ..., -1.1726e-02,
          8.9493e-03,  1.0178e-02],
        ...,
        [-1.0941e-02, -1.2253e-02,  7.2479e-05,  ...,  2.6825e-02,
         -1.4038e-02, -5.3177e-03],
        [-2.1637e-02,  4.0802e-02, -3.9703e-02,  ..., -1.2939e-02,
          2.1820e-02, -1.1139e-02],
        [-2.4872e-02, -6.5796e-02,  1.7410e-02,  ..., -2.4841e-02,
         -4.6631e-02,  7.3364e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5957, -5.1797,  5.0273,  ...,  5.4258,  0.9590, -1.8594]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:55:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a bus is a seats
A part of a tonne is a kilogram
A part of a telephone is a receiver
A part of a cat is a whiskers
A part of a jewellery is a bead
A part of a sonata is a movement
A part of a day is a hour
A part of a poem is a
2024-08-01 08:55:01 root INFO     [order_1_approx] starting weight calculation for A part of a sonata is a movement
A part of a bus is a seats
A part of a day is a hour
A part of a telephone is a receiver
A part of a tonne is a kilogram
A part of a cat is a whiskers
A part of a poem is a stanza
A part of a jewellery is a
2024-08-01 08:55:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 08:58:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1625, -0.0101, -0.0114,  ...,  0.0248, -0.2573, -0.1670],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0725, -2.6582, -4.4297,  ..., -0.1934, -1.8496,  1.7891],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0041, -0.0097,  0.0100,  ..., -0.0019,  0.0018,  0.0191],
        [ 0.0091, -0.0025,  0.0063,  ..., -0.0034,  0.0228,  0.0123],
        [ 0.0106,  0.0082,  0.0092,  ..., -0.0002, -0.0126, -0.0086],
        ...,
        [ 0.0061, -0.0220, -0.0027,  ...,  0.0065,  0.0030,  0.0014],
        [-0.0098,  0.0013, -0.0077,  ...,  0.0006, -0.0002, -0.0128],
        [ 0.0108, -0.0018, -0.0058,  ..., -0.0016, -0.0072, -0.0052]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0406, -2.5547, -4.2578,  ..., -0.3760, -1.7861,  1.7139]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:58:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a sonata is a movement
A part of a bus is a seats
A part of a day is a hour
A part of a telephone is a receiver
A part of a tonne is a kilogram
A part of a cat is a whiskers
A part of a poem is a stanza
A part of a jewellery is a
2024-08-01 08:58:04 root INFO     [order_1_approx] starting weight calculation for A part of a day is a hour
A part of a tonne is a kilogram
A part of a sonata is a movement
A part of a bus is a seats
A part of a jewellery is a bead
A part of a poem is a stanza
A part of a cat is a whiskers
A part of a telephone is a
2024-08-01 08:58:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 09:01:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1362, -0.1198, -0.3196,  ..., -0.1453, -0.1421, -0.3467],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3086, -4.7539, -1.0527,  ...,  3.5742,  2.2656, -4.2383],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0357, -0.0070, -0.0051,  ..., -0.0330,  0.0169, -0.0434],
        [-0.0244, -0.0658,  0.0042,  ...,  0.0227, -0.0080,  0.0536],
        [ 0.0218, -0.0131, -0.0206,  ..., -0.0066, -0.0235,  0.0039],
        ...,
        [ 0.0042,  0.0275, -0.0085,  ...,  0.0378, -0.0175,  0.0213],
        [-0.0015,  0.0414, -0.0469,  ..., -0.0097,  0.0221, -0.0512],
        [ 0.0062, -0.0627,  0.0486,  ...,  0.0534, -0.0145,  0.0864]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3291, -4.8555, -0.5967,  ...,  3.3965,  2.1738, -4.2344]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 09:01:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a day is a hour
A part of a tonne is a kilogram
A part of a sonata is a movement
A part of a bus is a seats
A part of a jewellery is a bead
A part of a poem is a stanza
A part of a cat is a whiskers
A part of a telephone is a
2024-08-01 09:01:07 root INFO     [order_1_approx] starting weight calculation for A part of a day is a hour
A part of a telephone is a receiver
A part of a jewellery is a bead
A part of a sonata is a movement
A part of a tonne is a kilogram
A part of a poem is a stanza
A part of a bus is a seats
A part of a cat is a
2024-08-01 09:01:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 09:04:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0239, -0.0430,  0.0029,  ..., -0.1416, -0.3179, -0.0063],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5625, -2.4238, -2.4277,  ...,  0.2695, -2.8555, -0.5928],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.1383e-02,  4.2038e-03,  5.1422e-03,  ..., -3.6133e-02,
         -1.4877e-02, -8.3618e-03],
        [-9.7504e-03,  1.0895e-02,  2.1606e-02,  ...,  1.3245e-02,
          4.9561e-02,  3.7903e-02],
        [-3.8071e-03, -1.2680e-02,  6.0059e-02,  ..., -9.1553e-05,
         -1.3474e-02,  2.0081e-02],
        ...,
        [-3.6621e-02, -2.5742e-02,  1.4702e-02,  ...,  5.2826e-02,
         -1.3168e-02,  2.2476e-02],
        [ 5.7373e-03,  4.2908e-02,  1.4519e-02,  ...,  1.5053e-02,
          3.0289e-03, -2.1881e-02],
        [-4.6387e-02, -5.7770e-02, -6.8321e-03,  ..., -1.9867e-02,
         -6.3286e-03,  4.5105e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4043, -2.5234, -3.1641,  ...,  0.3250, -2.5781, -0.4075]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 09:04:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a day is a hour
A part of a telephone is a receiver
A part of a jewellery is a bead
A part of a sonata is a movement
A part of a tonne is a kilogram
A part of a poem is a stanza
A part of a bus is a seats
A part of a cat is a
2024-08-01 09:04:10 root INFO     total operator prediction time: 1466.992758512497 seconds
2024-08-01 09:04:10 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on synonyms - exact
2024-08-01 09:04:10 root INFO     building operator synonyms - exact
2024-08-01 09:04:11 root INFO     [order_1_approx] starting weight calculation for Another word for lad is chap
Another word for airplane is aeroplane
Another word for emphasis is accent
Another word for harbor is seaport
Another word for intelligent is clever
Another word for vocabulary is lexicon
Another word for flower is blossom
Another word for market is
2024-08-01 09:04:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
2024-08-01 09:07:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0675,  0.1302, -0.2114,  ...,  0.0425, -0.0425, -0.0242],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.2305, -0.8721, -0.4265,  ...,  0.7720, -2.7754,  0.0352],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0778,  0.0168, -0.0036,  ...,  0.0099, -0.0417,  0.0037],
        [ 0.0038,  0.0433,  0.0124,  ...,  0.0905,  0.0125,  0.0035],
        [-0.0197, -0.0117,  0.0742,  ..., -0.0464,  0.0181,  0.0354],
        ...,
        [-0.0017,  0.0041,  0.0149,  ...,  0.0414, -0.0150,  0.0261],
        [-0.0033,  0.0139, -0.0233,  ...,  0.0109,  0.0582, -0.0240],
        [-0.0064, -0.0045,  0.0038,  ...,  0.0697, -0.0009,  0.0372]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2642, -1.3359, -0.5132,  ...,  1.0156, -2.2227,  0.0524]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 09:07:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for lad is chap
Another word for airplane is aeroplane
Another word for emphasis is accent
Another word for harbor is seaport
Another word for intelligent is clever
Another word for vocabulary is lexicon
Another word for flower is blossom
Another word for market is
2024-08-01 09:07:14 root INFO     [order_1_approx] starting weight calculation for Another word for vocabulary is lexicon
Another word for intelligent is clever
Another word for market is marketplace
Another word for emphasis is accent
Another word for harbor is seaport
Another word for lad is chap
Another word for flower is blossom
Another word for airplane is
2024-08-01 09:07:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.6
