2024-07-29 09:26:52 root INFO     loading model + tokenizer
2024-07-29 09:27:27 root INFO     loading model + tokenizer
2024-07-29 09:27:30 root INFO     model + tokenizer loaded
2024-07-29 09:27:30 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+ment_irreg
2024-07-29 09:27:30 root INFO     building operator verb+ment_irreg
2024-07-29 09:27:31 root INFO     [order_1_approx] starting weight calculation for To fulfil results in a fulfilment
To resent results in a resentment
To achieve results in a achievement
To assign results in a assignment
To develop results in a development
To displace results in a displacement
To manage results in a management
To enroll results in a
2024-07-29 09:27:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 09:29:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0063,  0.1787, -0.4094,  ...,  0.0775, -0.1837, -0.5312],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6152, -2.5957, -1.7686,  ...,  2.1250, -0.6323, -5.2266],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0851,  0.0130,  0.0201,  ..., -0.0049,  0.0054,  0.0099],
        [-0.0053,  0.0814,  0.0244,  ...,  0.0313, -0.0122,  0.0068],
        [-0.0052, -0.0222,  0.0707,  ..., -0.0125, -0.0010, -0.0199],
        ...,
        [ 0.0027, -0.0010, -0.0304,  ...,  0.0772,  0.0040,  0.0037],
        [-0.0126,  0.0143,  0.0150,  ...,  0.0036,  0.0751, -0.0060],
        [-0.0014, -0.0006,  0.0028,  ...,  0.0079, -0.0173,  0.0997]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0098, -2.5703, -1.7002,  ...,  1.7734, -0.5273, -4.8594]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 09:29:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To fulfil results in a fulfilment
To resent results in a resentment
To achieve results in a achievement
To assign results in a assignment
To develop results in a development
To displace results in a displacement
To manage results in a management
To enroll results in a
2024-07-29 09:29:42 root INFO     [order_1_approx] starting weight calculation for To assign results in a assignment
To manage results in a management
To displace results in a displacement
To enroll results in a enrollment
To achieve results in a achievement
To resent results in a resentment
To develop results in a development
To fulfil results in a
2024-07-29 09:29:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 09:29:45 root INFO     loading model + tokenizer
2024-07-29 09:31:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1199,  0.1049, -0.0511,  ..., -0.0055, -0.2142, -0.0447],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.4766, -3.8887,  2.0469,  ...,  1.0322, -4.7188, -1.5918],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0917,  0.0136,  0.0182,  ..., -0.0060, -0.0112,  0.0098],
        [-0.0105,  0.0530, -0.0003,  ...,  0.0225,  0.0039, -0.0081],
        [ 0.0095,  0.0004,  0.0389,  ..., -0.0037, -0.0026, -0.0209],
        ...,
        [-0.0124, -0.0068, -0.0111,  ...,  0.0579,  0.0105,  0.0106],
        [-0.0010,  0.0130, -0.0067,  ...,  0.0165,  0.0660, -0.0027],
        [-0.0022, -0.0079,  0.0082,  ..., -0.0074, -0.0154,  0.0645]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.1250, -3.5605,  1.9551,  ...,  0.9707, -4.0312, -1.7773]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 09:31:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To assign results in a assignment
To manage results in a management
To displace results in a displacement
To enroll results in a enrollment
To achieve results in a achievement
To resent results in a resentment
To develop results in a development
To fulfil results in a
2024-07-29 09:31:50 root INFO     [order_1_approx] starting weight calculation for To displace results in a displacement
To develop results in a development
To enroll results in a enrollment
To fulfil results in a fulfilment
To achieve results in a achievement
To resent results in a resentment
To manage results in a management
To assign results in a
2024-07-29 09:31:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 09:34:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2174,  0.4800, -0.2080,  ...,  0.1140, -0.0532, -0.3037],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0703, -3.8555, -0.2544,  ...,  3.2773, -1.8945, -2.0586],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0536, -0.0005, -0.0074,  ...,  0.0023, -0.0012,  0.0121],
        [-0.0055,  0.0447,  0.0272,  ...,  0.0441,  0.0219, -0.0083],
        [ 0.0048, -0.0093,  0.0292,  ..., -0.0063, -0.0103, -0.0213],
        ...,
        [-0.0070,  0.0071, -0.0168,  ...,  0.0767,  0.0009, -0.0006],
        [ 0.0025,  0.0166, -0.0051,  ..., -0.0154,  0.0494, -0.0146],
        [ 0.0051, -0.0073, -0.0076,  ...,  0.0010, -0.0355,  0.0472]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9043, -3.3398, -0.1731,  ...,  2.6406, -1.9453, -2.3047]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 09:34:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To displace results in a displacement
To develop results in a development
To enroll results in a enrollment
To fulfil results in a fulfilment
To achieve results in a achievement
To resent results in a resentment
To manage results in a management
To assign results in a
2024-07-29 09:34:02 root INFO     [order_1_approx] starting weight calculation for To assign results in a assignment
To resent results in a resentment
To displace results in a displacement
To enroll results in a enrollment
To manage results in a management
To develop results in a development
To fulfil results in a fulfilment
To achieve results in a
2024-07-29 09:34:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 09:36:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3472,  0.3809, -0.3208,  ..., -0.1371, -0.6094,  0.1587],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3457, -3.3711, -1.4395,  ...,  1.1934, -1.8320, -2.3047],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.4514e-02,  1.2939e-02,  1.6327e-02,  ...,  9.0408e-03,
         -9.3746e-04,  3.2104e-02],
        [-1.3947e-02,  4.7089e-02,  1.2016e-03,  ...,  2.6520e-02,
          1.2527e-02, -4.7150e-03],
        [ 6.8741e-03, -2.6054e-03,  1.8646e-02,  ..., -7.0915e-03,
         -1.3557e-02, -8.1558e-03],
        ...,
        [-2.4887e-02,  4.0245e-03, -2.0798e-02,  ...,  3.7964e-02,
          1.5381e-02, -4.7684e-05],
        [ 7.6981e-03,  8.7051e-03,  1.4366e-02,  ...,  4.4060e-04,
          2.7878e-02, -5.8556e-04],
        [-4.9286e-03, -2.3026e-02,  7.4844e-03,  ..., -4.8447e-03,
         -2.2034e-02,  3.9093e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2441, -3.0820, -1.4482,  ...,  1.6582, -1.9961, -2.3555]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 09:36:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To assign results in a assignment
To resent results in a resentment
To displace results in a displacement
To enroll results in a enrollment
To manage results in a management
To develop results in a development
To fulfil results in a fulfilment
To achieve results in a
2024-07-29 09:36:12 root INFO     [order_1_approx] starting weight calculation for To manage results in a management
To displace results in a displacement
To fulfil results in a fulfilment
To assign results in a assignment
To develop results in a development
To enroll results in a enrollment
To achieve results in a achievement
To resent results in a
2024-07-29 09:36:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 09:38:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1719, -0.1001, -0.7026,  ..., -0.1697, -0.1520, -0.3293],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8428, -2.8301, -1.2559,  ..., -1.2988, -1.0781, -1.3740],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.9946e-02, -1.1703e-02,  2.1801e-03,  ..., -4.4746e-03,
         -7.3547e-03, -6.6757e-06],
        [ 7.3471e-03,  7.6355e-02,  1.1955e-02,  ...,  2.2247e-02,
          2.4033e-03,  1.3718e-02],
        [ 8.8806e-03, -1.5259e-04,  5.2429e-02,  ..., -5.4398e-03,
         -4.9744e-03, -3.0632e-03],
        ...,
        [ 1.4595e-02,  2.4368e-02,  1.4984e-02,  ...,  7.7881e-02,
          1.4771e-02,  2.9144e-02],
        [ 2.7733e-03, -5.8594e-03,  1.2054e-02,  ..., -1.3763e-02,
          5.6946e-02, -1.7334e-02],
        [ 4.2801e-03,  3.5286e-04,  5.7030e-03,  ..., -1.9798e-03,
         -3.7964e-02,  7.8247e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4863, -2.3145, -1.1934,  ..., -0.6670, -0.9175, -1.8828]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 09:38:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To manage results in a management
To displace results in a displacement
To fulfil results in a fulfilment
To assign results in a assignment
To develop results in a development
To enroll results in a enrollment
To achieve results in a achievement
To resent results in a
2024-07-29 09:38:23 root INFO     [order_1_approx] starting weight calculation for To achieve results in a achievement
To develop results in a development
To assign results in a assignment
To manage results in a management
To fulfil results in a fulfilment
To enroll results in a enrollment
To resent results in a resentment
To displace results in a
2024-07-29 09:38:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 09:40:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2045,  0.1515, -0.5391,  ...,  0.1797,  0.1161,  0.1431],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1992, -4.0977,  0.5684,  ...,  2.0801, -1.0146, -1.3389],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0842,  0.0018,  0.0117,  ..., -0.0042, -0.0172, -0.0013],
        [-0.0015,  0.0581,  0.0048,  ...,  0.0271,  0.0023,  0.0097],
        [-0.0100, -0.0070,  0.0334,  ..., -0.0119,  0.0059, -0.0293],
        ...,
        [ 0.0089,  0.0208,  0.0017,  ...,  0.0824,  0.0040,  0.0098],
        [ 0.0074,  0.0174,  0.0028,  ...,  0.0004,  0.0721, -0.0036],
        [ 0.0306,  0.0117,  0.0091,  ..., -0.0126, -0.0371,  0.0819]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9434, -3.7598,  0.6143,  ...,  1.5107, -1.2188, -2.2246]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 09:40:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To achieve results in a achievement
To develop results in a development
To assign results in a assignment
To manage results in a management
To fulfil results in a fulfilment
To enroll results in a enrollment
To resent results in a resentment
To displace results in a
2024-07-29 09:40:37 root INFO     [order_1_approx] starting weight calculation for To develop results in a development
To displace results in a displacement
To assign results in a assignment
To resent results in a resentment
To fulfil results in a fulfilment
To enroll results in a enrollment
To achieve results in a achievement
To manage results in a
2024-07-29 09:40:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 09:42:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0144,  0.2133, -0.1633,  ...,  0.1763, -0.3340, -0.4250],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1465, -4.4219,  1.0020,  ...,  1.0508, -1.8945, -3.4453],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.0262e-02,  1.2009e-02, -4.0054e-05,  ..., -2.8954e-03,
         -1.3893e-02,  1.6327e-02],
        [-9.5596e-03,  5.3314e-02,  1.6525e-02,  ...,  2.7679e-02,
          1.2093e-02,  2.3270e-02],
        [ 7.6904e-03, -7.2250e-03,  4.9438e-02,  ..., -7.6294e-03,
         -1.6785e-04, -8.0719e-03],
        ...,
        [-3.1338e-03,  6.7787e-03, -5.9509e-03,  ...,  6.2744e-02,
          1.5900e-02,  5.8365e-03],
        [-1.4114e-02,  1.5030e-03,  2.8534e-03,  ..., -6.8893e-03,
          3.3356e-02, -2.0981e-02],
        [-2.0714e-03, -9.4070e-03,  1.4053e-02,  ..., -7.0190e-03,
         -8.0719e-03,  4.0771e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8789, -4.1758,  0.6338,  ...,  0.7739, -1.7061, -3.1836]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 09:42:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To develop results in a development
To displace results in a displacement
To assign results in a assignment
To resent results in a resentment
To fulfil results in a fulfilment
To enroll results in a enrollment
To achieve results in a achievement
To manage results in a
2024-07-29 09:42:50 root INFO     [order_1_approx] starting weight calculation for To manage results in a management
To assign results in a assignment
To enroll results in a enrollment
To fulfil results in a fulfilment
To resent results in a resentment
To achieve results in a achievement
To displace results in a displacement
To develop results in a
2024-07-29 09:42:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 09:45:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2203,  0.1027,  0.0870,  ..., -0.1848,  0.0137, -0.2329],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9512, -5.1250,  0.4895,  ...,  3.1523, -2.3086, -2.1953],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.4463e-02,  1.0689e-02,  1.2299e-02,  ..., -3.3531e-03,
         -2.8343e-03,  2.5208e-02],
        [-1.4496e-03,  6.8237e-02,  1.1307e-02,  ...,  2.6276e-02,
          1.8051e-02,  4.6387e-03],
        [ 3.6240e-05, -1.3687e-02,  3.6926e-02,  ..., -3.4847e-03,
         -3.0537e-03,  2.0828e-03],
        ...,
        [-9.7198e-03, -1.2833e-02, -1.2329e-02,  ...,  6.8604e-02,
          3.6469e-03,  2.0279e-02],
        [ 3.4409e-03,  1.7487e-02, -6.0120e-03,  ...,  6.7902e-04,
          4.9133e-02, -7.6141e-03],
        [-1.1002e-02, -1.3535e-02, -9.0790e-04,  ...,  1.9112e-03,
         -3.1235e-02,  6.6650e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6934, -4.8789,  0.4268,  ...,  2.5996, -2.6738, -1.9600]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 09:45:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To manage results in a management
To assign results in a assignment
To enroll results in a enrollment
To fulfil results in a fulfilment
To resent results in a resentment
To achieve results in a achievement
To displace results in a displacement
To develop results in a
2024-07-29 09:45:04 root INFO     total operator prediction time: 1054.382423877716 seconds
2024-07-29 09:45:04 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun+less_reg
2024-07-29 09:45:04 root INFO     building operator noun+less_reg
2024-07-29 09:45:05 root INFO     [order_1_approx] starting weight calculation for Something without thought is thoughtless
Something without friend is friendless
Something without speech is speechless
Something without wit is witless
Something without faith is faithless
Something without tact is tactless
Something without defence is defenceless
Something without odor is
2024-07-29 09:45:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 09:47:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1526, -0.6816, -0.0796,  ..., -0.4268,  0.0027, -0.2084],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7617, -4.7188, -0.0547,  ..., -4.4883, -7.4453, -1.6475],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0284, -0.0043,  0.0249,  ..., -0.0136, -0.0045,  0.0152],
        [ 0.0270,  0.0380, -0.0176,  ..., -0.0017,  0.0119, -0.0082],
        [ 0.0191, -0.0032,  0.0345,  ...,  0.0127, -0.0200,  0.0049],
        ...,
        [ 0.0227,  0.0094,  0.0001,  ...,  0.0410,  0.0196, -0.0022],
        [-0.0028, -0.0052,  0.0054,  ..., -0.0178,  0.0498, -0.0007],
        [ 0.0294,  0.0111,  0.0034,  ...,  0.0205, -0.0174,  0.0320]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9531, -4.7812, -0.0317,  ..., -4.1367, -7.1328, -1.6680]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 09:47:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without thought is thoughtless
Something without friend is friendless
Something without speech is speechless
Something without wit is witless
Something without faith is faithless
Something without tact is tactless
Something without defence is defenceless
Something without odor is
2024-07-29 09:47:18 root INFO     [order_1_approx] starting weight calculation for Something without faith is faithless
Something without tact is tactless
Something without speech is speechless
Something without thought is thoughtless
Something without defence is defenceless
Something without wit is witless
Something without odor is odorless
Something without friend is
2024-07-29 09:47:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 09:49:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3984, -0.5703, -0.4141,  ..., -0.3264,  0.3220, -0.2510],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2686, -1.4980,  2.2168,  ..., -0.8735, -3.6016, -0.1211],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0334, -0.0053, -0.0032,  ..., -0.0066, -0.0002,  0.0125],
        [-0.0062,  0.0294,  0.0017,  ..., -0.0083,  0.0082, -0.0182],
        [ 0.0082, -0.0064,  0.0189,  ...,  0.0062, -0.0080, -0.0049],
        ...,
        [-0.0057,  0.0006,  0.0030,  ...,  0.0138,  0.0191,  0.0006],
        [ 0.0076, -0.0085,  0.0043,  ...,  0.0143,  0.0246, -0.0170],
        [ 0.0109,  0.0097,  0.0009,  ..., -0.0112, -0.0168,  0.0208]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3320, -1.4834,  2.0781,  ..., -1.0879, -3.9688, -0.4656]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 09:49:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without faith is faithless
Something without tact is tactless
Something without speech is speechless
Something without thought is thoughtless
Something without defence is defenceless
Something without wit is witless
Something without odor is odorless
Something without friend is
2024-07-29 09:49:30 root INFO     [order_1_approx] starting weight calculation for Something without tact is tactless
Something without wit is witless
Something without defence is defenceless
Something without odor is odorless
Something without faith is faithless
Something without friend is friendless
Something without speech is speechless
Something without thought is
2024-07-29 09:49:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 09:51:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2153, -0.4714,  0.8018,  ..., -0.1881,  0.0363,  0.0423],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8906, -1.5479,  2.2344,  ..., -2.0723, -3.1367, -0.5767],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0308, -0.0044,  0.0003,  ...,  0.0008, -0.0019,  0.0045],
        [ 0.0052,  0.0483, -0.0006,  ...,  0.0148, -0.0143,  0.0019],
        [ 0.0103,  0.0033,  0.0433,  ...,  0.0140,  0.0061,  0.0065],
        ...,
        [ 0.0065,  0.0228,  0.0033,  ...,  0.0270, -0.0164,  0.0093],
        [-0.0220, -0.0035, -0.0101,  ..., -0.0274,  0.0436, -0.0154],
        [ 0.0219,  0.0190,  0.0048,  ...,  0.0239, -0.0192,  0.0218]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7754, -1.7344,  1.7344,  ..., -2.0801, -2.8359, -0.4753]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 09:51:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without tact is tactless
Something without wit is witless
Something without defence is defenceless
Something without odor is odorless
Something without faith is faithless
Something without friend is friendless
Something without speech is speechless
Something without thought is
2024-07-29 09:51:43 root INFO     [order_1_approx] starting weight calculation for Something without odor is odorless
Something without friend is friendless
Something without thought is thoughtless
Something without wit is witless
Something without speech is speechless
Something without tact is tactless
Something without defence is defenceless
Something without faith is
2024-07-29 09:51:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 09:53:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3955, -0.3748, -0.1065,  ..., -0.0668,  0.0641,  0.7129],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.9883, -3.5312,  0.6709,  ..., -1.2119, -4.2578, -0.5254],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0328, -0.0069,  0.0117,  ..., -0.0194, -0.0090,  0.0040],
        [ 0.0123,  0.0430, -0.0050,  ...,  0.0212, -0.0024, -0.0133],
        [ 0.0129, -0.0187,  0.0417,  ..., -0.0046, -0.0082, -0.0109],
        ...,
        [ 0.0090,  0.0167, -0.0090,  ...,  0.0172, -0.0071,  0.0116],
        [-0.0138, -0.0012, -0.0065,  ..., -0.0128,  0.0393, -0.0151],
        [ 0.0358,  0.0164,  0.0058,  ...,  0.0114, -0.0151,  0.0181]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.1484, -3.4297,  0.3232,  ..., -0.9790, -4.2812, -0.6924]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 09:53:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without odor is odorless
Something without friend is friendless
Something without thought is thoughtless
Something without wit is witless
Something without speech is speechless
Something without tact is tactless
Something without defence is defenceless
Something without faith is
2024-07-29 09:53:55 root INFO     [order_1_approx] starting weight calculation for Something without defence is defenceless
Something without speech is speechless
Something without friend is friendless
Something without thought is thoughtless
Something without faith is faithless
Something without odor is odorless
Something without tact is tactless
Something without wit is
2024-07-29 09:53:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 09:56:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0905,  0.0546,  0.6797,  ..., -0.1224,  0.5054, -0.0184],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8691, -3.7363,  1.7109,  ..., -1.3330, -3.9961,  0.0449],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0103, -0.0172,  0.0022,  ...,  0.0154, -0.0042, -0.0118],
        [ 0.0183,  0.0173,  0.0054,  ..., -0.0012, -0.0055,  0.0131],
        [ 0.0077, -0.0238,  0.0386,  ...,  0.0028, -0.0075, -0.0012],
        ...,
        [ 0.0255,  0.0355,  0.0057,  ...,  0.0363,  0.0044,  0.0054],
        [ 0.0047,  0.0107,  0.0208,  ..., -0.0132,  0.0309, -0.0176],
        [ 0.0420,  0.0034,  0.0026,  ..., -0.0022, -0.0095,  0.0327]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4863, -3.4668,  1.4043,  ..., -0.8970, -4.0234, -0.1787]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 09:56:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without defence is defenceless
Something without speech is speechless
Something without friend is friendless
Something without thought is thoughtless
Something without faith is faithless
Something without odor is odorless
Something without tact is tactless
Something without wit is
2024-07-29 09:56:06 root INFO     [order_1_approx] starting weight calculation for Something without thought is thoughtless
Something without odor is odorless
Something without friend is friendless
Something without faith is faithless
Something without wit is witless
Something without defence is defenceless
Something without speech is speechless
Something without tact is
2024-07-29 09:56:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 09:58:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([0.3540, 0.0053, 0.0970,  ..., 0.2820, 0.0826, 0.3213], device='cuda:1',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8516, -0.5068,  0.9097,  ...,  0.5596, -5.7188, -4.5703],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.0863e-02, -3.9856e-02,  1.0689e-02,  ..., -1.5259e-04,
          5.2719e-03,  1.0048e-02],
        [ 1.9547e-02,  6.1615e-02,  3.3455e-03,  ...,  1.1917e-02,
          1.3084e-03, -1.7090e-03],
        [ 1.0239e-02,  1.8406e-03,  3.6652e-02,  ...,  1.5900e-02,
         -8.1406e-03,  1.1559e-03],
        ...,
        [ 1.5610e-02,  4.0253e-02,  1.6434e-02,  ...,  5.3162e-02,
          7.6294e-05,  1.1200e-02],
        [ 1.4038e-02,  1.1436e-02,  2.5970e-02,  ..., -8.5220e-03,
          5.0690e-02, -1.7334e-02],
        [ 2.7145e-02,  1.4900e-02,  2.2324e-02,  ...,  2.6337e-02,
         -2.0645e-02,  3.6346e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4082, -0.8315,  0.2324,  ...,  0.4524, -5.4727, -5.0312]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 09:58:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without thought is thoughtless
Something without odor is odorless
Something without friend is friendless
Something without faith is faithless
Something without wit is witless
Something without defence is defenceless
Something without speech is speechless
Something without tact is
2024-07-29 09:58:18 root INFO     [order_1_approx] starting weight calculation for Something without odor is odorless
Something without faith is faithless
Something without tact is tactless
Something without speech is speechless
Something without friend is friendless
Something without thought is thoughtless
Something without wit is witless
Something without defence is
2024-07-29 09:58:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 10:00:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2881, -0.3845, -0.1592,  ..., -0.1948, -0.0099, -0.3213],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4688, -5.3867,  1.3828,  ..., -2.4648, -2.4395, -1.9609],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0323, -0.0083,  0.0152,  ...,  0.0188, -0.0054,  0.0085],
        [ 0.0115,  0.0364, -0.0187,  ...,  0.0053, -0.0119,  0.0041],
        [ 0.0018, -0.0090,  0.0298,  ...,  0.0187, -0.0123, -0.0100],
        ...,
        [-0.0132,  0.0221,  0.0024,  ...,  0.0094,  0.0217,  0.0095],
        [-0.0040, -0.0066,  0.0012,  ...,  0.0011,  0.0539, -0.0092],
        [ 0.0335,  0.0100, -0.0146,  ..., -0.0099, -0.0224,  0.0292]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2236, -5.1523,  1.0996,  ..., -1.9980, -2.4980, -1.9502]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 10:00:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without odor is odorless
Something without faith is faithless
Something without tact is tactless
Something without speech is speechless
Something without friend is friendless
Something without thought is thoughtless
Something without wit is witless
Something without defence is
2024-07-29 10:00:29 root INFO     [order_1_approx] starting weight calculation for Something without wit is witless
Something without tact is tactless
Something without faith is faithless
Something without thought is thoughtless
Something without defence is defenceless
Something without friend is friendless
Something without odor is odorless
Something without speech is
2024-07-29 10:00:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 10:02:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0057, -0.1835,  0.1492,  ...,  0.1976,  0.2130,  0.0659],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6255, -1.9648,  0.6558,  ..., -0.3748, -1.5166, -1.5098],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0395, -0.0118,  0.0023,  ...,  0.0077,  0.0135,  0.0125],
        [ 0.0052,  0.0435,  0.0280,  ..., -0.0063,  0.0014,  0.0139],
        [ 0.0244, -0.0082,  0.0263,  ...,  0.0047, -0.0159, -0.0078],
        ...,
        [-0.0091,  0.0096,  0.0139,  ...,  0.0244,  0.0032, -0.0108],
        [-0.0056,  0.0021,  0.0078,  ..., -0.0186,  0.0237, -0.0299],
        [ 0.0001, -0.0013,  0.0039,  ..., -0.0055, -0.0116,  0.0195]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0391, -2.3203,  0.3481,  ..., -0.7876, -1.9951, -1.5361]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 10:02:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without wit is witless
Something without tact is tactless
Something without faith is faithless
Something without thought is thoughtless
Something without defence is defenceless
Something without friend is friendless
Something without odor is odorless
Something without speech is
2024-07-29 10:02:42 root INFO     total operator prediction time: 1057.5714156627655 seconds
2024-07-29 10:02:42 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj+ness_reg
2024-07-29 10:02:42 root INFO     building operator adj+ness_reg
2024-07-29 10:02:42 root INFO     [order_1_approx] starting weight calculation for The state of being helpful is helpfulness
The state of being vast is vastness
The state of being prepared is preparedness
The state of being conscious is consciousness
The state of being strange is strangeness
The state of being huge is hugeness
The state of being impressive is impressiveness
The state of being obvious is
2024-07-29 10:02:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 10:04:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1406,  0.2217,  0.2729,  ..., -0.2432, -0.4475, -0.1451],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2490, -3.0391, -1.7949,  ..., -2.7656, -6.0391,  1.6641],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0600, -0.0013,  0.0107,  ...,  0.0207, -0.0054,  0.0113],
        [-0.0163,  0.0559,  0.0139,  ...,  0.0229,  0.0218, -0.0116],
        [ 0.0117,  0.0044,  0.0347,  ..., -0.0201, -0.0264, -0.0049],
        ...,
        [ 0.0019,  0.0286,  0.0072,  ...,  0.0424, -0.0041,  0.0213],
        [ 0.0126,  0.0352, -0.0055,  ..., -0.0282,  0.0391, -0.0152],
        [ 0.0159,  0.0011, -0.0155,  ..., -0.0149, -0.0247,  0.0410]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0938, -2.9668, -1.8564,  ..., -2.9766, -6.0195,  1.5596]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 10:04:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being helpful is helpfulness
The state of being vast is vastness
The state of being prepared is preparedness
The state of being conscious is consciousness
The state of being strange is strangeness
The state of being huge is hugeness
The state of being impressive is impressiveness
The state of being obvious is
2024-07-29 10:04:57 root INFO     [order_1_approx] starting weight calculation for The state of being impressive is impressiveness
The state of being obvious is obviousness
The state of being helpful is helpfulness
The state of being conscious is consciousness
The state of being strange is strangeness
The state of being huge is hugeness
The state of being prepared is preparedness
The state of being vast is
2024-07-29 10:04:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 10:07:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2502, -0.2642,  0.3235,  ..., -0.3755, -0.2214, -0.2224],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9229, -2.5820, -2.8516,  ..., -5.1836, -6.3242, -0.7168],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.6030e-02,  1.4511e-02,  9.0942e-03,  ...,  2.1957e-02,
          3.4637e-03, -7.8201e-05],
        [-6.6910e-03,  5.0476e-02,  3.0975e-03,  ...,  2.9343e-02,
          9.7351e-03,  1.7197e-02],
        [ 8.3542e-03, -3.1143e-02,  5.8807e-02,  ..., -1.0117e-02,
         -2.1866e-02,  3.2463e-03],
        ...,
        [ 6.4163e-03,  2.9785e-02,  1.3954e-02,  ...,  4.9500e-02,
          1.5930e-02,  1.2672e-02],
        [ 1.6205e-02,  3.3207e-03, -7.1106e-03,  ..., -1.5854e-02,
          5.6122e-02,  8.6823e-03],
        [ 8.1711e-03,  2.1881e-02,  1.2405e-02,  ...,  5.1384e-03,
         -3.8929e-03,  4.4891e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9648, -2.3906, -2.6367,  ..., -4.9961, -6.5312, -0.7754]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 10:07:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being impressive is impressiveness
The state of being obvious is obviousness
The state of being helpful is helpfulness
The state of being conscious is consciousness
The state of being strange is strangeness
The state of being huge is hugeness
The state of being prepared is preparedness
The state of being vast is
2024-07-29 10:07:09 root INFO     [order_1_approx] starting weight calculation for The state of being vast is vastness
The state of being huge is hugeness
The state of being obvious is obviousness
The state of being strange is strangeness
The state of being prepared is preparedness
The state of being impressive is impressiveness
The state of being conscious is consciousness
The state of being helpful is
2024-07-29 10:07:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 10:09:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2402, -0.2419,  0.5024,  ...,  0.3887, -0.4219, -0.1440],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2812, -1.5195, -1.8516,  ...,  1.2715, -6.7578, -2.1758],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0380,  0.0143,  0.0027,  ...,  0.0241, -0.0028,  0.0154],
        [-0.0047,  0.0414,  0.0022,  ...,  0.0219,  0.0048, -0.0036],
        [-0.0100, -0.0271,  0.0495,  ..., -0.0052, -0.0092, -0.0175],
        ...,
        [ 0.0069,  0.0040,  0.0023,  ...,  0.0293, -0.0046,  0.0086],
        [ 0.0044,  0.0090,  0.0015,  ..., -0.0048,  0.0411, -0.0073],
        [ 0.0153,  0.0047, -0.0038,  ..., -0.0084, -0.0125,  0.0494]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1992, -1.3535, -1.3623,  ...,  1.1279, -6.9727, -2.0625]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 10:09:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being vast is vastness
The state of being huge is hugeness
The state of being obvious is obviousness
The state of being strange is strangeness
The state of being prepared is preparedness
The state of being impressive is impressiveness
The state of being conscious is consciousness
The state of being helpful is
2024-07-29 10:09:22 root INFO     [order_1_approx] starting weight calculation for The state of being strange is strangeness
The state of being impressive is impressiveness
The state of being obvious is obviousness
The state of being vast is vastness
The state of being huge is hugeness
The state of being helpful is helpfulness
The state of being prepared is preparedness
The state of being conscious is
2024-07-29 10:09:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 10:11:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2639, -0.3086, -0.1333,  ..., -0.1476, -0.0933,  0.2803],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4209, -2.4375,  2.2930,  ..., -3.0566, -1.7842,  0.6265],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0834,  0.0097, -0.0012,  ...,  0.0319, -0.0258,  0.0024],
        [ 0.0020,  0.0562,  0.0149,  ...,  0.0290,  0.0146, -0.0069],
        [-0.0090, -0.0279,  0.0892,  ..., -0.0068, -0.0149,  0.0215],
        ...,
        [ 0.0273,  0.0106, -0.0013,  ...,  0.0559,  0.0024,  0.0104],
        [ 0.0101, -0.0086,  0.0122,  ..., -0.0367,  0.0677, -0.0227],
        [ 0.0068,  0.0160, -0.0057,  ..., -0.0086, -0.0160,  0.0846]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5928, -2.2891,  2.1309,  ..., -3.2070, -2.0957,  0.1138]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 10:11:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being strange is strangeness
The state of being impressive is impressiveness
The state of being obvious is obviousness
The state of being vast is vastness
The state of being huge is hugeness
The state of being helpful is helpfulness
The state of being prepared is preparedness
The state of being conscious is
2024-07-29 10:11:34 root INFO     [order_1_approx] starting weight calculation for The state of being conscious is consciousness
The state of being obvious is obviousness
The state of being strange is strangeness
The state of being helpful is helpfulness
The state of being impressive is impressiveness
The state of being huge is hugeness
The state of being vast is vastness
The state of being prepared is
2024-07-29 10:11:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 10:13:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1141, -0.2859,  0.0194,  ...,  0.1832, -0.3486,  0.1572],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.6758, -6.1016, -1.2598,  ...,  0.2261, -3.8945, -2.7910],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0728, -0.0198, -0.0061,  ..., -0.0001, -0.0104, -0.0025],
        [ 0.0057,  0.0607, -0.0023,  ...,  0.0328,  0.0129, -0.0071],
        [-0.0087, -0.0109,  0.0650,  ...,  0.0196, -0.0018,  0.0066],
        ...,
        [ 0.0021,  0.0043, -0.0150,  ...,  0.0683,  0.0062,  0.0200],
        [ 0.0042,  0.0068,  0.0173,  ..., -0.0073,  0.0763, -0.0243],
        [ 0.0025,  0.0025, -0.0049,  ..., -0.0039, -0.0068,  0.0804]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 6.1094, -6.1562, -1.3467,  ...,  0.0262, -3.7812, -2.9727]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 10:13:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being conscious is consciousness
The state of being obvious is obviousness
The state of being strange is strangeness
The state of being helpful is helpfulness
The state of being impressive is impressiveness
The state of being huge is hugeness
The state of being vast is vastness
The state of being prepared is
2024-07-29 10:13:48 root INFO     [order_1_approx] starting weight calculation for The state of being conscious is consciousness
The state of being prepared is preparedness
The state of being strange is strangeness
The state of being huge is hugeness
The state of being helpful is helpfulness
The state of being vast is vastness
The state of being obvious is obviousness
The state of being impressive is
2024-07-29 10:13:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 10:16:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2339,  0.0872, -0.2234,  ...,  0.0050, -0.2715, -0.2498],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.1172, -1.7100, -2.0918,  ..., -0.9404, -4.1016, -4.0703],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.2561e-02,  5.9128e-05,  2.1744e-02,  ...,  4.0054e-04,
         -1.5465e-02,  3.3951e-04],
        [-8.6594e-04,  3.3386e-02, -1.5287e-03,  ...,  2.2308e-02,
          3.7384e-02, -6.7978e-03],
        [ 5.9242e-03, -7.9269e-03,  5.3864e-02,  ..., -9.8495e-03,
         -1.4893e-02, -1.5472e-02],
        ...,
        [ 2.0050e-02,  1.9592e-02, -6.6071e-03,  ...,  3.7598e-02,
          1.0666e-02,  1.1642e-02],
        [ 9.4147e-03,  2.0493e-02,  1.8921e-02,  ..., -4.1122e-03,
          2.2034e-02, -3.2635e-03],
        [-3.1357e-03,  9.3079e-04,  3.4485e-03,  ..., -6.2218e-03,
         -2.0020e-02,  2.7740e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.0352, -1.7930, -2.0098,  ..., -0.8833, -3.8750, -3.9180]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 10:16:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being conscious is consciousness
The state of being prepared is preparedness
The state of being strange is strangeness
The state of being huge is hugeness
The state of being helpful is helpfulness
The state of being vast is vastness
The state of being obvious is obviousness
The state of being impressive is
2024-07-29 10:16:01 root INFO     [order_1_approx] starting weight calculation for The state of being conscious is consciousness
The state of being impressive is impressiveness
The state of being prepared is preparedness
The state of being huge is hugeness
The state of being helpful is helpfulness
The state of being vast is vastness
The state of being obvious is obviousness
The state of being strange is
2024-07-29 10:16:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 10:18:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1035,  0.0809,  0.4072,  ..., -0.3171,  0.0632,  0.3203],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4434, -2.5469, -2.6309,  ..., -3.3262, -4.6758, -1.8496],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0587,  0.0106, -0.0052,  ...,  0.0062, -0.0044,  0.0013],
        [-0.0039,  0.0351,  0.0078,  ...,  0.0260,  0.0168, -0.0036],
        [ 0.0148, -0.0196,  0.0301,  ..., -0.0114, -0.0072,  0.0035],
        ...,
        [ 0.0181,  0.0276, -0.0024,  ...,  0.0282,  0.0013, -0.0039],
        [ 0.0139,  0.0166,  0.0174,  ...,  0.0018,  0.0360, -0.0187],
        [ 0.0076,  0.0095, -0.0017,  ...,  0.0031, -0.0210,  0.0347]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7842, -2.2637, -2.7559,  ..., -3.0742, -4.5742, -1.8281]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 10:18:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being conscious is consciousness
The state of being impressive is impressiveness
The state of being prepared is preparedness
The state of being huge is hugeness
The state of being helpful is helpfulness
The state of being vast is vastness
The state of being obvious is obviousness
The state of being strange is
2024-07-29 10:18:14 root INFO     [order_1_approx] starting weight calculation for The state of being obvious is obviousness
The state of being strange is strangeness
The state of being helpful is helpfulness
The state of being vast is vastness
The state of being prepared is preparedness
The state of being impressive is impressiveness
The state of being conscious is consciousness
The state of being huge is
2024-07-29 10:18:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 10:20:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0567, -0.2671,  0.0714,  ..., -0.0280, -0.2778, -0.3201],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0273, -3.6289, -1.5889,  ..., -3.7148, -8.8438, -1.8545],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0797, -0.0024, -0.0135,  ...,  0.0053, -0.0184,  0.0091],
        [ 0.0015,  0.0485,  0.0106,  ...,  0.0039,  0.0042,  0.0020],
        [-0.0068, -0.0152,  0.0637,  ..., -0.0115, -0.0067,  0.0078],
        ...,
        [ 0.0192,  0.0149,  0.0271,  ...,  0.0626, -0.0044,  0.0037],
        [ 0.0219,  0.0043,  0.0106,  ..., -0.0085,  0.0622, -0.0071],
        [ 0.0003, -0.0039, -0.0055,  ..., -0.0010, -0.0082,  0.0607]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7852, -3.6406, -1.2266,  ..., -3.7461, -8.5859, -1.5996]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 10:20:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being obvious is obviousness
The state of being strange is strangeness
The state of being helpful is helpfulness
The state of being vast is vastness
The state of being prepared is preparedness
The state of being impressive is impressiveness
The state of being conscious is consciousness
The state of being huge is
2024-07-29 10:20:24 root INFO     total operator prediction time: 1062.0532050132751 seconds
2024-07-29 10:20:24 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on re+verb_reg
2024-07-29 10:20:24 root INFO     building operator re+verb_reg
2024-07-29 10:20:24 root INFO     [order_1_approx] starting weight calculation for To submit again is to resubmit
To interpret again is to reinterpret
To grow again is to regrow
To write again is to rewrite
To learn again is to relearn
To assign again is to reassign
To adjust again is to readjust
To discover again is to
2024-07-29 10:20:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 10:22:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3540, -0.0906,  0.5532,  ..., -0.2306, -0.6060,  0.1110],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0947, -3.9512,  1.9893,  ...,  1.8213, -4.0469, -1.6914],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0584, -0.0085,  0.0205,  ...,  0.0032,  0.0033,  0.0181],
        [ 0.0134,  0.0547,  0.0077,  ...,  0.0134, -0.0124,  0.0086],
        [ 0.0036,  0.0003,  0.0342,  ..., -0.0030,  0.0093, -0.0140],
        ...,
        [ 0.0016,  0.0051, -0.0020,  ...,  0.0573,  0.0014, -0.0085],
        [ 0.0076,  0.0117, -0.0023,  ..., -0.0017,  0.0386, -0.0095],
        [ 0.0029, -0.0098,  0.0111,  ..., -0.0249, -0.0137,  0.0299]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3540, -4.1094,  2.0000,  ...,  2.3691, -4.3125, -1.9238]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 10:22:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To submit again is to resubmit
To interpret again is to reinterpret
To grow again is to regrow
To write again is to rewrite
To learn again is to relearn
To assign again is to reassign
To adjust again is to readjust
To discover again is to
2024-07-29 10:22:36 root INFO     [order_1_approx] starting weight calculation for To assign again is to reassign
To adjust again is to readjust
To discover again is to rediscover
To write again is to rewrite
To learn again is to relearn
To interpret again is to reinterpret
To submit again is to resubmit
To grow again is to
2024-07-29 10:22:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 10:24:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2759,  0.0425,  0.0129,  ..., -0.2197, -0.2471,  0.1721],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4570, -3.2090, -0.0554,  ...,  1.1133, -5.6875, -2.5938],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0651, -0.0081,  0.0188,  ...,  0.0135, -0.0087,  0.0236],
        [ 0.0171,  0.0402,  0.0066,  ...,  0.0041, -0.0153,  0.0113],
        [ 0.0168, -0.0045,  0.0546,  ..., -0.0156,  0.0028, -0.0090],
        ...,
        [-0.0165,  0.0146, -0.0132,  ...,  0.0889, -0.0065, -0.0002],
        [-0.0078,  0.0309,  0.0032,  ..., -0.0284,  0.0455, -0.0153],
        [ 0.0043, -0.0102, -0.0126,  ..., -0.0106, -0.0217,  0.0694]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0557, -3.8242, -0.0270,  ...,  1.2734, -5.6641, -2.7051]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 10:24:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To assign again is to reassign
To adjust again is to readjust
To discover again is to rediscover
To write again is to rewrite
To learn again is to relearn
To interpret again is to reinterpret
To submit again is to resubmit
To grow again is to
2024-07-29 10:24:48 root INFO     [order_1_approx] starting weight calculation for To grow again is to regrow
To interpret again is to reinterpret
To discover again is to rediscover
To adjust again is to readjust
To learn again is to relearn
To write again is to rewrite
To submit again is to resubmit
To assign again is to
2024-07-29 10:24:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 10:26:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3574,  0.6343, -0.0911,  ...,  0.3325, -0.2637, -0.1115],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4670, -3.3145, -0.4854,  ...,  2.0547, -4.1953, -4.5469],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.9734e-02,  1.8787e-03,  1.2016e-02,  ...,  3.7155e-03,
         -1.1436e-02,  1.6068e-02],
        [ 1.4587e-02,  3.0624e-02, -6.8626e-03,  ...,  1.9287e-02,
          1.4877e-02, -1.9043e-02],
        [ 1.5778e-02, -2.8133e-03,  3.9001e-02,  ..., -1.3168e-02,
         -2.4376e-03, -1.3382e-02],
        ...,
        [ 1.6479e-02, -4.0512e-03, -1.8845e-02,  ...,  5.5511e-02,
          5.7220e-03, -1.8585e-02],
        [-1.4896e-03,  1.1223e-02,  7.5817e-04,  ..., -4.1237e-03,
          4.1443e-02,  9.3937e-05],
        [ 7.9346e-03, -1.8539e-03, -1.1719e-02,  ..., -1.3306e-02,
         -1.5808e-02,  2.6886e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6660, -1.7246, -0.6074,  ...,  3.0801, -4.3555, -3.0859]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 10:27:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To grow again is to regrow
To interpret again is to reinterpret
To discover again is to rediscover
To adjust again is to readjust
To learn again is to relearn
To write again is to rewrite
To submit again is to resubmit
To assign again is to
2024-07-29 10:27:00 root INFO     [order_1_approx] starting weight calculation for To assign again is to reassign
To interpret again is to reinterpret
To discover again is to rediscover
To submit again is to resubmit
To grow again is to regrow
To write again is to rewrite
To learn again is to relearn
To adjust again is to
2024-07-29 10:27:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 10:29:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3491,  0.0482, -0.5562,  ...,  0.1614, -0.0656,  0.0386],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4766, -2.4297, -1.7764,  ...,  2.3184, -4.1797, -3.2441],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 8.2581e-02,  9.5673e-03,  5.1384e-03,  ..., -2.7054e-02,
          5.5695e-03,  3.2013e-02],
        [ 1.6083e-02,  6.7749e-02,  9.0179e-03,  ...,  8.6899e-03,
         -1.6129e-02,  1.6098e-02],
        [-4.9591e-05, -1.5259e-03,  4.4312e-02,  ..., -4.3907e-03,
          1.9407e-03, -1.6403e-03],
        ...,
        [ 4.5013e-03, -1.4191e-02, -6.8665e-03,  ...,  8.7280e-02,
          9.5558e-04, -7.1411e-03],
        [-1.1520e-02, -1.6747e-03, -1.8097e-02,  ..., -1.9928e-02,
          6.1035e-02, -2.1118e-02],
        [ 3.9597e-03,  1.3237e-02, -8.0719e-03,  ..., -2.8305e-02,
         -1.6220e-02,  5.6824e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0195, -2.5566, -1.4307,  ...,  2.7070, -3.9180, -2.9258]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 10:29:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To assign again is to reassign
To interpret again is to reinterpret
To discover again is to rediscover
To submit again is to resubmit
To grow again is to regrow
To write again is to rewrite
To learn again is to relearn
To adjust again is to
2024-07-29 10:29:12 root INFO     [order_1_approx] starting weight calculation for To discover again is to rediscover
To grow again is to regrow
To adjust again is to readjust
To write again is to rewrite
To interpret again is to reinterpret
To assign again is to reassign
To submit again is to resubmit
To learn again is to
2024-07-29 10:29:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 10:31:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1594, -0.2227,  0.1851,  ..., -0.4053, -0.2944,  0.1274],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5264, -2.7031,  0.6118,  ...,  3.6602, -5.1641, -5.7656],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0419, -0.0044,  0.0003,  ..., -0.0125, -0.0005,  0.0065],
        [ 0.0064,  0.0249,  0.0054,  ...,  0.0047, -0.0127,  0.0076],
        [-0.0044, -0.0003,  0.0335,  ..., -0.0009,  0.0106, -0.0106],
        ...,
        [ 0.0129, -0.0063, -0.0039,  ...,  0.0385, -0.0016, -0.0038],
        [ 0.0005,  0.0155, -0.0015,  ..., -0.0009,  0.0282, -0.0073],
        [-0.0065,  0.0074,  0.0009,  ...,  0.0018, -0.0140,  0.0207]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7388, -2.8906,  0.6436,  ...,  4.0234, -5.1992, -5.5430]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 10:31:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To discover again is to rediscover
To grow again is to regrow
To adjust again is to readjust
To write again is to rewrite
To interpret again is to reinterpret
To assign again is to reassign
To submit again is to resubmit
To learn again is to
2024-07-29 10:31:25 root INFO     [order_1_approx] starting weight calculation for To write again is to rewrite
To grow again is to regrow
To interpret again is to reinterpret
To learn again is to relearn
To adjust again is to readjust
To assign again is to reassign
To discover again is to rediscover
To submit again is to
2024-07-29 10:31:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 10:33:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3196, -0.0693, -0.0522,  ...,  0.0748, -0.1824,  0.2615],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7324, -3.2617, -1.9707,  ...,  1.0518, -3.8809, -3.2441],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.9124e-02, -1.1215e-02,  1.5671e-02,  ..., -4.5090e-03,
          1.3199e-03,  1.9104e-02],
        [ 2.3666e-02,  3.5217e-02,  1.1616e-03,  ...,  1.9638e-02,
         -1.8265e-02,  1.3321e-02],
        [ 2.1038e-03,  7.3624e-03,  4.1443e-02,  ..., -2.2526e-03,
          1.3145e-02, -6.2065e-03],
        ...,
        [ 1.7166e-05, -4.9896e-03,  1.0468e-02,  ...,  6.0547e-02,
          8.0109e-03, -1.5802e-03],
        [-9.9258e-03,  9.4757e-03,  9.9258e-03,  ..., -2.7485e-03,
          5.0262e-02, -1.4137e-02],
        [ 7.6218e-03, -1.1665e-02, -1.8597e-03,  ..., -1.9562e-02,
         -2.6611e-02,  4.9133e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5347, -3.3398, -2.0723,  ...,  1.3184, -3.8730, -3.2676]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 10:33:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To write again is to rewrite
To grow again is to regrow
To interpret again is to reinterpret
To learn again is to relearn
To adjust again is to readjust
To assign again is to reassign
To discover again is to rediscover
To submit again is to
2024-07-29 10:33:37 root INFO     [order_1_approx] starting weight calculation for To assign again is to reassign
To grow again is to regrow
To interpret again is to reinterpret
To discover again is to rediscover
To learn again is to relearn
To submit again is to resubmit
To adjust again is to readjust
To write again is to
2024-07-29 10:33:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 10:35:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1155, -0.0203,  0.2605,  ..., -0.4346, -0.1499,  0.1332],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3560, -3.1133, -0.0679,  ...,  2.1758, -4.8945, -2.3672],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0475, -0.0022,  0.0068,  ...,  0.0012, -0.0036,  0.0126],
        [ 0.0161,  0.0269,  0.0071,  ...,  0.0129, -0.0124, -0.0019],
        [ 0.0102, -0.0144,  0.0540,  ...,  0.0071,  0.0024, -0.0080],
        ...,
        [ 0.0185, -0.0020,  0.0064,  ...,  0.0609, -0.0077, -0.0029],
        [-0.0041,  0.0105, -0.0085,  ..., -0.0205,  0.0350, -0.0111],
        [ 0.0135,  0.0031,  0.0130,  ...,  0.0072, -0.0200,  0.0403]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3879, -3.3125, -0.1949,  ...,  2.4258, -4.9922, -2.4355]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 10:35:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To assign again is to reassign
To grow again is to regrow
To interpret again is to reinterpret
To discover again is to rediscover
To learn again is to relearn
To submit again is to resubmit
To adjust again is to readjust
To write again is to
2024-07-29 10:35:49 root INFO     [order_1_approx] starting weight calculation for To grow again is to regrow
To learn again is to relearn
To assign again is to reassign
To write again is to rewrite
To submit again is to resubmit
To adjust again is to readjust
To discover again is to rediscover
To interpret again is to
2024-07-29 10:35:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 10:38:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1938,  0.0198,  0.2444,  ...,  0.1836, -0.1448,  0.6372],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0398, -2.1172,  1.3535,  ...,  0.6177, -2.4746, -3.6543],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.9042e-02, -4.2992e-03,  1.5274e-02,  ...,  1.1543e-02,
         -4.1962e-03,  1.7441e-02],
        [ 1.6174e-02,  5.1819e-02,  1.6830e-02,  ...,  1.5541e-02,
          2.3308e-03, -6.1874e-03],
        [-9.1791e-04, -5.2795e-03,  4.1168e-02,  ...,  1.8940e-03,
          8.9493e-03, -6.6452e-03],
        ...,
        [ 2.1942e-02, -1.2054e-03, -2.2011e-03,  ...,  5.6946e-02,
          5.2643e-03, -1.2154e-02],
        [-1.3268e-02, -1.7166e-03,  5.5923e-03,  ..., -1.1795e-02,
          4.5166e-02, -8.7204e-03],
        [-9.8705e-05, -2.8801e-03,  1.3443e-02,  ..., -8.8654e-03,
         -2.2644e-02,  3.6804e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2786, -2.1113,  1.2109,  ...,  0.9932, -2.9961, -3.5586]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 10:38:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To grow again is to regrow
To learn again is to relearn
To assign again is to reassign
To write again is to rewrite
To submit again is to resubmit
To adjust again is to readjust
To discover again is to rediscover
To interpret again is to
2024-07-29 10:38:02 root INFO     total operator prediction time: 1057.7120127677917 seconds
2024-07-29 10:38:02 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on un+adj_reg
2024-07-29 10:38:02 root INFO     building operator un+adj_reg
2024-07-29 10:38:02 root INFO     [order_1_approx] starting weight calculation for The opposite of acceptable is unacceptable
The opposite of noticed is unnoticed
The opposite of reliable is unreliable
The opposite of able is unable
The opposite of veiled is unveiled
The opposite of controlled is uncontrolled
The opposite of restricted is unrestricted
The opposite of usual is
2024-07-29 10:38:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 10:40:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2961, -0.3301,  0.2097,  ..., -0.4124, -0.5239, -0.3389],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9219, -1.2461,  1.3057,  ..., -1.9023, -1.5352, -2.4629],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0478, -0.0096,  0.0069,  ..., -0.0199, -0.0017,  0.0121],
        [-0.0058,  0.0934, -0.0170,  ...,  0.0238,  0.0128, -0.0018],
        [ 0.0037,  0.0183,  0.0296,  ..., -0.0066, -0.0123,  0.0056],
        ...,
        [ 0.0054,  0.0167,  0.0155,  ...,  0.0815,  0.0089, -0.0180],
        [-0.0117,  0.0310,  0.0171,  ..., -0.0233,  0.0463,  0.0222],
        [ 0.0335, -0.0084, -0.0227,  ...,  0.0216, -0.0154,  0.0314]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7979, -1.1289,  1.0371,  ..., -1.4580, -1.8789, -2.2266]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 10:40:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of acceptable is unacceptable
The opposite of noticed is unnoticed
The opposite of reliable is unreliable
The opposite of able is unable
The opposite of veiled is unveiled
The opposite of controlled is uncontrolled
The opposite of restricted is unrestricted
The opposite of usual is
2024-07-29 10:40:15 root INFO     [order_1_approx] starting weight calculation for The opposite of able is unable
The opposite of usual is unusual
The opposite of restricted is unrestricted
The opposite of noticed is unnoticed
The opposite of controlled is uncontrolled
The opposite of reliable is unreliable
The opposite of veiled is unveiled
The opposite of acceptable is
2024-07-29 10:40:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 10:42:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1410,  0.3906, -0.3765,  ..., -0.1015, -0.5166, -0.0009],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9941, -2.5234,  1.1006,  ...,  0.1682, -2.5020, -2.1934],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0458, -0.0131,  0.0270,  ...,  0.0120, -0.0057,  0.0069],
        [-0.0102,  0.0626, -0.0293,  ..., -0.0133,  0.0028,  0.0173],
        [ 0.0010,  0.0127,  0.0148,  ...,  0.0018, -0.0353, -0.0124],
        ...,
        [ 0.0181,  0.0534, -0.0131,  ...,  0.0630,  0.0099, -0.0118],
        [-0.0151, -0.0269,  0.0195,  ..., -0.0162,  0.0306,  0.0010],
        [ 0.0041,  0.0286, -0.0244,  ..., -0.0060, -0.0186,  0.0514]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7773, -2.5254,  0.9683,  ...,  0.4536, -2.2754, -1.5098]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 10:42:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of able is unable
The opposite of usual is unusual
The opposite of restricted is unrestricted
The opposite of noticed is unnoticed
The opposite of controlled is uncontrolled
The opposite of reliable is unreliable
The opposite of veiled is unveiled
The opposite of acceptable is
2024-07-29 10:42:28 root INFO     [order_1_approx] starting weight calculation for The opposite of able is unable
The opposite of reliable is unreliable
The opposite of noticed is unnoticed
The opposite of controlled is uncontrolled
The opposite of veiled is unveiled
The opposite of acceptable is unacceptable
The opposite of usual is unusual
The opposite of restricted is
2024-07-29 10:42:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 10:44:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1251, -0.0321, -0.4109,  ..., -0.0412,  0.3564, -0.2306],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3359,  0.5801,  1.2002,  ...,  1.2070, -1.6836, -1.5889],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0558, -0.0233, -0.0110,  ..., -0.0071,  0.0087,  0.0253],
        [-0.0193,  0.0632,  0.0005,  ..., -0.0010,  0.0210,  0.0094],
        [ 0.0074,  0.0070,  0.0375,  ...,  0.0026, -0.0141,  0.0079],
        ...,
        [ 0.0020,  0.0076,  0.0243,  ...,  0.0440,  0.0160, -0.0098],
        [ 0.0096, -0.0125,  0.0140,  ..., -0.0049,  0.0195,  0.0171],
        [-0.0076, -0.0038,  0.0055,  ..., -0.0022, -0.0044,  0.0736]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7500,  0.4346,  0.8931,  ...,  1.0830, -1.8066, -1.2979]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 10:44:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of able is unable
The opposite of reliable is unreliable
The opposite of noticed is unnoticed
The opposite of controlled is uncontrolled
The opposite of veiled is unveiled
The opposite of acceptable is unacceptable
The opposite of usual is unusual
The opposite of restricted is
2024-07-29 10:44:41 root INFO     [order_1_approx] starting weight calculation for The opposite of veiled is unveiled
The opposite of acceptable is unacceptable
The opposite of able is unable
The opposite of usual is unusual
The opposite of noticed is unnoticed
The opposite of controlled is uncontrolled
The opposite of restricted is unrestricted
The opposite of reliable is
2024-07-29 10:44:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 10:46:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0632, -0.0265, -0.4033,  ..., -0.1289, -0.0150, -0.3098],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0537, -1.4863, -0.2559,  ...,  0.6709, -0.6099, -2.8516],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0828, -0.0139,  0.0148,  ...,  0.0120, -0.0146, -0.0100],
        [-0.0171,  0.0643,  0.0042,  ...,  0.0301,  0.0261,  0.0127],
        [-0.0066,  0.0150,  0.0312,  ..., -0.0167, -0.0153, -0.0084],
        ...,
        [ 0.0072,  0.0382, -0.0028,  ...,  0.0263, -0.0029, -0.0108],
        [-0.0109, -0.0222, -0.0203,  ...,  0.0095,  0.0322,  0.0109],
        [-0.0177, -0.0287,  0.0036,  ..., -0.0149, -0.0046,  0.0545]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4858, -1.2939, -0.6885,  ...,  0.6396, -1.0186, -3.1191]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 10:46:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of veiled is unveiled
The opposite of acceptable is unacceptable
The opposite of able is unable
The opposite of usual is unusual
The opposite of noticed is unnoticed
The opposite of controlled is uncontrolled
The opposite of restricted is unrestricted
The opposite of reliable is
2024-07-29 10:46:55 root INFO     [order_1_approx] starting weight calculation for The opposite of noticed is unnoticed
The opposite of acceptable is unacceptable
The opposite of reliable is unreliable
The opposite of veiled is unveiled
The opposite of usual is unusual
The opposite of restricted is unrestricted
The opposite of able is unable
The opposite of controlled is
2024-07-29 10:46:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 10:49:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0362, -0.0286, -0.2981,  ..., -0.1163, -0.0364, -0.1012],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0908, -0.1240,  0.7358,  ...,  1.1650,  2.3906, -2.4336],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0712, -0.0121, -0.0201,  ...,  0.0211,  0.0089,  0.0233],
        [-0.0030,  0.0408, -0.0074,  ...,  0.0317,  0.0197, -0.0084],
        [-0.0084,  0.0013,  0.0382,  ...,  0.0396, -0.0115, -0.0210],
        ...,
        [ 0.0091,  0.0376,  0.0047,  ...,  0.0243, -0.0165,  0.0029],
        [ 0.0038, -0.0136,  0.0198,  ..., -0.0100,  0.0383, -0.0019],
        [-0.0175,  0.0009,  0.0045,  ..., -0.0082, -0.0159,  0.0503]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3066, -0.4548,  0.6978,  ...,  1.3994,  2.2188, -2.2754]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 10:49:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of noticed is unnoticed
The opposite of acceptable is unacceptable
The opposite of reliable is unreliable
The opposite of veiled is unveiled
The opposite of usual is unusual
The opposite of restricted is unrestricted
The opposite of able is unable
The opposite of controlled is
2024-07-29 10:49:08 root INFO     [order_1_approx] starting weight calculation for The opposite of usual is unusual
The opposite of acceptable is unacceptable
The opposite of restricted is unrestricted
The opposite of controlled is uncontrolled
The opposite of noticed is unnoticed
The opposite of reliable is unreliable
The opposite of veiled is unveiled
The opposite of able is
2024-07-29 10:49:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 10:51:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4316,  0.1224, -0.2703,  ..., -0.8086, -0.1219,  0.2610],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0137, -5.8867,  2.3906,  ...,  0.7749, -1.7227, -2.3281],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0566, -0.0228,  0.0339,  ..., -0.0029, -0.0408,  0.0120],
        [-0.0232,  0.0403,  0.0011,  ...,  0.0348,  0.0667,  0.0298],
        [ 0.0060, -0.0062,  0.0070,  ..., -0.0346, -0.0201, -0.0179],
        ...,
        [-0.0152,  0.0045, -0.0037,  ...,  0.0059,  0.0273, -0.0039],
        [-0.0467, -0.0115,  0.0101,  ..., -0.0174,  0.0069, -0.0314],
        [ 0.0152,  0.0078, -0.0035,  ..., -0.0268, -0.0003,  0.0361]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0234, -4.9570,  1.7266,  ...,  1.3730, -1.5742, -2.4238]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 10:51:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of usual is unusual
The opposite of acceptable is unacceptable
The opposite of restricted is unrestricted
The opposite of controlled is uncontrolled
The opposite of noticed is unnoticed
The opposite of reliable is unreliable
The opposite of veiled is unveiled
The opposite of able is
2024-07-29 10:51:25 root INFO     [order_1_approx] starting weight calculation for The opposite of controlled is uncontrolled
The opposite of noticed is unnoticed
The opposite of able is unable
The opposite of usual is unusual
The opposite of reliable is unreliable
The opposite of restricted is unrestricted
The opposite of acceptable is unacceptable
The opposite of veiled is
2024-07-29 10:51:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 10:53:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1949, -0.7202,  0.0465,  ...,  0.1924, -0.0212,  0.2356],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0117,  0.9004, -0.4668,  ...,  3.7188, -3.1152, -0.1719],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0663, -0.0119,  0.0193,  ...,  0.0200,  0.0018, -0.0046],
        [-0.0089,  0.0604, -0.0099,  ...,  0.0109, -0.0214, -0.0176],
        [ 0.0092, -0.0213,  0.0627,  ...,  0.0265,  0.0034,  0.0299],
        ...,
        [ 0.0007,  0.0031,  0.0202,  ...,  0.0729,  0.0027,  0.0174],
        [ 0.0238, -0.0126,  0.0119,  ..., -0.0027,  0.0791,  0.0036],
        [-0.0137, -0.0102, -0.0060,  ...,  0.0040, -0.0067,  0.0770]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3438,  1.0254, -1.1113,  ...,  3.7012, -3.6016,  0.0576]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 10:53:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of controlled is uncontrolled
The opposite of noticed is unnoticed
The opposite of able is unable
The opposite of usual is unusual
The opposite of reliable is unreliable
The opposite of restricted is unrestricted
The opposite of acceptable is unacceptable
The opposite of veiled is
2024-07-29 10:53:38 root INFO     [order_1_approx] starting weight calculation for The opposite of acceptable is unacceptable
The opposite of veiled is unveiled
The opposite of controlled is uncontrolled
The opposite of usual is unusual
The opposite of able is unable
The opposite of reliable is unreliable
The opposite of restricted is unrestricted
The opposite of noticed is
2024-07-29 10:53:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 10:55:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0592,  0.4585, -0.0737,  ..., -0.0646, -0.4648, -0.0452],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6670,  0.5264, -1.7783,  ..., -2.7031, -2.0820, -1.3418],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0633, -0.0019, -0.0007,  ...,  0.0089,  0.0108,  0.0194],
        [-0.0188,  0.0680,  0.0057,  ...,  0.0321, -0.0068,  0.0046],
        [ 0.0221,  0.0264,  0.0494,  ...,  0.0250, -0.0370, -0.0061],
        ...,
        [-0.0027,  0.0469,  0.0314,  ...,  0.0445,  0.0002, -0.0181],
        [-0.0099, -0.0103,  0.0189,  ..., -0.0270,  0.0354, -0.0285],
        [ 0.0172,  0.0025, -0.0291,  ..., -0.0169, -0.0083,  0.0747]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4722,  0.2568, -1.8340,  ..., -2.5684, -1.8848, -1.6318]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 10:55:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of acceptable is unacceptable
The opposite of veiled is unveiled
The opposite of controlled is uncontrolled
The opposite of usual is unusual
The opposite of able is unable
The opposite of reliable is unreliable
The opposite of restricted is unrestricted
The opposite of noticed is
2024-07-29 10:55:51 root INFO     total operator prediction time: 1069.7852897644043 seconds
2024-07-29 10:55:51 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+able_reg
2024-07-29 10:55:51 root INFO     building operator verb+able_reg
2024-07-29 10:55:52 root INFO     [order_1_approx] starting weight calculation for If you can publish something, that thing is publishable
If you can accept something, that thing is acceptable
If you can write something, that thing is writeable
If you can admire something, that thing is admirable
If you can expect something, that thing is expectable
If you can discover something, that thing is discoverable
If you can manage something, that thing is manageable
If you can inflate something, that thing is
2024-07-29 10:55:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 10:58:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0554, -0.0646, -0.4385,  ...,  0.0304,  0.4990,  0.7793],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5879, -1.6172,  0.3997,  ..., -1.0625, -6.5703, -1.3828],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0551,  0.0268, -0.0004,  ...,  0.0247, -0.0077,  0.0137],
        [-0.0107,  0.0357,  0.0100,  ...,  0.0114, -0.0032,  0.0009],
        [-0.0059,  0.0160,  0.0241,  ..., -0.0046,  0.0065, -0.0206],
        ...,
        [ 0.0152,  0.0126, -0.0129,  ...,  0.0603, -0.0013, -0.0023],
        [-0.0023, -0.0096, -0.0046,  ..., -0.0280,  0.0517, -0.0177],
        [-0.0011,  0.0048,  0.0062,  ..., -0.0105, -0.0341,  0.0438]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6953, -1.6025,  0.5293,  ..., -0.7119, -6.3633, -1.2256]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 10:58:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can publish something, that thing is publishable
If you can accept something, that thing is acceptable
If you can write something, that thing is writeable
If you can admire something, that thing is admirable
If you can expect something, that thing is expectable
If you can discover something, that thing is discoverable
If you can manage something, that thing is manageable
If you can inflate something, that thing is
2024-07-29 10:58:04 root INFO     [order_1_approx] starting weight calculation for If you can admire something, that thing is admirable
If you can manage something, that thing is manageable
If you can discover something, that thing is discoverable
If you can publish something, that thing is publishable
If you can inflate something, that thing is inflatable
If you can expect something, that thing is expectable
If you can accept something, that thing is acceptable
If you can write something, that thing is
2024-07-29 10:58:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 11:00:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-3.0225e-01, -3.3643e-01,  4.6533e-01,  ..., -5.1758e-01,
         4.5776e-05, -6.8359e-03], device='cuda:1', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6260, -1.6602, -1.1865,  ..., -2.5547, -7.7148,  0.2207],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0540, -0.0064, -0.0019,  ..., -0.0069, -0.0099,  0.0185],
        [-0.0100,  0.0385,  0.0031,  ...,  0.0070, -0.0147, -0.0040],
        [ 0.0054, -0.0035,  0.0662,  ...,  0.0047, -0.0037,  0.0021],
        ...,
        [ 0.0223,  0.0048, -0.0110,  ...,  0.0510,  0.0117, -0.0198],
        [ 0.0087, -0.0023,  0.0003,  ..., -0.0130,  0.0421, -0.0087],
        [ 0.0189,  0.0100,  0.0101,  ..., -0.0123, -0.0164,  0.0350]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6611, -1.6016, -1.0586,  ..., -2.0918, -7.2812,  0.3108]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 11:00:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can admire something, that thing is admirable
If you can manage something, that thing is manageable
If you can discover something, that thing is discoverable
If you can publish something, that thing is publishable
If you can inflate something, that thing is inflatable
If you can expect something, that thing is expectable
If you can accept something, that thing is acceptable
If you can write something, that thing is
2024-07-29 11:00:15 root INFO     [order_1_approx] starting weight calculation for If you can discover something, that thing is discoverable
If you can write something, that thing is writeable
If you can inflate something, that thing is inflatable
If you can admire something, that thing is admirable
If you can publish something, that thing is publishable
If you can expect something, that thing is expectable
If you can accept something, that thing is acceptable
If you can manage something, that thing is
2024-07-29 11:00:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 11:02:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1237,  0.3789,  0.1602,  ...,  0.0088, -0.0568, -0.1462],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4863, -0.7349, -0.5762,  ..., -3.8945, -5.8711, -2.5410],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0657,  0.0143, -0.0028,  ...,  0.0063, -0.0046,  0.0185],
        [-0.0071,  0.0500,  0.0159,  ...,  0.0080, -0.0085, -0.0074],
        [-0.0002, -0.0148,  0.0352,  ..., -0.0065,  0.0073, -0.0161],
        ...,
        [ 0.0278, -0.0036,  0.0048,  ...,  0.0632,  0.0193, -0.0017],
        [ 0.0135,  0.0022,  0.0062,  ..., -0.0284,  0.0348, -0.0086],
        [-0.0174, -0.0020,  0.0038,  ..., -0.0228, -0.0086,  0.0270]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3467, -0.7129, -0.6909,  ..., -3.8457, -5.6719, -2.5645]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 11:02:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can discover something, that thing is discoverable
If you can write something, that thing is writeable
If you can inflate something, that thing is inflatable
If you can admire something, that thing is admirable
If you can publish something, that thing is publishable
If you can expect something, that thing is expectable
If you can accept something, that thing is acceptable
If you can manage something, that thing is
2024-07-29 11:02:27 root INFO     [order_1_approx] starting weight calculation for If you can write something, that thing is writeable
If you can accept something, that thing is acceptable
If you can admire something, that thing is admirable
If you can discover something, that thing is discoverable
If you can manage something, that thing is manageable
If you can inflate something, that thing is inflatable
If you can publish something, that thing is publishable
If you can expect something, that thing is
2024-07-29 11:02:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 11:04:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0183, -0.1257,  0.0010,  ..., -0.3660, -0.1755, -0.3657],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4844, -0.5361, -5.2031,  ..., -3.6406, -7.9531, -3.5508],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0436,  0.0019,  0.0172,  ...,  0.0328, -0.0132,  0.0209],
        [-0.0256,  0.0667,  0.0280,  ...,  0.0161,  0.0043, -0.0182],
        [ 0.0040, -0.0135,  0.0257,  ..., -0.0198,  0.0109, -0.0402],
        ...,
        [-0.0111,  0.0098, -0.0025,  ...,  0.0565,  0.0167,  0.0003],
        [ 0.0130, -0.0057, -0.0236,  ..., -0.0486,  0.0538, -0.0188],
        [ 0.0119, -0.0042,  0.0110,  ..., -0.0169, -0.0066,  0.0446]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1445, -0.1807, -5.4688,  ..., -3.4961, -7.6992, -3.7246]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 11:04:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can write something, that thing is writeable
If you can accept something, that thing is acceptable
If you can admire something, that thing is admirable
If you can discover something, that thing is discoverable
If you can manage something, that thing is manageable
If you can inflate something, that thing is inflatable
If you can publish something, that thing is publishable
If you can expect something, that thing is
2024-07-29 11:04:38 root INFO     [order_1_approx] starting weight calculation for If you can discover something, that thing is discoverable
If you can expect something, that thing is expectable
If you can publish something, that thing is publishable
If you can accept something, that thing is acceptable
If you can write something, that thing is writeable
If you can inflate something, that thing is inflatable
If you can manage something, that thing is manageable
If you can admire something, that thing is
2024-07-29 11:04:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 11:06:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1453, -0.1844,  0.2148,  ...,  0.2822,  0.0336,  0.3057],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.1953, -1.1631, -3.1445,  ..., -1.9707, -5.5234, -1.9336],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0565,  0.0121, -0.0010,  ...,  0.0072, -0.0156,  0.0126],
        [-0.0146,  0.0388, -0.0020,  ...,  0.0271,  0.0017, -0.0070],
        [-0.0051, -0.0021,  0.0461,  ...,  0.0070, -0.0078, -0.0212],
        ...,
        [ 0.0172,  0.0067, -0.0255,  ...,  0.0529,  0.0200,  0.0084],
        [-0.0119,  0.0020,  0.0113,  ..., -0.0387,  0.0468,  0.0014],
        [-0.0101, -0.0109, -0.0176,  ..., -0.0105, -0.0178,  0.0335]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.8125, -1.1650, -3.5078,  ..., -1.7607, -5.7383, -1.6953]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 11:06:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can discover something, that thing is discoverable
If you can expect something, that thing is expectable
If you can publish something, that thing is publishable
If you can accept something, that thing is acceptable
If you can write something, that thing is writeable
If you can inflate something, that thing is inflatable
If you can manage something, that thing is manageable
If you can admire something, that thing is
2024-07-29 11:06:50 root INFO     [order_1_approx] starting weight calculation for If you can inflate something, that thing is inflatable
If you can discover something, that thing is discoverable
If you can accept something, that thing is acceptable
If you can manage something, that thing is manageable
If you can admire something, that thing is admirable
If you can write something, that thing is writeable
If you can expect something, that thing is expectable
If you can publish something, that thing is
2024-07-29 11:06:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 11:09:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2566,  0.1260,  0.3530,  ...,  0.3459,  0.0402,  0.3152],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5898, -2.8398, -0.8169,  ..., -1.7998, -8.8594, -0.5254],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0446,  0.0142, -0.0042,  ...,  0.0079, -0.0009,  0.0256],
        [-0.0262,  0.0411, -0.0011,  ...,  0.0064, -0.0071, -0.0009],
        [ 0.0153, -0.0045,  0.0308,  ..., -0.0063, -0.0102, -0.0077],
        ...,
        [ 0.0135,  0.0005, -0.0103,  ...,  0.0397,  0.0113, -0.0040],
        [-0.0053, -0.0084, -0.0068,  ..., -0.0368,  0.0311, -0.0358],
        [ 0.0044,  0.0044,  0.0018,  ..., -0.0190, -0.0173,  0.0322]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5986, -2.9375, -0.6699,  ..., -1.8916, -8.5469, -0.6377]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 11:09:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can inflate something, that thing is inflatable
If you can discover something, that thing is discoverable
If you can accept something, that thing is acceptable
If you can manage something, that thing is manageable
If you can admire something, that thing is admirable
If you can write something, that thing is writeable
If you can expect something, that thing is expectable
If you can publish something, that thing is
2024-07-29 11:09:02 root INFO     [order_1_approx] starting weight calculation for If you can write something, that thing is writeable
If you can publish something, that thing is publishable
If you can expect something, that thing is expectable
If you can inflate something, that thing is inflatable
If you can manage something, that thing is manageable
If you can admire something, that thing is admirable
If you can discover something, that thing is discoverable
If you can accept something, that thing is
2024-07-29 11:09:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 11:11:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3496,  0.1206, -0.2495,  ...,  0.3545,  0.0625,  0.2406],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0361,  0.0684, -3.4277,  ..., -2.2617, -8.3359, -0.9043],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0568,  0.0110,  0.0067,  ...,  0.0089, -0.0036,  0.0168],
        [-0.0050,  0.0626,  0.0152,  ...,  0.0234, -0.0031, -0.0206],
        [ 0.0177,  0.0009,  0.0503,  ..., -0.0026,  0.0029, -0.0116],
        ...,
        [ 0.0125,  0.0053,  0.0033,  ...,  0.0430,  0.0140, -0.0090],
        [ 0.0119,  0.0063, -0.0060,  ..., -0.0343,  0.0466, -0.0035],
        [-0.0009, -0.0033, -0.0093,  ..., -0.0143, -0.0113,  0.0347]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6655,  0.0228, -3.6191,  ..., -1.9336, -8.2500, -0.9497]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 11:11:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can write something, that thing is writeable
If you can publish something, that thing is publishable
If you can expect something, that thing is expectable
If you can inflate something, that thing is inflatable
If you can manage something, that thing is manageable
If you can admire something, that thing is admirable
If you can discover something, that thing is discoverable
If you can accept something, that thing is
2024-07-29 11:11:08 root INFO     [order_1_approx] starting weight calculation for If you can accept something, that thing is acceptable
If you can write something, that thing is writeable
If you can inflate something, that thing is inflatable
If you can expect something, that thing is expectable
If you can manage something, that thing is manageable
If you can admire something, that thing is admirable
If you can publish something, that thing is publishable
If you can discover something, that thing is
2024-07-29 11:11:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 11:13:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2361,  0.0745,  0.2947,  ..., -0.2212, -0.6343, -0.0605],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8945, -3.2969,  0.5112,  ..., -1.7891, -6.5625,  0.8613],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0633,  0.0082,  0.0127,  ...,  0.0233,  0.0030,  0.0146],
        [-0.0125,  0.0587,  0.0081,  ...,  0.0226, -0.0108,  0.0029],
        [ 0.0071, -0.0021,  0.0548,  ...,  0.0071, -0.0027, -0.0166],
        ...,
        [ 0.0154,  0.0088,  0.0040,  ...,  0.0740,  0.0120, -0.0026],
        [ 0.0073,  0.0090, -0.0070,  ..., -0.0257,  0.0582, -0.0062],
        [ 0.0174, -0.0012,  0.0153,  ..., -0.0134, -0.0228,  0.0474]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5791, -3.4473,  0.5015,  ..., -1.8320, -6.2812,  0.3796]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 11:13:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can accept something, that thing is acceptable
If you can write something, that thing is writeable
If you can inflate something, that thing is inflatable
If you can expect something, that thing is expectable
If you can manage something, that thing is manageable
If you can admire something, that thing is admirable
If you can publish something, that thing is publishable
If you can discover something, that thing is
2024-07-29 11:13:18 root INFO     total operator prediction time: 1046.594886302948 seconds
2024-07-29 11:13:18 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+tion_irreg
2024-07-29 11:13:18 root INFO     building operator verb+tion_irreg
2024-07-29 11:13:18 root INFO     [order_1_approx] starting weight calculation for To civilize results in civilization
To globalize results in globalization
To colonize results in colonization
To observe results in observation
To authorize results in authorization
To starve results in starvation
To stabilize results in stabilization
To minimize results in
2024-07-29 11:13:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 11:15:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3752,  0.0173, -0.5410,  ..., -0.2898,  0.0801, -0.3135],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4375, -0.3677,  2.0176,  ..., -1.2246, -3.3086, -2.7441],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0699,  0.0080, -0.0043,  ..., -0.0043,  0.0022,  0.0109],
        [ 0.0028,  0.0651,  0.0106,  ...,  0.0188, -0.0074,  0.0130],
        [-0.0178, -0.0138,  0.0367,  ...,  0.0064, -0.0006, -0.0118],
        ...,
        [ 0.0048,  0.0174,  0.0033,  ...,  0.0623, -0.0030,  0.0092],
        [-0.0058,  0.0083, -0.0031,  ..., -0.0052,  0.0593, -0.0070],
        [-0.0023,  0.0046,  0.0058,  ..., -0.0102, -0.0242,  0.0556]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6025, -0.3953,  2.1719,  ..., -1.1885, -3.5371, -2.7305]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 11:15:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To civilize results in civilization
To globalize results in globalization
To colonize results in colonization
To observe results in observation
To authorize results in authorization
To starve results in starvation
To stabilize results in stabilization
To minimize results in
2024-07-29 11:15:41 root INFO     [order_1_approx] starting weight calculation for To minimize results in minimization
To authorize results in authorization
To globalize results in globalization
To starve results in starvation
To civilize results in civilization
To colonize results in colonization
To stabilize results in stabilization
To observe results in
2024-07-29 11:15:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 11:17:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0942,  0.2098, -0.1220,  ..., -0.1194, -0.2910, -0.1821],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.0527, -3.5156,  2.7051,  ...,  0.7754, -1.6328, -0.9316],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 9.3994e-02,  4.6501e-03, -1.4465e-02,  ..., -2.8191e-03,
         -6.7482e-03, -5.2567e-03],
        [ 4.1962e-03,  1.0620e-01,  2.0462e-02,  ...,  2.9999e-02,
         -6.1760e-03,  2.2507e-02],
        [-2.6360e-03, -1.1009e-02,  8.4045e-02,  ..., -8.2474e-03,
         -3.9597e-03,  3.9940e-03],
        ...,
        [-2.2827e-02,  1.0452e-03,  1.5007e-02,  ...,  9.0698e-02,
          1.7166e-05,  1.3962e-03],
        [-9.7198e-03,  2.1667e-03,  2.1667e-03,  ...,  8.6975e-03,
          7.4097e-02, -2.4567e-02],
        [ 2.3407e-02,  1.7273e-02,  2.1057e-03,  ...,  4.2267e-03,
         -2.8595e-02,  9.7595e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.0254, -3.1055,  2.6211,  ...,  0.9785, -2.5176, -1.1895]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 11:17:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To minimize results in minimization
To authorize results in authorization
To globalize results in globalization
To starve results in starvation
To civilize results in civilization
To colonize results in colonization
To stabilize results in stabilization
To observe results in
2024-07-29 11:17:53 root INFO     [order_1_approx] starting weight calculation for To starve results in starvation
To stabilize results in stabilization
To authorize results in authorization
To colonize results in colonization
To globalize results in globalization
To observe results in observation
To minimize results in minimization
To civilize results in
2024-07-29 11:17:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 11:20:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2385,  0.1333, -0.5039,  ..., -0.3193, -0.8271,  0.2695],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.7842, -1.8945,  2.7734,  ...,  0.3477,  0.0569, -1.1270],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0668, -0.0075,  0.0127,  ...,  0.0037, -0.0045,  0.0100],
        [ 0.0101,  0.0511,  0.0057,  ...,  0.0099, -0.0030,  0.0042],
        [-0.0156, -0.0120,  0.0405,  ..., -0.0035,  0.0022, -0.0119],
        ...,
        [ 0.0007,  0.0015, -0.0063,  ...,  0.0662, -0.0072,  0.0029],
        [ 0.0026,  0.0115,  0.0007,  ..., -0.0019,  0.0506, -0.0063],
        [ 0.0004, -0.0089,  0.0014,  ..., -0.0023, -0.0249,  0.0616]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.0664, -1.6768,  2.5098,  ...,  0.4370, -0.0544, -1.0010]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 11:20:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To starve results in starvation
To stabilize results in stabilization
To authorize results in authorization
To colonize results in colonization
To globalize results in globalization
To observe results in observation
To minimize results in minimization
To civilize results in
2024-07-29 11:20:05 root INFO     [order_1_approx] starting weight calculation for To stabilize results in stabilization
To civilize results in civilization
To globalize results in globalization
To colonize results in colonization
To observe results in observation
To minimize results in minimization
To authorize results in authorization
To starve results in
2024-07-29 11:20:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 11:22:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0405, -0.2313, -0.4619,  ..., -0.2268, -0.1494,  0.1490],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8984, -3.9023,  3.0605,  ...,  0.4646, -1.7783, -1.8398],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1030, -0.0084,  0.0239,  ...,  0.0027, -0.0260,  0.0071],
        [-0.0112,  0.0618,  0.0024,  ...,  0.0270,  0.0093,  0.0006],
        [ 0.0034, -0.0231,  0.0584,  ..., -0.0203, -0.0077, -0.0064],
        ...,
        [-0.0005,  0.0209,  0.0015,  ...,  0.0578,  0.0103, -0.0033],
        [-0.0052,  0.0218,  0.0042,  ...,  0.0019,  0.0560, -0.0172],
        [ 0.0112, -0.0073, -0.0079,  ..., -0.0027, -0.0186,  0.0767]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7646, -4.0898,  3.0059,  ...,  0.9072, -1.8047, -1.8262]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 11:22:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To stabilize results in stabilization
To civilize results in civilization
To globalize results in globalization
To colonize results in colonization
To observe results in observation
To minimize results in minimization
To authorize results in authorization
To starve results in
2024-07-29 11:22:17 root INFO     [order_1_approx] starting weight calculation for To authorize results in authorization
To globalize results in globalization
To minimize results in minimization
To observe results in observation
To stabilize results in stabilization
To starve results in starvation
To civilize results in civilization
To colonize results in
2024-07-29 11:22:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 11:24:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2180,  0.0677, -0.3027,  ..., -0.2920, -0.2595, -0.0673],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.5605, -1.5332,  4.0117,  ..., -0.1907, -1.1992, -2.9023],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0513, -0.0049,  0.0158,  ...,  0.0075, -0.0037,  0.0140],
        [ 0.0045,  0.0496,  0.0071,  ...,  0.0077,  0.0178,  0.0037],
        [-0.0045, -0.0057,  0.0367,  ..., -0.0038, -0.0100, -0.0057],
        ...,
        [-0.0036,  0.0051,  0.0063,  ...,  0.0391, -0.0007,  0.0013],
        [ 0.0003,  0.0178, -0.0060,  ..., -0.0039,  0.0345,  0.0053],
        [-0.0042, -0.0008,  0.0044,  ..., -0.0067, -0.0235,  0.0430]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.6348, -1.6094,  4.0898,  ..., -0.1049, -1.0293, -2.9883]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 11:24:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To authorize results in authorization
To globalize results in globalization
To minimize results in minimization
To observe results in observation
To stabilize results in stabilization
To starve results in starvation
To civilize results in civilization
To colonize results in
2024-07-29 11:24:31 root INFO     [order_1_approx] starting weight calculation for To globalize results in globalization
To authorize results in authorization
To starve results in starvation
To observe results in observation
To civilize results in civilization
To minimize results in minimization
To colonize results in colonization
To stabilize results in
2024-07-29 11:24:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 11:26:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2551,  0.0909, -0.4414,  ..., -0.4290, -0.4836, -0.0656],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1250, -3.3281,  0.9668,  ...,  0.5586, -3.8145, -3.5020],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0405, -0.0018,  0.0031,  ..., -0.0048, -0.0076,  0.0043],
        [-0.0050,  0.0267,  0.0102,  ...,  0.0139,  0.0055, -0.0011],
        [-0.0052,  0.0070,  0.0243,  ..., -0.0005, -0.0041, -0.0081],
        ...,
        [-0.0003,  0.0052, -0.0035,  ...,  0.0245,  0.0026,  0.0034],
        [ 0.0020,  0.0019, -0.0106,  ..., -0.0053,  0.0201, -0.0020],
        [-0.0046,  0.0044,  0.0050,  ..., -0.0018, -0.0096,  0.0311]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0918, -3.4492,  1.0107,  ...,  0.5552, -3.8164, -3.4336]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 11:26:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To globalize results in globalization
To authorize results in authorization
To starve results in starvation
To observe results in observation
To civilize results in civilization
To minimize results in minimization
To colonize results in colonization
To stabilize results in
2024-07-29 11:26:43 root INFO     [order_1_approx] starting weight calculation for To starve results in starvation
To authorize results in authorization
To stabilize results in stabilization
To observe results in observation
To civilize results in civilization
To minimize results in minimization
To colonize results in colonization
To globalize results in
2024-07-29 11:26:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 11:28:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0208,  0.2698, -0.1832,  ..., -0.1903, -0.3062,  0.0551],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.2285, -2.3066,  1.4902,  ...,  0.7983, -2.0137, -1.0625],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0484, -0.0040,  0.0093,  ...,  0.0039, -0.0069,  0.0136],
        [-0.0050,  0.0455,  0.0032,  ...,  0.0163,  0.0011,  0.0032],
        [-0.0026,  0.0027,  0.0317,  ..., -0.0040, -0.0059, -0.0085],
        ...,
        [ 0.0084,  0.0054, -0.0014,  ...,  0.0452,  0.0050,  0.0004],
        [ 0.0017, -0.0009, -0.0038,  ..., -0.0097,  0.0391, -0.0032],
        [-0.0065, -0.0029,  0.0044,  ..., -0.0038, -0.0152,  0.0484]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.2080, -2.3809,  1.5879,  ...,  0.8408, -1.9375, -1.1387]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 11:28:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To starve results in starvation
To authorize results in authorization
To stabilize results in stabilization
To observe results in observation
To civilize results in civilization
To minimize results in minimization
To colonize results in colonization
To globalize results in
2024-07-29 11:28:56 root INFO     [order_1_approx] starting weight calculation for To civilize results in civilization
To observe results in observation
To globalize results in globalization
To minimize results in minimization
To colonize results in colonization
To starve results in starvation
To stabilize results in stabilization
To authorize results in
2024-07-29 11:28:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 11:31:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1470,  0.3040, -0.1279,  ..., -0.1161, -0.2974, -0.2078],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.4062, -4.2578,  2.1133,  ...,  0.8643, -2.7871, -2.3750],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.6294e-02, -8.6594e-03,  1.5869e-02,  ..., -4.8676e-03,
         -9.6283e-03,  5.4321e-03],
        [ 2.0504e-03,  5.8655e-02,  1.5343e-02,  ...,  2.6093e-02,
         -8.2703e-03,  1.0452e-02],
        [ 2.8954e-03, -5.7106e-03,  3.8940e-02,  ..., -2.6779e-03,
          5.6076e-04, -2.7161e-03],
        ...,
        [ 7.5378e-03,  2.1454e-02, -1.2398e-05,  ...,  5.7770e-02,
         -1.2674e-03,  3.1776e-03],
        [-3.3498e-05,  2.5696e-02,  5.7793e-03,  ...,  2.0580e-03,
          6.1890e-02,  6.2790e-03],
        [ 1.0391e-02, -6.1760e-03,  3.4943e-03,  ...,  9.8953e-03,
         -2.9205e-02,  6.6895e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.2783, -4.2188,  1.9658,  ...,  0.9072, -3.3184, -2.4258]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 11:31:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To civilize results in civilization
To observe results in observation
To globalize results in globalization
To minimize results in minimization
To colonize results in colonization
To starve results in starvation
To stabilize results in stabilization
To authorize results in
2024-07-29 11:31:08 root INFO     total operator prediction time: 1069.9829847812653 seconds
2024-07-29 11:31:08 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj+ly_reg
2024-07-29 11:31:08 root INFO     building operator adj+ly_reg
2024-07-29 11:31:08 root INFO     [order_1_approx] starting weight calculation for The adjective form of different is differently
The adjective form of unique is uniquely
The adjective form of typical is typically
The adjective form of important is importantly
The adjective form of increasing is increasingly
The adjective form of beautiful is beautifully
The adjective form of rare is rarely
The adjective form of historical is
2024-07-29 11:31:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 11:33:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1309, -0.1171, -0.2803,  ..., -0.6763, -0.4431,  0.0486],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1299, -1.9600,  0.6274,  ..., -3.1230, -3.3672, -2.6270],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1051, -0.0341,  0.0144,  ...,  0.0092, -0.0121,  0.0048],
        [ 0.0004,  0.0727,  0.0071,  ...,  0.0354,  0.0094,  0.0051],
        [ 0.0060, -0.0158,  0.0521,  ...,  0.0170, -0.0075, -0.0094],
        ...,
        [ 0.0015,  0.0190, -0.0344,  ...,  0.0723,  0.0035, -0.0021],
        [-0.0066,  0.0307,  0.0067,  ..., -0.0100,  0.0522, -0.0186],
        [ 0.0126,  0.0051, -0.0110,  ...,  0.0154, -0.0213,  0.0453]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1494, -2.0273,  0.6509,  ..., -2.7871, -2.9824, -2.8867]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 11:33:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of different is differently
The adjective form of unique is uniquely
The adjective form of typical is typically
The adjective form of important is importantly
The adjective form of increasing is increasingly
The adjective form of beautiful is beautifully
The adjective form of rare is rarely
The adjective form of historical is
2024-07-29 11:33:22 root INFO     [order_1_approx] starting weight calculation for The adjective form of rare is rarely
The adjective form of unique is uniquely
The adjective form of different is differently
The adjective form of typical is typically
The adjective form of increasing is increasingly
The adjective form of historical is historically
The adjective form of important is importantly
The adjective form of beautiful is
2024-07-29 11:33:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 11:35:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6904, -0.1560,  0.0856,  ...,  0.1168, -0.2400,  0.0355],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2656, -2.4102, -0.9463,  ...,  0.7129, -3.5469, -2.4082],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0812, -0.0173,  0.0307,  ..., -0.0189,  0.0093,  0.0125],
        [ 0.0084,  0.0559,  0.0067,  ...,  0.0225,  0.0035, -0.0065],
        [-0.0013, -0.0139,  0.0692,  ...,  0.0146, -0.0131, -0.0125],
        ...,
        [ 0.0052,  0.0094, -0.0126,  ...,  0.0820, -0.0110, -0.0119],
        [-0.0090,  0.0236, -0.0106,  ...,  0.0054,  0.0391,  0.0077],
        [-0.0081,  0.0004, -0.0098,  ...,  0.0078, -0.0192,  0.0456]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7637, -2.1406, -0.9961,  ...,  0.2893, -3.6152, -2.8066]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 11:35:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of rare is rarely
The adjective form of unique is uniquely
The adjective form of different is differently
The adjective form of typical is typically
The adjective form of increasing is increasingly
The adjective form of historical is historically
The adjective form of important is importantly
The adjective form of beautiful is
2024-07-29 11:35:36 root INFO     [order_1_approx] starting weight calculation for The adjective form of beautiful is beautifully
The adjective form of increasing is increasingly
The adjective form of different is differently
The adjective form of typical is typically
The adjective form of historical is historically
The adjective form of rare is rarely
The adjective form of unique is uniquely
The adjective form of important is
2024-07-29 11:35:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 11:37:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3091, -0.3101, -0.2197,  ..., -0.2019, -0.0844,  0.1477],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.2266, -0.7808, -0.3784,  ..., -3.9141, -1.2969, -3.2305],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0678, -0.0209,  0.0156,  ...,  0.0083,  0.0092,  0.0240],
        [ 0.0074,  0.0290,  0.0207,  ...,  0.0220, -0.0043, -0.0072],
        [-0.0017,  0.0272,  0.0608,  ...,  0.0042, -0.0036, -0.0064],
        ...,
        [ 0.0059,  0.0171, -0.0077,  ...,  0.0687,  0.0054,  0.0274],
        [-0.0106,  0.0235, -0.0082,  ..., -0.0083,  0.0371, -0.0112],
        [ 0.0150, -0.0117, -0.0119,  ...,  0.0024, -0.0324,  0.0304]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8672, -0.7778, -0.2197,  ..., -4.1562, -1.1709, -3.3086]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 11:37:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of beautiful is beautifully
The adjective form of increasing is increasingly
The adjective form of different is differently
The adjective form of typical is typically
The adjective form of historical is historically
The adjective form of rare is rarely
The adjective form of unique is uniquely
The adjective form of important is
2024-07-29 11:37:50 root INFO     [order_1_approx] starting weight calculation for The adjective form of historical is historically
The adjective form of rare is rarely
The adjective form of beautiful is beautifully
The adjective form of typical is typically
The adjective form of important is importantly
The adjective form of increasing is increasingly
The adjective form of different is differently
The adjective form of unique is
2024-07-29 11:37:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 11:40:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0641, -0.1788, -0.2988,  ..., -0.1074, -0.0884,  0.3569],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0581, -2.3438,  0.4473,  ..., -2.0527, -2.9941, -1.5107],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0773, -0.0182,  0.0211,  ...,  0.0180,  0.0038, -0.0084],
        [-0.0067,  0.0601, -0.0147,  ...,  0.0300,  0.0080, -0.0074],
        [-0.0096, -0.0114,  0.0422,  ..., -0.0007,  0.0004, -0.0143],
        ...,
        [ 0.0073,  0.0241, -0.0040,  ...,  0.0604,  0.0037,  0.0016],
        [ 0.0091,  0.0184,  0.0077,  ..., -0.0025,  0.0480, -0.0073],
        [ 0.0090, -0.0094, -0.0199,  ...,  0.0075, -0.0316,  0.0452]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0568, -2.3906,  0.8594,  ..., -2.0078, -3.1465, -1.8047]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 11:40:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of historical is historically
The adjective form of rare is rarely
The adjective form of beautiful is beautifully
The adjective form of typical is typically
The adjective form of important is importantly
The adjective form of increasing is increasingly
The adjective form of different is differently
The adjective form of unique is
2024-07-29 11:40:04 root INFO     [order_1_approx] starting weight calculation for The adjective form of rare is rarely
The adjective form of historical is historically
The adjective form of important is importantly
The adjective form of typical is typically
The adjective form of beautiful is beautifully
The adjective form of increasing is increasingly
The adjective form of unique is uniquely
The adjective form of different is
2024-07-29 11:40:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 11:42:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2773, -0.5444, -0.0308,  ..., -0.2266, -0.0476, -0.0585],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5225, -1.9033,  3.0039,  ..., -2.0547, -0.5444, -2.0762],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0868, -0.0048,  0.0035,  ...,  0.0133,  0.0402,  0.0382],
        [ 0.0106,  0.0371,  0.0123,  ...,  0.0513,  0.0152,  0.0147],
        [ 0.0087,  0.0131,  0.0442,  ..., -0.0015,  0.0103,  0.0037],
        ...,
        [ 0.0090,  0.0053, -0.0207,  ...,  0.0697,  0.0041, -0.0034],
        [-0.0002,  0.0175, -0.0050,  ..., -0.0207,  0.0445, -0.0048],
        [ 0.0103,  0.0070, -0.0011,  ..., -0.0077, -0.0277,  0.0558]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6445, -1.7842,  2.7930,  ..., -2.0898, -0.3447, -2.0684]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 11:42:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of rare is rarely
The adjective form of historical is historically
The adjective form of important is importantly
The adjective form of typical is typically
The adjective form of beautiful is beautifully
The adjective form of increasing is increasingly
The adjective form of unique is uniquely
The adjective form of different is
2024-07-29 11:42:17 root INFO     [order_1_approx] starting weight calculation for The adjective form of different is differently
The adjective form of typical is typically
The adjective form of beautiful is beautifully
The adjective form of increasing is increasingly
The adjective form of historical is historically
The adjective form of unique is uniquely
The adjective form of important is importantly
The adjective form of rare is
2024-07-29 11:42:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 11:44:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1963, -0.4805, -0.3979,  ..., -0.2617,  0.1600, -0.2712],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.9141, -3.3086, -0.4570,  ..., -4.3320, -3.7656, -4.1367],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0828, -0.0092,  0.0395,  ...,  0.0162,  0.0216,  0.0195],
        [ 0.0149,  0.0583,  0.0342,  ...,  0.0421,  0.0340,  0.0181],
        [ 0.0142, -0.0230,  0.0464,  ..., -0.0146,  0.0021,  0.0154],
        ...,
        [ 0.0010,  0.0370, -0.0091,  ...,  0.0791,  0.0044,  0.0183],
        [-0.0061,  0.0273,  0.0175,  ...,  0.0066,  0.0377, -0.0036],
        [ 0.0201,  0.0089,  0.0058,  ..., -0.0034, -0.0211,  0.0576]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.7803, -3.6113, -0.3818,  ..., -4.6445, -3.7773, -4.2305]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 11:44:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of different is differently
The adjective form of typical is typically
The adjective form of beautiful is beautifully
The adjective form of increasing is increasingly
The adjective form of historical is historically
The adjective form of unique is uniquely
The adjective form of important is importantly
The adjective form of rare is
2024-07-29 11:44:30 root INFO     [order_1_approx] starting weight calculation for The adjective form of typical is typically
The adjective form of different is differently
The adjective form of beautiful is beautifully
The adjective form of important is importantly
The adjective form of rare is rarely
The adjective form of historical is historically
The adjective form of unique is uniquely
The adjective form of increasing is
2024-07-29 11:44:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 11:46:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2308, -0.1040, -0.4099,  ..., -0.0673, -0.0317, -0.0935],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4119, -2.8164,  1.2080,  ..., -0.3525, -2.1680, -2.3594],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0795, -0.0187,  0.0042,  ..., -0.0024,  0.0103,  0.0298],
        [ 0.0326,  0.0530,  0.0132,  ...,  0.0316, -0.0098,  0.0199],
        [ 0.0163,  0.0149,  0.0129,  ..., -0.0055,  0.0079, -0.0111],
        ...,
        [-0.0082,  0.0136,  0.0091,  ...,  0.0704, -0.0007,  0.0098],
        [-0.0327,  0.0233, -0.0122,  ..., -0.0192,  0.0600,  0.0019],
        [ 0.0018, -0.0107, -0.0092,  ...,  0.0063, -0.0174,  0.0407]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3975, -3.3203,  1.6113,  ..., -0.6133, -1.8936, -2.3145]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 11:46:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of typical is typically
The adjective form of different is differently
The adjective form of beautiful is beautifully
The adjective form of important is importantly
The adjective form of rare is rarely
The adjective form of historical is historically
The adjective form of unique is uniquely
The adjective form of increasing is
2024-07-29 11:46:44 root INFO     [order_1_approx] starting weight calculation for The adjective form of different is differently
The adjective form of increasing is increasingly
The adjective form of important is importantly
The adjective form of historical is historically
The adjective form of beautiful is beautifully
The adjective form of unique is uniquely
The adjective form of rare is rarely
The adjective form of typical is
2024-07-29 11:46:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 11:48:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0209, -0.2000,  0.0754,  ..., -0.1721, -0.1617,  0.0775],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6152, -1.7656,  2.0508,  ...,  0.7686, -4.6094, -3.5020],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0679, -0.0573,  0.0261,  ..., -0.0034,  0.0106,  0.0159],
        [ 0.0006,  0.0435, -0.0131,  ...,  0.0567, -0.0089, -0.0037],
        [ 0.0073, -0.0151,  0.0241,  ..., -0.0112, -0.0116,  0.0021],
        ...,
        [-0.0308,  0.0024, -0.0143,  ...,  0.0652, -0.0086,  0.0089],
        [ 0.0103,  0.0155,  0.0186,  ..., -0.0130,  0.0377,  0.0051],
        [-0.0081,  0.0087,  0.0026,  ...,  0.0088, -0.0399,  0.0291]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4346, -1.4072,  2.1191,  ...,  1.0547, -4.4297, -3.2949]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 11:48:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of different is differently
The adjective form of increasing is increasingly
The adjective form of important is importantly
The adjective form of historical is historically
The adjective form of beautiful is beautifully
The adjective form of unique is uniquely
The adjective form of rare is rarely
The adjective form of typical is
2024-07-29 11:48:59 root INFO     total operator prediction time: 1070.5650446414948 seconds
2024-07-29 11:48:59 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on over+adj_reg
2024-07-29 11:48:59 root INFO     building operator over+adj_reg
2024-07-29 11:49:00 root INFO     [order_1_approx] starting weight calculation for If something is too zealous, it is overzealous
If something is too spent, it is overspent
If something is too stressed, it is overstressed
If something is too turned, it is overturned
If something is too written, it is overwritten
If something is too confident, it is overconfident
If something is too heated, it is overheated
If something is too protected, it is
2024-07-29 11:49:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 11:51:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2896, -0.4551, -0.5537,  ...,  0.0303, -0.3345,  0.1175],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9883, -4.1680,  1.5000,  ...,  0.2437, -1.3164, -3.3887],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0627, -0.0146, -0.0019,  ..., -0.0009, -0.0023,  0.0113],
        [-0.0105,  0.0666, -0.0024,  ...,  0.0084,  0.0031,  0.0048],
        [-0.0041,  0.0004,  0.0537,  ...,  0.0248, -0.0013,  0.0049],
        ...,
        [-0.0005,  0.0012,  0.0029,  ...,  0.0670,  0.0059,  0.0008],
        [-0.0033,  0.0011, -0.0107,  ...,  0.0032,  0.0804, -0.0285],
        [ 0.0085,  0.0024, -0.0102,  ..., -0.0031, -0.0156,  0.0795]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2383, -4.2383,  1.4414,  ...,  0.5107, -1.2852, -3.3828]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 11:51:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too zealous, it is overzealous
If something is too spent, it is overspent
If something is too stressed, it is overstressed
If something is too turned, it is overturned
If something is too written, it is overwritten
If something is too confident, it is overconfident
If something is too heated, it is overheated
If something is too protected, it is
2024-07-29 11:51:12 root INFO     [order_1_approx] starting weight calculation for If something is too spent, it is overspent
If something is too zealous, it is overzealous
If something is too written, it is overwritten
If something is too protected, it is overprotected
If something is too stressed, it is overstressed
If something is too confident, it is overconfident
If something is too turned, it is overturned
If something is too heated, it is
2024-07-29 11:51:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 11:53:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0146, -0.6484, -0.2576,  ..., -0.0371, -0.4336,  0.0958],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4492, -1.9492,  0.0645,  ..., -0.7310, -0.7886, -2.8359],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0708, -0.0085,  0.0069,  ..., -0.0113,  0.0065, -0.0023],
        [ 0.0168,  0.0617, -0.0027,  ...,  0.0083,  0.0098, -0.0007],
        [ 0.0023,  0.0034,  0.0416,  ...,  0.0021,  0.0052,  0.0006],
        ...,
        [-0.0082,  0.0235,  0.0018,  ...,  0.0643,  0.0167,  0.0086],
        [ 0.0073, -0.0095,  0.0010,  ...,  0.0069,  0.0742, -0.0233],
        [-0.0061,  0.0131,  0.0056,  ...,  0.0061, -0.0169,  0.0686]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9385, -2.2266,  0.2152,  ..., -0.6011, -0.9170, -2.5781]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 11:53:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too spent, it is overspent
If something is too zealous, it is overzealous
If something is too written, it is overwritten
If something is too protected, it is overprotected
If something is too stressed, it is overstressed
If something is too confident, it is overconfident
If something is too turned, it is overturned
If something is too heated, it is
2024-07-29 11:53:24 root INFO     [order_1_approx] starting weight calculation for If something is too stressed, it is overstressed
If something is too protected, it is overprotected
If something is too zealous, it is overzealous
If something is too confident, it is overconfident
If something is too turned, it is overturned
If something is too heated, it is overheated
If something is too spent, it is overspent
If something is too written, it is
2024-07-29 11:53:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 11:55:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2111, -0.2568, -0.1570,  ..., -0.6582, -0.1478,  0.1669],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9629, -4.1953,  1.2412,  ..., -0.6182, -1.5820, -2.1348],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0753, -0.0154, -0.0028,  ..., -0.0080,  0.0056,  0.0184],
        [-0.0001,  0.0750, -0.0008,  ...,  0.0144,  0.0014, -0.0033],
        [ 0.0094, -0.0087,  0.0731,  ...,  0.0145, -0.0148,  0.0007],
        ...,
        [ 0.0197,  0.0148,  0.0130,  ...,  0.0807,  0.0014, -0.0013],
        [-0.0145, -0.0034, -0.0045,  ...,  0.0035,  0.0774, -0.0263],
        [ 0.0172,  0.0271,  0.0016,  ...,  0.0050, -0.0235,  0.0691]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1211, -4.4180,  1.2100,  ..., -0.5532, -0.9761, -2.1328]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 11:55:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too stressed, it is overstressed
If something is too protected, it is overprotected
If something is too zealous, it is overzealous
If something is too confident, it is overconfident
If something is too turned, it is overturned
If something is too heated, it is overheated
If something is too spent, it is overspent
If something is too written, it is
2024-07-29 11:55:37 root INFO     [order_1_approx] starting weight calculation for If something is too written, it is overwritten
If something is too stressed, it is overstressed
If something is too protected, it is overprotected
If something is too confident, it is overconfident
If something is too turned, it is overturned
If something is too zealous, it is overzealous
If something is too heated, it is overheated
If something is too spent, it is
2024-07-29 11:55:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 11:57:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1223, -0.2305, -0.1177,  ..., -0.2729, -0.0554, -0.0239],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4297, -3.7930, -1.2988,  ..., -1.6299, -1.3340, -3.3496],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0786,  0.0002,  0.0135,  ..., -0.0013,  0.0137,  0.0123],
        [-0.0080,  0.0500, -0.0165,  ...,  0.0235,  0.0056,  0.0024],
        [ 0.0268, -0.0090,  0.0564,  ..., -0.0116, -0.0070, -0.0044],
        ...,
        [ 0.0045,  0.0184, -0.0050,  ...,  0.0767,  0.0047, -0.0018],
        [-0.0134, -0.0027, -0.0021,  ...,  0.0141,  0.0518, -0.0244],
        [-0.0009,  0.0160, -0.0028,  ...,  0.0023, -0.0070,  0.0771]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5098, -3.6641, -1.3799,  ..., -1.4434, -0.9346, -3.3145]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 11:57:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too written, it is overwritten
If something is too stressed, it is overstressed
If something is too protected, it is overprotected
If something is too confident, it is overconfident
If something is too turned, it is overturned
If something is too zealous, it is overzealous
If something is too heated, it is overheated
If something is too spent, it is
2024-07-29 11:57:49 root INFO     [order_1_approx] starting weight calculation for If something is too confident, it is overconfident
If something is too written, it is overwritten
If something is too spent, it is overspent
If something is too stressed, it is overstressed
If something is too heated, it is overheated
If something is too protected, it is overprotected
If something is too turned, it is overturned
If something is too zealous, it is
2024-07-29 11:57:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 12:00:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6201, -0.4067, -0.3071,  ..., -0.0049, -0.7520,  0.4270],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3965, -5.0977,  0.0527,  ..., -0.2737, -0.9043, -2.0957],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.5806e-02,  1.4219e-03,  1.9272e-02,  ..., -9.0027e-04,
         -9.0637e-03,  1.0918e-02],
        [-1.9531e-03,  4.5837e-02,  4.0436e-03,  ...,  2.0569e-02,
          8.4686e-03,  1.6159e-02],
        [ 1.9791e-02, -7.7667e-03,  5.6702e-02,  ..., -7.2441e-03,
         -7.9651e-03, -3.3512e-03],
        ...,
        [-3.2997e-03,  2.9846e-02, -5.0068e-04,  ...,  7.5012e-02,
          1.6296e-02, -2.5158e-03],
        [ 6.7472e-05, -3.9940e-03,  7.4425e-03,  ...,  3.5477e-04,
          6.4453e-02, -2.4048e-02],
        [-6.4230e-04,  3.1853e-03, -3.3455e-03,  ...,  4.0665e-03,
         -2.3132e-02,  5.6122e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5127, -5.1602,  0.6006,  ...,  0.0142, -0.6934, -1.7988]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 12:00:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too confident, it is overconfident
If something is too written, it is overwritten
If something is too spent, it is overspent
If something is too stressed, it is overstressed
If something is too heated, it is overheated
If something is too protected, it is overprotected
If something is too turned, it is overturned
If something is too zealous, it is
2024-07-29 12:00:02 root INFO     [order_1_approx] starting weight calculation for If something is too zealous, it is overzealous
If something is too confident, it is overconfident
If something is too written, it is overwritten
If something is too protected, it is overprotected
If something is too spent, it is overspent
If something is too turned, it is overturned
If something is too heated, it is overheated
If something is too stressed, it is
2024-07-29 12:00:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 12:02:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2949, -0.5010, -0.3147,  ..., -0.3110, -0.3022,  0.3328],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3301, -3.0898,  0.5205,  ...,  0.0557,  0.8379, -2.2617],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0369, -0.0060,  0.0117,  ...,  0.0025, -0.0025, -0.0025],
        [ 0.0067,  0.0417,  0.0064,  ...,  0.0062,  0.0084, -0.0029],
        [ 0.0199,  0.0029,  0.0192,  ..., -0.0020, -0.0015, -0.0110],
        ...,
        [ 0.0094,  0.0103,  0.0061,  ...,  0.0550,  0.0096,  0.0095],
        [ 0.0034,  0.0024,  0.0025,  ..., -0.0028,  0.0363, -0.0203],
        [ 0.0024,  0.0083,  0.0087,  ...,  0.0035, -0.0179,  0.0443]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6113, -3.0176,  0.4941,  ...,  0.1957,  0.7324, -2.2012]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 12:02:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too zealous, it is overzealous
If something is too confident, it is overconfident
If something is too written, it is overwritten
If something is too protected, it is overprotected
If something is too spent, it is overspent
If something is too turned, it is overturned
If something is too heated, it is overheated
If something is too stressed, it is
2024-07-29 12:02:14 root INFO     [order_1_approx] starting weight calculation for If something is too protected, it is overprotected
If something is too stressed, it is overstressed
If something is too spent, it is overspent
If something is too written, it is overwritten
If something is too heated, it is overheated
If something is too zealous, it is overzealous
If something is too turned, it is overturned
If something is too confident, it is
2024-07-29 12:02:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 12:04:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2456, -0.0088, -0.3513,  ...,  0.6699, -0.2979, -0.1722],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2656, -4.2188,  1.6943,  ...,  1.5215, -1.1855, -1.5762],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0484, -0.0223,  0.0040,  ..., -0.0086, -0.0049,  0.0052],
        [ 0.0078,  0.0457, -0.0033,  ...,  0.0129,  0.0169,  0.0083],
        [ 0.0074, -0.0012,  0.0340,  ..., -0.0049, -0.0036, -0.0088],
        ...,
        [-0.0047,  0.0133, -0.0035,  ...,  0.0625,  0.0075,  0.0032],
        [-0.0026, -0.0018,  0.0153,  ...,  0.0029,  0.0371, -0.0163],
        [ 0.0004, -0.0014,  0.0051,  ..., -0.0005, -0.0149,  0.0282]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6064, -4.1875,  1.6777,  ...,  1.7383, -0.9829, -1.7217]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 12:04:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too protected, it is overprotected
If something is too stressed, it is overstressed
If something is too spent, it is overspent
If something is too written, it is overwritten
If something is too heated, it is overheated
If something is too zealous, it is overzealous
If something is too turned, it is overturned
If something is too confident, it is
2024-07-29 12:04:27 root INFO     [order_1_approx] starting weight calculation for If something is too written, it is overwritten
If something is too zealous, it is overzealous
If something is too stressed, it is overstressed
If something is too heated, it is overheated
If something is too spent, it is overspent
If something is too confident, it is overconfident
If something is too protected, it is overprotected
If something is too turned, it is
2024-07-29 12:04:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 12:06:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1835, -0.1035,  0.0007,  ..., -0.1279, -0.0184,  0.1213],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3867, -4.1992,  1.2305,  ...,  0.1387, -0.9375, -2.0059],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0770,  0.0144, -0.0004,  ..., -0.0035, -0.0008,  0.0230],
        [-0.0063,  0.0602, -0.0123,  ...,  0.0193,  0.0120, -0.0125],
        [ 0.0394, -0.0178,  0.0708,  ...,  0.0041,  0.0083,  0.0005],
        ...,
        [ 0.0215,  0.0064,  0.0077,  ...,  0.0832,  0.0280,  0.0058],
        [-0.0005, -0.0002,  0.0062,  ..., -0.0043,  0.0790, -0.0265],
        [-0.0087,  0.0098,  0.0075,  ..., -0.0225, -0.0235,  0.0715]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4199, -4.4023,  0.9014,  ...,  0.3169, -0.6973, -2.1328]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 12:06:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too written, it is overwritten
If something is too zealous, it is overzealous
If something is too stressed, it is overstressed
If something is too heated, it is overheated
If something is too spent, it is overspent
If something is too confident, it is overconfident
If something is too protected, it is overprotected
If something is too turned, it is
2024-07-29 12:06:39 root INFO     total operator prediction time: 1060.6701595783234 seconds
2024-07-29 12:06:39 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+er_irreg
2024-07-29 12:06:39 root INFO     building operator verb+er_irreg
2024-07-29 12:06:40 root INFO     [order_1_approx] starting weight calculation for If you borrow something, you are a borrower
If you learn something, you are a learner
If you entertain something, you are a entertainer
If you examine something, you are a examiner
If you teach something, you are a teacher
If you send something, you are a sender
If you intrude something, you are a intruder
If you lose something, you are a
2024-07-29 12:06:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 12:08:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0294, -0.1711,  0.5620,  ..., -0.1096,  0.2583, -0.1353],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0332, -1.3789, -0.4248,  ..., -0.6919, -2.4277,  0.2822],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.3691e-02, -1.4954e-02,  1.2169e-02,  ...,  8.0643e-03,
         -1.2674e-03,  1.7303e-02],
        [-6.4468e-03,  3.2166e-02,  9.4604e-03,  ...,  3.4119e-02,
          7.0763e-03,  4.9286e-03],
        [ 1.3824e-02, -3.0689e-03,  2.1210e-02,  ..., -7.1068e-03,
         -3.7146e-04,  3.1891e-03],
        ...,
        [ 1.7136e-02,  6.2523e-03, -4.7722e-03,  ...,  1.3672e-02,
          6.4087e-03, -1.6642e-03],
        [ 4.1962e-05,  1.8707e-02, -7.5569e-03,  ..., -2.3773e-02,
          3.8422e-02, -2.2476e-02],
        [-3.6163e-03, -2.3308e-03,  2.1423e-02,  ..., -1.8509e-02,
         -1.1475e-02,  1.9348e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9111, -1.2695, -0.4268,  ..., -0.3289, -2.5840, -0.0098]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 12:08:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you borrow something, you are a borrower
If you learn something, you are a learner
If you entertain something, you are a entertainer
If you examine something, you are a examiner
If you teach something, you are a teacher
If you send something, you are a sender
If you intrude something, you are a intruder
If you lose something, you are a
2024-07-29 12:08:52 root INFO     [order_1_approx] starting weight calculation for If you borrow something, you are a borrower
If you intrude something, you are a intruder
If you examine something, you are a examiner
If you teach something, you are a teacher
If you learn something, you are a learner
If you lose something, you are a loser
If you send something, you are a sender
If you entertain something, you are a
2024-07-29 12:08:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 12:11:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0477,  0.0942, -0.0321,  ..., -0.0040, -0.1803, -0.0173],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1055, -1.3896, -0.1338,  ..., -0.1602, -2.5039, -5.0000],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0701,  0.0020,  0.0089,  ...,  0.0086,  0.0013, -0.0106],
        [-0.0111,  0.0532, -0.0279,  ...,  0.0082,  0.0151, -0.0100],
        [ 0.0067, -0.0078,  0.0612,  ..., -0.0078, -0.0122, -0.0008],
        ...,
        [ 0.0098,  0.0034, -0.0009,  ...,  0.0457,  0.0075,  0.0048],
        [-0.0064,  0.0237,  0.0149,  ..., -0.0080,  0.0251, -0.0073],
        [ 0.0084,  0.0072,  0.0060,  ..., -0.0035, -0.0250,  0.0552]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5781, -1.3779, -0.3042,  ...,  0.3408, -2.4590, -5.0898]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 12:11:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you borrow something, you are a borrower
If you intrude something, you are a intruder
If you examine something, you are a examiner
If you teach something, you are a teacher
If you learn something, you are a learner
If you lose something, you are a loser
If you send something, you are a sender
If you entertain something, you are a
2024-07-29 12:11:05 root INFO     [order_1_approx] starting weight calculation for If you borrow something, you are a borrower
If you entertain something, you are a entertainer
If you examine something, you are a examiner
If you lose something, you are a loser
If you learn something, you are a learner
If you teach something, you are a teacher
If you send something, you are a sender
If you intrude something, you are a
2024-07-29 12:11:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 12:13:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2260, -0.1067, -0.0654,  ..., -0.0288,  0.1368,  0.1362],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.3516, -2.0703, -0.7754,  ..., -0.8887, -3.7871, -2.7305],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0551,  0.0121,  0.0251,  ...,  0.0100, -0.0094,  0.0238],
        [-0.0083,  0.0453,  0.0143,  ...,  0.0116,  0.0109, -0.0123],
        [ 0.0081,  0.0058,  0.0224,  ...,  0.0005,  0.0054, -0.0071],
        ...,
        [ 0.0129,  0.0207,  0.0079,  ...,  0.0599,  0.0170,  0.0107],
        [-0.0156,  0.0059,  0.0071,  ..., -0.0310,  0.0641, -0.0232],
        [ 0.0219, -0.0024,  0.0112,  ..., -0.0112, -0.0316,  0.0581]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.3594, -2.2539, -0.7021,  ..., -0.5449, -3.8984, -2.8066]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 12:13:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you borrow something, you are a borrower
If you entertain something, you are a entertainer
If you examine something, you are a examiner
If you lose something, you are a loser
If you learn something, you are a learner
If you teach something, you are a teacher
If you send something, you are a sender
If you intrude something, you are a
2024-07-29 12:13:15 root INFO     [order_1_approx] starting weight calculation for If you examine something, you are a examiner
If you entertain something, you are a entertainer
If you borrow something, you are a borrower
If you teach something, you are a teacher
If you intrude something, you are a intruder
If you send something, you are a sender
If you lose something, you are a loser
If you learn something, you are a
2024-07-29 12:13:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 12:15:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0131, -0.4341,  0.2430,  ..., -0.4316, -0.2413, -0.1345],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7754, -2.3262,  1.0557,  ...,  1.0293, -4.0195, -5.4570],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0249, -0.0012,  0.0079,  ...,  0.0003,  0.0026,  0.0128],
        [-0.0114,  0.0378,  0.0055,  ...,  0.0160,  0.0017, -0.0053],
        [ 0.0021, -0.0047,  0.0343,  ..., -0.0061,  0.0032, -0.0012],
        ...,
        [ 0.0248,  0.0071, -0.0042,  ...,  0.0306,  0.0036, -0.0017],
        [-0.0084, -0.0051,  0.0023,  ..., -0.0143,  0.0247, -0.0018],
        [-0.0048,  0.0028,  0.0147,  ..., -0.0182, -0.0054,  0.0155]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6738, -2.1582,  0.8618,  ...,  1.2236, -3.8281, -5.5391]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 12:15:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you examine something, you are a examiner
If you entertain something, you are a entertainer
If you borrow something, you are a borrower
If you teach something, you are a teacher
If you intrude something, you are a intruder
If you send something, you are a sender
If you lose something, you are a loser
If you learn something, you are a
2024-07-29 12:15:27 root INFO     [order_1_approx] starting weight calculation for If you entertain something, you are a entertainer
If you borrow something, you are a borrower
If you intrude something, you are a intruder
If you learn something, you are a learner
If you examine something, you are a examiner
If you lose something, you are a loser
If you teach something, you are a teacher
If you send something, you are a
2024-07-29 12:15:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 12:17:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0219,  0.1671,  0.5684,  ...,  0.1278,  0.3633, -0.2197],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7671, -2.3301, -2.9746,  ..., -0.3262, -1.2266, -3.0410],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.5532e-02, -1.6422e-03,  9.4757e-03,  ..., -1.9550e-03,
          1.8295e-02, -7.4387e-05],
        [-3.0518e-05,  4.1199e-02, -2.1896e-03,  ...,  9.0179e-03,
         -6.6986e-03, -2.6810e-02],
        [ 1.7334e-02,  4.0779e-03,  2.7939e-02,  ..., -1.3290e-02,
         -8.2397e-03,  1.2680e-02],
        ...,
        [ 1.0857e-02,  5.9319e-03, -1.5297e-03,  ...,  5.3711e-02,
          5.0850e-03,  1.0857e-02],
        [-1.5900e-02,  5.7335e-03, -9.4986e-03,  ..., -1.8906e-02,
          4.1199e-02, -1.8402e-02],
        [-3.1757e-04, -1.1826e-03,  5.2299e-03,  ..., -1.0300e-02,
         -1.5068e-02,  3.3630e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1504, -2.5684, -2.8613,  ..., -0.1300, -1.3115, -3.0156]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 12:17:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you entertain something, you are a entertainer
If you borrow something, you are a borrower
If you intrude something, you are a intruder
If you learn something, you are a learner
If you examine something, you are a examiner
If you lose something, you are a loser
If you teach something, you are a teacher
If you send something, you are a
2024-07-29 12:17:37 root INFO     [order_1_approx] starting weight calculation for If you learn something, you are a learner
If you borrow something, you are a borrower
If you entertain something, you are a entertainer
If you teach something, you are a teacher
If you send something, you are a sender
If you intrude something, you are a intruder
If you lose something, you are a loser
If you examine something, you are a
2024-07-29 12:17:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 12:19:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0729, -0.1992,  0.0290,  ..., -0.2622,  0.0925, -0.1736],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9238, -1.7646,  0.3984,  ..., -2.9609, -2.3242, -5.0117],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0754, -0.0089,  0.0137,  ...,  0.0142, -0.0127,  0.0092],
        [-0.0046,  0.0689,  0.0006,  ...,  0.0114,  0.0066, -0.0113],
        [ 0.0053,  0.0054,  0.0617,  ..., -0.0074,  0.0119, -0.0065],
        ...,
        [ 0.0168,  0.0057,  0.0103,  ...,  0.0741, -0.0031, -0.0009],
        [-0.0032, -0.0007, -0.0103,  ..., -0.0038,  0.0537, -0.0078],
        [ 0.0094,  0.0009,  0.0104,  ..., -0.0013, -0.0213,  0.0522]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0703, -1.9326,  0.1771,  ..., -2.5488, -2.3535, -4.7227]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 12:19:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you learn something, you are a learner
If you borrow something, you are a borrower
If you entertain something, you are a entertainer
If you teach something, you are a teacher
If you send something, you are a sender
If you intrude something, you are a intruder
If you lose something, you are a loser
If you examine something, you are a
2024-07-29 12:19:48 root INFO     [order_1_approx] starting weight calculation for If you examine something, you are a examiner
If you send something, you are a sender
If you learn something, you are a learner
If you intrude something, you are a intruder
If you entertain something, you are a entertainer
If you borrow something, you are a borrower
If you lose something, you are a loser
If you teach something, you are a
2024-07-29 12:19:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 12:21:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0266,  0.1985,  0.4077,  ..., -0.2922,  0.0156,  0.1163],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0371, -3.0977,  3.0488,  ...,  2.3438, -4.1836, -5.6289],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.8717e-02,  2.9888e-03,  1.8539e-02,  ..., -2.4967e-03,
          2.5177e-03, -2.4147e-03],
        [-1.2993e-02,  3.9581e-02, -3.8700e-03,  ...,  2.4704e-02,
          2.4090e-03, -1.1215e-02],
        [ 3.0785e-03,  1.0330e-02,  3.7354e-02,  ...,  3.7422e-03,
         -3.8300e-03,  5.0163e-04],
        ...,
        [ 1.3794e-02,  9.4604e-03, -3.5286e-03,  ...,  3.1189e-02,
          1.0040e-02, -1.1261e-02],
        [ 1.1444e-05, -1.6794e-03, -7.9498e-03,  ..., -1.3092e-02,
          2.2903e-02, -1.8864e-03],
        [ 1.6212e-04,  1.0080e-03,  1.6983e-02,  ..., -6.5384e-03,
          3.0632e-03,  1.5762e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2598, -2.9609,  3.0898,  ...,  2.4902, -4.2305, -5.5273]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 12:22:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you examine something, you are a examiner
If you send something, you are a sender
If you learn something, you are a learner
If you intrude something, you are a intruder
If you entertain something, you are a entertainer
If you borrow something, you are a borrower
If you lose something, you are a loser
If you teach something, you are a
2024-07-29 12:22:04 root INFO     [order_1_approx] starting weight calculation for If you learn something, you are a learner
If you entertain something, you are a entertainer
If you examine something, you are a examiner
If you teach something, you are a teacher
If you intrude something, you are a intruder
If you send something, you are a sender
If you lose something, you are a loser
If you borrow something, you are a
2024-07-29 12:22:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 12:24:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3662,  0.1906,  0.0787,  ..., -0.4282,  0.3101,  0.0375],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4102, -2.6562, -0.3916,  ..., -2.0977, -1.7695, -3.8633],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0712, -0.0068, -0.0008,  ...,  0.0042,  0.0085,  0.0232],
        [-0.0144,  0.0609,  0.0079,  ...,  0.0223,  0.0016, -0.0143],
        [ 0.0092, -0.0011,  0.0435,  ..., -0.0004,  0.0081,  0.0053],
        ...,
        [ 0.0235, -0.0033,  0.0045,  ...,  0.0798,  0.0196, -0.0049],
        [-0.0080,  0.0182, -0.0103,  ..., -0.0131,  0.0503, -0.0303],
        [-0.0093,  0.0065,  0.0008,  ..., -0.0311,  0.0030,  0.0461]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4395, -2.5996, -0.8633,  ..., -2.0469, -1.4648, -4.0703]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 12:24:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you learn something, you are a learner
If you entertain something, you are a entertainer
If you examine something, you are a examiner
If you teach something, you are a teacher
If you intrude something, you are a intruder
If you send something, you are a sender
If you lose something, you are a loser
If you borrow something, you are a
2024-07-29 12:24:16 root INFO     total operator prediction time: 1056.7354848384857 seconds
2024-07-29 12:24:16 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj - superlative
2024-07-29 12:24:16 root INFO     building operator adj - superlative
2024-07-29 12:24:16 root INFO     [order_1_approx] starting weight calculation for If something is the most handy, it is handiest
If something is the most neat, it is neatest
If something is the most angry, it is angriest
If something is the most happy, it is happiest
If something is the most weird, it is weirdest
If something is the most sad, it is saddest
If something is the most hardy, it is hardiest
If something is the most lucky, it is
2024-07-29 12:24:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 12:26:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1938,  0.4756, -0.1667,  ..., -0.2991, -0.1376,  0.2289],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2070, -3.5859, -3.1328,  ..., -0.3745, -0.3086, -1.6982],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0359,  0.0002,  0.0213,  ...,  0.0074, -0.0018,  0.0074],
        [-0.0054,  0.0396,  0.0034,  ...,  0.0044, -0.0012,  0.0001],
        [ 0.0122,  0.0043,  0.0232,  ..., -0.0088, -0.0092, -0.0063],
        ...,
        [ 0.0108,  0.0120, -0.0018,  ...,  0.0435,  0.0041,  0.0078],
        [ 0.0059, -0.0089, -0.0027,  ..., -0.0154,  0.0204, -0.0239],
        [ 0.0070, -0.0142, -0.0025,  ..., -0.0070, -0.0091,  0.0294]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0365, -3.8066, -3.1211,  ..., -0.4307, -0.2737, -1.8555]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 12:26:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most handy, it is handiest
If something is the most neat, it is neatest
If something is the most angry, it is angriest
If something is the most happy, it is happiest
If something is the most weird, it is weirdest
If something is the most sad, it is saddest
If something is the most hardy, it is hardiest
If something is the most lucky, it is
2024-07-29 12:26:29 root INFO     [order_1_approx] starting weight calculation for If something is the most weird, it is weirdest
If something is the most angry, it is angriest
If something is the most handy, it is handiest
If something is the most lucky, it is luckiest
If something is the most hardy, it is hardiest
If something is the most sad, it is saddest
If something is the most happy, it is happiest
If something is the most neat, it is
2024-07-29 12:26:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 12:28:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0748, -0.3486, -0.2255,  ..., -0.0175, -0.1992,  0.4885],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3921, -1.4590, -2.3906,  ..., -1.9863, -2.1875, -3.6543],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0441,  0.0088,  0.0016,  ...,  0.0123,  0.0030,  0.0213],
        [-0.0034,  0.0631,  0.0113,  ...,  0.0068,  0.0086, -0.0085],
        [ 0.0178, -0.0145,  0.0453,  ..., -0.0052, -0.0173, -0.0050],
        ...,
        [-0.0031,  0.0288,  0.0036,  ...,  0.0521,  0.0229, -0.0205],
        [ 0.0039, -0.0172,  0.0032,  ...,  0.0062,  0.0192, -0.0192],
        [ 0.0016, -0.0162,  0.0093,  ..., -0.0039, -0.0058,  0.0484]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7881, -1.4414, -2.6230,  ..., -1.8262, -1.5010, -3.6621]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 12:28:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most weird, it is weirdest
If something is the most angry, it is angriest
If something is the most handy, it is handiest
If something is the most lucky, it is luckiest
If something is the most hardy, it is hardiest
If something is the most sad, it is saddest
If something is the most happy, it is happiest
If something is the most neat, it is
2024-07-29 12:28:41 root INFO     [order_1_approx] starting weight calculation for If something is the most weird, it is weirdest
If something is the most angry, it is angriest
If something is the most neat, it is neatest
If something is the most sad, it is saddest
If something is the most happy, it is happiest
If something is the most lucky, it is luckiest
If something is the most handy, it is handiest
If something is the most hardy, it is
2024-07-29 12:28:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 12:30:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1385,  0.1215, -0.3662,  ..., -0.7437,  0.0154,  0.2783],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7441, -7.3242, -0.8662,  ..., -2.7402, -3.0605, -2.2520],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0690, -0.0214,  0.0255,  ...,  0.0158, -0.0134, -0.0099],
        [ 0.0023,  0.0518, -0.0079,  ..., -0.0065,  0.0222,  0.0088],
        [-0.0061, -0.0041,  0.0826,  ..., -0.0040, -0.0093,  0.0003],
        ...,
        [ 0.0024,  0.0252, -0.0027,  ...,  0.0878,  0.0253,  0.0123],
        [ 0.0061, -0.0294,  0.0054,  ..., -0.0347,  0.0682, -0.0404],
        [ 0.0022, -0.0087, -0.0123,  ..., -0.0219,  0.0093,  0.0594]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6426, -7.3789, -1.1992,  ..., -2.3262, -2.9961, -1.9990]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 12:30:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most weird, it is weirdest
If something is the most angry, it is angriest
If something is the most neat, it is neatest
If something is the most sad, it is saddest
If something is the most happy, it is happiest
If something is the most lucky, it is luckiest
If something is the most handy, it is handiest
If something is the most hardy, it is
2024-07-29 12:30:50 root INFO     [order_1_approx] starting weight calculation for If something is the most handy, it is handiest
If something is the most angry, it is angriest
If something is the most lucky, it is luckiest
If something is the most weird, it is weirdest
If something is the most neat, it is neatest
If something is the most hardy, it is hardiest
If something is the most happy, it is happiest
If something is the most sad, it is
2024-07-29 12:30:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 12:33:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1572,  0.1051, -0.2241,  ..., -0.0893, -0.4011,  0.1647],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3828, -5.6016, -2.6309,  ..., -5.2188,  0.5977, -2.6484],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.2603e-02, -1.0178e-02,  5.0545e-05,  ..., -1.4755e-02,
         -2.2125e-04,  2.3651e-04],
        [ 1.5640e-02,  1.7349e-02,  8.3618e-03,  ..., -1.7223e-03,
          1.8356e-02,  3.5744e-03],
        [ 5.4169e-03, -7.6523e-03,  1.6876e-02,  ...,  2.0027e-03,
         -1.0239e-02, -8.3923e-03],
        ...,
        [ 8.7662e-03,  2.5101e-02,  4.4441e-03,  ...,  2.8351e-02,
         -6.6452e-03,  1.6800e-02],
        [-1.1787e-02, -1.2001e-02,  1.7204e-03,  ...,  7.3586e-03,
          2.6550e-02, -2.8992e-02],
        [ 2.7981e-03,  1.1047e-02, -8.4457e-03,  ..., -2.2842e-02,
          2.7046e-03,  2.5558e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2668, -5.4062, -2.5664,  ..., -5.1523,  0.5439, -2.7500]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 12:33:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most handy, it is handiest
If something is the most angry, it is angriest
If something is the most lucky, it is luckiest
If something is the most weird, it is weirdest
If something is the most neat, it is neatest
If something is the most hardy, it is hardiest
If something is the most happy, it is happiest
If something is the most sad, it is
2024-07-29 12:33:02 root INFO     [order_1_approx] starting weight calculation for If something is the most happy, it is happiest
If something is the most sad, it is saddest
If something is the most handy, it is handiest
If something is the most hardy, it is hardiest
If something is the most angry, it is angriest
If something is the most lucky, it is luckiest
If something is the most neat, it is neatest
If something is the most weird, it is
2024-07-29 12:33:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 12:35:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0336,  0.1177,  0.3503,  ..., -0.2124, -0.1693,  0.5215],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8848, -4.8477, -1.4453,  ..., -1.8857, -1.2207, -2.9473],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0417, -0.0032,  0.0134,  ...,  0.0005, -0.0010, -0.0002],
        [ 0.0062,  0.0350, -0.0059,  ...,  0.0099,  0.0046,  0.0020],
        [ 0.0093, -0.0125,  0.0478,  ...,  0.0020, -0.0018,  0.0080],
        ...,
        [ 0.0303,  0.0393, -0.0116,  ...,  0.0466, -0.0020,  0.0002],
        [ 0.0131,  0.0019,  0.0038,  ..., -0.0192,  0.0255, -0.0232],
        [ 0.0038, -0.0078,  0.0110,  ..., -0.0068, -0.0177,  0.0233]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2568, -4.8906, -2.0664,  ..., -2.0645, -1.3848, -3.0059]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 12:35:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most happy, it is happiest
If something is the most sad, it is saddest
If something is the most handy, it is handiest
If something is the most hardy, it is hardiest
If something is the most angry, it is angriest
If something is the most lucky, it is luckiest
If something is the most neat, it is neatest
If something is the most weird, it is
2024-07-29 12:35:14 root INFO     [order_1_approx] starting weight calculation for If something is the most sad, it is saddest
If something is the most weird, it is weirdest
If something is the most lucky, it is luckiest
If something is the most hardy, it is hardiest
If something is the most angry, it is angriest
If something is the most happy, it is happiest
If something is the most neat, it is neatest
If something is the most handy, it is
2024-07-29 12:35:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 12:37:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0115,  0.4683,  0.1146,  ..., -0.8242, -0.3938,  0.1664],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4556, -4.6914, -1.2695,  ..., -1.1777, -4.7930, -0.7300],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0515, -0.0074,  0.0206,  ...,  0.0028, -0.0115,  0.0108],
        [ 0.0024,  0.0527,  0.0170,  ...,  0.0088,  0.0088,  0.0007],
        [ 0.0135,  0.0016,  0.0384,  ..., -0.0030, -0.0037, -0.0109],
        ...,
        [ 0.0059,  0.0290, -0.0157,  ...,  0.0645,  0.0092, -0.0020],
        [ 0.0253,  0.0041, -0.0006,  ..., -0.0142,  0.0595, -0.0266],
        [ 0.0085, -0.0055, -0.0028,  ..., -0.0163, -0.0130,  0.0377]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0417, -4.4062, -1.4414,  ..., -0.7490, -4.4336, -0.5605]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 12:37:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most sad, it is saddest
If something is the most weird, it is weirdest
If something is the most lucky, it is luckiest
If something is the most hardy, it is hardiest
If something is the most angry, it is angriest
If something is the most happy, it is happiest
If something is the most neat, it is neatest
If something is the most handy, it is
2024-07-29 12:37:24 root INFO     [order_1_approx] starting weight calculation for If something is the most happy, it is happiest
If something is the most handy, it is handiest
If something is the most hardy, it is hardiest
If something is the most weird, it is weirdest
If something is the most lucky, it is luckiest
If something is the most neat, it is neatest
If something is the most sad, it is saddest
If something is the most angry, it is
2024-07-29 12:37:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 12:39:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2075,  0.1653, -0.4104,  ..., -0.0907, -0.3301, -0.0225],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.0273, -6.5234, -2.2305,  ..., -2.7266, -1.2715, -1.5840],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.0598e-02,  4.1962e-03,  6.7520e-04,  ..., -4.5319e-03,
         -7.4768e-04,  1.2070e-02],
        [ 8.0261e-03,  2.9556e-02,  1.1223e-02,  ...,  5.0278e-03,
          2.2522e-02, -2.4834e-03],
        [ 1.3107e-02, -1.0681e-04,  3.6804e-02,  ..., -9.7885e-03,
          9.5139e-03, -1.1574e-02],
        ...,
        [ 1.3588e-02,  1.6418e-02,  4.1199e-04,  ...,  4.1260e-02,
          6.4163e-03, -8.1348e-04],
        [-1.0996e-03, -3.9978e-03, -1.0223e-03,  ..., -5.0812e-03,
          4.6600e-02, -2.2583e-02],
        [ 2.2888e-05, -8.1024e-03,  3.2196e-03,  ..., -1.5762e-02,
         -1.4320e-02,  2.7756e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.0918, -6.2070, -2.2852,  ..., -2.5371, -1.2139, -1.9609]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 12:39:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most happy, it is happiest
If something is the most handy, it is handiest
If something is the most hardy, it is hardiest
If something is the most weird, it is weirdest
If something is the most lucky, it is luckiest
If something is the most neat, it is neatest
If something is the most sad, it is saddest
If something is the most angry, it is
2024-07-29 12:39:35 root INFO     [order_1_approx] starting weight calculation for If something is the most neat, it is neatest
If something is the most lucky, it is luckiest
If something is the most angry, it is angriest
If something is the most weird, it is weirdest
If something is the most sad, it is saddest
If something is the most handy, it is handiest
If something is the most hardy, it is hardiest
If something is the most happy, it is
2024-07-29 12:39:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 12:41:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0894, -0.4641, -0.3938,  ..., -0.2905, -0.2573, -0.1798],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6836, -4.1445,  0.0928,  ...,  0.3311, -1.5039, -1.0586],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0559, -0.0050,  0.0092,  ...,  0.0068,  0.0078,  0.0238],
        [-0.0036,  0.0223, -0.0028,  ...,  0.0012,  0.0112,  0.0041],
        [ 0.0106,  0.0087,  0.0421,  ...,  0.0042, -0.0170, -0.0057],
        ...,
        [ 0.0140,  0.0198, -0.0040,  ...,  0.0612,  0.0192, -0.0019],
        [-0.0086, -0.0103,  0.0025,  ..., -0.0139,  0.0312, -0.0257],
        [ 0.0046, -0.0071,  0.0022,  ...,  0.0030,  0.0003,  0.0378]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2837, -4.2227, -0.2012,  ...,  0.5225, -1.5693, -1.0967]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 12:41:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most neat, it is neatest
If something is the most lucky, it is luckiest
If something is the most angry, it is angriest
If something is the most weird, it is weirdest
If something is the most sad, it is saddest
If something is the most handy, it is handiest
If something is the most hardy, it is hardiest
If something is the most happy, it is
2024-07-29 12:41:47 root INFO     total operator prediction time: 1050.8042078018188 seconds
2024-07-29 12:41:47 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_3pSg - Ved
2024-07-29 12:41:47 root INFO     building operator verb_3pSg - Ved
2024-07-29 12:41:47 root INFO     [order_1_approx] starting weight calculation for When he involves something, something has been involved
When he receives something, something has been received
When he requires something, something has been required
When he allows something, something has been allowed
When he occurs something, something has been occurred
When he tells something, something has been told
When he provides something, something has been provided
When he proposes something, something has been
2024-07-29 12:41:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 12:43:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([0.1699, 0.0161, 0.2069,  ..., 0.0985, 0.1003, 0.4358], device='cuda:1',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5312, -1.6367,  1.8730,  ...,  0.1689, -2.1055,  0.1016],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0279, -0.0087,  0.0068,  ..., -0.0094, -0.0061,  0.0027],
        [-0.0097,  0.0082,  0.0121,  ...,  0.0148, -0.0035,  0.0086],
        [ 0.0030, -0.0087,  0.0037,  ..., -0.0167,  0.0023, -0.0139],
        ...,
        [-0.0011,  0.0018,  0.0004,  ...,  0.0224,  0.0046,  0.0098],
        [ 0.0045,  0.0026,  0.0043,  ...,  0.0001,  0.0203, -0.0338],
        [ 0.0016,  0.0124,  0.0029,  ...,  0.0050, -0.0073,  0.0054]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4746, -1.7588,  1.9043,  ..., -0.0781, -1.9053, -0.0455]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 12:43:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he involves something, something has been involved
When he receives something, something has been received
When he requires something, something has been required
When he allows something, something has been allowed
When he occurs something, something has been occurred
When he tells something, something has been told
When he provides something, something has been provided
When he proposes something, something has been
2024-07-29 12:43:59 root INFO     [order_1_approx] starting weight calculation for When he involves something, something has been involved
When he provides something, something has been provided
When he allows something, something has been allowed
When he requires something, something has been required
When he proposes something, something has been proposed
When he occurs something, something has been occurred
When he tells something, something has been told
When he receives something, something has been
2024-07-29 12:43:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 12:46:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0533,  0.3262, -0.0220,  ..., -0.3311,  0.1213, -0.1218],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5996,  0.4150, -0.7705,  ..., -1.3936, -3.1465, -2.3457],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0532, -0.0080,  0.0211,  ..., -0.0190, -0.0093,  0.0378],
        [-0.0166,  0.0182,  0.0070,  ...,  0.0149,  0.0177, -0.0063],
        [ 0.0083, -0.0036,  0.0116,  ..., -0.0152,  0.0070, -0.0174],
        ...,
        [ 0.0038,  0.0061,  0.0197,  ...,  0.0455,  0.0045,  0.0089],
        [ 0.0094,  0.0031,  0.0016,  ..., -0.0058,  0.0352, -0.0268],
        [-0.0069, -0.0169,  0.0121,  ..., -0.0040,  0.0098,  0.0257]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1680,  0.4756, -0.8628,  ..., -1.2314, -3.0996, -2.0352]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 12:46:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he involves something, something has been involved
When he provides something, something has been provided
When he allows something, something has been allowed
When he requires something, something has been required
When he proposes something, something has been proposed
When he occurs something, something has been occurred
When he tells something, something has been told
When he receives something, something has been
2024-07-29 12:46:09 root INFO     [order_1_approx] starting weight calculation for When he tells something, something has been told
When he provides something, something has been provided
When he receives something, something has been received
When he involves something, something has been involved
When he allows something, something has been allowed
When he occurs something, something has been occurred
When he proposes something, something has been proposed
When he requires something, something has been
2024-07-29 12:46:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 12:48:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3550, -0.0475,  0.0104,  ...,  0.0855,  0.0462, -0.2849],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5332,  1.6602,  1.3809,  ..., -1.1992, -3.0176, -1.7539],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.3752e-02, -9.1476e-03,  2.3834e-02,  ..., -1.3184e-02,
         -3.6125e-03,  7.3204e-03],
        [-1.1780e-02,  2.8427e-02, -3.0785e-03,  ...,  1.7920e-03,
          1.1452e-02,  1.0574e-02],
        [ 6.1531e-03, -1.1871e-02,  1.9806e-02,  ..., -2.0615e-02,
          6.3171e-03, -7.0152e-03],
        ...,
        [-4.0741e-03,  6.6795e-03,  1.0323e-02,  ...,  3.5400e-02,
         -1.2646e-03,  2.0676e-02],
        [ 1.6670e-03,  9.5367e-05, -1.9798e-03,  ...,  2.9373e-04,
          4.1901e-02, -4.0344e-02],
        [-2.3392e-02, -1.7080e-03,  1.7029e-02,  ...,  5.0354e-03,
          1.3840e-02,  1.8982e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4492,  1.2852,  1.3623,  ..., -1.2646, -2.7930, -1.4922]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 12:48:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he tells something, something has been told
When he provides something, something has been provided
When he receives something, something has been received
When he involves something, something has been involved
When he allows something, something has been allowed
When he occurs something, something has been occurred
When he proposes something, something has been proposed
When he requires something, something has been
2024-07-29 12:48:22 root INFO     [order_1_approx] starting weight calculation for When he provides something, something has been provided
When he allows something, something has been allowed
When he occurs something, something has been occurred
When he proposes something, something has been proposed
When he requires something, something has been required
When he tells something, something has been told
When he receives something, something has been received
When he involves something, something has been
2024-07-29 12:48:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 12:50:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1711, -0.2378, -0.1075,  ...,  0.1595, -0.1453, -0.1547],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2988,  1.1494,  2.4844,  ...,  1.0742,  0.6670, -3.9062],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0617,  0.0029,  0.0364,  ..., -0.0041, -0.0155,  0.0276],
        [-0.0355,  0.0317,  0.0091,  ...,  0.0319,  0.0258, -0.0075],
        [ 0.0074, -0.0278,  0.0230,  ..., -0.0213,  0.0007, -0.0234],
        ...,
        [ 0.0090,  0.0098, -0.0158,  ...,  0.0626,  0.0020,  0.0284],
        [ 0.0092,  0.0122, -0.0058,  ...,  0.0012,  0.0524, -0.0390],
        [-0.0163,  0.0219,  0.0234,  ..., -0.0079, -0.0249,  0.0504]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9287,  1.5879,  2.2344,  ...,  0.7568,  0.3713, -3.4922]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 12:50:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he provides something, something has been provided
When he allows something, something has been allowed
When he occurs something, something has been occurred
When he proposes something, something has been proposed
When he requires something, something has been required
When he tells something, something has been told
When he receives something, something has been received
When he involves something, something has been
2024-07-29 12:50:35 root INFO     [order_1_approx] starting weight calculation for When he occurs something, something has been occurred
When he requires something, something has been required
When he involves something, something has been involved
When he allows something, something has been allowed
When he provides something, something has been provided
When he receives something, something has been received
When he proposes something, something has been proposed
When he tells something, something has been
2024-07-29 12:50:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 12:52:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0954, -0.0293,  0.5884,  ...,  0.2029,  0.0698, -0.0759],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7812,  1.3135,  3.0527,  ...,  3.4258, -5.5781, -1.8105],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0337, -0.0048,  0.0045,  ..., -0.0022, -0.0054,  0.0182],
        [-0.0279,  0.0277,  0.0029,  ...,  0.0136, -0.0085, -0.0020],
        [ 0.0031, -0.0181,  0.0198,  ..., -0.0102,  0.0021, -0.0161],
        ...,
        [-0.0096,  0.0097, -0.0026,  ...,  0.0257,  0.0029,  0.0061],
        [ 0.0005, -0.0043,  0.0041,  ..., -0.0067,  0.0520, -0.0125],
        [-0.0061, -0.0045,  0.0282,  ..., -0.0087,  0.0043,  0.0188]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6641,  1.3525,  2.9258,  ...,  3.1875, -5.3828, -1.6318]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 12:52:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he occurs something, something has been occurred
When he requires something, something has been required
When he involves something, something has been involved
When he allows something, something has been allowed
When he provides something, something has been provided
When he receives something, something has been received
When he proposes something, something has been proposed
When he tells something, something has been
2024-07-29 12:52:49 root INFO     [order_1_approx] starting weight calculation for When he receives something, something has been received
When he allows something, something has been allowed
When he tells something, something has been told
When he involves something, something has been involved
When he requires something, something has been required
When he proposes something, something has been proposed
When he occurs something, something has been occurred
When he provides something, something has been
2024-07-29 12:52:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 12:55:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0017, -0.2427, -0.0536,  ...,  0.0792,  0.1660, -0.1876],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5801, -2.6289,  1.8193,  ..., -0.8433, -3.2656, -0.3926],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0696,  0.0059,  0.0250,  ...,  0.0024, -0.0026,  0.0266],
        [-0.0334,  0.0371,  0.0239,  ...,  0.0210,  0.0073,  0.0125],
        [ 0.0043, -0.0302,  0.0344,  ..., -0.0126, -0.0045, -0.0084],
        ...,
        [-0.0025,  0.0040, -0.0057,  ...,  0.0652,  0.0019,  0.0166],
        [ 0.0242, -0.0098, -0.0102,  ..., -0.0150,  0.0386, -0.0394],
        [-0.0005,  0.0225, -0.0068,  ..., -0.0205, -0.0109,  0.0498]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5703, -1.9688,  2.0508,  ..., -0.7056, -3.0195, -0.4944]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 12:55:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he receives something, something has been received
When he allows something, something has been allowed
When he tells something, something has been told
When he involves something, something has been involved
When he requires something, something has been required
When he proposes something, something has been proposed
When he occurs something, something has been occurred
When he provides something, something has been
2024-07-29 12:55:08 root INFO     [order_1_approx] starting weight calculation for When he proposes something, something has been proposed
When he involves something, something has been involved
When he receives something, something has been received
When he occurs something, something has been occurred
When he tells something, something has been told
When he provides something, something has been provided
When he requires something, something has been required
When he allows something, something has been
2024-07-29 12:55:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 12:57:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3838,  0.4106,  0.1259,  ..., -0.1194,  0.0712, -0.1870],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.2188, -2.6855,  0.8062,  ...,  1.0000, -3.1953, -0.0234],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.0964e-02, -9.4795e-04,  1.5762e-02,  ..., -1.0277e-02,
          2.8877e-03,  1.3084e-02],
        [-5.8289e-03,  3.0975e-02, -3.1681e-03,  ...,  2.4338e-02,
          1.2787e-02, -3.6201e-03],
        [-1.1169e-02, -1.7319e-02,  2.8915e-02,  ..., -2.6001e-02,
          7.2327e-03, -1.6235e-02],
        ...,
        [-8.0109e-05,  1.7960e-02, -1.1749e-02,  ...,  3.7018e-02,
          2.1088e-02,  1.4015e-02],
        [ 6.3515e-03,  8.1482e-03, -2.3079e-03,  ..., -7.8201e-04,
          3.2654e-02, -3.0884e-02],
        [-1.1383e-02, -1.0689e-02,  1.1269e-02,  ...,  5.9433e-03,
         -9.4299e-03,  2.6276e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8984, -2.4414,  0.6421,  ...,  1.1289, -3.1172,  0.2103]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 12:57:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he proposes something, something has been proposed
When he involves something, something has been involved
When he receives something, something has been received
When he occurs something, something has been occurred
When he tells something, something has been told
When he provides something, something has been provided
When he requires something, something has been required
When he allows something, something has been
2024-07-29 12:57:20 root INFO     [order_1_approx] starting weight calculation for When he tells something, something has been told
When he involves something, something has been involved
When he allows something, something has been allowed
When he receives something, something has been received
When he requires something, something has been required
When he provides something, something has been provided
When he proposes something, something has been proposed
When he occurs something, something has been
2024-07-29 12:57:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 12:59:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3364,  0.0149, -0.3647,  ..., -0.0282,  0.2412, -0.7529],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4482,  1.8613,  2.4766,  ..., -0.6147, -1.5000,  1.1387],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0365, -0.0050,  0.0237,  ...,  0.0117, -0.0077,  0.0347],
        [-0.0258,  0.0293,  0.0180,  ...,  0.0130,  0.0058, -0.0156],
        [-0.0066,  0.0055,  0.0201,  ..., -0.0335,  0.0173, -0.0198],
        ...,
        [ 0.0109,  0.0144, -0.0045,  ...,  0.0510,  0.0021,  0.0103],
        [ 0.0172,  0.0023,  0.0004,  ..., -0.0153,  0.0474, -0.0261],
        [ 0.0008, -0.0026,  0.0156,  ..., -0.0170, -0.0101,  0.0480]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0410,  1.7383,  2.9375,  ..., -0.3403, -1.4365,  1.1914]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 12:59:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he tells something, something has been told
When he involves something, something has been involved
When he allows something, something has been allowed
When he receives something, something has been received
When he requires something, something has been required
When he provides something, something has been provided
When he proposes something, something has been proposed
When he occurs something, something has been
2024-07-29 12:59:33 root INFO     total operator prediction time: 1065.7660360336304 seconds
2024-07-29 12:59:33 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun - plural_reg
2024-07-29 12:59:33 root INFO     building operator noun - plural_reg
2024-07-29 12:59:33 root INFO     [order_1_approx] starting weight calculation for The plural form of resource is resources
The plural form of player is players
The plural form of day is days
The plural form of idea is ideas
The plural form of god is gods
The plural form of hour is hours
The plural form of website is websites
The plural form of student is
2024-07-29 12:59:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 13:01:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0033,  0.2113, -0.3789,  ..., -0.0380, -0.3525, -0.2063],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8320, -1.5811,  2.5762,  ..., -0.1306,  0.3555, -1.3057],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.8940e-02,  1.6266e-02, -7.7057e-04,  ...,  1.1391e-02,
         -9.9792e-03,  8.9722e-03],
        [-6.1684e-03,  5.7648e-02, -4.7379e-03,  ...,  4.2572e-03,
          1.6647e-02,  4.7150e-03],
        [-1.7557e-03, -4.7684e-05,  4.9591e-02,  ..., -6.0806e-03,
         -1.7376e-03,  8.1329e-03],
        ...,
        [ 3.1834e-03,  9.0866e-03, -3.6163e-03,  ...,  3.9917e-02,
          3.8147e-04,  2.5806e-03],
        [-1.1993e-02,  1.7670e-02, -2.5940e-04,  ..., -2.6230e-02,
          2.7481e-02, -1.7044e-02],
        [-5.3558e-03,  9.0485e-03, -1.8936e-02,  ...,  3.5858e-03,
         -1.6937e-02,  4.6448e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0703, -1.7139,  2.5332,  ..., -0.5977,  0.4165, -0.9297]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 13:01:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of resource is resources
The plural form of player is players
The plural form of day is days
The plural form of idea is ideas
The plural form of god is gods
The plural form of hour is hours
The plural form of website is websites
The plural form of student is
2024-07-29 13:01:46 root INFO     [order_1_approx] starting weight calculation for The plural form of student is students
The plural form of hour is hours
The plural form of god is gods
The plural form of resource is resources
The plural form of day is days
The plural form of website is websites
The plural form of player is players
The plural form of idea is
2024-07-29 13:01:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 13:03:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1110,  0.0450,  0.2173,  ..., -0.3875, -0.0823, -0.2002],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1973, -2.6602,  2.5605,  ..., -0.8477, -0.9683, -1.8926],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0705, -0.0065, -0.0038,  ...,  0.0035, -0.0018,  0.0244],
        [ 0.0005,  0.0343,  0.0330,  ...,  0.0137, -0.0090,  0.0023],
        [-0.0012, -0.0037,  0.0611,  ..., -0.0196,  0.0104,  0.0081],
        ...,
        [-0.0056,  0.0067,  0.0082,  ...,  0.0370,  0.0071, -0.0047],
        [-0.0078,  0.0063,  0.0039,  ..., -0.0027,  0.0532, -0.0169],
        [ 0.0174,  0.0048,  0.0004,  ..., -0.0140, -0.0156,  0.0586]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9189, -3.1602,  2.4883,  ..., -0.3655, -0.7222, -1.7363]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 13:04:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of student is students
The plural form of hour is hours
The plural form of god is gods
The plural form of resource is resources
The plural form of day is days
The plural form of website is websites
The plural form of player is players
The plural form of idea is
2024-07-29 13:04:07 root INFO     [order_1_approx] starting weight calculation for The plural form of god is gods
The plural form of day is days
The plural form of hour is hours
The plural form of student is students
The plural form of resource is resources
The plural form of website is websites
The plural form of idea is ideas
The plural form of player is
2024-07-29 13:04:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 13:06:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2344,  0.1965,  0.1667,  ..., -0.0160, -0.3665, -0.2903],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6680, -5.3242,  0.4429,  ..., -0.4673, -1.9600, -1.8457],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0783, -0.0183,  0.0139,  ..., -0.0094,  0.0267, -0.0063],
        [ 0.0002,  0.0786, -0.0085,  ..., -0.0038,  0.0291,  0.0050],
        [-0.0011, -0.0044,  0.0673,  ..., -0.0212, -0.0082, -0.0090],
        ...,
        [ 0.0117,  0.0124,  0.0067,  ...,  0.0565,  0.0183,  0.0058],
        [-0.0223,  0.0068, -0.0114,  ..., -0.0117,  0.0620, -0.0159],
        [ 0.0029,  0.0137, -0.0267,  ..., -0.0070,  0.0170,  0.0457]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8662, -4.8516,  0.4919,  ..., -0.3096, -1.6182, -1.2383]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 13:06:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of god is gods
The plural form of day is days
The plural form of hour is hours
The plural form of student is students
The plural form of resource is resources
The plural form of website is websites
The plural form of idea is ideas
The plural form of player is
2024-07-29 13:06:20 root INFO     [order_1_approx] starting weight calculation for The plural form of idea is ideas
The plural form of hour is hours
The plural form of god is gods
The plural form of player is players
The plural form of website is websites
The plural form of student is students
The plural form of resource is resources
The plural form of day is
2024-07-29 13:06:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 13:08:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3750, -0.1787, -0.1509,  ..., -0.0387, -0.6123, -0.1075],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4934, -4.4062,  2.2598,  ..., -1.4346, -0.4160, -3.1797],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0641,  0.0054,  0.0086,  ...,  0.0028,  0.0052,  0.0070],
        [ 0.0291,  0.0478,  0.0125,  ...,  0.0197, -0.0032,  0.0078],
        [ 0.0025, -0.0047,  0.0398,  ...,  0.0121, -0.0110,  0.0071],
        ...,
        [-0.0056,  0.0090, -0.0099,  ...,  0.0664, -0.0161,  0.0110],
        [-0.0372,  0.0104, -0.0138,  ...,  0.0125,  0.0709, -0.0031],
        [-0.0066,  0.0062, -0.0057,  ..., -0.0276, -0.0152,  0.0601]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0625, -4.2539,  1.8350,  ..., -1.0703, -0.8457, -2.2324]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 13:08:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of idea is ideas
The plural form of hour is hours
The plural form of god is gods
The plural form of player is players
The plural form of website is websites
The plural form of student is students
The plural form of resource is resources
The plural form of day is
2024-07-29 13:08:33 root INFO     [order_1_approx] starting weight calculation for The plural form of player is players
The plural form of idea is ideas
The plural form of day is days
The plural form of god is gods
The plural form of hour is hours
The plural form of student is students
The plural form of website is websites
The plural form of resource is
2024-07-29 13:08:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 13:10:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2939, -0.0165, -0.5278,  ..., -0.0445,  0.0358, -0.0848],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2183, -3.1191,  0.4158,  ..., -1.6152, -1.7207, -1.4023],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0451,  0.0077, -0.0151,  ..., -0.0403, -0.0032, -0.0248],
        [-0.0056,  0.0539,  0.0298,  ...,  0.0282,  0.0071,  0.0279],
        [ 0.0038,  0.0002,  0.0662,  ...,  0.0148,  0.0087, -0.0189],
        ...,
        [ 0.0127,  0.0110,  0.0053,  ...,  0.0988, -0.0013, -0.0010],
        [-0.0166,  0.0096, -0.0192,  ..., -0.0344,  0.0571, -0.0113],
        [ 0.0265, -0.0029,  0.0002,  ...,  0.0097, -0.0131,  0.0733]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6221, -3.2070,  0.7197,  ..., -0.9868, -1.4033, -0.9658]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 13:10:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of player is players
The plural form of idea is ideas
The plural form of day is days
The plural form of god is gods
The plural form of hour is hours
The plural form of student is students
The plural form of website is websites
The plural form of resource is
2024-07-29 13:10:46 root INFO     [order_1_approx] starting weight calculation for The plural form of day is days
The plural form of website is websites
The plural form of resource is resources
The plural form of player is players
The plural form of god is gods
The plural form of student is students
The plural form of idea is ideas
The plural form of hour is
2024-07-29 13:10:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 13:12:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4839, -0.3562,  0.1998,  ...,  0.1611, -0.1240, -0.1027],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3425, -3.1328,  1.2412,  ..., -1.8340,  0.3389, -2.6934],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0735,  0.0136,  0.0057,  ..., -0.0052, -0.0130,  0.0183],
        [ 0.0072,  0.0636, -0.0013,  ...,  0.0081,  0.0113,  0.0032],
        [ 0.0136, -0.0010,  0.0540,  ..., -0.0060, -0.0094,  0.0130],
        ...,
        [ 0.0056,  0.0265,  0.0248,  ...,  0.0645, -0.0093,  0.0126],
        [-0.0056,  0.0073, -0.0074,  ...,  0.0253,  0.0507, -0.0092],
        [-0.0098, -0.0029, -0.0217,  ...,  0.0025,  0.0016,  0.0619]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9141, -2.6699,  0.8213,  ..., -1.6914,  0.0422, -2.3652]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 13:13:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of day is days
The plural form of website is websites
The plural form of resource is resources
The plural form of player is players
The plural form of god is gods
The plural form of student is students
The plural form of idea is ideas
The plural form of hour is
2024-07-29 13:13:02 root INFO     [order_1_approx] starting weight calculation for The plural form of resource is resources
The plural form of player is players
The plural form of hour is hours
The plural form of student is students
The plural form of idea is ideas
The plural form of website is websites
The plural form of day is days
The plural form of god is
2024-07-29 13:13:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 13:15:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0162,  0.2563, -0.1030,  ..., -0.1262, -0.1952, -0.1184],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.6211, -4.2109,  0.8057,  ..., -1.7617,  0.4980, -2.7188],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0371, -0.0195,  0.0061,  ...,  0.0090, -0.0018,  0.0102],
        [ 0.0240,  0.0485,  0.0207,  ...,  0.0090,  0.0151,  0.0067],
        [ 0.0018, -0.0119,  0.0439,  ...,  0.0192,  0.0067,  0.0032],
        ...,
        [ 0.0214,  0.0090, -0.0094,  ...,  0.0565, -0.0068,  0.0028],
        [ 0.0102,  0.0063, -0.0076,  ..., -0.0316,  0.0181, -0.0185],
        [-0.0083,  0.0191, -0.0155,  ..., -0.0071, -0.0038,  0.0671]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.3555, -3.9629,  0.5723,  ..., -1.4404,  1.0625, -2.4766]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 13:15:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of resource is resources
The plural form of player is players
The plural form of hour is hours
The plural form of student is students
The plural form of idea is ideas
The plural form of website is websites
The plural form of day is days
The plural form of god is
2024-07-29 13:15:16 root INFO     [order_1_approx] starting weight calculation for The plural form of idea is ideas
The plural form of day is days
The plural form of student is students
The plural form of god is gods
The plural form of resource is resources
The plural form of hour is hours
The plural form of player is players
The plural form of website is
2024-07-29 13:15:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 13:17:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0010,  0.4763, -0.1692,  ...,  0.0143, -0.2971, -0.2377],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4609, -3.2285,  1.6113,  ...,  0.4438, -1.0195, -0.9805],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0465, -0.0119,  0.0085,  ...,  0.0012, -0.0013,  0.0042],
        [-0.0014,  0.0752,  0.0115,  ...,  0.0023,  0.0022, -0.0015],
        [ 0.0212,  0.0105,  0.0606,  ...,  0.0098,  0.0073,  0.0160],
        ...,
        [-0.0026,  0.0085,  0.0152,  ...,  0.0460,  0.0015, -0.0142],
        [ 0.0022,  0.0253, -0.0146,  ...,  0.0025,  0.0523,  0.0011],
        [-0.0075,  0.0058, -0.0083,  ...,  0.0016, -0.0175,  0.0584]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8594, -3.6914,  1.0410,  ...,  0.4731, -1.0713, -0.4302]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 13:17:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of idea is ideas
The plural form of day is days
The plural form of student is students
The plural form of god is gods
The plural form of resource is resources
The plural form of hour is hours
The plural form of player is players
The plural form of website is
2024-07-29 13:17:29 root INFO     total operator prediction time: 1076.493005990982 seconds
2024-07-29 13:17:29 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_Ving - 3pSg
2024-07-29 13:17:29 root INFO     building operator verb_Ving - 3pSg
2024-07-29 13:17:29 root INFO     [order_1_approx] starting weight calculation for When something is suggesting, it suggests
When something is operating, it operates
When something is developing, it develops
When something is explaining, it explains
When something is creating, it creates
When something is involving, it involves
When something is understanding, it understands
When something is requiring, it
2024-07-29 13:17:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 13:19:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1027, -0.1538, -0.1656,  ..., -0.3340, -0.2588, -0.3572],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6904, -3.2539,  1.8477,  ..., -0.9727, -4.5273, -0.8262],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.4016e-02, -1.1301e-03,  1.7166e-02,  ...,  7.8659e-03,
         -1.5747e-02,  2.2949e-02],
        [-1.9760e-02,  6.4941e-02, -2.4887e-02,  ...,  1.2703e-02,
          6.0081e-03,  3.8422e-02],
        [ 1.3565e-02, -7.3700e-03,  5.2246e-02,  ..., -2.8961e-02,
          5.8289e-03, -1.8555e-02],
        ...,
        [ 1.8768e-03,  9.0179e-03,  1.9867e-02,  ...,  5.8807e-02,
         -2.3918e-03,  1.8494e-02],
        [-1.5442e-02, -2.4567e-02,  1.9302e-02,  ..., -2.3773e-02,
          6.3721e-02, -7.2571e-02],
        [-1.9318e-02,  3.3188e-03,  4.1485e-05,  ..., -1.1536e-02,
         -8.8425e-03,  4.5319e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8462, -3.3066,  2.0000,  ..., -0.9551, -4.3438, -0.7930]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 13:19:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is suggesting, it suggests
When something is operating, it operates
When something is developing, it develops
When something is explaining, it explains
When something is creating, it creates
When something is involving, it involves
When something is understanding, it understands
When something is requiring, it
2024-07-29 13:19:43 root INFO     [order_1_approx] starting weight calculation for When something is creating, it creates
When something is suggesting, it suggests
When something is operating, it operates
When something is developing, it develops
When something is requiring, it requires
When something is explaining, it explains
When something is understanding, it understands
When something is involving, it
2024-07-29 13:19:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 13:21:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0369, -0.0917, -0.0411,  ..., -0.3269, -0.6060, -0.2346],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0859, -1.1162,  3.2793,  ..., -0.0742, -3.6035, -3.2090],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0657, -0.0074,  0.0210,  ...,  0.0139, -0.0100,  0.0251],
        [-0.0204,  0.0650,  0.0027,  ...,  0.0225,  0.0148,  0.0102],
        [-0.0057,  0.0006,  0.0334,  ..., -0.0294,  0.0050, -0.0233],
        ...,
        [ 0.0284,  0.0197, -0.0160,  ...,  0.0487,  0.0066,  0.0110],
        [-0.0153, -0.0030, -0.0133,  ..., -0.0037,  0.0654, -0.0568],
        [-0.0178, -0.0109,  0.0120,  ..., -0.0074, -0.0243,  0.0460]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4199, -0.9966,  3.2676,  ..., -0.1399, -3.9336, -3.0898]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 13:21:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is creating, it creates
When something is suggesting, it suggests
When something is operating, it operates
When something is developing, it develops
When something is requiring, it requires
When something is explaining, it explains
When something is understanding, it understands
When something is involving, it
2024-07-29 13:21:57 root INFO     [order_1_approx] starting weight calculation for When something is involving, it involves
When something is understanding, it understands
When something is requiring, it requires
When something is suggesting, it suggests
When something is creating, it creates
When something is explaining, it explains
When something is developing, it develops
When something is operating, it
2024-07-29 13:21:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 13:24:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1763, -0.1214, -0.2651,  ..., -0.1251, -0.1091, -0.3660],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4141, -4.4883,  0.3047,  ..., -2.0039, -5.7383, -0.3320],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0698, -0.0105, -0.0012,  ...,  0.0030, -0.0011,  0.0286],
        [-0.0136,  0.0509,  0.0016,  ...,  0.0163,  0.0026,  0.0071],
        [ 0.0002,  0.0291,  0.0483,  ..., -0.0144,  0.0101, -0.0160],
        ...,
        [-0.0032,  0.0063, -0.0118,  ...,  0.0611,  0.0023,  0.0004],
        [ 0.0040, -0.0170, -0.0059,  ..., -0.0171,  0.0410, -0.0308],
        [ 0.0070, -0.0060,  0.0085,  ..., -0.0113, -0.0193,  0.0392]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5469, -4.0898,  0.1444,  ..., -1.3301, -5.9336, -0.0914]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 13:24:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is involving, it involves
When something is understanding, it understands
When something is requiring, it requires
When something is suggesting, it suggests
When something is creating, it creates
When something is explaining, it explains
When something is developing, it develops
When something is operating, it
2024-07-29 13:24:11 root INFO     [order_1_approx] starting weight calculation for When something is operating, it operates
When something is suggesting, it suggests
When something is requiring, it requires
When something is explaining, it explains
When something is understanding, it understands
When something is involving, it involves
When something is developing, it develops
When something is creating, it
2024-07-29 13:24:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 13:26:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1276, -0.1604,  0.4426,  ..., -0.4585,  0.2039, -0.0452],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1953, -3.4570,  2.0352,  ...,  0.5811, -6.0469,  0.7852],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0567, -0.0044,  0.0102,  ...,  0.0162, -0.0010,  0.0032],
        [-0.0036,  0.0479, -0.0087,  ...,  0.0150,  0.0004,  0.0089],
        [ 0.0069,  0.0070,  0.0309,  ...,  0.0060,  0.0191, -0.0068],
        ...,
        [ 0.0138,  0.0200,  0.0054,  ...,  0.0392, -0.0027, -0.0051],
        [-0.0040,  0.0150, -0.0085,  ..., -0.0067,  0.0450, -0.0181],
        [-0.0118,  0.0016,  0.0167,  ..., -0.0107, -0.0145,  0.0355]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9883, -3.4297,  2.0117,  ...,  0.6064, -6.5977,  0.4082]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 13:26:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is operating, it operates
When something is suggesting, it suggests
When something is requiring, it requires
When something is explaining, it explains
When something is understanding, it understands
When something is involving, it involves
When something is developing, it develops
When something is creating, it
2024-07-29 13:26:24 root INFO     [order_1_approx] starting weight calculation for When something is involving, it involves
When something is requiring, it requires
When something is creating, it creates
When something is developing, it develops
When something is operating, it operates
When something is understanding, it understands
When something is suggesting, it suggests
When something is explaining, it
2024-07-29 13:26:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 13:29:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0955, -0.2930,  0.3577,  ..., -0.5767,  0.4119, -0.2404],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1680, -3.0020,  3.2344,  ...,  0.8638, -5.9922,  0.4434],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0388,  0.0002, -0.0042,  ...,  0.0155, -0.0037,  0.0108],
        [-0.0159,  0.0531,  0.0037,  ...,  0.0188,  0.0003,  0.0116],
        [-0.0062,  0.0113,  0.0252,  ..., -0.0176,  0.0064, -0.0239],
        ...,
        [ 0.0036,  0.0046,  0.0050,  ...,  0.0402,  0.0039, -0.0047],
        [-0.0024, -0.0002, -0.0080,  ..., -0.0133,  0.0341, -0.0232],
        [-0.0009,  0.0074,  0.0212,  ...,  0.0031, -0.0027,  0.0371]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1387, -2.7676,  3.2188,  ...,  1.2588, -5.9609,  0.0457]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 13:29:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is involving, it involves
When something is requiring, it requires
When something is creating, it creates
When something is developing, it develops
When something is operating, it operates
When something is understanding, it understands
When something is suggesting, it suggests
When something is explaining, it
2024-07-29 13:29:30 root INFO     [order_1_approx] starting weight calculation for When something is operating, it operates
When something is involving, it involves
When something is creating, it creates
When something is understanding, it understands
When something is developing, it develops
When something is requiring, it requires
When something is explaining, it explains
When something is suggesting, it
2024-07-29 13:29:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 13:32:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0067, -0.1107,  0.4768,  ...,  0.1379, -0.2203, -0.2612],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.8750, -2.2676, -0.3945,  ...,  1.5283, -3.7637,  1.4434],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0586,  0.0092,  0.0125,  ..., -0.0120, -0.0109,  0.0133],
        [-0.0244,  0.0465, -0.0101,  ...,  0.0152, -0.0065,  0.0251],
        [-0.0001, -0.0219,  0.0291,  ..., -0.0244,  0.0010, -0.0225],
        ...,
        [-0.0048,  0.0055,  0.0212,  ...,  0.0424, -0.0079,  0.0065],
        [-0.0024, -0.0026, -0.0034,  ...,  0.0009,  0.0327, -0.0359],
        [-0.0035,  0.0096,  0.0112,  ...,  0.0003, -0.0087,  0.0230]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.5000, -2.4961,  0.1196,  ...,  1.5117, -3.9707,  1.1182]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 13:32:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is operating, it operates
When something is involving, it involves
When something is creating, it creates
When something is understanding, it understands
When something is developing, it develops
When something is requiring, it requires
When something is explaining, it explains
When something is suggesting, it
2024-07-29 13:32:02 root INFO     [order_1_approx] starting weight calculation for When something is explaining, it explains
When something is involving, it involves
When something is creating, it creates
When something is requiring, it requires
When something is operating, it operates
When something is suggesting, it suggests
When something is developing, it develops
When something is understanding, it
2024-07-29 13:32:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 13:34:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0682,  0.0989,  0.0033,  ..., -0.1936, -0.2722, -0.2480],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9863, -1.8809,  1.4141,  ..., -0.7690, -6.2578,  1.9766],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0521, -0.0007,  0.0055,  ...,  0.0025, -0.0057,  0.0163],
        [-0.0071,  0.0547,  0.0060,  ...,  0.0198, -0.0006,  0.0170],
        [-0.0193, -0.0167,  0.0565,  ..., -0.0209,  0.0101, -0.0280],
        ...,
        [ 0.0095,  0.0263,  0.0025,  ...,  0.0503,  0.0050, -0.0082],
        [-0.0149, -0.0145, -0.0083,  ..., -0.0264,  0.0485, -0.0293],
        [-0.0049, -0.0166,  0.0154,  ..., -0.0042, -0.0087,  0.0297]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8320, -1.7412,  1.5000,  ..., -0.6108, -6.3477,  1.8213]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 13:34:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is explaining, it explains
When something is involving, it involves
When something is creating, it creates
When something is requiring, it requires
When something is operating, it operates
When something is suggesting, it suggests
When something is developing, it develops
When something is understanding, it
2024-07-29 13:34:35 root INFO     [order_1_approx] starting weight calculation for When something is operating, it operates
When something is requiring, it requires
When something is creating, it creates
When something is understanding, it understands
When something is suggesting, it suggests
When something is explaining, it explains
When something is involving, it involves
When something is developing, it
2024-07-29 13:34:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 13:37:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5747, -0.3921, -0.1837,  ..., -0.4231, -0.0189, -0.2375],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.7266, -4.5859,  1.4492,  ..., -0.6953, -5.5391, -1.4893],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0449,  0.0040,  0.0096,  ...,  0.0117, -0.0096,  0.0156],
        [ 0.0054,  0.0488, -0.0034,  ...,  0.0235,  0.0041,  0.0170],
        [-0.0035, -0.0062,  0.0213,  ..., -0.0052,  0.0117, -0.0138],
        ...,
        [ 0.0181,  0.0026,  0.0065,  ...,  0.0469, -0.0080,  0.0143],
        [-0.0175, -0.0157, -0.0215,  ..., -0.0204,  0.0532, -0.0220],
        [-0.0108, -0.0155,  0.0045,  ..., -0.0245, -0.0164,  0.0316]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.5469, -4.3281,  1.5205,  ..., -0.7720, -5.7812, -1.6299]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 13:37:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is operating, it operates
When something is requiring, it requires
When something is creating, it creates
When something is understanding, it understands
When something is suggesting, it suggests
When something is explaining, it explains
When something is involving, it involves
When something is developing, it
2024-07-29 13:37:07 root INFO     total operator prediction time: 1178.2298247814178 seconds
2024-07-29 13:37:07 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_inf - 3pSg
2024-07-29 13:37:07 root INFO     building operator verb_inf - 3pSg
2024-07-29 13:37:08 root INFO     [order_1_approx] starting weight calculation for I reduce, he reduces
I describe, he describes
I continue, he continues
I exist, he exists
I explain, he explains
I tell, he tells
I contain, he contains
I achieve, he
2024-07-29 13:37:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 13:39:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6260,  0.1422, -0.1544,  ..., -0.0585, -0.5107,  0.6221],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3906, -3.1309, -1.8223,  ..., -1.8242, -8.7188, -0.1211],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0439,  0.0058,  0.0275,  ...,  0.0053,  0.0041,  0.0364],
        [-0.0015,  0.0289, -0.0170,  ..., -0.0033,  0.0243, -0.0127],
        [-0.0149,  0.0032, -0.0049,  ...,  0.0040, -0.0009, -0.0118],
        ...,
        [-0.0147,  0.0004, -0.0041,  ...,  0.0175,  0.0080, -0.0155],
        [-0.0111,  0.0005,  0.0026,  ..., -0.0013,  0.0130,  0.0001],
        [ 0.0103, -0.0139,  0.0083,  ..., -0.0150, -0.0101,  0.0017]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0117, -3.0684, -1.3818,  ..., -1.8066, -8.4609, -0.2571]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 13:39:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I reduce, he reduces
I describe, he describes
I continue, he continues
I exist, he exists
I explain, he explains
I tell, he tells
I contain, he contains
I achieve, he
2024-07-29 13:39:59 root INFO     [order_1_approx] starting weight calculation for I reduce, he reduces
I contain, he contains
I explain, he explains
I continue, he continues
I exist, he exists
I achieve, he achieves
I describe, he describes
I tell, he
2024-07-29 13:39:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 13:42:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4358, -0.2761,  0.4006,  ..., -0.3174,  0.0990,  0.1295],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([  1.3477,  -2.9102,   1.2500,  ...,   0.2905, -10.4375,  -0.9863],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0421,  0.0054, -0.0019,  ...,  0.0045,  0.0057,  0.0215],
        [-0.0162,  0.0350, -0.0109,  ...,  0.0131, -0.0015,  0.0037],
        [-0.0055, -0.0142,  0.0174,  ..., -0.0107, -0.0046, -0.0051],
        ...,
        [-0.0016, -0.0008,  0.0009,  ...,  0.0249, -0.0124, -0.0137],
        [-0.0251, -0.0070, -0.0034,  ..., -0.0015,  0.0206, -0.0045],
        [ 0.0128, -0.0068, -0.0002,  ..., -0.0203, -0.0031,  0.0166]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1797, -2.8984,  1.6299,  ...,  0.5210, -9.8828, -0.9702]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 13:42:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I reduce, he reduces
I contain, he contains
I explain, he explains
I continue, he continues
I exist, he exists
I achieve, he achieves
I describe, he describes
I tell, he
2024-07-29 13:42:46 root INFO     [order_1_approx] starting weight calculation for I contain, he contains
I exist, he exists
I describe, he describes
I continue, he continues
I tell, he tells
I explain, he explains
I achieve, he achieves
I reduce, he
2024-07-29 13:42:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 13:45:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1763,  0.0121,  0.0746,  ..., -0.1902,  0.2163,  0.0840],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.9854, -1.7344,  0.5391,  ..., -2.3984, -7.8281, -3.4980],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0585,  0.0067,  0.0132,  ...,  0.0074, -0.0044,  0.0241],
        [ 0.0002,  0.0427, -0.0008,  ...,  0.0144,  0.0054,  0.0097],
        [ 0.0135,  0.0058,  0.0426,  ...,  0.0070,  0.0037,  0.0145],
        ...,
        [ 0.0013, -0.0038,  0.0072,  ...,  0.0513, -0.0023,  0.0102],
        [-0.0240, -0.0088, -0.0060,  ..., -0.0115,  0.0347, -0.0293],
        [-0.0037, -0.0043,  0.0061,  ..., -0.0107, -0.0046,  0.0396]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.2383, -1.9795,  0.1985,  ..., -2.0469, -6.9414, -3.4688]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 13:45:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I contain, he contains
I exist, he exists
I describe, he describes
I continue, he continues
I tell, he tells
I explain, he explains
I achieve, he achieves
I reduce, he
2024-07-29 13:45:19 root INFO     [order_1_approx] starting weight calculation for I tell, he tells
I achieve, he achieves
I describe, he describes
I reduce, he reduces
I contain, he contains
I continue, he continues
I explain, he explains
I exist, he
2024-07-29 13:45:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 13:47:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4333, -0.3833, -0.6626,  ..., -0.0435,  0.3362,  0.1309],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6699, -3.2344, -1.0391,  ..., -1.1436, -5.2344,  0.1348],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0270, -0.0075,  0.0004,  ...,  0.0070, -0.0088,  0.0302],
        [-0.0011,  0.0349, -0.0009,  ...,  0.0086,  0.0107, -0.0027],
        [-0.0023,  0.0060,  0.0072,  ..., -0.0142, -0.0046, -0.0138],
        ...,
        [-0.0255,  0.0028, -0.0021,  ...,  0.0184,  0.0036, -0.0090],
        [-0.0129, -0.0195, -0.0043,  ..., -0.0131,  0.0252,  0.0054],
        [-0.0002, -0.0042,  0.0023,  ..., -0.0172, -0.0093,  0.0177]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6191, -3.1875, -0.7378,  ..., -0.8320, -5.1641,  0.5273]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 13:47:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I tell, he tells
I achieve, he achieves
I describe, he describes
I reduce, he reduces
I contain, he contains
I continue, he continues
I explain, he explains
I exist, he
2024-07-29 13:47:52 root INFO     [order_1_approx] starting weight calculation for I describe, he describes
I exist, he exists
I reduce, he reduces
I continue, he continues
I contain, he contains
I tell, he tells
I achieve, he achieves
I explain, he
2024-07-29 13:47:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 13:50:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0989, -0.4250,  0.2334,  ..., -0.4375, -0.0551, -0.0486],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1016, -3.2148,  0.9180,  ..., -0.2695, -6.9180,  1.5547],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.3518e-02,  7.6485e-04,  5.3406e-03,  ...,  3.0460e-03,
         -8.6784e-05,  2.6840e-02],
        [-1.1726e-02,  2.5726e-02,  1.2589e-03,  ...,  8.4114e-04,
         -1.5049e-03,  4.5013e-04],
        [-1.0498e-02,  3.4332e-05,  1.4679e-02,  ..., -1.3191e-02,
          2.8000e-03, -1.0357e-03],
        ...,
        [-1.5343e-02,  4.4098e-03,  7.7057e-03,  ...,  3.3600e-02,
          1.9379e-03,  9.9373e-04],
        [ 4.7417e-03, -7.7744e-03, -3.9558e-03,  ..., -9.3613e-03,
          2.6978e-02, -8.6670e-03],
        [-2.6894e-03, -1.6975e-03,  1.6739e-02,  ..., -6.7520e-03,
         -7.2365e-03,  2.8564e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9072, -3.1973,  0.7783,  ..., -0.3760, -6.9375,  1.4639]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 13:50:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I describe, he describes
I exist, he exists
I reduce, he reduces
I continue, he continues
I contain, he contains
I tell, he tells
I achieve, he achieves
I explain, he
2024-07-29 13:50:04 root INFO     [order_1_approx] starting weight calculation for I explain, he explains
I reduce, he reduces
I exist, he exists
I achieve, he achieves
I contain, he contains
I describe, he describes
I tell, he tells
I continue, he
2024-07-29 13:50:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 13:52:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2223, -0.4548, -0.2690,  ...,  0.0452, -0.7471,  0.7456],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0312, -4.4375, -1.6064,  ..., -1.2588, -6.1250, -0.2031],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0414, -0.0083, -0.0069,  ...,  0.0037,  0.0003,  0.0320],
        [-0.0271,  0.0467,  0.0023,  ..., -0.0174,  0.0123, -0.0120],
        [-0.0052,  0.0164,  0.0088,  ..., -0.0093, -0.0079, -0.0022],
        ...,
        [-0.0031,  0.0045,  0.0142,  ...,  0.0309,  0.0041, -0.0031],
        [-0.0051, -0.0062, -0.0028,  ..., -0.0067,  0.0221, -0.0256],
        [-0.0005,  0.0017,  0.0003,  ..., -0.0202, -0.0094,  0.0189]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8848, -4.2578, -1.4453,  ..., -1.2021, -6.0039, -0.0381]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 13:52:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I explain, he explains
I reduce, he reduces
I exist, he exists
I achieve, he achieves
I contain, he contains
I describe, he describes
I tell, he tells
I continue, he
2024-07-29 13:52:36 root INFO     [order_1_approx] starting weight calculation for I reduce, he reduces
I explain, he explains
I exist, he exists
I tell, he tells
I continue, he continues
I achieve, he achieves
I contain, he contains
I describe, he
2024-07-29 13:52:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 13:54:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0609, -0.4839,  0.3003,  ..., -0.0961, -0.0604, -0.4326],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6699, -3.9258,  3.3809,  ..., -0.0352, -5.5352, -0.6182],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.0436e-02, -5.8441e-03,  1.9760e-03,  ...,  1.0109e-02,
         -2.4033e-03,  2.3590e-02],
        [-7.6790e-03,  3.5522e-02, -3.4523e-03,  ...,  8.2092e-03,
          1.5259e-02, -7.6561e-03],
        [ 3.4657e-03, -1.3046e-03,  1.9104e-02,  ..., -4.9591e-04,
          1.2100e-02, -8.9111e-03],
        ...,
        [-4.2725e-03,  4.3640e-03,  7.9041e-03,  ...,  2.9526e-02,
          3.3684e-03,  2.5024e-03],
        [-7.1182e-03, -6.8932e-03, -7.5264e-03,  ..., -3.6774e-03,
          3.3264e-02, -2.6970e-03],
        [ 8.8425e-03,  4.9829e-05,  3.8738e-03,  ..., -1.6510e-02,
         -7.3624e-03,  2.6718e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8203, -3.8340,  3.1953,  ..., -0.0256, -5.7266, -0.4868]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 13:54:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I reduce, he reduces
I explain, he explains
I exist, he exists
I tell, he tells
I continue, he continues
I achieve, he achieves
I contain, he contains
I describe, he
2024-07-29 13:54:49 root INFO     [order_1_approx] starting weight calculation for I tell, he tells
I explain, he explains
I continue, he continues
I describe, he describes
I exist, he exists
I achieve, he achieves
I reduce, he reduces
I contain, he
2024-07-29 13:54:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 13:57:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2798, -0.5132, -0.4414,  ...,  0.0377,  0.0070,  0.1394],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3486, -2.0664,  0.7148,  ..., -3.5449, -5.7539, -2.5000],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0532, -0.0038, -0.0193,  ...,  0.0096, -0.0129,  0.0179],
        [-0.0153,  0.0469, -0.0050,  ...,  0.0031,  0.0057, -0.0120],
        [-0.0128,  0.0164,  0.0111,  ..., -0.0114, -0.0024, -0.0230],
        ...,
        [-0.0169, -0.0009,  0.0253,  ...,  0.0378, -0.0102, -0.0046],
        [-0.0132, -0.0005,  0.0140,  ..., -0.0190,  0.0352,  0.0035],
        [ 0.0033,  0.0154,  0.0061,  ..., -0.0239, -0.0188,  0.0190]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0059, -2.2168,  1.2139,  ..., -3.3359, -5.6875, -2.2637]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 13:57:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I tell, he tells
I explain, he explains
I continue, he continues
I describe, he describes
I exist, he exists
I achieve, he achieves
I reduce, he reduces
I contain, he
2024-07-29 13:57:02 root INFO     total operator prediction time: 1194.5909917354584 seconds
2024-07-29 13:57:02 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_inf - Ved
2024-07-29 13:57:02 root INFO     building operator verb_inf - Ved
2024-07-29 13:57:02 root INFO     [order_1_approx] starting weight calculation for If the present form is become, the past form is became
If the present form is lose, the past form is lost
If the present form is agree, the past form is agreed
If the present form is accept, the past form is accepted
If the present form is tell, the past form is told
If the present form is attend, the past form is attended
If the present form is publish, the past form is published
If the present form is ensure, the past form is
2024-07-29 13:57:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 13:59:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1594, -0.1917, -0.4004,  ..., -0.2340,  0.1219, -0.2424],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0361, -0.1118,  0.3831,  ...,  0.2798, -2.1562, -2.6230],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0566, -0.0223,  0.0235,  ..., -0.0100, -0.0037,  0.0186],
        [-0.0102,  0.0527, -0.0021,  ...,  0.0160,  0.0175, -0.0003],
        [-0.0013,  0.0027,  0.0331,  ..., -0.0066, -0.0127,  0.0075],
        ...,
        [-0.0123, -0.0073, -0.0067,  ...,  0.0701,  0.0054,  0.0229],
        [-0.0018, -0.0131,  0.0047,  ..., -0.0080,  0.0367, -0.0213],
        [ 0.0029,  0.0051,  0.0205,  ...,  0.0043, -0.0058,  0.0305]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1732, -0.1272,  0.2412,  ...,  0.2542, -1.9766, -2.0703]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 13:59:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is become, the past form is became
If the present form is lose, the past form is lost
If the present form is agree, the past form is agreed
If the present form is accept, the past form is accepted
If the present form is tell, the past form is told
If the present form is attend, the past form is attended
If the present form is publish, the past form is published
If the present form is ensure, the past form is
2024-07-29 13:59:13 root INFO     [order_1_approx] starting weight calculation for If the present form is agree, the past form is agreed
If the present form is publish, the past form is published
If the present form is lose, the past form is lost
If the present form is accept, the past form is accepted
If the present form is tell, the past form is told
If the present form is attend, the past form is attended
If the present form is ensure, the past form is ensured
If the present form is become, the past form is
2024-07-29 13:59:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 14:01:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4875,  0.2454, -0.0299,  ..., -0.3152, -0.1754,  0.2239],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0908, -0.1520,  1.1777,  ...,  0.2778,  0.9277, -1.1416],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0742, -0.0203,  0.0313,  ...,  0.0007,  0.0087,  0.0287],
        [-0.0299,  0.0574,  0.0102,  ...,  0.0075,  0.0181, -0.0081],
        [ 0.0127,  0.0014,  0.0320,  ..., -0.0201, -0.0081, -0.0079],
        ...,
        [-0.0018,  0.0262, -0.0024,  ...,  0.0778,  0.0161, -0.0039],
        [ 0.0122,  0.0150, -0.0140,  ..., -0.0065,  0.0155,  0.0148],
        [-0.0147,  0.0067,  0.0229,  ..., -0.0116, -0.0276,  0.0410]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9810, -0.0104,  0.8359,  ...,  0.4270,  0.6094, -0.7803]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 14:01:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is agree, the past form is agreed
If the present form is publish, the past form is published
If the present form is lose, the past form is lost
If the present form is accept, the past form is accepted
If the present form is tell, the past form is told
If the present form is attend, the past form is attended
If the present form is ensure, the past form is ensured
If the present form is become, the past form is
2024-07-29 14:01:26 root INFO     [order_1_approx] starting weight calculation for If the present form is ensure, the past form is ensured
If the present form is accept, the past form is accepted
If the present form is agree, the past form is agreed
If the present form is lose, the past form is lost
If the present form is attend, the past form is attended
If the present form is tell, the past form is told
If the present form is become, the past form is became
If the present form is publish, the past form is
2024-07-29 14:01:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 14:03:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2079,  0.1166,  0.4065,  ..., -0.0051,  0.0150,  0.2983],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8086, -2.0391,  0.5723,  ..., -2.2090, -1.3594,  1.5957],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0535, -0.0103,  0.0130,  ..., -0.0055,  0.0161,  0.0194],
        [-0.0233,  0.0506,  0.0095,  ...,  0.0006,  0.0147, -0.0105],
        [ 0.0187, -0.0081,  0.0338,  ..., -0.0129, -0.0105, -0.0054],
        ...,
        [ 0.0001,  0.0031,  0.0007,  ...,  0.0530,  0.0156,  0.0129],
        [ 0.0035, -0.0172, -0.0145,  ..., -0.0123,  0.0119, -0.0297],
        [-0.0082,  0.0100,  0.0124,  ..., -0.0144, -0.0215,  0.0372]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1875, -1.9756,  0.7197,  ..., -1.9453, -0.7109,  1.4219]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 14:03:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is ensure, the past form is ensured
If the present form is accept, the past form is accepted
If the present form is agree, the past form is agreed
If the present form is lose, the past form is lost
If the present form is attend, the past form is attended
If the present form is tell, the past form is told
If the present form is become, the past form is became
If the present form is publish, the past form is
2024-07-29 14:03:58 root INFO     [order_1_approx] starting weight calculation for If the present form is ensure, the past form is ensured
If the present form is tell, the past form is told
If the present form is agree, the past form is agreed
If the present form is publish, the past form is published
If the present form is attend, the past form is attended
If the present form is accept, the past form is accepted
If the present form is become, the past form is became
If the present form is lose, the past form is
2024-07-29 14:03:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 14:06:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1401,  0.0132,  0.1301,  ..., -0.7148,  0.2434, -0.1201],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0674, -1.3545, -0.0452,  ..., -0.6807, -0.3105, -1.0742],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.4829e-02, -4.4632e-03,  2.0157e-02,  ...,  1.8578e-03,
          9.2621e-03,  1.2619e-02],
        [-1.9112e-03,  4.9805e-02,  1.1711e-03,  ...,  1.2604e-02,
          1.0262e-03,  1.1253e-03],
        [-1.6830e-02,  3.4904e-03,  2.9800e-02,  ..., -9.7275e-05,
         -2.6215e-02, -1.5884e-02],
        ...,
        [ 8.2550e-03,  1.5213e-02, -2.4094e-02,  ...,  4.6570e-02,
          1.9455e-02, -2.8419e-03],
        [-8.6021e-04,  1.2848e-02,  8.2855e-03,  ..., -2.0020e-02,
          1.8982e-02, -2.2873e-02],
        [-8.4000e-03,  5.1117e-03,  1.3618e-02,  ..., -2.6855e-02,
         -1.4130e-02,  2.8961e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0180, -1.2119,  0.1506,  ..., -0.2786, -0.2400, -0.9824]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 14:06:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is ensure, the past form is ensured
If the present form is tell, the past form is told
If the present form is agree, the past form is agreed
If the present form is publish, the past form is published
If the present form is attend, the past form is attended
If the present form is accept, the past form is accepted
If the present form is become, the past form is became
If the present form is lose, the past form is
2024-07-29 14:06:28 root INFO     [order_1_approx] starting weight calculation for If the present form is publish, the past form is published
If the present form is tell, the past form is told
If the present form is agree, the past form is agreed
If the present form is lose, the past form is lost
If the present form is become, the past form is became
If the present form is ensure, the past form is ensured
If the present form is attend, the past form is attended
If the present form is accept, the past form is
2024-07-29 14:06:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 14:08:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2465,  0.0362, -0.3618,  ...,  0.1288, -0.0562, -0.0652],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2148,  0.2002, -1.3193,  ..., -0.7627, -2.7031,  0.7822],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0598, -0.0264,  0.0168,  ..., -0.0151,  0.0044,  0.0170],
        [-0.0089,  0.0635,  0.0062,  ...,  0.0200, -0.0040, -0.0077],
        [-0.0002,  0.0187,  0.0235,  ..., -0.0084, -0.0220, -0.0169],
        ...,
        [-0.0022, -0.0033, -0.0280,  ...,  0.0545,  0.0140, -0.0128],
        [-0.0007,  0.0065, -0.0204,  ..., -0.0137,  0.0201, -0.0241],
        [-0.0172, -0.0066,  0.0088,  ..., -0.0231, -0.0224,  0.0308]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2080,  0.2283, -1.7061,  ..., -0.3059, -2.4590,  1.0078]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 14:08:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is publish, the past form is published
If the present form is tell, the past form is told
If the present form is agree, the past form is agreed
If the present form is lose, the past form is lost
If the present form is become, the past form is became
If the present form is ensure, the past form is ensured
If the present form is attend, the past form is attended
If the present form is accept, the past form is
2024-07-29 14:08:34 root INFO     [order_1_approx] starting weight calculation for If the present form is accept, the past form is accepted
If the present form is tell, the past form is told
If the present form is agree, the past form is agreed
If the present form is become, the past form is became
If the present form is publish, the past form is published
If the present form is lose, the past form is lost
If the present form is ensure, the past form is ensured
If the present form is attend, the past form is
2024-07-29 14:08:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 14:10:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3706,  0.2493, -0.6016,  ..., -0.5269, -0.2421, -0.3440],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1523,  1.6787, -0.5122,  ..., -0.3140, -4.5352, -1.2588],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0867, -0.0266, -0.0011,  ..., -0.0135,  0.0130, -0.0003],
        [-0.0101,  0.0963, -0.0233,  ...,  0.0252,  0.0137, -0.0054],
        [ 0.0053,  0.0066,  0.0587,  ...,  0.0030, -0.0209, -0.0037],
        ...,
        [-0.0155, -0.0022,  0.0237,  ...,  0.0769,  0.0065, -0.0109],
        [-0.0070, -0.0082, -0.0068,  ..., -0.0021,  0.0290, -0.0219],
        [ 0.0083,  0.0031, -0.0068,  ..., -0.0173, -0.0172,  0.0488]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6582,  1.8799, -0.7422,  ..., -0.2800, -3.5410, -0.8179]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 14:10:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is accept, the past form is accepted
If the present form is tell, the past form is told
If the present form is agree, the past form is agreed
If the present form is become, the past form is became
If the present form is publish, the past form is published
If the present form is lose, the past form is lost
If the present form is ensure, the past form is ensured
If the present form is attend, the past form is
2024-07-29 14:10:47 root INFO     [order_1_approx] starting weight calculation for If the present form is attend, the past form is attended
If the present form is ensure, the past form is ensured
If the present form is tell, the past form is told
If the present form is accept, the past form is accepted
If the present form is become, the past form is became
If the present form is publish, the past form is published
If the present form is lose, the past form is lost
If the present form is agree, the past form is
2024-07-29 14:10:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 14:12:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0800,  0.0666, -0.2404,  ..., -0.0572, -0.4722, -0.1029],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9043, -1.6787,  0.4626,  ..., -0.5576, -2.3867,  0.3652],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0704, -0.0280,  0.0253,  ..., -0.0122,  0.0010,  0.0206],
        [-0.0170,  0.0537, -0.0135,  ...,  0.0112,  0.0026, -0.0166],
        [-0.0156, -0.0204,  0.0273,  ...,  0.0024, -0.0079, -0.0232],
        ...,
        [ 0.0052,  0.0052, -0.0211,  ...,  0.0646,  0.0038, -0.0031],
        [-0.0189,  0.0039, -0.0237,  ..., -0.0178,  0.0297, -0.0304],
        [ 0.0033, -0.0007,  0.0108,  ..., -0.0087, -0.0118,  0.0509]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9614, -1.6484,  0.7158,  ..., -0.5947, -1.8389,  0.4485]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 14:13:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is attend, the past form is attended
If the present form is ensure, the past form is ensured
If the present form is tell, the past form is told
If the present form is accept, the past form is accepted
If the present form is become, the past form is became
If the present form is publish, the past form is published
If the present form is lose, the past form is lost
If the present form is agree, the past form is
2024-07-29 14:13:00 root INFO     [order_1_approx] starting weight calculation for If the present form is become, the past form is became
If the present form is ensure, the past form is ensured
If the present form is agree, the past form is agreed
If the present form is accept, the past form is accepted
If the present form is lose, the past form is lost
If the present form is attend, the past form is attended
If the present form is publish, the past form is published
If the present form is tell, the past form is
2024-07-29 14:13:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 14:15:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0076, -0.1735,  0.2981,  ..., -0.1882, -0.2230,  0.0419],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3770,  0.4038,  1.7324,  ...,  2.8848, -4.3750, -1.8818],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.7220e-02, -1.2161e-02,  1.1444e-05,  ...,  8.6136e-03,
          2.5463e-03,  2.0386e-02],
        [-9.7733e-03,  6.3293e-02, -1.7670e-02,  ...,  4.6043e-03,
         -7.0496e-03,  1.5163e-03],
        [ 2.0809e-03, -9.0256e-03,  4.0253e-02,  ..., -1.3367e-02,
         -2.1317e-02,  2.8076e-03],
        ...,
        [ 1.5366e-02,  2.3438e-02, -5.3253e-03,  ...,  4.8492e-02,
          5.3139e-03,  3.8395e-03],
        [-1.3374e-02, -1.7975e-02, -4.9057e-03,  ..., -1.4587e-02,
          5.3070e-02, -2.0172e-02],
        [ 3.0670e-03,  1.3977e-02,  2.9205e-02,  ..., -9.9411e-03,
         -7.1373e-03,  3.5431e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4336,  0.6611,  1.8174,  ...,  2.6094, -3.7031, -1.8281]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 14:15:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is become, the past form is became
If the present form is ensure, the past form is ensured
If the present form is agree, the past form is agreed
If the present form is accept, the past form is accepted
If the present form is lose, the past form is lost
If the present form is attend, the past form is attended
If the present form is publish, the past form is published
If the present form is tell, the past form is
2024-07-29 14:15:10 root INFO     total operator prediction time: 1087.6539888381958 seconds
2024-07-29 14:15:10 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_Ving - Ved
2024-07-29 14:15:10 root INFO     building operator verb_Ving - Ved
2024-07-29 14:15:10 root INFO     [order_1_approx] starting weight calculation for After something is representing, it has represented
After something is announcing, it has announced
After something is including, it has included
After something is teaching, it has taught
After something is following, it has followed
After something is hearing, it has heard
After something is appearing, it has appeared
After something is attending, it has
2024-07-29 14:15:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 14:17:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1832,  0.0622, -0.4478,  ..., -0.5771, -0.0952, -0.3899],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1309,  2.0879,  0.2432,  ..., -1.1191, -4.3242, -1.1113],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0596, -0.0093,  0.0053,  ...,  0.0151, -0.0015,  0.0003],
        [-0.0110,  0.0717,  0.0026,  ...,  0.0091,  0.0170, -0.0028],
        [ 0.0061,  0.0019,  0.0429,  ...,  0.0046, -0.0045, -0.0077],
        ...,
        [-0.0059,  0.0045,  0.0020,  ...,  0.0599,  0.0006,  0.0079],
        [ 0.0133, -0.0046, -0.0044,  ..., -0.0060,  0.0371, -0.0106],
        [ 0.0102,  0.0165,  0.0024,  ..., -0.0030, -0.0148,  0.0335]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8867,  2.1816,  0.2175,  ..., -0.4404, -3.9277, -0.8506]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 14:17:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is representing, it has represented
After something is announcing, it has announced
After something is including, it has included
After something is teaching, it has taught
After something is following, it has followed
After something is hearing, it has heard
After something is appearing, it has appeared
After something is attending, it has
2024-07-29 14:17:24 root INFO     [order_1_approx] starting weight calculation for After something is following, it has followed
After something is announcing, it has announced
After something is hearing, it has heard
After something is attending, it has attended
After something is appearing, it has appeared
After something is teaching, it has taught
After something is including, it has included
After something is representing, it has
2024-07-29 14:17:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 14:19:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0602,  0.1061, -0.3218,  ..., -0.4539, -0.0112, -0.1545],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6816,  0.6602,  2.1113,  ..., -1.3594, -0.5518, -0.2109],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0616, -0.0105,  0.0197,  ...,  0.0078, -0.0030,  0.0138],
        [-0.0336,  0.0482, -0.0098,  ...,  0.0081,  0.0182, -0.0253],
        [ 0.0155,  0.0111,  0.0580,  ...,  0.0043,  0.0014, -0.0087],
        ...,
        [ 0.0004,  0.0189, -0.0192,  ...,  0.0745, -0.0014,  0.0156],
        [ 0.0085,  0.0069, -0.0011,  ...,  0.0033,  0.0489, -0.0135],
        [-0.0146,  0.0068,  0.0026,  ..., -0.0066, -0.0116,  0.0408]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2996,  0.6680,  2.3184,  ..., -1.2148, -0.3726, -0.3374]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 14:19:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is following, it has followed
After something is announcing, it has announced
After something is hearing, it has heard
After something is attending, it has attended
After something is appearing, it has appeared
After something is teaching, it has taught
After something is including, it has included
After something is representing, it has
2024-07-29 14:19:38 root INFO     [order_1_approx] starting weight calculation for After something is following, it has followed
After something is representing, it has represented
After something is attending, it has attended
After something is appearing, it has appeared
After something is hearing, it has heard
After something is announcing, it has announced
After something is including, it has included
After something is teaching, it has
2024-07-29 14:19:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 14:21:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2114,  0.2085,  0.2285,  ..., -0.4570, -0.1886,  0.0327],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3027,  1.0117,  3.4766,  ..., -0.7812, -2.6094, -3.9395],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0511, -0.0054,  0.0170,  ...,  0.0068, -0.0164,  0.0071],
        [-0.0205,  0.0545, -0.0023,  ...,  0.0298,  0.0074,  0.0054],
        [-0.0006, -0.0008,  0.0473,  ...,  0.0075,  0.0085,  0.0017],
        ...,
        [ 0.0059,  0.0220, -0.0153,  ...,  0.0410,  0.0086, -0.0045],
        [ 0.0117,  0.0015, -0.0147,  ..., -0.0071,  0.0246, -0.0103],
        [-0.0114,  0.0162,  0.0345,  ..., -0.0059,  0.0042,  0.0237]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1328,  1.0195,  3.3633,  ..., -0.9727, -2.3438, -3.7031]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 14:21:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is following, it has followed
After something is representing, it has represented
After something is attending, it has attended
After something is appearing, it has appeared
After something is hearing, it has heard
After something is announcing, it has announced
After something is including, it has included
After something is teaching, it has
2024-07-29 14:21:50 root INFO     [order_1_approx] starting weight calculation for After something is hearing, it has heard
After something is following, it has followed
After something is appearing, it has appeared
After something is teaching, it has taught
After something is attending, it has attended
After something is representing, it has represented
After something is including, it has included
After something is announcing, it has
2024-07-29 14:21:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 14:24:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2473,  0.2025,  0.0374,  ..., -0.0961, -0.1315, -0.5049],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4746, -0.7715,  2.3262,  ..., -0.2373, -1.4062,  1.3965],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0558, -0.0016,  0.0318,  ...,  0.0060, -0.0084,  0.0219],
        [-0.0186,  0.0237,  0.0102,  ...,  0.0157,  0.0121,  0.0011],
        [ 0.0202, -0.0102,  0.0141,  ..., -0.0089, -0.0052, -0.0158],
        ...,
        [-0.0054,  0.0124, -0.0111,  ...,  0.0287,  0.0075,  0.0138],
        [ 0.0232,  0.0003, -0.0099,  ...,  0.0009,  0.0170, -0.0087],
        [-0.0024,  0.0073,  0.0130,  ..., -0.0043, -0.0065,  0.0109]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4307, -0.6992,  2.7227,  ...,  0.1289, -1.2109,  1.0430]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 14:24:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is hearing, it has heard
After something is following, it has followed
After something is appearing, it has appeared
After something is teaching, it has taught
After something is attending, it has attended
After something is representing, it has represented
After something is including, it has included
After something is announcing, it has
2024-07-29 14:24:03 root INFO     [order_1_approx] starting weight calculation for After something is announcing, it has announced
After something is attending, it has attended
After something is hearing, it has heard
After something is appearing, it has appeared
After something is representing, it has represented
After something is following, it has followed
After something is teaching, it has taught
After something is including, it has
2024-07-29 14:24:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 14:26:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1477, -0.5566,  0.2285,  ...,  0.1152,  0.1436, -0.4707],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9575,  1.3467,  0.9121,  ..., -1.4492, -0.2275, -2.1680],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0695, -0.0048,  0.0288,  ...,  0.0166, -0.0030, -0.0086],
        [-0.0290,  0.0668, -0.0175,  ...,  0.0199,  0.0026, -0.0120],
        [ 0.0060, -0.0002,  0.0331,  ..., -0.0043,  0.0048, -0.0001],
        ...,
        [ 0.0167,  0.0114, -0.0176,  ...,  0.0781, -0.0023,  0.0118],
        [ 0.0086,  0.0243, -0.0016,  ..., -0.0130,  0.0233, -0.0181],
        [-0.0125,  0.0188,  0.0013,  ..., -0.0148, -0.0136,  0.0424]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4258,  1.6895,  1.1992,  ..., -1.3057, -0.2090, -1.8652]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 14:26:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is announcing, it has announced
After something is attending, it has attended
After something is hearing, it has heard
After something is appearing, it has appeared
After something is representing, it has represented
After something is following, it has followed
After something is teaching, it has taught
After something is including, it has
2024-07-29 14:26:17 root INFO     [order_1_approx] starting weight calculation for After something is following, it has followed
After something is appearing, it has appeared
After something is including, it has included
After something is attending, it has attended
After something is announcing, it has announced
After something is teaching, it has taught
After something is representing, it has represented
After something is hearing, it has
2024-07-29 14:26:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 14:28:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0337, -0.3992,  0.3354,  ...,  0.0918, -0.0669,  0.0381],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7695,  0.2646,  1.3428,  ..., -0.1660, -4.2461, -2.8086],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.1228e-02, -1.0902e-02,  2.5330e-02,  ..., -2.9030e-03,
          9.5825e-03,  2.5146e-02],
        [-5.2338e-03,  8.2153e-02, -3.7308e-03,  ...,  1.9043e-02,
          8.1863e-03, -6.0120e-03],
        [-3.9825e-03, -5.2032e-03,  6.0150e-02,  ..., -8.0395e-04,
          1.6663e-02, -8.9169e-05],
        ...,
        [ 1.0033e-02,  3.3142e-02, -8.4305e-04,  ...,  6.5674e-02,
          5.0659e-03, -4.9973e-03],
        [ 1.3840e-02,  1.7319e-02, -1.6602e-02,  ..., -3.2196e-03,
          4.2633e-02, -2.9007e-02],
        [-1.9531e-02,  1.2985e-02,  3.6682e-02,  ..., -1.2115e-02,
         -9.4833e-03,  4.8706e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0381,  0.0806,  1.4395,  ..., -0.1477, -4.1602, -2.7266]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 14:28:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is following, it has followed
After something is appearing, it has appeared
After something is including, it has included
After something is attending, it has attended
After something is announcing, it has announced
After something is teaching, it has taught
After something is representing, it has represented
After something is hearing, it has
2024-07-29 14:28:31 root INFO     [order_1_approx] starting weight calculation for After something is following, it has followed
After something is attending, it has attended
After something is hearing, it has heard
After something is announcing, it has announced
After something is including, it has included
After something is representing, it has represented
After something is teaching, it has taught
After something is appearing, it has
2024-07-29 14:28:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 14:30:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1406, -0.3159,  0.0322,  ..., -0.2061,  0.3027, -0.5752],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5742,  1.0879,  1.3828,  ...,  0.5537, -1.1172,  1.6250],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0723, -0.0162,  0.0345,  ...,  0.0118, -0.0001,  0.0327],
        [-0.0256,  0.0903,  0.0143,  ...,  0.0403, -0.0140, -0.0127],
        [ 0.0145,  0.0223,  0.0750,  ..., -0.0074,  0.0220, -0.0149],
        ...,
        [-0.0187,  0.0247, -0.0084,  ...,  0.0693, -0.0172,  0.0079],
        [ 0.0369,  0.0276,  0.0151,  ..., -0.0016,  0.0620, -0.0146],
        [-0.0117, -0.0147,  0.0190,  ..., -0.0112, -0.0169,  0.0587]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1206,  0.5312,  1.3242,  ...,  0.6060, -0.5723,  1.8047]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 14:30:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is following, it has followed
After something is attending, it has attended
After something is hearing, it has heard
After something is announcing, it has announced
After something is including, it has included
After something is representing, it has represented
After something is teaching, it has taught
After something is appearing, it has
2024-07-29 14:30:44 root INFO     [order_1_approx] starting weight calculation for After something is representing, it has represented
After something is hearing, it has heard
After something is appearing, it has appeared
After something is including, it has included
After something is attending, it has attended
After something is announcing, it has announced
After something is teaching, it has taught
After something is following, it has
2024-07-29 14:30:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 14:32:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0288, -0.3789, -0.0238,  ..., -0.1278,  0.3193,  0.2080],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6992, -1.3066,  2.6465,  ..., -0.4597, -2.8320, -0.2754],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0863, -0.0002,  0.0058,  ...,  0.0093,  0.0094,  0.0168],
        [-0.0031,  0.0788,  0.0060,  ...,  0.0157, -0.0031, -0.0197],
        [ 0.0066,  0.0069,  0.0595,  ...,  0.0113, -0.0024, -0.0029],
        ...,
        [-0.0127,  0.0293, -0.0246,  ...,  0.0623, -0.0090, -0.0045],
        [ 0.0099,  0.0155, -0.0016,  ...,  0.0134,  0.0376, -0.0150],
        [-0.0151,  0.0244, -0.0051,  ..., -0.0280, -0.0026,  0.0432]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3711e+00, -1.3359e+00,  2.4707e+00,  ..., -2.4414e-03,
         -2.2812e+00, -1.7285e-01]], device='cuda:1', dtype=torch.float16,
       grad_fn=<SubBackward0>) 

                    
2024-07-29 14:32:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is representing, it has represented
After something is hearing, it has heard
After something is appearing, it has appeared
After something is including, it has included
After something is attending, it has attended
After something is announcing, it has announced
After something is teaching, it has taught
After something is following, it has
2024-07-29 14:32:56 root INFO     total operator prediction time: 1066.0146493911743 seconds
2024-07-29 14:32:56 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on Ving - verb_inf
2024-07-29 14:32:56 root INFO     building operator Ving - verb_inf
2024-07-29 14:32:56 root INFO     [order_1_approx] starting weight calculation for performing is the active form of perform
remaining is the active form of remain
including is the active form of include
understanding is the active form of understand
happening is the active form of happen
teaching is the active form of teach
promoting is the active form of promote
asking is the active form of
2024-07-29 14:32:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 14:35:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3867, -0.2434,  0.2739,  ..., -0.0608, -0.2448, -0.6025],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0332, -4.0664, -1.1689,  ...,  3.1582, -1.5352, -1.6377],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0598, -0.0034,  0.0076,  ...,  0.0095, -0.0046,  0.0142],
        [-0.0053,  0.0627, -0.0158,  ...,  0.0190, -0.0104,  0.0030],
        [ 0.0073, -0.0212,  0.0526,  ..., -0.0092,  0.0082, -0.0107],
        ...,
        [-0.0010,  0.0183, -0.0073,  ...,  0.0529,  0.0110, -0.0132],
        [ 0.0098,  0.0141,  0.0010,  ...,  0.0108,  0.0300, -0.0104],
        [-0.0008,  0.0120, -0.0170,  ..., -0.0076, -0.0056,  0.0510]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1597, -4.0820, -1.2695,  ...,  3.2188, -1.5938, -1.7236]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 14:35:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for performing is the active form of perform
remaining is the active form of remain
including is the active form of include
understanding is the active form of understand
happening is the active form of happen
teaching is the active form of teach
promoting is the active form of promote
asking is the active form of
2024-07-29 14:35:18 root INFO     [order_1_approx] starting weight calculation for including is the active form of include
performing is the active form of perform
happening is the active form of happen
understanding is the active form of understand
asking is the active form of ask
promoting is the active form of promote
teaching is the active form of teach
remaining is the active form of
2024-07-29 14:35:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 14:37:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4126, -0.3384,  0.1934,  ..., -0.4460, -0.0671,  0.0789],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4541, -3.6406, -0.5586,  ..., -0.2029,  0.2588, -2.4102],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1022, -0.0176,  0.0009,  ...,  0.0090,  0.0240,  0.0063],
        [-0.0003,  0.0786, -0.0164,  ...,  0.0055,  0.0086, -0.0160],
        [ 0.0146, -0.0135,  0.0692,  ..., -0.0103, -0.0234, -0.0137],
        ...,
        [ 0.0096,  0.0124, -0.0217,  ...,  0.0803,  0.0087,  0.0272],
        [ 0.0025,  0.0233,  0.0091,  ..., -0.0024,  0.0476, -0.0064],
        [-0.0113,  0.0070, -0.0174,  ..., -0.0273, -0.0237,  0.0856]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3018, -3.4766, -0.7285,  ..., -0.0372,  0.1296, -2.4199]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 14:37:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for including is the active form of include
performing is the active form of perform
happening is the active form of happen
understanding is the active form of understand
asking is the active form of ask
promoting is the active form of promote
teaching is the active form of teach
remaining is the active form of
2024-07-29 14:37:32 root INFO     [order_1_approx] starting weight calculation for remaining is the active form of remain
performing is the active form of perform
asking is the active form of ask
including is the active form of include
understanding is the active form of understand
teaching is the active form of teach
promoting is the active form of promote
happening is the active form of
2024-07-29 14:37:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 14:39:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0051, -0.0611,  0.2014,  ..., -0.3110,  0.0485, -0.4351],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7949, -3.8555,  1.3789,  ...,  1.4492, -1.8105, -0.0430],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0574, -0.0066,  0.0056,  ...,  0.0131,  0.0056,  0.0091],
        [-0.0072,  0.0458, -0.0042,  ..., -0.0065, -0.0079, -0.0079],
        [ 0.0139, -0.0020,  0.0348,  ..., -0.0008, -0.0070, -0.0208],
        ...,
        [ 0.0104,  0.0056, -0.0130,  ...,  0.0328,  0.0061, -0.0020],
        [-0.0008, -0.0021,  0.0123,  ...,  0.0077,  0.0318,  0.0120],
        [-0.0114,  0.0066,  0.0023,  ..., -0.0142, -0.0078,  0.0485]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9482, -3.7285,  1.2041,  ...,  1.5127, -2.1367,  0.0990]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 14:39:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for remaining is the active form of remain
performing is the active form of perform
asking is the active form of ask
including is the active form of include
understanding is the active form of understand
teaching is the active form of teach
promoting is the active form of promote
happening is the active form of
2024-07-29 14:39:45 root INFO     [order_1_approx] starting weight calculation for happening is the active form of happen
promoting is the active form of promote
understanding is the active form of understand
teaching is the active form of teach
performing is the active form of perform
remaining is the active form of remain
asking is the active form of ask
including is the active form of
2024-07-29 14:39:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 14:41:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0893, -0.5381,  0.0998,  ...,  0.1578,  0.2959, -0.6011],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0488, -1.5400,  0.7119,  ...,  0.8535, -1.4277, -3.4922],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0818, -0.0094,  0.0209,  ...,  0.0037,  0.0061, -0.0111],
        [-0.0051,  0.0612, -0.0138,  ...,  0.0181, -0.0165,  0.0020],
        [ 0.0201, -0.0024,  0.0469,  ..., -0.0070, -0.0056, -0.0057],
        ...,
        [ 0.0104,  0.0045, -0.0129,  ...,  0.0760,  0.0019,  0.0179],
        [-0.0069,  0.0145, -0.0008,  ...,  0.0046,  0.0292, -0.0057],
        [-0.0017,  0.0062, -0.0192,  ..., -0.0100, -0.0093,  0.0586]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1975, -1.5234,  0.5732,  ...,  0.5098, -1.3242, -3.0605]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 14:41:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for happening is the active form of happen
promoting is the active form of promote
understanding is the active form of understand
teaching is the active form of teach
performing is the active form of perform
remaining is the active form of remain
asking is the active form of ask
including is the active form of
2024-07-29 14:41:58 root INFO     [order_1_approx] starting weight calculation for including is the active form of include
performing is the active form of perform
understanding is the active form of understand
happening is the active form of happen
remaining is the active form of remain
promoting is the active form of promote
asking is the active form of ask
teaching is the active form of
2024-07-29 14:41:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 14:44:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1207,  0.1864,  0.4246,  ..., -0.2607, -0.2378,  0.4851],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9004, -3.3438,  1.8057,  ...,  3.4531, -2.5117, -3.9824],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0594, -0.0031,  0.0119,  ..., -0.0032, -0.0144, -0.0005],
        [ 0.0056,  0.0499,  0.0078,  ...,  0.0155, -0.0093, -0.0018],
        [ 0.0054, -0.0070,  0.0526,  ..., -0.0109, -0.0095,  0.0020],
        ...,
        [ 0.0064,  0.0123, -0.0184,  ...,  0.0415,  0.0025, -0.0057],
        [ 0.0059,  0.0101,  0.0007,  ...,  0.0029,  0.0370,  0.0023],
        [-0.0088, -0.0009,  0.0042,  ..., -0.0055, -0.0005,  0.0518]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7881, -3.1719,  1.4902,  ...,  3.5449, -2.6094, -3.9531]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 14:44:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for including is the active form of include
performing is the active form of perform
understanding is the active form of understand
happening is the active form of happen
remaining is the active form of remain
promoting is the active form of promote
asking is the active form of ask
teaching is the active form of
2024-07-29 14:44:12 root INFO     [order_1_approx] starting weight calculation for remaining is the active form of remain
including is the active form of include
teaching is the active form of teach
understanding is the active form of understand
asking is the active form of ask
performing is the active form of perform
happening is the active form of happen
promoting is the active form of
2024-07-29 14:44:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 14:46:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([0.1166, 0.0100, 0.1760,  ..., 0.1127, 0.1907, 0.0610], device='cuda:1',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5430, -3.7852, -0.4897,  ...,  2.4863, -2.2559, -2.1680],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0514,  0.0025,  0.0051,  ...,  0.0122, -0.0176,  0.0158],
        [-0.0081,  0.0618, -0.0008,  ...,  0.0136, -0.0017, -0.0102],
        [ 0.0142, -0.0049,  0.0378,  ..., -0.0023, -0.0038, -0.0032],
        ...,
        [ 0.0084,  0.0003,  0.0021,  ...,  0.0518, -0.0054, -0.0001],
        [-0.0065,  0.0048,  0.0072,  ...,  0.0142,  0.0446, -0.0304],
        [ 0.0029, -0.0017, -0.0287,  ..., -0.0195, -0.0253,  0.0486]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6641, -3.5703, -0.5806,  ...,  2.3496, -1.8945, -2.0684]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 14:46:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for remaining is the active form of remain
including is the active form of include
teaching is the active form of teach
understanding is the active form of understand
asking is the active form of ask
performing is the active form of perform
happening is the active form of happen
promoting is the active form of
2024-07-29 14:46:25 root INFO     [order_1_approx] starting weight calculation for promoting is the active form of promote
including is the active form of include
asking is the active form of ask
teaching is the active form of teach
happening is the active form of happen
remaining is the active form of remain
performing is the active form of perform
understanding is the active form of
2024-07-29 14:46:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 14:48:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2751,  0.0817,  0.3491,  ...,  0.0412, -0.1152, -0.1493],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4883, -1.8994,  0.6279,  ...,  0.3459, -1.3359,  0.0723],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0584, -0.0120, -0.0013,  ...,  0.0005, -0.0068,  0.0075],
        [ 0.0079,  0.0338, -0.0061,  ...,  0.0119, -0.0001,  0.0102],
        [-0.0025, -0.0125,  0.0405,  ..., -0.0067, -0.0014, -0.0003],
        ...,
        [ 0.0037,  0.0107, -0.0206,  ...,  0.0422,  0.0067, -0.0058],
        [-0.0017,  0.0040,  0.0027,  ..., -0.0024,  0.0246, -0.0092],
        [ 0.0112,  0.0012,  0.0076,  ..., -0.0119, -0.0039,  0.0372]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4062, -2.1133,  0.6201,  ...,  0.3064, -1.2861, -0.2375]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 14:48:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for promoting is the active form of promote
including is the active form of include
asking is the active form of ask
teaching is the active form of teach
happening is the active form of happen
remaining is the active form of remain
performing is the active form of perform
understanding is the active form of
2024-07-29 14:48:37 root INFO     [order_1_approx] starting weight calculation for teaching is the active form of teach
asking is the active form of ask
understanding is the active form of understand
remaining is the active form of remain
happening is the active form of happen
promoting is the active form of promote
including is the active form of include
performing is the active form of
2024-07-29 14:48:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 14:50:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 6.3184e-01, -8.6914e-02,  1.0815e-01,  ..., -4.2529e-01,
         4.2725e-04,  9.5947e-02], device='cuda:1', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9658, -3.8789,  2.3320,  ...,  1.9053, -1.2793, -3.4492],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0499,  0.0066,  0.0056,  ...,  0.0073,  0.0081,  0.0038],
        [-0.0033,  0.0397, -0.0006,  ...,  0.0098,  0.0058,  0.0050],
        [ 0.0057, -0.0132,  0.0282,  ...,  0.0038,  0.0023,  0.0019],
        ...,
        [ 0.0077,  0.0080, -0.0068,  ...,  0.0305, -0.0004, -0.0085],
        [ 0.0033,  0.0008,  0.0070,  ..., -0.0023,  0.0184, -0.0098],
        [ 0.0048,  0.0054, -0.0042,  ..., -0.0092, -0.0028,  0.0314]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8896, -3.7793,  2.3496,  ...,  1.9375, -1.3193, -3.4688]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 14:50:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for teaching is the active form of teach
asking is the active form of ask
understanding is the active form of understand
remaining is the active form of remain
happening is the active form of happen
promoting is the active form of promote
including is the active form of include
performing is the active form of
2024-07-29 14:50:52 root INFO     total operator prediction time: 1075.8775947093964 seconds
2024-07-29 14:50:52 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun - plural_irreg
2024-07-29 14:50:52 root INFO     building operator noun - plural_irreg
2024-07-29 14:50:52 root INFO     [order_1_approx] starting weight calculation for The plural form of life is lives
The plural form of academy is academies
The plural form of history is histories
The plural form of entry is entries
The plural form of facility is facilities
The plural form of library is libraries
The plural form of security is securities
The plural form of industry is
2024-07-29 14:50:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 14:53:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1292,  0.3940,  0.2764,  ..., -0.3552, -0.0603, -0.1033],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0820, -2.6953,  0.6597,  ..., -0.8335, -1.5703, -1.8760],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0750,  0.0061,  0.0040,  ..., -0.0037, -0.0052,  0.0105],
        [ 0.0044,  0.0598, -0.0032,  ...,  0.0141, -0.0092,  0.0036],
        [ 0.0146,  0.0052,  0.0631,  ...,  0.0106,  0.0223,  0.0124],
        ...,
        [ 0.0149,  0.0174,  0.0100,  ...,  0.0687,  0.0048,  0.0060],
        [-0.0058,  0.0178, -0.0192,  ...,  0.0058,  0.0360,  0.0107],
        [ 0.0093,  0.0146,  0.0049,  ...,  0.0111, -0.0081,  0.0264]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0977, -2.3203,  0.4590,  ..., -0.9165, -1.5771, -1.5742]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 14:53:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of life is lives
The plural form of academy is academies
The plural form of history is histories
The plural form of entry is entries
The plural form of facility is facilities
The plural form of library is libraries
The plural form of security is securities
The plural form of industry is
2024-07-29 14:53:06 root INFO     [order_1_approx] starting weight calculation for The plural form of entry is entries
The plural form of library is libraries
The plural form of security is securities
The plural form of life is lives
The plural form of industry is industries
The plural form of history is histories
The plural form of academy is academies
The plural form of facility is
2024-07-29 14:53:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 14:55:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1682, -0.1177, -0.5845,  ..., -0.5781, -0.5098, -0.1541],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6523, -2.1406,  3.7617,  ..., -0.1230, -1.2061, -2.3789],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0953, -0.0156, -0.0005,  ...,  0.0111, -0.0126,  0.0140],
        [-0.0212,  0.0811, -0.0128,  ...,  0.0095,  0.0131, -0.0034],
        [ 0.0084,  0.0060,  0.0487,  ..., -0.0168, -0.0118,  0.0115],
        ...,
        [-0.0197,  0.0213, -0.0133,  ...,  0.1140, -0.0130,  0.0139],
        [-0.0071,  0.0047,  0.0031,  ...,  0.0165,  0.0604, -0.0113],
        [-0.0047,  0.0002, -0.0079,  ...,  0.0145, -0.0037,  0.0665]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8486, -2.2070,  3.7070,  ..., -0.2656, -0.4971, -2.2480]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 14:55:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of entry is entries
The plural form of library is libraries
The plural form of security is securities
The plural form of life is lives
The plural form of industry is industries
The plural form of history is histories
The plural form of academy is academies
The plural form of facility is
2024-07-29 14:55:19 root INFO     [order_1_approx] starting weight calculation for The plural form of industry is industries
The plural form of library is libraries
The plural form of security is securities
The plural form of academy is academies
The plural form of facility is facilities
The plural form of history is histories
The plural form of life is lives
The plural form of entry is
2024-07-29 14:55:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 14:57:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0718, -0.0371, -0.2455,  ...,  0.1218, -0.1447,  0.0349],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4277, -1.5371, -1.1250,  ..., -0.6162, -4.1719, -3.9102],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1514,  0.0113,  0.0174,  ..., -0.0115,  0.0149, -0.0113],
        [-0.0312,  0.1211,  0.0075,  ...,  0.0293, -0.0063,  0.0111],
        [ 0.0134,  0.0005,  0.1103,  ..., -0.0057, -0.0008,  0.0326],
        ...,
        [ 0.0108,  0.0124, -0.0078,  ...,  0.1019, -0.0022,  0.0222],
        [-0.0144,  0.0140, -0.0071,  ..., -0.0069,  0.0802, -0.0018],
        [-0.0004,  0.0091,  0.0082,  ..., -0.0076, -0.0122,  0.0907]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5400, -1.6260, -1.1943,  ..., -1.2080, -3.6016, -3.6230]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 14:57:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of industry is industries
The plural form of library is libraries
The plural form of security is securities
The plural form of academy is academies
The plural form of facility is facilities
The plural form of history is histories
The plural form of life is lives
The plural form of entry is
2024-07-29 14:57:32 root INFO     [order_1_approx] starting weight calculation for The plural form of industry is industries
The plural form of academy is academies
The plural form of library is libraries
The plural form of entry is entries
The plural form of life is lives
The plural form of security is securities
The plural form of facility is facilities
The plural form of history is
2024-07-29 14:57:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 14:59:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2244, -0.1010, -0.0920,  ...,  0.0063,  0.0099, -0.0441],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8418, -2.0938,  1.0859,  ..., -1.9004, -3.6133, -3.0957],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0809,  0.0201,  0.0010,  ..., -0.0066, -0.0110, -0.0004],
        [-0.0011,  0.0696,  0.0053,  ...,  0.0144, -0.0058,  0.0017],
        [ 0.0157, -0.0055,  0.0460,  ...,  0.0102, -0.0042,  0.0263],
        ...,
        [ 0.0104,  0.0205, -0.0062,  ...,  0.0802, -0.0082,  0.0058],
        [-0.0115,  0.0200,  0.0069,  ...,  0.0022,  0.0437, -0.0003],
        [ 0.0219,  0.0057,  0.0011,  ..., -0.0025, -0.0294,  0.0588]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9473, -1.8516,  1.1221,  ..., -1.6934, -3.7949, -2.9961]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 14:59:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of industry is industries
The plural form of academy is academies
The plural form of library is libraries
The plural form of entry is entries
The plural form of life is lives
The plural form of security is securities
The plural form of facility is facilities
The plural form of history is
2024-07-29 14:59:46 root INFO     [order_1_approx] starting weight calculation for The plural form of history is histories
The plural form of life is lives
The plural form of academy is academies
The plural form of library is libraries
The plural form of facility is facilities
The plural form of entry is entries
The plural form of industry is industries
The plural form of security is
2024-07-29 14:59:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 15:01:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0288,  0.0789, -0.4033,  ...,  0.3330,  0.0784, -0.1804],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5396, -1.9365,  1.3320,  ..., -0.0061, -2.5566, -5.3359],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1047, -0.0072,  0.0018,  ...,  0.0005, -0.0204,  0.0161],
        [-0.0383,  0.0787,  0.0177,  ..., -0.0050,  0.0111,  0.0222],
        [ 0.0237,  0.0221,  0.0814,  ...,  0.0036,  0.0035,  0.0158],
        ...,
        [ 0.0050,  0.0176, -0.0020,  ...,  0.0852, -0.0049,  0.0264],
        [-0.0019,  0.0094, -0.0190,  ..., -0.0102,  0.0508, -0.0219],
        [ 0.0097, -0.0014,  0.0295,  ...,  0.0223,  0.0097,  0.0662]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.9863e-01, -2.3223e+00,  1.4795e+00,  ..., -2.1095e-03,
         -2.1582e+00, -5.5820e+00]], device='cuda:1', dtype=torch.float16,
       grad_fn=<SubBackward0>) 

                    
2024-07-29 15:02:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of history is histories
The plural form of life is lives
The plural form of academy is academies
The plural form of library is libraries
The plural form of facility is facilities
The plural form of entry is entries
The plural form of industry is industries
The plural form of security is
2024-07-29 15:02:00 root INFO     [order_1_approx] starting weight calculation for The plural form of library is libraries
The plural form of history is histories
The plural form of security is securities
The plural form of facility is facilities
The plural form of academy is academies
The plural form of entry is entries
The plural form of industry is industries
The plural form of life is
2024-07-29 15:02:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 15:04:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0818, -0.1577, -0.0188,  ..., -0.0983, -0.4521, -0.4424],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8506, -2.8809,  0.2512,  ..., -1.8018, -2.6133, -2.1719],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0678,  0.0272,  0.0120,  ...,  0.0173, -0.0027,  0.0191],
        [-0.0109,  0.0756,  0.0183,  ...,  0.0262, -0.0008,  0.0117],
        [ 0.0040,  0.0018,  0.0760,  ..., -0.0048,  0.0019,  0.0243],
        ...,
        [ 0.0284,  0.0070, -0.0184,  ...,  0.0842, -0.0070,  0.0239],
        [-0.0137,  0.0080, -0.0179,  ..., -0.0170,  0.0263,  0.0004],
        [-0.0130,  0.0051, -0.0167,  ...,  0.0030,  0.0060,  0.0690]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5859, -3.1094,  0.2720,  ..., -1.3926, -2.0859, -2.3496]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 15:04:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of library is libraries
The plural form of history is histories
The plural form of security is securities
The plural form of facility is facilities
The plural form of academy is academies
The plural form of entry is entries
The plural form of industry is industries
The plural form of life is
2024-07-29 15:04:14 root INFO     [order_1_approx] starting weight calculation for The plural form of entry is entries
The plural form of security is securities
The plural form of facility is facilities
The plural form of history is histories
The plural form of academy is academies
The plural form of industry is industries
The plural form of life is lives
The plural form of library is
2024-07-29 15:04:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 15:06:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2832, -0.4995, -1.1133,  ...,  0.1780, -0.5420, -0.0225],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5391, -4.3789,  1.0742,  ...,  0.1895, -1.3223, -3.2656],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.3425e-02, -2.8648e-03,  1.6232e-03,  ..., -1.7481e-03,
          5.7602e-03, -4.9210e-03],
        [-4.2038e-03,  7.0312e-02,  5.8632e-03,  ...,  1.9577e-02,
         -1.1703e-02,  6.4850e-05],
        [ 2.6321e-03, -2.9449e-03,  3.9093e-02,  ..., -3.0869e-02,
          9.5367e-05,  4.2877e-03],
        ...,
        [ 3.2864e-03,  7.0305e-03,  1.3580e-02,  ...,  5.9723e-02,
         -6.4392e-03,  1.7487e-02],
        [-1.5419e-02,  1.7456e-02, -1.4587e-02,  ..., -4.5013e-04,
          4.4495e-02,  1.2070e-02],
        [ 1.7395e-03, -8.0414e-03,  8.3847e-03,  ...,  1.1505e-02,
         -1.0712e-02,  6.4026e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8066, -4.3867,  1.2715,  ...,  0.1299, -0.8584, -3.0938]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 15:06:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of entry is entries
The plural form of security is securities
The plural form of facility is facilities
The plural form of history is histories
The plural form of academy is academies
The plural form of industry is industries
The plural form of life is lives
The plural form of library is
2024-07-29 15:06:27 root INFO     [order_1_approx] starting weight calculation for The plural form of library is libraries
The plural form of facility is facilities
The plural form of history is histories
The plural form of security is securities
The plural form of entry is entries
The plural form of industry is industries
The plural form of life is lives
The plural form of academy is
2024-07-29 15:06:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 15:08:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2081,  0.5054, -0.8159,  ...,  0.2295, -0.3794,  0.0394],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8384, -0.8115,  1.7090,  ...,  1.3359, -2.1680, -1.8711],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0706, -0.0044,  0.0085,  ..., -0.0158, -0.0139, -0.0092],
        [-0.0033,  0.0925, -0.0070,  ..., -0.0068, -0.0186,  0.0132],
        [ 0.0097,  0.0070,  0.0878,  ..., -0.0024, -0.0079,  0.0114],
        ...,
        [-0.0033,  0.0245,  0.0041,  ...,  0.0861, -0.0324, -0.0063],
        [-0.0173,  0.0303,  0.0059,  ..., -0.0085,  0.0586, -0.0319],
        [ 0.0293, -0.0135, -0.0482,  ..., -0.0159, -0.0023,  0.0846]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4309, -0.9561,  1.0332,  ...,  1.5625, -1.6016, -1.6846]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 15:08:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of library is libraries
The plural form of facility is facilities
The plural form of history is histories
The plural form of security is securities
The plural form of entry is entries
The plural form of industry is industries
The plural form of life is lives
The plural form of academy is
2024-07-29 15:08:41 root INFO     total operator prediction time: 1069.1454799175262 seconds
2024-07-29 15:08:41 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - member
2024-07-29 15:08:41 root INFO     building operator meronyms - member
2024-07-29 15:08:41 root INFO     [order_1_approx] starting weight calculation for A word is a member of a paragraph
A listener is a member of a audience
A cow is a member of a herd
A flower is a member of a bouquet
A employee is a member of a staff
A calf is a member of a cattle
A goose is a member of a gaggle
A student is a member of a
2024-07-29 15:08:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 15:10:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0453,  0.0347, -0.2454,  ...,  0.4070, -0.4202, -0.2303],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6104, -4.2070,  2.8711,  ..., -0.8525, -0.8975, -3.5586],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0556,  0.0026, -0.0118,  ...,  0.0090, -0.0122,  0.0046],
        [-0.0041,  0.0383,  0.0090,  ..., -0.0083, -0.0004, -0.0132],
        [ 0.0124, -0.0191,  0.0425,  ..., -0.0026,  0.0155,  0.0017],
        ...,
        [-0.0090,  0.0143,  0.0064,  ...,  0.0497, -0.0206, -0.0069],
        [ 0.0231,  0.0026, -0.0073,  ..., -0.0110,  0.0448, -0.0019],
        [ 0.0009, -0.0162, -0.0079,  ..., -0.0034, -0.0170,  0.0656]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5420, -4.0430,  2.7773,  ..., -0.6646, -1.0635, -2.7285]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 15:10:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A word is a member of a paragraph
A listener is a member of a audience
A cow is a member of a herd
A flower is a member of a bouquet
A employee is a member of a staff
A calf is a member of a cattle
A goose is a member of a gaggle
A student is a member of a
2024-07-29 15:10:54 root INFO     [order_1_approx] starting weight calculation for A goose is a member of a gaggle
A flower is a member of a bouquet
A student is a member of a class
A calf is a member of a cattle
A employee is a member of a staff
A cow is a member of a herd
A listener is a member of a audience
A word is a member of a
2024-07-29 15:10:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 15:13:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0842,  0.1202, -0.4524,  ...,  0.5918, -0.1643, -0.2830],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9023, -5.1641,  5.2070,  ..., -0.4395, -0.6377, -0.3359],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0496,  0.0040, -0.0579,  ...,  0.0474,  0.0317,  0.0204],
        [ 0.0134,  0.0372,  0.0536,  ..., -0.0230, -0.0307,  0.0037],
        [ 0.0088, -0.0168,  0.0478,  ...,  0.0206,  0.0114,  0.0072],
        ...,
        [ 0.0160,  0.0095,  0.0136,  ...,  0.0358, -0.0247,  0.0042],
        [-0.0083, -0.0053, -0.0169,  ...,  0.0022,  0.0669, -0.0039],
        [ 0.0039,  0.0086,  0.0181,  ..., -0.0303, -0.0221,  0.0540]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9043, -5.3516,  5.1523,  ..., -0.8506, -0.0894,  0.0452]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 15:13:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A goose is a member of a gaggle
A flower is a member of a bouquet
A student is a member of a class
A calf is a member of a cattle
A employee is a member of a staff
A cow is a member of a herd
A listener is a member of a audience
A word is a member of a
2024-07-29 15:13:08 root INFO     [order_1_approx] starting weight calculation for A listener is a member of a audience
A student is a member of a class
A employee is a member of a staff
A goose is a member of a gaggle
A word is a member of a paragraph
A calf is a member of a cattle
A cow is a member of a herd
A flower is a member of a
2024-07-29 15:13:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 15:15:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3628, -0.0353, -0.0903,  ...,  0.1382, -0.0378, -0.0143],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0693e+00, -3.9453e+00, -9.7656e-04,  ...,  2.1914e+00,
        -4.5703e+00, -2.9023e+00], device='cuda:1', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.9469e-02,  3.5095e-03,  9.0332e-03,  ...,  3.6068e-03,
         -5.1498e-03,  1.7807e-02],
        [-9.4223e-04,  6.3599e-02,  3.2227e-02,  ...,  5.0468e-03,
          9.5215e-03, -3.6621e-02],
        [ 1.8112e-02,  2.0416e-02,  7.9102e-02,  ..., -4.4708e-03,
         -3.2120e-03,  9.9945e-03],
        ...,
        [ 7.3509e-03, -9.5367e-04,  8.1635e-03,  ...,  7.6416e-02,
          2.0355e-02, -3.6438e-02],
        [-2.3403e-03,  1.7071e-03, -7.6447e-03,  ..., -8.4305e-03,
          6.3965e-02,  1.1063e-02],
        [-2.5085e-02, -5.1918e-03,  1.7471e-02,  ...,  6.1035e-05,
         -2.7313e-03,  5.5359e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3984, -3.8770,  0.2502,  ...,  2.2715, -4.7891, -2.5918]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 15:15:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A listener is a member of a audience
A student is a member of a class
A employee is a member of a staff
A goose is a member of a gaggle
A word is a member of a paragraph
A calf is a member of a cattle
A cow is a member of a herd
A flower is a member of a
2024-07-29 15:15:21 root INFO     [order_1_approx] starting weight calculation for A goose is a member of a gaggle
A student is a member of a class
A word is a member of a paragraph
A cow is a member of a herd
A employee is a member of a staff
A calf is a member of a cattle
A flower is a member of a bouquet
A listener is a member of a
2024-07-29 15:15:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 15:17:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0750, -0.1050, -0.0257,  ...,  0.4456,  0.0437,  0.0575],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6543, -5.5078,  3.5977,  ...,  1.6533, -2.3438, -2.6504],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0399, -0.0029,  0.0186,  ...,  0.0298, -0.0123,  0.0136],
        [-0.0055,  0.0301,  0.0025,  ...,  0.0028, -0.0008, -0.0307],
        [-0.0130, -0.0126,  0.0523,  ..., -0.0113,  0.0015,  0.0120],
        ...,
        [ 0.0146,  0.0245,  0.0075,  ...,  0.0550,  0.0171, -0.0208],
        [ 0.0162,  0.0197, -0.0043,  ..., -0.0170,  0.0527,  0.0029],
        [ 0.0049, -0.0215, -0.0299,  ...,  0.0165,  0.0092,  0.0634]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9697, -5.5391,  3.2109,  ...,  1.8750, -2.4629, -2.1758]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 15:17:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A goose is a member of a gaggle
A student is a member of a class
A word is a member of a paragraph
A cow is a member of a herd
A employee is a member of a staff
A calf is a member of a cattle
A flower is a member of a bouquet
A listener is a member of a
2024-07-29 15:17:35 root INFO     [order_1_approx] starting weight calculation for A word is a member of a paragraph
A listener is a member of a audience
A employee is a member of a staff
A goose is a member of a gaggle
A student is a member of a class
A flower is a member of a bouquet
A calf is a member of a cattle
A cow is a member of a
2024-07-29 15:17:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 15:19:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5415,  0.4404,  0.4038,  ...,  0.0792, -0.2070,  0.1798],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.2461, -3.2773,  2.9590,  ..., -2.9551, -0.5884, -1.8135],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0476,  0.0174, -0.0132,  ...,  0.0019, -0.0151, -0.0086],
        [ 0.0175,  0.0406,  0.0054,  ...,  0.0172, -0.0038, -0.0263],
        [ 0.0083, -0.0119,  0.0333,  ..., -0.0101,  0.0145,  0.0071],
        ...,
        [-0.0026, -0.0023,  0.0221,  ...,  0.0469,  0.0179, -0.0167],
        [-0.0011,  0.0171, -0.0165,  ...,  0.0121,  0.0548, -0.0251],
        [-0.0145, -0.0013, -0.0040,  ..., -0.0176, -0.0134,  0.0415]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 6.1094, -3.2656,  2.9258,  ..., -2.8027, -0.9028, -1.6426]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 15:19:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A word is a member of a paragraph
A listener is a member of a audience
A employee is a member of a staff
A goose is a member of a gaggle
A student is a member of a class
A flower is a member of a bouquet
A calf is a member of a cattle
A cow is a member of a
2024-07-29 15:19:44 root INFO     [order_1_approx] starting weight calculation for A flower is a member of a bouquet
A student is a member of a class
A cow is a member of a herd
A word is a member of a paragraph
A listener is a member of a audience
A goose is a member of a gaggle
A employee is a member of a staff
A calf is a member of a
2024-07-29 15:19:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 15:21:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4978, -0.1987,  0.3384,  ..., -0.0576, -0.4451,  0.5557],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.9297, -1.4932,  1.5127,  ..., -1.3057,  0.1137, -1.7715],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0499, -0.0048,  0.0048,  ...,  0.0046, -0.0129, -0.0040],
        [ 0.0252,  0.0432, -0.0128,  ...,  0.0145,  0.0056, -0.0268],
        [ 0.0075, -0.0087,  0.0442,  ...,  0.0056, -0.0192, -0.0128],
        ...,
        [ 0.0119,  0.0055,  0.0146,  ...,  0.0578,  0.0187, -0.0204],
        [ 0.0013,  0.0148, -0.0197,  ...,  0.0163,  0.0671, -0.0202],
        [ 0.0003, -0.0035, -0.0018,  ..., -0.0348,  0.0075,  0.0784]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.9766, -1.5469,  1.6631,  ..., -1.4238, -0.1543, -2.2734]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 15:21:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A flower is a member of a bouquet
A student is a member of a class
A cow is a member of a herd
A word is a member of a paragraph
A listener is a member of a audience
A goose is a member of a gaggle
A employee is a member of a staff
A calf is a member of a
2024-07-29 15:21:57 root INFO     [order_1_approx] starting weight calculation for A calf is a member of a cattle
A listener is a member of a audience
A goose is a member of a gaggle
A flower is a member of a bouquet
A student is a member of a class
A cow is a member of a herd
A word is a member of a paragraph
A employee is a member of a
2024-07-29 15:21:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 15:24:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4194,  0.0637, -0.7300,  ...,  0.1277, -0.3081, -0.1952],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5195, -5.1562,  5.2109,  ..., -2.8086,  2.0703, -4.1875],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0395,  0.0109, -0.0034,  ...,  0.0153, -0.0050,  0.0079],
        [-0.0201,  0.0453,  0.0096,  ...,  0.0066, -0.0023,  0.0208],
        [ 0.0063,  0.0036,  0.0539,  ..., -0.0020,  0.0222,  0.0012],
        ...,
        [ 0.0069,  0.0159,  0.0073,  ...,  0.0453, -0.0058,  0.0043],
        [-0.0133,  0.0017, -0.0079,  ...,  0.0098,  0.0456, -0.0041],
        [-0.0017, -0.0154, -0.0156,  ..., -0.0025, -0.0155,  0.0751]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3594, -5.4258,  4.9141,  ..., -2.5332,  2.0332, -4.0352]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 15:24:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A calf is a member of a cattle
A listener is a member of a audience
A goose is a member of a gaggle
A flower is a member of a bouquet
A student is a member of a class
A cow is a member of a herd
A word is a member of a paragraph
A employee is a member of a
2024-07-29 15:24:09 root INFO     [order_1_approx] starting weight calculation for A word is a member of a paragraph
A cow is a member of a herd
A flower is a member of a bouquet
A student is a member of a class
A listener is a member of a audience
A calf is a member of a cattle
A employee is a member of a staff
A goose is a member of a
2024-07-29 15:24:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 15:26:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4736,  0.0611, -0.0104,  ...,  0.1877, -0.2944, -0.0352],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.8516, -3.1562,  3.0059,  ...,  0.0264, -5.1953,  1.9639],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.2155e-02,  2.9724e-02,  2.8992e-04,  ..., -4.0894e-03,
         -1.5656e-02,  2.3834e-02],
        [ 5.6992e-03,  5.9937e-02,  2.1591e-02,  ..., -1.5961e-02,
         -2.6970e-03, -8.7280e-03],
        [ 3.8147e-05,  1.9714e-02,  6.7871e-02,  ...,  8.0414e-03,
         -1.2493e-03, -1.3611e-02],
        ...,
        [ 2.0004e-02,  1.4084e-02,  2.1484e-02,  ...,  5.8197e-02,
          1.7838e-02, -3.4058e-02],
        [ 2.6932e-02,  6.5689e-03, -4.0970e-03,  ...,  1.4481e-02,
          6.2927e-02, -4.1275e-03],
        [ 5.1041e-03, -8.1444e-04, -6.7215e-03,  ..., -2.4185e-02,
         -9.8572e-03,  4.5288e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.8984, -3.3457,  2.5430,  ...,  0.0396, -5.4141,  1.6592]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 15:26:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A word is a member of a paragraph
A cow is a member of a herd
A flower is a member of a bouquet
A student is a member of a class
A listener is a member of a audience
A calf is a member of a cattle
A employee is a member of a staff
A goose is a member of a
2024-07-29 15:26:37 root INFO     total operator prediction time: 1076.3774921894073 seconds
2024-07-29 15:26:37 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on antonyms - binary
2024-07-29 15:26:37 root INFO     building operator antonyms - binary
2024-07-29 15:26:38 root INFO     [order_1_approx] starting weight calculation for The opposite of over is under
The opposite of up is down
The opposite of climb is descend
The opposite of under is over
The opposite of occupied is vacant
The opposite of inhale is exhale
The opposite of south is north
The opposite of downslope is
2024-07-29 15:26:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 15:28:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2900,  0.2344, -0.1781,  ..., -0.2452, -0.9116, -0.4077],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4512, -1.2051, -2.8438,  ..., -2.3750, -1.9492, -3.6289],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.0435e-02, -5.6534e-03, -4.0436e-03,  ...,  2.2827e-02,
         -2.7580e-03,  1.3565e-02],
        [ 4.0932e-03,  9.0332e-02,  1.0178e-02,  ...,  1.5945e-02,
         -4.7088e-05,  3.0696e-05],
        [ 1.0536e-02, -9.7198e-03, -1.4095e-03,  ...,  2.9510e-02,
         -1.7838e-02,  1.4069e-02],
        ...,
        [-2.1667e-02,  1.4778e-02,  1.3474e-02,  ...,  7.9224e-02,
         -7.3776e-03,  3.1738e-02],
        [ 1.0918e-02,  2.7420e-02,  5.2185e-03,  ..., -4.5471e-03,
          9.0942e-02,  1.3535e-02],
        [ 2.1942e-02,  1.0323e-02,  2.1667e-02,  ..., -1.0872e-03,
          1.5060e-02,  2.7161e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0693, -1.2490, -2.5508,  ..., -1.8896, -2.0273, -3.7773]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 15:28:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of over is under
The opposite of up is down
The opposite of climb is descend
The opposite of under is over
The opposite of occupied is vacant
The opposite of inhale is exhale
The opposite of south is north
The opposite of downslope is
2024-07-29 15:28:50 root INFO     [order_1_approx] starting weight calculation for The opposite of under is over
The opposite of occupied is vacant
The opposite of downslope is upslope
The opposite of up is down
The opposite of south is north
The opposite of over is under
The opposite of climb is descend
The opposite of inhale is
2024-07-29 15:28:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 15:31:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1973, -0.0468, -0.4275,  ..., -0.0315, -0.2068, -0.0428],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1074, -1.9346,  2.6016,  ..., -2.2891,  0.3555,  0.7832],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0411, -0.0223,  0.0174,  ...,  0.0177,  0.0121,  0.0146],
        [ 0.0055,  0.0633, -0.0179,  ..., -0.0087,  0.0211, -0.0004],
        [ 0.0097, -0.0075,  0.0014,  ..., -0.0177, -0.0212, -0.0302],
        ...,
        [-0.0116, -0.0090,  0.0095,  ...,  0.0208,  0.0182,  0.0050],
        [ 0.0008,  0.0130,  0.0096,  ...,  0.0139,  0.0108,  0.0152],
        [-0.0172,  0.0007,  0.0004,  ..., -0.0126,  0.0011,  0.0246]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2070, -1.9961,  2.3301,  ..., -2.1230,  0.2173,  0.7261]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 15:31:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of under is over
The opposite of occupied is vacant
The opposite of downslope is upslope
The opposite of up is down
The opposite of south is north
The opposite of over is under
The opposite of climb is descend
The opposite of inhale is
2024-07-29 15:31:02 root INFO     [order_1_approx] starting weight calculation for The opposite of downslope is upslope
The opposite of climb is descend
The opposite of south is north
The opposite of inhale is exhale
The opposite of under is over
The opposite of up is down
The opposite of over is under
The opposite of occupied is
2024-07-29 15:31:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 15:33:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0463,  0.0927, -0.4363,  ...,  0.0938, -0.3586,  0.2603],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3345, -1.9199,  0.5156,  ...,  0.4841, -2.2031, -0.8496],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0795,  0.0169, -0.0079,  ...,  0.0197,  0.0156,  0.0018],
        [ 0.0172,  0.0518, -0.0222,  ...,  0.0192,  0.0498, -0.0006],
        [-0.0067, -0.0048,  0.0273,  ..., -0.0231, -0.0089, -0.0030],
        ...,
        [ 0.0042,  0.0203, -0.0002,  ...,  0.0253, -0.0081,  0.0106],
        [ 0.0249, -0.0249,  0.0384,  ..., -0.0159,  0.0350,  0.0049],
        [-0.0024,  0.0348,  0.0013,  ..., -0.0149,  0.0006,  0.0704]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0752, -2.1113,  0.0664,  ...,  0.6924, -1.4570, -1.1133]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 15:33:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of downslope is upslope
The opposite of climb is descend
The opposite of south is north
The opposite of inhale is exhale
The opposite of under is over
The opposite of up is down
The opposite of over is under
The opposite of occupied is
2024-07-29 15:33:15 root INFO     [order_1_approx] starting weight calculation for The opposite of downslope is upslope
The opposite of climb is descend
The opposite of south is north
The opposite of inhale is exhale
The opposite of under is over
The opposite of occupied is vacant
The opposite of over is under
The opposite of up is
2024-07-29 15:33:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 15:35:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1896, -0.2874,  0.1466,  ..., -0.0934, -0.2024, -0.2749],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0078, -3.8262,  1.9922,  ..., -3.3945, -0.1040, -3.0684],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.8807e-02,  5.0621e-03,  2.5589e-02,  ...,  4.0197e-04,
          4.8981e-03, -5.0659e-03],
        [ 6.4278e-03,  7.4158e-02, -1.4458e-02,  ...,  3.4008e-03,
          4.2801e-03,  1.0292e-02],
        [-1.5160e-02,  2.4734e-02,  1.2817e-02,  ...,  5.0888e-03,
         -8.4877e-05, -1.4809e-02],
        ...,
        [ 8.2474e-03,  6.4278e-03, -3.9368e-03,  ...,  6.9763e-02,
          1.1795e-02, -2.8122e-02],
        [ 4.1351e-03,  1.2161e-02, -1.0849e-02,  ..., -2.2583e-02,
          5.7922e-02,  4.3411e-03],
        [ 1.0506e-02, -8.8120e-03,  1.4679e-02,  ...,  5.3329e-03,
         -9.9564e-03,  3.4546e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9023, -3.1953,  1.6016,  ..., -3.4043, -0.5327, -3.2422]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 15:35:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of downslope is upslope
The opposite of climb is descend
The opposite of south is north
The opposite of inhale is exhale
The opposite of under is over
The opposite of occupied is vacant
The opposite of over is under
The opposite of up is
2024-07-29 15:35:29 root INFO     [order_1_approx] starting weight calculation for The opposite of south is north
The opposite of up is down
The opposite of downslope is upslope
The opposite of occupied is vacant
The opposite of inhale is exhale
The opposite of under is over
The opposite of climb is descend
The opposite of over is
2024-07-29 15:35:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 15:37:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4055, -0.1733, -0.2051,  ..., -0.4456, -0.0234, -0.0875],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7500, -1.6367,  1.3457,  ..., -2.3887,  0.8062, -0.1289],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0555, -0.0064,  0.0075,  ...,  0.0139,  0.0137, -0.0022],
        [ 0.0061,  0.0501, -0.0325,  ...,  0.0075,  0.0105,  0.0259],
        [ 0.0081, -0.0053,  0.0220,  ..., -0.0104, -0.0133, -0.0249],
        ...,
        [-0.0017,  0.0083, -0.0012,  ...,  0.0597,  0.0133, -0.0218],
        [-0.0077, -0.0323,  0.0521,  ..., -0.0260,  0.0108,  0.0552],
        [-0.0026, -0.0096,  0.0232,  ...,  0.0115,  0.0105,  0.0316]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9512, -1.5635,  1.4326,  ..., -2.1992, -0.1338, -0.4050]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 15:37:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of south is north
The opposite of up is down
The opposite of downslope is upslope
The opposite of occupied is vacant
The opposite of inhale is exhale
The opposite of under is over
The opposite of climb is descend
The opposite of over is
2024-07-29 15:37:43 root INFO     [order_1_approx] starting weight calculation for The opposite of under is over
The opposite of over is under
The opposite of downslope is upslope
The opposite of up is down
The opposite of occupied is vacant
The opposite of climb is descend
The opposite of inhale is exhale
The opposite of south is
2024-07-29 15:37:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 15:39:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0178, -0.0585,  0.0526,  ...,  0.3098,  0.0706, -0.0983],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6562, -3.8262,  0.7632,  ..., -1.1816,  0.6304, -3.8984],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.9225e-02, -3.4485e-02,  9.5367e-05,  ...,  4.7150e-03,
          1.7395e-02, -9.2468e-03],
        [ 9.7351e-03,  2.7512e-02,  1.0612e-02,  ..., -8.9035e-03,
          1.7181e-02,  9.5215e-03],
        [-2.3880e-02, -2.1820e-03,  2.2125e-02,  ...,  2.7283e-02,
         -5.0888e-03,  1.8616e-02],
        ...,
        [ 8.5373e-03, -9.6207e-03,  1.2733e-02,  ...,  3.9551e-02,
          1.2642e-02, -3.5095e-02],
        [-1.2398e-03, -2.0859e-02, -2.3117e-03,  ...,  1.0132e-02,
          5.6519e-02,  1.3138e-02],
        [-1.5707e-03,  1.2924e-02,  1.5884e-02,  ..., -5.7487e-03,
          1.6693e-02,  3.7415e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0703, -4.2109,  0.7681,  ..., -1.1494,  0.5996, -3.6016]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 15:39:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of under is over
The opposite of over is under
The opposite of downslope is upslope
The opposite of up is down
The opposite of occupied is vacant
The opposite of climb is descend
The opposite of inhale is exhale
The opposite of south is
2024-07-29 15:39:58 root INFO     [order_1_approx] starting weight calculation for The opposite of downslope is upslope
The opposite of south is north
The opposite of up is down
The opposite of inhale is exhale
The opposite of over is under
The opposite of climb is descend
The opposite of occupied is vacant
The opposite of under is
2024-07-29 15:39:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 15:42:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1157,  0.0840, -0.1587,  ..., -0.5308,  0.2102, -0.2188],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.3008, -4.3359,  2.1934,  ..., -1.3057,  0.8091, -1.2656],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0128, -0.0316,  0.0257,  ...,  0.0234,  0.0187, -0.0120],
        [ 0.0089,  0.0521, -0.0267,  ...,  0.0139,  0.0177,  0.0070],
        [-0.0154,  0.0081, -0.0146,  ..., -0.0183, -0.0098,  0.0076],
        ...,
        [-0.0172,  0.0197,  0.0207,  ...,  0.0175,  0.0063, -0.0435],
        [-0.0009, -0.0205,  0.0439,  ..., -0.0223, -0.0147,  0.0058],
        [-0.0141,  0.0137, -0.0045,  ...,  0.0092,  0.0197,  0.0372]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.2539, -3.6152,  2.1797,  ..., -1.4199, -0.2290, -1.1719]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 15:42:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of downslope is upslope
The opposite of south is north
The opposite of up is down
The opposite of inhale is exhale
The opposite of over is under
The opposite of climb is descend
The opposite of occupied is vacant
The opposite of under is
2024-07-29 15:42:16 root INFO     [order_1_approx] starting weight calculation for The opposite of downslope is upslope
The opposite of inhale is exhale
The opposite of south is north
The opposite of occupied is vacant
The opposite of over is under
The opposite of under is over
The opposite of up is down
The opposite of climb is
2024-07-29 15:42:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 15:44:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2482,  0.1141,  0.3389,  ..., -0.3784, -0.6729,  0.2056],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0469, -1.1377,  2.6191,  ..., -0.5742, -3.4453, -1.0312],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0423, -0.0077, -0.0049,  ...,  0.0208,  0.0037, -0.0233],
        [ 0.0108,  0.0517, -0.0046,  ..., -0.0010,  0.0081, -0.0022],
        [-0.0169, -0.0060, -0.0108,  ..., -0.0132, -0.0125, -0.0043],
        ...,
        [-0.0111,  0.0221,  0.0012,  ...,  0.0207, -0.0029, -0.0057],
        [-0.0002,  0.0056, -0.0096,  ...,  0.0137,  0.0306,  0.0304],
        [ 0.0001,  0.0119,  0.0132,  ..., -0.0093,  0.0114,  0.0280]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5117, -1.1279,  2.6113,  ..., -0.7866, -3.5254, -1.1855]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 15:44:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of downslope is upslope
The opposite of inhale is exhale
The opposite of south is north
The opposite of occupied is vacant
The opposite of over is under
The opposite of under is over
The opposite of up is down
The opposite of climb is
2024-07-29 15:44:29 root INFO     total operator prediction time: 1072.1072781085968 seconds
2024-07-29 15:44:29 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hyponyms - misc
2024-07-29 15:44:29 root INFO     building operator hyponyms - misc
2024-07-29 15:44:29 root INFO     [order_1_approx] starting weight calculation for A more specific term for a emotion is anger
A more specific term for a guitar is ukulele
A more specific term for a container is bag
A more specific term for a church is chapel
A more specific term for a trousers is jeans
A more specific term for a collar is choker
A more specific term for a boat is ferry
A more specific term for a candy is
2024-07-29 15:44:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 15:46:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0939, -0.2440, -0.3789,  ..., -0.0345, -0.0357, -0.5093],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0820, -9.6797, -1.3828,  ..., -2.4434, -1.6582,  5.2578],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0693, -0.0045,  0.0048,  ...,  0.0180,  0.0057,  0.0145],
        [-0.0013,  0.0548,  0.0034,  ...,  0.0074,  0.0155, -0.0175],
        [ 0.0020, -0.0010,  0.0496,  ...,  0.0120, -0.0027, -0.0061],
        ...,
        [-0.0043,  0.0084, -0.0144,  ...,  0.0669, -0.0099, -0.0145],
        [-0.0199,  0.0064, -0.0045,  ..., -0.0026,  0.0471, -0.0169],
        [-0.0020,  0.0074, -0.0101,  ..., -0.0269,  0.0181,  0.0768]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8145, -9.5312, -1.6875,  ..., -2.3828, -1.8721,  5.3594]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 15:46:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a emotion is anger
A more specific term for a guitar is ukulele
A more specific term for a container is bag
A more specific term for a church is chapel
A more specific term for a trousers is jeans
A more specific term for a collar is choker
A more specific term for a boat is ferry
A more specific term for a candy is
2024-07-29 15:46:42 root INFO     [order_1_approx] starting weight calculation for A more specific term for a collar is choker
A more specific term for a guitar is ukulele
A more specific term for a trousers is jeans
A more specific term for a boat is ferry
A more specific term for a candy is lollipop
A more specific term for a church is chapel
A more specific term for a emotion is anger
A more specific term for a container is
2024-07-29 15:46:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 15:48:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1428, -0.7949, -0.5640,  ...,  0.7148, -0.1415, -0.3428],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.5312, -4.8594, -0.9756,  ...,  0.3457,  0.4360, -0.0049],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0780, -0.0080, -0.0191,  ...,  0.0243, -0.0046,  0.0134],
        [ 0.0133,  0.0388, -0.0008,  ..., -0.0027,  0.0229, -0.0006],
        [ 0.0168,  0.0050,  0.0959,  ...,  0.0303, -0.0133, -0.0017],
        ...,
        [ 0.0080,  0.0093,  0.0148,  ...,  0.0662, -0.0060, -0.0074],
        [-0.0161, -0.0110, -0.0047,  ...,  0.0026,  0.0325, -0.0013],
        [-0.0129,  0.0075, -0.0014,  ..., -0.0135, -0.0121,  0.0869]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.3828e+00, -4.9727e+00, -4.7876e-01,  ...,  5.7715e-01,
          4.3945e-01,  5.7983e-04]], device='cuda:1', dtype=torch.float16,
       grad_fn=<SubBackward0>) 

                    
2024-07-29 15:48:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a collar is choker
A more specific term for a guitar is ukulele
A more specific term for a trousers is jeans
A more specific term for a boat is ferry
A more specific term for a candy is lollipop
A more specific term for a church is chapel
A more specific term for a emotion is anger
A more specific term for a container is
2024-07-29 15:48:54 root INFO     [order_1_approx] starting weight calculation for A more specific term for a trousers is jeans
A more specific term for a church is chapel
A more specific term for a container is bag
A more specific term for a candy is lollipop
A more specific term for a boat is ferry
A more specific term for a guitar is ukulele
A more specific term for a collar is choker
A more specific term for a emotion is
2024-07-29 15:48:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 15:51:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0837, -0.2827,  0.0694,  ...,  0.2382, -0.3750, -0.0793],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0547, -3.2070,  1.3184,  ...,  1.4395, -1.9160, -1.4531],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.4880e-02,  1.2726e-02, -1.4893e-02,  ..., -1.0178e-02,
          5.4245e-03,  1.2909e-02],
        [ 1.7929e-03,  5.4871e-02,  1.6422e-03,  ...,  9.7885e-03,
          1.4961e-02, -3.6716e-03],
        [-1.8158e-03, -4.9057e-03,  3.3142e-02,  ...,  6.6757e-03,
         -2.7740e-02, -1.1505e-02],
        ...,
        [ 3.5381e-03,  8.9264e-03, -4.2572e-03,  ...,  4.9835e-02,
         -1.4305e-05, -5.2681e-03],
        [-1.6541e-02,  1.1597e-02, -4.8370e-03,  ..., -9.8495e-03,
          3.9764e-02,  6.1493e-03],
        [-2.3079e-03, -9.0027e-03, -1.2909e-02,  ...,  1.6800e-02,
         -6.1302e-03,  4.3671e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6523, -2.9570,  0.8369,  ...,  1.4268, -2.0410, -1.5703]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 15:51:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a trousers is jeans
A more specific term for a church is chapel
A more specific term for a container is bag
A more specific term for a candy is lollipop
A more specific term for a boat is ferry
A more specific term for a guitar is ukulele
A more specific term for a collar is choker
A more specific term for a emotion is
2024-07-29 15:51:07 root INFO     [order_1_approx] starting weight calculation for A more specific term for a emotion is anger
A more specific term for a candy is lollipop
A more specific term for a collar is choker
A more specific term for a container is bag
A more specific term for a trousers is jeans
A more specific term for a boat is ferry
A more specific term for a guitar is ukulele
A more specific term for a church is
2024-07-29 15:51:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 15:53:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4084, -0.0906, -0.2137,  ...,  0.3730, -0.3960,  0.0375],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0107, -7.5742,  4.7539,  ..., -2.6875, -0.4519,  0.4639],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0606, -0.0050,  0.0121,  ...,  0.0056, -0.0041, -0.0168],
        [-0.0138,  0.0655, -0.0094,  ..., -0.0010,  0.0144, -0.0105],
        [ 0.0246,  0.0060,  0.0671,  ..., -0.0190, -0.0034, -0.0005],
        ...,
        [-0.0021,  0.0121, -0.0080,  ...,  0.0663, -0.0030, -0.0158],
        [-0.0192, -0.0197, -0.0107,  ...,  0.0061,  0.0648, -0.0143],
        [-0.0177, -0.0017, -0.0210,  ..., -0.0123,  0.0045,  0.0723]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6865, -7.2539,  3.9219,  ..., -2.2441, -0.3335,  0.5527]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 15:53:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a emotion is anger
A more specific term for a candy is lollipop
A more specific term for a collar is choker
A more specific term for a container is bag
A more specific term for a trousers is jeans
A more specific term for a boat is ferry
A more specific term for a guitar is ukulele
A more specific term for a church is
2024-07-29 15:53:17 root INFO     [order_1_approx] starting weight calculation for A more specific term for a trousers is jeans
A more specific term for a candy is lollipop
A more specific term for a church is chapel
A more specific term for a collar is choker
A more specific term for a boat is ferry
A more specific term for a emotion is anger
A more specific term for a container is bag
A more specific term for a guitar is
2024-07-29 15:53:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 15:55:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1993,  0.2231,  0.0967,  ...,  0.1231, -0.3203, -0.1345],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3821, -6.2344, -0.7920,  ..., -0.6973, -0.1064, -3.6543],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0831,  0.0034, -0.0036,  ...,  0.0027,  0.0141,  0.0096],
        [-0.0118,  0.0685, -0.0078,  ...,  0.0105, -0.0032, -0.0340],
        [ 0.0219,  0.0070,  0.0822,  ..., -0.0009,  0.0012,  0.0099],
        ...,
        [ 0.0103,  0.0108, -0.0046,  ...,  0.0862,  0.0033, -0.0027],
        [-0.0200, -0.0131,  0.0222,  ...,  0.0157,  0.0463, -0.0195],
        [ 0.0087,  0.0165, -0.0228,  ..., -0.0225,  0.0080,  0.0637]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7617, -6.1680, -0.6421,  ..., -0.8037,  0.1213, -3.2129]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 15:55:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a trousers is jeans
A more specific term for a candy is lollipop
A more specific term for a church is chapel
A more specific term for a collar is choker
A more specific term for a boat is ferry
A more specific term for a emotion is anger
A more specific term for a container is bag
A more specific term for a guitar is
2024-07-29 15:55:29 root INFO     [order_1_approx] starting weight calculation for A more specific term for a container is bag
A more specific term for a trousers is jeans
A more specific term for a church is chapel
A more specific term for a boat is ferry
A more specific term for a candy is lollipop
A more specific term for a emotion is anger
A more specific term for a guitar is ukulele
A more specific term for a collar is
2024-07-29 15:55:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 15:57:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2886, -0.2925, -0.3345,  ...,  0.2274, -0.3330, -0.1153],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0684, -4.9062, -1.4072,  ...,  3.8770,  4.5195,  0.5527],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0787,  0.0216, -0.0081,  ..., -0.0022,  0.0191, -0.0045],
        [-0.0155,  0.0892,  0.0084,  ...,  0.0413,  0.0056, -0.0145],
        [ 0.0412, -0.0255,  0.0657,  ..., -0.0119, -0.0346,  0.0122],
        ...,
        [ 0.0022,  0.0207,  0.0075,  ...,  0.0673, -0.0181, -0.0225],
        [-0.0057,  0.0067, -0.0146,  ..., -0.0096,  0.1217,  0.0210],
        [-0.0134,  0.0402, -0.0073,  ..., -0.0327, -0.0258,  0.0768]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8701, -5.1328, -1.3184,  ...,  4.0234,  4.3398,  0.6392]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 15:57:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a container is bag
A more specific term for a trousers is jeans
A more specific term for a church is chapel
A more specific term for a boat is ferry
A more specific term for a candy is lollipop
A more specific term for a emotion is anger
A more specific term for a guitar is ukulele
A more specific term for a collar is
2024-07-29 15:57:41 root INFO     [order_1_approx] starting weight calculation for A more specific term for a emotion is anger
A more specific term for a trousers is jeans
A more specific term for a container is bag
A more specific term for a candy is lollipop
A more specific term for a collar is choker
A more specific term for a guitar is ukulele
A more specific term for a church is chapel
A more specific term for a boat is
2024-07-29 15:57:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 15:59:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3979, -0.2397,  0.1580,  ..., -0.1816, -0.2756,  0.1666],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3242, -5.8281, -0.4543,  ...,  0.7373,  0.1338,  0.3271],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0950,  0.0226,  0.0043,  ..., -0.0035,  0.0217,  0.0083],
        [ 0.0078,  0.0746, -0.0189,  ...,  0.0070, -0.0045, -0.0038],
        [-0.0042,  0.0014,  0.0961,  ...,  0.0013, -0.0142,  0.0050],
        ...,
        [ 0.0075,  0.0185, -0.0104,  ...,  0.0537,  0.0086, -0.0134],
        [-0.0154, -0.0072, -0.0087,  ...,  0.0066,  0.0419, -0.0077],
        [ 0.0076,  0.0126, -0.0244,  ..., -0.0199, -0.0245,  0.0541]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-4.4482e-01, -5.8984e+00, -4.9048e-01,  ...,  1.0938e+00,
          3.0518e-03,  2.7026e-01]], device='cuda:1', dtype=torch.float16,
       grad_fn=<SubBackward0>) 

                    
2024-07-29 16:00:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a emotion is anger
A more specific term for a trousers is jeans
A more specific term for a container is bag
A more specific term for a candy is lollipop
A more specific term for a collar is choker
A more specific term for a guitar is ukulele
A more specific term for a church is chapel
A more specific term for a boat is
2024-07-29 16:00:06 root INFO     [order_1_approx] starting weight calculation for A more specific term for a collar is choker
A more specific term for a container is bag
A more specific term for a boat is ferry
A more specific term for a emotion is anger
A more specific term for a church is chapel
A more specific term for a guitar is ukulele
A more specific term for a candy is lollipop
A more specific term for a trousers is
2024-07-29 16:00:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 16:02:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0177, -0.3115, -0.4375,  ...,  0.5962, -0.4631, -0.2378],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1094, -7.2656, -0.1226,  ...,  1.2070,  0.2651,  1.5850],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0414, -0.0003,  0.0064,  ...,  0.0110,  0.0051, -0.0098],
        [-0.0115,  0.0388,  0.0022,  ..., -0.0026,  0.0103, -0.0036],
        [ 0.0070, -0.0157,  0.0326,  ..., -0.0122, -0.0052, -0.0104],
        ...,
        [ 0.0047, -0.0015, -0.0021,  ...,  0.0545,  0.0057, -0.0021],
        [-0.0079, -0.0071, -0.0103,  ..., -0.0046,  0.0372, -0.0076],
        [-0.0046, -0.0043,  0.0075,  ..., -0.0060,  0.0011,  0.0268]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9766, -7.0078, -0.3215,  ...,  1.2031,  0.3181,  1.5117]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 16:02:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a collar is choker
A more specific term for a container is bag
A more specific term for a boat is ferry
A more specific term for a emotion is anger
A more specific term for a church is chapel
A more specific term for a guitar is ukulele
A more specific term for a candy is lollipop
A more specific term for a trousers is
2024-07-29 16:02:18 root INFO     total operator prediction time: 1069.2643585205078 seconds
2024-07-29 16:02:19 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hypernyms - animals
2024-07-29 16:02:19 root INFO     building operator hypernyms - animals
2024-07-29 16:02:19 root INFO     [order_1_approx] starting weight calculation for The eagle falls into the category of raptor
The lion falls into the category of feline
The gibbon falls into the category of primate
The mouse falls into the category of rodent
The porcupine falls into the category of rodent
The wolf falls into the category of canine
The goose falls into the category of fowl
The orangutan falls into the category of
2024-07-29 16:02:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 16:04:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5532, -0.4678, -0.0804,  ..., -0.0070, -0.7578,  0.0194],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3789, -4.3203,  0.6445,  ..., -4.2188, -7.2031,  1.6660],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0394, -0.0006,  0.0024,  ..., -0.0017, -0.0119, -0.0075],
        [ 0.0226,  0.0132,  0.0094,  ..., -0.0050,  0.0006, -0.0190],
        [-0.0146,  0.0002,  0.0192,  ...,  0.0047,  0.0100, -0.0077],
        ...,
        [ 0.0154,  0.0067,  0.0101,  ...,  0.0167,  0.0069,  0.0059],
        [-0.0015, -0.0175, -0.0105,  ..., -0.0049,  0.0337,  0.0001],
        [ 0.0110, -0.0016,  0.0031,  ..., -0.0078, -0.0054,  0.0241]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4473, -3.9922,  0.5229,  ..., -4.2422, -7.3086,  1.7568]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 16:04:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The eagle falls into the category of raptor
The lion falls into the category of feline
The gibbon falls into the category of primate
The mouse falls into the category of rodent
The porcupine falls into the category of rodent
The wolf falls into the category of canine
The goose falls into the category of fowl
The orangutan falls into the category of
2024-07-29 16:04:31 root INFO     [order_1_approx] starting weight calculation for The mouse falls into the category of rodent
The goose falls into the category of fowl
The wolf falls into the category of canine
The orangutan falls into the category of primate
The lion falls into the category of feline
The eagle falls into the category of raptor
The gibbon falls into the category of primate
The porcupine falls into the category of
2024-07-29 16:04:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 16:06:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1714, -0.5298,  0.1926,  ...,  0.1208, -0.6328,  0.0129],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3574, -2.5312,  0.8086,  ..., -2.3750, -4.6562, -1.0674],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.1656e-02, -1.1948e-02, -8.2779e-03,  ..., -1.7319e-02,
         -1.1955e-02, -7.4158e-03],
        [ 5.5122e-04,  1.9623e-02, -4.9591e-05,  ...,  6.7825e-03,
          8.3847e-03, -2.1927e-02],
        [ 2.5578e-03,  1.2100e-02,  3.2532e-02,  ..., -5.2452e-03,
         -5.4398e-03, -8.9264e-03],
        ...,
        [ 1.7349e-02,  1.4639e-03,  4.2953e-03,  ...,  1.9974e-02,
          3.6545e-03, -7.6485e-04],
        [-6.8130e-03, -1.6205e-02, -4.0588e-03,  ..., -2.0233e-02,
          4.9622e-02, -7.6637e-03],
        [-5.5122e-03,  8.7433e-03,  4.0436e-03,  ..., -5.6915e-03,
          5.3883e-05,  3.2562e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1689, -2.5176,  0.6387,  ..., -2.6289, -4.2891, -0.7798]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 16:06:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The mouse falls into the category of rodent
The goose falls into the category of fowl
The wolf falls into the category of canine
The orangutan falls into the category of primate
The lion falls into the category of feline
The eagle falls into the category of raptor
The gibbon falls into the category of primate
The porcupine falls into the category of
2024-07-29 16:06:43 root INFO     [order_1_approx] starting weight calculation for The wolf falls into the category of canine
The orangutan falls into the category of primate
The eagle falls into the category of raptor
The goose falls into the category of fowl
The gibbon falls into the category of primate
The mouse falls into the category of rodent
The porcupine falls into the category of rodent
The lion falls into the category of
2024-07-29 16:06:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 16:08:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4209, -0.2695,  0.1567,  ...,  0.4482, -0.6382, -0.1294],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1929, -6.8203, -0.8398,  ..., -2.7812, -7.0859, -0.9932],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0379, -0.0018, -0.0252,  ..., -0.0100, -0.0154,  0.0039],
        [ 0.0240,  0.0354,  0.0232,  ..., -0.0111, -0.0056, -0.0143],
        [-0.0079,  0.0072,  0.0472,  ...,  0.0036,  0.0089, -0.0043],
        ...,
        [ 0.0069,  0.0031,  0.0203,  ...,  0.0431, -0.0039, -0.0076],
        [ 0.0027, -0.0236, -0.0059,  ...,  0.0079,  0.0522, -0.0002],
        [-0.0077,  0.0097, -0.0209,  ..., -0.0138, -0.0061,  0.0498]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2590, -6.6992, -0.8862,  ..., -2.4648, -6.9688, -0.7236]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 16:08:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The wolf falls into the category of canine
The orangutan falls into the category of primate
The eagle falls into the category of raptor
The goose falls into the category of fowl
The gibbon falls into the category of primate
The mouse falls into the category of rodent
The porcupine falls into the category of rodent
The lion falls into the category of
2024-07-29 16:08:57 root INFO     [order_1_approx] starting weight calculation for The porcupine falls into the category of rodent
The eagle falls into the category of raptor
The gibbon falls into the category of primate
The lion falls into the category of feline
The orangutan falls into the category of primate
The mouse falls into the category of rodent
The goose falls into the category of fowl
The wolf falls into the category of
2024-07-29 16:08:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 16:11:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4329, -0.0131,  0.2450,  ...,  0.5063, -0.3040, -0.0581],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2861, -5.2734,  1.0117,  ..., -4.9648, -5.0156,  0.9287],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0334,  0.0041, -0.0030,  ..., -0.0163, -0.0195,  0.0031],
        [ 0.0224,  0.0231,  0.0242,  ..., -0.0082, -0.0073, -0.0188],
        [ 0.0004,  0.0137,  0.0402,  ..., -0.0005,  0.0111, -0.0043],
        ...,
        [ 0.0025,  0.0164,  0.0125,  ...,  0.0130,  0.0133,  0.0151],
        [ 0.0078, -0.0291, -0.0069,  ...,  0.0033,  0.0405, -0.0119],
        [ 0.0087, -0.0091, -0.0026,  ..., -0.0104, -0.0170,  0.0174]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0225, -5.4023,  1.0195,  ..., -4.5430, -5.6758,  0.8721]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 16:11:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The porcupine falls into the category of rodent
The eagle falls into the category of raptor
The gibbon falls into the category of primate
The lion falls into the category of feline
The orangutan falls into the category of primate
The mouse falls into the category of rodent
The goose falls into the category of fowl
The wolf falls into the category of
2024-07-29 16:11:10 root INFO     [order_1_approx] starting weight calculation for The orangutan falls into the category of primate
The wolf falls into the category of canine
The eagle falls into the category of raptor
The lion falls into the category of feline
The porcupine falls into the category of rodent
The gibbon falls into the category of primate
The mouse falls into the category of rodent
The goose falls into the category of
2024-07-29 16:11:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 16:13:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4819, -0.1235,  0.1220,  ...,  0.5317, -0.1353, -0.0677],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3887, -2.9297,  3.9219,  ..., -2.5566, -9.7109,  1.9619],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0449,  0.0096, -0.0187,  ..., -0.0058, -0.0268, -0.0115],
        [ 0.0046,  0.0510,  0.0167,  ...,  0.0157, -0.0027, -0.0299],
        [-0.0040,  0.0061,  0.0526,  ...,  0.0011, -0.0028,  0.0022],
        ...,
        [ 0.0415, -0.0019,  0.0237,  ...,  0.0315,  0.0125,  0.0029],
        [-0.0135,  0.0121, -0.0162,  ...,  0.0132,  0.0598, -0.0073],
        [ 0.0155, -0.0071, -0.0063,  ..., -0.0276,  0.0007,  0.0623]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8633, -3.2422,  3.2637,  ..., -2.7500, -9.7500,  2.2051]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 16:13:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The orangutan falls into the category of primate
The wolf falls into the category of canine
The eagle falls into the category of raptor
The lion falls into the category of feline
The porcupine falls into the category of rodent
The gibbon falls into the category of primate
The mouse falls into the category of rodent
The goose falls into the category of
2024-07-29 16:13:22 root INFO     [order_1_approx] starting weight calculation for The lion falls into the category of feline
The mouse falls into the category of rodent
The eagle falls into the category of raptor
The orangutan falls into the category of primate
The porcupine falls into the category of rodent
The wolf falls into the category of canine
The goose falls into the category of fowl
The gibbon falls into the category of
2024-07-29 16:13:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 16:15:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4268, -0.4321,  0.5615,  ...,  0.2284, -1.1396,  0.7168],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9609, -3.9141,  1.4561,  ..., -4.0156, -7.5938,  0.8501],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0566, -0.0100, -0.0044,  ..., -0.0272, -0.0183, -0.0075],
        [ 0.0007,  0.0384, -0.0093,  ...,  0.0047,  0.0122, -0.0147],
        [-0.0021,  0.0087,  0.0470,  ...,  0.0027,  0.0084, -0.0163],
        ...,
        [ 0.0147,  0.0148, -0.0121,  ...,  0.0358,  0.0079,  0.0023],
        [-0.0031, -0.0168, -0.0019,  ...,  0.0054,  0.0387, -0.0155],
        [-0.0061, -0.0054, -0.0141,  ..., -0.0105, -0.0011,  0.0381]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2705, -4.2188,  0.9434,  ..., -3.7617, -8.3125,  1.0176]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 16:15:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The lion falls into the category of feline
The mouse falls into the category of rodent
The eagle falls into the category of raptor
The orangutan falls into the category of primate
The porcupine falls into the category of rodent
The wolf falls into the category of canine
The goose falls into the category of fowl
The gibbon falls into the category of
2024-07-29 16:15:40 root INFO     [order_1_approx] starting weight calculation for The wolf falls into the category of canine
The lion falls into the category of feline
The goose falls into the category of fowl
The orangutan falls into the category of primate
The gibbon falls into the category of primate
The mouse falls into the category of rodent
The porcupine falls into the category of rodent
The eagle falls into the category of
2024-07-29 16:15:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 16:17:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4819, -0.3455, -0.2014,  ...,  0.6045, -0.4238,  0.1350],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1973, -2.1387,  2.0820,  ..., -1.1641, -6.6094,  0.8213],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0558, -0.0094, -0.0144,  ..., -0.0020, -0.0107, -0.0027],
        [ 0.0073,  0.0300,  0.0054,  ..., -0.0035,  0.0038, -0.0097],
        [ 0.0034,  0.0093,  0.0478,  ...,  0.0048,  0.0010, -0.0151],
        ...,
        [ 0.0154, -0.0079,  0.0103,  ...,  0.0407, -0.0017,  0.0118],
        [ 0.0094, -0.0012, -0.0060,  ...,  0.0161,  0.0518, -0.0083],
        [ 0.0023, -0.0082,  0.0019,  ..., -0.0115, -0.0185,  0.0407]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3691, -2.3262,  1.5117,  ..., -0.9414, -6.8867,  0.9771]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 16:17:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The wolf falls into the category of canine
The lion falls into the category of feline
The goose falls into the category of fowl
The orangutan falls into the category of primate
The gibbon falls into the category of primate
The mouse falls into the category of rodent
The porcupine falls into the category of rodent
The eagle falls into the category of
2024-07-29 16:17:49 root INFO     [order_1_approx] starting weight calculation for The lion falls into the category of feline
The eagle falls into the category of raptor
The gibbon falls into the category of primate
The porcupine falls into the category of rodent
The goose falls into the category of fowl
The orangutan falls into the category of primate
The wolf falls into the category of canine
The mouse falls into the category of
2024-07-29 16:17:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 16:19:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3130, -0.1836,  0.5938,  ...,  0.1136, -0.3079, -0.0525],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5791, -3.7227,  2.1875,  ..., -4.3008, -6.1992, -0.3306],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0477, -0.0248,  0.0046,  ..., -0.0120, -0.0244, -0.0067],
        [ 0.0137,  0.0386,  0.0313,  ..., -0.0196, -0.0053, -0.0247],
        [ 0.0170,  0.0059,  0.0409,  ...,  0.0164,  0.0164, -0.0017],
        ...,
        [ 0.0158,  0.0079,  0.0142,  ...,  0.0370,  0.0003,  0.0065],
        [-0.0098,  0.0089, -0.0222,  ..., -0.0105,  0.0583,  0.0081],
        [-0.0138, -0.0062,  0.0047,  ..., -0.0280, -0.0271,  0.0615]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3286, -3.2578,  1.3438,  ..., -4.1289, -6.4961,  0.2778]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 16:20:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The lion falls into the category of feline
The eagle falls into the category of raptor
The gibbon falls into the category of primate
The porcupine falls into the category of rodent
The goose falls into the category of fowl
The orangutan falls into the category of primate
The wolf falls into the category of canine
The mouse falls into the category of
2024-07-29 16:20:00 root INFO     total operator prediction time: 1061.3292400836945 seconds
2024-07-29 16:20:00 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on synonyms - intensity
2024-07-29 16:20:00 root INFO     building operator synonyms - intensity
2024-07-29 16:20:00 root INFO     [order_1_approx] starting weight calculation for A more intense word for house is palace
A more intense word for pony is horse
A more intense word for nap is sleep
A more intense word for tasty is delicious
A more intense word for rain is deluge
A more intense word for angry is furious
A more intense word for drizzle is rain
A more intense word for creative is
2024-07-29 16:20:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 16:22:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3018,  0.1804,  0.0745,  ..., -0.2805, -0.0839,  0.1981],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6602, -1.7578,  2.6270,  ...,  1.0742, -4.9844,  0.7139],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.3782e-02,  1.4877e-02, -1.8101e-03,  ..., -1.0071e-02,
          1.2611e-02, -4.7073e-03],
        [ 6.5842e-03,  4.3610e-02,  2.1698e-02,  ...,  2.3270e-02,
          1.7685e-02,  2.5314e-02],
        [-2.4124e-02, -1.7242e-02,  6.4697e-02,  ..., -7.2479e-05,
          3.1158e-02, -1.4809e-02],
        ...,
        [ 3.3875e-02, -1.2169e-03,  2.1484e-02,  ...,  8.6365e-02,
         -6.0501e-03, -2.3041e-03],
        [ 1.2989e-03,  8.5754e-03, -1.1086e-02,  ..., -1.3161e-03,
          5.6152e-02, -1.2924e-02],
        [ 4.1847e-03, -2.4704e-02,  7.4921e-03,  ...,  1.5213e-02,
         -1.8967e-02,  8.4351e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0117, -2.2734,  2.6074,  ...,  1.1514, -5.0781,  0.8364]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 16:22:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for house is palace
A more intense word for pony is horse
A more intense word for nap is sleep
A more intense word for tasty is delicious
A more intense word for rain is deluge
A more intense word for angry is furious
A more intense word for drizzle is rain
A more intense word for creative is
2024-07-29 16:22:12 root INFO     [order_1_approx] starting weight calculation for A more intense word for drizzle is rain
A more intense word for house is palace
A more intense word for pony is horse
A more intense word for rain is deluge
A more intense word for angry is furious
A more intense word for tasty is delicious
A more intense word for creative is ingenious
A more intense word for nap is
2024-07-29 16:22:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 16:24:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3525, -0.0184, -0.0568,  ...,  0.0182, -0.7720, -0.1256],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6230, -4.2812,  4.4062,  ...,  1.4170, -1.0762, -1.1523],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0681,  0.0015, -0.0133,  ...,  0.0156,  0.0175, -0.0050],
        [-0.0222,  0.0555, -0.0051,  ..., -0.0017, -0.0140, -0.0259],
        [-0.0099, -0.0261,  0.0450,  ...,  0.0010,  0.0005, -0.0005],
        ...,
        [-0.0096,  0.0081,  0.0193,  ...,  0.0408,  0.0114, -0.0017],
        [ 0.0185, -0.0112,  0.0028,  ...,  0.0099,  0.0279,  0.0022],
        [-0.0082, -0.0149, -0.0076,  ..., -0.0020,  0.0023,  0.0299]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2500, -4.0898,  4.0781,  ...,  1.5020, -1.6816, -1.0430]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 16:24:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for drizzle is rain
A more intense word for house is palace
A more intense word for pony is horse
A more intense word for rain is deluge
A more intense word for angry is furious
A more intense word for tasty is delicious
A more intense word for creative is ingenious
A more intense word for nap is
2024-07-29 16:24:26 root INFO     [order_1_approx] starting weight calculation for A more intense word for creative is ingenious
A more intense word for tasty is delicious
A more intense word for house is palace
A more intense word for angry is furious
A more intense word for drizzle is rain
A more intense word for rain is deluge
A more intense word for nap is sleep
A more intense word for pony is
2024-07-29 16:24:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 16:26:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1340,  0.2827, -0.3174,  ..., -0.1677, -0.2695,  0.1003],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2012, -3.6777, -0.5273,  ...,  2.0195, -3.5625, -1.1357],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1101, -0.0077, -0.0008,  ...,  0.0192, -0.0007,  0.0111],
        [ 0.0021,  0.0652,  0.0186,  ..., -0.0037,  0.0288, -0.0260],
        [ 0.0439, -0.0326,  0.0847,  ..., -0.0605, -0.0087, -0.0018],
        ...,
        [-0.0021, -0.0076,  0.0053,  ...,  0.1122,  0.0058, -0.0400],
        [-0.0374, -0.0076, -0.0165,  ...,  0.0162,  0.0722,  0.0067],
        [-0.0163, -0.0204,  0.0163,  ..., -0.0221,  0.0022,  0.0458]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2568, -3.0605, -0.1257,  ...,  2.2617, -3.3340, -1.1602]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 16:26:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for creative is ingenious
A more intense word for tasty is delicious
A more intense word for house is palace
A more intense word for angry is furious
A more intense word for drizzle is rain
A more intense word for rain is deluge
A more intense word for nap is sleep
A more intense word for pony is
2024-07-29 16:26:38 root INFO     [order_1_approx] starting weight calculation for A more intense word for nap is sleep
A more intense word for tasty is delicious
A more intense word for rain is deluge
A more intense word for angry is furious
A more intense word for house is palace
A more intense word for pony is horse
A more intense word for creative is ingenious
A more intense word for drizzle is
2024-07-29 16:26:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 16:28:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1339, -0.5107, -0.6641,  ..., -0.3232, -0.3875, -0.2546],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3633, -3.1133, -1.4102,  ...,  1.2520, -0.5215, -1.0449],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0383, -0.0040, -0.0061,  ..., -0.0095, -0.0102, -0.0037],
        [ 0.0085,  0.0346, -0.0032,  ...,  0.0003, -0.0042, -0.0036],
        [-0.0014, -0.0156,  0.0350,  ..., -0.0092,  0.0022, -0.0076],
        ...,
        [ 0.0089, -0.0018, -0.0019,  ...,  0.0436, -0.0093,  0.0109],
        [-0.0042, -0.0028, -0.0065,  ..., -0.0033,  0.0307,  0.0017],
        [ 0.0013, -0.0053,  0.0018,  ..., -0.0027, -0.0068,  0.0327]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6562, -3.0801, -1.4463,  ...,  1.0645, -0.5488, -1.0078]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 16:28:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for nap is sleep
A more intense word for tasty is delicious
A more intense word for rain is deluge
A more intense word for angry is furious
A more intense word for house is palace
A more intense word for pony is horse
A more intense word for creative is ingenious
A more intense word for drizzle is
2024-07-29 16:28:50 root INFO     [order_1_approx] starting weight calculation for A more intense word for rain is deluge
A more intense word for house is palace
A more intense word for tasty is delicious
A more intense word for drizzle is rain
A more intense word for nap is sleep
A more intense word for pony is horse
A more intense word for creative is ingenious
A more intense word for angry is
2024-07-29 16:28:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 16:31:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2020,  0.0288, -0.5107,  ...,  0.0305, -0.1981,  0.0527],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6367, -6.1719, -1.1016,  ..., -2.0352, -2.4688,  0.2168],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0718,  0.0068,  0.0055,  ..., -0.0003,  0.0010,  0.0113],
        [ 0.0073,  0.0525, -0.0096,  ...,  0.0030,  0.0153, -0.0048],
        [ 0.0176,  0.0185,  0.0596,  ...,  0.0040,  0.0159,  0.0060],
        ...,
        [ 0.0080,  0.0096, -0.0044,  ...,  0.0486,  0.0064, -0.0113],
        [-0.0101, -0.0090, -0.0032,  ...,  0.0138,  0.0519, -0.0132],
        [-0.0011, -0.0142, -0.0015,  ...,  0.0014, -0.0195,  0.0544]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3457, -6.0898, -0.9766,  ..., -1.8525, -2.4590,  0.1238]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 16:31:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for rain is deluge
A more intense word for house is palace
A more intense word for tasty is delicious
A more intense word for drizzle is rain
A more intense word for nap is sleep
A more intense word for pony is horse
A more intense word for creative is ingenious
A more intense word for angry is
2024-07-29 16:31:03 root INFO     [order_1_approx] starting weight calculation for A more intense word for drizzle is rain
A more intense word for house is palace
A more intense word for pony is horse
A more intense word for angry is furious
A more intense word for rain is deluge
A more intense word for creative is ingenious
A more intense word for nap is sleep
A more intense word for tasty is
2024-07-29 16:31:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 16:33:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3621, -0.2410, -0.4238,  ..., -0.5107, -0.4958, -0.0187],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.1445, -3.4062, -1.2061,  ..., -2.2461, -9.3203, -1.3818],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0508, -0.0173,  0.0152,  ..., -0.0097,  0.0026,  0.0172],
        [ 0.0227,  0.0577, -0.0046,  ...,  0.0175,  0.0141,  0.0080],
        [-0.0079, -0.0087,  0.0582,  ...,  0.0153, -0.0015, -0.0224],
        ...,
        [ 0.0231,  0.0080, -0.0114,  ...,  0.0531,  0.0019, -0.0041],
        [ 0.0052, -0.0038,  0.0202,  ...,  0.0002,  0.0331, -0.0034],
        [-0.0066, -0.0081, -0.0157,  ..., -0.0042, -0.0076,  0.0360]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.3242, -3.5605, -1.1387,  ..., -2.0898, -9.3047, -1.2256]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 16:33:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for drizzle is rain
A more intense word for house is palace
A more intense word for pony is horse
A more intense word for angry is furious
A more intense word for rain is deluge
A more intense word for creative is ingenious
A more intense word for nap is sleep
A more intense word for tasty is
2024-07-29 16:33:20 root INFO     [order_1_approx] starting weight calculation for A more intense word for pony is horse
A more intense word for angry is furious
A more intense word for tasty is delicious
A more intense word for house is palace
A more intense word for drizzle is rain
A more intense word for nap is sleep
A more intense word for creative is ingenious
A more intense word for rain is
2024-07-29 16:33:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 16:35:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3232, -0.1548, -0.2081,  ..., -0.4956,  0.0085, -0.3875],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.1367, -5.9102, -1.6631,  ...,  0.4341,  1.0537, -3.1152],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0467,  0.0096, -0.0101,  ..., -0.0044, -0.0162,  0.0115],
        [ 0.0053,  0.0566,  0.0028,  ...,  0.0215, -0.0077, -0.0330],
        [ 0.0053, -0.0103,  0.0603,  ...,  0.0052, -0.0162,  0.0077],
        ...,
        [ 0.0086,  0.0018, -0.0155,  ...,  0.0532, -0.0017, -0.0155],
        [-0.0095, -0.0179, -0.0161,  ...,  0.0015,  0.0433,  0.0225],
        [ 0.0076, -0.0166, -0.0099,  ...,  0.0065, -0.0082,  0.0529]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.9922, -5.4414, -1.8818,  ...,  0.8140,  0.6250, -3.4062]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 16:35:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for pony is horse
A more intense word for angry is furious
A more intense word for tasty is delicious
A more intense word for house is palace
A more intense word for drizzle is rain
A more intense word for nap is sleep
A more intense word for creative is ingenious
A more intense word for rain is
2024-07-29 16:35:33 root INFO     [order_1_approx] starting weight calculation for A more intense word for drizzle is rain
A more intense word for rain is deluge
A more intense word for creative is ingenious
A more intense word for angry is furious
A more intense word for nap is sleep
A more intense word for tasty is delicious
A more intense word for pony is horse
A more intense word for house is
2024-07-29 16:35:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 16:37:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1376,  0.1245,  0.0646,  ...,  0.1732, -0.1851, -0.4827],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-3.1992, -5.2227,  0.8530,  ..., -0.2056, -1.8604,  0.7754],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0917, -0.0003, -0.0045,  ...,  0.0097,  0.0097,  0.0140],
        [ 0.0027,  0.0854,  0.0123,  ..., -0.0034,  0.0157, -0.0110],
        [ 0.0161,  0.0114,  0.0660,  ..., -0.0089,  0.0030,  0.0175],
        ...,
        [ 0.0017,  0.0017,  0.0031,  ...,  0.0649, -0.0050, -0.0247],
        [-0.0221, -0.0065, -0.0105,  ..., -0.0036,  0.0875,  0.0126],
        [-0.0134,  0.0029, -0.0084,  ..., -0.0056, -0.0047,  0.0614]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-3.1465, -5.0039,  0.8159,  ...,  0.1021, -2.3594,  0.7173]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 16:37:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for drizzle is rain
A more intense word for rain is deluge
A more intense word for creative is ingenious
A more intense word for angry is furious
A more intense word for nap is sleep
A more intense word for tasty is delicious
A more intense word for pony is horse
A more intense word for house is
2024-07-29 16:37:45 root INFO     total operator prediction time: 1064.974097251892 seconds
2024-07-29 16:37:45 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - substance
2024-07-29 16:37:45 root INFO     building operator meronyms - substance
2024-07-29 16:37:45 root INFO     [order_1_approx] starting weight calculation for A glacier is made up of ice
A flag is made up of fabric
A clothing is made up of fabric
A bronze is made up of copper
A lens is made up of glass
A roof is made up of shingles
A atmosphere is made up of gas
A bottle is made up of
2024-07-29 16:37:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 16:39:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2881, -0.0958, -0.4458,  ...,  0.3916, -0.4143, -0.1504],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9785, -5.6250,  1.4922,  ..., -1.9316,  1.0518,  0.8994],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0223, -0.0151, -0.0028,  ...,  0.0169, -0.0129, -0.0035],
        [ 0.0038,  0.0328, -0.0012,  ...,  0.0138, -0.0093, -0.0036],
        [ 0.0158, -0.0049,  0.0155,  ...,  0.0096,  0.0119, -0.0109],
        ...,
        [ 0.0096,  0.0123,  0.0063,  ...,  0.0383, -0.0014, -0.0102],
        [-0.0157,  0.0064, -0.0122,  ...,  0.0180,  0.0298, -0.0080],
        [-0.0054,  0.0034, -0.0025,  ...,  0.0164, -0.0053,  0.0310]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8457, -5.7344,  1.5312,  ..., -2.2852,  0.7783,  0.6997]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 16:39:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A glacier is made up of ice
A flag is made up of fabric
A clothing is made up of fabric
A bronze is made up of copper
A lens is made up of glass
A roof is made up of shingles
A atmosphere is made up of gas
A bottle is made up of
2024-07-29 16:39:59 root INFO     [order_1_approx] starting weight calculation for A bottle is made up of glass
A atmosphere is made up of gas
A clothing is made up of fabric
A bronze is made up of copper
A lens is made up of glass
A flag is made up of fabric
A glacier is made up of ice
A roof is made up of
2024-07-29 16:39:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 16:42:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0647, -0.3320,  0.3201,  ..., -0.0791, -0.5288, -0.4058],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.6562, -7.4102,  0.9170,  ..., -1.5146,  0.3662, -2.3730],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.3243e-02, -5.2681e-03,  1.1856e-02,  ..., -4.2648e-03,
         -2.4429e-02, -2.9755e-03],
        [-4.4060e-03,  4.3152e-02,  1.0620e-02,  ..., -5.2032e-03,
         -9.5520e-03, -1.3870e-02],
        [ 1.3687e-02,  1.8349e-03,  1.9440e-02,  ..., -1.0559e-02,
         -7.1449e-03, -1.7624e-02],
        ...,
        [ 2.1255e-02, -5.0240e-03,  1.2558e-02,  ...,  6.4148e-02,
          3.8147e-06, -1.0483e-02],
        [-9.6436e-03,  4.4479e-03, -1.4847e-02,  ...,  9.4604e-04,
          4.1290e-02,  3.8643e-03],
        [-1.5602e-03, -6.8130e-03,  3.2749e-03,  ..., -7.7667e-03,
         -7.2556e-03,  1.2413e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.5859, -7.1133,  0.5435,  ..., -1.3701,  0.0420, -2.1289]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 16:42:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A bottle is made up of glass
A atmosphere is made up of gas
A clothing is made up of fabric
A bronze is made up of copper
A lens is made up of glass
A flag is made up of fabric
A glacier is made up of ice
A roof is made up of
2024-07-29 16:42:13 root INFO     [order_1_approx] starting weight calculation for A lens is made up of glass
A glacier is made up of ice
A atmosphere is made up of gas
A clothing is made up of fabric
A flag is made up of fabric
A bottle is made up of glass
A roof is made up of shingles
A bronze is made up of
2024-07-29 16:42:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 16:44:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1379,  0.0197,  0.3674,  ..., -0.0505, -0.0300, -0.0991],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.0156, -5.0664,  0.2288,  ..., -3.4805, -2.0645,  0.4834],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0278, -0.0307, -0.0196,  ..., -0.0162, -0.0323, -0.0053],
        [-0.0225,  0.0450,  0.0136,  ...,  0.0071, -0.0018, -0.0231],
        [ 0.0252, -0.0142,  0.0159,  ...,  0.0262, -0.0128, -0.0261],
        ...,
        [ 0.0379, -0.0076,  0.0130,  ...,  0.0657, -0.0051, -0.0118],
        [-0.0142,  0.0101, -0.0026,  ...,  0.0361,  0.0320, -0.0083],
        [ 0.0088, -0.0092,  0.0069,  ..., -0.0246,  0.0102,  0.0283]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.0508e+00, -4.9492e+00, -2.5635e-03,  ..., -3.3301e+00,
         -2.0840e+00,  9.9756e-01]], device='cuda:1', dtype=torch.float16,
       grad_fn=<SubBackward0>) 

                    
2024-07-29 16:44:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A lens is made up of glass
A glacier is made up of ice
A atmosphere is made up of gas
A clothing is made up of fabric
A flag is made up of fabric
A bottle is made up of glass
A roof is made up of shingles
A bronze is made up of
2024-07-29 16:44:27 root INFO     [order_1_approx] starting weight calculation for A flag is made up of fabric
A roof is made up of shingles
A bronze is made up of copper
A atmosphere is made up of gas
A glacier is made up of ice
A lens is made up of glass
A bottle is made up of glass
A clothing is made up of
2024-07-29 16:44:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 16:46:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0312, -0.4854, -0.3560,  ...,  0.2546, -0.2781, -0.1759],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.1680, -8.4844,  1.5879,  ..., -0.6943, -0.9028,  1.5078],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.7252e-02, -8.6403e-04,  1.5045e-02,  ...,  3.2379e-02,
         -1.4511e-02,  4.8332e-03],
        [ 4.0283e-03,  3.2471e-02,  4.2610e-03,  ...,  1.1711e-03,
         -1.5564e-03, -1.5610e-02],
        [ 7.6294e-05, -3.6125e-03,  2.6047e-02,  ..., -3.3646e-03,
         -4.1008e-03, -8.4000e-03],
        ...,
        [ 2.7313e-02, -1.9312e-03,  1.0582e-02,  ...,  5.0018e-02,
         -3.6621e-03, -1.3046e-02],
        [-7.6790e-03, -6.7177e-03, -4.5509e-03,  ...,  1.2642e-02,
          3.2593e-02, -6.4011e-03],
        [ 2.2125e-04, -8.3351e-04, -6.5498e-03,  ..., -9.9945e-04,
         -2.7657e-03,  3.5706e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.7109, -8.5156,  1.0312,  ..., -0.4980, -0.9658,  1.3389]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 16:46:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A flag is made up of fabric
A roof is made up of shingles
A bronze is made up of copper
A atmosphere is made up of gas
A glacier is made up of ice
A lens is made up of glass
A bottle is made up of glass
A clothing is made up of
2024-07-29 16:46:40 root INFO     [order_1_approx] starting weight calculation for A bottle is made up of glass
A lens is made up of glass
A bronze is made up of copper
A clothing is made up of fabric
A roof is made up of shingles
A flag is made up of fabric
A glacier is made up of ice
A atmosphere is made up of
2024-07-29 16:46:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 16:48:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4856,  0.0089, -0.4502,  ..., -0.2288, -0.5703, -0.2812],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7422, -3.1641,  0.9990,  ..., -6.1992,  3.6660, -0.7227],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0412, -0.0117, -0.0206,  ...,  0.0307, -0.0169, -0.0238],
        [-0.0286,  0.0426,  0.0102,  ...,  0.0025,  0.0040, -0.0089],
        [ 0.0155,  0.0110,  0.0355,  ...,  0.0130, -0.0155,  0.0076],
        ...,
        [ 0.0052,  0.0022,  0.0117,  ...,  0.0294,  0.0043, -0.0071],
        [-0.0066, -0.0097,  0.0051,  ...,  0.0274,  0.0442,  0.0038],
        [-0.0204,  0.0036, -0.0130,  ..., -0.0060,  0.0029,  0.0322]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3359, -3.7891,  1.1260,  ..., -6.0508,  3.6094, -0.5967]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 16:48:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A bottle is made up of glass
A lens is made up of glass
A bronze is made up of copper
A clothing is made up of fabric
A roof is made up of shingles
A flag is made up of fabric
A glacier is made up of ice
A atmosphere is made up of
2024-07-29 16:48:55 root INFO     [order_1_approx] starting weight calculation for A roof is made up of shingles
A bottle is made up of glass
A flag is made up of fabric
A lens is made up of glass
A atmosphere is made up of gas
A clothing is made up of fabric
A bronze is made up of copper
A glacier is made up of
2024-07-29 16:48:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 16:51:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3721,  0.2554, -0.3013,  ..., -0.2812, -0.7549,  0.3567],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1172, -6.5742,  1.0762,  ..., -4.0781,  1.4385, -2.7500],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0580, -0.0174,  0.0191,  ...,  0.0037, -0.0013, -0.0173],
        [ 0.0078,  0.0334,  0.0187,  ...,  0.0015, -0.0034, -0.0196],
        [ 0.0001,  0.0105,  0.0224,  ...,  0.0045, -0.0183, -0.0004],
        ...,
        [ 0.0159,  0.0127,  0.0032,  ...,  0.0646,  0.0108, -0.0076],
        [-0.0171,  0.0050, -0.0178,  ...,  0.0404,  0.0380,  0.0162],
        [ 0.0095,  0.0033, -0.0010,  ..., -0.0043,  0.0135,  0.0347]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5391, -6.8828,  1.0898,  ..., -3.7734,  1.4717, -2.8203]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 16:51:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A roof is made up of shingles
A bottle is made up of glass
A flag is made up of fabric
A lens is made up of glass
A atmosphere is made up of gas
A clothing is made up of fabric
A bronze is made up of copper
A glacier is made up of
2024-07-29 16:51:08 root INFO     [order_1_approx] starting weight calculation for A roof is made up of shingles
A bottle is made up of glass
A atmosphere is made up of gas
A glacier is made up of ice
A bronze is made up of copper
A flag is made up of fabric
A clothing is made up of fabric
A lens is made up of
2024-07-29 16:51:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 16:53:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2080, -0.3474, -0.2119,  ...,  0.6221, -0.1017, -0.3374],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9004, -3.5703,  0.4326,  ..., -0.6006,  1.6201,  0.1074],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0632, -0.0106, -0.0087,  ...,  0.0224, -0.0171, -0.0231],
        [-0.0095,  0.0580, -0.0117,  ...,  0.0216,  0.0023, -0.0025],
        [ 0.0400,  0.0084,  0.0554,  ...,  0.0011,  0.0054, -0.0105],
        ...,
        [ 0.0404,  0.0098,  0.0063,  ...,  0.0449,  0.0037,  0.0309],
        [-0.0218,  0.0155, -0.0198,  ...,  0.0143,  0.0416,  0.0058],
        [ 0.0069, -0.0018,  0.0097,  ..., -0.0036, -0.0024,  0.0384]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1562, -4.0977,  0.5918,  ..., -0.7900,  1.0156,  0.2446]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 16:53:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A roof is made up of shingles
A bottle is made up of glass
A atmosphere is made up of gas
A glacier is made up of ice
A bronze is made up of copper
A flag is made up of fabric
A clothing is made up of fabric
A lens is made up of
2024-07-29 16:53:18 root INFO     [order_1_approx] starting weight calculation for A glacier is made up of ice
A bronze is made up of copper
A bottle is made up of glass
A atmosphere is made up of gas
A roof is made up of shingles
A lens is made up of glass
A clothing is made up of fabric
A flag is made up of
2024-07-29 16:53:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 16:55:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5630,  0.0594, -0.5522,  ...,  0.3228, -0.4248, -0.2554],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0195, -5.8633,  2.6113,  ..., -2.9805,  0.4055, -0.2461],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0392, -0.0097,  0.0143,  ...,  0.0025, -0.0112, -0.0291],
        [ 0.0157,  0.0348,  0.0219,  ...,  0.0291, -0.0115, -0.0206],
        [-0.0038,  0.0143,  0.0210,  ...,  0.0055, -0.0081, -0.0308],
        ...,
        [ 0.0132,  0.0115,  0.0245,  ...,  0.0645, -0.0101, -0.0249],
        [-0.0137, -0.0077, -0.0219,  ...,  0.0007,  0.0581, -0.0018],
        [ 0.0184,  0.0070,  0.0219,  ..., -0.0189, -0.0073,  0.0246]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0273, -6.0391,  2.6445,  ..., -2.8066,  0.3164, -0.1959]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 16:55:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A glacier is made up of ice
A bronze is made up of copper
A bottle is made up of glass
A atmosphere is made up of gas
A roof is made up of shingles
A lens is made up of glass
A clothing is made up of fabric
A flag is made up of
2024-07-29 16:55:32 root INFO     total operator prediction time: 1067.231094121933 seconds
2024-07-29 16:55:32 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hypernyms - misc
2024-07-29 16:55:32 root INFO     building operator hypernyms - misc
2024-07-29 16:55:32 root INFO     [order_1_approx] starting weight calculation for The vase falls into the category of jar
The hamburger falls into the category of sandwich
The blender falls into the category of appliance
The sofa falls into the category of furniture
The cake falls into the category of dessert
The mascara falls into the category of makeup
The tv falls into the category of device
The grapefruit falls into the category of
2024-07-29 16:55:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 16:57:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1425, -0.5586, -0.2263,  ..., -0.0911, -0.3662, -0.3450],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6738, -4.2109,  1.7607,  ..., -5.1094, -2.5117, -2.3438],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0634,  0.0088, -0.0120,  ...,  0.0310, -0.0112,  0.0110],
        [ 0.0199,  0.0523,  0.0120,  ...,  0.0207,  0.0042,  0.0037],
        [-0.0071, -0.0030,  0.0403,  ...,  0.0129, -0.0168,  0.0196],
        ...,
        [ 0.0179,  0.0079,  0.0049,  ...,  0.0562,  0.0085, -0.0068],
        [ 0.0060, -0.0009,  0.0082,  ...,  0.0106,  0.0435, -0.0165],
        [-0.0139, -0.0243,  0.0077,  ..., -0.0231, -0.0152,  0.0578]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5801, -4.5469,  1.2656,  ..., -4.8984, -2.1797, -2.3262]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 16:57:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The vase falls into the category of jar
The hamburger falls into the category of sandwich
The blender falls into the category of appliance
The sofa falls into the category of furniture
The cake falls into the category of dessert
The mascara falls into the category of makeup
The tv falls into the category of device
The grapefruit falls into the category of
2024-07-29 16:57:46 root INFO     [order_1_approx] starting weight calculation for The sofa falls into the category of furniture
The grapefruit falls into the category of citrus
The tv falls into the category of device
The blender falls into the category of appliance
The cake falls into the category of dessert
The hamburger falls into the category of sandwich
The mascara falls into the category of makeup
The vase falls into the category of
2024-07-29 16:57:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 16:59:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3291, -0.4216, -0.0813,  ...,  0.7490,  0.0060, -0.1416],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2188, -2.4805,  0.4233,  ..., -3.4766, -3.6152,  1.2305],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0806, -0.0099, -0.0053,  ..., -0.0242, -0.0247,  0.0168],
        [ 0.0265,  0.0728,  0.0061,  ...,  0.0295, -0.0215, -0.0092],
        [ 0.0081,  0.0159,  0.0529,  ..., -0.0112, -0.0017, -0.0053],
        ...,
        [ 0.0125,  0.0037,  0.0303,  ...,  0.0780,  0.0081, -0.0286],
        [ 0.0226, -0.0201,  0.0111,  ..., -0.0023,  0.0675, -0.0136],
        [-0.0080, -0.0105, -0.0052,  ..., -0.0258, -0.0151,  0.0603]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3926, -3.0156,  0.1805,  ..., -3.7344, -3.2598,  1.1562]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 16:59:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sofa falls into the category of furniture
The grapefruit falls into the category of citrus
The tv falls into the category of device
The blender falls into the category of appliance
The cake falls into the category of dessert
The hamburger falls into the category of sandwich
The mascara falls into the category of makeup
The vase falls into the category of
2024-07-29 16:59:58 root INFO     [order_1_approx] starting weight calculation for The sofa falls into the category of furniture
The vase falls into the category of jar
The tv falls into the category of device
The blender falls into the category of appliance
The hamburger falls into the category of sandwich
The mascara falls into the category of makeup
The grapefruit falls into the category of citrus
The cake falls into the category of
2024-07-29 16:59:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 17:02:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2737, -0.0089,  0.0406,  ...,  0.2014, -0.6567, -0.0275],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9492, -6.2305, -0.0488,  ..., -4.1953, -5.2188,  0.3730],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.5817e-02,  8.0032e-03,  5.2719e-03,  ..., -2.0103e-03,
          1.8177e-03,  7.6218e-03],
        [ 2.7237e-02,  5.4749e-02,  1.1269e-02,  ...,  3.0518e-03,
         -4.5586e-03, -2.3697e-02],
        [-1.1101e-02, -1.8585e-02,  5.4932e-02,  ..., -9.9335e-03,
          8.6823e-03,  1.1902e-02],
        ...,
        [ 2.6321e-02,  8.8425e-03,  1.2611e-02,  ...,  5.1147e-02,
          2.1267e-03, -1.4664e-02],
        [-3.2043e-04, -2.9449e-03, -9.9182e-05,  ..., -1.7071e-03,
          6.3843e-02, -1.8066e-02],
        [-1.2177e-02,  9.8953e-03, -1.3008e-02,  ..., -1.0056e-02,
         -4.6921e-03,  4.9194e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5020, -6.2344, -0.6025,  ..., -3.8164, -5.1055,  0.7588]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 17:02:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sofa falls into the category of furniture
The vase falls into the category of jar
The tv falls into the category of device
The blender falls into the category of appliance
The hamburger falls into the category of sandwich
The mascara falls into the category of makeup
The grapefruit falls into the category of citrus
The cake falls into the category of
2024-07-29 17:02:10 root INFO     [order_1_approx] starting weight calculation for The tv falls into the category of device
The grapefruit falls into the category of citrus
The sofa falls into the category of furniture
The cake falls into the category of dessert
The blender falls into the category of appliance
The hamburger falls into the category of sandwich
The vase falls into the category of jar
The mascara falls into the category of
2024-07-29 17:02:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 17:04:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3125, -0.5576, -0.2104,  ...,  0.2485, -0.2812, -0.1841],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6846, -1.2188, -0.0280,  ...,  0.5498, -1.3574,  0.8125],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.1361e-02,  1.2131e-02,  3.3875e-03,  ..., -3.3836e-03,
         -2.2030e-03,  1.7899e-02],
        [ 1.2451e-02,  5.7007e-02, -3.5553e-03,  ...,  7.2632e-03,
          5.7602e-03,  1.3952e-03],
        [-9.4299e-03,  2.3651e-04,  5.4962e-02,  ..., -1.9104e-02,
         -9.9487e-03, -2.2564e-03],
        ...,
        [ 9.5215e-03, -1.5068e-02,  8.0948e-03,  ...,  6.2103e-02,
          1.9165e-02,  1.2695e-02],
        [-9.3689e-03,  1.9714e-02,  9.7275e-05,  ..., -6.4545e-03,
          5.7526e-02, -1.8250e-02],
        [ 9.7809e-03,  1.7715e-02, -6.7902e-03,  ..., -2.1011e-02,
         -1.9196e-02,  5.3619e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3027, -1.3428,  0.0807,  ...,  0.6890, -1.5518,  0.9600]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 17:04:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The tv falls into the category of device
The grapefruit falls into the category of citrus
The sofa falls into the category of furniture
The cake falls into the category of dessert
The blender falls into the category of appliance
The hamburger falls into the category of sandwich
The vase falls into the category of jar
The mascara falls into the category of
2024-07-29 17:04:23 root INFO     [order_1_approx] starting weight calculation for The grapefruit falls into the category of citrus
The tv falls into the category of device
The sofa falls into the category of furniture
The hamburger falls into the category of sandwich
The mascara falls into the category of makeup
The vase falls into the category of jar
The cake falls into the category of dessert
The blender falls into the category of
2024-07-29 17:04:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 17:06:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0803, -0.3562,  0.2986,  ...,  0.8589,  0.0578, -0.2017],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6211, -4.1797, -0.2861,  ..., -2.9180, -3.3086,  0.0273],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0685, -0.0071, -0.0062,  ...,  0.0032,  0.0024,  0.0066],
        [ 0.0253,  0.0662, -0.0009,  ..., -0.0188,  0.0054,  0.0002],
        [-0.0036,  0.0126,  0.0563,  ..., -0.0030, -0.0019,  0.0063],
        ...,
        [ 0.0180,  0.0057,  0.0033,  ...,  0.0513,  0.0182,  0.0067],
        [-0.0139, -0.0044,  0.0023,  ...,  0.0088,  0.0691, -0.0312],
        [-0.0026,  0.0048,  0.0069,  ..., -0.0122, -0.0039,  0.0533]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5034, -4.0117, -0.2891,  ..., -3.0078, -3.0547,  0.1448]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 17:06:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The grapefruit falls into the category of citrus
The tv falls into the category of device
The sofa falls into the category of furniture
The hamburger falls into the category of sandwich
The mascara falls into the category of makeup
The vase falls into the category of jar
The cake falls into the category of dessert
The blender falls into the category of
2024-07-29 17:06:40 root INFO     [order_1_approx] starting weight calculation for The vase falls into the category of jar
The sofa falls into the category of furniture
The cake falls into the category of dessert
The mascara falls into the category of makeup
The blender falls into the category of appliance
The tv falls into the category of device
The grapefruit falls into the category of citrus
The hamburger falls into the category of
2024-07-29 17:06:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 17:08:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0132,  0.2715, -0.1165,  ...,  0.3552, -0.2289, -0.2983],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9438, -4.0859,  0.9692,  ..., -3.4062, -4.9727, -3.0625],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0411,  0.0095,  0.0060,  ...,  0.0054, -0.0148, -0.0078],
        [ 0.0202,  0.0521, -0.0008,  ...,  0.0198,  0.0018, -0.0153],
        [-0.0109, -0.0079,  0.0347,  ...,  0.0030, -0.0007,  0.0059],
        ...,
        [ 0.0093,  0.0007,  0.0111,  ...,  0.0560,  0.0110, -0.0101],
        [ 0.0092, -0.0050, -0.0051,  ...,  0.0015,  0.0539, -0.0097],
        [-0.0065,  0.0004,  0.0035,  ..., -0.0181, -0.0147,  0.0520]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9771, -4.0586,  0.5889,  ..., -3.4512, -4.9062, -2.8750]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 17:08:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The vase falls into the category of jar
The sofa falls into the category of furniture
The cake falls into the category of dessert
The mascara falls into the category of makeup
The blender falls into the category of appliance
The tv falls into the category of device
The grapefruit falls into the category of citrus
The hamburger falls into the category of
2024-07-29 17:08:48 root INFO     [order_1_approx] starting weight calculation for The sofa falls into the category of furniture
The blender falls into the category of appliance
The hamburger falls into the category of sandwich
The cake falls into the category of dessert
The mascara falls into the category of makeup
The grapefruit falls into the category of citrus
The vase falls into the category of jar
The tv falls into the category of
2024-07-29 17:08:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 17:10:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0586, -0.7852, -0.1167,  ...,  0.4033, -0.1339, -0.1028],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.6924, -3.9258,  2.9043,  ..., -1.8916, -3.2617, -1.6963],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0687, -0.0120,  0.0110,  ..., -0.0053,  0.0121,  0.0126],
        [-0.0004,  0.0546,  0.0126,  ..., -0.0004, -0.0079, -0.0106],
        [ 0.0058,  0.0013,  0.0474,  ...,  0.0038,  0.0019,  0.0155],
        ...,
        [ 0.0101,  0.0244,  0.0191,  ...,  0.0721,  0.0051, -0.0178],
        [-0.0075, -0.0094,  0.0033,  ...,  0.0175,  0.0731,  0.0015],
        [-0.0026,  0.0033, -0.0084,  ..., -0.0189, -0.0215,  0.0266]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.5801, -3.7754,  3.0176,  ..., -1.7197, -3.4141, -1.3789]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 17:10:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sofa falls into the category of furniture
The blender falls into the category of appliance
The hamburger falls into the category of sandwich
The cake falls into the category of dessert
The mascara falls into the category of makeup
The grapefruit falls into the category of citrus
The vase falls into the category of jar
The tv falls into the category of
2024-07-29 17:10:57 root INFO     [order_1_approx] starting weight calculation for The hamburger falls into the category of sandwich
The vase falls into the category of jar
The blender falls into the category of appliance
The mascara falls into the category of makeup
The cake falls into the category of dessert
The grapefruit falls into the category of citrus
The tv falls into the category of device
The sofa falls into the category of
2024-07-29 17:10:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 17:13:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0862, -0.0398,  0.2661,  ...,  0.6665, -0.3660, -0.0771],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.9736, -5.3984,  3.5352,  ..., -1.8018, -3.3730, -0.1240],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0418, -0.0032, -0.0043,  ...,  0.0114,  0.0078, -0.0021],
        [ 0.0260,  0.0551,  0.0180,  ...,  0.0033, -0.0060, -0.0140],
        [-0.0275, -0.0088,  0.0397,  ..., -0.0142, -0.0132,  0.0064],
        ...,
        [ 0.0164,  0.0083,  0.0055,  ...,  0.0564,  0.0124, -0.0060],
        [ 0.0120,  0.0098, -0.0027,  ...,  0.0112,  0.0612, -0.0200],
        [ 0.0002, -0.0002, -0.0013,  ..., -0.0258, -0.0016,  0.0323]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7754, -5.4961,  3.4238,  ..., -1.7754, -3.2949,  0.1499]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 17:13:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The hamburger falls into the category of sandwich
The vase falls into the category of jar
The blender falls into the category of appliance
The mascara falls into the category of makeup
The cake falls into the category of dessert
The grapefruit falls into the category of citrus
The tv falls into the category of device
The sofa falls into the category of
2024-07-29 17:13:10 root INFO     total operator prediction time: 1058.2321617603302 seconds
2024-07-29 17:13:10 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on synonyms - exact
2024-07-29 17:13:10 root INFO     building operator synonyms - exact
2024-07-29 17:13:11 root INFO     [order_1_approx] starting weight calculation for Another word for incorrect is wrong
Another word for identical is same
Another word for portion is part
Another word for mesh is gauze
Another word for clothes is clothing
Another word for flower is blossom
Another word for auto is car
Another word for mother is
2024-07-29 17:13:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 17:15:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6387, -0.1724,  0.3040,  ...,  0.1881, -0.0887, -0.4280],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5498, -6.5312,  0.5127,  ..., -0.8442, -0.9814, -1.6816],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0693, -0.0356,  0.0268,  ...,  0.0019, -0.0121, -0.0001],
        [ 0.0265,  0.0522,  0.0098,  ...,  0.0124,  0.0237, -0.0210],
        [ 0.0287,  0.0095,  0.0641,  ...,  0.0034,  0.0129, -0.0065],
        ...,
        [-0.0232,  0.0252,  0.0272,  ...,  0.0646,  0.0007, -0.0109],
        [-0.0209,  0.0265, -0.0155,  ...,  0.0024,  0.0532, -0.0152],
        [-0.0116, -0.0029, -0.0035,  ..., -0.0370, -0.0240,  0.0516]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2952, -6.2578,  0.7754,  ..., -0.8369, -0.5996, -1.5957]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 17:15:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for incorrect is wrong
Another word for identical is same
Another word for portion is part
Another word for mesh is gauze
Another word for clothes is clothing
Another word for flower is blossom
Another word for auto is car
Another word for mother is
2024-07-29 17:15:24 root INFO     [order_1_approx] starting weight calculation for Another word for mesh is gauze
Another word for clothes is clothing
Another word for incorrect is wrong
Another word for flower is blossom
Another word for identical is same
Another word for mother is mom
Another word for portion is part
Another word for auto is
2024-07-29 17:15:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 17:17:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0436,  0.0226, -0.1178,  ..., -0.0606, -0.0016, -0.0887],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.5215, -6.2930,  2.2090,  ..., -1.1113,  0.0215,  1.4678],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1064, -0.0157,  0.0283,  ...,  0.0150,  0.0207, -0.0298],
        [-0.0160,  0.1028,  0.0102,  ...,  0.0289,  0.0280, -0.0258],
        [ 0.0218,  0.0152,  0.1098,  ..., -0.0312, -0.0022,  0.0254],
        ...,
        [-0.0071,  0.0145, -0.0024,  ...,  0.0941, -0.0022, -0.0155],
        [-0.0110, -0.0286,  0.0039,  ...,  0.0285,  0.0845, -0.0234],
        [-0.0008,  0.0079, -0.0214,  ..., -0.0150, -0.0047,  0.0753]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.2295, -5.5195,  1.3838,  ..., -0.5796,  0.2952,  1.0547]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 17:17:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for mesh is gauze
Another word for clothes is clothing
Another word for incorrect is wrong
Another word for flower is blossom
Another word for identical is same
Another word for mother is mom
Another word for portion is part
Another word for auto is
2024-07-29 17:17:38 root INFO     [order_1_approx] starting weight calculation for Another word for mesh is gauze
Another word for identical is same
Another word for flower is blossom
Another word for mother is mom
Another word for auto is car
Another word for incorrect is wrong
Another word for portion is part
Another word for clothes is
2024-07-29 17:17:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 17:19:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1699, -0.4880, -0.2859,  ...,  0.1406, -0.0621,  0.1036],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5156, -2.9805,  0.7280,  ..., -1.1533, -2.3398, -1.4961],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0453,  0.0034, -0.0003,  ...,  0.0255,  0.0038,  0.0137],
        [-0.0047,  0.0466,  0.0157,  ..., -0.0342,  0.0295, -0.0181],
        [ 0.0074,  0.0116,  0.0382,  ..., -0.0280,  0.0139,  0.0145],
        ...,
        [ 0.0042, -0.0176,  0.0163,  ...,  0.0634,  0.0014, -0.0277],
        [-0.0128,  0.0166, -0.0201,  ...,  0.0086,  0.0823,  0.0117],
        [-0.0066,  0.0054,  0.0022,  ..., -0.0136,  0.0073,  0.0300]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2148, -2.5195,  0.0420,  ..., -0.6387, -1.8184, -0.8760]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 17:19:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for mesh is gauze
Another word for identical is same
Another word for flower is blossom
Another word for mother is mom
Another word for auto is car
Another word for incorrect is wrong
Another word for portion is part
Another word for clothes is
2024-07-29 17:19:52 root INFO     [order_1_approx] starting weight calculation for Another word for identical is same
Another word for auto is car
Another word for mother is mom
Another word for flower is blossom
Another word for clothes is clothing
Another word for incorrect is wrong
Another word for portion is part
Another word for mesh is
2024-07-29 17:19:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 17:22:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4272, -0.0124, -0.2356,  ...,  0.4482, -0.0495,  0.2915],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9287, -1.7920,  1.4775,  ...,  0.5498, -1.9121,  1.9521],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1501, -0.0130, -0.0141,  ...,  0.0267, -0.0085, -0.0136],
        [ 0.0079,  0.0979,  0.0352,  ...,  0.0092,  0.0058, -0.0330],
        [ 0.0366, -0.0108,  0.1191,  ..., -0.0172, -0.0133, -0.0305],
        ...,
        [ 0.0204,  0.0266,  0.0330,  ...,  0.1549, -0.0110, -0.0033],
        [-0.0175, -0.0280, -0.0260,  ..., -0.0299,  0.0953,  0.0168],
        [-0.0056,  0.0047, -0.0163,  ..., -0.0330, -0.0246,  0.1228]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0996, -1.7168,  0.7285,  ...,  0.8799, -2.6660,  1.3438]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 17:22:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for identical is same
Another word for auto is car
Another word for mother is mom
Another word for flower is blossom
Another word for clothes is clothing
Another word for incorrect is wrong
Another word for portion is part
Another word for mesh is
2024-07-29 17:22:06 root INFO     [order_1_approx] starting weight calculation for Another word for clothes is clothing
Another word for mesh is gauze
Another word for identical is same
Another word for portion is part
Another word for incorrect is wrong
Another word for auto is car
Another word for mother is mom
Another word for flower is
2024-07-29 17:22:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 17:24:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5190, -0.0063, -0.1719,  ..., -0.0315,  0.0717,  0.0239],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.3359, -4.5273,  0.3647,  ...,  2.7695, -2.2285, -0.5679],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0782, -0.0266,  0.0305,  ...,  0.0034,  0.0010, -0.0005],
        [ 0.0039,  0.0792,  0.0289,  ...,  0.0106,  0.0032, -0.0133],
        [ 0.0061,  0.0241,  0.0788,  ...,  0.0093, -0.0333, -0.0087],
        ...,
        [-0.0237,  0.0079,  0.0025,  ...,  0.0907, -0.0058, -0.0126],
        [-0.0156,  0.0086,  0.0059,  ...,  0.0013,  0.0738,  0.0163],
        [-0.0354, -0.0100, -0.0159,  ..., -0.0055, -0.0105,  0.0663]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.0967, -3.9297,  0.3491,  ...,  2.9219, -2.3223,  0.2334]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 17:24:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for clothes is clothing
Another word for mesh is gauze
Another word for identical is same
Another word for portion is part
Another word for incorrect is wrong
Another word for auto is car
Another word for mother is mom
Another word for flower is
2024-07-29 17:24:17 root INFO     [order_1_approx] starting weight calculation for Another word for mesh is gauze
Another word for auto is car
Another word for flower is blossom
Another word for clothes is clothing
Another word for identical is same
Another word for portion is part
Another word for mother is mom
Another word for incorrect is
2024-07-29 17:24:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 17:26:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1794, -0.1138, -0.4531,  ...,  0.1138, -0.1433, -0.1528],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3706, -1.4482,  1.9863,  ...,  1.3203, -1.5273, -1.6719],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0713, -0.0436,  0.0394,  ...,  0.0075, -0.0131, -0.0113],
        [-0.0229,  0.0757,  0.0030,  ..., -0.0078,  0.0014, -0.0085],
        [-0.0092, -0.0158,  0.0715,  ..., -0.0162,  0.0060, -0.0003],
        ...,
        [ 0.0035,  0.0330,  0.0103,  ...,  0.0782,  0.0144, -0.0147],
        [-0.0113, -0.0011, -0.0179,  ..., -0.0098,  0.0532,  0.0045],
        [ 0.0265,  0.0038, -0.0146,  ..., -0.0038, -0.0084,  0.0566]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1272, -1.4580,  1.7734,  ...,  1.3105, -1.2227, -1.5459]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 17:26:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for mesh is gauze
Another word for auto is car
Another word for flower is blossom
Another word for clothes is clothing
Another word for identical is same
Another word for portion is part
Another word for mother is mom
Another word for incorrect is
2024-07-29 17:26:30 root INFO     [order_1_approx] starting weight calculation for Another word for mother is mom
Another word for incorrect is wrong
Another word for mesh is gauze
Another word for auto is car
Another word for identical is same
Another word for flower is blossom
Another word for clothes is clothing
Another word for portion is
2024-07-29 17:26:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 17:28:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6025, -0.4443, -0.0456,  ..., -0.2417,  0.2158,  0.0654],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1777, -4.0625,  0.4333,  ..., -2.6523, -0.5093, -2.4492],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1221, -0.0298,  0.0100,  ...,  0.0023,  0.0059, -0.0117],
        [-0.0071,  0.0706,  0.0165,  ...,  0.0093,  0.0119, -0.0241],
        [-0.0142,  0.0322,  0.1015,  ..., -0.0064, -0.0143, -0.0209],
        ...,
        [ 0.0074,  0.0066,  0.0027,  ...,  0.1265,  0.0017, -0.0278],
        [-0.0177,  0.0328,  0.0054,  ..., -0.0177,  0.1088, -0.0141],
        [-0.0263,  0.0038, -0.0136,  ..., -0.0440, -0.0266,  0.0979]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0137, -3.8184,  0.7588,  ..., -2.6055, -0.6509, -2.2598]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 17:28:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for mother is mom
Another word for incorrect is wrong
Another word for mesh is gauze
Another word for auto is car
Another word for identical is same
Another word for flower is blossom
Another word for clothes is clothing
Another word for portion is
2024-07-29 17:28:44 root INFO     [order_1_approx] starting weight calculation for Another word for auto is car
Another word for clothes is clothing
Another word for mother is mom
Another word for incorrect is wrong
Another word for portion is part
Another word for mesh is gauze
Another word for flower is blossom
Another word for identical is
2024-07-29 17:28:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 17:30:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1569, -0.5464,  0.0017,  ...,  0.1392, -0.0296, -0.0198],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5317, -0.6592,  1.7461,  ...,  0.5166, -3.0859, -0.2666],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 9.8572e-02,  8.8978e-04,  9.4452e-03,  ...,  2.5482e-02,
          1.1307e-02, -5.5389e-03],
        [ 5.1498e-03,  9.7168e-02,  1.4664e-02,  ...,  8.4763e-03,
          7.4387e-04,  1.2833e-02],
        [ 1.5961e-02,  1.1299e-02,  9.6497e-02,  ..., -1.3069e-02,
          3.0136e-03, -7.2327e-03],
        ...,
        [ 1.2177e-02,  2.4017e-02,  1.1444e-05,  ...,  1.2299e-01,
         -5.9280e-03,  1.0841e-02],
        [ 3.5034e-02, -2.3544e-02,  7.3433e-03,  ..., -1.7746e-02,
          4.8065e-02,  2.3087e-02],
        [ 4.6158e-03, -1.4465e-02, -2.3300e-02,  ..., -5.0697e-03,
         -1.7059e-02,  8.6731e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1050, -0.6123,  1.5547,  ...,  0.7588, -2.8535, -0.3901]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 17:30:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for auto is car
Another word for clothes is clothing
Another word for mother is mom
Another word for incorrect is wrong
Another word for portion is part
Another word for mesh is gauze
Another word for flower is blossom
Another word for identical is
2024-07-29 17:30:58 root INFO     total operator prediction time: 1067.4667887687683 seconds
2024-07-29 17:30:58 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - youth
2024-07-29 17:30:58 root INFO     building operator animal - youth
2024-07-29 17:30:58 root INFO     [order_1_approx] starting weight calculation for The offspring of a sheep is referred to as a lamb
The offspring of a duck is referred to as a duckling
The offspring of a skunk is referred to as a kit
The offspring of a beetle is referred to as a larva
The offspring of a cattle is referred to as a calf
The offspring of a rabbit is referred to as a bunny
The offspring of a gorilla is referred to as a infant
The offspring of a tiger is referred to as a
2024-07-29 17:30:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 17:33:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1516,  0.2639, -0.0414,  ...,  0.2332, -0.4009, -0.2710],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8945, -5.7266, -2.4219,  ..., -0.0308, -2.4727,  1.3477],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0359, -0.0192, -0.0113,  ...,  0.0058, -0.0059, -0.0121],
        [-0.0023,  0.0200,  0.0063,  ..., -0.0131,  0.0008, -0.0219],
        [-0.0011,  0.0122,  0.0452,  ...,  0.0122,  0.0067, -0.0039],
        ...,
        [ 0.0098,  0.0038,  0.0229,  ...,  0.0542,  0.0125, -0.0024],
        [-0.0004, -0.0275,  0.0193,  ...,  0.0071,  0.0198,  0.0099],
        [-0.0031,  0.0039, -0.0105,  ..., -0.0313, -0.0163,  0.0287]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3262, -5.0586, -2.1367,  ..., -0.0700, -2.5840,  1.3887]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 17:33:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a sheep is referred to as a lamb
The offspring of a duck is referred to as a duckling
The offspring of a skunk is referred to as a kit
The offspring of a beetle is referred to as a larva
The offspring of a cattle is referred to as a calf
The offspring of a rabbit is referred to as a bunny
The offspring of a gorilla is referred to as a infant
The offspring of a tiger is referred to as a
2024-07-29 17:33:08 root INFO     [order_1_approx] starting weight calculation for The offspring of a rabbit is referred to as a bunny
The offspring of a duck is referred to as a duckling
The offspring of a beetle is referred to as a larva
The offspring of a sheep is referred to as a lamb
The offspring of a cattle is referred to as a calf
The offspring of a tiger is referred to as a cub
The offspring of a skunk is referred to as a kit
The offspring of a gorilla is referred to as a
2024-07-29 17:33:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 17:35:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3308, -0.1294,  0.1252,  ..., -0.0275, -1.0078,  0.3967],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1006, -3.5586, -0.7056,  ...,  1.3682, -2.6992,  1.9824],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0262, -0.0090, -0.0161,  ...,  0.0041, -0.0030, -0.0036],
        [-0.0132,  0.0232,  0.0110,  ..., -0.0065,  0.0091, -0.0007],
        [ 0.0053,  0.0092,  0.0254,  ...,  0.0059,  0.0041, -0.0035],
        ...,
        [-0.0016,  0.0123, -0.0043,  ...,  0.0340,  0.0104, -0.0080],
        [ 0.0039, -0.0094,  0.0128,  ..., -0.0030,  0.0202,  0.0065],
        [-0.0127, -0.0034, -0.0069,  ..., -0.0260, -0.0049,  0.0244]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2549, -3.2344, -0.6138,  ...,  1.5703, -2.8516,  1.9424]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 17:35:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a rabbit is referred to as a bunny
The offspring of a duck is referred to as a duckling
The offspring of a beetle is referred to as a larva
The offspring of a sheep is referred to as a lamb
The offspring of a cattle is referred to as a calf
The offspring of a tiger is referred to as a cub
The offspring of a skunk is referred to as a kit
The offspring of a gorilla is referred to as a
2024-07-29 17:35:20 root INFO     [order_1_approx] starting weight calculation for The offspring of a sheep is referred to as a lamb
The offspring of a duck is referred to as a duckling
The offspring of a beetle is referred to as a larva
The offspring of a rabbit is referred to as a bunny
The offspring of a gorilla is referred to as a infant
The offspring of a tiger is referred to as a cub
The offspring of a skunk is referred to as a kit
The offspring of a cattle is referred to as a
2024-07-29 17:35:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 17:37:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2484, -0.3174,  0.0149,  ..., -0.1139, -0.1721,  0.1847],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7402, -3.6094, -1.1523,  ...,  0.6592, -0.2236, -0.4521],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.4159e-02, -2.4796e-02,  1.5717e-03,  ...,  1.0773e-02,
          1.9255e-03, -1.0498e-02],
        [ 1.9958e-02,  2.8351e-02,  1.2980e-03,  ..., -2.0828e-03,
          7.6675e-03, -1.9867e-02],
        [ 1.3397e-02, -1.2100e-02,  3.8391e-02,  ...,  4.3945e-03,
         -2.4414e-03, -1.6571e-02],
        ...,
        [-6.1035e-05,  5.4703e-03,  8.1329e-03,  ...,  5.6519e-02,
          2.0218e-02, -1.2520e-02],
        [-2.8477e-03,  1.9760e-02,  2.1942e-02,  ...,  9.9411e-03,
          2.9633e-02, -3.7903e-02],
        [-2.9316e-03,  7.4768e-03, -1.6418e-02,  ..., -2.5406e-02,
         -1.7776e-03,  3.5645e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3027, -3.8340, -0.8154,  ...,  0.8066, -1.2266, -0.3987]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 17:37:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a sheep is referred to as a lamb
The offspring of a duck is referred to as a duckling
The offspring of a beetle is referred to as a larva
The offspring of a rabbit is referred to as a bunny
The offspring of a gorilla is referred to as a infant
The offspring of a tiger is referred to as a cub
The offspring of a skunk is referred to as a kit
The offspring of a cattle is referred to as a
2024-07-29 17:37:32 root INFO     [order_1_approx] starting weight calculation for The offspring of a rabbit is referred to as a bunny
The offspring of a tiger is referred to as a cub
The offspring of a sheep is referred to as a lamb
The offspring of a duck is referred to as a duckling
The offspring of a cattle is referred to as a calf
The offspring of a skunk is referred to as a kit
The offspring of a gorilla is referred to as a infant
The offspring of a beetle is referred to as a
2024-07-29 17:37:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 17:39:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1405,  0.3152,  0.0844,  ...,  0.1820, -0.3110, -0.3350],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4414, -1.9453, -0.1519,  ...,  0.9468, -0.2461, -0.3809],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0387, -0.0262, -0.0049,  ...,  0.0107,  0.0064, -0.0226],
        [ 0.0197,  0.0256,  0.0119,  ...,  0.0019, -0.0013, -0.0280],
        [-0.0059, -0.0079,  0.0362,  ...,  0.0067, -0.0035, -0.0127],
        ...,
        [ 0.0118,  0.0087, -0.0024,  ...,  0.0331,  0.0220, -0.0004],
        [ 0.0033,  0.0089,  0.0182,  ...,  0.0220, -0.0008, -0.0172],
        [ 0.0023, -0.0061, -0.0020,  ..., -0.0099, -0.0154,  0.0358]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7656, -2.1562, -0.3940,  ...,  1.2559, -0.2261, -0.3726]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 17:39:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a rabbit is referred to as a bunny
The offspring of a tiger is referred to as a cub
The offspring of a sheep is referred to as a lamb
The offspring of a duck is referred to as a duckling
The offspring of a cattle is referred to as a calf
The offspring of a skunk is referred to as a kit
The offspring of a gorilla is referred to as a infant
The offspring of a beetle is referred to as a
2024-07-29 17:39:44 root INFO     [order_1_approx] starting weight calculation for The offspring of a skunk is referred to as a kit
The offspring of a beetle is referred to as a larva
The offspring of a cattle is referred to as a calf
The offspring of a duck is referred to as a duckling
The offspring of a rabbit is referred to as a bunny
The offspring of a tiger is referred to as a cub
The offspring of a gorilla is referred to as a infant
The offspring of a sheep is referred to as a
2024-07-29 17:39:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 17:41:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5156,  0.0724,  0.3750,  ...,  0.1141, -0.4363,  0.3958],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9375, -2.5352,  0.2729,  ...,  2.7812, -2.4766, -2.0527],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0318, -0.0271, -0.0008,  ...,  0.0061, -0.0247, -0.0116],
        [-0.0003,  0.0300,  0.0028,  ...,  0.0040, -0.0048, -0.0285],
        [ 0.0053,  0.0049,  0.0365,  ...,  0.0036, -0.0064, -0.0113],
        ...,
        [-0.0034,  0.0302,  0.0240,  ...,  0.0640,  0.0331, -0.0177],
        [ 0.0053,  0.0276,  0.0104,  ..., -0.0071,  0.0168,  0.0037],
        [-0.0059,  0.0052, -0.0142,  ..., -0.0354, -0.0242,  0.0406]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4023, -2.6836,  0.0968,  ...,  2.4727, -2.6152, -1.6562]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 17:41:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a skunk is referred to as a kit
The offspring of a beetle is referred to as a larva
The offspring of a cattle is referred to as a calf
The offspring of a duck is referred to as a duckling
The offspring of a rabbit is referred to as a bunny
The offspring of a tiger is referred to as a cub
The offspring of a gorilla is referred to as a infant
The offspring of a sheep is referred to as a
2024-07-29 17:41:55 root INFO     [order_1_approx] starting weight calculation for The offspring of a sheep is referred to as a lamb
The offspring of a cattle is referred to as a calf
The offspring of a gorilla is referred to as a infant
The offspring of a beetle is referred to as a larva
The offspring of a tiger is referred to as a cub
The offspring of a skunk is referred to as a kit
The offspring of a duck is referred to as a duckling
The offspring of a rabbit is referred to as a
2024-07-29 17:41:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 17:44:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1638,  0.0210,  0.4404,  ..., -0.2849, -0.6260, -0.3218],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.3203, -1.7676, -0.2017,  ...,  1.9648, -2.1484, -0.2061],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0252, -0.0161,  0.0061,  ...,  0.0089,  0.0042, -0.0131],
        [-0.0056,  0.0184,  0.0060,  ...,  0.0065,  0.0067, -0.0124],
        [-0.0030, -0.0010,  0.0119,  ..., -0.0043, -0.0014, -0.0030],
        ...,
        [ 0.0008,  0.0104,  0.0021,  ...,  0.0222,  0.0118,  0.0015],
        [ 0.0060,  0.0029,  0.0012,  ...,  0.0018,  0.0141, -0.0011],
        [-0.0064, -0.0047, -0.0007,  ..., -0.0101, -0.0042,  0.0156]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.3320, -1.6836, -0.2581,  ...,  2.0469, -2.1543, -0.1764]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 17:44:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a sheep is referred to as a lamb
The offspring of a cattle is referred to as a calf
The offspring of a gorilla is referred to as a infant
The offspring of a beetle is referred to as a larva
The offspring of a tiger is referred to as a cub
The offspring of a skunk is referred to as a kit
The offspring of a duck is referred to as a duckling
The offspring of a rabbit is referred to as a
2024-07-29 17:44:07 root INFO     [order_1_approx] starting weight calculation for The offspring of a gorilla is referred to as a infant
The offspring of a skunk is referred to as a kit
The offspring of a tiger is referred to as a cub
The offspring of a sheep is referred to as a lamb
The offspring of a cattle is referred to as a calf
The offspring of a beetle is referred to as a larva
The offspring of a rabbit is referred to as a bunny
The offspring of a duck is referred to as a
2024-07-29 17:44:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 17:46:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5732, -0.2302,  0.6069,  ..., -0.0721, -0.5918,  0.1318],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6641, -1.6836, -1.2998,  ...,  0.9116, -5.5234,  2.4219],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0465, -0.0167,  0.0013,  ...,  0.0006,  0.0043,  0.0047],
        [-0.0004,  0.0348,  0.0069,  ...,  0.0005, -0.0086, -0.0133],
        [-0.0012,  0.0013,  0.0380,  ..., -0.0136, -0.0029, -0.0166],
        ...,
        [-0.0076,  0.0161,  0.0029,  ...,  0.0397,  0.0154, -0.0116],
        [ 0.0014, -0.0092,  0.0098,  ...,  0.0095,  0.0299, -0.0037],
        [ 0.0052, -0.0092,  0.0058,  ..., -0.0081, -0.0055,  0.0262]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4531, -1.6201, -1.4512,  ...,  1.2539, -5.5078,  2.4180]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 17:46:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a gorilla is referred to as a infant
The offspring of a skunk is referred to as a kit
The offspring of a tiger is referred to as a cub
The offspring of a sheep is referred to as a lamb
The offspring of a cattle is referred to as a calf
The offspring of a beetle is referred to as a larva
The offspring of a rabbit is referred to as a bunny
The offspring of a duck is referred to as a
2024-07-29 17:46:19 root INFO     [order_1_approx] starting weight calculation for The offspring of a gorilla is referred to as a infant
The offspring of a tiger is referred to as a cub
The offspring of a rabbit is referred to as a bunny
The offspring of a cattle is referred to as a calf
The offspring of a duck is referred to as a duckling
The offspring of a sheep is referred to as a lamb
The offspring of a beetle is referred to as a larva
The offspring of a skunk is referred to as a
2024-07-29 17:46:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 17:48:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1066,  0.1536,  0.2354,  ...,  0.3899, -0.7578,  0.1243],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4492, -2.6797, -2.0000,  ...,  0.7861, -4.0625,  1.8203],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0622, -0.0361, -0.0320,  ...,  0.0271, -0.0024,  0.0028],
        [-0.0001,  0.0514,  0.0040,  ...,  0.0047, -0.0122, -0.0008],
        [ 0.0032, -0.0056,  0.0525,  ...,  0.0353, -0.0327, -0.0154],
        ...,
        [ 0.0029,  0.0151,  0.0365,  ...,  0.0594,  0.0184,  0.0164],
        [-0.0100, -0.0053,  0.0275,  ..., -0.0003,  0.0346, -0.0151],
        [ 0.0066,  0.0035,  0.0047,  ..., -0.0229,  0.0013,  0.0617]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8574, -2.7188, -2.6641,  ...,  1.1416, -4.1719,  1.4893]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 17:48:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a gorilla is referred to as a infant
The offspring of a tiger is referred to as a cub
The offspring of a rabbit is referred to as a bunny
The offspring of a cattle is referred to as a calf
The offspring of a duck is referred to as a duckling
The offspring of a sheep is referred to as a lamb
The offspring of a beetle is referred to as a larva
The offspring of a skunk is referred to as a
2024-07-29 17:48:31 root INFO     total operator prediction time: 1052.8201642036438 seconds
2024-07-29 17:48:31 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - sound
2024-07-29 17:48:31 root INFO     building operator animal - sound
2024-07-29 17:48:31 root INFO     [order_1_approx] starting weight calculation for The sound that a deer makes is called a bellow
The sound that a sheep makes is called a baa
The sound that a magpie makes is called a chatter
The sound that a rat makes is called a squeak
The sound that a chimpanzee makes is called a scream
The sound that a seal makes is called a bark
The sound that a cat makes is called a meow
The sound that a hornet makes is called a
2024-07-29 17:48:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 17:50:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1934,  0.1919,  0.3445,  ...,  0.5527, -0.2263,  0.0554],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7598, -1.9258,  2.9121,  ..., -0.1726, -1.4912,  2.6191],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0409, -0.0298, -0.0117,  ..., -0.0037, -0.0305, -0.0026],
        [-0.0219,  0.0557, -0.0045,  ...,  0.0219, -0.0232, -0.0181],
        [-0.0051,  0.0094,  0.0619,  ...,  0.0065, -0.0012, -0.0151],
        ...,
        [-0.0137, -0.0106,  0.0258,  ...,  0.0561, -0.0119, -0.0112],
        [-0.0009, -0.0113,  0.0050,  ..., -0.0079,  0.0348,  0.0035],
        [-0.0028,  0.0022, -0.0120,  ..., -0.0187, -0.0086,  0.0355]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6602, -2.0391,  3.0000,  ..., -0.2134, -1.6680,  2.4785]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 17:50:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a deer makes is called a bellow
The sound that a sheep makes is called a baa
The sound that a magpie makes is called a chatter
The sound that a rat makes is called a squeak
The sound that a chimpanzee makes is called a scream
The sound that a seal makes is called a bark
The sound that a cat makes is called a meow
The sound that a hornet makes is called a
2024-07-29 17:50:44 root INFO     [order_1_approx] starting weight calculation for The sound that a deer makes is called a bellow
The sound that a cat makes is called a meow
The sound that a rat makes is called a squeak
The sound that a magpie makes is called a chatter
The sound that a hornet makes is called a buzz
The sound that a seal makes is called a bark
The sound that a sheep makes is called a baa
The sound that a chimpanzee makes is called a
2024-07-29 17:50:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 17:52:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2418, -0.0762,  0.1139,  ..., -0.3928, -0.5898, -0.0701],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0840, -2.5742,  1.1299,  ..., -0.4814, -2.5371,  0.3965],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0092, -0.0021, -0.0025,  ...,  0.0006, -0.0029, -0.0009],
        [-0.0024,  0.0075,  0.0027,  ...,  0.0034, -0.0006, -0.0050],
        [ 0.0025,  0.0017,  0.0074,  ..., -0.0085,  0.0028, -0.0091],
        ...,
        [ 0.0047,  0.0069,  0.0021,  ...,  0.0128, -0.0052, -0.0005],
        [ 0.0014, -0.0035, -0.0026,  ...,  0.0030,  0.0126,  0.0015],
        [-0.0029, -0.0047, -0.0062,  ..., -0.0061,  0.0019,  0.0058]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0527, -2.5898,  1.0938,  ..., -0.4612, -2.5859,  0.3716]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 17:52:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a deer makes is called a bellow
The sound that a cat makes is called a meow
The sound that a rat makes is called a squeak
The sound that a magpie makes is called a chatter
The sound that a hornet makes is called a buzz
The sound that a seal makes is called a bark
The sound that a sheep makes is called a baa
The sound that a chimpanzee makes is called a
2024-07-29 17:52:55 root INFO     [order_1_approx] starting weight calculation for The sound that a magpie makes is called a chatter
The sound that a deer makes is called a bellow
The sound that a hornet makes is called a buzz
The sound that a chimpanzee makes is called a scream
The sound that a cat makes is called a meow
The sound that a sheep makes is called a baa
The sound that a rat makes is called a squeak
The sound that a seal makes is called a
2024-07-29 17:52:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 17:55:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6357, -0.3691,  0.5020,  ...,  0.1497, -0.7075,  0.2197],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7334, -0.4495,  0.1084,  ..., -0.6836, -0.3643,  2.4316],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0745, -0.0246, -0.0160,  ..., -0.0120, -0.0265, -0.0174],
        [ 0.0201,  0.0757, -0.0279,  ..., -0.0104, -0.0263, -0.0477],
        [ 0.0337,  0.0179,  0.0490,  ..., -0.0340, -0.0209, -0.0252],
        ...,
        [ 0.0094,  0.0094,  0.0189,  ...,  0.0547,  0.0022, -0.0107],
        [-0.0164, -0.0063, -0.0097,  ...,  0.0171,  0.0518, -0.0084],
        [-0.0132, -0.0048, -0.0189,  ...,  0.0013, -0.0030,  0.0520]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5039, -1.0117,  0.2020,  ..., -0.8760, -0.3450,  2.3789]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 17:55:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a magpie makes is called a chatter
The sound that a deer makes is called a bellow
The sound that a hornet makes is called a buzz
The sound that a chimpanzee makes is called a scream
The sound that a cat makes is called a meow
The sound that a sheep makes is called a baa
The sound that a rat makes is called a squeak
The sound that a seal makes is called a
2024-07-29 17:55:08 root INFO     [order_1_approx] starting weight calculation for The sound that a rat makes is called a squeak
The sound that a deer makes is called a bellow
The sound that a chimpanzee makes is called a scream
The sound that a cat makes is called a meow
The sound that a magpie makes is called a chatter
The sound that a seal makes is called a bark
The sound that a hornet makes is called a buzz
The sound that a sheep makes is called a
2024-07-29 17:55:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 17:57:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0199, -0.2964,  0.5083,  ...,  0.1547, -0.4631,  0.4387],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3989, -0.4688,  2.6641,  ...,  0.4922, -0.4189,  0.0684],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0488, -0.0203,  0.0052,  ..., -0.0128, -0.0244, -0.0045],
        [-0.0164,  0.0461, -0.0203,  ...,  0.0196,  0.0348, -0.0342],
        [-0.0020,  0.0032,  0.0424,  ..., -0.0176, -0.0291, -0.0138],
        ...,
        [ 0.0184,  0.0372,  0.0177,  ...,  0.0642,  0.0134, -0.0242],
        [ 0.0073,  0.0294,  0.0009,  ...,  0.0112,  0.0399, -0.0075],
        [ 0.0025, -0.0011, -0.0059,  ..., -0.0162, -0.0052,  0.0372]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1714, -0.3083,  2.9570,  ..., -0.3867, -0.7998, -0.2280]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 17:57:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a rat makes is called a squeak
The sound that a deer makes is called a bellow
The sound that a chimpanzee makes is called a scream
The sound that a cat makes is called a meow
The sound that a magpie makes is called a chatter
The sound that a seal makes is called a bark
The sound that a hornet makes is called a buzz
The sound that a sheep makes is called a
2024-07-29 17:57:20 root INFO     [order_1_approx] starting weight calculation for The sound that a rat makes is called a squeak
The sound that a sheep makes is called a baa
The sound that a chimpanzee makes is called a scream
The sound that a hornet makes is called a buzz
The sound that a magpie makes is called a chatter
The sound that a cat makes is called a meow
The sound that a seal makes is called a bark
The sound that a deer makes is called a
2024-07-29 17:57:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 17:59:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0675, -0.0244,  0.5010,  ...,  0.2493, -0.5981,  0.2607],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1885, -1.0967,  0.2598,  ...,  0.5791, -1.3965,  0.1270],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0382, -0.0149, -0.0012,  ..., -0.0039, -0.0068,  0.0061],
        [ 0.0012,  0.0603,  0.0039,  ...,  0.0282,  0.0118, -0.0339],
        [ 0.0149,  0.0165,  0.0534,  ..., -0.0295, -0.0211, -0.0074],
        ...,
        [-0.0162,  0.0305,  0.0077,  ...,  0.0814,  0.0088, -0.0166],
        [ 0.0184,  0.0077, -0.0081,  ..., -0.0036,  0.0530,  0.0075],
        [-0.0083, -0.0196,  0.0082,  ..., -0.0348, -0.0190,  0.0298]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2988, -1.2373,  0.4514,  ..., -0.2861, -1.1553, -0.0798]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 17:59:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a rat makes is called a squeak
The sound that a sheep makes is called a baa
The sound that a chimpanzee makes is called a scream
The sound that a hornet makes is called a buzz
The sound that a magpie makes is called a chatter
The sound that a cat makes is called a meow
The sound that a seal makes is called a bark
The sound that a deer makes is called a
2024-07-29 17:59:33 root INFO     [order_1_approx] starting weight calculation for The sound that a rat makes is called a squeak
The sound that a sheep makes is called a baa
The sound that a cat makes is called a meow
The sound that a seal makes is called a bark
The sound that a hornet makes is called a buzz
The sound that a deer makes is called a bellow
The sound that a chimpanzee makes is called a scream
The sound that a magpie makes is called a
2024-07-29 17:59:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 18:01:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4253,  0.2568, -0.1381,  ...,  0.6035, -0.6528,  0.4126],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5000, -1.0059,  2.4688,  ...,  1.2549, -2.5215,  0.9922],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0649,  0.0029,  0.0128,  ..., -0.0059, -0.0202, -0.0198],
        [-0.0441,  0.0679, -0.0027,  ...,  0.0546,  0.0683, -0.0361],
        [ 0.0397,  0.0098,  0.0573,  ..., -0.0045, -0.0224,  0.0069],
        ...,
        [ 0.0052,  0.0008,  0.0435,  ...,  0.0917, -0.0025, -0.0210],
        [-0.0509, -0.0297, -0.0022,  ..., -0.0184,  0.0744,  0.0173],
        [ 0.0342,  0.0204,  0.0057,  ..., -0.0392, -0.0439,  0.0321]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7227, -0.6592,  2.8242,  ...,  0.8154, -1.9688,  0.8047]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 18:01:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a rat makes is called a squeak
The sound that a sheep makes is called a baa
The sound that a cat makes is called a meow
The sound that a seal makes is called a bark
The sound that a hornet makes is called a buzz
The sound that a deer makes is called a bellow
The sound that a chimpanzee makes is called a scream
The sound that a magpie makes is called a
2024-07-29 18:01:45 root INFO     [order_1_approx] starting weight calculation for The sound that a seal makes is called a bark
The sound that a hornet makes is called a buzz
The sound that a chimpanzee makes is called a scream
The sound that a magpie makes is called a chatter
The sound that a sheep makes is called a baa
The sound that a rat makes is called a squeak
The sound that a deer makes is called a bellow
The sound that a cat makes is called a
2024-07-29 18:01:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 18:03:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1404, -0.2529,  0.5728,  ...,  0.1350, -0.2847, -0.1742],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5547, -4.4414, -1.4385,  ..., -1.7480, -0.6108,  3.6777],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.2074e-02, -8.9417e-03, -9.5367e-06,  ..., -8.1024e-03,
         -1.5091e-02,  7.6103e-03],
        [-3.2940e-03,  4.2664e-02, -7.2479e-05,  ..., -1.6136e-03,
          1.4397e-02, -1.6174e-02],
        [-7.7972e-03,  4.3106e-04,  4.6539e-02,  ..., -2.7939e-02,
          2.4796e-02,  4.9210e-03],
        ...,
        [-7.2479e-05,  1.6159e-02,  6.1226e-03,  ...,  3.8940e-02,
          4.8218e-03, -1.2085e-02],
        [ 2.2797e-02,  5.7716e-03, -6.2256e-03,  ...,  1.6068e-02,
          6.9313e-03, -1.3542e-03],
        [ 2.3060e-03, -1.4778e-02, -1.1856e-02,  ..., -1.6418e-02,
         -1.9791e-02,  2.7634e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8184, -4.5859, -0.7036,  ..., -2.0645, -1.0547,  3.4043]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 18:03:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a seal makes is called a bark
The sound that a hornet makes is called a buzz
The sound that a chimpanzee makes is called a scream
The sound that a magpie makes is called a chatter
The sound that a sheep makes is called a baa
The sound that a rat makes is called a squeak
The sound that a deer makes is called a bellow
The sound that a cat makes is called a
2024-07-29 18:03:58 root INFO     [order_1_approx] starting weight calculation for The sound that a cat makes is called a meow
The sound that a hornet makes is called a buzz
The sound that a seal makes is called a bark
The sound that a magpie makes is called a chatter
The sound that a deer makes is called a bellow
The sound that a chimpanzee makes is called a scream
The sound that a sheep makes is called a baa
The sound that a rat makes is called a
2024-07-29 18:03:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 18:06:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2908, -0.3337,  0.4688,  ..., -0.3975, -0.2449, -0.2942],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0742, -1.6729,  1.3789,  ..., -1.7373, -0.6592,  2.2969],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0623, -0.0217,  0.0186,  ..., -0.0107, -0.0200, -0.0147],
        [ 0.0048,  0.0714, -0.0026,  ...,  0.0062, -0.0031, -0.0285],
        [ 0.0097,  0.0062,  0.0600,  ..., -0.0162, -0.0053, -0.0285],
        ...,
        [ 0.0082, -0.0111,  0.0057,  ...,  0.0468, -0.0078, -0.0075],
        [ 0.0003, -0.0248,  0.0026,  ...,  0.0109,  0.0405,  0.0041],
        [ 0.0102,  0.0087, -0.0116,  ..., -0.0457, -0.0159,  0.0356]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8789, -1.9756,  1.2295,  ..., -1.8926, -0.7295,  2.2012]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 18:06:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a cat makes is called a meow
The sound that a hornet makes is called a buzz
The sound that a seal makes is called a bark
The sound that a magpie makes is called a chatter
The sound that a deer makes is called a bellow
The sound that a chimpanzee makes is called a scream
The sound that a sheep makes is called a baa
The sound that a rat makes is called a
2024-07-29 18:06:10 root INFO     total operator prediction time: 1059.4632840156555 seconds
2024-07-29 18:06:10 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on things - color
2024-07-29 18:06:10 root INFO     building operator things - color
2024-07-29 18:06:10 root INFO     [order_1_approx] starting weight calculation for The ant is colored black
The sea is colored blue
The cranberry is colored red
The cherry is colored red
The grass is colored green
The carrot is colored orange
The sugar is colored white
The parsley is colored
2024-07-29 18:06:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 18:08:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3052,  0.0276, -0.6528,  ..., -0.4795, -0.5620, -0.0088],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2295, -5.2734, -1.8809,  ..., -0.1084, -0.4023, -2.4707],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0778,  0.0040,  0.0110,  ..., -0.0062,  0.0097,  0.0010],
        [ 0.0235,  0.0437,  0.0174,  ...,  0.0124,  0.0097, -0.0257],
        [-0.0077, -0.0103,  0.0546,  ...,  0.0107, -0.0130,  0.0033],
        ...,
        [ 0.0201, -0.0127,  0.0283,  ...,  0.0850, -0.0003,  0.0090],
        [ 0.0080,  0.0001, -0.0136,  ...,  0.0175,  0.0698, -0.0063],
        [-0.0064,  0.0007,  0.0105,  ..., -0.0176, -0.0011,  0.0558]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8271, -5.2617, -1.7305,  ..., -0.1731, -0.4304, -1.7676]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 18:08:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The ant is colored black
The sea is colored blue
The cranberry is colored red
The cherry is colored red
The grass is colored green
The carrot is colored orange
The sugar is colored white
The parsley is colored
2024-07-29 18:08:24 root INFO     [order_1_approx] starting weight calculation for The cranberry is colored red
The sea is colored blue
The carrot is colored orange
The grass is colored green
The cherry is colored red
The parsley is colored green
The ant is colored black
The sugar is colored
2024-07-29 18:08:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 18:10:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3020, -0.3831, -0.3125,  ..., -0.0373, -0.4775, -0.3892],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.4355, -5.5859,  0.7842,  ..., -1.3115, -1.1641, -0.7012],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0582,  0.0027,  0.0198,  ...,  0.0061,  0.0039,  0.0016],
        [ 0.0204,  0.0856,  0.0096,  ..., -0.0060,  0.0400, -0.0299],
        [ 0.0090, -0.0090,  0.0476,  ...,  0.0291, -0.0130,  0.0063],
        ...,
        [ 0.0023, -0.0129,  0.0102,  ...,  0.0534,  0.0034, -0.0070],
        [-0.0125,  0.0158, -0.0271,  ...,  0.0172,  0.0468, -0.0111],
        [-0.0216, -0.0252, -0.0059,  ...,  0.0030, -0.0173,  0.0340]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.0557, -5.1992,  0.5039,  ..., -1.2402, -0.8027, -0.3596]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 18:10:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The cranberry is colored red
The sea is colored blue
The carrot is colored orange
The grass is colored green
The cherry is colored red
The parsley is colored green
The ant is colored black
The sugar is colored
2024-07-29 18:10:38 root INFO     [order_1_approx] starting weight calculation for The parsley is colored green
The ant is colored black
The sugar is colored white
The grass is colored green
The sea is colored blue
The carrot is colored orange
The cranberry is colored red
The cherry is colored
2024-07-29 18:10:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 18:12:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1667, -0.6470,  0.0435,  ..., -0.0888, -0.6094, -0.2705],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.6348, -6.5508, -2.5078,  ..., -0.7383,  1.4238, -1.1113],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0400, -0.0053,  0.0048,  ..., -0.0128,  0.0147,  0.0007],
        [-0.0075,  0.0473,  0.0130,  ...,  0.0150,  0.0101, -0.0050],
        [ 0.0046,  0.0016,  0.0304,  ...,  0.0146, -0.0105, -0.0096],
        ...,
        [ 0.0111, -0.0016,  0.0101,  ...,  0.0489,  0.0104,  0.0039],
        [-0.0082, -0.0091, -0.0142,  ...,  0.0263,  0.0384, -0.0078],
        [-0.0110, -0.0099, -0.0088,  ..., -0.0020, -0.0141,  0.0453]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.5332, -6.4531, -2.4785,  ..., -0.4849,  1.2188, -1.2686]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 18:12:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The parsley is colored green
The ant is colored black
The sugar is colored white
The grass is colored green
The sea is colored blue
The carrot is colored orange
The cranberry is colored red
The cherry is colored
2024-07-29 18:12:51 root INFO     [order_1_approx] starting weight calculation for The cranberry is colored red
The parsley is colored green
The sugar is colored white
The cherry is colored red
The sea is colored blue
The ant is colored black
The grass is colored green
The carrot is colored
2024-07-29 18:12:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 18:15:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0106, -0.4126, -0.0092,  ..., -0.2932, -0.6079,  0.2534],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.1602, -6.3203,  0.4607,  ..., -4.6172, -0.3015, -2.9492],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0741, -0.0038,  0.0246,  ..., -0.0020, -0.0016,  0.0064],
        [ 0.0026,  0.0509,  0.0332,  ...,  0.0021,  0.0034, -0.0229],
        [-0.0008, -0.0072,  0.0542,  ...,  0.0404, -0.0195, -0.0120],
        ...,
        [-0.0063, -0.0338,  0.0063,  ...,  0.0748, -0.0137, -0.0041],
        [ 0.0043,  0.0015, -0.0155,  ...,  0.0356,  0.0539, -0.0165],
        [-0.0049, -0.0122,  0.0140,  ..., -0.0071,  0.0032,  0.0734]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.2852, -6.0000,  0.3032,  ..., -4.0430, -0.3225, -2.5898]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 18:15:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The cranberry is colored red
The parsley is colored green
The sugar is colored white
The cherry is colored red
The sea is colored blue
The ant is colored black
The grass is colored green
The carrot is colored
2024-07-29 18:15:05 root INFO     [order_1_approx] starting weight calculation for The sugar is colored white
The cherry is colored red
The sea is colored blue
The parsley is colored green
The ant is colored black
The carrot is colored orange
The grass is colored green
The cranberry is colored
2024-07-29 18:15:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 18:17:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7095, -0.7715, -0.5811,  ...,  0.0711, -0.7500, -0.1685],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-4.2188, -6.6602, -1.1445,  ..., -0.8027,  1.1670, -0.1384],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.3354e-02, -2.0123e-03, -2.0599e-04,  ..., -1.6998e-02,
          1.9318e-02, -2.2697e-04],
        [-5.9776e-03,  4.7729e-02,  2.2156e-02,  ...,  2.5253e-02,
          8.5907e-03, -1.5343e-02],
        [ 6.4468e-03,  1.3947e-04,  4.3945e-02,  ...,  1.7242e-02,
         -1.1063e-02,  4.7379e-03],
        ...,
        [ 9.6970e-03,  2.3651e-04,  1.5717e-02,  ...,  7.4829e-02,
         -3.4523e-04,  8.3923e-05],
        [-1.3359e-02, -9.0027e-03, -4.9438e-03,  ...,  3.2562e-02,
          4.5197e-02,  6.0997e-03],
        [-1.9180e-02, -9.6893e-04, -5.2414e-03,  ..., -1.8492e-03,
         -1.0704e-02,  4.9713e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-4.1602, -6.5391, -0.9590,  ..., -0.6562,  0.9087, -0.0999]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 18:17:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sugar is colored white
The cherry is colored red
The sea is colored blue
The parsley is colored green
The ant is colored black
The carrot is colored orange
The grass is colored green
The cranberry is colored
2024-07-29 18:17:18 root INFO     [order_1_approx] starting weight calculation for The grass is colored green
The cherry is colored red
The sugar is colored white
The cranberry is colored red
The parsley is colored green
The carrot is colored orange
The ant is colored black
The sea is colored
2024-07-29 18:17:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 18:19:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3452, -0.2629,  0.0392,  ..., -0.2817, -0.0349,  0.1250],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.3828, -2.3633, -1.4893,  ...,  0.9946,  1.1309, -0.0752],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.6377e-02, -8.7738e-05,  1.3214e-02,  ..., -1.6708e-02,
          2.8038e-03,  7.5989e-03],
        [-1.2115e-02,  3.8208e-02, -1.0963e-02,  ...,  6.5994e-03,
          5.3940e-03, -9.2010e-03],
        [-4.9744e-03, -9.6893e-04,  3.3051e-02,  ..., -8.2397e-04,
          6.9199e-03,  2.0172e-02],
        ...,
        [-5.2881e-04,  1.1917e-02,  1.9318e-02,  ...,  4.4373e-02,
         -5.0354e-03, -1.1093e-02],
        [-8.4381e-03, -4.9973e-03,  4.0436e-04,  ...,  2.1393e-02,
          2.3376e-02, -7.5378e-03],
        [-1.7807e-02, -4.3373e-03, -1.3443e-02,  ...,  6.5231e-03,
          5.5313e-04,  2.1820e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.5781, -2.3105, -1.7793,  ...,  1.0752,  1.2881,  0.1196]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 18:19:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The grass is colored green
The cherry is colored red
The sugar is colored white
The cranberry is colored red
The parsley is colored green
The carrot is colored orange
The ant is colored black
The sea is colored
2024-07-29 18:19:32 root INFO     [order_1_approx] starting weight calculation for The carrot is colored orange
The parsley is colored green
The sea is colored blue
The sugar is colored white
The grass is colored green
The cherry is colored red
The cranberry is colored red
The ant is colored
2024-07-29 18:19:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 18:21:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2908, -0.3965,  0.0051,  ..., -0.1591, -0.3774, -0.0875],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8359, -3.9062,  0.1703,  ..., -0.0869, -1.4238, -1.1758],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0840, -0.0090,  0.0039,  ...,  0.0089, -0.0021, -0.0054],
        [ 0.0190,  0.0525,  0.0046,  ...,  0.0138,  0.0175, -0.0101],
        [-0.0011, -0.0097,  0.0334,  ...,  0.0166, -0.0245,  0.0077],
        ...,
        [ 0.0107,  0.0015,  0.0037,  ...,  0.0883, -0.0080, -0.0070],
        [ 0.0074,  0.0070, -0.0064,  ...,  0.0203,  0.0333,  0.0072],
        [-0.0058, -0.0008, -0.0104,  ...,  0.0005, -0.0166,  0.0487]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1660, -4.2500, -0.3184,  ..., -0.0510, -1.2881, -1.0811]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 18:21:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The carrot is colored orange
The parsley is colored green
The sea is colored blue
The sugar is colored white
The grass is colored green
The cherry is colored red
The cranberry is colored red
The ant is colored
2024-07-29 18:21:45 root INFO     [order_1_approx] starting weight calculation for The carrot is colored orange
The sugar is colored white
The cranberry is colored red
The cherry is colored red
The parsley is colored green
The sea is colored blue
The ant is colored black
The grass is colored
2024-07-29 18:21:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 18:23:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3435, -0.1208, -0.1530,  ...,  0.0404, -0.3044, -0.0775],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6484, -6.1836, -2.0547,  ..., -0.5103,  0.5586, -3.1055],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0765,  0.0024,  0.0112,  ..., -0.0005,  0.0006, -0.0065],
        [ 0.0091,  0.0451,  0.0115,  ...,  0.0014,  0.0080, -0.0192],
        [-0.0066, -0.0091,  0.0572,  ..., -0.0105, -0.0240,  0.0030],
        ...,
        [ 0.0085, -0.0069,  0.0241,  ...,  0.0641, -0.0042, -0.0027],
        [-0.0077, -0.0096, -0.0082,  ...,  0.0299,  0.0751, -0.0012],
        [-0.0178, -0.0054, -0.0078,  ..., -0.0117,  0.0008,  0.0468]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8086, -5.8242, -2.1250,  ..., -0.2053,  0.3955, -2.7891]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 18:23:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The carrot is colored orange
The sugar is colored white
The cranberry is colored red
The cherry is colored red
The parsley is colored green
The sea is colored blue
The ant is colored black
The grass is colored
2024-07-29 18:23:58 root INFO     total operator prediction time: 1067.716582775116 seconds
2024-07-29 18:23:58 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on country - capital
2024-07-29 18:23:58 root INFO     building operator country - capital
2024-07-29 18:23:58 root INFO     [order_1_approx] starting weight calculation for The country with oslo as its capital is known as norway
The country with jakarta as its capital is known as indonesia
The country with kiev as its capital is known as ukraine
The country with berlin as its capital is known as germany
The country with london as its capital is known as england
The country with belgrade as its capital is known as serbia
The country with tehran as its capital is known as iran
The country with bern as its capital is known as
2024-07-29 18:23:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 18:26:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6577,  0.8936, -0.0439,  ...,  0.5005,  0.0663, -0.2483],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0273, -6.0938, -1.9980,  ...,  0.1206, -1.6865, -1.4570],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0214, -0.0065,  0.0013,  ...,  0.0325, -0.0169, -0.0267],
        [-0.0021,  0.0470,  0.0177,  ..., -0.0341,  0.0024, -0.0496],
        [ 0.0085,  0.0106,  0.0556,  ...,  0.0217,  0.0113,  0.0028],
        ...,
        [-0.0040,  0.0024,  0.0007,  ...,  0.0623,  0.0170, -0.0494],
        [ 0.0172,  0.0030,  0.0155,  ...,  0.0219,  0.0295,  0.0136],
        [-0.0065,  0.0025, -0.0143,  ..., -0.0074,  0.0015,  0.0362]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1094, -6.2422, -2.2383,  ...,  0.0243, -1.7607, -1.5479]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 18:26:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with oslo as its capital is known as norway
The country with jakarta as its capital is known as indonesia
The country with kiev as its capital is known as ukraine
The country with berlin as its capital is known as germany
The country with london as its capital is known as england
The country with belgrade as its capital is known as serbia
The country with tehran as its capital is known as iran
The country with bern as its capital is known as
2024-07-29 18:26:11 root INFO     [order_1_approx] starting weight calculation for The country with oslo as its capital is known as norway
The country with london as its capital is known as england
The country with belgrade as its capital is known as serbia
The country with bern as its capital is known as switzerland
The country with kiev as its capital is known as ukraine
The country with jakarta as its capital is known as indonesia
The country with berlin as its capital is known as germany
The country with tehran as its capital is known as
2024-07-29 18:26:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 18:28:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2559, -0.0973, -0.5718,  ...,  0.4634,  0.2312,  0.3940],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1738, -4.2344, -0.3403,  ..., -1.3047,  0.6909, -4.6953],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0246, -0.0040,  0.0018,  ...,  0.0048, -0.0085, -0.0022],
        [-0.0072,  0.0316, -0.0008,  ..., -0.0051,  0.0091, -0.0073],
        [ 0.0003, -0.0015,  0.0441,  ...,  0.0028,  0.0050, -0.0032],
        ...,
        [ 0.0025,  0.0089,  0.0012,  ...,  0.0328,  0.0068, -0.0043],
        [-0.0083,  0.0005,  0.0010,  ..., -0.0034,  0.0078,  0.0045],
        [-0.0083, -0.0056, -0.0121,  ...,  0.0067, -0.0045,  0.0352]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0847, -3.8672, -0.3882,  ..., -1.1357,  0.8755, -4.3281]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 18:28:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with oslo as its capital is known as norway
The country with london as its capital is known as england
The country with belgrade as its capital is known as serbia
The country with bern as its capital is known as switzerland
The country with kiev as its capital is known as ukraine
The country with jakarta as its capital is known as indonesia
The country with berlin as its capital is known as germany
The country with tehran as its capital is known as
2024-07-29 18:28:19 root INFO     [order_1_approx] starting weight calculation for The country with kiev as its capital is known as ukraine
The country with bern as its capital is known as switzerland
The country with oslo as its capital is known as norway
The country with belgrade as its capital is known as serbia
The country with jakarta as its capital is known as indonesia
The country with tehran as its capital is known as iran
The country with london as its capital is known as england
The country with berlin as its capital is known as
2024-07-29 18:28:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 18:30:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5474,  0.1906, -0.2231,  ...,  0.8252,  0.1707,  0.1699],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6030, -6.0547, -1.0781,  ...,  0.0383,  1.0732, -4.5820],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0278,  0.0004,  0.0008,  ...,  0.0036, -0.0051,  0.0029],
        [-0.0173,  0.0308,  0.0106,  ...,  0.0108, -0.0078, -0.0279],
        [-0.0013,  0.0088,  0.0548,  ...,  0.0191, -0.0047, -0.0174],
        ...,
        [-0.0077,  0.0037,  0.0050,  ...,  0.0522, -0.0031, -0.0143],
        [ 0.0163, -0.0002, -0.0015,  ..., -0.0071,  0.0096, -0.0085],
        [-0.0129,  0.0037, -0.0005,  ...,  0.0085, -0.0144,  0.0225]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5830, -6.0820, -1.2139,  ...,  0.0202,  1.0059, -4.3203]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 18:30:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with kiev as its capital is known as ukraine
The country with bern as its capital is known as switzerland
The country with oslo as its capital is known as norway
The country with belgrade as its capital is known as serbia
The country with jakarta as its capital is known as indonesia
The country with tehran as its capital is known as iran
The country with london as its capital is known as england
The country with berlin as its capital is known as
2024-07-29 18:30:26 root INFO     [order_1_approx] starting weight calculation for The country with belgrade as its capital is known as serbia
The country with tehran as its capital is known as iran
The country with jakarta as its capital is known as indonesia
The country with oslo as its capital is known as norway
The country with berlin as its capital is known as germany
The country with kiev as its capital is known as ukraine
The country with bern as its capital is known as switzerland
The country with london as its capital is known as
2024-07-29 18:30:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 18:32:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3359, -0.1064, -0.1052,  ...,  0.6216,  0.6807, -0.1575],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8770, -5.8047, -1.3418,  ..., -3.3320,  0.7529, -5.9648],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0282, -0.0092,  0.0054,  ...,  0.0029, -0.0010,  0.0028],
        [-0.0079,  0.0300,  0.0066,  ...,  0.0024, -0.0077, -0.0021],
        [-0.0016,  0.0087,  0.0343,  ...,  0.0123,  0.0068, -0.0017],
        ...,
        [-0.0061,  0.0032,  0.0071,  ...,  0.0277,  0.0086, -0.0154],
        [-0.0024,  0.0013, -0.0028,  ..., -0.0034,  0.0161, -0.0030],
        [-0.0020, -0.0133, -0.0057,  ..., -0.0054, -0.0158,  0.0234]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8691, -5.6953, -1.5107,  ..., -3.1230,  0.7954, -5.8750]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 18:32:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with belgrade as its capital is known as serbia
The country with tehran as its capital is known as iran
The country with jakarta as its capital is known as indonesia
The country with oslo as its capital is known as norway
The country with berlin as its capital is known as germany
The country with kiev as its capital is known as ukraine
The country with bern as its capital is known as switzerland
The country with london as its capital is known as
2024-07-29 18:32:39 root INFO     [order_1_approx] starting weight calculation for The country with london as its capital is known as england
The country with bern as its capital is known as switzerland
The country with oslo as its capital is known as norway
The country with jakarta as its capital is known as indonesia
The country with berlin as its capital is known as germany
The country with kiev as its capital is known as ukraine
The country with tehran as its capital is known as iran
The country with belgrade as its capital is known as
2024-07-29 18:32:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 18:34:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7842,  0.3730, -0.6836,  ...,  0.4751, -0.0365,  0.2903],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7764, -6.6719, -2.5000,  ..., -2.1445,  1.5127, -2.8281],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.4780e-02,  1.0910e-03, -1.9550e-03,  ...,  1.4313e-02,
         -1.4946e-02, -4.5090e-03],
        [ 1.4648e-02,  3.2013e-02,  3.0823e-02,  ...,  1.9562e-02,
          5.6000e-03, -2.8503e-02],
        [-6.2943e-05,  1.2100e-02,  5.5939e-02,  ..., -5.4169e-04,
         -6.6872e-03, -9.1324e-03],
        ...,
        [ 1.2665e-02,  1.5205e-02,  1.7347e-03,  ...,  5.3192e-02,
         -4.6158e-04,  2.3499e-03],
        [ 3.7079e-03,  1.7334e-02, -9.6741e-03,  ...,  3.5667e-04,
          3.4393e-02, -5.4398e-03],
        [-2.2720e-02,  1.2024e-02, -2.7435e-02,  ...,  2.8610e-04,
          9.0561e-03,  1.4114e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4788, -6.4023, -2.4961,  ..., -2.1230,  1.0176, -2.9941]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 18:34:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with london as its capital is known as england
The country with bern as its capital is known as switzerland
The country with oslo as its capital is known as norway
The country with jakarta as its capital is known as indonesia
The country with berlin as its capital is known as germany
The country with kiev as its capital is known as ukraine
The country with tehran as its capital is known as iran
The country with belgrade as its capital is known as
2024-07-29 18:34:52 root INFO     [order_1_approx] starting weight calculation for The country with oslo as its capital is known as norway
The country with belgrade as its capital is known as serbia
The country with london as its capital is known as england
The country with bern as its capital is known as switzerland
The country with berlin as its capital is known as germany
The country with kiev as its capital is known as ukraine
The country with tehran as its capital is known as iran
The country with jakarta as its capital is known as
2024-07-29 18:34:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 18:37:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2983,  0.2424, -0.5200,  ...,  0.5864, -0.3098,  0.2913],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6426, -5.8359, -0.5039,  ..., -1.6699, -1.6797, -4.4062],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0395, -0.0053, -0.0060,  ...,  0.0115, -0.0007, -0.0036],
        [-0.0054,  0.0417,  0.0114,  ..., -0.0165, -0.0045, -0.0226],
        [ 0.0038,  0.0109,  0.0482,  ...,  0.0069,  0.0003, -0.0119],
        ...,
        [-0.0158,  0.0139,  0.0117,  ...,  0.0405,  0.0186, -0.0150],
        [ 0.0019,  0.0164, -0.0011,  ..., -0.0014,  0.0070, -0.0083],
        [-0.0078,  0.0064, -0.0057,  ..., -0.0046, -0.0041,  0.0201]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4414, -5.6953, -0.6221,  ..., -1.5586, -1.6709, -4.1055]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 18:37:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with oslo as its capital is known as norway
The country with belgrade as its capital is known as serbia
The country with london as its capital is known as england
The country with bern as its capital is known as switzerland
The country with berlin as its capital is known as germany
The country with kiev as its capital is known as ukraine
The country with tehran as its capital is known as iran
The country with jakarta as its capital is known as
2024-07-29 18:37:04 root INFO     [order_1_approx] starting weight calculation for The country with oslo as its capital is known as norway
The country with tehran as its capital is known as iran
The country with bern as its capital is known as switzerland
The country with belgrade as its capital is known as serbia
The country with london as its capital is known as england
The country with berlin as its capital is known as germany
The country with jakarta as its capital is known as indonesia
The country with kiev as its capital is known as
2024-07-29 18:37:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 18:39:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.8252, -0.0221, -0.3699,  ...,  0.2244, -0.4121, -0.0504],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1172, -4.5508, -1.4746,  ...,  0.4917, -0.3218, -3.6719],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0392, -0.0151, -0.0109,  ...,  0.0072,  0.0008,  0.0026],
        [-0.0056,  0.0412,  0.0064,  ...,  0.0102,  0.0078, -0.0057],
        [ 0.0119,  0.0191,  0.0428,  ...,  0.0110, -0.0042, -0.0110],
        ...,
        [-0.0066,  0.0172, -0.0079,  ...,  0.0486,  0.0118, -0.0163],
        [-0.0009,  0.0008, -0.0022,  ...,  0.0019,  0.0235, -0.0073],
        [-0.0113, -0.0095,  0.0003,  ...,  0.0019, -0.0036,  0.0159]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.1641, -4.4141, -1.5928,  ...,  0.3286, -0.5122, -3.4316]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 18:39:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with oslo as its capital is known as norway
The country with tehran as its capital is known as iran
The country with bern as its capital is known as switzerland
The country with belgrade as its capital is known as serbia
The country with london as its capital is known as england
The country with berlin as its capital is known as germany
The country with jakarta as its capital is known as indonesia
The country with kiev as its capital is known as
2024-07-29 18:39:17 root INFO     [order_1_approx] starting weight calculation for The country with belgrade as its capital is known as serbia
The country with tehran as its capital is known as iran
The country with kiev as its capital is known as ukraine
The country with berlin as its capital is known as germany
The country with bern as its capital is known as switzerland
The country with london as its capital is known as england
The country with jakarta as its capital is known as indonesia
The country with oslo as its capital is known as
2024-07-29 18:39:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 18:41:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3855,  0.1322, -0.6582,  ...,  0.4036,  0.0204,  0.1949],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.5938, -4.7578, -3.1055,  ..., -1.6670, -0.8281, -4.7578],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0396,  0.0026, -0.0066,  ...,  0.0024,  0.0068, -0.0059],
        [-0.0040,  0.0309,  0.0047,  ..., -0.0086, -0.0011, -0.0119],
        [-0.0031,  0.0139,  0.0414,  ...,  0.0066,  0.0058, -0.0054],
        ...,
        [-0.0093,  0.0172,  0.0061,  ...,  0.0513,  0.0132, -0.0052],
        [ 0.0164,  0.0219, -0.0100,  ...,  0.0177,  0.0396,  0.0040],
        [-0.0106, -0.0055, -0.0003,  ...,  0.0065, -0.0154,  0.0185]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.5430, -4.7891, -3.0527,  ..., -1.5771, -0.7920, -4.6562]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 18:41:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with belgrade as its capital is known as serbia
The country with tehran as its capital is known as iran
The country with kiev as its capital is known as ukraine
The country with berlin as its capital is known as germany
The country with bern as its capital is known as switzerland
The country with london as its capital is known as england
The country with jakarta as its capital is known as indonesia
The country with oslo as its capital is known as
2024-07-29 18:41:29 root INFO     total operator prediction time: 1051.2411432266235 seconds
2024-07-29 18:41:29 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on name - occupation
2024-07-29 18:41:29 root INFO     building operator name - occupation
2024-07-29 18:41:29 root INFO     [order_1_approx] starting weight calculation for lincoln was known for their work as a  president
tolstoi was known for their work as a  novelist
truman was known for their work as a  president
picasso was known for their work as a  painter
caesar was known for their work as a  emperor
balzac was known for their work as a  novelist
wittgenstein was known for their work as a  philosopher
darwin was known for their work as a 
2024-07-29 18:41:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 18:43:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3726, -0.1908,  0.1532,  ...,  0.3152,  0.1304,  0.4004],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1094, -5.0391,  1.8672,  ..., -5.0625, -1.2461, -1.6240],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0351, -0.0133, -0.0027,  ..., -0.0135, -0.0067,  0.0049],
        [ 0.0002,  0.0382, -0.0015,  ..., -0.0021, -0.0034, -0.0101],
        [ 0.0120, -0.0139,  0.0426,  ..., -0.0094,  0.0019,  0.0076],
        ...,
        [ 0.0160, -0.0052, -0.0019,  ...,  0.0359,  0.0087, -0.0049],
        [-0.0062,  0.0118,  0.0010,  ...,  0.0016,  0.0316, -0.0107],
        [-0.0133,  0.0024,  0.0057,  ..., -0.0048, -0.0013,  0.0446]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0039, -5.1797,  1.8418,  ..., -4.9648, -1.1914, -1.2686]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 18:43:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for lincoln was known for their work as a  president
tolstoi was known for their work as a  novelist
truman was known for their work as a  president
picasso was known for their work as a  painter
caesar was known for their work as a  emperor
balzac was known for their work as a  novelist
wittgenstein was known for their work as a  philosopher
darwin was known for their work as a 
2024-07-29 18:43:42 root INFO     [order_1_approx] starting weight calculation for wittgenstein was known for their work as a  philosopher
picasso was known for their work as a  painter
lincoln was known for their work as a  president
darwin was known for their work as a  naturalist
truman was known for their work as a  president
balzac was known for their work as a  novelist
tolstoi was known for their work as a  novelist
caesar was known for their work as a 
2024-07-29 18:43:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 18:45:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0396, -0.1410, -0.5977,  ...,  0.5825, -0.6494,  0.4138],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4697, -6.1875,  1.5908,  ..., -1.5938,  0.9258,  0.0264],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0619, -0.0034, -0.0059,  ..., -0.0100, -0.0175,  0.0118],
        [ 0.0077,  0.0434,  0.0130,  ..., -0.0065,  0.0056,  0.0067],
        [ 0.0236, -0.0008,  0.0725,  ...,  0.0009, -0.0060,  0.0180],
        ...,
        [ 0.0182,  0.0103, -0.0121,  ...,  0.0981,  0.0065, -0.0006],
        [ 0.0114,  0.0133,  0.0096,  ...,  0.0002,  0.0432, -0.0039],
        [ 0.0010,  0.0078, -0.0156,  ..., -0.0048,  0.0096,  0.0535]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0786, -5.8711,  1.5918,  ..., -2.0449,  0.6353, -0.0707]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 18:45:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for wittgenstein was known for their work as a  philosopher
picasso was known for their work as a  painter
lincoln was known for their work as a  president
darwin was known for their work as a  naturalist
truman was known for their work as a  president
balzac was known for their work as a  novelist
tolstoi was known for their work as a  novelist
caesar was known for their work as a 
2024-07-29 18:45:57 root INFO     [order_1_approx] starting weight calculation for tolstoi was known for their work as a  novelist
balzac was known for their work as a  novelist
caesar was known for their work as a  emperor
truman was known for their work as a  president
wittgenstein was known for their work as a  philosopher
picasso was known for their work as a  painter
darwin was known for their work as a  naturalist
lincoln was known for their work as a 
2024-07-29 18:45:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 18:48:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1725, -0.2627, -0.4194,  ...,  0.1259, -0.1879,  0.2159],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8164, -3.1816,  2.4902,  ..., -2.4648, -0.0166, -0.6201],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0441, -0.0004,  0.0073,  ...,  0.0020, -0.0074,  0.0069],
        [ 0.0012,  0.0433, -0.0002,  ..., -0.0087,  0.0015, -0.0045],
        [ 0.0187, -0.0081,  0.0437,  ...,  0.0023, -0.0013,  0.0008],
        ...,
        [ 0.0161,  0.0104, -0.0060,  ...,  0.0627, -0.0059,  0.0009],
        [-0.0131,  0.0099,  0.0096,  ..., -0.0032,  0.0201,  0.0021],
        [ 0.0004, -0.0090, -0.0062,  ...,  0.0014, -0.0134,  0.0466]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8281, -3.1855,  2.1660,  ..., -2.6641, -0.1108, -0.4429]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 18:48:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for tolstoi was known for their work as a  novelist
balzac was known for their work as a  novelist
caesar was known for their work as a  emperor
truman was known for their work as a  president
wittgenstein was known for their work as a  philosopher
picasso was known for their work as a  painter
darwin was known for their work as a  naturalist
lincoln was known for their work as a 
2024-07-29 18:48:09 root INFO     [order_1_approx] starting weight calculation for lincoln was known for their work as a  president
truman was known for their work as a  president
darwin was known for their work as a  naturalist
caesar was known for their work as a  emperor
wittgenstein was known for their work as a  philosopher
picasso was known for their work as a  painter
tolstoi was known for their work as a  novelist
balzac was known for their work as a 
2024-07-29 18:48:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 18:50:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4277, -0.1111, -0.2128,  ...,  0.1909, -0.2488,  0.0825],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1006, -3.7500,  3.0430,  ..., -3.6387, -1.3779,  0.4922],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0701, -0.0003,  0.0119,  ..., -0.0057, -0.0109, -0.0036],
        [ 0.0062,  0.0458,  0.0037,  ..., -0.0165,  0.0007, -0.0101],
        [ 0.0092,  0.0021,  0.0549,  ...,  0.0040,  0.0029,  0.0017],
        ...,
        [ 0.0044,  0.0145, -0.0125,  ...,  0.0760,  0.0147, -0.0076],
        [ 0.0038,  0.0069,  0.0137,  ...,  0.0030,  0.0405, -0.0044],
        [-0.0151,  0.0065, -0.0039,  ...,  0.0015, -0.0033,  0.0556]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1943, -3.5820,  2.8906,  ..., -3.6758, -1.1729,  0.3838]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 18:50:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for lincoln was known for their work as a  president
truman was known for their work as a  president
darwin was known for their work as a  naturalist
caesar was known for their work as a  emperor
wittgenstein was known for their work as a  philosopher
picasso was known for their work as a  painter
tolstoi was known for their work as a  novelist
balzac was known for their work as a 
2024-07-29 18:50:23 root INFO     [order_1_approx] starting weight calculation for picasso was known for their work as a  painter
wittgenstein was known for their work as a  philosopher
tolstoi was known for their work as a  novelist
balzac was known for their work as a  novelist
lincoln was known for their work as a  president
caesar was known for their work as a  emperor
darwin was known for their work as a  naturalist
truman was known for their work as a 
2024-07-29 18:50:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 18:52:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0405, -0.0922, -0.3037,  ...,  0.5083, -0.4089,  0.3276],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.4375, -2.3809,  2.9590,  ..., -2.9141,  1.0732, -0.0186],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0547, -0.0156,  0.0062,  ...,  0.0230, -0.0128,  0.0100],
        [-0.0173,  0.0533,  0.0078,  ...,  0.0029,  0.0033,  0.0037],
        [ 0.0135, -0.0107,  0.0474,  ...,  0.0053, -0.0031,  0.0159],
        ...,
        [ 0.0120,  0.0133, -0.0013,  ...,  0.0728, -0.0003,  0.0112],
        [-0.0006,  0.0170,  0.0003,  ...,  0.0051,  0.0356,  0.0134],
        [ 0.0083,  0.0075, -0.0100,  ...,  0.0088, -0.0065,  0.0614]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.9648, -2.5547,  2.5430,  ..., -2.8984,  1.3379, -0.1106]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 18:52:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for picasso was known for their work as a  painter
wittgenstein was known for their work as a  philosopher
tolstoi was known for their work as a  novelist
balzac was known for their work as a  novelist
lincoln was known for their work as a  president
caesar was known for their work as a  emperor
darwin was known for their work as a  naturalist
truman was known for their work as a 
2024-07-29 18:52:35 root INFO     [order_1_approx] starting weight calculation for picasso was known for their work as a  painter
balzac was known for their work as a  novelist
caesar was known for their work as a  emperor
darwin was known for their work as a  naturalist
lincoln was known for their work as a  president
wittgenstein was known for their work as a  philosopher
truman was known for their work as a  president
tolstoi was known for their work as a 
2024-07-29 18:52:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 18:54:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.8179,  0.1227, -0.4006,  ..., -0.0973, -0.4604,  0.2710],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9390, -5.6562,  2.8301,  ..., -5.5742, -2.7441, -0.3472],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0521, -0.0062,  0.0155,  ..., -0.0033, -0.0211,  0.0082],
        [-0.0022,  0.0481,  0.0002,  ..., -0.0132,  0.0056, -0.0030],
        [ 0.0166, -0.0025,  0.0390,  ...,  0.0018,  0.0067,  0.0053],
        ...,
        [ 0.0035,  0.0116, -0.0048,  ...,  0.0599,  0.0174, -0.0143],
        [ 0.0016,  0.0118,  0.0073,  ...,  0.0011,  0.0242, -0.0005],
        [-0.0093,  0.0101, -0.0046,  ...,  0.0001, -0.0045,  0.0425]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7197, -5.4062,  2.3984,  ..., -5.3906, -2.4043, -0.4995]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 18:54:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for picasso was known for their work as a  painter
balzac was known for their work as a  novelist
caesar was known for their work as a  emperor
darwin was known for their work as a  naturalist
lincoln was known for their work as a  president
wittgenstein was known for their work as a  philosopher
truman was known for their work as a  president
tolstoi was known for their work as a 
2024-07-29 18:54:47 root INFO     [order_1_approx] starting weight calculation for balzac was known for their work as a  novelist
wittgenstein was known for their work as a  philosopher
tolstoi was known for their work as a  novelist
lincoln was known for their work as a  president
caesar was known for their work as a  emperor
darwin was known for their work as a  naturalist
truman was known for their work as a  president
picasso was known for their work as a 
2024-07-29 18:54:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 18:56:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0055, -0.3364, -0.2134,  ...,  0.6772, -0.2434,  0.1145],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8672, -6.8789,  0.9746,  ..., -3.9258, -0.8804, -1.9824],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.0283e-02, -6.0225e-04,  8.3466e-03,  ...,  1.8559e-03,
         -2.2217e-02, -1.0395e-03],
        [ 9.0408e-04,  3.3264e-02,  1.5440e-03,  ..., -1.0834e-02,
          2.3098e-03,  7.6294e-05],
        [ 2.0432e-02,  6.5994e-03,  4.2358e-02,  ..., -4.5547e-03,
          3.0785e-03, -3.6049e-04],
        ...,
        [ 2.9144e-03, -1.1797e-03, -9.2773e-03,  ...,  5.2673e-02,
          2.7332e-03,  5.7983e-03],
        [-1.7843e-03,  4.2839e-03,  5.7907e-03,  ...,  4.9057e-03,
          2.3682e-02, -7.0038e-03],
        [-5.3024e-03,  8.9264e-04,  5.3329e-03,  ..., -2.4719e-02,
         -5.2452e-04,  3.7354e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7910, -6.7461,  1.0918,  ..., -3.9531, -0.8057, -1.7979]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 18:56:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for balzac was known for their work as a  novelist
wittgenstein was known for their work as a  philosopher
tolstoi was known for their work as a  novelist
lincoln was known for their work as a  president
caesar was known for their work as a  emperor
darwin was known for their work as a  naturalist
truman was known for their work as a  president
picasso was known for their work as a 
2024-07-29 18:56:58 root INFO     [order_1_approx] starting weight calculation for lincoln was known for their work as a  president
tolstoi was known for their work as a  novelist
picasso was known for their work as a  painter
caesar was known for their work as a  emperor
balzac was known for their work as a  novelist
darwin was known for their work as a  naturalist
truman was known for their work as a  president
wittgenstein was known for their work as a 
2024-07-29 18:56:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 18:59:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1262, -0.4114, -0.2460,  ...,  0.6465, -0.1489,  0.5151],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6309, -3.6094,  2.1504,  ..., -4.5117, -1.7627, -1.3262],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.2969e-02, -1.1703e-02,  9.0179e-03,  ..., -1.2100e-02,
         -1.5556e-02,  8.0013e-04],
        [-1.8492e-03,  3.9520e-02, -7.4120e-03,  ..., -6.8893e-03,
         -8.1100e-03, -1.7195e-03],
        [ 6.3705e-03, -1.1978e-02,  5.2460e-02,  ..., -1.0513e-02,
          4.5929e-03,  9.7809e-03],
        ...,
        [ 1.7426e-02,  5.1117e-04, -6.1035e-05,  ...,  3.6743e-02,
          1.2871e-02, -8.2970e-04],
        [ 2.9945e-04,  1.4519e-02,  5.9090e-03,  ...,  1.2184e-02,
          1.9501e-02, -9.5062e-03],
        [ 1.7824e-03,  8.3771e-03, -1.0109e-04,  ..., -2.4796e-04,
         -2.1248e-03,  3.8513e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7891, -3.4941,  2.2812,  ..., -4.3438, -1.7939, -1.2100]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 18:59:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for lincoln was known for their work as a  president
tolstoi was known for their work as a  novelist
picasso was known for their work as a  painter
caesar was known for their work as a  emperor
balzac was known for their work as a  novelist
darwin was known for their work as a  naturalist
truman was known for their work as a  president
wittgenstein was known for their work as a 
2024-07-29 18:59:08 root INFO     total operator prediction time: 1058.4310944080353 seconds
2024-07-29 18:59:08 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on male - female
2024-07-29 18:59:08 root INFO     building operator male - female
2024-07-29 18:59:08 root INFO     [order_1_approx] starting weight calculation for A female buck is known as a doe
A female gentleman is known as a lady
A female king is known as a queen
A female son is known as a daughter
A female manager is known as a manageress
A female grandson is known as a granddaughter
A female grandfather is known as a grandmother
A female heir is known as a
2024-07-29 18:59:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 19:01:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3118,  0.1372, -0.4072,  ...,  0.1350, -0.0469,  0.1274],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7676, -3.3984,  2.4609,  ..., -3.3945, -5.3750,  2.1992],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0604, -0.0057,  0.0018,  ..., -0.0042,  0.0025,  0.0013],
        [-0.0103,  0.0422, -0.0025,  ...,  0.0172,  0.0247, -0.0244],
        [-0.0059,  0.0028,  0.0504,  ..., -0.0106, -0.0126, -0.0068],
        ...,
        [-0.0043,  0.0122,  0.0011,  ...,  0.0612, -0.0046, -0.0093],
        [-0.0186,  0.0243, -0.0037,  ...,  0.0065,  0.0482,  0.0006],
        [-0.0043,  0.0209,  0.0009,  ..., -0.0084,  0.0032,  0.0578]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7500, -2.9863,  2.1582,  ..., -3.5078, -5.1484,  2.2930]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 19:01:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female buck is known as a doe
A female gentleman is known as a lady
A female king is known as a queen
A female son is known as a daughter
A female manager is known as a manageress
A female grandson is known as a granddaughter
A female grandfather is known as a grandmother
A female heir is known as a
2024-07-29 19:01:21 root INFO     [order_1_approx] starting weight calculation for A female manager is known as a manageress
A female king is known as a queen
A female heir is known as a heiress
A female buck is known as a doe
A female son is known as a daughter
A female grandson is known as a granddaughter
A female grandfather is known as a grandmother
A female gentleman is known as a
2024-07-29 19:01:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 19:03:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.8525,  0.5654, -0.3752,  ...,  0.1594, -0.6680,  0.1825],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.0000, -1.2383, -3.1465,  ...,  0.8535, -3.6973, -1.3105],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.7434e-02, -2.7176e-02,  2.6596e-02,  ...,  1.6953e-02,
         -1.8219e-02,  2.5909e-02],
        [-1.7532e-02,  6.0791e-02,  3.2959e-02,  ...,  3.2928e-02,
          2.4185e-03,  8.5602e-03],
        [ 2.8229e-02, -1.7792e-02,  3.5187e-02,  ..., -3.7109e-02,
         -1.1864e-03, -1.0681e-04],
        ...,
        [-3.2104e-02,  1.3123e-02,  4.9744e-02,  ...,  1.1951e-01,
         -6.5498e-03, -4.9667e-03],
        [-1.6891e-02,  7.6675e-03,  5.8212e-03,  ..., -4.4899e-03,
          2.3544e-02,  3.2654e-03],
        [ 7.7438e-04,  2.4323e-02, -1.4496e-04,  ...,  9.0027e-04,
         -5.3711e-03,  2.4689e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.3594, -1.3438, -2.7031,  ...,  0.1621, -3.9434, -0.9297]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 19:03:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female manager is known as a manageress
A female king is known as a queen
A female heir is known as a heiress
A female buck is known as a doe
A female son is known as a daughter
A female grandson is known as a granddaughter
A female grandfather is known as a grandmother
A female gentleman is known as a
2024-07-29 19:03:33 root INFO     [order_1_approx] starting weight calculation for A female heir is known as a heiress
A female gentleman is known as a lady
A female grandson is known as a granddaughter
A female manager is known as a manageress
A female buck is known as a doe
A female grandfather is known as a grandmother
A female son is known as a daughter
A female king is known as a
2024-07-29 19:03:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 19:05:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5947,  0.2859, -0.1641,  ...,  0.3494, -0.3364, -0.0351],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4619, -3.1836,  0.9863,  ..., -2.7949, -4.4258, -0.3184],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0497, -0.0215,  0.0121,  ...,  0.0094,  0.0055, -0.0049],
        [-0.0058,  0.0299,  0.0092,  ...,  0.0202,  0.0247,  0.0046],
        [-0.0061,  0.0064,  0.0433,  ..., -0.0011,  0.0005,  0.0108],
        ...,
        [-0.0188,  0.0149,  0.0077,  ...,  0.0696,  0.0011, -0.0159],
        [ 0.0124, -0.0119,  0.0060,  ..., -0.0044,  0.0297,  0.0111],
        [-0.0146, -0.0082, -0.0016,  ..., -0.0099,  0.0037,  0.0394]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6904, -2.8965,  0.9287,  ..., -2.9746, -4.7227, -0.2252]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 19:05:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female heir is known as a heiress
A female gentleman is known as a lady
A female grandson is known as a granddaughter
A female manager is known as a manageress
A female buck is known as a doe
A female grandfather is known as a grandmother
A female son is known as a daughter
A female king is known as a
2024-07-29 19:05:45 root INFO     [order_1_approx] starting weight calculation for A female gentleman is known as a lady
A female heir is known as a heiress
A female king is known as a queen
A female manager is known as a manageress
A female buck is known as a doe
A female grandson is known as a granddaughter
A female grandfather is known as a grandmother
A female son is known as a
2024-07-29 19:05:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 19:07:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0042,  0.7075,  0.7495,  ...,  0.1619, -0.0638, -0.2212],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.3164, -1.1943, -1.5693,  ...,  2.2480, -3.2539,  0.2900],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0503, -0.0283,  0.0136,  ...,  0.0073, -0.0049,  0.0214],
        [ 0.0194,  0.0396, -0.0108,  ...,  0.0061,  0.0117, -0.0431],
        [-0.0031, -0.0094,  0.0444,  ..., -0.0238,  0.0084, -0.0296],
        ...,
        [-0.0220,  0.0072, -0.0141,  ...,  0.0702, -0.0102, -0.0167],
        [ 0.0008,  0.0030,  0.0097,  ..., -0.0005,  0.0403,  0.0007],
        [ 0.0033, -0.0048, -0.0061,  ...,  0.0079, -0.0124,  0.0326]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.0039, -0.4263, -1.5605,  ...,  2.4570, -3.3750,  0.3555]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 19:07:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female gentleman is known as a lady
A female heir is known as a heiress
A female king is known as a queen
A female manager is known as a manageress
A female buck is known as a doe
A female grandson is known as a granddaughter
A female grandfather is known as a grandmother
A female son is known as a
2024-07-29 19:07:56 root INFO     [order_1_approx] starting weight calculation for A female son is known as a daughter
A female manager is known as a manageress
A female buck is known as a doe
A female gentleman is known as a lady
A female grandfather is known as a grandmother
A female king is known as a queen
A female heir is known as a heiress
A female grandson is known as a
2024-07-29 19:07:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 19:10:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1918,  0.6875,  0.5840,  ...,  0.0338, -0.3066, -0.0715],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1758, -0.6299, -2.0117,  ...,  1.4688, -2.9180, -1.5977],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.3091e-02, -2.1591e-02,  5.7449e-03,  ...,  7.6218e-03,
          7.2975e-03,  4.6997e-03],
        [ 9.3842e-03,  3.1113e-02, -8.3694e-03,  ...,  3.1776e-03,
          1.0895e-02, -2.5436e-02],
        [ 1.6434e-02,  2.0294e-03,  4.2480e-02,  ..., -8.7585e-03,
         -1.6327e-03, -2.2919e-02],
        ...,
        [-1.5900e-02,  1.1421e-02, -1.3016e-02,  ...,  5.4199e-02,
         -2.0390e-03, -3.9940e-03],
        [-4.9591e-05, -3.7670e-03,  1.1706e-04,  ..., -2.7275e-03,
          2.4429e-02,  1.6495e-02],
        [ 6.4507e-03, -6.5842e-03, -5.4550e-04,  ...,  2.2526e-03,
          3.1509e-03,  2.0020e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.1914, -0.2063, -2.1133,  ...,  1.5742, -2.8613, -1.4062]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 19:10:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female son is known as a daughter
A female manager is known as a manageress
A female buck is known as a doe
A female gentleman is known as a lady
A female grandfather is known as a grandmother
A female king is known as a queen
A female heir is known as a heiress
A female grandson is known as a
2024-07-29 19:10:09 root INFO     [order_1_approx] starting weight calculation for A female grandson is known as a granddaughter
A female gentleman is known as a lady
A female king is known as a queen
A female heir is known as a heiress
A female buck is known as a doe
A female son is known as a daughter
A female manager is known as a manageress
A female grandfather is known as a
2024-07-29 19:10:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 19:12:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7529,  0.3232, -0.0742,  ..., -0.1085, -0.2183, -0.0559],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1719, -0.8862, -0.3071,  ...,  0.4219, -3.4844, -1.7949],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0286, -0.0177,  0.0369,  ...,  0.0453, -0.0168,  0.0151],
        [ 0.0181,  0.0222,  0.0019,  ...,  0.0275,  0.0063, -0.0081],
        [ 0.0039, -0.0084,  0.0411,  ...,  0.0033,  0.0113, -0.0019],
        ...,
        [-0.0063,  0.0090, -0.0017,  ...,  0.0437,  0.0004, -0.0044],
        [ 0.0042, -0.0037,  0.0135,  ...,  0.0141,  0.0294,  0.0156],
        [-0.0072, -0.0130,  0.0005,  ..., -0.0029,  0.0039,  0.0279]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5273, -0.7710, -0.4138,  ...,  0.8701, -3.5039, -1.8975]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 19:12:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female grandson is known as a granddaughter
A female gentleman is known as a lady
A female king is known as a queen
A female heir is known as a heiress
A female buck is known as a doe
A female son is known as a daughter
A female manager is known as a manageress
A female grandfather is known as a
2024-07-29 19:12:22 root INFO     [order_1_approx] starting weight calculation for A female buck is known as a doe
A female heir is known as a heiress
A female grandfather is known as a grandmother
A female son is known as a daughter
A female grandson is known as a granddaughter
A female gentleman is known as a lady
A female king is known as a queen
A female manager is known as a
2024-07-29 19:12:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 19:14:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2651,  0.5342, -0.1265,  ...,  0.7188, -0.7070, -0.7910],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.4219, -5.7148,  0.5581,  ...,  2.0234, -1.9082, -3.8164],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0533, -0.0289, -0.0134,  ..., -0.0033, -0.0034, -0.0051],
        [ 0.0155,  0.0771,  0.0108,  ...,  0.0144,  0.0187, -0.0198],
        [ 0.0108, -0.0025,  0.0642,  ..., -0.0082, -0.0261,  0.0102],
        ...,
        [-0.0169,  0.0171,  0.0106,  ...,  0.0695,  0.0172, -0.0059],
        [-0.0172,  0.0069,  0.0153,  ...,  0.0070,  0.0244, -0.0134],
        [ 0.0123, -0.0063, -0.0179,  ..., -0.0208,  0.0072,  0.0404]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.4219, -5.6367, -0.1724,  ...,  1.9385, -2.2656, -3.1016]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 19:14:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female buck is known as a doe
A female heir is known as a heiress
A female grandfather is known as a grandmother
A female son is known as a daughter
A female grandson is known as a granddaughter
A female gentleman is known as a lady
A female king is known as a queen
A female manager is known as a
2024-07-29 19:14:33 root INFO     [order_1_approx] starting weight calculation for A female king is known as a queen
A female son is known as a daughter
A female grandson is known as a granddaughter
A female grandfather is known as a grandmother
A female manager is known as a manageress
A female gentleman is known as a lady
A female heir is known as a heiress
A female buck is known as a
2024-07-29 19:14:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 19:16:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5112,  0.4634,  0.0381,  ...,  0.1465, -0.4497,  0.2917],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9219, -2.7559, -1.2266,  ...,  2.4883, -5.5820,  0.8569],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0435,  0.0181,  0.0091,  ...,  0.0019, -0.0046, -0.0189],
        [ 0.0110,  0.0455, -0.0217,  ...,  0.0249,  0.0307, -0.0125],
        [-0.0220, -0.0244,  0.0544,  ..., -0.0129, -0.0187, -0.0164],
        ...,
        [-0.0046, -0.0240,  0.0082,  ...,  0.0732,  0.0174, -0.0236],
        [-0.0429,  0.0389,  0.0058,  ..., -0.0548,  0.0273, -0.0448],
        [-0.0304, -0.0166, -0.0022,  ..., -0.0423, -0.0023,  0.0361]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.1445, -2.6895, -1.0752,  ...,  1.8848, -5.4336,  0.9043]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 19:16:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female king is known as a queen
A female son is known as a daughter
A female grandson is known as a granddaughter
A female grandfather is known as a grandmother
A female manager is known as a manageress
A female gentleman is known as a lady
A female heir is known as a heiress
A female buck is known as a
2024-07-29 19:16:44 root INFO     total operator prediction time: 1056.5101668834686 seconds
2024-07-29 19:16:44 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - shelter
2024-07-29 19:16:44 root INFO     building operator animal - shelter
2024-07-29 19:16:44 root INFO     [order_1_approx] starting weight calculation for The place ape lives in is called grove
The place horse lives in is called stable
The place hornet lives in is called nest
The place termite lives in is called hill
The place wolf lives in is called den
The place locust lives in is called nest
The place cockroach lives in is called nest
The place scorpion lives in is called
2024-07-29 19:16:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 19:18:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0801,  0.0251, -0.0033,  ..., -0.0980, -0.1990, -0.2942],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5664, -5.1875,  1.6289,  ..., -1.9756,  0.1306, -1.0361],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.7181e-02,  2.7332e-03,  4.7989e-03,  ...,  7.1793e-03,
         -8.4457e-03, -2.6970e-03],
        [-7.9651e-03,  6.1035e-04,  1.1883e-03,  ..., -7.1716e-03,
          5.0163e-03, -8.4763e-03],
        [-3.0823e-03,  1.6022e-02,  1.4832e-02,  ...,  4.1351e-03,
         -1.2531e-03,  4.3106e-03],
        ...,
        [ 2.5606e-04, -2.1839e-04,  4.1122e-03,  ...,  2.1851e-02,
          8.8043e-03, -5.7220e-06],
        [-7.5150e-04,  2.3594e-03, -4.3716e-03,  ...,  2.7657e-03,
          1.6724e-02, -4.8370e-03],
        [-5.2452e-03, -4.9472e-06, -2.5768e-03,  ..., -4.1809e-03,
         -4.6692e-03,  1.6846e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4746, -5.2266,  1.6094,  ..., -1.9678,  0.1326, -1.0342]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 19:18:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place ape lives in is called grove
The place horse lives in is called stable
The place hornet lives in is called nest
The place termite lives in is called hill
The place wolf lives in is called den
The place locust lives in is called nest
The place cockroach lives in is called nest
The place scorpion lives in is called
2024-07-29 19:18:57 root INFO     [order_1_approx] starting weight calculation for The place locust lives in is called nest
The place cockroach lives in is called nest
The place horse lives in is called stable
The place ape lives in is called grove
The place scorpion lives in is called nest
The place hornet lives in is called nest
The place wolf lives in is called den
The place termite lives in is called
2024-07-29 19:18:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 19:21:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3569, -0.4565,  0.0732,  ...,  0.1616, -0.2937, -0.0636],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0391, -7.2969,  1.7607,  ..., -3.9219,  0.7012, -1.4180],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0627,  0.0091,  0.0183,  ...,  0.0318, -0.0262,  0.0112],
        [-0.0030,  0.0398,  0.0222,  ...,  0.0059, -0.0014, -0.0194],
        [-0.0040,  0.0451,  0.0603,  ...,  0.0063, -0.0145,  0.0179],
        ...,
        [-0.0004, -0.0035,  0.0044,  ...,  0.0528,  0.0292,  0.0012],
        [ 0.0070,  0.0097, -0.0010,  ...,  0.0323,  0.0529,  0.0184],
        [ 0.0078, -0.0140, -0.0099,  ...,  0.0078, -0.0171,  0.0662]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3652, -7.3008,  1.8428,  ..., -3.9727,  0.7905, -1.1631]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 19:21:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place locust lives in is called nest
The place cockroach lives in is called nest
The place horse lives in is called stable
The place ape lives in is called grove
The place scorpion lives in is called nest
The place hornet lives in is called nest
The place wolf lives in is called den
The place termite lives in is called
2024-07-29 19:21:11 root INFO     [order_1_approx] starting weight calculation for The place ape lives in is called grove
The place hornet lives in is called nest
The place locust lives in is called nest
The place scorpion lives in is called nest
The place cockroach lives in is called nest
The place horse lives in is called stable
The place termite lives in is called hill
The place wolf lives in is called
2024-07-29 19:21:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 19:23:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4360, -0.2512,  0.0571,  ...,  0.5454, -0.1097, -0.3052],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8418, -9.6719,  2.9355,  ..., -3.2539,  0.0220,  1.7969],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.4200e-02, -5.3482e-03, -3.3379e-03,  ...,  2.4704e-02,
         -1.6251e-02,  8.7738e-05],
        [-3.6201e-03,  2.1698e-02,  1.3931e-02,  ..., -8.4076e-03,
         -1.2802e-02, -2.3209e-02],
        [-6.7596e-03,  1.9623e-02,  5.1392e-02,  ..., -1.3351e-03,
         -3.3951e-03, -2.7142e-03],
        ...,
        [-4.8409e-03, -1.7807e-02,  2.3743e-02,  ...,  4.5502e-02,
          4.4098e-03,  2.7637e-03],
        [ 2.2461e-02, -1.1501e-03, -4.2648e-03,  ...,  6.2523e-03,
          4.9866e-02, -8.2779e-03],
        [-4.3411e-03, -1.3313e-02, -1.4198e-02,  ..., -2.2125e-02,
         -1.0696e-02,  2.6764e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0195, -9.2031,  2.8691,  ..., -3.2871, -0.4661,  2.1758]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 19:23:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place ape lives in is called grove
The place hornet lives in is called nest
The place locust lives in is called nest
The place scorpion lives in is called nest
The place cockroach lives in is called nest
The place horse lives in is called stable
The place termite lives in is called hill
The place wolf lives in is called
2024-07-29 19:23:24 root INFO     [order_1_approx] starting weight calculation for The place hornet lives in is called nest
The place horse lives in is called stable
The place termite lives in is called hill
The place scorpion lives in is called nest
The place wolf lives in is called den
The place locust lives in is called nest
The place cockroach lives in is called nest
The place ape lives in is called
2024-07-29 19:23:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 19:25:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1929, -0.1996, -0.1995,  ...,  0.0535, -0.3098, -0.0222],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9629, -8.0781,  2.0156,  ..., -1.9482, -2.7891,  0.7910],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0168, -0.0034, -0.0108,  ..., -0.0041, -0.0084, -0.0161],
        [-0.0081,  0.0233,  0.0044,  ..., -0.0291, -0.0123, -0.0054],
        [-0.0113,  0.0204,  0.0334,  ...,  0.0065,  0.0206, -0.0127],
        ...,
        [ 0.0124,  0.0127,  0.0199,  ...,  0.0609, -0.0004,  0.0034],
        [-0.0034,  0.0044, -0.0149,  ...,  0.0002,  0.0414, -0.0047],
        [-0.0134,  0.0068, -0.0098,  ..., -0.0235, -0.0186,  0.0556]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1719, -7.3281,  1.3008,  ..., -1.7549, -3.2773,  1.1211]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 19:25:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place hornet lives in is called nest
The place horse lives in is called stable
The place termite lives in is called hill
The place scorpion lives in is called nest
The place wolf lives in is called den
The place locust lives in is called nest
The place cockroach lives in is called nest
The place ape lives in is called
2024-07-29 19:25:37 root INFO     [order_1_approx] starting weight calculation for The place ape lives in is called grove
The place locust lives in is called nest
The place scorpion lives in is called nest
The place termite lives in is called hill
The place horse lives in is called stable
The place wolf lives in is called den
The place cockroach lives in is called nest
The place hornet lives in is called
2024-07-29 19:25:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 19:27:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1243, -0.0448,  0.2339,  ...,  0.6411, -0.2056,  0.0162],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0801, -6.7266,  2.2383,  ..., -3.1699,  0.5347, -1.7383],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0649,  0.0074,  0.0041,  ...,  0.0138, -0.0145, -0.0052],
        [-0.0245,  0.0635,  0.0136,  ...,  0.0108,  0.0011, -0.0251],
        [-0.0015,  0.0298,  0.0548,  ...,  0.0114, -0.0175,  0.0197],
        ...,
        [ 0.0023, -0.0005,  0.0172,  ...,  0.0759,  0.0121, -0.0047],
        [-0.0021,  0.0061,  0.0104,  ...,  0.0344,  0.0165,  0.0161],
        [-0.0149,  0.0004, -0.0207,  ..., -0.0030, -0.0150,  0.0494]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5234, -6.7227,  1.9570,  ..., -3.4199,  0.4370, -1.7334]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 19:27:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place ape lives in is called grove
The place locust lives in is called nest
The place scorpion lives in is called nest
The place termite lives in is called hill
The place horse lives in is called stable
The place wolf lives in is called den
The place cockroach lives in is called nest
The place hornet lives in is called
2024-07-29 19:27:51 root INFO     [order_1_approx] starting weight calculation for The place hornet lives in is called nest
The place scorpion lives in is called nest
The place wolf lives in is called den
The place ape lives in is called grove
The place horse lives in is called stable
The place cockroach lives in is called nest
The place termite lives in is called hill
The place locust lives in is called
2024-07-29 19:27:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 19:29:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2300, -0.4316,  0.3123,  ...,  0.1836, -0.2246, -0.1935],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1602, -5.5234,  2.3613,  ..., -0.4204,  0.8232, -2.9375],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0241, -0.0171,  0.0242,  ...,  0.0240, -0.0076,  0.0348],
        [ 0.0179,  0.0346,  0.0062,  ...,  0.0218, -0.0108, -0.0273],
        [ 0.0110,  0.0307,  0.0645,  ..., -0.0025, -0.0275, -0.0020],
        ...,
        [-0.0005,  0.0143,  0.0127,  ...,  0.0894,  0.0220,  0.0034],
        [-0.0008,  0.0021,  0.0040,  ...,  0.0237,  0.0303,  0.0093],
        [-0.0121, -0.0068,  0.0007,  ...,  0.0085, -0.0143,  0.0634]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0508, -5.5938,  2.3242,  ..., -0.6689,  0.5117, -3.1270]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 19:30:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place hornet lives in is called nest
The place scorpion lives in is called nest
The place wolf lives in is called den
The place ape lives in is called grove
The place horse lives in is called stable
The place cockroach lives in is called nest
The place termite lives in is called hill
The place locust lives in is called
2024-07-29 19:30:00 root INFO     [order_1_approx] starting weight calculation for The place scorpion lives in is called nest
The place termite lives in is called hill
The place wolf lives in is called den
The place locust lives in is called nest
The place ape lives in is called grove
The place hornet lives in is called nest
The place cockroach lives in is called nest
The place horse lives in is called
2024-07-29 19:30:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 19:32:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1229, -0.3220,  0.4009,  ...,  0.3289,  0.3699,  0.2549],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9609, -6.7500,  2.2363,  ..., -0.8662,  0.7168,  0.3066],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0329,  0.0035, -0.0022,  ...,  0.0036, -0.0198, -0.0010],
        [-0.0069,  0.0297,  0.0049,  ..., -0.0111, -0.0027,  0.0033],
        [ 0.0060,  0.0147,  0.0312,  ...,  0.0146,  0.0084, -0.0038],
        ...,
        [ 0.0144,  0.0006, -0.0012,  ...,  0.0364,  0.0086, -0.0113],
        [ 0.0136,  0.0183, -0.0178,  ...,  0.0187,  0.0506, -0.0098],
        [ 0.0099, -0.0048,  0.0051,  ..., -0.0130, -0.0125,  0.0448]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0215, -6.5703,  2.1602,  ..., -1.3799,  0.1304,  0.4458]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 19:32:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place scorpion lives in is called nest
The place termite lives in is called hill
The place wolf lives in is called den
The place locust lives in is called nest
The place ape lives in is called grove
The place hornet lives in is called nest
The place cockroach lives in is called nest
The place horse lives in is called
2024-07-29 19:32:09 root INFO     [order_1_approx] starting weight calculation for The place termite lives in is called hill
The place scorpion lives in is called nest
The place locust lives in is called nest
The place ape lives in is called grove
The place wolf lives in is called den
The place horse lives in is called stable
The place hornet lives in is called nest
The place cockroach lives in is called
2024-07-29 19:32:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 19:34:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0582, -0.5889, -0.3108,  ...,  0.2175, -0.2861, -0.4551],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5781, -5.8594,  4.6484,  ..., -2.0566,  0.2371, -0.5444],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0229,  0.0013,  0.0076,  ...,  0.0222, -0.0182, -0.0002],
        [-0.0027,  0.0160,  0.0035,  ..., -0.0194,  0.0019, -0.0091],
        [-0.0030,  0.0094,  0.0170,  ...,  0.0116, -0.0036,  0.0099],
        ...,
        [ 0.0048,  0.0044,  0.0009,  ...,  0.0146,  0.0068, -0.0009],
        [ 0.0006,  0.0042,  0.0003,  ...,  0.0148,  0.0107, -0.0046],
        [-0.0064, -0.0003, -0.0037,  ..., -0.0149, -0.0027,  0.0223]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4688, -5.6875,  4.6133,  ..., -2.0527,  0.1029, -0.4592]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 19:34:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place termite lives in is called hill
The place scorpion lives in is called nest
The place locust lives in is called nest
The place ape lives in is called grove
The place wolf lives in is called den
The place horse lives in is called stable
The place hornet lives in is called nest
The place cockroach lives in is called
2024-07-29 19:34:18 root INFO     total operator prediction time: 1053.787414073944 seconds
2024-07-29 19:34:18 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on country - language
2024-07-29 19:34:18 root INFO     building operator country - language
2024-07-29 19:34:18 root INFO     [order_1_approx] starting weight calculation for The country of taiwan primarily speaks the language of chinese
The country of cuba primarily speaks the language of spanish
The country of jamaica primarily speaks the language of english
The country of denmark primarily speaks the language of danish
The country of netherlands primarily speaks the language of dutch
The country of ethiopia primarily speaks the language of amharic
The country of argentina primarily speaks the language of spanish
The country of fiji primarily speaks the language of
2024-07-29 19:34:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 19:36:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4692, -0.1699, -0.4141,  ...,  0.1882, -0.2217,  0.0609],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0386,  0.3896,  3.6855,  ...,  1.2412, -3.5508, -0.0947],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0509,  0.0084,  0.0047,  ...,  0.0093, -0.0107, -0.0072],
        [ 0.0078,  0.0387, -0.0036,  ..., -0.0046, -0.0148, -0.0352],
        [-0.0273,  0.0039,  0.0605,  ...,  0.0197,  0.0123,  0.0029],
        ...,
        [-0.0226,  0.0105,  0.0109,  ...,  0.0571,  0.0134,  0.0041],
        [ 0.0130,  0.0032,  0.0050,  ..., -0.0025,  0.0380, -0.0100],
        [-0.0014, -0.0044,  0.0112,  ...,  0.0153,  0.0036,  0.0580]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2571,  0.5396,  3.4316,  ...,  1.0557, -3.2285,  0.1819]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 19:36:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of taiwan primarily speaks the language of chinese
The country of cuba primarily speaks the language of spanish
The country of jamaica primarily speaks the language of english
The country of denmark primarily speaks the language of danish
The country of netherlands primarily speaks the language of dutch
The country of ethiopia primarily speaks the language of amharic
The country of argentina primarily speaks the language of spanish
The country of fiji primarily speaks the language of
2024-07-29 19:36:29 root INFO     [order_1_approx] starting weight calculation for The country of taiwan primarily speaks the language of chinese
The country of argentina primarily speaks the language of spanish
The country of ethiopia primarily speaks the language of amharic
The country of fiji primarily speaks the language of english
The country of netherlands primarily speaks the language of dutch
The country of jamaica primarily speaks the language of english
The country of cuba primarily speaks the language of spanish
The country of denmark primarily speaks the language of
2024-07-29 19:36:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 19:38:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3325,  0.0218, -0.2361,  ...,  0.4282,  0.2418,  0.1272],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8491, -2.9453,  2.1641,  ..., -1.8369, -1.3037, -0.5898],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.7302e-02, -1.1475e-02,  1.9073e-05,  ...,  8.2016e-03,
          5.7983e-04, -8.4991e-03],
        [-7.2861e-03,  1.7975e-02,  9.6893e-03,  ..., -6.9695e-03,
         -3.8090e-03, -4.2191e-03],
        [-3.1311e-02, -7.5302e-03,  5.5786e-02,  ...,  1.9302e-02,
          1.0132e-02,  7.4005e-04],
        ...,
        [-1.9226e-03, -6.1750e-05,  1.7761e-02,  ...,  4.2236e-02,
          1.6571e-02,  1.8654e-03],
        [ 4.4289e-03,  4.1847e-03, -4.5013e-03,  ...,  8.1635e-03,
          3.0090e-02, -9.1324e-03],
        [-5.1041e-03, -1.7609e-02, -1.3168e-02,  ...,  3.3531e-03,
         -3.5915e-03,  3.0228e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6313, -2.7285,  1.8945,  ..., -1.9434, -1.3027, -0.3057]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 19:38:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of taiwan primarily speaks the language of chinese
The country of argentina primarily speaks the language of spanish
The country of ethiopia primarily speaks the language of amharic
The country of fiji primarily speaks the language of english
The country of netherlands primarily speaks the language of dutch
The country of jamaica primarily speaks the language of english
The country of cuba primarily speaks the language of spanish
The country of denmark primarily speaks the language of
2024-07-29 19:38:42 root INFO     [order_1_approx] starting weight calculation for The country of denmark primarily speaks the language of danish
The country of fiji primarily speaks the language of english
The country of argentina primarily speaks the language of spanish
The country of cuba primarily speaks the language of spanish
The country of jamaica primarily speaks the language of english
The country of taiwan primarily speaks the language of chinese
The country of netherlands primarily speaks the language of dutch
The country of ethiopia primarily speaks the language of
2024-07-29 19:38:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 19:40:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0847, -0.0747, -0.2355,  ...,  0.2083, -0.6519, -0.1741],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7329, -2.6211,  3.6133,  ..., -2.2910, -1.0879, -3.1758],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0252, -0.0007,  0.0066,  ...,  0.0090, -0.0098, -0.0056],
        [ 0.0028,  0.0206,  0.0041,  ..., -0.0030, -0.0005,  0.0035],
        [-0.0156, -0.0065,  0.0222,  ...,  0.0072,  0.0080,  0.0078],
        ...,
        [-0.0062, -0.0004, -0.0056,  ...,  0.0181,  0.0070,  0.0052],
        [ 0.0066,  0.0055, -0.0015,  ...,  0.0023,  0.0121, -0.0020],
        [ 0.0068,  0.0086, -0.0026,  ...,  0.0005, -0.0048,  0.0167]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6230, -2.6211,  3.6953,  ..., -2.2891, -1.0029, -3.1680]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 19:40:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of denmark primarily speaks the language of danish
The country of fiji primarily speaks the language of english
The country of argentina primarily speaks the language of spanish
The country of cuba primarily speaks the language of spanish
The country of jamaica primarily speaks the language of english
The country of taiwan primarily speaks the language of chinese
The country of netherlands primarily speaks the language of dutch
The country of ethiopia primarily speaks the language of
2024-07-29 19:40:54 root INFO     [order_1_approx] starting weight calculation for The country of argentina primarily speaks the language of spanish
The country of cuba primarily speaks the language of spanish
The country of denmark primarily speaks the language of danish
The country of ethiopia primarily speaks the language of amharic
The country of taiwan primarily speaks the language of chinese
The country of netherlands primarily speaks the language of dutch
The country of fiji primarily speaks the language of english
The country of jamaica primarily speaks the language of
2024-07-29 19:40:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 19:43:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1440,  0.1624, -0.1237,  ...,  0.3962, -0.5107, -0.1349],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0898,  0.2305,  2.0312,  ...,  0.9717,  0.6543, -1.8535],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0217,  0.0029,  0.0039,  ...,  0.0113, -0.0029, -0.0004],
        [-0.0027,  0.0142,  0.0051,  ..., -0.0003, -0.0071, -0.0032],
        [-0.0171, -0.0048,  0.0217,  ...,  0.0130,  0.0153,  0.0070],
        ...,
        [-0.0146,  0.0002, -0.0031,  ...,  0.0335,  0.0099,  0.0063],
        [-0.0059,  0.0052, -0.0088,  ..., -0.0031,  0.0187, -0.0002],
        [-0.0017, -0.0082,  0.0025,  ...,  0.0026,  0.0055,  0.0202]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1172,  0.2759,  2.0059,  ...,  1.0068,  0.6333, -1.7197]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 19:43:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of argentina primarily speaks the language of spanish
The country of cuba primarily speaks the language of spanish
The country of denmark primarily speaks the language of danish
The country of ethiopia primarily speaks the language of amharic
The country of taiwan primarily speaks the language of chinese
The country of netherlands primarily speaks the language of dutch
The country of fiji primarily speaks the language of english
The country of jamaica primarily speaks the language of
2024-07-29 19:43:07 root INFO     [order_1_approx] starting weight calculation for The country of jamaica primarily speaks the language of english
The country of netherlands primarily speaks the language of dutch
The country of argentina primarily speaks the language of spanish
The country of ethiopia primarily speaks the language of amharic
The country of fiji primarily speaks the language of english
The country of taiwan primarily speaks the language of chinese
The country of denmark primarily speaks the language of danish
The country of cuba primarily speaks the language of
2024-07-29 19:43:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 19:45:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0332,  0.0027,  0.2322,  ..., -0.0916, -0.2556, -0.0244],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7832, -2.5938,  1.4980,  ...,  0.9609, -0.4082, -2.0293],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.6255e-02,  3.6850e-03,  9.1095e-03,  ...,  1.7258e-02,
          1.0399e-02, -5.6076e-03],
        [-2.6474e-03,  4.4769e-02,  8.5297e-03,  ..., -1.2619e-02,
         -1.4946e-02, -9.7580e-03],
        [-1.3573e-02,  4.4174e-03,  3.8452e-02,  ...,  2.8488e-02,
          2.1866e-02,  1.7014e-02],
        ...,
        [-6.2027e-03, -1.5240e-03, -7.7782e-03,  ...,  3.8269e-02,
          1.7578e-02,  8.4839e-03],
        [-8.5526e-03, -5.9013e-03, -9.5520e-03,  ..., -8.4381e-03,
          8.4610e-03,  4.8714e-03],
        [ 5.7220e-05, -1.5823e-02,  4.3058e-04,  ..., -8.4763e-03,
          9.2163e-03,  2.2614e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6621, -2.1270,  1.1289,  ...,  0.2559, -0.1610, -1.8350]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 19:45:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of jamaica primarily speaks the language of english
The country of netherlands primarily speaks the language of dutch
The country of argentina primarily speaks the language of spanish
The country of ethiopia primarily speaks the language of amharic
The country of fiji primarily speaks the language of english
The country of taiwan primarily speaks the language of chinese
The country of denmark primarily speaks the language of danish
The country of cuba primarily speaks the language of
2024-07-29 19:45:10 root INFO     [order_1_approx] starting weight calculation for The country of fiji primarily speaks the language of english
The country of argentina primarily speaks the language of spanish
The country of netherlands primarily speaks the language of dutch
The country of jamaica primarily speaks the language of english
The country of ethiopia primarily speaks the language of amharic
The country of denmark primarily speaks the language of danish
The country of cuba primarily speaks the language of spanish
The country of taiwan primarily speaks the language of
2024-07-29 19:45:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 19:47:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1558, -0.1407,  0.3887,  ...,  0.8652, -0.1947,  0.2061],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.7861, -1.7080,  2.4238,  ..., -0.2112, -3.0996, -0.1011],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0291, -0.0007,  0.0049,  ...,  0.0020,  0.0012, -0.0101],
        [-0.0031,  0.0261,  0.0078,  ...,  0.0069, -0.0104, -0.0069],
        [-0.0059, -0.0082,  0.0350,  ...,  0.0127, -0.0038,  0.0171],
        ...,
        [-0.0004,  0.0063, -0.0021,  ...,  0.0346,  0.0090, -0.0026],
        [ 0.0086,  0.0051,  0.0007,  ...,  0.0028,  0.0103, -0.0122],
        [ 0.0101, -0.0084, -0.0081,  ...,  0.0014, -0.0055,  0.0205]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.5225, -1.7246,  1.8711,  ..., -0.1823, -3.0195,  0.0587]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 19:47:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of fiji primarily speaks the language of english
The country of argentina primarily speaks the language of spanish
The country of netherlands primarily speaks the language of dutch
The country of jamaica primarily speaks the language of english
The country of ethiopia primarily speaks the language of amharic
The country of denmark primarily speaks the language of danish
The country of cuba primarily speaks the language of spanish
The country of taiwan primarily speaks the language of
2024-07-29 19:47:22 root INFO     [order_1_approx] starting weight calculation for The country of fiji primarily speaks the language of english
The country of denmark primarily speaks the language of danish
The country of argentina primarily speaks the language of spanish
The country of taiwan primarily speaks the language of chinese
The country of cuba primarily speaks the language of spanish
The country of ethiopia primarily speaks the language of amharic
The country of jamaica primarily speaks the language of english
The country of netherlands primarily speaks the language of
2024-07-29 19:47:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 19:49:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3936, -0.0717,  0.0754,  ...,  0.4182, -0.0254,  0.0405],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4639, -2.7109,  1.6641,  ..., -0.9126, -0.8291, -3.1602],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0292, -0.0019,  0.0035,  ...,  0.0140,  0.0046, -0.0165],
        [-0.0105,  0.0242,  0.0194,  ...,  0.0003, -0.0041, -0.0116],
        [-0.0163, -0.0075,  0.0321,  ...,  0.0223,  0.0246, -0.0004],
        ...,
        [-0.0146, -0.0126,  0.0055,  ...,  0.0296,  0.0094,  0.0035],
        [-0.0028, -0.0140,  0.0006,  ...,  0.0019,  0.0199, -0.0108],
        [-0.0030, -0.0058, -0.0015,  ...,  0.0033, -0.0010,  0.0290]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4773, -2.6582,  1.6631,  ..., -0.9521, -0.6846, -3.0781]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 19:49:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of fiji primarily speaks the language of english
The country of denmark primarily speaks the language of danish
The country of argentina primarily speaks the language of spanish
The country of taiwan primarily speaks the language of chinese
The country of cuba primarily speaks the language of spanish
The country of ethiopia primarily speaks the language of amharic
The country of jamaica primarily speaks the language of english
The country of netherlands primarily speaks the language of
2024-07-29 19:49:35 root INFO     [order_1_approx] starting weight calculation for The country of denmark primarily speaks the language of danish
The country of ethiopia primarily speaks the language of amharic
The country of cuba primarily speaks the language of spanish
The country of fiji primarily speaks the language of english
The country of jamaica primarily speaks the language of english
The country of taiwan primarily speaks the language of chinese
The country of netherlands primarily speaks the language of dutch
The country of argentina primarily speaks the language of
2024-07-29 19:49:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 19:51:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2869, -0.1104, -0.0880,  ...,  0.3562, -0.5020, -0.1055],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9805, -3.2441,  0.8813,  ...,  0.9819,  0.1816, -2.1055],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0231, -0.0093, -0.0008,  ...,  0.0041, -0.0017, -0.0034],
        [-0.0045,  0.0107,  0.0123,  ..., -0.0005, -0.0078, -0.0062],
        [-0.0039,  0.0013,  0.0179,  ...,  0.0141,  0.0204,  0.0095],
        ...,
        [-0.0035,  0.0013, -0.0018,  ...,  0.0251,  0.0104,  0.0049],
        [ 0.0053, -0.0070,  0.0008,  ..., -0.0027,  0.0102, -0.0090],
        [-0.0056, -0.0082, -0.0052,  ..., -0.0008,  0.0004,  0.0157]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9336, -3.1660,  0.8652,  ...,  0.9062,  0.2482, -1.9912]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 19:51:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of denmark primarily speaks the language of danish
The country of ethiopia primarily speaks the language of amharic
The country of cuba primarily speaks the language of spanish
The country of fiji primarily speaks the language of english
The country of jamaica primarily speaks the language of english
The country of taiwan primarily speaks the language of chinese
The country of netherlands primarily speaks the language of dutch
The country of argentina primarily speaks the language of
2024-07-29 19:51:47 root INFO     total operator prediction time: 1049.5349385738373 seconds
2024-07-29 19:51:47 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on name - nationality
2024-07-29 19:51:47 root INFO     building operator name - nationality
2024-07-29 19:51:48 root INFO     [order_1_approx] starting weight calculation for locke was english
newton was english
fermi was italian
michelangelo was italian
kepler was german
caesar was roman
strauss was austrian
mencius was
2024-07-29 19:51:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 19:54:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1270,  0.0484, -0.4976,  ...,  0.7461, -0.3877,  0.2559],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5391, -1.8262,  1.1406,  ..., -5.5703, -0.5527,  1.6426],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0497,  0.0052,  0.0025,  ..., -0.0293,  0.0224, -0.0035],
        [ 0.0377,  0.0476,  0.0089,  ..., -0.0007, -0.0251, -0.0107],
        [-0.0061,  0.0137,  0.0547,  ..., -0.0254,  0.0079,  0.0207],
        ...,
        [ 0.0458, -0.0026, -0.0220,  ...,  0.0460, -0.0251, -0.0270],
        [-0.0140,  0.0154, -0.0064,  ...,  0.0094,  0.0587, -0.0145],
        [ 0.0003,  0.0202, -0.0345,  ...,  0.0306, -0.0390,  0.0912]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4121, -1.8594,  0.5527,  ..., -5.4648, -0.4983,  1.5820]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 19:54:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for locke was english
newton was english
fermi was italian
michelangelo was italian
kepler was german
caesar was roman
strauss was austrian
mencius was
2024-07-29 19:54:01 root INFO     [order_1_approx] starting weight calculation for fermi was italian
michelangelo was italian
mencius was chinese
locke was english
newton was english
strauss was austrian
kepler was german
caesar was
2024-07-29 19:54:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 19:56:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1348,  0.0308, -0.6299,  ...,  0.4988, -0.6636,  0.4866],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6807, -3.4180,  0.3928,  ..., -1.7119,  0.6621, -1.0684],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0983, -0.0011,  0.0081,  ..., -0.0080,  0.0215,  0.0020],
        [ 0.0041,  0.0546,  0.0237,  ..., -0.0154, -0.0080, -0.0072],
        [ 0.0281, -0.0043,  0.0792,  ...,  0.0169,  0.0152,  0.0106],
        ...,
        [ 0.0213,  0.0054, -0.0104,  ...,  0.1086, -0.0123, -0.0025],
        [ 0.0291,  0.0109,  0.0221,  ..., -0.0056,  0.0648,  0.0136],
        [-0.0290,  0.0177, -0.0112,  ..., -0.0154, -0.0135,  0.0814]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1973, -3.0488,  0.4604,  ..., -2.1309,  0.6030, -1.1230]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 19:56:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for fermi was italian
michelangelo was italian
mencius was chinese
locke was english
newton was english
strauss was austrian
kepler was german
caesar was
2024-07-29 19:56:14 root INFO     [order_1_approx] starting weight calculation for strauss was austrian
mencius was chinese
kepler was german
newton was english
fermi was italian
caesar was roman
locke was english
michelangelo was
2024-07-29 19:56:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 19:58:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1136,  0.0929, -0.2844,  ...,  0.3257, -0.2314,  0.9097],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6855, -5.6562,  1.3779,  ..., -3.3242, -2.1602, -0.0596],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0580,  0.0116, -0.0024,  ..., -0.0088,  0.0193,  0.0117],
        [ 0.0552,  0.0684,  0.0309,  ..., -0.0016, -0.0365, -0.0501],
        [-0.0020,  0.0013,  0.0803,  ...,  0.0048,  0.0219,  0.0083],
        ...,
        [ 0.0344,  0.0105, -0.0217,  ...,  0.0615, -0.0233, -0.0183],
        [-0.0098,  0.0251,  0.0071,  ..., -0.0306,  0.1018, -0.0064],
        [ 0.0348, -0.0020, -0.0023,  ...,  0.0103, -0.0321,  0.0621]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.1094, -6.2656,  1.1855,  ..., -3.7949, -1.2832, -0.9868]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 19:58:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for strauss was austrian
mencius was chinese
kepler was german
newton was english
fermi was italian
caesar was roman
locke was english
michelangelo was
2024-07-29 19:58:28 root INFO     [order_1_approx] starting weight calculation for kepler was german
caesar was roman
strauss was austrian
locke was english
mencius was chinese
newton was english
michelangelo was italian
fermi was
2024-07-29 19:58:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 20:00:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2484, -0.1288, -0.3354,  ...,  0.3601, -0.1790,  1.0127],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8496, -4.1289, -0.9160,  ..., -2.8535, -1.0791,  0.7197],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0632,  0.0117, -0.0076,  ..., -0.0467,  0.0024, -0.0274],
        [ 0.0391,  0.0655,  0.0113,  ...,  0.0483,  0.0077,  0.0008],
        [ 0.0149, -0.0046,  0.0563,  ...,  0.0069,  0.0344,  0.0125],
        ...,
        [ 0.0141,  0.0173, -0.0185,  ...,  0.0620, -0.0088, -0.0004],
        [ 0.0126,  0.0072, -0.0195,  ..., -0.0239,  0.0562, -0.0194],
        [-0.0229, -0.0047,  0.0105,  ...,  0.0040,  0.0164,  0.1052]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1934, -4.5000, -0.7344,  ..., -3.0078, -0.6562,  0.7285]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 20:00:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for kepler was german
caesar was roman
strauss was austrian
locke was english
mencius was chinese
newton was english
michelangelo was italian
fermi was
2024-07-29 20:00:41 root INFO     [order_1_approx] starting weight calculation for newton was english
strauss was austrian
locke was english
fermi was italian
michelangelo was italian
mencius was chinese
caesar was roman
kepler was
2024-07-29 20:00:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 20:02:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0105, -0.1093,  0.1086,  ...,  0.0565, -0.0419,  0.7051],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8711, -4.9531,  1.2295,  ..., -3.2910, -1.8311, -0.0269],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.0638e-01,  1.7029e-02, -6.3324e-03,  ..., -1.2230e-02,
          5.3711e-03, -1.4877e-04],
        [-5.8708e-03,  6.7871e-02,  1.5961e-02,  ...,  1.7609e-02,
          2.0447e-03, -1.8509e-02],
        [-1.4206e-02,  5.1765e-03,  7.7393e-02,  ...,  2.3148e-02,
         -1.0696e-02,  2.7954e-02],
        ...,
        [ 6.2714e-03,  1.3428e-02, -9.7275e-05,  ...,  5.4169e-02,
          1.2512e-02, -1.5129e-02],
        [ 2.2125e-02,  1.6693e-02,  2.5818e-02,  ..., -2.4063e-02,
          7.4646e-02, -3.5522e-02],
        [-1.3638e-03, -1.3672e-02, -6.1951e-03,  ...,  9.9792e-03,
         -1.0544e-02,  9.7656e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8770, -4.9102,  0.6826,  ..., -2.9961, -1.3789, -0.3618]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 20:02:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for newton was english
strauss was austrian
locke was english
fermi was italian
michelangelo was italian
mencius was chinese
caesar was roman
kepler was
2024-07-29 20:02:54 root INFO     [order_1_approx] starting weight calculation for michelangelo was italian
caesar was roman
mencius was chinese
newton was english
fermi was italian
strauss was austrian
kepler was german
locke was
2024-07-29 20:02:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 20:05:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0916, -0.1565, -0.5762,  ...,  0.0578, -0.4094, -0.0122],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5098, -1.8604,  1.8164,  ..., -4.3047,  0.3262, -4.3164],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0738,  0.0356, -0.0049,  ..., -0.0101,  0.0163, -0.0111],
        [-0.0014,  0.0587,  0.0031,  ...,  0.0176, -0.0389, -0.0317],
        [-0.0011,  0.0133,  0.0594,  ...,  0.0139,  0.0220,  0.0453],
        ...,
        [ 0.0019, -0.0032, -0.0143,  ...,  0.0599, -0.0227, -0.0315],
        [-0.0025,  0.0054, -0.0082,  ..., -0.0208,  0.0594, -0.0051],
        [-0.0087,  0.0107, -0.0285,  ..., -0.0125, -0.0333,  0.0616]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5293, -2.3828,  1.7363,  ..., -4.1641,  0.5005, -4.1875]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 20:05:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for michelangelo was italian
caesar was roman
mencius was chinese
newton was english
fermi was italian
strauss was austrian
kepler was german
locke was
2024-07-29 20:05:08 root INFO     [order_1_approx] starting weight calculation for locke was english
caesar was roman
fermi was italian
michelangelo was italian
kepler was german
newton was english
mencius was chinese
strauss was
2024-07-29 20:05:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 20:07:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0634, -0.1338,  0.0875,  ...,  0.2384, -0.2507,  0.1130],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6016, -5.3125, -0.9316,  ..., -4.5625, -0.3276, -1.6650],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.2999e-02,  4.4937e-03, -1.2726e-02,  ..., -2.1332e-02,
          2.3193e-03,  5.7220e-06],
        [ 1.2253e-02,  5.2521e-02,  4.3182e-03,  ...,  2.1027e-02,
         -4.6234e-02, -2.9007e-02],
        [ 1.3626e-02,  1.6251e-03,  2.8625e-02,  ..., -4.6921e-03,
          1.1353e-02,  1.4015e-02],
        ...,
        [ 1.3626e-02,  1.4336e-02, -1.0170e-02,  ...,  7.1716e-02,
         -7.4081e-03, -9.2163e-03],
        [ 2.7256e-03,  7.3051e-03, -3.5591e-03,  ..., -2.5665e-02,
          3.1464e-02,  1.4038e-03],
        [ 2.9373e-04,  5.6992e-03, -5.7106e-03,  ...,  1.7258e-02,
         -1.6083e-02,  6.5613e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0020, -5.2656, -1.0020,  ..., -4.7266,  0.3550, -1.5146]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 20:07:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for locke was english
caesar was roman
fermi was italian
michelangelo was italian
kepler was german
newton was english
mencius was chinese
strauss was
2024-07-29 20:07:21 root INFO     [order_1_approx] starting weight calculation for kepler was german
fermi was italian
strauss was austrian
locke was english
caesar was roman
mencius was chinese
michelangelo was italian
newton was
2024-07-29 20:07:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 20:09:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3147, -0.2366, -0.0683,  ..., -0.0063, -0.2568,  0.7729],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9727, -1.4932, -0.7124,  ..., -4.6719, -1.6152, -3.2852],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0508,  0.0233,  0.0078,  ..., -0.0282, -0.0205, -0.0101],
        [ 0.0066,  0.0722,  0.0242,  ...,  0.0297,  0.0004, -0.0222],
        [ 0.0166, -0.0225,  0.0545,  ...,  0.0077,  0.0168,  0.0135],
        ...,
        [-0.0004,  0.0197, -0.0028,  ...,  0.0329,  0.0099, -0.0074],
        [ 0.0041,  0.0140,  0.0129,  ...,  0.0015,  0.0622, -0.0188],
        [ 0.0004, -0.0019, -0.0061,  ..., -0.0052,  0.0081,  0.0807]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.6172, -1.9824, -0.9492,  ..., -4.1836, -1.5322, -3.2090]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 20:09:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for kepler was german
fermi was italian
strauss was austrian
locke was english
caesar was roman
mencius was chinese
michelangelo was italian
newton was
2024-07-29 20:09:34 root INFO     total operator prediction time: 1066.624061346054 seconds
2024-07-29 20:09:34 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on UK_city - county
2024-07-29 20:09:34 root INFO     building operator UK_city - county
2024-07-29 20:09:34 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of glasgow is in the county of lowlands
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of exeter is in the county of devon
In the United Kingdom, the city of wakefield is in the county of yorkshire
In the United Kingdom, the city of newport is in the county of gwent
In the United Kingdom, the city of nottingham is in the county of nottinghamshire
In the United Kingdom, the city of bradford is in the county of yorkshire
In the United Kingdom, the city of cardiff is in the county of
2024-07-29 20:09:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 20:11:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5679, -0.4460, -0.5117,  ...,  0.2334, -0.0516,  0.2233],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.7539, -4.3711,  1.1797,  ..., -2.9141,  0.6792,  0.2598],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0097,  0.0100,  0.0117,  ...,  0.0122, -0.0143,  0.0070],
        [-0.0011,  0.0012,  0.0025,  ..., -0.0061, -0.0026, -0.0028],
        [ 0.0017, -0.0065,  0.0268,  ...,  0.0096,  0.0099, -0.0177],
        ...,
        [ 0.0010, -0.0070, -0.0025,  ...,  0.0237,  0.0002, -0.0038],
        [-0.0018, -0.0162, -0.0074,  ...,  0.0020,  0.0187, -0.0023],
        [-0.0103,  0.0010, -0.0073,  ..., -0.0122,  0.0027,  0.0128]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.6328, -4.1836,  0.9424,  ..., -2.7695,  0.6323,  0.1829]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 20:11:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of glasgow is in the county of lowlands
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of exeter is in the county of devon
In the United Kingdom, the city of wakefield is in the county of yorkshire
In the United Kingdom, the city of newport is in the county of gwent
In the United Kingdom, the city of nottingham is in the county of nottinghamshire
In the United Kingdom, the city of bradford is in the county of yorkshire
In the United Kingdom, the city of cardiff is in the county of
2024-07-29 20:11:54 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of bradford is in the county of yorkshire
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of exeter is in the county of devon
In the United Kingdom, the city of cardiff is in the county of glamorgan
In the United Kingdom, the city of wakefield is in the county of yorkshire
In the United Kingdom, the city of nottingham is in the county of nottinghamshire
In the United Kingdom, the city of newport is in the county of gwent
In the United Kingdom, the city of glasgow is in the county of
2024-07-29 20:11:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 20:14:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4851,  0.5283,  0.0616,  ...,  0.4976, -0.1772,  0.1257],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6367, -2.8281,  0.5322,  ..., -4.0469,  1.2334, -0.8257],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0130, -0.0016,  0.0047,  ...,  0.0155, -0.0034, -0.0075],
        [-0.0073,  0.0036,  0.0151,  ..., -0.0009,  0.0071,  0.0016],
        [-0.0048,  0.0101,  0.0274,  ...,  0.0183,  0.0149, -0.0112],
        ...,
        [ 0.0110, -0.0215, -0.0069,  ...,  0.0235,  0.0074, -0.0009],
        [ 0.0074, -0.0167, -0.0007,  ..., -0.0033, -0.0043, -0.0090],
        [-0.0090,  0.0014, -0.0172,  ..., -0.0047, -0.0014,  0.0297]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6953, -3.0703,  0.4370,  ..., -3.9336,  1.2627, -0.7769]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 20:14:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of bradford is in the county of yorkshire
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of exeter is in the county of devon
In the United Kingdom, the city of cardiff is in the county of glamorgan
In the United Kingdom, the city of wakefield is in the county of yorkshire
In the United Kingdom, the city of nottingham is in the county of nottinghamshire
In the United Kingdom, the city of newport is in the county of gwent
In the United Kingdom, the city of glasgow is in the county of
2024-07-29 20:14:14 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of nottingham is in the county of nottinghamshire
In the United Kingdom, the city of cardiff is in the county of glamorgan
In the United Kingdom, the city of newport is in the county of gwent
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of glasgow is in the county of lowlands
In the United Kingdom, the city of wakefield is in the county of yorkshire
In the United Kingdom, the city of exeter is in the county of devon
In the United Kingdom, the city of bradford is in the county of
2024-07-29 20:14:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 20:16:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6045,  0.3716, -0.3455,  ...,  0.5293, -0.5034,  0.4663],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4971, -6.1328, -0.4832,  ..., -2.8730,  0.3936, -0.3438],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0125,  0.0040,  0.0049,  ..., -0.0002, -0.0052, -0.0098],
        [-0.0061,  0.0069,  0.0024,  ..., -0.0224,  0.0093, -0.0079],
        [-0.0124,  0.0027,  0.0258,  ...,  0.0206, -0.0038, -0.0040],
        ...,
        [ 0.0178,  0.0094, -0.0120,  ...,  0.0312,  0.0129,  0.0004],
        [-0.0006, -0.0057, -0.0102,  ...,  0.0045,  0.0126, -0.0054],
        [ 0.0040,  0.0026, -0.0262,  ..., -0.0150, -0.0082,  0.0350]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6074, -6.1719, -0.5972,  ..., -2.8477,  0.4285, -0.4917]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 20:16:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of nottingham is in the county of nottinghamshire
In the United Kingdom, the city of cardiff is in the county of glamorgan
In the United Kingdom, the city of newport is in the county of gwent
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of glasgow is in the county of lowlands
In the United Kingdom, the city of wakefield is in the county of yorkshire
In the United Kingdom, the city of exeter is in the county of devon
In the United Kingdom, the city of bradford is in the county of
2024-07-29 20:16:35 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of newport is in the county of gwent
In the United Kingdom, the city of bradford is in the county of yorkshire
In the United Kingdom, the city of wakefield is in the county of yorkshire
In the United Kingdom, the city of glasgow is in the county of lowlands
In the United Kingdom, the city of cardiff is in the county of glamorgan
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of nottingham is in the county of nottinghamshire
In the United Kingdom, the city of exeter is in the county of
2024-07-29 20:16:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 20:18:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4448, -0.0256, -0.3184,  ...,  0.7129, -0.2954, -0.0734],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5508, -4.9844,  2.4102,  ..., -4.8867,  0.7080, -2.6641],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 8.4839e-03,  5.6686e-03, -8.5754e-03,  ..., -1.1269e-02,
         -1.8951e-02,  6.7940e-03],
        [-3.4561e-03,  2.1301e-02,  4.0512e-03,  ...,  8.1921e-04,
          2.6207e-03, -7.4692e-03],
        [-6.2828e-03, -3.5286e-03,  2.5940e-02,  ...,  1.7334e-02,
          1.4740e-02, -8.8806e-03],
        ...,
        [ 1.1810e-02, -1.7075e-02,  2.5749e-05,  ...,  3.2990e-02,
          2.1912e-02, -4.6997e-03],
        [ 1.8787e-03,  1.3714e-03,  7.3090e-03,  ...,  1.3618e-02,
          1.9379e-02, -6.6376e-03],
        [-1.9140e-03,  9.8953e-03, -5.1842e-03,  ...,  1.4992e-03,
          1.1120e-03,  7.0839e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6992, -5.0625,  2.1875,  ..., -4.9492,  0.6943, -2.6094]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 20:18:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of newport is in the county of gwent
In the United Kingdom, the city of bradford is in the county of yorkshire
In the United Kingdom, the city of wakefield is in the county of yorkshire
In the United Kingdom, the city of glasgow is in the county of lowlands
In the United Kingdom, the city of cardiff is in the county of glamorgan
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of nottingham is in the county of nottinghamshire
In the United Kingdom, the city of exeter is in the county of
2024-07-29 20:18:55 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of exeter is in the county of devon
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of glasgow is in the county of lowlands
In the United Kingdom, the city of wakefield is in the county of yorkshire
In the United Kingdom, the city of newport is in the county of gwent
In the United Kingdom, the city of cardiff is in the county of glamorgan
In the United Kingdom, the city of bradford is in the county of yorkshire
In the United Kingdom, the city of nottingham is in the county of
2024-07-29 20:18:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 20:21:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1384, -0.3010, -0.2411,  ...,  0.4592, -0.2969, -0.1792],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0078, -5.1719, -0.5503,  ..., -4.9688, -2.1289, -1.2881],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0026,  0.0046,  0.0157,  ..., -0.0057, -0.0062, -0.0038],
        [-0.0038,  0.0146,  0.0013,  ..., -0.0060, -0.0011, -0.0047],
        [-0.0042,  0.0025,  0.0215,  ...,  0.0101,  0.0058, -0.0033],
        ...,
        [ 0.0064,  0.0027, -0.0077,  ...,  0.0196,  0.0049,  0.0003],
        [ 0.0005, -0.0072,  0.0022,  ...,  0.0097,  0.0038, -0.0059],
        [-0.0061, -0.0003, -0.0065,  ..., -0.0095, -0.0066,  0.0143]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9717, -5.2695, -0.6836,  ..., -4.8398, -1.8730, -1.2490]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 20:21:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of exeter is in the county of devon
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of glasgow is in the county of lowlands
In the United Kingdom, the city of wakefield is in the county of yorkshire
In the United Kingdom, the city of newport is in the county of gwent
In the United Kingdom, the city of cardiff is in the county of glamorgan
In the United Kingdom, the city of bradford is in the county of yorkshire
In the United Kingdom, the city of nottingham is in the county of
2024-07-29 20:21:21 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of glasgow is in the county of lowlands
In the United Kingdom, the city of newport is in the county of gwent
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of nottingham is in the county of nottinghamshire
In the United Kingdom, the city of exeter is in the county of devon
In the United Kingdom, the city of cardiff is in the county of glamorgan
In the United Kingdom, the city of bradford is in the county of yorkshire
In the United Kingdom, the city of wakefield is in the county of
2024-07-29 20:21:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 20:23:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4609,  0.0841, -0.4736,  ...,  0.1514, -0.4519,  0.5024],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0078, -3.5469, -1.0439,  ..., -1.5020,  1.2031, -0.4805],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0188,  0.0087,  0.0096,  ...,  0.0064,  0.0045, -0.0132],
        [-0.0011,  0.0033, -0.0013,  ..., -0.0157,  0.0094, -0.0110],
        [-0.0003, -0.0071,  0.0192,  ...,  0.0180, -0.0065, -0.0109],
        ...,
        [ 0.0205, -0.0028,  0.0003,  ...,  0.0407,  0.0007, -0.0117],
        [ 0.0065, -0.0012,  0.0011,  ...,  0.0183,  0.0131, -0.0088],
        [-0.0096,  0.0026, -0.0295,  ..., -0.0122, -0.0047,  0.0321]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9746, -3.6152, -0.8975,  ..., -1.3281,  1.3174, -0.6094]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 20:23:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of glasgow is in the county of lowlands
In the United Kingdom, the city of newport is in the county of gwent
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of nottingham is in the county of nottinghamshire
In the United Kingdom, the city of exeter is in the county of devon
In the United Kingdom, the city of cardiff is in the county of glamorgan
In the United Kingdom, the city of bradford is in the county of yorkshire
In the United Kingdom, the city of wakefield is in the county of
2024-07-29 20:23:41 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of nottingham is in the county of nottinghamshire
In the United Kingdom, the city of cardiff is in the county of glamorgan
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of wakefield is in the county of yorkshire
In the United Kingdom, the city of bradford is in the county of yorkshire
In the United Kingdom, the city of glasgow is in the county of lowlands
In the United Kingdom, the city of exeter is in the county of devon
In the United Kingdom, the city of newport is in the county of
2024-07-29 20:23:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 20:26:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5742, -0.2021, -0.0734,  ...,  0.3882, -0.2277,  0.0725],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.5039, -4.6562,  2.2637,  ..., -2.4785,  0.4507,  0.5488],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0239,  0.0037,  0.0149,  ...,  0.0023,  0.0055, -0.0154],
        [ 0.0117,  0.0227,  0.0221,  ...,  0.0023,  0.0264, -0.0029],
        [ 0.0137, -0.0033,  0.0425,  ...,  0.0033,  0.0131, -0.0135],
        ...,
        [ 0.0186, -0.0219,  0.0057,  ...,  0.0351,  0.0260,  0.0025],
        [ 0.0124,  0.0212,  0.0037,  ...,  0.0283,  0.0339, -0.0102],
        [ 0.0151, -0.0130, -0.0117,  ..., -0.0295,  0.0047,  0.0044]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 6.1484, -4.7891,  2.1660,  ..., -2.6367,  0.5923,  0.5898]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 20:26:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of nottingham is in the county of nottinghamshire
In the United Kingdom, the city of cardiff is in the county of glamorgan
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of wakefield is in the county of yorkshire
In the United Kingdom, the city of bradford is in the county of yorkshire
In the United Kingdom, the city of glasgow is in the county of lowlands
In the United Kingdom, the city of exeter is in the county of devon
In the United Kingdom, the city of newport is in the county of
2024-07-29 20:26:02 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of cardiff is in the county of glamorgan
In the United Kingdom, the city of exeter is in the county of devon
In the United Kingdom, the city of glasgow is in the county of lowlands
In the United Kingdom, the city of wakefield is in the county of yorkshire
In the United Kingdom, the city of newport is in the county of gwent
In the United Kingdom, the city of bradford is in the county of yorkshire
In the United Kingdom, the city of nottingham is in the county of nottinghamshire
In the United Kingdom, the city of swansea is in the county of
2024-07-29 20:26:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 20:28:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3489, -0.3889, -0.3647,  ...,  0.5024, -0.4463, -0.1785],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.5117, -5.2109,  1.2158,  ..., -2.9023, -2.2070,  0.5234],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0052,  0.0079,  0.0027,  ..., -0.0019, -0.0076,  0.0034],
        [-0.0023,  0.0129, -0.0041,  ..., -0.0071, -0.0054, -0.0064],
        [ 0.0070, -0.0034,  0.0055,  ...,  0.0059,  0.0078,  0.0012],
        ...,
        [ 0.0016, -0.0059, -0.0075,  ...,  0.0163,  0.0137, -0.0015],
        [-0.0034, -0.0005, -0.0002,  ..., -0.0019, -0.0001, -0.0052],
        [-0.0084,  0.0021, -0.0022,  ..., -0.0104,  0.0068,  0.0116]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.4766, -5.3398,  1.2256,  ..., -2.6953, -2.3711,  0.5889]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 20:28:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of cardiff is in the county of glamorgan
In the United Kingdom, the city of exeter is in the county of devon
In the United Kingdom, the city of glasgow is in the county of lowlands
In the United Kingdom, the city of wakefield is in the county of yorkshire
In the United Kingdom, the city of newport is in the county of gwent
In the United Kingdom, the city of bradford is in the county of yorkshire
In the United Kingdom, the city of nottingham is in the county of nottinghamshire
In the United Kingdom, the city of swansea is in the county of
2024-07-29 20:28:22 root INFO     total operator prediction time: 1128.375352859497 seconds
2024-07-29 20:28:22 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+ment_irreg
2024-07-29 20:28:22 root INFO     building operator verb+ment_irreg
2024-07-29 20:28:23 root INFO     [order_1_approx] starting weight calculation for To acknowledge results in a acknowledgement
To adjust results in a adjustment
To amuse results in a amusement
To reimburse results in a reimbursement
To disappoint results in a disappointment
To resent results in a resentment
To impair results in a impairment
To engage results in a
2024-07-29 20:28:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 20:30:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0491,  0.5205,  0.0564,  ...,  0.1611, -0.1002, -0.0323],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3691, -3.6543, -0.0818,  ...,  0.5586, -1.2461, -2.6836],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0917,  0.0130,  0.0043,  ..., -0.0140,  0.0080,  0.0210],
        [ 0.0038,  0.0956,  0.0013,  ...,  0.0232,  0.0110, -0.0018],
        [ 0.0009, -0.0057,  0.0748,  ..., -0.0082, -0.0068, -0.0012],
        ...,
        [ 0.0007,  0.0134,  0.0018,  ...,  0.0928,  0.0092,  0.0212],
        [-0.0122,  0.0241,  0.0132,  ..., -0.0061,  0.0770, -0.0177],
        [ 0.0159,  0.0068, -0.0153,  ...,  0.0079, -0.0177,  0.0811]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8086, -3.2363, -0.1821,  ...,  0.3303, -1.4883, -2.6660]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 20:30:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To acknowledge results in a acknowledgement
To adjust results in a adjustment
To amuse results in a amusement
To reimburse results in a reimbursement
To disappoint results in a disappointment
To resent results in a resentment
To impair results in a impairment
To engage results in a
2024-07-29 20:30:36 root INFO     [order_1_approx] starting weight calculation for To engage results in a engagement
To amuse results in a amusement
To resent results in a resentment
To adjust results in a adjustment
To disappoint results in a disappointment
To reimburse results in a reimbursement
To impair results in a impairment
To acknowledge results in a
2024-07-29 20:30:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 20:32:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1289,  0.5933, -0.2056,  ..., -0.1382, -0.2034, -0.3032],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3223, -1.9502, -0.5454,  ...,  0.5459, -1.3906,  2.5508],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0667, -0.0075, -0.0303,  ..., -0.0331, -0.0050, -0.0121],
        [ 0.0264,  0.0674,  0.0336,  ...,  0.0133,  0.0094,  0.0328],
        [ 0.0057,  0.0016,  0.0265,  ..., -0.0124, -0.0165, -0.0148],
        ...,
        [ 0.0050,  0.0126,  0.0129,  ...,  0.0700,  0.0139,  0.0393],
        [-0.0128,  0.0083, -0.0007,  ..., -0.0114,  0.0474, -0.0229],
        [ 0.0100, -0.0044,  0.0211,  ..., -0.0022, -0.0250,  0.0709]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8672, -1.7275, -0.5459,  ...,  1.0566, -1.5537,  2.1270]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 20:32:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To engage results in a engagement
To amuse results in a amusement
To resent results in a resentment
To adjust results in a adjustment
To disappoint results in a disappointment
To reimburse results in a reimbursement
To impair results in a impairment
To acknowledge results in a
2024-07-29 20:32:50 root INFO     [order_1_approx] starting weight calculation for To acknowledge results in a acknowledgement
To engage results in a engagement
To disappoint results in a disappointment
To resent results in a resentment
To impair results in a impairment
To adjust results in a adjustment
To reimburse results in a reimbursement
To amuse results in a
2024-07-29 20:32:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 20:35:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0756,  0.3005,  0.0226,  ..., -0.0834, -0.0767, -0.1387],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8711, -1.3594,  1.0371,  ...,  1.7383, -0.3733, -1.1230],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0841,  0.0195,  0.0047,  ..., -0.0004,  0.0064, -0.0030],
        [-0.0144,  0.0681,  0.0007,  ...,  0.0067,  0.0042,  0.0092],
        [-0.0066, -0.0086,  0.0528,  ..., -0.0078, -0.0214, -0.0163],
        ...,
        [ 0.0027, -0.0053, -0.0176,  ...,  0.0583,  0.0067,  0.0077],
        [-0.0055,  0.0238,  0.0080,  ..., -0.0135,  0.0584,  0.0096],
        [-0.0079, -0.0053, -0.0088,  ...,  0.0010, -0.0099,  0.0729]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6504, -1.2812,  0.7100,  ...,  1.9385, -0.6709, -1.3018]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 20:35:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To acknowledge results in a acknowledgement
To engage results in a engagement
To disappoint results in a disappointment
To resent results in a resentment
To impair results in a impairment
To adjust results in a adjustment
To reimburse results in a reimbursement
To amuse results in a
2024-07-29 20:35:03 root INFO     [order_1_approx] starting weight calculation for To acknowledge results in a acknowledgement
To engage results in a engagement
To resent results in a resentment
To impair results in a impairment
To adjust results in a adjustment
To amuse results in a amusement
To disappoint results in a disappointment
To reimburse results in a
2024-07-29 20:35:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 20:37:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3201, -0.0108, -0.2925,  ...,  0.2668,  0.4419, -0.4839],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1211, -3.4414, -1.0166,  ..., -0.9756, -2.7734, -1.4492],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0735,  0.0102,  0.0147,  ..., -0.0098, -0.0040,  0.0112],
        [-0.0006,  0.0641,  0.0103,  ...,  0.0104,  0.0055,  0.0058],
        [-0.0078,  0.0079,  0.0530,  ..., -0.0103, -0.0013, -0.0131],
        ...,
        [-0.0096,  0.0024,  0.0022,  ...,  0.0720,  0.0115,  0.0123],
        [-0.0040,  0.0012,  0.0071,  ..., -0.0056,  0.0590, -0.0223],
        [-0.0048, -0.0003, -0.0120,  ...,  0.0041, -0.0185,  0.0709]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0703, -3.1523, -1.4766,  ..., -0.7603, -2.4609, -1.5557]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 20:37:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To acknowledge results in a acknowledgement
To engage results in a engagement
To resent results in a resentment
To impair results in a impairment
To adjust results in a adjustment
To amuse results in a amusement
To disappoint results in a disappointment
To reimburse results in a
2024-07-29 20:37:16 root INFO     [order_1_approx] starting weight calculation for To engage results in a engagement
To amuse results in a amusement
To impair results in a impairment
To acknowledge results in a acknowledgement
To adjust results in a adjustment
To disappoint results in a disappointment
To reimburse results in a reimbursement
To resent results in a
2024-07-29 20:37:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 20:39:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4668,  0.0950, -0.7197,  ..., -0.1089,  0.0783, -0.0101],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5869, -2.6562, -0.5312,  ..., -1.5225, -0.4421, -0.1055],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1006,  0.0008,  0.0047,  ..., -0.0122, -0.0064,  0.0089],
        [-0.0083,  0.0706, -0.0039,  ...,  0.0129,  0.0050,  0.0065],
        [ 0.0134,  0.0161,  0.0638,  ..., -0.0063, -0.0200, -0.0193],
        ...,
        [ 0.0087,  0.0206, -0.0027,  ...,  0.0783,  0.0240,  0.0148],
        [-0.0210, -0.0222,  0.0097,  ..., -0.0004,  0.0789, -0.0374],
        [-0.0094,  0.0083,  0.0009,  ..., -0.0139, -0.0280,  0.0676]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2402, -2.3086, -0.3650,  ..., -1.4775, -1.3174, -0.6201]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 20:39:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To engage results in a engagement
To amuse results in a amusement
To impair results in a impairment
To acknowledge results in a acknowledgement
To adjust results in a adjustment
To disappoint results in a disappointment
To reimburse results in a reimbursement
To resent results in a
2024-07-29 20:39:30 root INFO     [order_1_approx] starting weight calculation for To engage results in a engagement
To amuse results in a amusement
To disappoint results in a disappointment
To resent results in a resentment
To reimburse results in a reimbursement
To acknowledge results in a acknowledgement
To impair results in a impairment
To adjust results in a
2024-07-29 20:39:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 20:41:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0440,  0.1882, -0.3242,  ..., -0.1597, -0.0428,  0.1248],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3340, -2.5176, -1.8672,  ...,  1.0674, -0.6748, -0.6357],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0849,  0.0118,  0.0201,  ..., -0.0007,  0.0138,  0.0263],
        [ 0.0052,  0.0675,  0.0104,  ...,  0.0228,  0.0089,  0.0091],
        [-0.0007,  0.0033,  0.0347,  ..., -0.0006, -0.0084, -0.0199],
        ...,
        [ 0.0001,  0.0105, -0.0057,  ...,  0.0736,  0.0118,  0.0031],
        [-0.0149, -0.0057, -0.0094,  ..., -0.0173,  0.0573, -0.0312],
        [ 0.0028,  0.0133,  0.0059,  ..., -0.0126, -0.0090,  0.0449]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9570, -2.0488, -1.7822,  ...,  0.8291, -0.4326, -0.6616]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 20:41:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To engage results in a engagement
To amuse results in a amusement
To disappoint results in a disappointment
To resent results in a resentment
To reimburse results in a reimbursement
To acknowledge results in a acknowledgement
To impair results in a impairment
To adjust results in a
2024-07-29 20:41:44 root INFO     [order_1_approx] starting weight calculation for To adjust results in a adjustment
To engage results in a engagement
To impair results in a impairment
To reimburse results in a reimbursement
To amuse results in a amusement
To acknowledge results in a acknowledgement
To resent results in a resentment
To disappoint results in a
2024-07-29 20:41:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 20:43:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3181,  0.6543, -0.1807,  ..., -0.0178, -0.3208, -0.0040],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2598, -4.0781,  1.2344,  ...,  1.4268,  2.8340, -1.1865],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.5928e-02,  1.3908e-02,  1.0284e-02,  ...,  7.0686e-03,
         -1.5381e-02,  3.5496e-03],
        [-1.1559e-02,  6.1371e-02, -1.8716e-05,  ...,  4.0680e-02,
          2.6062e-02, -6.0320e-04],
        [ 1.0010e-02, -2.3621e-02,  7.4348e-03,  ..., -1.1505e-02,
         -1.0750e-02, -4.4632e-03],
        ...,
        [ 1.5106e-02, -2.7161e-03, -2.5650e-02,  ...,  4.4800e-02,
         -5.1880e-04,  2.0630e-02],
        [ 3.9597e-03, -2.2675e-02,  1.3397e-02,  ..., -1.2184e-02,
          3.6438e-02, -7.5340e-03],
        [-1.2924e-02, -1.6144e-02,  5.2147e-03,  ..., -1.5732e-02,
         -1.9897e-02,  3.8300e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8086, -3.5410,  1.0000,  ...,  0.9902,  2.6855, -1.4277]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 20:43:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To adjust results in a adjustment
To engage results in a engagement
To impair results in a impairment
To reimburse results in a reimbursement
To amuse results in a amusement
To acknowledge results in a acknowledgement
To resent results in a resentment
To disappoint results in a
2024-07-29 20:43:58 root INFO     [order_1_approx] starting weight calculation for To disappoint results in a disappointment
To acknowledge results in a acknowledgement
To resent results in a resentment
To adjust results in a adjustment
To engage results in a engagement
To amuse results in a amusement
To reimburse results in a reimbursement
To impair results in a
2024-07-29 20:43:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 20:46:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3701,  0.0327, -0.3320,  ..., -0.1331,  0.1171,  0.1014],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.7812, -2.7031, -0.0049,  ..., -0.8149, -0.9316, -1.8643],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0559, -0.0421, -0.0144,  ..., -0.0124,  0.0248,  0.0056],
        [ 0.0197,  0.1299,  0.0168,  ...,  0.0154, -0.0068,  0.0050],
        [-0.0046, -0.0188,  0.0537,  ..., -0.0089,  0.0096, -0.0108],
        ...,
        [ 0.0193,  0.0346,  0.0037,  ...,  0.0844, -0.0148,  0.0112],
        [ 0.0024, -0.0038,  0.0158,  ...,  0.0004,  0.0640, -0.0149],
        [ 0.0143,  0.0142,  0.0136,  ..., -0.0130, -0.0291,  0.0631]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.6250, -2.2617, -0.4951,  ..., -0.4175, -1.0469, -1.7139]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 20:46:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To disappoint results in a disappointment
To acknowledge results in a acknowledgement
To resent results in a resentment
To adjust results in a adjustment
To engage results in a engagement
To amuse results in a amusement
To reimburse results in a reimbursement
To impair results in a
2024-07-29 20:46:06 root INFO     total operator prediction time: 1063.5195169448853 seconds
2024-07-29 20:46:06 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun+less_reg
2024-07-29 20:46:06 root INFO     building operator noun+less_reg
2024-07-29 20:46:06 root INFO     [order_1_approx] starting weight calculation for Something without emotion is emotionless
Something without breath is breathless
Something without leg is legless
Something without odor is odorless
Something without effort is effortless
Something without hair is hairless
Something without speech is speechless
Something without faith is
2024-07-29 20:46:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 20:48:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3904, -0.1539,  0.0423,  ...,  0.0898,  0.0520,  0.7646],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.7891, -2.7266,  2.0820,  ..., -1.1523, -4.2617, -0.3945],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0445,  0.0035, -0.0012,  ...,  0.0030, -0.0072,  0.0117],
        [-0.0018,  0.0393,  0.0048,  ...,  0.0170, -0.0067, -0.0165],
        [ 0.0141, -0.0046,  0.0224,  ...,  0.0098, -0.0051, -0.0042],
        ...,
        [ 0.0098,  0.0160, -0.0038,  ...,  0.0148, -0.0034,  0.0140],
        [-0.0232,  0.0086,  0.0066,  ..., -0.0089,  0.0389, -0.0216],
        [ 0.0275,  0.0166, -0.0084,  ...,  0.0161, -0.0243,  0.0207]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.1523, -2.7422,  1.9453,  ..., -1.1221, -4.3750, -0.3645]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 20:48:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without emotion is emotionless
Something without breath is breathless
Something without leg is legless
Something without odor is odorless
Something without effort is effortless
Something without hair is hairless
Something without speech is speechless
Something without faith is
2024-07-29 20:48:19 root INFO     [order_1_approx] starting weight calculation for Something without effort is effortless
Something without faith is faithless
Something without breath is breathless
Something without emotion is emotionless
Something without leg is legless
Something without odor is odorless
Something without hair is hairless
Something without speech is
2024-07-29 20:48:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 20:50:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0121,  0.0035,  0.5547,  ...,  0.1814,  0.2325,  0.0591],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.1211, -1.9775,  0.8975,  ..., -0.2300, -1.6455, -0.7793],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0443, -0.0118,  0.0118,  ...,  0.0192,  0.0190,  0.0130],
        [-0.0010,  0.0511,  0.0261,  ..., -0.0009,  0.0005,  0.0076],
        [ 0.0237, -0.0090,  0.0247,  ...,  0.0040, -0.0178, -0.0067],
        ...,
        [-0.0063,  0.0122,  0.0020,  ...,  0.0153, -0.0016, -0.0104],
        [-0.0045, -0.0004, -0.0020,  ..., -0.0282,  0.0272, -0.0299],
        [ 0.0082, -0.0002,  0.0027,  ..., -0.0103, -0.0182,  0.0235]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.9102, -2.3867,  0.5166,  ..., -0.5249, -1.9414, -0.7188]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 20:50:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without effort is effortless
Something without faith is faithless
Something without breath is breathless
Something without emotion is emotionless
Something without leg is legless
Something without odor is odorless
Something without hair is hairless
Something without speech is
2024-07-29 20:50:32 root INFO     [order_1_approx] starting weight calculation for Something without faith is faithless
Something without speech is speechless
Something without emotion is emotionless
Something without breath is breathless
Something without hair is hairless
Something without odor is odorless
Something without effort is effortless
Something without leg is
2024-07-29 20:50:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 20:52:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5859, -0.2402,  0.0330,  ..., -0.0065,  0.0495, -0.4546],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0586, -4.6797,  1.7051,  ...,  0.3274, -0.6489, -2.2402],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.3987e-02, -1.0147e-02, -1.2222e-02,  ..., -1.9426e-03,
          3.3798e-03,  5.3406e-05],
        [ 3.1376e-03,  1.9806e-02, -7.4768e-03,  ...,  1.1932e-02,
          1.1234e-03,  7.2327e-03],
        [ 2.2141e-02, -6.8474e-03,  1.6861e-02,  ...,  8.5449e-04,
         -1.7532e-02,  8.7280e-03],
        ...,
        [ 5.8975e-03,  1.1887e-02,  1.3763e-02,  ...,  2.9968e-02,
          8.4534e-03,  1.0300e-02],
        [-2.5940e-02,  3.8509e-03, -3.1342e-02,  ..., -2.1240e-02,
          2.7130e-02, -3.3051e-02],
        [-8.8692e-05,  3.3283e-03,  2.3621e-02,  ...,  3.6964e-03,
         -1.4191e-02,  1.2367e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2861, -4.2891,  1.1523,  ...,  0.5850, -0.5259, -2.3105]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 20:52:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without faith is faithless
Something without speech is speechless
Something without emotion is emotionless
Something without breath is breathless
Something without hair is hairless
Something without odor is odorless
Something without effort is effortless
Something without leg is
2024-07-29 20:52:45 root INFO     [order_1_approx] starting weight calculation for Something without speech is speechless
Something without emotion is emotionless
Something without odor is odorless
Something without leg is legless
Something without effort is effortless
Something without hair is hairless
Something without faith is faithless
Something without breath is
2024-07-29 20:52:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 20:54:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3831, -0.4800,  0.3691,  ..., -0.2036,  0.1254,  0.0140],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8477, -4.6445,  1.7910,  ..., -2.9023, -2.3711, -1.0615],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0347, -0.0021, -0.0020,  ...,  0.0152,  0.0091,  0.0102],
        [ 0.0047,  0.0442,  0.0003,  ...,  0.0171,  0.0140, -0.0028],
        [ 0.0188, -0.0073,  0.0370,  ...,  0.0222, -0.0080, -0.0107],
        ...,
        [ 0.0010,  0.0036, -0.0023,  ...,  0.0045,  0.0012, -0.0066],
        [ 0.0094, -0.0064, -0.0083,  ..., -0.0046,  0.0406, -0.0093],
        [ 0.0075,  0.0045,  0.0023,  ..., -0.0004, -0.0155,  0.0231]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4824, -4.2148,  1.5615,  ..., -2.5918, -2.7812, -0.7769]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 20:54:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without speech is speechless
Something without emotion is emotionless
Something without odor is odorless
Something without leg is legless
Something without effort is effortless
Something without hair is hairless
Something without faith is faithless
Something without breath is
2024-07-29 20:54:58 root INFO     [order_1_approx] starting weight calculation for Something without hair is hairless
Something without effort is effortless
Something without emotion is emotionless
Something without leg is legless
Something without speech is speechless
Something without breath is breathless
Something without faith is faithless
Something without odor is
2024-07-29 20:54:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 20:57:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3003, -0.6709,  0.0914,  ..., -0.4150, -0.0262, -0.1674],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1367, -3.2148, -2.0801,  ..., -4.5625, -6.8945, -1.2744],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0480, -0.0171,  0.0220,  ..., -0.0148,  0.0052,  0.0031],
        [ 0.0112,  0.0417, -0.0248,  ..., -0.0090,  0.0182, -0.0135],
        [ 0.0178,  0.0114,  0.0440,  ...,  0.0117, -0.0134,  0.0003],
        ...,
        [ 0.0123,  0.0185,  0.0043,  ...,  0.0439,  0.0176,  0.0012],
        [ 0.0205,  0.0045,  0.0079,  ..., -0.0121,  0.0504, -0.0033],
        [ 0.0157, -0.0026, -0.0036,  ...,  0.0250, -0.0198,  0.0381]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3652, -3.3516, -2.0586,  ..., -4.2734, -6.6875, -1.3604]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 20:57:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without hair is hairless
Something without effort is effortless
Something without emotion is emotionless
Something without leg is legless
Something without speech is speechless
Something without breath is breathless
Something without faith is faithless
Something without odor is
2024-07-29 20:57:11 root INFO     [order_1_approx] starting weight calculation for Something without leg is legless
Something without emotion is emotionless
Something without faith is faithless
Something without speech is speechless
Something without effort is effortless
Something without breath is breathless
Something without odor is odorless
Something without hair is
2024-07-29 20:57:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 20:59:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2781, -0.5708, -0.0313,  ...,  0.1304,  0.1847,  0.0534],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3496, -2.4336, -1.1211,  ..., -1.7676, -4.8125, -1.7188],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0370, -0.0174,  0.0088,  ...,  0.0085, -0.0023,  0.0061],
        [-0.0068,  0.0338, -0.0104,  ..., -0.0172, -0.0016, -0.0141],
        [ 0.0040,  0.0014,  0.0120,  ...,  0.0123, -0.0021, -0.0015],
        ...,
        [ 0.0049,  0.0239,  0.0216,  ...,  0.0175,  0.0208, -0.0084],
        [-0.0022,  0.0142,  0.0069,  ..., -0.0282,  0.0293, -0.0281],
        [-0.0078, -0.0048,  0.0041,  ..., -0.0022, -0.0005,  0.0327]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5898, -2.1250, -1.2119,  ..., -1.7012, -5.0156, -1.5752]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 20:59:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without leg is legless
Something without emotion is emotionless
Something without faith is faithless
Something without speech is speechless
Something without effort is effortless
Something without breath is breathless
Something without odor is odorless
Something without hair is
2024-07-29 20:59:23 root INFO     [order_1_approx] starting weight calculation for Something without odor is odorless
Something without faith is faithless
Something without leg is legless
Something without breath is breathless
Something without effort is effortless
Something without hair is hairless
Something without speech is speechless
Something without emotion is
2024-07-29 20:59:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 21:01:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1047, -0.5962,  0.0509,  ...,  0.1019, -0.1785,  0.4292],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3262, -0.6982,  0.3660,  ..., -2.9707, -1.9131, -3.6992],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0346, -0.0175,  0.0203,  ...,  0.0003, -0.0010,  0.0155],
        [-0.0042,  0.0343, -0.0010,  ...,  0.0025, -0.0070, -0.0102],
        [ 0.0057, -0.0100,  0.0125,  ...,  0.0114, -0.0114,  0.0012],
        ...,
        [ 0.0048,  0.0058,  0.0009,  ...,  0.0218,  0.0106, -0.0040],
        [ 0.0014,  0.0097,  0.0061,  ..., -0.0046,  0.0328, -0.0139],
        [ 0.0069,  0.0078, -0.0065,  ...,  0.0120, -0.0020,  0.0234]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3555, -0.7290,  0.2534,  ..., -2.7090, -2.0586, -3.6055]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 21:01:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without odor is odorless
Something without faith is faithless
Something without leg is legless
Something without breath is breathless
Something without effort is effortless
Something without hair is hairless
Something without speech is speechless
Something without emotion is
2024-07-29 21:01:36 root INFO     [order_1_approx] starting weight calculation for Something without speech is speechless
Something without faith is faithless
Something without hair is hairless
Something without odor is odorless
Something without emotion is emotionless
Something without breath is breathless
Something without leg is legless
Something without effort is
2024-07-29 21:01:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 21:03:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0553,  0.0204,  0.0908,  ..., -0.3010, -0.2927,  0.3328],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3145, -4.5508, -0.5112,  ..., -1.8604, -3.4570, -5.1523],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0121, -0.0202,  0.0051,  ...,  0.0024,  0.0003,  0.0167],
        [ 0.0184,  0.0516, -0.0240,  ...,  0.0169,  0.0001, -0.0182],
        [ 0.0172, -0.0141,  0.0340,  ...,  0.0125, -0.0202, -0.0015],
        ...,
        [-0.0014,  0.0381, -0.0030,  ...,  0.0267,  0.0050,  0.0009],
        [-0.0219,  0.0014, -0.0119,  ..., -0.0166,  0.0508, -0.0235],
        [ 0.0196,  0.0058,  0.0085,  ...,  0.0052, -0.0177,  0.0219]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0703, -4.4570, -0.5513,  ..., -2.0449, -3.1641, -5.0117]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 21:03:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without speech is speechless
Something without faith is faithless
Something without hair is hairless
Something without odor is odorless
Something without emotion is emotionless
Something without breath is breathless
Something without leg is legless
Something without effort is
2024-07-29 21:03:48 root INFO     total operator prediction time: 1062.1575660705566 seconds
2024-07-29 21:03:48 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj+ness_reg
2024-07-29 21:03:48 root INFO     building operator adj+ness_reg
2024-07-29 21:03:48 root INFO     [order_1_approx] starting weight calculation for The state of being hot is hotness
The state of being weak is weakness
The state of being mad is madness
The state of being situated is situatedness
The state of being pure is pureness
The state of being foreign is foreignness
The state of being fixed is fixedness
The state of being huge is
2024-07-29 21:03:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 21:06:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0442, -0.2588,  0.3740,  ..., -0.0568, -0.2944, -0.1338],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3037, -3.5762, -0.7070,  ..., -4.0781, -6.7969, -2.0996],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0579, -0.0050, -0.0114,  ...,  0.0168, -0.0081,  0.0070],
        [-0.0039,  0.0410,  0.0204,  ..., -0.0150,  0.0047,  0.0056],
        [-0.0086, -0.0171,  0.0503,  ...,  0.0011, -0.0118,  0.0066],
        ...,
        [ 0.0189,  0.0298,  0.0298,  ...,  0.0373, -0.0079,  0.0037],
        [ 0.0233, -0.0007, -0.0071,  ...,  0.0095,  0.0468,  0.0027],
        [-0.0016,  0.0043,  0.0116,  ..., -0.0167, -0.0146,  0.0326]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3838, -4.0039, -0.6045,  ..., -4.3359, -6.6641, -2.2266]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 21:06:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being hot is hotness
The state of being weak is weakness
The state of being mad is madness
The state of being situated is situatedness
The state of being pure is pureness
The state of being foreign is foreignness
The state of being fixed is fixedness
The state of being huge is
2024-07-29 21:06:02 root INFO     [order_1_approx] starting weight calculation for The state of being situated is situatedness
The state of being hot is hotness
The state of being foreign is foreignness
The state of being huge is hugeness
The state of being weak is weakness
The state of being fixed is fixedness
The state of being pure is pureness
The state of being mad is
2024-07-29 21:06:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 21:08:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4121,  0.0350,  0.3103,  ...,  0.2583, -0.4778,  0.3462],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9453, -3.0586, -1.5137,  ..., -4.4766, -1.8789, -1.5273],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0562,  0.0054,  0.0093,  ..., -0.0030, -0.0055, -0.0020],
        [ 0.0026,  0.0384, -0.0147,  ...,  0.0085,  0.0076, -0.0013],
        [ 0.0204, -0.0138,  0.0502,  ...,  0.0099, -0.0052,  0.0117],
        ...,
        [ 0.0290,  0.0018,  0.0006,  ...,  0.0577,  0.0028,  0.0034],
        [-0.0157,  0.0045,  0.0020,  ...,  0.0001,  0.0628,  0.0001],
        [ 0.0054,  0.0114,  0.0088,  ..., -0.0032, -0.0138,  0.0510]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9746, -2.8516, -1.7363,  ..., -4.4844, -2.2773, -1.5654]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 21:08:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being situated is situatedness
The state of being hot is hotness
The state of being foreign is foreignness
The state of being huge is hugeness
The state of being weak is weakness
The state of being fixed is fixedness
The state of being pure is pureness
The state of being mad is
2024-07-29 21:08:16 root INFO     [order_1_approx] starting weight calculation for The state of being hot is hotness
The state of being fixed is fixedness
The state of being situated is situatedness
The state of being mad is madness
The state of being huge is hugeness
The state of being weak is weakness
The state of being foreign is foreignness
The state of being pure is
2024-07-29 21:08:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 21:10:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1440, -0.1368,  0.9678,  ...,  0.0078,  0.0733,  0.3105],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8477, -1.3984, -2.2773,  ..., -3.3164, -3.3750, -3.6016],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0540, -0.0246, -0.0143,  ..., -0.0137, -0.0151, -0.0074],
        [ 0.0112,  0.0658,  0.0338,  ...,  0.0108,  0.0202,  0.0091],
        [ 0.0150,  0.0068,  0.0550,  ...,  0.0282, -0.0076,  0.0204],
        ...,
        [ 0.0150,  0.0086,  0.0155,  ...,  0.0295,  0.0154,  0.0168],
        [-0.0061,  0.0005, -0.0268,  ...,  0.0030,  0.0573, -0.0148],
        [ 0.0141,  0.0120,  0.0032,  ..., -0.0074, -0.0217,  0.0646]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6055, -1.3066, -2.4082,  ..., -3.1836, -3.1211, -3.7344]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 21:10:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being hot is hotness
The state of being fixed is fixedness
The state of being situated is situatedness
The state of being mad is madness
The state of being huge is hugeness
The state of being weak is weakness
The state of being foreign is foreignness
The state of being pure is
2024-07-29 21:10:30 root INFO     [order_1_approx] starting weight calculation for The state of being mad is madness
The state of being weak is weakness
The state of being pure is pureness
The state of being fixed is fixedness
The state of being foreign is foreignness
The state of being hot is hotness
The state of being huge is hugeness
The state of being situated is
2024-07-29 21:10:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 21:12:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1097,  0.3257, -0.0769,  ...,  0.3218, -0.5122, -0.1682],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1211, -3.6074, -3.2070,  ..., -3.5156, -3.4121, -3.9102],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0538,  0.0020, -0.0031,  ...,  0.0065, -0.0106,  0.0175],
        [ 0.0127,  0.0464,  0.0095,  ...,  0.0247,  0.0020,  0.0247],
        [ 0.0273, -0.0116,  0.0285,  ..., -0.0118, -0.0298, -0.0063],
        ...,
        [ 0.0131,  0.0157,  0.0014,  ...,  0.0493, -0.0084,  0.0168],
        [-0.0015,  0.0112, -0.0029,  ..., -0.0005,  0.0581, -0.0247],
        [ 0.0252,  0.0194,  0.0062,  ..., -0.0024, -0.0551,  0.0516]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.1523, -3.9453, -3.3047,  ..., -3.8281, -3.1992, -4.3125]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 21:12:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being mad is madness
The state of being weak is weakness
The state of being pure is pureness
The state of being fixed is fixedness
The state of being foreign is foreignness
The state of being hot is hotness
The state of being huge is hugeness
The state of being situated is
2024-07-29 21:12:43 root INFO     [order_1_approx] starting weight calculation for The state of being weak is weakness
The state of being situated is situatedness
The state of being fixed is fixedness
The state of being pure is pureness
The state of being foreign is foreignness
The state of being huge is hugeness
The state of being mad is madness
The state of being hot is
2024-07-29 21:12:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 21:14:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0983, -0.3403,  0.5542,  ...,  0.1506, -0.2466, -0.1053],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.0664, -2.3828, -0.9390,  ..., -4.1680, -5.7109, -0.6001],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0504,  0.0056, -0.0103,  ..., -0.0153, -0.0038,  0.0005],
        [ 0.0077,  0.0443,  0.0197,  ..., -0.0049,  0.0025, -0.0022],
        [-0.0040, -0.0079,  0.0426,  ...,  0.0144,  0.0034,  0.0057],
        ...,
        [ 0.0045,  0.0111,  0.0150,  ...,  0.0428, -0.0050, -0.0060],
        [ 0.0133,  0.0124, -0.0211,  ...,  0.0008,  0.0746, -0.0039],
        [-0.0056,  0.0043, -0.0070,  ..., -0.0017,  0.0005,  0.0448]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.7217, -2.2246, -1.1191,  ..., -4.0859, -5.6992, -0.3635]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 21:14:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being weak is weakness
The state of being situated is situatedness
The state of being fixed is fixedness
The state of being pure is pureness
The state of being foreign is foreignness
The state of being huge is hugeness
The state of being mad is madness
The state of being hot is
2024-07-29 21:14:57 root INFO     [order_1_approx] starting weight calculation for The state of being huge is hugeness
The state of being fixed is fixedness
The state of being weak is weakness
The state of being situated is situatedness
The state of being hot is hotness
The state of being pure is pureness
The state of being mad is madness
The state of being foreign is
2024-07-29 21:14:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 21:17:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2012,  0.0194,  0.3369,  ..., -0.0595,  0.3657,  0.1963],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3982, -2.6445,  0.4580,  ..., -2.9258, -2.2578, -2.2031],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0661,  0.0027, -0.0050,  ...,  0.0033,  0.0081,  0.0045],
        [ 0.0091,  0.0402,  0.0098,  ...,  0.0053,  0.0151, -0.0004],
        [-0.0069,  0.0018,  0.0342,  ..., -0.0036,  0.0052,  0.0008],
        ...,
        [ 0.0021,  0.0133,  0.0071,  ...,  0.0283,  0.0134,  0.0012],
        [ 0.0019,  0.0046, -0.0061,  ..., -0.0025,  0.0505, -0.0201],
        [ 0.0088,  0.0109,  0.0075,  ..., -0.0089, -0.0036,  0.0473]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1881, -2.3184,  0.6094,  ..., -2.7520, -2.2441, -2.0020]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 21:17:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being huge is hugeness
The state of being fixed is fixedness
The state of being weak is weakness
The state of being situated is situatedness
The state of being hot is hotness
The state of being pure is pureness
The state of being mad is madness
The state of being foreign is
2024-07-29 21:17:10 root INFO     [order_1_approx] starting weight calculation for The state of being mad is madness
The state of being foreign is foreignness
The state of being hot is hotness
The state of being fixed is fixedness
The state of being huge is hugeness
The state of being situated is situatedness
The state of being pure is pureness
The state of being weak is
2024-07-29 21:17:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 21:19:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2416,  0.0187,  0.1357,  ..., -0.0040,  0.0394,  0.2080],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9492, -2.4922, -2.7988,  ..., -5.8672, -0.0166, -4.1328],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0451,  0.0017, -0.0038,  ..., -0.0095,  0.0002, -0.0005],
        [ 0.0008,  0.0312,  0.0093,  ...,  0.0132,  0.0079,  0.0100],
        [ 0.0192, -0.0191,  0.0405,  ...,  0.0124, -0.0112, -0.0061],
        ...,
        [ 0.0090,  0.0089, -0.0083,  ...,  0.0253,  0.0019, -0.0004],
        [-0.0006,  0.0045, -0.0116,  ...,  0.0047,  0.0452, -0.0026],
        [ 0.0029,  0.0021, -0.0063,  ..., -0.0028, -0.0169,  0.0294]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8145, -2.1465, -2.7070,  ..., -5.4688, -0.1957, -3.7910]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 21:19:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being mad is madness
The state of being foreign is foreignness
The state of being hot is hotness
The state of being fixed is fixedness
The state of being huge is hugeness
The state of being situated is situatedness
The state of being pure is pureness
The state of being weak is
2024-07-29 21:19:25 root INFO     [order_1_approx] starting weight calculation for The state of being pure is pureness
The state of being weak is weakness
The state of being mad is madness
The state of being situated is situatedness
The state of being foreign is foreignness
The state of being huge is hugeness
The state of being hot is hotness
The state of being fixed is
2024-07-29 21:19:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 21:21:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0109, -0.0790, -0.3154,  ...,  0.2671, -0.0699,  0.5176],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4766, -4.0430,  0.3215,  ...,  0.2085, -2.7578, -2.6094],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0770, -0.0028, -0.0168,  ..., -0.0112,  0.0017,  0.0230],
        [ 0.0002,  0.0769,  0.0117,  ...,  0.0363,  0.0124,  0.0011],
        [-0.0235, -0.0064,  0.0422,  ..., -0.0073, -0.0081,  0.0241],
        ...,
        [-0.0060,  0.0037, -0.0013,  ...,  0.0708,  0.0012,  0.0071],
        [-0.0020,  0.0149, -0.0030,  ..., -0.0213,  0.0611, -0.0289],
        [-0.0063,  0.0321, -0.0228,  ..., -0.0028, -0.0170,  0.0843]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4512, -3.5703,  0.5410,  ..., -0.1482, -2.7070, -2.5566]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 21:21:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being pure is pureness
The state of being weak is weakness
The state of being mad is madness
The state of being situated is situatedness
The state of being foreign is foreignness
The state of being huge is hugeness
The state of being hot is hotness
The state of being fixed is
2024-07-29 21:21:38 root INFO     total operator prediction time: 1069.9368607997894 seconds
2024-07-29 21:21:38 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on re+verb_reg
2024-07-29 21:21:38 root INFO     building operator re+verb_reg
2024-07-29 21:21:38 root INFO     [order_1_approx] starting weight calculation for To marry again is to remarry
To examine again is to reexamine
To define again is to redefine
To solve again is to resolve
To publish again is to republish
To establish again is to reestablish
To interpret again is to reinterpret
To acquire again is to
2024-07-29 21:21:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 21:23:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4243,  0.2273, -0.2793,  ..., -0.0153,  0.0981, -0.0381],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6484, -3.7422, -0.0161,  ...,  0.6162, -4.7891, -1.7676],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0548, -0.0142,  0.0125,  ...,  0.0080, -0.0035,  0.0257],
        [ 0.0107,  0.0402,  0.0024,  ...,  0.0130, -0.0014,  0.0047],
        [ 0.0079,  0.0015,  0.0442,  ...,  0.0123,  0.0006, -0.0025],
        ...,
        [ 0.0060,  0.0061,  0.0012,  ...,  0.0631,  0.0098, -0.0115],
        [-0.0110,  0.0238, -0.0005,  ..., -0.0090,  0.0524, -0.0236],
        [-0.0026, -0.0037, -0.0004,  ..., -0.0079, -0.0089,  0.0493]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6875, -3.9180, -0.1276,  ...,  0.7256, -4.7148, -1.6045]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 21:23:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To marry again is to remarry
To examine again is to reexamine
To define again is to redefine
To solve again is to resolve
To publish again is to republish
To establish again is to reestablish
To interpret again is to reinterpret
To acquire again is to
2024-07-29 21:23:52 root INFO     [order_1_approx] starting weight calculation for To define again is to redefine
To publish again is to republish
To solve again is to resolve
To establish again is to reestablish
To acquire again is to reacquire
To examine again is to reexamine
To marry again is to remarry
To interpret again is to
2024-07-29 21:23:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 21:26:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0898, -0.2374,  0.1083,  ...,  0.0825, -0.2954,  0.4307],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6216, -2.3633,  0.7939,  ...,  0.4067, -2.1426, -2.7266],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0684, -0.0049,  0.0250,  ...,  0.0022, -0.0126,  0.0082],
        [ 0.0122,  0.0652,  0.0181,  ...,  0.0080, -0.0019, -0.0027],
        [-0.0070, -0.0145,  0.0551,  ..., -0.0027,  0.0102, -0.0081],
        ...,
        [ 0.0164,  0.0003,  0.0052,  ...,  0.0652,  0.0122, -0.0069],
        [-0.0073, -0.0016,  0.0054,  ..., -0.0085,  0.0473, -0.0097],
        [ 0.0016,  0.0042,  0.0071,  ..., -0.0100, -0.0328,  0.0554]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8877, -2.5781,  0.9004,  ...,  0.3733, -2.1582, -2.9512]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 21:26:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To define again is to redefine
To publish again is to republish
To solve again is to resolve
To establish again is to reestablish
To acquire again is to reacquire
To examine again is to reexamine
To marry again is to remarry
To interpret again is to
2024-07-29 21:26:06 root INFO     [order_1_approx] starting weight calculation for To interpret again is to reinterpret
To solve again is to resolve
To define again is to redefine
To examine again is to reexamine
To establish again is to reestablish
To publish again is to republish
To acquire again is to reacquire
To marry again is to
2024-07-29 21:26:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 21:28:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3301, -0.1769,  0.0214,  ..., -0.2988, -0.7031,  0.3555],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6968, -2.9434,  1.6816,  ..., -0.8228, -3.2266, -2.9629],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.0527e-02,  1.6670e-03,  1.9897e-02,  ...,  1.3588e-02,
         -2.0771e-03,  9.9182e-03],
        [ 8.4763e-03,  2.4963e-02, -6.3171e-03,  ...,  5.0926e-03,
         -9.0179e-03,  2.1324e-03],
        [ 1.9638e-02, -2.5215e-03,  3.2288e-02,  ..., -4.2610e-03,
         -1.4412e-02,  1.4526e-02],
        ...,
        [ 2.0981e-04, -1.4095e-03,  3.2387e-03,  ...,  4.1534e-02,
          3.8147e-06, -1.8997e-03],
        [ 1.5839e-02,  4.5700e-03,  8.1406e-03,  ..., -4.3793e-03,
          2.0248e-02,  9.5367e-03],
        [-4.8981e-03, -6.3133e-03, -3.5534e-03,  ..., -5.1384e-03,
         -1.3206e-02,  4.2664e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7261, -2.8789,  1.2051,  ..., -0.6626, -3.1250, -2.7773]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 21:28:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To interpret again is to reinterpret
To solve again is to resolve
To define again is to redefine
To examine again is to reexamine
To establish again is to reestablish
To publish again is to republish
To acquire again is to reacquire
To marry again is to
2024-07-29 21:28:20 root INFO     [order_1_approx] starting weight calculation for To establish again is to reestablish
To solve again is to resolve
To acquire again is to reacquire
To define again is to redefine
To marry again is to remarry
To interpret again is to reinterpret
To examine again is to reexamine
To publish again is to
2024-07-29 21:28:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 21:30:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0806,  0.0873,  0.2988,  ...,  0.2092,  0.1155,  0.3762],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8115, -2.6953, -0.4170,  ...,  1.2002, -2.9766, -1.3525],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0534, -0.0067,  0.0278,  ...,  0.0162, -0.0157,  0.0177],
        [ 0.0147,  0.0515, -0.0018,  ...,  0.0168, -0.0064,  0.0015],
        [ 0.0091, -0.0050,  0.0469,  ..., -0.0051, -0.0022, -0.0017],
        ...,
        [-0.0019,  0.0029, -0.0004,  ...,  0.0490,  0.0034,  0.0001],
        [-0.0069,  0.0014, -0.0085,  ..., -0.0013,  0.0350, -0.0128],
        [ 0.0029, -0.0148,  0.0040,  ...,  0.0011, -0.0344,  0.0445]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8721, -2.8145,  0.0425,  ...,  1.3633, -2.7988, -1.4736]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 21:30:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To establish again is to reestablish
To solve again is to resolve
To acquire again is to reacquire
To define again is to redefine
To marry again is to remarry
To interpret again is to reinterpret
To examine again is to reexamine
To publish again is to
2024-07-29 21:30:33 root INFO     [order_1_approx] starting weight calculation for To acquire again is to reacquire
To interpret again is to reinterpret
To marry again is to remarry
To examine again is to reexamine
To publish again is to republish
To define again is to redefine
To solve again is to resolve
To establish again is to
2024-07-29 21:30:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 21:32:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0800,  0.0215,  0.1488,  ..., -0.0064, -0.3730,  0.1414],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.4072, -5.7305,  0.8594,  ...,  0.9834, -4.8125, -2.5547],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0739, -0.0226,  0.0200,  ...,  0.0053, -0.0059,  0.0167],
        [ 0.0049,  0.0737,  0.0042,  ...,  0.0116, -0.0066,  0.0052],
        [ 0.0019,  0.0152,  0.0490,  ...,  0.0096,  0.0188, -0.0050],
        ...,
        [ 0.0070, -0.0020, -0.0121,  ...,  0.0731,  0.0024, -0.0071],
        [-0.0044,  0.0118,  0.0135,  ...,  0.0128,  0.0551, -0.0053],
        [-0.0038,  0.0139, -0.0045,  ...,  0.0004, -0.0135,  0.0547]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.2148, -5.7773,  1.1133,  ...,  1.2285, -4.6016, -2.9336]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 21:32:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To acquire again is to reacquire
To interpret again is to reinterpret
To marry again is to remarry
To examine again is to reexamine
To publish again is to republish
To define again is to redefine
To solve again is to resolve
To establish again is to
2024-07-29 21:32:47 root INFO     [order_1_approx] starting weight calculation for To establish again is to reestablish
To publish again is to republish
To acquire again is to reacquire
To marry again is to remarry
To solve again is to resolve
To interpret again is to reinterpret
To define again is to redefine
To examine again is to
2024-07-29 21:32:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 21:35:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1833, -0.2847, -0.0566,  ..., -0.2043, -0.1381,  0.0043],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.2188, -4.0195,  2.8672,  ..., -0.5420, -1.7715, -4.7500],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.4829e-02, -5.2185e-03,  1.6998e-02,  ...,  1.1459e-02,
         -1.1806e-03,  1.2756e-02],
        [ 2.4796e-02,  7.1960e-02, -2.0103e-03,  ...,  1.1948e-02,
          2.1629e-03,  9.8343e-03],
        [-4.2877e-03,  4.1389e-04,  4.8157e-02,  ..., -8.2016e-05,
          1.2581e-02, -1.0529e-02],
        ...,
        [ 1.7731e-02,  6.0043e-03,  6.8512e-03,  ...,  6.7261e-02,
         -9.4299e-03, -1.2531e-03],
        [-1.0292e-02,  3.1471e-03, -7.4539e-03,  ...,  1.4549e-02,
          5.4688e-02, -1.0178e-02],
        [-4.8332e-03,  5.6343e-03, -1.0967e-03,  ..., -6.9733e-03,
         -1.8799e-02,  5.1025e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1807, -4.0703,  2.7070,  ..., -0.3960, -1.9961, -4.1797]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 21:35:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To establish again is to reestablish
To publish again is to republish
To acquire again is to reacquire
To marry again is to remarry
To solve again is to resolve
To interpret again is to reinterpret
To define again is to redefine
To examine again is to
2024-07-29 21:35:01 root INFO     [order_1_approx] starting weight calculation for To acquire again is to reacquire
To examine again is to reexamine
To interpret again is to reinterpret
To establish again is to reestablish
To define again is to redefine
To marry again is to remarry
To publish again is to republish
To solve again is to
2024-07-29 21:35:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 21:37:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2710, -0.6357, -0.1794,  ..., -0.3647, -0.5098,  0.3259],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0308, -1.8906, -1.6709,  ...,  1.6484, -3.4238,  0.7871],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.6284e-02, -7.2708e-03,  2.4963e-02,  ...,  7.4348e-03,
         -6.2561e-03,  2.7069e-02],
        [ 1.3290e-02,  5.5145e-02, -4.1428e-03,  ...,  2.1118e-02,
         -1.5545e-04,  4.1008e-05],
        [-3.5172e-03,  1.4915e-03,  5.2124e-02,  ..., -1.9760e-03,
          2.4612e-02, -1.3855e-02],
        ...,
        [ 2.9114e-02,  4.7302e-03,  7.4768e-03,  ...,  7.9346e-02,
         -9.3689e-03,  5.0392e-03],
        [-2.5986e-02,  2.1088e-02, -9.8419e-03,  ..., -8.3618e-03,
          5.2307e-02, -2.3438e-02],
        [ 1.0582e-02, -5.0049e-03,  1.5450e-02,  ...,  3.2425e-03,
         -7.4463e-03,  5.3223e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0817, -1.6631, -1.4492,  ...,  1.6289, -3.3750,  0.8877]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 21:37:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To acquire again is to reacquire
To examine again is to reexamine
To interpret again is to reinterpret
To establish again is to reestablish
To define again is to redefine
To marry again is to remarry
To publish again is to republish
To solve again is to
2024-07-29 21:37:14 root INFO     [order_1_approx] starting weight calculation for To examine again is to reexamine
To solve again is to resolve
To marry again is to remarry
To acquire again is to reacquire
To publish again is to republish
To establish again is to reestablish
To interpret again is to reinterpret
To define again is to
2024-07-29 21:37:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 21:39:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2217, -0.5117,  0.5137,  ..., -0.2778,  0.2273, -0.4155],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.8936, -2.4434,  1.8174,  ...,  2.1992, -2.8145, -2.6270],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0469, -0.0005,  0.0077,  ..., -0.0098, -0.0004,  0.0066],
        [ 0.0043,  0.0287,  0.0062,  ..., -0.0015,  0.0047,  0.0041],
        [-0.0034,  0.0096,  0.0368,  ...,  0.0073,  0.0060,  0.0026],
        ...,
        [ 0.0012, -0.0014, -0.0021,  ...,  0.0569,  0.0085, -0.0068],
        [-0.0013, -0.0039, -0.0027,  ..., -0.0089,  0.0471, -0.0043],
        [-0.0013,  0.0017, -0.0024,  ..., -0.0156, -0.0171,  0.0372]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.2578, -2.1230,  1.3594,  ...,  2.6992, -2.8438, -2.3672]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 21:39:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To examine again is to reexamine
To solve again is to resolve
To marry again is to remarry
To acquire again is to reacquire
To publish again is to republish
To establish again is to reestablish
To interpret again is to reinterpret
To define again is to
2024-07-29 21:39:27 root INFO     total operator prediction time: 1068.9065828323364 seconds
2024-07-29 21:39:27 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on un+adj_reg
2024-07-29 21:39:27 root INFO     building operator un+adj_reg
2024-07-29 21:39:27 root INFO     [order_1_approx] starting weight calculation for The opposite of predictable is unpredictable
The opposite of known is unknown
The opposite of sustainable is unsustainable
The opposite of expected is unexpected
The opposite of avoidable is unavoidable
The opposite of forgettable is unforgettable
The opposite of fortunate is unfortunate
The opposite of lucky is
2024-07-29 21:39:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 21:41:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0404,  0.3450,  0.3115,  ..., -0.4009,  0.0116,  0.3123],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4580, -1.7129, -0.8594,  ..., -2.7793, -0.4014, -1.8174],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.0884e-02,  2.5101e-03, -2.3212e-03,  ...,  1.4290e-02,
         -5.8899e-03, -7.3051e-03],
        [ 6.3095e-03,  3.2990e-02,  3.8414e-03,  ...,  1.9791e-02,
          5.4855e-03,  4.2534e-04],
        [-1.7185e-03,  2.7008e-03,  2.6199e-02,  ..., -4.8637e-04,
         -1.4374e-02, -1.4061e-02],
        ...,
        [ 1.7715e-02,  6.0272e-04, -7.1106e-03,  ...,  1.4626e-02,
         -1.1368e-03, -2.0370e-02],
        [-2.0142e-02,  4.9591e-05, -3.6926e-03,  ..., -5.4436e-03,
          2.9526e-02,  1.2581e-02],
        [ 1.3718e-02, -3.8696e-02, -2.6703e-04,  ...,  1.2810e-02,
         -9.7961e-03,  4.1046e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6167, -1.5352, -0.7329,  ..., -2.6953, -0.2256, -2.1172]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 21:41:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of predictable is unpredictable
The opposite of known is unknown
The opposite of sustainable is unsustainable
The opposite of expected is unexpected
The opposite of avoidable is unavoidable
The opposite of forgettable is unforgettable
The opposite of fortunate is unfortunate
The opposite of lucky is
2024-07-29 21:41:38 root INFO     [order_1_approx] starting weight calculation for The opposite of fortunate is unfortunate
The opposite of avoidable is unavoidable
The opposite of expected is unexpected
The opposite of forgettable is unforgettable
The opposite of sustainable is unsustainable
The opposite of lucky is unlucky
The opposite of predictable is unpredictable
The opposite of known is
2024-07-29 21:41:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 21:43:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1271,  0.0651,  0.0061,  ..., -0.0561,  0.0220, -0.7090],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3804,  0.2490,  1.0684,  ...,  1.3066, -3.1133, -0.6602],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0767, -0.0059,  0.0105,  ...,  0.0138, -0.0066,  0.0122],
        [-0.0185,  0.0518,  0.0029,  ...,  0.0191,  0.0085,  0.0012],
        [ 0.0137,  0.0106,  0.0364,  ...,  0.0025, -0.0196,  0.0216],
        ...,
        [-0.0020,  0.0245, -0.0016,  ...,  0.0312, -0.0121, -0.0022],
        [ 0.0098,  0.0019,  0.0080,  ..., -0.0015,  0.0461, -0.0022],
        [ 0.0082,  0.0070, -0.0181,  ..., -0.0226, -0.0201,  0.0503]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3438,  0.4575,  0.3862,  ...,  1.1895, -3.6289, -0.9922]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 21:43:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of fortunate is unfortunate
The opposite of avoidable is unavoidable
The opposite of expected is unexpected
The opposite of forgettable is unforgettable
The opposite of sustainable is unsustainable
The opposite of lucky is unlucky
The opposite of predictable is unpredictable
The opposite of known is
2024-07-29 21:43:51 root INFO     [order_1_approx] starting weight calculation for The opposite of sustainable is unsustainable
The opposite of fortunate is unfortunate
The opposite of known is unknown
The opposite of forgettable is unforgettable
The opposite of predictable is unpredictable
The opposite of lucky is unlucky
The opposite of expected is unexpected
The opposite of avoidable is
2024-07-29 21:43:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 21:46:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0857,  0.2308, -0.0428,  ..., -0.6899, -0.0599, -0.0930],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3125, -1.9863, -1.4805,  ..., -0.9854, -5.2031, -5.1250],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0635,  0.0260,  0.0186,  ...,  0.0229, -0.0330,  0.0007],
        [ 0.0040,  0.0517,  0.0064,  ...,  0.0326,  0.0198,  0.0077],
        [ 0.0078, -0.0023,  0.0294,  ..., -0.0181, -0.0241, -0.0099],
        ...,
        [ 0.0138,  0.0152, -0.0069,  ..., -0.0073, -0.0023, -0.0177],
        [ 0.0082,  0.0162,  0.0164,  ..., -0.0070,  0.0279, -0.0065],
        [ 0.0045,  0.0030, -0.0077,  ..., -0.0114,  0.0184,  0.0239]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7617, -1.9688, -2.0664,  ..., -0.7905, -5.3672, -5.1758]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 21:46:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of sustainable is unsustainable
The opposite of fortunate is unfortunate
The opposite of known is unknown
The opposite of forgettable is unforgettable
The opposite of predictable is unpredictable
The opposite of lucky is unlucky
The opposite of expected is unexpected
The opposite of avoidable is
2024-07-29 21:46:05 root INFO     [order_1_approx] starting weight calculation for The opposite of avoidable is unavoidable
The opposite of forgettable is unforgettable
The opposite of fortunate is unfortunate
The opposite of lucky is unlucky
The opposite of known is unknown
The opposite of predictable is unpredictable
The opposite of sustainable is unsustainable
The opposite of expected is
2024-07-29 21:46:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 21:48:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1794, -0.0444, -0.1324,  ..., -0.6040,  0.0745, -0.5034],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.9844, -1.4375, -0.9355,  ..., -0.8945, -1.4219, -3.6348],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0457, -0.0189,  0.0100,  ...,  0.0190, -0.0126,  0.0122],
        [-0.0063,  0.0532, -0.0032,  ...,  0.0093,  0.0148,  0.0031],
        [ 0.0119, -0.0103,  0.0236,  ...,  0.0082, -0.0053,  0.0082],
        ...,
        [-0.0059,  0.0209, -0.0163,  ...,  0.0323, -0.0187, -0.0148],
        [ 0.0036,  0.0045,  0.0150,  ..., -0.0148,  0.0580,  0.0181],
        [ 0.0253, -0.0057, -0.0111,  ..., -0.0095, -0.0150,  0.0487]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.5156, -1.7725, -1.1660,  ..., -0.3540, -1.7314, -3.7734]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 21:48:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of avoidable is unavoidable
The opposite of forgettable is unforgettable
The opposite of fortunate is unfortunate
The opposite of lucky is unlucky
The opposite of known is unknown
The opposite of predictable is unpredictable
The opposite of sustainable is unsustainable
The opposite of expected is
2024-07-29 21:48:18 root INFO     [order_1_approx] starting weight calculation for The opposite of predictable is unpredictable
The opposite of sustainable is unsustainable
The opposite of lucky is unlucky
The opposite of expected is unexpected
The opposite of avoidable is unavoidable
The opposite of forgettable is unforgettable
The opposite of known is unknown
The opposite of fortunate is
2024-07-29 21:48:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 21:50:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0712,  0.5991, -0.2915,  ..., -0.3469, -0.0215,  0.3127],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0234, -0.4199, -1.1748,  ..., -1.7900, -1.0264, -3.4570],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.5532e-02, -1.6281e-02,  1.3054e-02,  ...,  1.2680e-02,
         -3.6659e-03,  7.3318e-03],
        [-6.2103e-03,  2.8641e-02, -1.7986e-03,  ...,  3.0777e-02,
          1.1513e-02,  3.0487e-02],
        [ 4.5738e-03, -2.2156e-02,  2.4918e-02,  ..., -9.3384e-03,
         -1.0979e-02, -1.2177e-02],
        ...,
        [ 1.8051e-02,  1.4977e-02,  2.0142e-03,  ...,  2.6642e-02,
          8.3923e-05,  9.5139e-03],
        [ 1.9226e-02, -1.1353e-02,  2.0660e-02,  ..., -3.2101e-03,
          4.9103e-02,  1.2466e-02],
        [ 8.8730e-03, -2.3071e-02, -2.1286e-02,  ..., -1.7433e-03,
         -2.0386e-02,  5.8594e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8633, -0.3984, -0.9873,  ..., -1.4580, -1.3184, -3.1855]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 21:50:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of predictable is unpredictable
The opposite of sustainable is unsustainable
The opposite of lucky is unlucky
The opposite of expected is unexpected
The opposite of avoidable is unavoidable
The opposite of forgettable is unforgettable
The opposite of known is unknown
The opposite of fortunate is
2024-07-29 21:50:31 root INFO     [order_1_approx] starting weight calculation for The opposite of lucky is unlucky
The opposite of sustainable is unsustainable
The opposite of avoidable is unavoidable
The opposite of forgettable is unforgettable
The opposite of expected is unexpected
The opposite of known is unknown
The opposite of fortunate is unfortunate
The opposite of predictable is
2024-07-29 21:50:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 21:52:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2280,  0.2798, -0.1375,  ..., -0.1567,  0.2708,  0.1001],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9980, -0.8242, -1.3887,  ...,  1.0449, -1.1670, -2.2324],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0319,  0.0093, -0.0026,  ...,  0.0080,  0.0042, -0.0024],
        [ 0.0056,  0.0307,  0.0080,  ...,  0.0162,  0.0070,  0.0007],
        [ 0.0073,  0.0075,  0.0164,  ...,  0.0032, -0.0197,  0.0130],
        ...,
        [ 0.0003,  0.0084, -0.0043,  ...,  0.0200, -0.0069, -0.0043],
        [ 0.0088,  0.0220,  0.0210,  ...,  0.0023,  0.0287,  0.0062],
        [ 0.0081, -0.0084, -0.0109,  ..., -0.0146, -0.0110,  0.0276]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3086, -0.8418, -1.3066,  ...,  1.3018, -1.1309, -2.5039]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 21:52:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of lucky is unlucky
The opposite of sustainable is unsustainable
The opposite of avoidable is unavoidable
The opposite of forgettable is unforgettable
The opposite of expected is unexpected
The opposite of known is unknown
The opposite of fortunate is unfortunate
The opposite of predictable is
2024-07-29 21:52:45 root INFO     [order_1_approx] starting weight calculation for The opposite of expected is unexpected
The opposite of forgettable is unforgettable
The opposite of predictable is unpredictable
The opposite of known is unknown
The opposite of lucky is unlucky
The opposite of fortunate is unfortunate
The opposite of avoidable is unavoidable
The opposite of sustainable is
2024-07-29 21:52:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 21:54:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3835, -0.1411, -0.1527,  ..., -0.2920,  0.0565,  0.1733],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9541, -3.0430,  0.3945,  ..., -2.3750, -2.5625, -0.7646],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0566,  0.0105, -0.0028,  ...,  0.0116, -0.0094, -0.0101],
        [-0.0165,  0.0439,  0.0070,  ...,  0.0070,  0.0174,  0.0128],
        [-0.0024, -0.0017,  0.0145,  ...,  0.0109, -0.0258, -0.0119],
        ...,
        [-0.0048,  0.0112, -0.0121,  ...,  0.0116,  0.0116, -0.0093],
        [-0.0179,  0.0257,  0.0094,  ..., -0.0111,  0.0267,  0.0211],
        [-0.0132, -0.0106, -0.0133,  ..., -0.0113,  0.0094,  0.0270]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2207, -2.9434,  0.7715,  ..., -2.0977, -2.3613, -0.6885]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 21:54:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of expected is unexpected
The opposite of forgettable is unforgettable
The opposite of predictable is unpredictable
The opposite of known is unknown
The opposite of lucky is unlucky
The opposite of fortunate is unfortunate
The opposite of avoidable is unavoidable
The opposite of sustainable is
2024-07-29 21:54:56 root INFO     [order_1_approx] starting weight calculation for The opposite of avoidable is unavoidable
The opposite of fortunate is unfortunate
The opposite of lucky is unlucky
The opposite of expected is unexpected
The opposite of sustainable is unsustainable
The opposite of predictable is unpredictable
The opposite of known is unknown
The opposite of forgettable is
2024-07-29 21:54:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 21:57:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4844, -0.5010, -0.2063,  ..., -0.3413, -0.0908,  0.0618],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1357, -1.8359, -1.0938,  ..., -1.4980, -6.5430, -4.0859],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0682,  0.0289,  0.0182,  ...,  0.0089, -0.0164,  0.0200],
        [-0.0175,  0.0809,  0.0025,  ...,  0.0265,  0.0070, -0.0094],
        [ 0.0202,  0.0277,  0.0282,  ..., -0.0048, -0.0251, -0.0088],
        ...,
        [-0.0071,  0.0202,  0.0111,  ...,  0.0381,  0.0073, -0.0299],
        [ 0.0069,  0.0141,  0.0195,  ..., -0.0173,  0.0523, -0.0119],
        [ 0.0040,  0.0134, -0.0152,  ...,  0.0039, -0.0158,  0.0621]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5166, -1.7812, -0.8301,  ..., -1.0928, -6.5859, -4.2227]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 21:57:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of avoidable is unavoidable
The opposite of fortunate is unfortunate
The opposite of lucky is unlucky
The opposite of expected is unexpected
The opposite of sustainable is unsustainable
The opposite of predictable is unpredictable
The opposite of known is unknown
The opposite of forgettable is
2024-07-29 21:57:09 root INFO     total operator prediction time: 1062.4852764606476 seconds
2024-07-29 21:57:09 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+able_reg
2024-07-29 21:57:09 root INFO     building operator verb+able_reg
2024-07-29 21:57:10 root INFO     [order_1_approx] starting weight calculation for If you can expand something, that thing is expandable
If you can expect something, that thing is expectable
If you can enjoy something, that thing is enjoyable
If you can achieve something, that thing is achieveable
If you can imagine something, that thing is imaginable
If you can publish something, that thing is publishable
If you can write something, that thing is writeable
If you can deliver something, that thing is
2024-07-29 21:57:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 21:59:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3240,  0.3215,  0.1240,  ...,  0.0983, -0.2705,  0.2651],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7695, -2.5176, -1.0654,  ..., -2.0566, -7.7227, -3.8906],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0699,  0.0150,  0.0128,  ...,  0.0184, -0.0170,  0.0321],
        [-0.0155,  0.0605,  0.0036,  ...,  0.0110, -0.0074, -0.0062],
        [ 0.0095,  0.0048,  0.0328,  ...,  0.0020,  0.0027, -0.0189],
        ...,
        [ 0.0216,  0.0067,  0.0005,  ...,  0.0552,  0.0077, -0.0019],
        [-0.0020, -0.0360, -0.0189,  ..., -0.0261,  0.0352, -0.0269],
        [ 0.0106, -0.0138, -0.0097,  ..., -0.0181, -0.0135,  0.0484]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4727, -2.5801, -0.9873,  ..., -2.1035, -7.2031, -3.8164]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 21:59:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can expand something, that thing is expandable
If you can expect something, that thing is expectable
If you can enjoy something, that thing is enjoyable
If you can achieve something, that thing is achieveable
If you can imagine something, that thing is imaginable
If you can publish something, that thing is publishable
If you can write something, that thing is writeable
If you can deliver something, that thing is
2024-07-29 21:59:22 root INFO     [order_1_approx] starting weight calculation for If you can write something, that thing is writeable
If you can publish something, that thing is publishable
If you can expand something, that thing is expandable
If you can imagine something, that thing is imaginable
If you can achieve something, that thing is achieveable
If you can expect something, that thing is expectable
If you can deliver something, that thing is deliverable
If you can enjoy something, that thing is
2024-07-29 21:59:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 22:01:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2886, -0.0363,  0.2239,  ..., -0.1664, -0.2129, -0.0193],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.3359, -0.1807, -1.6221,  ..., -2.2832, -8.0469, -2.8047],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0579,  0.0196,  0.0203,  ...,  0.0219, -0.0048,  0.0350],
        [-0.0010,  0.0405, -0.0006,  ...,  0.0190, -0.0120, -0.0110],
        [-0.0052, -0.0183,  0.0352,  ..., -0.0010, -0.0312, -0.0129],
        ...,
        [ 0.0102, -0.0012, -0.0087,  ...,  0.0463,  0.0137,  0.0021],
        [ 0.0061, -0.0022, -0.0022,  ..., -0.0207,  0.0485, -0.0009],
        [-0.0027, -0.0018,  0.0115,  ..., -0.0092, -0.0175,  0.0247]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.0625, -0.4431, -1.7217,  ..., -2.1582, -7.9492, -2.9531]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 22:01:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can write something, that thing is writeable
If you can publish something, that thing is publishable
If you can expand something, that thing is expandable
If you can imagine something, that thing is imaginable
If you can achieve something, that thing is achieveable
If you can expect something, that thing is expectable
If you can deliver something, that thing is deliverable
If you can enjoy something, that thing is
2024-07-29 22:01:30 root INFO     [order_1_approx] starting weight calculation for If you can enjoy something, that thing is enjoyable
If you can write something, that thing is writeable
If you can imagine something, that thing is imaginable
If you can deliver something, that thing is deliverable
If you can expand something, that thing is expandable
If you can achieve something, that thing is achieveable
If you can publish something, that thing is publishable
If you can expect something, that thing is
2024-07-29 22:01:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 22:03:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0060,  0.0714,  0.0490,  ..., -0.2751, -0.0487, -0.4038],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4375, -0.8086, -4.6406,  ..., -3.1035, -7.9297, -3.8281],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0509,  0.0269,  0.0178,  ...,  0.0235, -0.0190,  0.0197],
        [-0.0228,  0.0554,  0.0188,  ...,  0.0148, -0.0007, -0.0108],
        [ 0.0055, -0.0166,  0.0274,  ..., -0.0100,  0.0129, -0.0338],
        ...,
        [-0.0097,  0.0275,  0.0033,  ...,  0.0487,  0.0007,  0.0062],
        [ 0.0189, -0.0004, -0.0172,  ..., -0.0333,  0.0514, -0.0213],
        [ 0.0195, -0.0030,  0.0122,  ..., -0.0178, -0.0109,  0.0360]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0869, -0.7207, -4.8477,  ..., -3.1230, -7.6094, -4.1328]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 22:03:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can enjoy something, that thing is enjoyable
If you can write something, that thing is writeable
If you can imagine something, that thing is imaginable
If you can deliver something, that thing is deliverable
If you can expand something, that thing is expandable
If you can achieve something, that thing is achieveable
If you can publish something, that thing is publishable
If you can expect something, that thing is
2024-07-29 22:03:42 root INFO     [order_1_approx] starting weight calculation for If you can expect something, that thing is expectable
If you can achieve something, that thing is achieveable
If you can publish something, that thing is publishable
If you can write something, that thing is writeable
If you can enjoy something, that thing is enjoyable
If you can expand something, that thing is expandable
If you can deliver something, that thing is deliverable
If you can imagine something, that thing is
2024-07-29 22:03:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 22:05:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0659, -0.0834,  0.8457,  ..., -0.3242,  0.2549, -0.0941],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5820, -0.8672,  1.2793,  ..., -3.0879, -7.6562, -2.5781],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0618,  0.0099,  0.0092,  ...,  0.0005, -0.0163,  0.0073],
        [-0.0095,  0.0404,  0.0092,  ...,  0.0168, -0.0054, -0.0045],
        [ 0.0004, -0.0050,  0.0433,  ...,  0.0010, -0.0003, -0.0129],
        ...,
        [ 0.0110,  0.0150, -0.0053,  ...,  0.0515, -0.0105, -0.0115],
        [ 0.0094, -0.0048, -0.0014,  ..., -0.0248,  0.0496, -0.0025],
        [ 0.0069, -0.0083, -0.0099,  ..., -0.0117, -0.0297,  0.0505]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5723, -1.0049,  0.9961,  ..., -2.6133, -7.1328, -2.7090]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 22:05:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can expect something, that thing is expectable
If you can achieve something, that thing is achieveable
If you can publish something, that thing is publishable
If you can write something, that thing is writeable
If you can enjoy something, that thing is enjoyable
If you can expand something, that thing is expandable
If you can deliver something, that thing is deliverable
If you can imagine something, that thing is
2024-07-29 22:05:54 root INFO     [order_1_approx] starting weight calculation for If you can publish something, that thing is publishable
If you can enjoy something, that thing is enjoyable
If you can write something, that thing is writeable
If you can expect something, that thing is expectable
If you can imagine something, that thing is imaginable
If you can expand something, that thing is expandable
If you can deliver something, that thing is deliverable
If you can achieve something, that thing is
2024-07-29 22:05:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 22:08:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4016,  0.4236, -0.1969,  ..., -0.0809, -0.3284,  0.1873],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1934,  0.5371, -2.3398,  ..., -3.5547, -8.9766, -3.9531],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0403,  0.0222,  0.0028,  ...,  0.0069,  0.0070,  0.0337],
        [-0.0026,  0.0337,  0.0027,  ..., -0.0003,  0.0049, -0.0156],
        [ 0.0061, -0.0145,  0.0189,  ..., -0.0061,  0.0030, -0.0044],
        ...,
        [ 0.0085,  0.0092, -0.0039,  ...,  0.0291,  0.0097, -0.0046],
        [ 0.0106,  0.0128, -0.0076,  ..., -0.0237,  0.0211, -0.0040],
        [ 0.0055, -0.0096,  0.0040,  ..., -0.0158, -0.0090,  0.0225]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2240,  0.3403, -2.2266,  ..., -3.6582, -9.0234, -4.1211]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 22:08:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can publish something, that thing is publishable
If you can enjoy something, that thing is enjoyable
If you can write something, that thing is writeable
If you can expect something, that thing is expectable
If you can imagine something, that thing is imaginable
If you can expand something, that thing is expandable
If you can deliver something, that thing is deliverable
If you can achieve something, that thing is
2024-07-29 22:08:07 root INFO     [order_1_approx] starting weight calculation for If you can publish something, that thing is publishable
If you can enjoy something, that thing is enjoyable
If you can expect something, that thing is expectable
If you can deliver something, that thing is deliverable
If you can write something, that thing is writeable
If you can imagine something, that thing is imaginable
If you can achieve something, that thing is achieveable
If you can expand something, that thing is
2024-07-29 22:08:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 22:10:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1753,  0.0162, -0.0452,  ...,  0.0367,  0.3501,  0.2896],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5283, -1.9902,  0.2725,  ..., -2.2109, -7.4922, -3.5059],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.0436e-02, -2.5711e-03,  3.9406e-03,  ...,  2.6672e-02,
          1.1185e-02,  2.5604e-02],
        [-1.2985e-02,  6.3538e-02,  1.6983e-02,  ...,  3.7842e-03,
         -1.4526e-02, -2.3880e-03],
        [ 1.1223e-02, -7.7782e-03,  5.4871e-02,  ...,  1.9073e-06,
         -5.2376e-03, -1.5274e-02],
        ...,
        [ 1.8036e-02,  1.3199e-02, -9.9182e-05,  ...,  5.8716e-02,
          1.0284e-02,  2.2980e-02],
        [ 6.8092e-03, -4.8828e-04, -1.2756e-02,  ..., -4.4617e-02,
          5.8807e-02, -1.5457e-02],
        [ 2.0790e-04,  1.2207e-04,  1.0010e-02,  ..., -1.0780e-02,
         -2.7481e-02,  6.0822e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0151, -1.8945,  0.4434,  ..., -2.3223, -7.1758, -3.4648]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 22:10:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can publish something, that thing is publishable
If you can enjoy something, that thing is enjoyable
If you can expect something, that thing is expectable
If you can deliver something, that thing is deliverable
If you can write something, that thing is writeable
If you can imagine something, that thing is imaginable
If you can achieve something, that thing is achieveable
If you can expand something, that thing is
2024-07-29 22:10:19 root INFO     [order_1_approx] starting weight calculation for If you can expand something, that thing is expandable
If you can write something, that thing is writeable
If you can achieve something, that thing is achieveable
If you can expect something, that thing is expectable
If you can imagine something, that thing is imaginable
If you can enjoy something, that thing is enjoyable
If you can deliver something, that thing is deliverable
If you can publish something, that thing is
2024-07-29 22:10:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 22:12:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2859,  0.2285,  0.2676,  ...,  0.3303,  0.0266,  0.4338],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8750, -2.7031, -1.4053,  ..., -2.2500, -8.3594, -1.0449],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.7516e-02,  1.7059e-02, -7.2556e-03,  ...,  6.4926e-03,
         -1.5717e-03,  3.1586e-02],
        [-2.1744e-02,  3.8727e-02,  9.7275e-05,  ...,  3.9444e-03,
         -1.1810e-02, -1.5678e-03],
        [ 9.4681e-03, -1.1078e-02,  2.7756e-02,  ..., -3.5229e-03,
         -4.4937e-03, -1.0986e-02],
        ...,
        [ 9.6512e-03,  9.1858e-03, -6.0310e-03,  ...,  3.6011e-02,
          7.3624e-03,  4.9286e-03],
        [-6.3820e-03, -1.7151e-02, -5.8975e-03,  ..., -3.0533e-02,
          3.5126e-02, -3.0396e-02],
        [ 7.7782e-03,  7.1564e-03,  1.6155e-03,  ..., -2.3834e-02,
         -1.9836e-02,  3.1769e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6782, -2.8984, -1.2119,  ..., -2.3242, -7.9180, -1.2158]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 22:12:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can expand something, that thing is expandable
If you can write something, that thing is writeable
If you can achieve something, that thing is achieveable
If you can expect something, that thing is expectable
If you can imagine something, that thing is imaginable
If you can enjoy something, that thing is enjoyable
If you can deliver something, that thing is deliverable
If you can publish something, that thing is
2024-07-29 22:12:32 root INFO     [order_1_approx] starting weight calculation for If you can publish something, that thing is publishable
If you can enjoy something, that thing is enjoyable
If you can achieve something, that thing is achieveable
If you can expand something, that thing is expandable
If you can deliver something, that thing is deliverable
If you can imagine something, that thing is imaginable
If you can expect something, that thing is expectable
If you can write something, that thing is
2024-07-29 22:12:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 22:14:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2029, -0.1823,  0.3252,  ..., -0.4929, -0.0321,  0.1127],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.2988, -1.5771, -0.1279,  ..., -3.3281, -8.0859,  0.4238],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.1035e-02,  7.4387e-03, -2.3727e-03,  ..., -5.6171e-04,
         -1.5488e-02,  2.1393e-02],
        [-9.4147e-03,  3.3630e-02,  9.2850e-03,  ...,  8.2703e-03,
         -1.2680e-02, -1.1292e-02],
        [ 5.9662e-03, -9.4070e-03,  5.6793e-02,  ...,  4.3335e-03,
         -1.1110e-03, -9.7046e-03],
        ...,
        [ 2.9587e-02,  1.3863e-02, -6.8054e-03,  ...,  4.8248e-02,
          9.9182e-05, -1.2779e-02],
        [ 1.5144e-02,  7.7057e-04,  1.0757e-03,  ..., -7.9956e-03,
          3.9520e-02, -5.2719e-03],
        [ 1.6220e-02,  7.1716e-03,  8.1253e-03,  ..., -1.4542e-02,
         -1.0437e-02,  2.6337e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.2744, -1.5146, -0.1946,  ..., -2.8887, -7.9609,  0.3997]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 22:14:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can publish something, that thing is publishable
If you can enjoy something, that thing is enjoyable
If you can achieve something, that thing is achieveable
If you can expand something, that thing is expandable
If you can deliver something, that thing is deliverable
If you can imagine something, that thing is imaginable
If you can expect something, that thing is expectable
If you can write something, that thing is
2024-07-29 22:14:44 root INFO     total operator prediction time: 1054.747683763504 seconds
2024-07-29 22:14:44 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+tion_irreg
2024-07-29 22:14:44 root INFO     building operator verb+tion_irreg
2024-07-29 22:14:45 root INFO     [order_1_approx] starting weight calculation for To perspire results in perspiration
To occupy results in occupation
To observe results in observation
To compile results in compilation
To determine results in determination
To randomize results in randomization
To consult results in consulation
To derive results in
2024-07-29 22:14:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 22:16:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1600, -0.2367,  0.1328,  ..., -0.0165, -0.0309,  0.1816],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2148, -4.7891,  3.0859,  ..., -0.3076, -1.6934, -2.3555],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0363, -0.0138, -0.0553,  ..., -0.0308,  0.0438, -0.0201],
        [ 0.0435,  0.1279,  0.0651,  ...,  0.0411, -0.0297,  0.0272],
        [-0.0275, -0.0314,  0.0386,  ..., -0.0006,  0.0136, -0.0232],
        ...,
        [ 0.0549,  0.0425,  0.0252,  ...,  0.0991, -0.0084,  0.0260],
        [-0.0038,  0.0124,  0.0103,  ..., -0.0012,  0.0839, -0.0110],
        [ 0.0328,  0.0156,  0.0307,  ...,  0.0009, -0.0569,  0.0919]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3296, -3.8398,  2.9922,  ...,  0.3560, -1.8193, -1.9658]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 22:16:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To perspire results in perspiration
To occupy results in occupation
To observe results in observation
To compile results in compilation
To determine results in determination
To randomize results in randomization
To consult results in consulation
To derive results in
2024-07-29 22:16:58 root INFO     [order_1_approx] starting weight calculation for To determine results in determination
To compile results in compilation
To randomize results in randomization
To derive results in derivation
To observe results in observation
To consult results in consulation
To perspire results in perspiration
To occupy results in
2024-07-29 22:16:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 22:19:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1062,  0.2000, -0.2085,  ...,  0.0029, -0.2937, -0.0634],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0186, -6.1406,  2.5586,  ...,  0.0559, -2.0645, -1.6934],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0647,  0.0102, -0.0060,  ...,  0.0012, -0.0041,  0.0105],
        [ 0.0048,  0.0483,  0.0049,  ...,  0.0150,  0.0040,  0.0077],
        [-0.0075, -0.0006,  0.0376,  ...,  0.0031, -0.0087,  0.0021],
        ...,
        [ 0.0037,  0.0063,  0.0070,  ...,  0.0569, -0.0096,  0.0138],
        [-0.0084,  0.0051, -0.0013,  ...,  0.0201,  0.0357, -0.0079],
        [ 0.0072,  0.0033, -0.0052,  ...,  0.0026, -0.0101,  0.0552]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0429, -5.6836,  2.5254,  ..., -0.1033, -1.9609, -1.5615]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 22:19:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To determine results in determination
To compile results in compilation
To randomize results in randomization
To derive results in derivation
To observe results in observation
To consult results in consulation
To perspire results in perspiration
To occupy results in
2024-07-29 22:19:10 root INFO     [order_1_approx] starting weight calculation for To perspire results in perspiration
To derive results in derivation
To occupy results in occupation
To observe results in observation
To consult results in consulation
To compile results in compilation
To determine results in determination
To randomize results in
2024-07-29 22:19:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 22:21:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2168,  0.3247, -0.1652,  ...,  0.2275, -0.4771, -0.5957],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8369, -3.5449,  0.4414,  ...,  1.8848, -2.9805, -4.6562],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0405,  0.0206,  0.0236,  ..., -0.0092,  0.0206, -0.0040],
        [ 0.0191,  0.0797,  0.0177,  ...,  0.0196, -0.0102,  0.0021],
        [-0.0060, -0.0202,  0.0437,  ..., -0.0139,  0.0191, -0.0021],
        ...,
        [ 0.0134,  0.0059,  0.0040,  ...,  0.0623, -0.0208,  0.0201],
        [ 0.0103,  0.0471,  0.0170,  ...,  0.0164,  0.0572,  0.0013],
        [ 0.0088,  0.0015,  0.0022,  ..., -0.0113, -0.0208,  0.0755]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.3779, -3.5273,  0.5649,  ...,  2.2695, -3.4863, -4.5508]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 22:21:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To perspire results in perspiration
To derive results in derivation
To occupy results in occupation
To observe results in observation
To consult results in consulation
To compile results in compilation
To determine results in determination
To randomize results in
2024-07-29 22:21:23 root INFO     [order_1_approx] starting weight calculation for To determine results in determination
To randomize results in randomization
To observe results in observation
To perspire results in perspiration
To consult results in consulation
To occupy results in occupation
To derive results in derivation
To compile results in
2024-07-29 22:21:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 22:23:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2705, -0.0238, -0.0743,  ..., -0.2283, -0.2500,  0.2754],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7031, -4.5586,  4.0742,  ...,  0.7686, -1.5674, -0.1846],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0931, -0.0022,  0.0171,  ..., -0.0079,  0.0171, -0.0017],
        [-0.0027,  0.0797,  0.0214,  ...,  0.0261, -0.0043,  0.0139],
        [-0.0228, -0.0327,  0.0673,  ..., -0.0001,  0.0189, -0.0158],
        ...,
        [ 0.0046,  0.0023,  0.0183,  ...,  0.0898, -0.0112, -0.0196],
        [-0.0100,  0.0138,  0.0087,  ...,  0.0059,  0.0690, -0.0011],
        [ 0.0190,  0.0070,  0.0109,  ...,  0.0064, -0.0319,  0.0772]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6919, -4.1367,  3.8164,  ...,  0.7793, -1.9307, -0.3237]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 22:23:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To determine results in determination
To randomize results in randomization
To observe results in observation
To perspire results in perspiration
To consult results in consulation
To occupy results in occupation
To derive results in derivation
To compile results in
2024-07-29 22:23:36 root INFO     [order_1_approx] starting weight calculation for To determine results in determination
To derive results in derivation
To compile results in compilation
To observe results in observation
To randomize results in randomization
To occupy results in occupation
To consult results in consulation
To perspire results in
2024-07-29 22:23:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 22:25:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0170, -0.6343, -1.1260,  ..., -0.0128,  0.0049, -0.3823],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7676, -6.1914,  3.2461,  ..., -0.8403, -2.1699, -0.9365],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0187, -0.0041, -0.0294,  ..., -0.0087,  0.0341, -0.0183],
        [ 0.0452,  0.0636,  0.0244,  ...,  0.0090, -0.0251,  0.0271],
        [-0.0052,  0.0093,  0.0504,  ..., -0.0009, -0.0059,  0.0010],
        ...,
        [ 0.0299,  0.0006,  0.0057,  ...,  0.0647, -0.0096,  0.0134],
        [-0.0091, -0.0032,  0.0050,  ...,  0.0083,  0.0515,  0.0058],
        [ 0.0083, -0.0131,  0.0029,  ..., -0.0012, -0.0132,  0.0693]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0664, -6.6562,  3.0391,  ..., -0.9185, -2.1367, -1.2256]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 22:25:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To determine results in determination
To derive results in derivation
To compile results in compilation
To observe results in observation
To randomize results in randomization
To occupy results in occupation
To consult results in consulation
To perspire results in
2024-07-29 22:25:50 root INFO     [order_1_approx] starting weight calculation for To compile results in compilation
To randomize results in randomization
To occupy results in occupation
To consult results in consulation
To determine results in determination
To perspire results in perspiration
To derive results in derivation
To observe results in
2024-07-29 22:25:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 22:28:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1919,  0.5200, -0.0501,  ..., -0.0331, -0.1104, -0.1117],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4971, -6.7734,  2.5508,  ...,  0.0308, -1.7998, -1.7510],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 8.1543e-02,  8.0719e-03, -1.6647e-02,  ..., -1.0345e-02,
         -5.5618e-03, -5.1804e-03],
        [ 1.8661e-02,  8.8928e-02,  1.9775e-02,  ...,  1.9684e-02,
         -3.2692e-03,  1.9958e-02],
        [-1.1606e-03, -5.2261e-03,  7.1777e-02,  ..., -1.0345e-02,
          1.5930e-02, -4.9591e-05],
        ...,
        [-1.3123e-03, -6.7749e-03,  2.2598e-02,  ...,  8.2886e-02,
          4.4556e-03,  4.4556e-03],
        [ 2.5635e-03,  1.2878e-02,  1.1932e-02,  ...,  1.7151e-02,
          5.9937e-02, -1.1627e-02],
        [ 1.5495e-02, -4.5624e-03, -1.2360e-02,  ..., -6.2485e-03,
         -4.2358e-02,  7.4890e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4067, -6.3516,  2.5234,  ...,  0.0415, -2.2930, -2.0117]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 22:28:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To compile results in compilation
To randomize results in randomization
To occupy results in occupation
To consult results in consulation
To determine results in determination
To perspire results in perspiration
To derive results in derivation
To observe results in
2024-07-29 22:28:03 root INFO     [order_1_approx] starting weight calculation for To randomize results in randomization
To determine results in determination
To occupy results in occupation
To derive results in derivation
To observe results in observation
To compile results in compilation
To perspire results in perspiration
To consult results in
2024-07-29 22:28:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 22:30:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0476, -0.2778, -0.2961,  ..., -0.1017, -0.3906, -0.2227],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6562, -4.6641,  2.7617,  ...,  0.3013, -0.6631, -1.9062],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0436, -0.0104, -0.0032,  ..., -0.0183,  0.0174,  0.0180],
        [ 0.0129,  0.0667,  0.0236,  ...,  0.0327, -0.0267, -0.0042],
        [-0.0053, -0.0112,  0.0557,  ..., -0.0199,  0.0106, -0.0017],
        ...,
        [ 0.0200,  0.0127,  0.0201,  ...,  0.0656, -0.0026, -0.0055],
        [ 0.0019, -0.0129,  0.0105,  ...,  0.0147,  0.0646, -0.0063],
        [ 0.0248, -0.0012, -0.0041,  ...,  0.0186, -0.0207,  0.0448]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6885, -4.2969,  2.4395,  ...,  0.5122, -0.7603, -1.6104]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 22:30:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To randomize results in randomization
To determine results in determination
To occupy results in occupation
To derive results in derivation
To observe results in observation
To compile results in compilation
To perspire results in perspiration
To consult results in
2024-07-29 22:30:17 root INFO     [order_1_approx] starting weight calculation for To randomize results in randomization
To occupy results in occupation
To compile results in compilation
To perspire results in perspiration
To derive results in derivation
To observe results in observation
To consult results in consulation
To determine results in
2024-07-29 22:30:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 22:32:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3076,  0.1366, -0.2144,  ...,  0.1379, -0.4553, -0.0632],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4336e+00, -5.3750e+00,  3.4863e+00,  ...,  1.7090e-03,
        -4.7109e+00, -2.3887e+00], device='cuda:1', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.8564e-02,  3.8147e-06, -1.3504e-02,  ..., -4.9973e-03,
          1.9104e-02, -2.6188e-03],
        [ 3.3386e-02,  6.3416e-02,  2.3376e-02,  ...,  2.3239e-02,
         -1.8433e-02,  2.1240e-02],
        [ 1.7586e-03, -2.0813e-02,  2.6642e-02,  ..., -1.4038e-02,
          1.5915e-02, -1.2009e-02],
        ...,
        [ 1.1703e-02,  1.8326e-02,  1.1169e-02,  ...,  5.1300e-02,
         -1.1177e-02,  1.1528e-02],
        [ 5.1918e-03,  4.5204e-03,  1.3161e-02,  ...,  6.8817e-03,
          4.1382e-02, -1.4847e-02],
        [ 1.8311e-02,  4.1351e-03,  6.9389e-03,  ..., -1.1024e-02,
         -3.1921e-02,  4.0924e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0625, -4.7930,  3.7832,  ...,  0.2148, -4.4023, -2.2363]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 22:32:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To randomize results in randomization
To occupy results in occupation
To compile results in compilation
To perspire results in perspiration
To derive results in derivation
To observe results in observation
To consult results in consulation
To determine results in
2024-07-29 22:32:30 root INFO     total operator prediction time: 1065.5907926559448 seconds
2024-07-29 22:32:30 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj+ly_reg
2024-07-29 22:32:30 root INFO     building operator adj+ly_reg
2024-07-29 22:32:30 root INFO     [order_1_approx] starting weight calculation for The adjective form of actual is actually
The adjective form of different is differently
The adjective form of visual is visually
The adjective form of rare is rarely
The adjective form of strong is strongly
The adjective form of significant is significantly
The adjective form of important is importantly
The adjective form of physical is
2024-07-29 22:32:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 22:34:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2903, -0.2861, -0.3926,  ..., -0.4924, -0.4907,  0.0814],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0586, -3.5820,  1.2969,  ..., -3.1680, -2.9824, -2.9277],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0685, -0.0320,  0.0071,  ..., -0.0048,  0.0025,  0.0069],
        [-0.0165,  0.0815, -0.0027,  ...,  0.0023,  0.0169, -0.0215],
        [ 0.0019, -0.0283,  0.0639,  ...,  0.0152,  0.0063, -0.0007],
        ...,
        [-0.0154,  0.0216, -0.0446,  ...,  0.0732,  0.0152, -0.0137],
        [ 0.0132, -0.0083,  0.0114,  ..., -0.0133,  0.0476,  0.0105],
        [-0.0010, -0.0031, -0.0106,  ...,  0.0113, -0.0338,  0.0563]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2002, -2.6992,  1.0000,  ..., -2.1523, -2.5918, -3.0996]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 22:34:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of actual is actually
The adjective form of different is differently
The adjective form of visual is visually
The adjective form of rare is rarely
The adjective form of strong is strongly
The adjective form of significant is significantly
The adjective form of important is importantly
The adjective form of physical is
2024-07-29 22:34:44 root INFO     [order_1_approx] starting weight calculation for The adjective form of important is importantly
The adjective form of significant is significantly
The adjective form of different is differently
The adjective form of physical is physically
The adjective form of visual is visually
The adjective form of actual is actually
The adjective form of rare is rarely
The adjective form of strong is
2024-07-29 22:34:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 22:36:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2852, -0.4871,  0.0238,  ..., -0.0299,  0.0338, -0.0144],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0156, -3.2207, -0.9741,  ...,  0.1533, -2.2637, -4.5078],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0677, -0.0153, -0.0059,  ..., -0.0053, -0.0100,  0.0172],
        [ 0.0053,  0.0614,  0.0290,  ...,  0.0097,  0.0138, -0.0045],
        [ 0.0168, -0.0159,  0.0465,  ...,  0.0127, -0.0022, -0.0038],
        ...,
        [-0.0172,  0.0271, -0.0175,  ...,  0.0713,  0.0025,  0.0165],
        [-0.0233,  0.0024, -0.0116,  ..., -0.0154,  0.0469, -0.0076],
        [-0.0120, -0.0052,  0.0192,  ...,  0.0276, -0.0275,  0.0374]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8145, -3.0527, -1.0928,  ...,  0.1427, -2.0000, -4.4375]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 22:36:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of important is importantly
The adjective form of significant is significantly
The adjective form of different is differently
The adjective form of physical is physically
The adjective form of visual is visually
The adjective form of actual is actually
The adjective form of rare is rarely
The adjective form of strong is
2024-07-29 22:36:58 root INFO     [order_1_approx] starting weight calculation for The adjective form of rare is rarely
The adjective form of actual is actually
The adjective form of significant is significantly
The adjective form of important is importantly
The adjective form of strong is strongly
The adjective form of different is differently
The adjective form of physical is physically
The adjective form of visual is
2024-07-29 22:36:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 22:39:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0197, -0.0692, -0.0005,  ..., -0.4504, -0.4011, -0.1941],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1738, -3.7305,  1.6406,  ..., -2.5312, -0.3169, -1.2930],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1006, -0.0293,  0.0036,  ..., -0.0106, -0.0207,  0.0109],
        [ 0.0025,  0.0758,  0.0321,  ...,  0.0234, -0.0080, -0.0093],
        [ 0.0021, -0.0207,  0.0618,  ...,  0.0136, -0.0087,  0.0192],
        ...,
        [ 0.0076,  0.0205, -0.0160,  ...,  0.0788, -0.0043,  0.0042],
        [ 0.0038,  0.0238, -0.0149,  ..., -0.0282,  0.0684, -0.0094],
        [-0.0014,  0.0186, -0.0041,  ...,  0.0010, -0.0272,  0.0401]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7549, -3.7695,  1.1875,  ..., -2.5586,  0.0493, -1.5527]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 22:39:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of rare is rarely
The adjective form of actual is actually
The adjective form of significant is significantly
The adjective form of important is importantly
The adjective form of strong is strongly
The adjective form of different is differently
The adjective form of physical is physically
The adjective form of visual is
2024-07-29 22:39:12 root INFO     [order_1_approx] starting weight calculation for The adjective form of visual is visually
The adjective form of different is differently
The adjective form of rare is rarely
The adjective form of actual is actually
The adjective form of significant is significantly
The adjective form of physical is physically
The adjective form of strong is strongly
The adjective form of important is
2024-07-29 22:39:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 22:41:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2162, -0.3489, -0.2871,  ..., -0.1610, -0.2396, -0.0214],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.2109, -0.8467, -1.1113,  ..., -3.5586, -0.3799, -2.6992],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0611, -0.0172,  0.0138,  ...,  0.0121,  0.0033,  0.0233],
        [ 0.0106,  0.0327,  0.0171,  ...,  0.0170, -0.0045, -0.0052],
        [-0.0049,  0.0177,  0.0485,  ...,  0.0038, -0.0109, -0.0048],
        ...,
        [ 0.0030,  0.0118, -0.0061,  ...,  0.0465,  0.0081,  0.0203],
        [-0.0108,  0.0138,  0.0006,  ..., -0.0176,  0.0306, -0.0038],
        [ 0.0239, -0.0127, -0.0032,  ...,  0.0005, -0.0229,  0.0308]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0430, -0.8887, -0.8076,  ..., -3.7402, -0.2482, -2.8047]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 22:41:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of visual is visually
The adjective form of different is differently
The adjective form of rare is rarely
The adjective form of actual is actually
The adjective form of significant is significantly
The adjective form of physical is physically
The adjective form of strong is strongly
The adjective form of important is
2024-07-29 22:41:24 root INFO     [order_1_approx] starting weight calculation for The adjective form of important is importantly
The adjective form of rare is rarely
The adjective form of different is differently
The adjective form of strong is strongly
The adjective form of physical is physically
The adjective form of actual is actually
The adjective form of visual is visually
The adjective form of significant is
2024-07-29 22:41:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 22:43:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1919, -0.0376, -0.4805,  ..., -0.2178, -0.0880, -0.3367],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8164, -0.0796, -0.8530,  ..., -4.6953, -0.2095, -3.4727],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0745, -0.0137,  0.0291,  ..., -0.0111,  0.0003,  0.0067],
        [ 0.0109,  0.0409,  0.0170,  ...,  0.0305, -0.0035,  0.0104],
        [ 0.0039, -0.0026,  0.0511,  ..., -0.0026,  0.0057,  0.0010],
        ...,
        [-0.0136,  0.0064,  0.0089,  ...,  0.0745,  0.0164,  0.0065],
        [-0.0252,  0.0126, -0.0017,  ..., -0.0135,  0.0433, -0.0118],
        [ 0.0154,  0.0090, -0.0076,  ...,  0.0027, -0.0306,  0.0302]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8408, -0.2832, -0.5264,  ..., -4.4297,  0.0679, -3.1719]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 22:43:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of important is importantly
The adjective form of rare is rarely
The adjective form of different is differently
The adjective form of strong is strongly
The adjective form of physical is physically
The adjective form of actual is actually
The adjective form of visual is visually
The adjective form of significant is
2024-07-29 22:43:37 root INFO     [order_1_approx] starting weight calculation for The adjective form of rare is rarely
The adjective form of actual is actually
The adjective form of strong is strongly
The adjective form of physical is physically
The adjective form of significant is significantly
The adjective form of important is importantly
The adjective form of visual is visually
The adjective form of different is
2024-07-29 22:43:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 22:45:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1501, -0.4836, -0.0886,  ..., -0.0833, -0.1360, -0.1261],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6016, -1.7207,  2.4785,  ..., -2.2969, -0.3657, -2.4688],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1002,  0.0070,  0.0050,  ...,  0.0202,  0.0319,  0.0421],
        [ 0.0091,  0.0543,  0.0166,  ...,  0.0599,  0.0054,  0.0180],
        [ 0.0096,  0.0176,  0.0544,  ..., -0.0049,  0.0139,  0.0093],
        ...,
        [ 0.0130,  0.0076, -0.0133,  ...,  0.0713,  0.0168,  0.0019],
        [-0.0075,  0.0129, -0.0065,  ..., -0.0255,  0.0532, -0.0038],
        [ 0.0186,  0.0115,  0.0077,  ..., -0.0172, -0.0302,  0.0607]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5410, -1.7266,  2.1562,  ..., -2.5391,  0.0452, -2.6602]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 22:45:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of rare is rarely
The adjective form of actual is actually
The adjective form of strong is strongly
The adjective form of physical is physically
The adjective form of significant is significantly
The adjective form of important is importantly
The adjective form of visual is visually
The adjective form of different is
2024-07-29 22:45:49 root INFO     [order_1_approx] starting weight calculation for The adjective form of physical is physically
The adjective form of significant is significantly
The adjective form of actual is actually
The adjective form of visual is visually
The adjective form of important is importantly
The adjective form of strong is strongly
The adjective form of different is differently
The adjective form of rare is
2024-07-29 22:45:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 22:48:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2043, -0.3948, -0.4253,  ..., -0.2463,  0.1788, -0.2581],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.8984, -3.6680, -0.5742,  ..., -4.3008, -3.0332, -4.2969],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0838, -0.0175,  0.0316,  ...,  0.0130,  0.0072,  0.0040],
        [ 0.0199,  0.0645,  0.0322,  ...,  0.0462,  0.0133,  0.0178],
        [ 0.0144, -0.0129,  0.0442,  ..., -0.0243,  0.0047,  0.0095],
        ...,
        [ 0.0123,  0.0377, -0.0030,  ...,  0.0806,  0.0103,  0.0103],
        [-0.0136,  0.0260,  0.0221,  ..., -0.0040,  0.0567,  0.0089],
        [ 0.0165,  0.0037, -0.0180,  ...,  0.0051, -0.0225,  0.0538]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.5840, -3.9297, -0.4714,  ..., -4.3516, -3.3164, -4.1719]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 22:48:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of physical is physically
The adjective form of significant is significantly
The adjective form of actual is actually
The adjective form of visual is visually
The adjective form of important is importantly
The adjective form of strong is strongly
The adjective form of different is differently
The adjective form of rare is
2024-07-29 22:48:03 root INFO     [order_1_approx] starting weight calculation for The adjective form of strong is strongly
The adjective form of rare is rarely
The adjective form of physical is physically
The adjective form of different is differently
The adjective form of important is importantly
The adjective form of visual is visually
The adjective form of significant is significantly
The adjective form of actual is
2024-07-29 22:48:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 22:50:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4851, -0.3145, -0.3584,  ..., -0.6147, -0.1707, -0.1216],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9287, -3.2070,  1.2100,  ..., -0.0615, -1.8945, -1.7314],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1034, -0.0383,  0.0176,  ...,  0.0061,  0.0194,  0.0518],
        [ 0.0002,  0.0751,  0.0054,  ...,  0.0432,  0.0033, -0.0053],
        [-0.0051, -0.0193,  0.0803,  ...,  0.0065, -0.0107, -0.0265],
        ...,
        [ 0.0085,  0.0497, -0.0252,  ...,  0.0754, -0.0115,  0.0064],
        [-0.0109,  0.0304,  0.0241,  ..., -0.0100,  0.0483, -0.0075],
        [ 0.0191, -0.0110, -0.0087,  ..., -0.0083, -0.0468,  0.0621]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4824, -3.0117,  1.1865,  ...,  0.1677, -1.6875, -2.0215]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 22:50:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of strong is strongly
The adjective form of rare is rarely
The adjective form of physical is physically
The adjective form of different is differently
The adjective form of important is importantly
The adjective form of visual is visually
The adjective form of significant is significantly
The adjective form of actual is
2024-07-29 22:50:17 root INFO     total operator prediction time: 1067.6101424694061 seconds
2024-07-29 22:50:17 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on over+adj_reg
2024-07-29 22:50:17 root INFO     building operator over+adj_reg
2024-07-29 22:50:18 root INFO     [order_1_approx] starting weight calculation for If something is too subscribed, it is oversubscribed
If something is too paid, it is overpaid
If something is too charged, it is overcharged
If something is too strained, it is overstrained
If something is too spent, it is overspent
If something is too shadowed, it is overshadowed
If something is too grown, it is overgrown
If something is too stocked, it is
2024-07-29 22:50:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 22:52:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2067, -0.2749, -0.8096,  ..., -0.1315, -0.0962,  0.2100],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4199, -2.8555,  0.1450,  ..., -0.4644, -1.1035, -2.1289],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0574, -0.0124,  0.0042,  ..., -0.0042,  0.0033,  0.0043],
        [-0.0009,  0.0586,  0.0018,  ...,  0.0041,  0.0131, -0.0006],
        [-0.0040,  0.0096,  0.0331,  ...,  0.0043, -0.0021, -0.0037],
        ...,
        [-0.0105, -0.0119, -0.0006,  ...,  0.0644,  0.0134, -0.0026],
        [-0.0131,  0.0051, -0.0033,  ..., -0.0010,  0.0620, -0.0257],
        [ 0.0017, -0.0072, -0.0061,  ..., -0.0137, -0.0118,  0.0548]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5244, -2.8027,  0.1802,  ..., -0.4368, -0.7246, -1.9590]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 22:52:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too subscribed, it is oversubscribed
If something is too paid, it is overpaid
If something is too charged, it is overcharged
If something is too strained, it is overstrained
If something is too spent, it is overspent
If something is too shadowed, it is overshadowed
If something is too grown, it is overgrown
If something is too stocked, it is
2024-07-29 22:52:30 root INFO     [order_1_approx] starting weight calculation for If something is too spent, it is overspent
If something is too charged, it is overcharged
If something is too grown, it is overgrown
If something is too strained, it is overstrained
If something is too stocked, it is overstocked
If something is too paid, it is overpaid
If something is too shadowed, it is overshadowed
If something is too subscribed, it is
2024-07-29 22:52:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 22:54:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1705, -0.2686, -0.4988,  ..., -0.2412, -0.0817,  0.0060],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4111, -3.3125,  0.7627,  ..., -0.2666, -1.5547, -2.0410],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0568, -0.0153,  0.0045,  ..., -0.0051,  0.0023, -0.0020],
        [-0.0008,  0.0523,  0.0068,  ...,  0.0041,  0.0034, -0.0062],
        [-0.0003,  0.0025,  0.0421,  ..., -0.0090, -0.0012,  0.0012],
        ...,
        [ 0.0003,  0.0090, -0.0111,  ...,  0.0616,  0.0088, -0.0031],
        [-0.0047,  0.0051,  0.0020,  ...,  0.0017,  0.0590, -0.0163],
        [-0.0018,  0.0058, -0.0112,  ..., -0.0157, -0.0157,  0.0544]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3408, -3.2773,  1.0264,  ...,  0.0598, -1.5273, -2.0039]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 22:54:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too spent, it is overspent
If something is too charged, it is overcharged
If something is too grown, it is overgrown
If something is too strained, it is overstrained
If something is too stocked, it is overstocked
If something is too paid, it is overpaid
If something is too shadowed, it is overshadowed
If something is too subscribed, it is
2024-07-29 22:54:43 root INFO     [order_1_approx] starting weight calculation for If something is too charged, it is overcharged
If something is too subscribed, it is oversubscribed
If something is too grown, it is overgrown
If something is too stocked, it is overstocked
If something is too shadowed, it is overshadowed
If something is too strained, it is overstrained
If something is too paid, it is overpaid
If something is too spent, it is
2024-07-29 22:54:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 22:56:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0253, -0.1036, -0.1750,  ..., -0.4893, -0.0823,  0.0116],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2988, -3.9336, -1.0527,  ..., -1.3320, -1.2529, -2.9648],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0674, -0.0031,  0.0154,  ..., -0.0042,  0.0120,  0.0158],
        [-0.0053,  0.0403, -0.0163,  ...,  0.0229,  0.0101, -0.0027],
        [ 0.0240,  0.0045,  0.0508,  ..., -0.0144, -0.0102, -0.0074],
        ...,
        [ 0.0024,  0.0173, -0.0150,  ...,  0.0800,  0.0110,  0.0036],
        [-0.0078,  0.0006,  0.0024,  ...,  0.0197,  0.0584, -0.0222],
        [-0.0094,  0.0190, -0.0032,  ..., -0.0015, -0.0019,  0.0753]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7051, -4.0000, -1.0352,  ..., -0.8467, -0.7412, -3.0820]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 22:56:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too charged, it is overcharged
If something is too subscribed, it is oversubscribed
If something is too grown, it is overgrown
If something is too stocked, it is overstocked
If something is too shadowed, it is overshadowed
If something is too strained, it is overstrained
If something is too paid, it is overpaid
If something is too spent, it is
2024-07-29 22:56:54 root INFO     [order_1_approx] starting weight calculation for If something is too strained, it is overstrained
If something is too grown, it is overgrown
If something is too subscribed, it is oversubscribed
If something is too charged, it is overcharged
If something is too paid, it is overpaid
If something is too spent, it is overspent
If something is too stocked, it is overstocked
If something is too shadowed, it is
2024-07-29 22:56:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 22:59:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2532, -0.4639, -0.5732,  ..., -0.1132, -0.1870, -0.1210],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1211, -3.1621,  1.9932,  ...,  0.6240, -0.7178, -1.8438],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0426, -0.0102, -0.0017,  ...,  0.0017, -0.0089,  0.0132],
        [ 0.0013,  0.0459,  0.0086,  ...,  0.0048,  0.0011, -0.0012],
        [ 0.0099,  0.0097,  0.0399,  ...,  0.0049,  0.0013, -0.0009],
        ...,
        [ 0.0060,  0.0167,  0.0102,  ...,  0.0470,  0.0022,  0.0089],
        [ 0.0028, -0.0091, -0.0033,  ...,  0.0061,  0.0465, -0.0204],
        [-0.0023, -0.0032, -0.0040,  ..., -0.0159, -0.0165,  0.0496]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3213, -3.3262,  2.0195,  ...,  0.7427, -0.6616, -1.7256]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 22:59:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too strained, it is overstrained
If something is too grown, it is overgrown
If something is too subscribed, it is oversubscribed
If something is too charged, it is overcharged
If something is too paid, it is overpaid
If something is too spent, it is overspent
If something is too stocked, it is overstocked
If something is too shadowed, it is
2024-07-29 22:59:02 root INFO     [order_1_approx] starting weight calculation for If something is too strained, it is overstrained
If something is too shadowed, it is overshadowed
If something is too stocked, it is overstocked
If something is too grown, it is overgrown
If something is too subscribed, it is oversubscribed
If something is too spent, it is overspent
If something is too charged, it is overcharged
If something is too paid, it is
2024-07-29 22:59:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 23:01:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2625, -0.4678, -0.4092,  ..., -0.1550, -0.1300, -0.1326],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5000, -4.2891, -0.3784,  ..., -1.1436, -1.9521, -2.8984],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0690, -0.0313,  0.0222,  ..., -0.0110,  0.0042,  0.0229],
        [-0.0060,  0.0290,  0.0003,  ...,  0.0216,  0.0052, -0.0111],
        [ 0.0211,  0.0046,  0.0457,  ...,  0.0024,  0.0137, -0.0007],
        ...,
        [ 0.0044,  0.0044, -0.0205,  ...,  0.0626,  0.0295,  0.0032],
        [-0.0096, -0.0181,  0.0004,  ...,  0.0045,  0.0803, -0.0518],
        [-0.0090,  0.0024, -0.0079,  ..., -0.0062, -0.0105,  0.0745]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5977, -3.9316, -0.2974,  ..., -0.7188, -1.5938, -3.0449]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 23:01:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too strained, it is overstrained
If something is too shadowed, it is overshadowed
If something is too stocked, it is overstocked
If something is too grown, it is overgrown
If something is too subscribed, it is oversubscribed
If something is too spent, it is overspent
If something is too charged, it is overcharged
If something is too paid, it is
2024-07-29 23:01:14 root INFO     [order_1_approx] starting weight calculation for If something is too spent, it is overspent
If something is too grown, it is overgrown
If something is too paid, it is overpaid
If something is too subscribed, it is oversubscribed
If something is too strained, it is overstrained
If something is too shadowed, it is overshadowed
If something is too stocked, it is overstocked
If something is too charged, it is
2024-07-29 23:01:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 23:03:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1960, -0.4365, -0.6665,  ..., -0.1196, -0.1620,  0.1278],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1802, -3.3047,  0.0195,  ...,  0.0984,  0.2170, -2.2656],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0692, -0.0186,  0.0043,  ...,  0.0034, -0.0037,  0.0152],
        [ 0.0085,  0.0651, -0.0011,  ...,  0.0028,  0.0166, -0.0063],
        [ 0.0296,  0.0046,  0.0561,  ...,  0.0098,  0.0140,  0.0109],
        ...,
        [-0.0070, -0.0065, -0.0271,  ...,  0.0743,  0.0232,  0.0007],
        [ 0.0048,  0.0061,  0.0098,  ...,  0.0197,  0.0748, -0.0341],
        [-0.0153,  0.0252, -0.0244,  ..., -0.0033,  0.0005,  0.0601]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8433, -3.1191, -0.3049,  ...,  0.2842,  0.0774, -2.4902]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 23:03:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too spent, it is overspent
If something is too grown, it is overgrown
If something is too paid, it is overpaid
If something is too subscribed, it is oversubscribed
If something is too strained, it is overstrained
If something is too shadowed, it is overshadowed
If something is too stocked, it is overstocked
If something is too charged, it is
2024-07-29 23:03:27 root INFO     [order_1_approx] starting weight calculation for If something is too charged, it is overcharged
If something is too grown, it is overgrown
If something is too stocked, it is overstocked
If something is too paid, it is overpaid
If something is too shadowed, it is overshadowed
If something is too spent, it is overspent
If something is too subscribed, it is oversubscribed
If something is too strained, it is
2024-07-29 23:03:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 23:05:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3108, -0.6992, -0.3604,  ..., -0.3733, -0.0429,  0.3884],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7236, -4.0625,  0.6318,  ...,  0.0337,  1.3027, -2.8965],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0508,  0.0029,  0.0026,  ..., -0.0037,  0.0124,  0.0116],
        [ 0.0041,  0.0604, -0.0093,  ...,  0.0027,  0.0044, -0.0169],
        [ 0.0246,  0.0039,  0.0617,  ...,  0.0025,  0.0090,  0.0006],
        ...,
        [ 0.0059,  0.0087, -0.0066,  ...,  0.0790,  0.0086,  0.0046],
        [-0.0068,  0.0039,  0.0021,  ...,  0.0045,  0.0676, -0.0186],
        [-0.0184,  0.0081, -0.0081,  ..., -0.0135, -0.0214,  0.0643]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0117, -4.1562,  0.5132,  ...,  0.5513,  1.0225, -2.5547]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 23:05:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too charged, it is overcharged
If something is too grown, it is overgrown
If something is too stocked, it is overstocked
If something is too paid, it is overpaid
If something is too shadowed, it is overshadowed
If something is too spent, it is overspent
If something is too subscribed, it is oversubscribed
If something is too strained, it is
2024-07-29 23:05:34 root INFO     [order_1_approx] starting weight calculation for If something is too shadowed, it is overshadowed
If something is too subscribed, it is oversubscribed
If something is too charged, it is overcharged
If something is too strained, it is overstrained
If something is too paid, it is overpaid
If something is too stocked, it is overstocked
If something is too spent, it is overspent
If something is too grown, it is
2024-07-29 23:05:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 23:07:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3638, -0.2347, -0.6313,  ..., -0.5938, -0.3557, -0.1377],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2588, -4.2656,  1.0928,  ..., -0.0579, -0.7705, -2.1074],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0599,  0.0101,  0.0080,  ..., -0.0070,  0.0035,  0.0167],
        [ 0.0075,  0.0370,  0.0002,  ...,  0.0127, -0.0034, -0.0009],
        [ 0.0134, -0.0043,  0.0570,  ..., -0.0228,  0.0058,  0.0052],
        ...,
        [-0.0137, -0.0050, -0.0047,  ...,  0.0944,  0.0128,  0.0108],
        [-0.0028,  0.0178, -0.0060,  ...,  0.0102,  0.0520, -0.0320],
        [-0.0072,  0.0056,  0.0003,  ..., -0.0052, -0.0261,  0.0689]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4258, -4.4102,  1.2148,  ...,  0.2991, -0.9487, -2.3438]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 23:07:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too shadowed, it is overshadowed
If something is too subscribed, it is oversubscribed
If something is too charged, it is overcharged
If something is too strained, it is overstrained
If something is too paid, it is overpaid
If something is too stocked, it is overstocked
If something is too spent, it is overspent
If something is too grown, it is
2024-07-29 23:07:46 root INFO     total operator prediction time: 1048.7875788211823 seconds
2024-07-29 23:07:46 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+er_irreg
2024-07-29 23:07:46 root INFO     building operator verb+er_irreg
2024-07-29 23:07:46 root INFO     [order_1_approx] starting weight calculation for If you intrude something, you are a intruder
If you write something, you are a writer
If you discover something, you are a discoverer
If you subscribe something, you are a subscriber
If you consume something, you are a consumer
If you begin something, you are a beginner
If you entertain something, you are a entertainer
If you listen something, you are a
2024-07-29 23:07:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 23:09:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4521, -0.2979,  0.1986,  ...,  0.1575,  0.0756, -0.0490],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6299, -2.1113,  1.2402,  ...,  0.3652, -2.9238, -4.2266],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0463,  0.0094, -0.0026,  ...,  0.0235,  0.0031,  0.0145],
        [-0.0107,  0.0446, -0.0028,  ...,  0.0217,  0.0071, -0.0071],
        [-0.0035, -0.0047,  0.0649,  ..., -0.0096, -0.0053, -0.0046],
        ...,
        [ 0.0193,  0.0062,  0.0011,  ...,  0.0599,  0.0093,  0.0042],
        [ 0.0083, -0.0083,  0.0032,  ..., -0.0161,  0.0242, -0.0094],
        [ 0.0095, -0.0107,  0.0060,  ...,  0.0007,  0.0164,  0.0348]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7285, -2.0742,  1.4219,  ...,  0.4463, -3.0840, -4.2070]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 23:09:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you intrude something, you are a intruder
If you write something, you are a writer
If you discover something, you are a discoverer
If you subscribe something, you are a subscriber
If you consume something, you are a consumer
If you begin something, you are a beginner
If you entertain something, you are a entertainer
If you listen something, you are a
2024-07-29 23:09:59 root INFO     [order_1_approx] starting weight calculation for If you begin something, you are a beginner
If you subscribe something, you are a subscriber
If you discover something, you are a discoverer
If you listen something, you are a listener
If you intrude something, you are a intruder
If you entertain something, you are a entertainer
If you write something, you are a writer
If you consume something, you are a
2024-07-29 23:09:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 23:12:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3330, -0.3411, -0.2186,  ...,  0.1523, -0.0679, -0.0858],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1445,  0.7695,  1.6758,  ..., -1.6377, -3.0078, -1.5957],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0485,  0.0192,  0.0236,  ...,  0.0299, -0.0043,  0.0070],
        [-0.0028,  0.0465, -0.0050,  ...,  0.0203,  0.0113, -0.0241],
        [ 0.0182, -0.0057,  0.0367,  ..., -0.0143,  0.0123, -0.0053],
        ...,
        [ 0.0153,  0.0005,  0.0168,  ...,  0.0604, -0.0077, -0.0185],
        [-0.0051,  0.0168, -0.0117,  ..., -0.0186,  0.0476, -0.0150],
        [-0.0004,  0.0028,  0.0069,  ..., -0.0172, -0.0178,  0.0428]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1504,  0.4492,  1.6846,  ..., -1.3535, -2.9785, -1.8652]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 23:12:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you begin something, you are a beginner
If you subscribe something, you are a subscriber
If you discover something, you are a discoverer
If you listen something, you are a listener
If you intrude something, you are a intruder
If you entertain something, you are a entertainer
If you write something, you are a writer
If you consume something, you are a
2024-07-29 23:12:11 root INFO     [order_1_approx] starting weight calculation for If you subscribe something, you are a subscriber
If you begin something, you are a beginner
If you entertain something, you are a entertainer
If you consume something, you are a consumer
If you listen something, you are a listener
If you discover something, you are a discoverer
If you intrude something, you are a intruder
If you write something, you are a
2024-07-29 23:12:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 23:14:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.6250, -0.1298,  0.5273,  ..., -0.5674,  0.1451, -0.1018],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7637, -3.7637,  0.6943,  ..., -0.0312, -4.4102, -0.9697],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0533,  0.0077,  0.0026,  ...,  0.0079, -0.0070,  0.0045],
        [-0.0077,  0.0306,  0.0031,  ...,  0.0165,  0.0034, -0.0129],
        [ 0.0179,  0.0030,  0.0529,  ..., -0.0052, -0.0050,  0.0093],
        ...,
        [ 0.0157,  0.0088,  0.0052,  ...,  0.0434,  0.0100, -0.0235],
        [ 0.0095,  0.0236, -0.0073,  ..., -0.0098,  0.0340,  0.0030],
        [ 0.0086,  0.0113, -0.0027,  ..., -0.0179,  0.0009,  0.0338]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8408, -3.9824,  0.6045,  ...,  0.4436, -4.2969, -1.0068]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 23:14:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you subscribe something, you are a subscriber
If you begin something, you are a beginner
If you entertain something, you are a entertainer
If you consume something, you are a consumer
If you listen something, you are a listener
If you discover something, you are a discoverer
If you intrude something, you are a intruder
If you write something, you are a
2024-07-29 23:14:23 root INFO     [order_1_approx] starting weight calculation for If you consume something, you are a consumer
If you write something, you are a writer
If you intrude something, you are a intruder
If you listen something, you are a listener
If you discover something, you are a discoverer
If you begin something, you are a beginner
If you entertain something, you are a entertainer
If you subscribe something, you are a
2024-07-29 23:14:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 23:16:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0542,  0.0605, -0.1387,  ...,  0.2654, -0.1562,  0.0973],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7520, -1.0039,  1.5107,  ...,  0.9004, -1.0801, -4.1602],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0705, -0.0068,  0.0138,  ...,  0.0071,  0.0033,  0.0080],
        [-0.0040,  0.0458,  0.0139,  ...,  0.0322, -0.0076, -0.0166],
        [ 0.0096, -0.0056,  0.0507,  ..., -0.0093, -0.0091,  0.0004],
        ...,
        [ 0.0121,  0.0137, -0.0067,  ...,  0.0612,  0.0031, -0.0031],
        [-0.0051,  0.0142,  0.0102,  ..., -0.0102,  0.0364, -0.0271],
        [ 0.0019, -0.0177, -0.0033,  ..., -0.0096, -0.0054,  0.0439]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5693, -1.0176,  1.6602,  ...,  0.8677, -1.2266, -4.2305]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 23:16:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you consume something, you are a consumer
If you write something, you are a writer
If you intrude something, you are a intruder
If you listen something, you are a listener
If you discover something, you are a discoverer
If you begin something, you are a beginner
If you entertain something, you are a entertainer
If you subscribe something, you are a
2024-07-29 23:16:34 root INFO     [order_1_approx] starting weight calculation for If you consume something, you are a consumer
If you discover something, you are a discoverer
If you intrude something, you are a intruder
If you begin something, you are a beginner
If you listen something, you are a listener
If you subscribe something, you are a subscriber
If you write something, you are a writer
If you entertain something, you are a
2024-07-29 23:16:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 23:18:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1167,  0.0977,  0.0016,  ...,  0.0897, -0.3989, -0.0951],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7998, -2.0938,  0.2354,  ..., -0.3135, -2.1230, -4.9102],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0701,  0.0139,  0.0226,  ...,  0.0043,  0.0002, -0.0092],
        [-0.0118,  0.0438, -0.0142,  ...,  0.0088,  0.0120, -0.0084],
        [ 0.0073,  0.0040,  0.0529,  ..., -0.0039, -0.0091, -0.0025],
        ...,
        [ 0.0142,  0.0114, -0.0016,  ...,  0.0557,  0.0058,  0.0002],
        [ 0.0124,  0.0272,  0.0093,  ..., -0.0181,  0.0153, -0.0073],
        [ 0.0110,  0.0055,  0.0075,  ...,  0.0033, -0.0185,  0.0573]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9395, -2.3730,  0.4688,  ...,  0.1165, -2.1836, -4.9648]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 23:18:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you consume something, you are a consumer
If you discover something, you are a discoverer
If you intrude something, you are a intruder
If you begin something, you are a beginner
If you listen something, you are a listener
If you subscribe something, you are a subscriber
If you write something, you are a writer
If you entertain something, you are a
2024-07-29 23:18:46 root INFO     [order_1_approx] starting weight calculation for If you write something, you are a writer
If you listen something, you are a listener
If you entertain something, you are a entertainer
If you begin something, you are a beginner
If you consume something, you are a consumer
If you subscribe something, you are a subscriber
If you intrude something, you are a intruder
If you discover something, you are a
2024-07-29 23:18:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 23:20:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1267,  0.1440,  0.0543,  ..., -0.0483, -0.1321, -0.3123],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4941, -2.4609,  3.2227,  ..., -1.1289, -4.6953, -1.0557],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0659,  0.0132,  0.0087,  ...,  0.0116,  0.0049,  0.0018],
        [ 0.0046,  0.0543, -0.0032,  ...,  0.0249, -0.0128, -0.0091],
        [ 0.0013,  0.0053,  0.0329,  ..., -0.0275,  0.0021, -0.0216],
        ...,
        [ 0.0082,  0.0181,  0.0087,  ...,  0.0564,  0.0081, -0.0103],
        [ 0.0004,  0.0191, -0.0081,  ..., -0.0135,  0.0450, -0.0109],
        [ 0.0214, -0.0089,  0.0213,  ..., -0.0179, -0.0366,  0.0383]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7480, -2.5566,  2.9961,  ..., -0.9375, -4.4102, -1.6094]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 23:20:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you write something, you are a writer
If you listen something, you are a listener
If you entertain something, you are a entertainer
If you begin something, you are a beginner
If you consume something, you are a consumer
If you subscribe something, you are a subscriber
If you intrude something, you are a intruder
If you discover something, you are a
2024-07-29 23:20:58 root INFO     [order_1_approx] starting weight calculation for If you intrude something, you are a intruder
If you write something, you are a writer
If you listen something, you are a listener
If you discover something, you are a discoverer
If you entertain something, you are a entertainer
If you subscribe something, you are a subscriber
If you consume something, you are a consumer
If you begin something, you are a
2024-07-29 23:20:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 23:23:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2045,  0.0062, -0.2262,  ...,  0.2532, -0.5142, -0.3940],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5273, -1.8828,  1.1621,  ...,  3.6172, -3.2734, -3.2168],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0482,  0.0078,  0.0139,  ...,  0.0245,  0.0036,  0.0010],
        [ 0.0040,  0.0434,  0.0126,  ...,  0.0278,  0.0062, -0.0177],
        [ 0.0023, -0.0023,  0.0298,  ...,  0.0012, -0.0001,  0.0032],
        ...,
        [ 0.0224,  0.0026,  0.0081,  ...,  0.0410,  0.0088, -0.0066],
        [ 0.0062,  0.0252, -0.0040,  ..., -0.0030,  0.0486, -0.0214],
        [ 0.0081, -0.0007, -0.0011,  ..., -0.0197, -0.0118,  0.0381]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2070, -1.7627,  1.1016,  ...,  3.7148, -2.9414, -3.2715]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 23:23:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you intrude something, you are a intruder
If you write something, you are a writer
If you listen something, you are a listener
If you discover something, you are a discoverer
If you entertain something, you are a entertainer
If you subscribe something, you are a subscriber
If you consume something, you are a consumer
If you begin something, you are a
2024-07-29 23:23:10 root INFO     [order_1_approx] starting weight calculation for If you listen something, you are a listener
If you begin something, you are a beginner
If you subscribe something, you are a subscriber
If you write something, you are a writer
If you consume something, you are a consumer
If you discover something, you are a discoverer
If you entertain something, you are a entertainer
If you intrude something, you are a
2024-07-29 23:23:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 23:25:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0176,  0.0335,  0.1754,  ...,  0.0256,  0.2113,  0.1350],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.1992, -1.4551, -0.2842,  ..., -0.9463, -4.0586, -1.6631],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.3293e-02,  1.1398e-02,  2.6016e-02,  ...,  1.2947e-02,
         -4.8523e-03,  1.4565e-02],
        [-6.3515e-03,  4.7180e-02,  1.7792e-02,  ...,  2.0187e-02,
          4.6883e-03, -1.2634e-02],
        [ 5.2338e-03,  2.9182e-03,  3.7903e-02,  ..., -8.0414e-03,
          9.4833e-03, -8.7166e-04],
        ...,
        [-1.9073e-05,  1.6296e-02,  5.5847e-03,  ...,  7.0984e-02,
          1.8311e-02,  3.3321e-03],
        [-1.8509e-02,  8.6975e-04,  2.1973e-02,  ..., -4.1718e-02,
          5.8472e-02, -1.8585e-02],
        [ 2.2308e-02,  6.5689e-03,  6.4735e-03,  ..., -9.5520e-03,
         -2.9404e-02,  6.3293e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.0234, -1.4785, -0.2788,  ..., -0.4399, -4.3750, -1.6709]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 23:25:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you listen something, you are a listener
If you begin something, you are a beginner
If you subscribe something, you are a subscriber
If you write something, you are a writer
If you consume something, you are a consumer
If you discover something, you are a discoverer
If you entertain something, you are a entertainer
If you intrude something, you are a
2024-07-29 23:25:21 root INFO     total operator prediction time: 1054.473551750183 seconds
2024-07-29 23:25:21 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj - superlative
2024-07-29 23:25:21 root INFO     building operator adj - superlative
2024-07-29 23:25:21 root INFO     [order_1_approx] starting weight calculation for If something is the most scary, it is scariest
If something is the most fierce, it is fiercest
If something is the most handy, it is handiest
If something is the most weird, it is weirdest
If something is the most tiny, it is tiniest
If something is the most lazy, it is laziest
If something is the most cute, it is cutest
If something is the most polite, it is
2024-07-29 23:25:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 23:27:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3237,  0.6523, -0.3340,  ..., -0.0524,  0.0593,  0.1886],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7939, -0.2080, -2.6797,  ..., -0.1324, -0.1807, -0.9346],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0443, -0.0232,  0.0059,  ...,  0.0085,  0.0014,  0.0226],
        [-0.0024,  0.0526, -0.0035,  ...,  0.0054,  0.0199,  0.0071],
        [ 0.0043, -0.0187,  0.0383,  ..., -0.0140, -0.0224, -0.0037],
        ...,
        [ 0.0030,  0.0363, -0.0089,  ...,  0.0732,  0.0024, -0.0109],
        [-0.0005,  0.0150,  0.0058,  ..., -0.0123,  0.0334, -0.0266],
        [ 0.0005, -0.0087,  0.0017,  ...,  0.0033, -0.0038,  0.0240]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8418, -0.2720, -2.5820,  ..., -0.4199, -0.0612, -0.6934]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 23:27:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most scary, it is scariest
If something is the most fierce, it is fiercest
If something is the most handy, it is handiest
If something is the most weird, it is weirdest
If something is the most tiny, it is tiniest
If something is the most lazy, it is laziest
If something is the most cute, it is cutest
If something is the most polite, it is
2024-07-29 23:27:34 root INFO     [order_1_approx] starting weight calculation for If something is the most weird, it is weirdest
If something is the most scary, it is scariest
If something is the most cute, it is cutest
If something is the most lazy, it is laziest
If something is the most polite, it is politest
If something is the most tiny, it is tiniest
If something is the most handy, it is handiest
If something is the most fierce, it is
2024-07-29 23:27:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 23:29:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2886,  0.1675, -0.2179,  ..., -0.2480, -0.1564,  0.4751],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.1260, -4.0547, -1.8623,  ..., -1.9023, -3.0664, -0.2559],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0316, -0.0124,  0.0295,  ..., -0.0070, -0.0077,  0.0105],
        [ 0.0014,  0.0345,  0.0133,  ...,  0.0100,  0.0178, -0.0040],
        [ 0.0065, -0.0079,  0.0280,  ..., -0.0137, -0.0130, -0.0014],
        ...,
        [ 0.0094,  0.0264,  0.0069,  ...,  0.0412,  0.0150, -0.0022],
        [ 0.0034, -0.0034, -0.0064,  ..., -0.0102,  0.0321, -0.0169],
        [-0.0015, -0.0109,  0.0021,  ..., -0.0050, -0.0032,  0.0100]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1123, -4.2695, -1.4590,  ..., -1.7734, -2.9785,  0.0979]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 23:29:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most weird, it is weirdest
If something is the most scary, it is scariest
If something is the most cute, it is cutest
If something is the most lazy, it is laziest
If something is the most polite, it is politest
If something is the most tiny, it is tiniest
If something is the most handy, it is handiest
If something is the most fierce, it is
2024-07-29 23:29:46 root INFO     [order_1_approx] starting weight calculation for If something is the most cute, it is cutest
If something is the most lazy, it is laziest
If something is the most tiny, it is tiniest
If something is the most weird, it is weirdest
If something is the most handy, it is handiest
If something is the most polite, it is politest
If something is the most fierce, it is fiercest
If something is the most scary, it is
2024-07-29 23:29:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 23:31:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2194,  0.0389, -0.4053,  ..., -0.1807, -0.4058,  0.0156],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.1133, -3.5371, -1.9023,  ..., -2.3887, -0.4541, -1.4629],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0550, -0.0045,  0.0241,  ...,  0.0144, -0.0028,  0.0101],
        [ 0.0173,  0.0233,  0.0113,  ...,  0.0009,  0.0120, -0.0112],
        [ 0.0049, -0.0019,  0.0137,  ..., -0.0055, -0.0054, -0.0031],
        ...,
        [ 0.0086,  0.0313, -0.0031,  ...,  0.0353,  0.0054,  0.0124],
        [-0.0094, -0.0058,  0.0052,  ..., -0.0075,  0.0242, -0.0171],
        [ 0.0148,  0.0048,  0.0117,  ..., -0.0033, -0.0149,  0.0184]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.2207, -3.6875, -1.8574,  ..., -2.3379, -0.2661, -1.4365]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 23:31:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most cute, it is cutest
If something is the most lazy, it is laziest
If something is the most tiny, it is tiniest
If something is the most weird, it is weirdest
If something is the most handy, it is handiest
If something is the most polite, it is politest
If something is the most fierce, it is fiercest
If something is the most scary, it is
2024-07-29 23:31:59 root INFO     [order_1_approx] starting weight calculation for If something is the most lazy, it is laziest
If something is the most polite, it is politest
If something is the most scary, it is scariest
If something is the most tiny, it is tiniest
If something is the most fierce, it is fiercest
If something is the most handy, it is handiest
If something is the most cute, it is cutest
If something is the most weird, it is
2024-07-29 23:31:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 23:34:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1947, -0.0064,  0.5293,  ..., -0.2830, -0.1246,  0.4136],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5889, -4.8398, -1.2305,  ..., -1.7607,  0.2129, -2.5117],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0464, -0.0056,  0.0055,  ...,  0.0024,  0.0050,  0.0102],
        [ 0.0066,  0.0306, -0.0041,  ...,  0.0121,  0.0049,  0.0046],
        [ 0.0011, -0.0070,  0.0367,  ...,  0.0064, -0.0049,  0.0090],
        ...,
        [ 0.0188,  0.0339, -0.0101,  ...,  0.0520, -0.0065,  0.0025],
        [ 0.0029,  0.0024,  0.0069,  ..., -0.0062,  0.0239, -0.0202],
        [ 0.0061, -0.0081,  0.0085,  ..., -0.0042, -0.0110,  0.0195]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0366, -4.9414, -1.8008,  ..., -1.8789,  0.1078, -2.3340]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 23:34:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most lazy, it is laziest
If something is the most polite, it is politest
If something is the most scary, it is scariest
If something is the most tiny, it is tiniest
If something is the most fierce, it is fiercest
If something is the most handy, it is handiest
If something is the most cute, it is cutest
If something is the most weird, it is
2024-07-29 23:34:11 root INFO     [order_1_approx] starting weight calculation for If something is the most polite, it is politest
If something is the most cute, it is cutest
If something is the most lazy, it is laziest
If something is the most weird, it is weirdest
If something is the most handy, it is handiest
If something is the most scary, it is scariest
If something is the most fierce, it is fiercest
If something is the most tiny, it is
2024-07-29 23:34:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 23:36:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1083, -0.4634, -0.6694,  ..., -0.2900,  0.1219, -0.2266],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.9883,  0.4517, -1.0918,  ..., -3.8770, -2.4570, -0.9780],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0608, -0.0135, -0.0083,  ..., -0.0183,  0.0061,  0.0041],
        [ 0.0135,  0.0557,  0.0233,  ...,  0.0266,  0.0028,  0.0017],
        [ 0.0067, -0.0038,  0.0376,  ..., -0.0086, -0.0168, -0.0055],
        ...,
        [-0.0014,  0.0281,  0.0069,  ...,  0.0696,  0.0058, -0.0044],
        [ 0.0058, -0.0008, -0.0007,  ...,  0.0027,  0.0341, -0.0076],
        [ 0.0004, -0.0007,  0.0132,  ..., -0.0092, -0.0137,  0.0482]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.2422,  0.5083, -1.2217,  ..., -3.5742, -2.3535, -0.8516]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 23:36:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most polite, it is politest
If something is the most cute, it is cutest
If something is the most lazy, it is laziest
If something is the most weird, it is weirdest
If something is the most handy, it is handiest
If something is the most scary, it is scariest
If something is the most fierce, it is fiercest
If something is the most tiny, it is
2024-07-29 23:36:24 root INFO     [order_1_approx] starting weight calculation for If something is the most weird, it is weirdest
If something is the most cute, it is cutest
If something is the most scary, it is scariest
If something is the most tiny, it is tiniest
If something is the most polite, it is politest
If something is the most handy, it is handiest
If something is the most fierce, it is fiercest
If something is the most lazy, it is
2024-07-29 23:36:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 23:38:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4189,  0.0522, -0.3223,  ..., -0.6055,  0.1006,  0.4426],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.6621, -4.4102, -1.4434,  ..., -2.3535, -0.8228, -2.3535],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0530, -0.0123,  0.0135,  ...,  0.0038,  0.0088,  0.0109],
        [ 0.0026,  0.0413,  0.0137,  ..., -0.0030,  0.0139,  0.0075],
        [ 0.0033, -0.0209,  0.0408,  ..., -0.0051, -0.0054, -0.0019],
        ...,
        [ 0.0090,  0.0255,  0.0121,  ...,  0.0453,  0.0042, -0.0170],
        [-0.0093,  0.0064, -0.0135,  ...,  0.0003,  0.0306, -0.0157],
        [ 0.0053, -0.0106,  0.0146,  ..., -0.0158, -0.0116,  0.0288]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.6953, -4.3594, -1.6973,  ..., -2.0078, -0.6396, -2.2598]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 23:38:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most weird, it is weirdest
If something is the most cute, it is cutest
If something is the most scary, it is scariest
If something is the most tiny, it is tiniest
If something is the most polite, it is politest
If something is the most handy, it is handiest
If something is the most fierce, it is fiercest
If something is the most lazy, it is
2024-07-29 23:38:37 root INFO     [order_1_approx] starting weight calculation for If something is the most polite, it is politest
If something is the most scary, it is scariest
If something is the most weird, it is weirdest
If something is the most handy, it is handiest
If something is the most fierce, it is fiercest
If something is the most tiny, it is tiniest
If something is the most lazy, it is laziest
If something is the most cute, it is
2024-07-29 23:38:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 23:40:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1062,  0.0193,  0.2445,  ..., -0.5337, -0.5479,  0.3516],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.2539, -1.3633, -1.5439,  ..., -1.4238,  0.1562,  1.6816],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0505, -0.0030,  0.0137,  ..., -0.0107, -0.0086,  0.0144],
        [ 0.0022,  0.0519, -0.0067,  ...,  0.0258,  0.0064,  0.0152],
        [ 0.0051,  0.0050,  0.0325,  ..., -0.0036, -0.0170, -0.0037],
        ...,
        [ 0.0088,  0.0157,  0.0137,  ...,  0.0659,  0.0123, -0.0013],
        [ 0.0036, -0.0028,  0.0030,  ..., -0.0320,  0.0151, -0.0074],
        [-0.0136, -0.0171, -0.0076,  ..., -0.0104, -0.0087,  0.0520]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.5156, -1.6533, -1.7510,  ..., -1.6475,  0.1466,  1.6211]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 23:40:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most polite, it is politest
If something is the most scary, it is scariest
If something is the most weird, it is weirdest
If something is the most handy, it is handiest
If something is the most fierce, it is fiercest
If something is the most tiny, it is tiniest
If something is the most lazy, it is laziest
If something is the most cute, it is
2024-07-29 23:40:46 root INFO     [order_1_approx] starting weight calculation for If something is the most scary, it is scariest
If something is the most polite, it is politest
If something is the most tiny, it is tiniest
If something is the most fierce, it is fiercest
If something is the most lazy, it is laziest
If something is the most weird, it is weirdest
If something is the most cute, it is cutest
If something is the most handy, it is
2024-07-29 23:40:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 23:42:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1055,  0.2908,  0.2700,  ..., -0.4731, -0.4624,  0.1765],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0850, -3.6777, -1.8809,  ..., -1.3008, -4.2578, -0.2246],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0423, -0.0092,  0.0169,  ...,  0.0098, -0.0110,  0.0168],
        [ 0.0026,  0.0492,  0.0131,  ...,  0.0114,  0.0127,  0.0070],
        [ 0.0040, -0.0014,  0.0398,  ...,  0.0086, -0.0098, -0.0121],
        ...,
        [ 0.0042,  0.0249, -0.0096,  ...,  0.0555,  0.0124, -0.0115],
        [ 0.0195,  0.0064,  0.0027,  ..., -0.0125,  0.0565, -0.0271],
        [ 0.0051,  0.0004, -0.0072,  ..., -0.0162, -0.0190,  0.0344]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7490, -3.3340, -1.9844,  ..., -0.7217, -3.8164,  0.0215]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 23:42:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most scary, it is scariest
If something is the most polite, it is politest
If something is the most tiny, it is tiniest
If something is the most fierce, it is fiercest
If something is the most lazy, it is laziest
If something is the most weird, it is weirdest
If something is the most cute, it is cutest
If something is the most handy, it is
2024-07-29 23:42:59 root INFO     total operator prediction time: 1058.1924195289612 seconds
2024-07-29 23:42:59 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_3pSg - Ved
2024-07-29 23:42:59 root INFO     building operator verb_3pSg - Ved
2024-07-29 23:42:59 root INFO     [order_1_approx] starting weight calculation for When he appears something, something has been appeared
When he follows something, something has been followed
When he includes something, something has been included
When he occurs something, something has been occurred
When he provides something, something has been provided
When he tells something, something has been told
When he intends something, something has been intended
When he remains something, something has been
2024-07-29 23:42:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 23:45:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0595,  0.2480,  0.1733,  ...,  0.0146, -0.2839, -0.0081],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6562,  0.7773,  1.5332,  ..., -2.2988, -0.7681, -1.2998],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0400, -0.0185,  0.0122,  ..., -0.0029, -0.0080,  0.0148],
        [-0.0194,  0.0254, -0.0077,  ...,  0.0300,  0.0193,  0.0044],
        [-0.0093,  0.0041,  0.0355,  ..., -0.0252, -0.0123, -0.0159],
        ...,
        [ 0.0100,  0.0098, -0.0118,  ...,  0.0485,  0.0046,  0.0372],
        [ 0.0296,  0.0079, -0.0093,  ..., -0.0098,  0.0609, -0.0174],
        [-0.0150,  0.0049,  0.0251,  ...,  0.0219, -0.0153,  0.0235]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6846,  1.0303,  1.7129,  ..., -1.8203, -0.7280, -0.9106]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 23:45:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he appears something, something has been appeared
When he follows something, something has been followed
When he includes something, something has been included
When he occurs something, something has been occurred
When he provides something, something has been provided
When he tells something, something has been told
When he intends something, something has been intended
When he remains something, something has been
2024-07-29 23:45:13 root INFO     [order_1_approx] starting weight calculation for When he intends something, something has been intended
When he includes something, something has been included
When he follows something, something has been followed
When he tells something, something has been told
When he occurs something, something has been occurred
When he remains something, something has been remained
When he appears something, something has been appeared
When he provides something, something has been
2024-07-29 23:45:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 23:47:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1189, -0.2451, -0.0381,  ...,  0.3662,  0.1041, -0.2646],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0801, -2.7305,  1.9658,  ..., -1.1553, -3.1016, -0.8340],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.0079e-02, -8.3160e-03,  2.8259e-02,  ..., -1.5831e-04,
         -8.5144e-03,  2.4460e-02],
        [-3.1067e-02,  3.3539e-02,  1.6785e-02,  ...,  1.1047e-02,
          1.5030e-02,  9.9640e-03],
        [ 6.6719e-03, -2.3056e-02,  2.4414e-02,  ..., -5.8937e-03,
          8.2970e-05, -7.7667e-03],
        ...,
        [-4.6730e-03, -3.3379e-03,  3.7670e-03,  ...,  4.4922e-02,
          3.1090e-03,  1.9547e-02],
        [ 2.9984e-02, -3.8795e-03, -3.5744e-03,  ..., -7.5531e-03,
          3.1921e-02, -2.6688e-02],
        [-4.1351e-03,  8.3771e-03, -2.3117e-03,  ..., -2.7740e-02,
         -5.8899e-03,  5.0598e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9805, -1.8477,  2.1855,  ..., -0.8545, -2.7871, -0.5615]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 23:47:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he intends something, something has been intended
When he includes something, something has been included
When he follows something, something has been followed
When he tells something, something has been told
When he occurs something, something has been occurred
When he remains something, something has been remained
When he appears something, something has been appeared
When he provides something, something has been
2024-07-29 23:47:26 root INFO     [order_1_approx] starting weight calculation for When he provides something, something has been provided
When he remains something, something has been remained
When he follows something, something has been followed
When he includes something, something has been included
When he tells something, something has been told
When he intends something, something has been intended
When he appears something, something has been appeared
When he occurs something, something has been
2024-07-29 23:47:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 23:49:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4624,  0.0631, -0.1854,  ..., -0.1858,  0.1895, -0.8921],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3271,  1.2871,  1.8018,  ..., -0.8877, -0.8574,  1.3262],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0221, -0.0097,  0.0279,  ...,  0.0195, -0.0032,  0.0246],
        [-0.0212,  0.0211,  0.0057,  ...,  0.0231,  0.0103, -0.0135],
        [ 0.0019, -0.0048,  0.0099,  ..., -0.0301,  0.0053, -0.0094],
        ...,
        [-0.0003,  0.0091,  0.0020,  ...,  0.0328, -0.0030,  0.0167],
        [ 0.0186,  0.0017, -0.0069,  ..., -0.0147,  0.0345, -0.0176],
        [ 0.0111,  0.0051,  0.0166,  ..., -0.0085, -0.0123,  0.0349]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6069,  1.3770,  2.1621,  ..., -0.6318, -0.7900,  1.7783]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 23:49:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he provides something, something has been provided
When he remains something, something has been remained
When he follows something, something has been followed
When he includes something, something has been included
When he tells something, something has been told
When he intends something, something has been intended
When he appears something, something has been appeared
When he occurs something, something has been
2024-07-29 23:49:39 root INFO     [order_1_approx] starting weight calculation for When he occurs something, something has been occurred
When he intends something, something has been intended
When he remains something, something has been remained
When he follows something, something has been followed
When he appears something, something has been appeared
When he includes something, something has been included
When he provides something, something has been provided
When he tells something, something has been
2024-07-29 23:49:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 23:51:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1433, -0.1054,  0.4822,  ...,  0.2952, -0.2095, -0.2163],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0469,  1.4414,  4.2969,  ...,  2.0703, -4.3555, -1.2500],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.1637e-02, -7.3242e-03, -6.7616e-04,  ..., -2.6741e-03,
         -4.8256e-03,  2.2675e-02],
        [-2.2934e-02,  2.3178e-02,  4.4823e-04,  ...,  1.8036e-02,
         -2.8648e-03, -2.4509e-04],
        [ 3.6240e-03, -2.1057e-02,  1.3786e-02,  ..., -1.0681e-02,
         -2.2392e-03, -8.7891e-03],
        ...,
        [-1.1810e-02,  1.1225e-03,  2.7180e-03,  ...,  1.2505e-02,
          9.7275e-05,  1.2054e-02],
        [ 1.3733e-04,  3.8795e-03,  2.8496e-03,  ..., -1.0004e-03,
          3.2074e-02, -1.1002e-02],
        [-1.0862e-03, -8.8196e-03,  2.1545e-02,  ..., -8.8196e-03,
          9.6893e-03,  1.9897e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8242,  1.5928,  4.2461,  ...,  1.8389, -3.9863, -1.0391]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 23:51:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he occurs something, something has been occurred
When he intends something, something has been intended
When he remains something, something has been remained
When he follows something, something has been followed
When he appears something, something has been appeared
When he includes something, something has been included
When he provides something, something has been provided
When he tells something, something has been
2024-07-29 23:51:53 root INFO     [order_1_approx] starting weight calculation for When he follows something, something has been followed
When he occurs something, something has been occurred
When he includes something, something has been included
When he remains something, something has been remained
When he provides something, something has been provided
When he tells something, something has been told
When he appears something, something has been appeared
When he intends something, something has been
2024-07-29 23:51:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 23:54:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.6436, -0.2117,  0.1300,  ...,  0.2163,  0.1600,  0.2593],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5850,  2.7344,  0.1982,  ..., -1.0469, -2.2715, -2.6328],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0189, -0.0244,  0.0155,  ...,  0.0013, -0.0090,  0.0019],
        [-0.0094,  0.0134,  0.0165,  ...,  0.0061,  0.0116, -0.0144],
        [ 0.0016,  0.0040,  0.0189,  ..., -0.0202, -0.0084, -0.0221],
        ...,
        [-0.0111, -0.0061,  0.0111,  ...,  0.0182,  0.0238,  0.0127],
        [ 0.0107,  0.0086,  0.0039,  ...,  0.0042,  0.0171, -0.0032],
        [-0.0036,  0.0210,  0.0270,  ..., -0.0021, -0.0099,  0.0050]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5459,  3.0293,  0.3296,  ..., -0.4570, -2.3633, -2.1914]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 23:54:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he follows something, something has been followed
When he occurs something, something has been occurred
When he includes something, something has been included
When he remains something, something has been remained
When he provides something, something has been provided
When he tells something, something has been told
When he appears something, something has been appeared
When he intends something, something has been
2024-07-29 23:54:06 root INFO     [order_1_approx] starting weight calculation for When he tells something, something has been told
When he occurs something, something has been occurred
When he provides something, something has been provided
When he remains something, something has been remained
When he intends something, something has been intended
When he includes something, something has been included
When he follows something, something has been followed
When he appears something, something has been
2024-07-29 23:54:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 23:56:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4221, -0.0173, -0.3159,  ...,  0.1652,  0.0934, -0.5176],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1641,  1.9062,  1.6055,  ...,  0.7432, -2.1836,  0.7109],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0370, -0.0102,  0.0192,  ...,  0.0062,  0.0007,  0.0155],
        [-0.0035,  0.0310,  0.0199,  ...,  0.0284,  0.0075, -0.0049],
        [-0.0079, -0.0007,  0.0269,  ..., -0.0187,  0.0081, -0.0281],
        ...,
        [-0.0070, -0.0038, -0.0165,  ...,  0.0293,  0.0057,  0.0034],
        [ 0.0253,  0.0170, -0.0042,  ..., -0.0062,  0.0428, -0.0177],
        [-0.0198, -0.0041,  0.0292,  ...,  0.0003, -0.0113,  0.0282]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2129,  1.6748,  1.5820,  ...,  0.5815, -1.8721,  1.0195]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 23:56:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he tells something, something has been told
When he occurs something, something has been occurred
When he provides something, something has been provided
When he remains something, something has been remained
When he intends something, something has been intended
When he includes something, something has been included
When he follows something, something has been followed
When he appears something, something has been
2024-07-29 23:56:20 root INFO     [order_1_approx] starting weight calculation for When he follows something, something has been followed
When he intends something, something has been intended
When he occurs something, something has been occurred
When he remains something, something has been remained
When he provides something, something has been provided
When he appears something, something has been appeared
When he tells something, something has been told
When he includes something, something has been
2024-07-29 23:56:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-29 23:58:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1475, -0.2433,  0.3252,  ...,  0.6084,  0.1707, -0.5801],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9922,  1.7988,  0.9268,  ...,  0.7012, -1.0293, -3.3457],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0341, -0.0109,  0.0320,  ..., -0.0028, -0.0116,  0.0015],
        [-0.0198,  0.0390,  0.0097,  ...,  0.0149,  0.0029, -0.0024],
        [ 0.0027, -0.0066,  0.0174,  ..., -0.0203, -0.0045, -0.0028],
        ...,
        [ 0.0218, -0.0011, -0.0015,  ...,  0.0316,  0.0182,  0.0321],
        [ 0.0400,  0.0051,  0.0060,  ..., -0.0100,  0.0070, -0.0154],
        [-0.0068,  0.0097,  0.0196,  ...,  0.0035, -0.0056,  0.0305]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2061,  2.2305,  1.2168,  ...,  0.2351, -1.0820, -2.4844]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-29 23:58:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he follows something, something has been followed
When he intends something, something has been intended
When he occurs something, something has been occurred
When he remains something, something has been remained
When he provides something, something has been provided
When he appears something, something has been appeared
When he tells something, something has been told
When he includes something, something has been
2024-07-29 23:58:33 root INFO     [order_1_approx] starting weight calculation for When he appears something, something has been appeared
When he includes something, something has been included
When he remains something, something has been remained
When he occurs something, something has been occurred
When he tells something, something has been told
When he intends something, something has been intended
When he provides something, something has been provided
When he follows something, something has been
2024-07-29 23:58:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 00:00:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3181, -0.0446, -0.0709,  ...,  0.1667,  0.1666,  0.4023],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4766,  0.1152,  4.9414,  ..., -0.3433, -1.7549, -0.6211],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0365,  0.0050, -0.0029,  ...,  0.0088, -0.0065,  0.0088],
        [-0.0060,  0.0245, -0.0013,  ...,  0.0177,  0.0223, -0.0038],
        [-0.0033,  0.0051,  0.0037,  ..., -0.0252, -0.0139, -0.0228],
        ...,
        [-0.0023,  0.0232, -0.0123,  ...,  0.0217, -0.0136, -0.0078],
        [ 0.0033,  0.0130, -0.0076,  ...,  0.0095,  0.0238, -0.0208],
        [-0.0043,  0.0020,  0.0030,  ..., -0.0138, -0.0001,  0.0123]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5547,  0.3359,  4.8242,  ..., -0.4724, -1.2588, -0.1560]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 00:00:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he appears something, something has been appeared
When he includes something, something has been included
When he remains something, something has been remained
When he occurs something, something has been occurred
When he tells something, something has been told
When he intends something, something has been intended
When he provides something, something has been provided
When he follows something, something has been
2024-07-30 00:00:46 root INFO     total operator prediction time: 1066.8169078826904 seconds
2024-07-30 00:00:46 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun - plural_reg
2024-07-30 00:00:46 root INFO     building operator noun - plural_reg
2024-07-30 00:00:46 root INFO     [order_1_approx] starting weight calculation for The plural form of department is departments
The plural form of area is areas
The plural form of resource is resources
The plural form of period is periods
The plural form of website is websites
The plural form of player is players
The plural form of director is directors
The plural form of year is
2024-07-30 00:00:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 00:02:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2393,  0.1484, -0.1409,  ..., -0.0752, -0.4226, -0.0903],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2686, -4.4453,  2.6719,  ..., -1.9961, -0.2954, -4.2500],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0572,  0.0050,  0.0023,  ...,  0.0045, -0.0038,  0.0019],
        [-0.0058,  0.0677,  0.0056,  ...,  0.0175, -0.0062,  0.0012],
        [ 0.0040,  0.0148,  0.0428,  ..., -0.0197, -0.0164,  0.0347],
        ...,
        [ 0.0080,  0.0191, -0.0044,  ...,  0.0457, -0.0130,  0.0151],
        [-0.0148,  0.0199, -0.0013,  ...,  0.0359,  0.0346, -0.0015],
        [-0.0157,  0.0123, -0.0069,  ..., -0.0054, -0.0110,  0.0463]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3389, -4.5039,  2.8184,  ..., -1.9639,  0.1467, -3.9648]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 00:02:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of department is departments
The plural form of area is areas
The plural form of resource is resources
The plural form of period is periods
The plural form of website is websites
The plural form of player is players
The plural form of director is directors
The plural form of year is
2024-07-30 00:03:00 root INFO     [order_1_approx] starting weight calculation for The plural form of area is areas
The plural form of period is periods
The plural form of year is years
The plural form of player is players
The plural form of department is departments
The plural form of resource is resources
The plural form of website is websites
The plural form of director is
2024-07-30 00:03:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 00:05:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1757,  0.3032, -0.5742,  ...,  0.1737, -0.0654, -0.0391],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5801, -2.8418,  3.5332,  ..., -1.1621,  0.0739, -3.1562],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0615, -0.0031,  0.0049,  ...,  0.0129, -0.0060,  0.0292],
        [ 0.0124,  0.0576,  0.0171,  ...,  0.0084,  0.0109, -0.0075],
        [ 0.0079, -0.0154,  0.0495,  ...,  0.0086, -0.0115,  0.0032],
        ...,
        [ 0.0082,  0.0108,  0.0081,  ...,  0.0488,  0.0171, -0.0006],
        [-0.0177, -0.0117, -0.0146,  ...,  0.0236,  0.0284,  0.0128],
        [ 0.0154,  0.0095,  0.0137,  ..., -0.0098,  0.0152,  0.0284]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5059, -2.8887,  3.1836,  ..., -1.1963,  0.0204, -2.5938]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 00:05:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of area is areas
The plural form of period is periods
The plural form of year is years
The plural form of player is players
The plural form of department is departments
The plural form of resource is resources
The plural form of website is websites
The plural form of director is
2024-07-30 00:05:13 root INFO     [order_1_approx] starting weight calculation for The plural form of department is departments
The plural form of year is years
The plural form of period is periods
The plural form of area is areas
The plural form of website is websites
The plural form of director is directors
The plural form of player is players
The plural form of resource is
2024-07-30 00:05:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 00:07:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3694, -0.0044, -0.5278,  ..., -0.0020,  0.1205, -0.0452],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2378, -3.0391,  0.4021,  ..., -1.5938, -1.4062, -1.5156],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0698, -0.0009, -0.0111,  ..., -0.0136,  0.0005, -0.0089],
        [-0.0150,  0.0615,  0.0278,  ...,  0.0186,  0.0042,  0.0266],
        [ 0.0023, -0.0021,  0.0802,  ...,  0.0086, -0.0009, -0.0318],
        ...,
        [ 0.0014,  0.0116,  0.0023,  ...,  0.0931,  0.0039, -0.0141],
        [-0.0205,  0.0118, -0.0214,  ..., -0.0491,  0.0500, -0.0074],
        [ 0.0241, -0.0007,  0.0093,  ...,  0.0111, -0.0096,  0.0648]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1833, -3.1758,  0.9756,  ..., -1.0859, -1.0020, -1.2998]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 00:07:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of department is departments
The plural form of year is years
The plural form of period is periods
The plural form of area is areas
The plural form of website is websites
The plural form of director is directors
The plural form of player is players
The plural form of resource is
2024-07-30 00:07:24 root INFO     [order_1_approx] starting weight calculation for The plural form of director is directors
The plural form of year is years
The plural form of period is periods
The plural form of player is players
The plural form of area is areas
The plural form of resource is resources
The plural form of website is websites
The plural form of department is
2024-07-30 00:07:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 00:09:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1097,  0.1903, -0.3477,  ..., -0.0406,  0.0338, -0.3679],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8301, -3.1133,  3.1289,  ..., -1.2314,  1.4502, -2.8125],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0674,  0.0060, -0.0074,  ..., -0.0013, -0.0114,  0.0154],
        [ 0.0295,  0.0354,  0.0154,  ...,  0.0089, -0.0087,  0.0021],
        [-0.0139,  0.0141,  0.0511,  ...,  0.0107, -0.0023,  0.0084],
        ...,
        [ 0.0095,  0.0324,  0.0080,  ...,  0.0569, -0.0044,  0.0041],
        [-0.0264,  0.0114, -0.0163,  ...,  0.0138,  0.0507,  0.0104],
        [ 0.0214, -0.0092,  0.0066,  ..., -0.0266, -0.0163,  0.0275]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7090, -3.8730,  3.3594,  ..., -1.5967,  1.6367, -2.5527]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 00:09:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of director is directors
The plural form of year is years
The plural form of period is periods
The plural form of player is players
The plural form of area is areas
The plural form of resource is resources
The plural form of website is websites
The plural form of department is
2024-07-30 00:09:37 root INFO     [order_1_approx] starting weight calculation for The plural form of department is departments
The plural form of area is areas
The plural form of year is years
The plural form of website is websites
The plural form of resource is resources
The plural form of player is players
The plural form of director is directors
The plural form of period is
2024-07-30 00:09:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 00:11:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3789, -0.3108, -0.0925,  ..., -0.0917, -0.2292, -0.2010],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0212, -3.5176,  1.9004,  ..., -0.3794, -0.3501, -1.1807],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0826,  0.0019,  0.0207,  ..., -0.0121, -0.0269, -0.0048],
        [ 0.0099,  0.0845,  0.0228,  ...,  0.0132, -0.0006,  0.0101],
        [ 0.0038,  0.0195,  0.0757,  ..., -0.0216, -0.0192, -0.0035],
        ...,
        [ 0.0026,  0.0062,  0.0131,  ...,  0.1021, -0.0055,  0.0197],
        [-0.0301, -0.0049,  0.0050,  ...,  0.0068,  0.0587,  0.0058],
        [-0.0090,  0.0192, -0.0066,  ...,  0.0040, -0.0003,  0.0668]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0414, -3.7012,  2.2012,  ..., -0.4626, -0.2954, -0.9551]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 00:11:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of department is departments
The plural form of area is areas
The plural form of year is years
The plural form of website is websites
The plural form of resource is resources
The plural form of player is players
The plural form of director is directors
The plural form of period is
2024-07-30 00:11:50 root INFO     [order_1_approx] starting weight calculation for The plural form of resource is resources
The plural form of director is directors
The plural form of website is websites
The plural form of department is departments
The plural form of year is years
The plural form of player is players
The plural form of period is periods
The plural form of area is
2024-07-30 00:11:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 00:14:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2512, -0.0427,  0.0922,  ...,  0.0046,  0.3074, -0.3237],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7856, -4.0312,  2.6133,  ..., -1.7363,  0.6641, -2.8242],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0842, -0.0045, -0.0039,  ..., -0.0060, -0.0100,  0.0080],
        [ 0.0408,  0.0479,  0.0365,  ...,  0.0158,  0.0049, -0.0018],
        [-0.0120,  0.0294,  0.0574,  ...,  0.0015, -0.0080,  0.0192],
        ...,
        [ 0.0048, -0.0156,  0.0054,  ...,  0.0886, -0.0204, -0.0106],
        [-0.0284,  0.0276, -0.0095,  ...,  0.0074,  0.0906, -0.0147],
        [ 0.0086, -0.0159,  0.0166,  ...,  0.0037, -0.0238,  0.0648]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9575, -4.1836,  2.3066,  ..., -1.5322,  0.6553, -2.5703]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 00:14:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of resource is resources
The plural form of director is directors
The plural form of website is websites
The plural form of department is departments
The plural form of year is years
The plural form of player is players
The plural form of period is periods
The plural form of area is
2024-07-30 00:14:04 root INFO     [order_1_approx] starting weight calculation for The plural form of department is departments
The plural form of year is years
The plural form of website is websites
The plural form of period is periods
The plural form of director is directors
The plural form of resource is resources
The plural form of area is areas
The plural form of player is
2024-07-30 00:14:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 00:16:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2686,  0.3186,  0.1063,  ..., -0.0444, -0.3040, -0.1289],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2119, -5.0586,  0.8530,  ..., -0.5625, -1.6279, -2.0273],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0963, -0.0189,  0.0182,  ...,  0.0005,  0.0323,  0.0041],
        [-0.0003,  0.0767, -0.0064,  ...,  0.0085,  0.0134,  0.0122],
        [ 0.0043,  0.0017,  0.0785,  ..., -0.0281, -0.0019, -0.0131],
        ...,
        [ 0.0109,  0.0254,  0.0127,  ...,  0.0693,  0.0081,  0.0138],
        [-0.0257,  0.0177, -0.0018,  ..., -0.0145,  0.0682, -0.0116],
        [-0.0045,  0.0200, -0.0056,  ..., -0.0019,  0.0158,  0.0477]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6157, -4.7500,  1.1865,  ..., -0.6909, -1.2266, -1.5830]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 00:16:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of department is departments
The plural form of year is years
The plural form of website is websites
The plural form of period is periods
The plural form of director is directors
The plural form of resource is resources
The plural form of area is areas
The plural form of player is
2024-07-30 00:16:18 root INFO     [order_1_approx] starting weight calculation for The plural form of year is years
The plural form of player is players
The plural form of period is periods
The plural form of area is areas
The plural form of director is directors
The plural form of resource is resources
The plural form of department is departments
The plural form of website is
2024-07-30 00:16:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 00:18:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0400,  0.4609,  0.0529,  ...,  0.1006, -0.1995, -0.1222],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9849, -2.9863,  1.3672,  ...,  0.5786, -0.7246, -1.0762],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0558, -0.0007,  0.0056,  ..., -0.0094, -0.0005,  0.0025],
        [ 0.0039,  0.0744,  0.0077,  ...,  0.0023, -0.0045, -0.0021],
        [ 0.0126,  0.0045,  0.0596,  ...,  0.0101, -0.0051,  0.0220],
        ...,
        [ 0.0020,  0.0191,  0.0038,  ...,  0.0419,  0.0157, -0.0160],
        [-0.0120,  0.0500, -0.0121,  ...,  0.0045,  0.0517, -0.0060],
        [-0.0130, -0.0025, -0.0032,  ...,  0.0070, -0.0139,  0.0565]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4160, -3.3750,  0.9897,  ...,  0.7002, -0.3503, -1.0332]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 00:18:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of year is years
The plural form of player is players
The plural form of period is periods
The plural form of area is areas
The plural form of director is directors
The plural form of resource is resources
The plural form of department is departments
The plural form of website is
2024-07-30 00:18:31 root INFO     total operator prediction time: 1065.555888414383 seconds
2024-07-30 00:18:31 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_Ving - 3pSg
2024-07-30 00:18:31 root INFO     building operator verb_Ving - 3pSg
2024-07-30 00:18:32 root INFO     [order_1_approx] starting weight calculation for When something is considering, it considers
When something is teaching, it teaches
When something is enabling, it enables
When something is seeming, it seems
When something is telling, it tells
When something is becoming, it becomes
When something is discovering, it discovers
When something is believing, it
2024-07-30 00:18:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 00:20:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1741,  0.2603,  0.0659,  ..., -0.4185, -0.1899,  0.5532],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8164, -4.5898,  0.2031,  ..., -0.0234, -3.8535,  0.1445],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0331, -0.0068,  0.0126,  ...,  0.0155, -0.0086,  0.0155],
        [-0.0035,  0.0292,  0.0065,  ...,  0.0175,  0.0043,  0.0213],
        [-0.0062, -0.0107,  0.0316,  ..., -0.0165,  0.0058, -0.0010],
        ...,
        [ 0.0037, -0.0082, -0.0076,  ...,  0.0194, -0.0041,  0.0158],
        [-0.0149, -0.0046, -0.0081,  ..., -0.0141,  0.0408, -0.0351],
        [ 0.0066,  0.0059,  0.0096,  ..., -0.0073, -0.0101,  0.0116]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7246, -4.5742,  0.2678,  ...,  0.1598, -4.1992, -0.3479]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 00:20:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is considering, it considers
When something is teaching, it teaches
When something is enabling, it enables
When something is seeming, it seems
When something is telling, it tells
When something is becoming, it becomes
When something is discovering, it discovers
When something is believing, it
2024-07-30 00:20:45 root INFO     [order_1_approx] starting weight calculation for When something is teaching, it teaches
When something is enabling, it enables
When something is believing, it believes
When something is seeming, it seems
When something is discovering, it discovers
When something is becoming, it becomes
When something is considering, it considers
When something is telling, it
2024-07-30 00:20:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 00:22:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1132, -0.3691,  0.3555,  ...,  0.0120, -0.0735, -0.3789],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6992, -1.7275,  1.3984,  ...,  1.4238, -8.5156, -0.0840],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0575, -0.0024,  0.0065,  ...,  0.0017, -0.0388,  0.0195],
        [-0.0219,  0.0458, -0.0136,  ...,  0.0046, -0.0134,  0.0217],
        [ 0.0052, -0.0154,  0.0530,  ..., -0.0127, -0.0093, -0.0211],
        ...,
        [ 0.0083,  0.0109,  0.0029,  ...,  0.0621,  0.0033,  0.0009],
        [-0.0397, -0.0168, -0.0076,  ...,  0.0222,  0.0656, -0.0360],
        [ 0.0092,  0.0131,  0.0124,  ..., -0.0024, -0.0052,  0.0646]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0078, -1.8193,  1.6523,  ...,  1.3125, -8.4766, -0.0665]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 00:22:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is teaching, it teaches
When something is enabling, it enables
When something is believing, it believes
When something is seeming, it seems
When something is discovering, it discovers
When something is becoming, it becomes
When something is considering, it considers
When something is telling, it
2024-07-30 00:22:59 root INFO     [order_1_approx] starting weight calculation for When something is believing, it believes
When something is enabling, it enables
When something is telling, it tells
When something is considering, it considers
When something is becoming, it becomes
When something is seeming, it seems
When something is discovering, it discovers
When something is teaching, it
2024-07-30 00:22:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 00:25:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0469,  0.0947,  0.3662,  ..., -0.4846, -0.1731,  0.3799],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6621, -2.5293,  1.2422,  ...,  0.3911, -7.4688, -2.7695],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0423, -0.0014,  0.0053,  ...,  0.0038, -0.0120,  0.0117],
        [-0.0119,  0.0410, -0.0080,  ...,  0.0103, -0.0155,  0.0054],
        [-0.0058, -0.0082,  0.0378,  ..., -0.0081,  0.0160, -0.0108],
        ...,
        [ 0.0076, -0.0041, -0.0097,  ...,  0.0361,  0.0102, -0.0138],
        [-0.0093, -0.0026, -0.0076,  ..., -0.0103,  0.0311, -0.0381],
        [-0.0058, -0.0026,  0.0173,  ...,  0.0046,  0.0027,  0.0395]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7363, -2.3594,  1.4756,  ...,  0.4829, -7.3750, -2.5352]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 00:25:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is believing, it believes
When something is enabling, it enables
When something is telling, it tells
When something is considering, it considers
When something is becoming, it becomes
When something is seeming, it seems
When something is discovering, it discovers
When something is teaching, it
2024-07-30 00:25:13 root INFO     [order_1_approx] starting weight calculation for When something is believing, it believes
When something is becoming, it becomes
When something is seeming, it seems
When something is considering, it considers
When something is telling, it tells
When something is enabling, it enables
When something is teaching, it teaches
When something is discovering, it
2024-07-30 00:25:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 00:27:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1069, -0.3081,  0.3225,  ..., -0.4702, -0.3325, -0.1270],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0781, -4.4141,  1.7324,  ..., -0.3906, -5.2539,  1.4824],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0318,  0.0102,  0.0193,  ...,  0.0105, -0.0083,  0.0038],
        [ 0.0016,  0.0275,  0.0035,  ...,  0.0061, -0.0067,  0.0163],
        [-0.0029, -0.0025,  0.0086,  ..., -0.0137,  0.0096, -0.0209],
        ...,
        [ 0.0095,  0.0039, -0.0016,  ...,  0.0217, -0.0006, -0.0065],
        [-0.0005, -0.0103, -0.0174,  ..., -0.0072,  0.0381, -0.0208],
        [-0.0026, -0.0043,  0.0189,  ..., -0.0085, -0.0057,  0.0110]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1270, -4.2070,  1.6582,  ..., -0.1715, -5.8203,  1.2139]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 00:27:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is believing, it believes
When something is becoming, it becomes
When something is seeming, it seems
When something is considering, it considers
When something is telling, it tells
When something is enabling, it enables
When something is teaching, it teaches
When something is discovering, it
2024-07-30 00:27:27 root INFO     [order_1_approx] starting weight calculation for When something is believing, it believes
When something is discovering, it discovers
When something is teaching, it teaches
When something is telling, it tells
When something is becoming, it becomes
When something is seeming, it seems
When something is considering, it considers
When something is enabling, it
2024-07-30 00:27:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 00:29:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1899, -0.5991, -0.0443,  ..., -0.6401, -0.2378,  0.1887],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8179, -3.2891, -0.5508,  ..., -0.5674, -8.6094, -2.1055],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0637, -0.0089,  0.0339,  ...,  0.0059, -0.0280,  0.0105],
        [-0.0041,  0.0560, -0.0057,  ...,  0.0267,  0.0003, -0.0028],
        [ 0.0094, -0.0047,  0.0526,  ..., -0.0327,  0.0157, -0.0067],
        ...,
        [ 0.0024,  0.0179, -0.0079,  ...,  0.0560,  0.0078,  0.0068],
        [-0.0080, -0.0221, -0.0231,  ..., -0.0166,  0.0670, -0.0497],
        [-0.0111, -0.0126,  0.0125,  ..., -0.0033, -0.0210,  0.0616]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3340, -3.1426, -0.3652,  ..., -0.3345, -8.5234, -2.3379]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 00:29:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is believing, it believes
When something is discovering, it discovers
When something is teaching, it teaches
When something is telling, it tells
When something is becoming, it becomes
When something is seeming, it seems
When something is considering, it considers
When something is enabling, it
2024-07-30 00:29:40 root INFO     [order_1_approx] starting weight calculation for When something is teaching, it teaches
When something is considering, it considers
When something is seeming, it seems
When something is discovering, it discovers
When something is enabling, it enables
When something is telling, it tells
When something is believing, it believes
When something is becoming, it
2024-07-30 00:29:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 00:31:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0974,  0.0786,  0.3252,  ...,  0.0751, -0.1578,  0.1655],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7109, -2.7754,  0.1719,  ...,  0.5537, -2.4570, -1.7207],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0567,  0.0069,  0.0043,  ...,  0.0188, -0.0103,  0.0232],
        [ 0.0064,  0.0509, -0.0003,  ...,  0.0064, -0.0059,  0.0180],
        [-0.0050, -0.0228,  0.0577,  ...,  0.0034,  0.0210, -0.0142],
        ...,
        [ 0.0211,  0.0024, -0.0074,  ...,  0.0775,  0.0018,  0.0156],
        [-0.0020,  0.0174, -0.0219,  ..., -0.0118,  0.0590, -0.0511],
        [-0.0050,  0.0013,  0.0039,  ..., -0.0147, -0.0090,  0.0455]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6191, -2.6172,  0.1177,  ...,  0.8018, -2.6562, -1.7207]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 00:31:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is teaching, it teaches
When something is considering, it considers
When something is seeming, it seems
When something is discovering, it discovers
When something is enabling, it enables
When something is telling, it tells
When something is believing, it believes
When something is becoming, it
2024-07-30 00:31:54 root INFO     [order_1_approx] starting weight calculation for When something is considering, it considers
When something is teaching, it teaches
When something is believing, it believes
When something is becoming, it becomes
When something is discovering, it discovers
When something is telling, it tells
When something is enabling, it enables
When something is seeming, it
2024-07-30 00:31:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 00:34:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1418, -0.5889,  0.3491,  ..., -0.3447, -0.1137,  0.0814],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2910, -2.3516, -3.0215,  ...,  1.4258, -4.2266, -1.1768],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0593, -0.0160,  0.0170,  ..., -0.0024,  0.0023,  0.0144],
        [-0.0117,  0.0383, -0.0111,  ...,  0.0167, -0.0045,  0.0049],
        [ 0.0011, -0.0115,  0.0423,  ..., -0.0141, -0.0045, -0.0121],
        ...,
        [ 0.0055,  0.0055,  0.0050,  ...,  0.0637, -0.0181,  0.0167],
        [-0.0079,  0.0229, -0.0099,  ..., -0.0171,  0.0496, -0.0576],
        [-0.0091, -0.0048,  0.0190,  ..., -0.0125,  0.0008,  0.0291]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3145, -2.2852, -3.1250,  ...,  1.6182, -4.5352, -1.1758]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 00:34:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is considering, it considers
When something is teaching, it teaches
When something is believing, it believes
When something is becoming, it becomes
When something is discovering, it discovers
When something is telling, it tells
When something is enabling, it enables
When something is seeming, it
2024-07-30 00:34:08 root INFO     [order_1_approx] starting weight calculation for When something is enabling, it enables
When something is teaching, it teaches
When something is discovering, it discovers
When something is becoming, it becomes
When something is telling, it tells
When something is believing, it believes
When something is seeming, it seems
When something is considering, it
2024-07-30 00:34:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 00:36:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0743, -0.1692, -0.0107,  ..., -0.0217,  0.0724, -0.1650],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9609, -3.6641,  1.6953,  ..., -1.9463, -4.9297, -0.2490],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0489, -0.0003,  0.0161,  ...,  0.0117, -0.0161,  0.0231],
        [-0.0015,  0.0174,  0.0060,  ...,  0.0237, -0.0023,  0.0156],
        [ 0.0045,  0.0012,  0.0323,  ..., -0.0214, -0.0108, -0.0229],
        ...,
        [ 0.0052, -0.0190,  0.0197,  ...,  0.0465, -0.0146,  0.0073],
        [-0.0010,  0.0109, -0.0046,  ..., -0.0374,  0.0436, -0.0355],
        [-0.0041,  0.0135,  0.0147,  ..., -0.0136, -0.0128,  0.0076]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6270, -3.3086,  1.5293,  ..., -1.2832, -5.4609, -0.3000]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 00:36:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is enabling, it enables
When something is teaching, it teaches
When something is discovering, it discovers
When something is becoming, it becomes
When something is telling, it tells
When something is believing, it believes
When something is seeming, it seems
When something is considering, it
2024-07-30 00:36:22 root INFO     total operator prediction time: 1070.4051299095154 seconds
2024-07-30 00:36:22 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_inf - 3pSg
2024-07-30 00:36:22 root INFO     building operator verb_inf - 3pSg
2024-07-30 00:36:22 root INFO     [order_1_approx] starting weight calculation for I exist, he exists
I develop, he develops
I promote, he promotes
I enjoy, he enjoys
I explain, he explains
I allow, he allows
I operate, he operates
I enable, he
2024-07-30 00:36:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 00:38:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0694, -0.1323, -0.0879,  ..., -0.5771, -0.0449,  0.4482],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8857, -2.7246, -0.3359,  ..., -1.0420, -8.7656, -1.4043],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0232,  0.0027,  0.0066,  ...,  0.0113, -0.0123,  0.0177],
        [-0.0068,  0.0299,  0.0080,  ...,  0.0185,  0.0134, -0.0103],
        [-0.0076, -0.0053, -0.0003,  ..., -0.0291,  0.0068,  0.0064],
        ...,
        [-0.0059,  0.0034,  0.0003,  ...,  0.0127,  0.0089,  0.0037],
        [-0.0076, -0.0068, -0.0112,  ..., -0.0055,  0.0262, -0.0138],
        [-0.0093, -0.0147,  0.0153,  ..., -0.0154, -0.0099,  0.0077]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4082, -2.5195,  0.1409,  ..., -0.5488, -8.1797, -0.7549]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 00:38:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I exist, he exists
I develop, he develops
I promote, he promotes
I enjoy, he enjoys
I explain, he explains
I allow, he allows
I operate, he operates
I enable, he
2024-07-30 00:38:35 root INFO     [order_1_approx] starting weight calculation for I develop, he develops
I operate, he operates
I promote, he promotes
I explain, he explains
I enable, he enables
I exist, he exists
I allow, he allows
I enjoy, he
2024-07-30 00:38:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 00:40:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0244, -0.1410,  0.1083,  ..., -0.4482, -0.4080,  0.0051],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5625, -3.3809, -1.5547,  ..., -2.1113, -6.6562, -0.2852],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0475,  0.0051,  0.0059,  ..., -0.0008,  0.0022,  0.0375],
        [-0.0025,  0.0311,  0.0004,  ...,  0.0091,  0.0155, -0.0010],
        [-0.0118,  0.0020,  0.0168,  ..., -0.0094, -0.0165, -0.0095],
        ...,
        [-0.0142, -0.0012, -0.0044,  ...,  0.0281,  0.0042, -0.0095],
        [-0.0198, -0.0008,  0.0101,  ..., -0.0068,  0.0328, -0.0149],
        [-0.0114,  0.0039, -0.0094,  ..., -0.0123, -0.0162,  0.0164]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5156, -3.4531, -1.3975,  ..., -1.8877, -6.7227, -0.1976]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 00:40:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I develop, he develops
I operate, he operates
I promote, he promotes
I explain, he explains
I enable, he enables
I exist, he exists
I allow, he allows
I enjoy, he
2024-07-30 00:40:48 root INFO     [order_1_approx] starting weight calculation for I enjoy, he enjoys
I explain, he explains
I promote, he promotes
I enable, he enables
I develop, he develops
I allow, he allows
I operate, he operates
I exist, he
2024-07-30 00:40:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 00:43:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3911, -0.1772, -0.6826,  ...,  0.0476,  0.0748, -0.1993],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.2656, -3.2031, -2.3691,  ..., -1.5732, -5.9375, -0.3262],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0151, -0.0054,  0.0038,  ...,  0.0146, -0.0057,  0.0351],
        [ 0.0075,  0.0296, -0.0069,  ...,  0.0146,  0.0069, -0.0036],
        [-0.0040,  0.0126,  0.0056,  ..., -0.0178, -0.0056, -0.0151],
        ...,
        [-0.0174,  0.0037, -0.0039,  ...,  0.0119,  0.0029, -0.0084],
        [-0.0183, -0.0132,  0.0089,  ..., -0.0210,  0.0197,  0.0019],
        [-0.0036, -0.0073, -0.0029,  ..., -0.0182, -0.0059,  0.0094]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0859, -2.9805, -2.1543,  ..., -1.0352, -6.0703,  0.1025]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 00:43:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I enjoy, he enjoys
I explain, he explains
I promote, he promotes
I enable, he enables
I develop, he develops
I allow, he allows
I operate, he operates
I exist, he
2024-07-30 00:43:07 root INFO     [order_1_approx] starting weight calculation for I promote, he promotes
I explain, he explains
I develop, he develops
I enable, he enables
I allow, he allows
I exist, he exists
I enjoy, he enjoys
I operate, he
2024-07-30 00:43:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 00:45:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3020, -0.1753, -0.6489,  ..., -0.1295, -0.3208, -0.4370],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1465, -4.3828,  0.0625,  ..., -1.6797, -6.2773,  0.0996],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0446,  0.0008,  0.0164,  ...,  0.0195, -0.0046,  0.0341],
        [-0.0127,  0.0261,  0.0024,  ...,  0.0148,  0.0167, -0.0005],
        [ 0.0063,  0.0137,  0.0227,  ..., -0.0093,  0.0054, -0.0035],
        ...,
        [-0.0120, -0.0021, -0.0120,  ...,  0.0265,  0.0220, -0.0060],
        [-0.0152, -0.0188, -0.0106,  ..., -0.0158,  0.0285, -0.0049],
        [ 0.0079, -0.0133, -0.0069,  ..., -0.0189, -0.0211,  0.0370]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0996, -4.1914,  0.0652,  ..., -1.3350, -6.3164,  0.2020]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 00:45:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I promote, he promotes
I explain, he explains
I develop, he develops
I enable, he enables
I allow, he allows
I exist, he exists
I enjoy, he enjoys
I operate, he
2024-07-30 00:45:20 root INFO     [order_1_approx] starting weight calculation for I operate, he operates
I promote, he promotes
I enjoy, he enjoys
I develop, he develops
I exist, he exists
I enable, he enables
I explain, he explains
I allow, he
2024-07-30 00:45:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 00:47:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1404, -0.3071, -0.1302,  ..., -0.4976, -0.0112,  0.0775],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0234, -4.1328, -0.7383,  ..., -1.3857, -7.8281,  1.1797],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0505, -0.0040, -0.0074,  ..., -0.0025, -0.0072,  0.0223],
        [-0.0056,  0.0299, -0.0057,  ...,  0.0259,  0.0229,  0.0010],
        [-0.0105, -0.0094,  0.0114,  ..., -0.0222, -0.0069, -0.0119],
        ...,
        [-0.0113,  0.0031,  0.0042,  ...,  0.0336,  0.0063,  0.0012],
        [-0.0091,  0.0021, -0.0057,  ..., -0.0058,  0.0323, -0.0182],
        [-0.0021, -0.0152, -0.0158,  ..., -0.0079, -0.0154,  0.0076]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3398, -4.0117, -0.6206,  ..., -0.8887, -7.7344,  1.5234]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 00:47:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I operate, he operates
I promote, he promotes
I enjoy, he enjoys
I develop, he develops
I exist, he exists
I enable, he enables
I explain, he explains
I allow, he
2024-07-30 00:47:33 root INFO     [order_1_approx] starting weight calculation for I promote, he promotes
I exist, he exists
I explain, he explains
I enjoy, he enjoys
I operate, he operates
I enable, he enables
I allow, he allows
I develop, he
2024-07-30 00:47:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 00:49:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6978, -0.3823,  0.1306,  ..., -0.1836, -0.3486,  0.0160],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6758, -4.4375, -0.3105,  ..., -0.4893, -7.1680, -0.9785],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.8849e-02,  4.9057e-03,  6.7787e-03,  ...,  1.1635e-02,
         -9.5749e-04,  2.5925e-02],
        [-9.0408e-03,  3.9673e-02,  3.1757e-03,  ...,  1.3321e-02,
          7.2479e-03,  6.3019e-03],
        [-1.0056e-02,  7.1049e-05,  1.8143e-02,  ..., -1.1711e-02,
          1.0979e-02, -1.1795e-02],
        ...,
        [ 4.6234e-03, -6.1302e-03,  8.5983e-03,  ...,  3.5522e-02,
         -1.1612e-02,  1.4107e-02],
        [-2.0020e-02, -1.3077e-02, -7.3166e-03,  ..., -1.4183e-02,
          2.8656e-02, -2.0905e-02],
        [-1.4656e-02, -9.8038e-03,  1.9722e-03,  ..., -1.5961e-02,
         -1.3687e-02,  1.3779e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3438, -4.2266, -0.0994,  ..., -0.7656, -7.1445, -0.6318]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 00:49:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I promote, he promotes
I exist, he exists
I explain, he explains
I enjoy, he enjoys
I operate, he operates
I enable, he enables
I allow, he allows
I develop, he
2024-07-30 00:49:46 root INFO     [order_1_approx] starting weight calculation for I develop, he develops
I operate, he operates
I allow, he allows
I explain, he explains
I exist, he exists
I enjoy, he enjoys
I enable, he enables
I promote, he
2024-07-30 00:49:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 00:51:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1228,  0.1222,  0.0377,  ...,  0.1802, -0.0657,  0.2505],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.2656, -4.3125, -0.1074,  ..., -1.1680, -8.0781,  0.7441],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0333, -0.0018,  0.0144,  ...,  0.0126, -0.0123,  0.0247],
        [-0.0190,  0.0408, -0.0047,  ...,  0.0236,  0.0135, -0.0042],
        [-0.0029,  0.0089,  0.0217,  ..., -0.0090, -0.0070, -0.0034],
        ...,
        [-0.0020,  0.0071,  0.0049,  ...,  0.0300,  0.0004, -0.0008],
        [-0.0259, -0.0025, -0.0047,  ..., -0.0122,  0.0281, -0.0381],
        [-0.0158, -0.0038, -0.0061,  ..., -0.0245, -0.0186,  0.0244]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0938, -4.1055, -0.1716,  ..., -1.0244, -7.8398,  0.8359]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 00:51:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I develop, he develops
I operate, he operates
I allow, he allows
I explain, he explains
I exist, he exists
I enjoy, he enjoys
I enable, he enables
I promote, he
2024-07-30 00:51:59 root INFO     [order_1_approx] starting weight calculation for I operate, he operates
I enable, he enables
I promote, he promotes
I exist, he exists
I develop, he develops
I enjoy, he enjoys
I allow, he allows
I explain, he
2024-07-30 00:51:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 00:54:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0754, -0.2842,  0.1057,  ..., -0.3706,  0.0218, -0.3022],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7773, -3.4238,  1.6211,  ...,  1.1133, -7.1641,  0.8828],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0352, -0.0028, -0.0051,  ...,  0.0111, -0.0005,  0.0334],
        [-0.0106,  0.0376,  0.0085,  ...,  0.0047,  0.0100,  0.0086],
        [-0.0231, -0.0063,  0.0148,  ..., -0.0213,  0.0070,  0.0004],
        ...,
        [-0.0211, -0.0010,  0.0122,  ...,  0.0207,  0.0022,  0.0093],
        [-0.0051, -0.0107,  0.0046,  ..., -0.0079,  0.0276, -0.0044],
        [-0.0045, -0.0120,  0.0089,  ..., -0.0086, -0.0051,  0.0136]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8398, -3.4785,  1.6299,  ...,  1.1221, -7.0781,  0.9395]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 00:54:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I operate, he operates
I enable, he enables
I promote, he promotes
I exist, he exists
I develop, he develops
I enjoy, he enjoys
I allow, he allows
I explain, he
2024-07-30 00:54:11 root INFO     total operator prediction time: 1069.5772223472595 seconds
2024-07-30 00:54:11 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_inf - Ved
2024-07-30 00:54:11 root INFO     building operator verb_inf - Ved
2024-07-30 00:54:12 root INFO     [order_1_approx] starting weight calculation for If the present form is refer, the past form is referred
If the present form is involve, the past form is involved
If the present form is relate, the past form is related
If the present form is agree, the past form is agreed
If the present form is improve, the past form is improved
If the present form is lose, the past form is lost
If the present form is allow, the past form is allowed
If the present form is become, the past form is
2024-07-30 00:54:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 00:56:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4324,  0.3779, -0.0477,  ..., -0.1565, -0.1788,  0.2783],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0635, -0.0818,  1.3018,  ...,  0.3872,  0.9033, -1.2432],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0878, -0.0241,  0.0328,  ...,  0.0041,  0.0121,  0.0237],
        [-0.0222,  0.0652,  0.0031,  ...,  0.0091,  0.0076, -0.0041],
        [ 0.0119, -0.0071,  0.0414,  ..., -0.0255, -0.0031, -0.0063],
        ...,
        [-0.0054,  0.0208, -0.0007,  ...,  0.0874,  0.0132, -0.0056],
        [ 0.0089,  0.0097, -0.0187,  ..., -0.0088,  0.0319,  0.0044],
        [-0.0166,  0.0054,  0.0197,  ..., -0.0096, -0.0238,  0.0486]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9478, -0.1486,  0.8076,  ...,  0.5576,  0.8184, -0.8652]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 00:56:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is refer, the past form is referred
If the present form is involve, the past form is involved
If the present form is relate, the past form is related
If the present form is agree, the past form is agreed
If the present form is improve, the past form is improved
If the present form is lose, the past form is lost
If the present form is allow, the past form is allowed
If the present form is become, the past form is
2024-07-30 00:56:24 root INFO     [order_1_approx] starting weight calculation for If the present form is relate, the past form is related
If the present form is allow, the past form is allowed
If the present form is refer, the past form is referred
If the present form is involve, the past form is involved
If the present form is become, the past form is became
If the present form is improve, the past form is improved
If the present form is agree, the past form is agreed
If the present form is lose, the past form is
2024-07-30 00:56:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 00:58:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1395, -0.0549,  0.1544,  ..., -0.5444,  0.3823,  0.0207],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2021, -1.8242, -0.0388,  ..., -0.8267, -0.5820, -1.6133],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0943, -0.0162,  0.0271,  ...,  0.0012,  0.0075,  0.0111],
        [-0.0069,  0.0771,  0.0068,  ...,  0.0090, -0.0044,  0.0057],
        [-0.0094, -0.0027,  0.0473,  ...,  0.0075, -0.0310, -0.0157],
        ...,
        [ 0.0128,  0.0156, -0.0294,  ...,  0.0541,  0.0170, -0.0045],
        [-0.0018,  0.0127,  0.0055,  ..., -0.0111,  0.0302, -0.0297],
        [-0.0164,  0.0138,  0.0139,  ..., -0.0294, -0.0080,  0.0461]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1826, -1.8662,  0.0521,  ..., -0.3416, -0.5171, -1.5830]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 00:58:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is relate, the past form is related
If the present form is allow, the past form is allowed
If the present form is refer, the past form is referred
If the present form is involve, the past form is involved
If the present form is become, the past form is became
If the present form is improve, the past form is improved
If the present form is agree, the past form is agreed
If the present form is lose, the past form is
2024-07-30 00:58:36 root INFO     [order_1_approx] starting weight calculation for If the present form is relate, the past form is related
If the present form is agree, the past form is agreed
If the present form is refer, the past form is referred
If the present form is lose, the past form is lost
If the present form is allow, the past form is allowed
If the present form is involve, the past form is involved
If the present form is become, the past form is became
If the present form is improve, the past form is
2024-07-30 00:58:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 01:00:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1019, -0.2468, -0.0920,  ..., -0.6152,  0.0472,  0.3342],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8379, -0.6514,  1.3203,  ..., -1.0732, -1.2285, -2.3730],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0587, -0.0195, -0.0036,  ..., -0.0060,  0.0038,  0.0133],
        [-0.0085,  0.0428,  0.0155,  ...,  0.0268,  0.0082,  0.0060],
        [ 0.0193,  0.0165,  0.0267,  ...,  0.0134,  0.0008,  0.0023],
        ...,
        [ 0.0027,  0.0026, -0.0054,  ...,  0.0668,  0.0038,  0.0030],
        [ 0.0099, -0.0081,  0.0028,  ...,  0.0003,  0.0154, -0.0122],
        [-0.0219, -0.0052,  0.0013,  ...,  0.0039, -0.0300,  0.0198]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7988, -0.4905,  1.1904,  ..., -0.7983, -0.6748, -2.3320]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 01:00:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is relate, the past form is related
If the present form is agree, the past form is agreed
If the present form is refer, the past form is referred
If the present form is lose, the past form is lost
If the present form is allow, the past form is allowed
If the present form is involve, the past form is involved
If the present form is become, the past form is became
If the present form is improve, the past form is
2024-07-30 01:00:49 root INFO     [order_1_approx] starting weight calculation for If the present form is involve, the past form is involved
If the present form is become, the past form is became
If the present form is refer, the past form is referred
If the present form is lose, the past form is lost
If the present form is allow, the past form is allowed
If the present form is relate, the past form is related
If the present form is improve, the past form is improved
If the present form is agree, the past form is
2024-07-30 01:00:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 01:03:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0291, -0.0588, -0.2262,  ..., -0.0336, -0.1970, -0.1355],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5059, -1.8594,  0.8770,  ..., -0.5366, -2.4492,  0.1348],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0804, -0.0266,  0.0236,  ...,  0.0017,  0.0082,  0.0227],
        [-0.0245,  0.0527,  0.0025,  ...,  0.0244,  0.0064, -0.0251],
        [-0.0105, -0.0140,  0.0264,  ...,  0.0043, -0.0006, -0.0231],
        ...,
        [ 0.0078,  0.0048, -0.0075,  ...,  0.0732, -0.0007, -0.0015],
        [-0.0022,  0.0008, -0.0338,  ..., -0.0170,  0.0241, -0.0274],
        [-0.0003,  0.0011,  0.0168,  ..., -0.0005, -0.0233,  0.0505]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5049, -1.6328,  0.8706,  ..., -0.5811, -2.0918,  0.1885]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 01:03:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is involve, the past form is involved
If the present form is become, the past form is became
If the present form is refer, the past form is referred
If the present form is lose, the past form is lost
If the present form is allow, the past form is allowed
If the present form is relate, the past form is related
If the present form is improve, the past form is improved
If the present form is agree, the past form is
2024-07-30 01:03:02 root INFO     [order_1_approx] starting weight calculation for If the present form is involve, the past form is involved
If the present form is improve, the past form is improved
If the present form is lose, the past form is lost
If the present form is refer, the past form is referred
If the present form is agree, the past form is agreed
If the present form is become, the past form is became
If the present form is relate, the past form is related
If the present form is allow, the past form is
2024-07-30 01:03:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 01:05:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0594,  0.2791, -0.1301,  ..., -0.2280,  0.1837, -0.2065],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7695, -3.1816, -0.6050,  ..., -0.6255, -2.9238,  0.3418],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0584, -0.0174,  0.0054,  ..., -0.0246,  0.0076, -0.0024],
        [-0.0056,  0.0308, -0.0218,  ...,  0.0153,  0.0093, -0.0216],
        [ 0.0021, -0.0030,  0.0274,  ..., -0.0185, -0.0118, -0.0113],
        ...,
        [ 0.0037,  0.0177, -0.0037,  ...,  0.0693,  0.0139,  0.0097],
        [-0.0022,  0.0050, -0.0185,  ..., -0.0092,  0.0175, -0.0338],
        [ 0.0057, -0.0036,  0.0006,  ..., -0.0146, -0.0237,  0.0244]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8037, -2.8770, -0.6836,  ..., -0.5513, -2.6602,  0.6772]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 01:05:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is involve, the past form is involved
If the present form is improve, the past form is improved
If the present form is lose, the past form is lost
If the present form is refer, the past form is referred
If the present form is agree, the past form is agreed
If the present form is become, the past form is became
If the present form is relate, the past form is related
If the present form is allow, the past form is
2024-07-30 01:05:15 root INFO     [order_1_approx] starting weight calculation for If the present form is become, the past form is became
If the present form is improve, the past form is improved
If the present form is lose, the past form is lost
If the present form is refer, the past form is referred
If the present form is allow, the past form is allowed
If the present form is agree, the past form is agreed
If the present form is involve, the past form is involved
If the present form is relate, the past form is
2024-07-30 01:05:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 01:07:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0030, -0.1626, -0.3145,  ..., -0.7646, -0.2124, -0.1508],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.1660,  0.4929,  2.0156,  ...,  0.2893, -1.2549, -2.0586],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0710, -0.0344, -0.0021,  ...,  0.0059,  0.0140,  0.0016],
        [-0.0135,  0.0667, -0.0033,  ...,  0.0186, -0.0057,  0.0042],
        [ 0.0074, -0.0026,  0.0313,  ..., -0.0107,  0.0025, -0.0157],
        ...,
        [ 0.0145,  0.0113, -0.0112,  ...,  0.0690,  0.0110,  0.0163],
        [ 0.0061, -0.0019, -0.0009,  ..., -0.0012,  0.0461, -0.0152],
        [-0.0237,  0.0016,  0.0081,  ...,  0.0088, -0.0111,  0.0423]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7236,  0.6904,  1.8906,  ...,  0.2798, -0.5732, -2.0566]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 01:07:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is become, the past form is became
If the present form is improve, the past form is improved
If the present form is lose, the past form is lost
If the present form is refer, the past form is referred
If the present form is allow, the past form is allowed
If the present form is agree, the past form is agreed
If the present form is involve, the past form is involved
If the present form is relate, the past form is
2024-07-30 01:07:24 root INFO     [order_1_approx] starting weight calculation for If the present form is improve, the past form is improved
If the present form is become, the past form is became
If the present form is lose, the past form is lost
If the present form is relate, the past form is related
If the present form is agree, the past form is agreed
If the present form is allow, the past form is allowed
If the present form is refer, the past form is referred
If the present form is involve, the past form is
2024-07-30 01:07:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 01:09:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0437,  0.3835, -0.0499,  ..., -0.4207, -0.1311,  0.1561],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1680,  0.8066,  2.1074,  ..., -1.2676,  0.5630, -2.9883],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0621, -0.0031,  0.0154,  ..., -0.0064,  0.0053,  0.0199],
        [-0.0282,  0.0534, -0.0029,  ...,  0.0228, -0.0078, -0.0002],
        [ 0.0067, -0.0089,  0.0287,  ..., -0.0091, -0.0237, -0.0142],
        ...,
        [ 0.0049,  0.0040, -0.0061,  ...,  0.0711,  0.0127,  0.0230],
        [-0.0076,  0.0108, -0.0141,  ...,  0.0062,  0.0359, -0.0166],
        [-0.0047, -0.0017,  0.0093,  ...,  0.0023, -0.0207,  0.0403]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2389,  0.6392,  1.9014,  ..., -1.1279,  0.7295, -3.0410]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 01:09:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is improve, the past form is improved
If the present form is become, the past form is became
If the present form is lose, the past form is lost
If the present form is relate, the past form is related
If the present form is agree, the past form is agreed
If the present form is allow, the past form is allowed
If the present form is refer, the past form is referred
If the present form is involve, the past form is
2024-07-30 01:09:28 root INFO     [order_1_approx] starting weight calculation for If the present form is lose, the past form is lost
If the present form is involve, the past form is involved
If the present form is improve, the past form is improved
If the present form is agree, the past form is agreed
If the present form is become, the past form is became
If the present form is relate, the past form is related
If the present form is allow, the past form is allowed
If the present form is refer, the past form is
2024-07-30 01:09:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 01:11:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4568, -0.4526, -0.1404,  ..., -0.1886, -0.0304, -0.1882],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7676, -1.4277,  0.6621,  ...,  1.4658, -1.7891, -2.8984],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0769, -0.0330,  0.0279,  ..., -0.0007,  0.0037,  0.0169],
        [-0.0297,  0.0629,  0.0016,  ...,  0.0101,  0.0006, -0.0031],
        [ 0.0271,  0.0051,  0.0399,  ..., -0.0231, -0.0065,  0.0162],
        ...,
        [ 0.0155,  0.0144, -0.0102,  ...,  0.0892,  0.0129,  0.0306],
        [ 0.0188,  0.0108,  0.0144,  ...,  0.0005,  0.0308, -0.0195],
        [-0.0124,  0.0172,  0.0256,  ..., -0.0026, -0.0127,  0.0343]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6108, -1.7646,  0.3257,  ...,  1.5898, -1.3779, -2.4219]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 01:11:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is lose, the past form is lost
If the present form is involve, the past form is involved
If the present form is improve, the past form is improved
If the present form is agree, the past form is agreed
If the present form is become, the past form is became
If the present form is relate, the past form is related
If the present form is allow, the past form is allowed
If the present form is refer, the past form is
2024-07-30 01:11:40 root INFO     total operator prediction time: 1048.2790231704712 seconds
2024-07-30 01:11:40 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_Ving - Ved
2024-07-30 01:11:40 root INFO     building operator verb_Ving - Ved
2024-07-30 01:11:40 root INFO     [order_1_approx] starting weight calculation for After something is involving, it has involved
After something is asking, it has asked
After something is adding, it has added
After something is performing, it has performed
After something is reducing, it has reduced
After something is requiring, it has required
After something is continuing, it has continued
After something is providing, it has
2024-07-30 01:11:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 01:13:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2686, -0.4036,  0.0857,  ..., -0.2136,  0.0728, -0.3167],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4258, -3.0449,  1.8037,  ..., -1.2041, -1.9082,  0.0293],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0732, -0.0071,  0.0445,  ...,  0.0106,  0.0004,  0.0299],
        [-0.0453,  0.0463,  0.0194,  ...,  0.0275, -0.0011,  0.0296],
        [ 0.0095, -0.0187,  0.0400,  ..., -0.0039,  0.0047, -0.0103],
        ...,
        [ 0.0186,  0.0106, -0.0131,  ...,  0.0670,  0.0061,  0.0085],
        [ 0.0204,  0.0041, -0.0242,  ..., -0.0029,  0.0528, -0.0308],
        [-0.0170,  0.0195, -0.0051,  ..., -0.0272, -0.0141,  0.0544]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2715, -2.8613,  2.0273,  ..., -1.0303, -1.5801,  0.1735]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 01:13:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is involving, it has involved
After something is asking, it has asked
After something is adding, it has added
After something is performing, it has performed
After something is reducing, it has reduced
After something is requiring, it has required
After something is continuing, it has continued
After something is providing, it has
2024-07-30 01:13:48 root INFO     [order_1_approx] starting weight calculation for After something is performing, it has performed
After something is providing, it has provided
After something is continuing, it has continued
After something is reducing, it has reduced
After something is asking, it has asked
After something is requiring, it has required
After something is adding, it has added
After something is involving, it has
2024-07-30 01:13:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 01:15:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0806,  0.0444,  0.0876,  ..., -0.4180, -0.3662, -0.0015],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8633,  1.9238,  3.6680,  ..., -1.0205,  0.5498, -3.0508],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0610, -0.0022,  0.0367,  ...,  0.0028,  0.0008,  0.0076],
        [-0.0374,  0.0619, -0.0012,  ...,  0.0011,  0.0145, -0.0081],
        [-0.0082, -0.0293,  0.0197,  ..., -0.0194,  0.0151, -0.0136],
        ...,
        [ 0.0218,  0.0278, -0.0328,  ...,  0.0493,  0.0155,  0.0127],
        [ 0.0101,  0.0229, -0.0005,  ...,  0.0052,  0.0543, -0.0248],
        [-0.0052,  0.0146,  0.0259,  ..., -0.0032, -0.0222,  0.0424]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1377,  2.0488,  3.6387,  ..., -1.0928,  0.3535, -2.9707]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 01:15:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is performing, it has performed
After something is providing, it has provided
After something is continuing, it has continued
After something is reducing, it has reduced
After something is asking, it has asked
After something is requiring, it has required
After something is adding, it has added
After something is involving, it has
2024-07-30 01:15:58 root INFO     [order_1_approx] starting weight calculation for After something is adding, it has added
After something is asking, it has asked
After something is requiring, it has required
After something is performing, it has performed
After something is involving, it has involved
After something is continuing, it has continued
After something is providing, it has provided
After something is reducing, it has
2024-07-30 01:15:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 01:18:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 1.2207e-04, -2.9443e-01, -1.5588e-01,  ..., -3.4814e-01,
         1.7700e-01, -4.0259e-01], device='cuda:1', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.7266, -0.0698,  0.9966,  ..., -4.7422, -1.4023, -5.1914],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0473, -0.0013,  0.0142,  ...,  0.0005,  0.0064,  0.0181],
        [-0.0328,  0.0471,  0.0103,  ...,  0.0200,  0.0170,  0.0193],
        [-0.0089, -0.0062,  0.0374,  ...,  0.0033,  0.0012, -0.0116],
        ...,
        [ 0.0222,  0.0054, -0.0187,  ...,  0.0487,  0.0237,  0.0101],
        [ 0.0288,  0.0114, -0.0163,  ..., -0.0052,  0.0562, -0.0117],
        [-0.0078,  0.0094,  0.0142,  ..., -0.0094,  0.0031,  0.0257]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.0332, -0.3970,  0.7817,  ..., -4.4727, -1.2705, -5.2812]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 01:18:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is adding, it has added
After something is asking, it has asked
After something is requiring, it has required
After something is performing, it has performed
After something is involving, it has involved
After something is continuing, it has continued
After something is providing, it has provided
After something is reducing, it has
2024-07-30 01:18:11 root INFO     [order_1_approx] starting weight calculation for After something is continuing, it has continued
After something is requiring, it has required
After something is involving, it has involved
After something is reducing, it has reduced
After something is adding, it has added
After something is performing, it has performed
After something is providing, it has provided
After something is asking, it has
2024-07-30 01:18:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 01:20:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0079,  0.0059,  0.1175,  ...,  0.0045, -0.3123, -0.7202],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8223, -0.9058,  0.5605,  ...,  0.0563, -2.9219, -0.6035],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0499, -0.0111,  0.0080,  ...,  0.0038, -0.0013,  0.0183],
        [-0.0207,  0.0561,  0.0014,  ...,  0.0242, -0.0010,  0.0104],
        [-0.0145, -0.0073,  0.0293,  ..., -0.0105,  0.0018, -0.0105],
        ...,
        [-0.0131,  0.0353, -0.0105,  ...,  0.0392,  0.0071,  0.0017],
        [ 0.0245, -0.0006, -0.0032,  ..., -0.0042,  0.0253, -0.0117],
        [-0.0200,  0.0188,  0.0170,  ...,  0.0033, -0.0177,  0.0188]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5742, -0.8794,  0.7778,  ..., -0.2036, -2.5176, -0.6343]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 01:20:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is continuing, it has continued
After something is requiring, it has required
After something is involving, it has involved
After something is reducing, it has reduced
After something is adding, it has added
After something is performing, it has performed
After something is providing, it has provided
After something is asking, it has
2024-07-30 01:20:25 root INFO     [order_1_approx] starting weight calculation for After something is performing, it has performed
After something is requiring, it has required
After something is providing, it has provided
After something is involving, it has involved
After something is asking, it has asked
After something is adding, it has added
After something is reducing, it has reduced
After something is continuing, it has
2024-07-30 01:20:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 01:22:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7378, -0.3420, -0.0388,  ..., -0.2103, -0.3125,  0.3491],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1992, -1.5381,  3.2188,  ..., -1.7930,  0.8242, -2.0430],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0503,  0.0022,  0.0112,  ...,  0.0099, -0.0031,  0.0234],
        [ 0.0035,  0.0565,  0.0024,  ...,  0.0122,  0.0035,  0.0183],
        [-0.0092,  0.0112,  0.0195,  ..., -0.0071,  0.0013, -0.0164],
        ...,
        [ 0.0125,  0.0121,  0.0133,  ...,  0.0543,  0.0036,  0.0073],
        [ 0.0072,  0.0153, -0.0158,  ..., -0.0044,  0.0232, -0.0168],
        [-0.0152,  0.0159,  0.0088,  ..., -0.0092, -0.0201,  0.0208]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1406, -1.3389,  3.0332,  ..., -1.6172,  0.6777, -2.1660]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 01:22:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is performing, it has performed
After something is requiring, it has required
After something is providing, it has provided
After something is involving, it has involved
After something is asking, it has asked
After something is adding, it has added
After something is reducing, it has reduced
After something is continuing, it has
2024-07-30 01:22:39 root INFO     [order_1_approx] starting weight calculation for After something is reducing, it has reduced
After something is providing, it has provided
After something is involving, it has involved
After something is continuing, it has continued
After something is requiring, it has required
After something is adding, it has added
After something is asking, it has asked
After something is performing, it has
2024-07-30 01:22:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 01:24:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2944, -0.1908, -0.3560,  ..., -0.1957, -0.0585, -0.3835],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8135, -0.4575,  3.8047,  ..., -2.0840, -2.1484, -1.0244],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0493, -0.0017,  0.0205,  ...,  0.0129, -0.0096,  0.0123],
        [-0.0359,  0.0650,  0.0016,  ...,  0.0041,  0.0243,  0.0132],
        [ 0.0064, -0.0075,  0.0349,  ...,  0.0066,  0.0173, -0.0108],
        ...,
        [ 0.0075,  0.0033, -0.0104,  ...,  0.0556,  0.0226,  0.0068],
        [ 0.0234, -0.0108,  0.0024,  ...,  0.0054,  0.0174, -0.0165],
        [ 0.0026,  0.0099,  0.0095,  ..., -0.0067, -0.0136,  0.0293]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7441, -0.3914,  3.9258,  ..., -1.7285, -1.7236, -0.6055]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 01:24:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is reducing, it has reduced
After something is providing, it has provided
After something is involving, it has involved
After something is continuing, it has continued
After something is requiring, it has required
After something is adding, it has added
After something is asking, it has asked
After something is performing, it has
2024-07-30 01:24:50 root INFO     [order_1_approx] starting weight calculation for After something is performing, it has performed
After something is providing, it has provided
After something is continuing, it has continued
After something is reducing, it has reduced
After something is requiring, it has required
After something is involving, it has involved
After something is asking, it has asked
After something is adding, it has
2024-07-30 01:24:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 01:27:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0746, -0.6538,  0.1986,  ..., -0.1465,  0.1827, -0.1581],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6875,  1.5645,  0.5874,  ..., -0.6455, -3.3262, -1.1875],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0767, -0.0114,  0.0170,  ..., -0.0080, -0.0191,  0.0007],
        [-0.0248,  0.0711,  0.0047,  ...,  0.0328,  0.0135,  0.0028],
        [ 0.0060, -0.0138,  0.0333,  ...,  0.0083, -0.0052,  0.0028],
        ...,
        [ 0.0248,  0.0311, -0.0220,  ...,  0.0565,  0.0320,  0.0197],
        [ 0.0319, -0.0014, -0.0129,  ..., -0.0166,  0.0558, -0.0167],
        [-0.0215,  0.0217,  0.0092,  ..., -0.0153, -0.0150,  0.0478]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6396,  1.3818,  0.7100,  ..., -0.6626, -3.2949, -1.2217]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 01:27:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is performing, it has performed
After something is providing, it has provided
After something is continuing, it has continued
After something is reducing, it has reduced
After something is requiring, it has required
After something is involving, it has involved
After something is asking, it has asked
After something is adding, it has
2024-07-30 01:27:04 root INFO     [order_1_approx] starting weight calculation for After something is continuing, it has continued
After something is reducing, it has reduced
After something is providing, it has provided
After something is involving, it has involved
After something is asking, it has asked
After something is performing, it has performed
After something is adding, it has added
After something is requiring, it has
2024-07-30 01:27:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 01:29:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2107,  0.0265, -0.2893,  ..., -0.3149, -0.2556, -0.3813],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4375,  0.2407,  2.0312,  ..., -1.5273, -2.2969, -2.1875],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0364, -0.0049,  0.0283,  ..., -0.0040,  0.0028,  0.0078],
        [-0.0342,  0.0368, -0.0271,  ..., -0.0051,  0.0180,  0.0111],
        [ 0.0011, -0.0161,  0.0282,  ..., -0.0204,  0.0115, -0.0150],
        ...,
        [ 0.0105,  0.0145,  0.0046,  ...,  0.0544, -0.0152,  0.0085],
        [ 0.0074,  0.0035,  0.0117,  ..., -0.0141,  0.0401, -0.0305],
        [-0.0147,  0.0023,  0.0019,  ..., -0.0061, -0.0008,  0.0242]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5342,  0.2238,  2.2168,  ..., -1.2656, -2.0098, -1.9297]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 01:29:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is continuing, it has continued
After something is reducing, it has reduced
After something is providing, it has provided
After something is involving, it has involved
After something is asking, it has asked
After something is performing, it has performed
After something is adding, it has added
After something is requiring, it has
2024-07-30 01:29:17 root INFO     total operator prediction time: 1057.669674873352 seconds
2024-07-30 01:29:17 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on Ving - verb_inf
2024-07-30 01:29:17 root INFO     building operator Ving - verb_inf
2024-07-30 01:29:18 root INFO     [order_1_approx] starting weight calculation for receiving is the active form of receive
spending is the active form of spend
continuing is the active form of continue
enjoying is the active form of enjoy
preventing is the active form of prevent
operating is the active form of operate
considering is the active form of consider
avoiding is the active form of
2024-07-30 01:29:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 01:31:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2100, -0.5244, -0.1245,  ..., -0.2605,  0.4695,  0.1967],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9893, -3.7539, -2.0898,  ...,  3.1875, -1.2500, -2.1875],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.0823e-02, -1.5583e-03,  1.5320e-02,  ...,  1.0559e-02,
          2.0733e-03,  1.2314e-02],
        [-8.2827e-04,  3.8147e-02, -3.8128e-03,  ...,  9.9182e-03,
         -4.8294e-03, -2.0828e-03],
        [ 1.7563e-02, -5.8327e-03,  2.1210e-02,  ..., -6.1493e-03,
         -4.5166e-03,  2.8534e-03],
        ...,
        [ 1.4000e-02,  2.2411e-05, -6.2904e-03,  ...,  2.8534e-02,
         -2.5234e-03,  3.9749e-03],
        [ 5.7602e-03,  6.0120e-03,  3.8319e-03,  ...,  9.5139e-03,
          2.1881e-02, -2.2583e-03],
        [ 2.6875e-03,  7.5607e-03,  8.3637e-04,  ..., -3.4256e-03,
         -4.3411e-03,  2.0004e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9253, -3.8457, -2.1328,  ...,  3.2812, -1.3477, -2.1992]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 01:31:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for receiving is the active form of receive
spending is the active form of spend
continuing is the active form of continue
enjoying is the active form of enjoy
preventing is the active form of prevent
operating is the active form of operate
considering is the active form of consider
avoiding is the active form of
2024-07-30 01:31:31 root INFO     [order_1_approx] starting weight calculation for operating is the active form of operate
preventing is the active form of prevent
spending is the active form of spend
continuing is the active form of continue
receiving is the active form of receive
enjoying is the active form of enjoy
avoiding is the active form of avoid
considering is the active form of
2024-07-30 01:31:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 01:33:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3152, -0.2964,  0.3047,  ...,  0.0861,  0.2942, -0.2380],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7979, -4.4336,  1.5361,  ..., -0.3994, -1.0273, -2.3965],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0493, -0.0011,  0.0101,  ...,  0.0047,  0.0016,  0.0122],
        [-0.0051,  0.0307, -0.0025,  ...,  0.0063,  0.0018,  0.0014],
        [ 0.0121, -0.0059,  0.0244,  ..., -0.0030, -0.0057, -0.0071],
        ...,
        [ 0.0023,  0.0011,  0.0002,  ...,  0.0381,  0.0005, -0.0023],
        [ 0.0076,  0.0092,  0.0072,  ...,  0.0041,  0.0194,  0.0027],
        [ 0.0074,  0.0015, -0.0031,  ..., -0.0102, -0.0126,  0.0290]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7559, -4.2656,  1.3906,  ..., -0.0457, -1.2051, -2.2422]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 01:34:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for operating is the active form of operate
preventing is the active form of prevent
spending is the active form of spend
continuing is the active form of continue
receiving is the active form of receive
enjoying is the active form of enjoy
avoiding is the active form of avoid
considering is the active form of
2024-07-30 01:34:05 root INFO     [order_1_approx] starting weight calculation for considering is the active form of consider
enjoying is the active form of enjoy
receiving is the active form of receive
avoiding is the active form of avoid
operating is the active form of operate
continuing is the active form of continue
preventing is the active form of prevent
spending is the active form of
2024-07-30 01:34:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 01:36:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0176, -0.0374,  0.3506,  ..., -0.0564, -0.0223, -0.0969],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9062, -2.1602, -2.6211,  ...,  0.4209, -0.8818, -1.5938],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0869,  0.0070,  0.0106,  ...,  0.0051,  0.0104,  0.0218],
        [ 0.0052,  0.0465, -0.0042,  ...,  0.0171,  0.0001, -0.0049],
        [ 0.0227, -0.0033,  0.0409,  ..., -0.0050, -0.0184, -0.0264],
        ...,
        [-0.0001,  0.0147, -0.0064,  ...,  0.0583,  0.0064, -0.0131],
        [-0.0075, -0.0024, -0.0014,  ..., -0.0040,  0.0375, -0.0198],
        [-0.0034,  0.0024, -0.0131,  ..., -0.0041, -0.0143,  0.0612]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8281, -2.2441, -2.8398,  ...,  0.6348, -0.7993, -1.8418]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 01:36:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for considering is the active form of consider
enjoying is the active form of enjoy
receiving is the active form of receive
avoiding is the active form of avoid
operating is the active form of operate
continuing is the active form of continue
preventing is the active form of prevent
spending is the active form of
2024-07-30 01:36:18 root INFO     [order_1_approx] starting weight calculation for avoiding is the active form of avoid
receiving is the active form of receive
enjoying is the active form of enjoy
considering is the active form of consider
spending is the active form of spend
operating is the active form of operate
preventing is the active form of prevent
continuing is the active form of
2024-07-30 01:36:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 01:38:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5791, -0.2529, -0.1760,  ...,  0.0168, -0.2874,  0.2068],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4443, -3.5938,  1.1504,  ...,  1.4961,  0.8486, -1.8926],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0522, -0.0032,  0.0041,  ..., -0.0009, -0.0046,  0.0190],
        [-0.0012,  0.0438,  0.0018,  ...,  0.0042,  0.0073, -0.0128],
        [ 0.0093, -0.0091,  0.0290,  ...,  0.0042, -0.0001,  0.0030],
        ...,
        [ 0.0073,  0.0053,  0.0007,  ...,  0.0388,  0.0040, -0.0007],
        [-0.0087,  0.0091,  0.0037,  ...,  0.0053,  0.0252, -0.0064],
        [-0.0049,  0.0110, -0.0170,  ..., -0.0126, -0.0070,  0.0282]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2847, -3.4648,  0.9258,  ...,  1.6191,  0.7476, -1.7705]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 01:38:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for avoiding is the active form of avoid
receiving is the active form of receive
enjoying is the active form of enjoy
considering is the active form of consider
spending is the active form of spend
operating is the active form of operate
preventing is the active form of prevent
continuing is the active form of
2024-07-30 01:38:31 root INFO     [order_1_approx] starting weight calculation for continuing is the active form of continue
spending is the active form of spend
enjoying is the active form of enjoy
avoiding is the active form of avoid
preventing is the active form of prevent
operating is the active form of operate
considering is the active form of consider
receiving is the active form of
2024-07-30 01:38:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 01:40:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3381, -0.0887,  0.0204,  ..., -0.2471,  0.1794,  0.0910],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3428, -3.3613, -2.1152,  ...,  0.2261, -0.1270, -3.1602],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0905, -0.0306,  0.0173,  ...,  0.0170,  0.0102,  0.0251],
        [-0.0052,  0.0726, -0.0130,  ...,  0.0137, -0.0039, -0.0038],
        [ 0.0108, -0.0043,  0.0443,  ..., -0.0144, -0.0073, -0.0026],
        ...,
        [ 0.0043,  0.0065, -0.0132,  ...,  0.0601, -0.0034, -0.0151],
        [-0.0160,  0.0043,  0.0005,  ..., -0.0196,  0.0449, -0.0034],
        [-0.0023,  0.0086, -0.0064,  ..., -0.0112, -0.0150,  0.0607]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1199, -3.5879, -2.3496,  ...,  0.5625, -0.0979, -3.0645]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 01:40:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for continuing is the active form of continue
spending is the active form of spend
enjoying is the active form of enjoy
avoiding is the active form of avoid
preventing is the active form of prevent
operating is the active form of operate
considering is the active form of consider
receiving is the active form of
2024-07-30 01:40:45 root INFO     [order_1_approx] starting weight calculation for spending is the active form of spend
considering is the active form of consider
avoiding is the active form of avoid
operating is the active form of operate
continuing is the active form of continue
enjoying is the active form of enjoy
receiving is the active form of receive
preventing is the active form of
2024-07-30 01:40:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 01:42:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1897, -0.4177,  0.0337,  ..., -0.3730,  0.3560, -0.3069],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8193, -3.7578, -1.8145,  ...,  2.0703, -0.8799, -2.2617],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0349, -0.0038,  0.0104,  ...,  0.0085, -0.0006,  0.0095],
        [-0.0033,  0.0312, -0.0050,  ...,  0.0067, -0.0014, -0.0035],
        [ 0.0118, -0.0105,  0.0225,  ..., -0.0018, -0.0044,  0.0012],
        ...,
        [ 0.0042, -0.0030, -0.0013,  ...,  0.0268, -0.0003, -0.0001],
        [ 0.0021, -0.0014, -0.0031,  ..., -0.0016,  0.0258, -0.0095],
        [-0.0025,  0.0046, -0.0023,  ...,  0.0003, -0.0035,  0.0251]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7412, -3.8047, -1.9355,  ...,  2.2773, -0.7803, -2.2832]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 01:42:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for spending is the active form of spend
considering is the active form of consider
avoiding is the active form of avoid
operating is the active form of operate
continuing is the active form of continue
enjoying is the active form of enjoy
receiving is the active form of receive
preventing is the active form of
2024-07-30 01:42:59 root INFO     [order_1_approx] starting weight calculation for operating is the active form of operate
considering is the active form of consider
avoiding is the active form of avoid
continuing is the active form of continue
spending is the active form of spend
receiving is the active form of receive
preventing is the active form of prevent
enjoying is the active form of
2024-07-30 01:42:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 01:45:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1273, -0.4187,  0.3103,  ..., -0.3901,  0.0295,  0.1274],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5293, -3.0781, -1.0020,  ...,  1.4316, -2.3867, -2.6289],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0768, -0.0094,  0.0052,  ...,  0.0088,  0.0082,  0.0208],
        [ 0.0011,  0.0554, -0.0136,  ...,  0.0109, -0.0028,  0.0055],
        [ 0.0123, -0.0134,  0.0439,  ...,  0.0036, -0.0072, -0.0216],
        ...,
        [-0.0033, -0.0031, -0.0094,  ...,  0.0445,  0.0008, -0.0194],
        [-0.0068,  0.0083,  0.0082,  ...,  0.0101,  0.0450, -0.0135],
        [ 0.0021,  0.0010, -0.0111,  ..., -0.0121, -0.0175,  0.0522]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4949, -3.1660, -1.2305,  ...,  1.6328, -2.2109, -2.4824]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 01:45:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for operating is the active form of operate
considering is the active form of consider
avoiding is the active form of avoid
continuing is the active form of continue
spending is the active form of spend
receiving is the active form of receive
preventing is the active form of prevent
enjoying is the active form of
2024-07-30 01:45:12 root INFO     [order_1_approx] starting weight calculation for preventing is the active form of prevent
enjoying is the active form of enjoy
receiving is the active form of receive
spending is the active form of spend
continuing is the active form of continue
avoiding is the active form of avoid
considering is the active form of consider
operating is the active form of
2024-07-30 01:45:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 01:47:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2903, -0.0186, -0.3594,  ...,  0.0036, -0.3428, -0.2781],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0742, -4.6172,  1.0859,  ...,  1.7002, -0.1766, -1.5371],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0576,  0.0045,  0.0053,  ...,  0.0011, -0.0013,  0.0149],
        [-0.0056,  0.0429,  0.0083,  ...,  0.0129,  0.0043, -0.0083],
        [ 0.0169,  0.0003,  0.0334,  ...,  0.0017,  0.0025,  0.0046],
        ...,
        [ 0.0009,  0.0136, -0.0115,  ...,  0.0383,  0.0013, -0.0050],
        [ 0.0064,  0.0061, -0.0019,  ..., -0.0034,  0.0299, -0.0107],
        [ 0.0044, -0.0006, -0.0011,  ..., -0.0018, -0.0151,  0.0431]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9453, -4.3320,  0.6982,  ...,  1.8721, -0.1473, -1.5293]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 01:47:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for preventing is the active form of prevent
enjoying is the active form of enjoy
receiving is the active form of receive
spending is the active form of spend
continuing is the active form of continue
avoiding is the active form of avoid
considering is the active form of consider
operating is the active form of
2024-07-30 01:47:26 root INFO     total operator prediction time: 1088.8972780704498 seconds
2024-07-30 01:47:26 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun - plural_irreg
2024-07-30 01:47:26 root INFO     building operator noun - plural_irreg
2024-07-30 01:47:26 root INFO     [order_1_approx] starting weight calculation for The plural form of county is counties
The plural form of academy is academies
The plural form of business is businesses
The plural form of community is communities
The plural form of safety is safeties
The plural form of entry is entries
The plural form of opportunity is opportunities
The plural form of army is
2024-07-30 01:47:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 01:49:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0402,  0.0864, -0.2352,  ..., -0.3306, -0.4585, -0.0139],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0742, -5.0469,  2.1094,  ..., -1.9902, -1.0312, -2.5664],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0679,  0.0093,  0.0124,  ..., -0.0187, -0.0104, -0.0132],
        [ 0.0155,  0.0806,  0.0119,  ...,  0.0159,  0.0024,  0.0097],
        [ 0.0192, -0.0019,  0.0460,  ..., -0.0169,  0.0070,  0.0141],
        ...,
        [ 0.0122,  0.0083,  0.0250,  ...,  0.0643,  0.0133,  0.0034],
        [-0.0371,  0.0241, -0.0173,  ..., -0.0064,  0.0316, -0.0211],
        [ 0.0040, -0.0125,  0.0028,  ..., -0.0025, -0.0021,  0.0736]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8945, -4.4688,  1.7129,  ..., -1.8955, -0.5210, -1.9570]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 01:49:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of county is counties
The plural form of academy is academies
The plural form of business is businesses
The plural form of community is communities
The plural form of safety is safeties
The plural form of entry is entries
The plural form of opportunity is opportunities
The plural form of army is
2024-07-30 01:49:40 root INFO     [order_1_approx] starting weight calculation for The plural form of county is counties
The plural form of academy is academies
The plural form of opportunity is opportunities
The plural form of entry is entries
The plural form of army is armies
The plural form of business is businesses
The plural form of community is communities
The plural form of safety is
2024-07-30 01:49:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 01:51:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1149, -0.0698, -0.1831,  ...,  0.0800,  0.0077, -0.1833],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2461, -0.3984,  0.3372,  ..., -0.4629, -3.6484, -2.9238],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0940, -0.0028, -0.0085,  ...,  0.0135, -0.0268,  0.0092],
        [-0.0141,  0.0701,  0.0041,  ...,  0.0121,  0.0068, -0.0016],
        [ 0.0141,  0.0189,  0.0875,  ...,  0.0105,  0.0063,  0.0083],
        ...,
        [ 0.0039,  0.0131,  0.0066,  ...,  0.0776, -0.0049,  0.0167],
        [-0.0143,  0.0281, -0.0027,  ..., -0.0012,  0.0300, -0.0096],
        [-0.0113,  0.0082,  0.0101,  ...,  0.0138,  0.0071,  0.0704]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0449, -0.9761,  0.6289,  ..., -0.8364, -3.3047, -2.3555]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 01:51:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of county is counties
The plural form of academy is academies
The plural form of opportunity is opportunities
The plural form of entry is entries
The plural form of army is armies
The plural form of business is businesses
The plural form of community is communities
The plural form of safety is
2024-07-30 01:51:53 root INFO     [order_1_approx] starting weight calculation for The plural form of county is counties
The plural form of army is armies
The plural form of entry is entries
The plural form of opportunity is opportunities
The plural form of community is communities
The plural form of business is businesses
The plural form of safety is safeties
The plural form of academy is
2024-07-30 01:51:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 01:54:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1759,  0.5234, -0.7544,  ...,  0.1470, -0.3286, -0.0455],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4102, -1.1582,  1.6699,  ...,  1.7393, -2.2656, -1.8809],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0675, -0.0054, -0.0018,  ..., -0.0185,  0.0057, -0.0163],
        [-0.0095,  0.1036, -0.0009,  ..., -0.0015, -0.0152,  0.0160],
        [ 0.0129,  0.0105,  0.0884,  ..., -0.0066, -0.0043,  0.0103],
        ...,
        [ 0.0059,  0.0122,  0.0013,  ...,  0.0883, -0.0204, -0.0115],
        [-0.0295,  0.0362,  0.0118,  ...,  0.0171,  0.0618, -0.0174],
        [ 0.0178, -0.0283, -0.0377,  ..., -0.0216, -0.0031,  0.0990]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8267, -1.3750,  1.1074,  ...,  1.8779, -2.2285, -1.6152]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 01:54:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of county is counties
The plural form of army is armies
The plural form of entry is entries
The plural form of opportunity is opportunities
The plural form of community is communities
The plural form of business is businesses
The plural form of safety is safeties
The plural form of academy is
2024-07-30 01:54:07 root INFO     [order_1_approx] starting weight calculation for The plural form of academy is academies
The plural form of county is counties
The plural form of army is armies
The plural form of entry is entries
The plural form of community is communities
The plural form of opportunity is opportunities
The plural form of safety is safeties
The plural form of business is
2024-07-30 01:54:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 01:56:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0576,  0.3875,  0.2123,  ..., -0.0114, -0.3257, -0.2671],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9805, -2.2578, -1.0000,  ...,  0.3018, -0.0098, -2.2188],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0573,  0.0186, -0.0263,  ..., -0.0144, -0.0159,  0.0224],
        [-0.0029,  0.0511,  0.0221,  ...,  0.0388, -0.0033,  0.0102],
        [ 0.0118,  0.0041,  0.0675,  ...,  0.0139,  0.0209,  0.0213],
        ...,
        [ 0.0138, -0.0037,  0.0071,  ...,  0.0721,  0.0114,  0.0040],
        [-0.0248,  0.0260, -0.0285,  ...,  0.0045,  0.0392,  0.0011],
        [-0.0048,  0.0047,  0.0008,  ..., -0.0115, -0.0052,  0.0648]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9863, -2.2520, -1.0420,  ...,  0.1298,  0.0986, -2.2617]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 01:56:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of academy is academies
The plural form of county is counties
The plural form of army is armies
The plural form of entry is entries
The plural form of community is communities
The plural form of opportunity is opportunities
The plural form of safety is safeties
The plural form of business is
2024-07-30 01:56:20 root INFO     [order_1_approx] starting weight calculation for The plural form of academy is academies
The plural form of community is communities
The plural form of army is armies
The plural form of business is businesses
The plural form of safety is safeties
The plural form of county is counties
The plural form of entry is entries
The plural form of opportunity is
2024-07-30 01:56:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 01:58:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4390,  0.1609, -0.0791,  ..., -0.2263, -0.3306, -0.1974],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0845, -0.1152, -1.1826,  ..., -0.4319, -1.7549, -0.3076],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0668, -0.0149,  0.0256,  ...,  0.0059, -0.0026, -0.0039],
        [-0.0078,  0.0629, -0.0154,  ...,  0.0171, -0.0020,  0.0173],
        [ 0.0156,  0.0052,  0.0344,  ..., -0.0017, -0.0303, -0.0013],
        ...,
        [-0.0051,  0.0121,  0.0068,  ...,  0.0510, -0.0021,  0.0361],
        [-0.0198,  0.0273, -0.0068,  ..., -0.0141,  0.0492,  0.0100],
        [-0.0105, -0.0143, -0.0286,  ...,  0.0092,  0.0007,  0.0693]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3184, -0.4758, -1.0371,  ..., -1.0586, -2.3555, -0.5225]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 01:58:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of academy is academies
The plural form of community is communities
The plural form of army is armies
The plural form of business is businesses
The plural form of safety is safeties
The plural form of county is counties
The plural form of entry is entries
The plural form of opportunity is
2024-07-30 01:58:34 root INFO     [order_1_approx] starting weight calculation for The plural form of army is armies
The plural form of safety is safeties
The plural form of community is communities
The plural form of academy is academies
The plural form of opportunity is opportunities
The plural form of business is businesses
The plural form of entry is entries
The plural form of county is
2024-07-30 01:58:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 02:00:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2966,  0.0034, -0.3149,  ..., -0.0370,  0.0394, -0.0466],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2874, -4.5234,  2.4805,  ..., -2.3047,  2.2383, -3.2363],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0541, -0.0003,  0.0036,  ..., -0.0126, -0.0208,  0.0130],
        [-0.0112,  0.0477, -0.0076,  ..., -0.0084, -0.0005, -0.0058],
        [ 0.0163,  0.0104,  0.0687,  ...,  0.0050, -0.0031,  0.0121],
        ...,
        [-0.0089,  0.0062,  0.0014,  ...,  0.0388,  0.0132, -0.0059],
        [-0.0112,  0.0092,  0.0105,  ...,  0.0139,  0.0552, -0.0015],
        [-0.0061, -0.0068, -0.0187,  ..., -0.0028, -0.0115,  0.0423]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6035, -3.7012,  2.0820,  ..., -2.4375,  1.0010, -2.4922]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 02:00:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of army is armies
The plural form of safety is safeties
The plural form of community is communities
The plural form of academy is academies
The plural form of opportunity is opportunities
The plural form of business is businesses
The plural form of entry is entries
The plural form of county is
2024-07-30 02:00:47 root INFO     [order_1_approx] starting weight calculation for The plural form of opportunity is opportunities
The plural form of county is counties
The plural form of business is businesses
The plural form of army is armies
The plural form of safety is safeties
The plural form of academy is academies
The plural form of entry is entries
The plural form of community is
2024-07-30 02:00:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 02:02:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6396,  0.2749, -0.1575,  ...,  0.2305, -0.1260, -0.3018],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3477, -3.8281,  1.7188,  ..., -3.6680,  0.7617, -2.2383],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0699,  0.0091,  0.0047,  ...,  0.0184,  0.0169,  0.0057],
        [ 0.0090,  0.0483,  0.0045,  ...,  0.0071, -0.0003,  0.0002],
        [-0.0019,  0.0017,  0.0595,  ...,  0.0001,  0.0104,  0.0150],
        ...,
        [ 0.0169,  0.0097,  0.0158,  ...,  0.0649, -0.0198,  0.0186],
        [-0.0295,  0.0370, -0.0179,  ...,  0.0097,  0.0604,  0.0046],
        [ 0.0090, -0.0009, -0.0185,  ..., -0.0057, -0.0023,  0.0542]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9785, -3.2695,  1.1816,  ..., -3.1348,  0.0439, -2.1758]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 02:03:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of opportunity is opportunities
The plural form of county is counties
The plural form of business is businesses
The plural form of army is armies
The plural form of safety is safeties
The plural form of academy is academies
The plural form of entry is entries
The plural form of community is
2024-07-30 02:03:00 root INFO     [order_1_approx] starting weight calculation for The plural form of safety is safeties
The plural form of business is businesses
The plural form of community is communities
The plural form of army is armies
The plural form of opportunity is opportunities
The plural form of academy is academies
The plural form of county is counties
The plural form of entry is
2024-07-30 02:03:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 02:05:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1017, -0.0280, -0.3376,  ...,  0.0719,  0.0190, -0.0247],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6445, -1.3477, -0.8193,  ..., -1.0000, -4.4727, -3.8340],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.1523e-01,  6.4850e-03,  2.0248e-02,  ..., -1.3710e-02,
          9.9945e-03, -1.0666e-02],
        [-1.0406e-02,  9.9915e-02, -4.3869e-05,  ...,  4.0894e-02,
          3.7670e-03,  6.8207e-03],
        [ 3.8147e-05, -9.1476e-03,  9.2529e-02,  ..., -7.7095e-03,
         -5.4092e-03,  4.0558e-02],
        ...,
        [ 1.4839e-03,  5.9700e-04, -6.5079e-03,  ...,  9.3628e-02,
          2.1973e-03,  3.0426e-02],
        [-9.0866e-03,  1.3344e-02, -7.3662e-03,  ...,  1.5965e-03,
          5.8075e-02,  2.0275e-03],
        [-3.5934e-03,  3.4752e-03,  9.1629e-03,  ..., -1.4809e-02,
         -1.2604e-02,  7.5134e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7363, -1.3369, -0.9893,  ..., -1.6602, -4.1133, -3.1953]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 02:05:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of safety is safeties
The plural form of business is businesses
The plural form of community is communities
The plural form of army is armies
The plural form of opportunity is opportunities
The plural form of academy is academies
The plural form of county is counties
The plural form of entry is
2024-07-30 02:05:13 root INFO     total operator prediction time: 1066.8850691318512 seconds
2024-07-30 02:05:13 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - member
2024-07-30 02:05:13 root INFO     building operator meronyms - member
2024-07-30 02:05:13 root INFO     [order_1_approx] starting weight calculation for A shrub is a member of a shrubbery
A letter is a member of a alphabet
A listener is a member of a audience
A employee is a member of a staff
A cat is a member of a clowder
A kitten is a member of a litter
A sheep is a member of a flock
A player is a member of a
2024-07-30 02:05:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 02:07:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1957,  0.0776,  0.1389,  ...,  0.1847, -0.3992, -0.3303],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4902, -5.9102,  0.4919,  ..., -1.0156, -0.9141, -3.9121],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0533,  0.0070, -0.0113,  ...,  0.0161, -0.0253,  0.0063],
        [ 0.0038,  0.0410,  0.0137,  ...,  0.0211,  0.0143, -0.0046],
        [ 0.0267,  0.0014,  0.0362,  ..., -0.0223,  0.0112,  0.0049],
        ...,
        [-0.0026,  0.0163,  0.0067,  ...,  0.0804, -0.0025, -0.0171],
        [ 0.0049, -0.0089,  0.0044,  ..., -0.0035,  0.0773, -0.0021],
        [ 0.0107, -0.0205, -0.0066,  ...,  0.0021, -0.0125,  0.0532]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5137, -5.5664,  0.6118,  ..., -0.3110, -0.9268, -3.1582]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 02:07:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A shrub is a member of a shrubbery
A letter is a member of a alphabet
A listener is a member of a audience
A employee is a member of a staff
A cat is a member of a clowder
A kitten is a member of a litter
A sheep is a member of a flock
A player is a member of a
2024-07-30 02:07:42 root INFO     [order_1_approx] starting weight calculation for A shrub is a member of a shrubbery
A employee is a member of a staff
A listener is a member of a audience
A cat is a member of a clowder
A player is a member of a team
A kitten is a member of a litter
A letter is a member of a alphabet
A sheep is a member of a
2024-07-30 02:07:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 02:09:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3567, -0.1696,  0.1599,  ...,  0.3821, -0.2761,  0.6279],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.8672,  1.5742,  2.7578,  ..., -0.6221, -3.5332, -0.5107],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0627,  0.0001,  0.0188,  ...,  0.0027, -0.0135, -0.0110],
        [ 0.0067,  0.0649,  0.0001,  ...,  0.0237, -0.0150, -0.0320],
        [ 0.0064, -0.0017,  0.0556,  ...,  0.0062,  0.0067, -0.0137],
        ...,
        [ 0.0069,  0.0111,  0.0011,  ...,  0.0587, -0.0074, -0.0262],
        [-0.0170,  0.0214,  0.0055,  ..., -0.0018,  0.0505, -0.0047],
        [-0.0135, -0.0092, -0.0077,  ..., -0.0184, -0.0067,  0.0457]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.0703,  1.5430,  2.3984,  ..., -0.7793, -4.0391, -0.6006]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 02:09:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A shrub is a member of a shrubbery
A employee is a member of a staff
A listener is a member of a audience
A cat is a member of a clowder
A player is a member of a team
A kitten is a member of a litter
A letter is a member of a alphabet
A sheep is a member of a
2024-07-30 02:09:55 root INFO     [order_1_approx] starting weight calculation for A player is a member of a team
A letter is a member of a alphabet
A listener is a member of a audience
A kitten is a member of a litter
A shrub is a member of a shrubbery
A sheep is a member of a flock
A employee is a member of a staff
A cat is a member of a
2024-07-30 02:09:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 02:12:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0245, -0.3701,  0.5474,  ...,  0.0981, -0.4241,  0.0315],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4609, -2.9648,  1.6943,  ..., -2.6289, -0.7998, -1.7646],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0328,  0.0231, -0.0056,  ...,  0.0190, -0.0241,  0.0082],
        [ 0.0152,  0.0370,  0.0065,  ...,  0.0017,  0.0218, -0.0091],
        [-0.0140, -0.0118,  0.0603,  ..., -0.0098, -0.0014,  0.0008],
        ...,
        [ 0.0021, -0.0085,  0.0108,  ...,  0.0318,  0.0282, -0.0294],
        [ 0.0281,  0.0097, -0.0226,  ...,  0.0157,  0.0414, -0.0155],
        [-0.0094, -0.0155, -0.0086,  ..., -0.0188,  0.0128,  0.0552]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7188, -3.0293,  1.9648,  ..., -2.3574, -1.1514, -1.4971]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 02:12:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A player is a member of a team
A letter is a member of a alphabet
A listener is a member of a audience
A kitten is a member of a litter
A shrub is a member of a shrubbery
A sheep is a member of a flock
A employee is a member of a staff
A cat is a member of a
2024-07-30 02:12:08 root INFO     [order_1_approx] starting weight calculation for A letter is a member of a alphabet
A sheep is a member of a flock
A player is a member of a team
A employee is a member of a staff
A cat is a member of a clowder
A listener is a member of a audience
A kitten is a member of a litter
A shrub is a member of a
2024-07-30 02:12:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 02:14:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3005, -0.0071,  0.1925,  ...,  0.0299, -0.3740, -0.2739],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9629, -3.3750,  0.8335,  ..., -2.6836, -1.5742, -2.6680],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0439, -0.0340, -0.0073,  ...,  0.0074, -0.0182,  0.0026],
        [ 0.0069,  0.0287,  0.0102,  ...,  0.0375,  0.0089, -0.0118],
        [-0.0173,  0.0035,  0.0709,  ..., -0.0364,  0.0074, -0.0018],
        ...,
        [-0.0045,  0.0090,  0.0098,  ...,  0.1002,  0.0183, -0.0118],
        [-0.0027,  0.0059, -0.0010,  ...,  0.0143,  0.0576,  0.0093],
        [-0.0354, -0.0284,  0.0051,  ..., -0.0221, -0.0304,  0.0612]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2334, -3.2891,  0.9390,  ..., -2.2656, -1.8662, -2.3301]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 02:14:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A letter is a member of a alphabet
A sheep is a member of a flock
A player is a member of a team
A employee is a member of a staff
A cat is a member of a clowder
A listener is a member of a audience
A kitten is a member of a litter
A shrub is a member of a
2024-07-30 02:14:21 root INFO     [order_1_approx] starting weight calculation for A listener is a member of a audience
A cat is a member of a clowder
A player is a member of a team
A letter is a member of a alphabet
A kitten is a member of a litter
A sheep is a member of a flock
A shrub is a member of a shrubbery
A employee is a member of a
2024-07-30 02:14:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 02:16:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4343,  0.0895, -0.6924,  ...,  0.1990, -0.3020, -0.1808],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3906, -5.0898,  4.1133,  ..., -2.7305,  1.8906, -3.9492],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0453,  0.0094,  0.0051,  ...,  0.0177, -0.0043,  0.0170],
        [-0.0229,  0.0460,  0.0202,  ...,  0.0173,  0.0007,  0.0207],
        [ 0.0081,  0.0054,  0.0452,  ..., -0.0057,  0.0113,  0.0015],
        ...,
        [-0.0024,  0.0166,  0.0092,  ...,  0.0444, -0.0090,  0.0049],
        [-0.0120,  0.0003, -0.0100,  ...,  0.0071,  0.0438, -0.0062],
        [-0.0008, -0.0134, -0.0067,  ...,  0.0072, -0.0154,  0.0817]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1895, -5.5664,  3.9062,  ..., -2.4727,  1.8584, -4.0391]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 02:16:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A listener is a member of a audience
A cat is a member of a clowder
A player is a member of a team
A letter is a member of a alphabet
A kitten is a member of a litter
A sheep is a member of a flock
A shrub is a member of a shrubbery
A employee is a member of a
2024-07-30 02:16:32 root INFO     [order_1_approx] starting weight calculation for A listener is a member of a audience
A cat is a member of a clowder
A employee is a member of a staff
A kitten is a member of a litter
A sheep is a member of a flock
A shrub is a member of a shrubbery
A player is a member of a team
A letter is a member of a
2024-07-30 02:16:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 02:18:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1951, -0.1670, -0.3960,  ...,  0.2913, -0.0204, -0.1637],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7612, -1.4570,  0.6421,  ...,  1.5518, -2.9238, -1.5605],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1292,  0.0042, -0.0218,  ..., -0.0085,  0.0111,  0.0149],
        [-0.0236,  0.0767,  0.0141,  ...,  0.0139, -0.0204,  0.0010],
        [ 0.0144, -0.0400,  0.0969,  ...,  0.0284, -0.0102,  0.0055],
        ...,
        [ 0.0054,  0.0140, -0.0087,  ...,  0.0820,  0.0166, -0.0081],
        [-0.0039, -0.0017, -0.0084,  ...,  0.0224,  0.0704, -0.0111],
        [-0.0037, -0.0060,  0.0275,  ...,  0.0146,  0.0150,  0.1046]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2393, -2.0449,  1.1680,  ...,  0.6265, -2.7051, -1.3809]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 02:18:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A listener is a member of a audience
A cat is a member of a clowder
A employee is a member of a staff
A kitten is a member of a litter
A sheep is a member of a flock
A shrub is a member of a shrubbery
A player is a member of a team
A letter is a member of a
2024-07-30 02:18:45 root INFO     [order_1_approx] starting weight calculation for A shrub is a member of a shrubbery
A player is a member of a team
A employee is a member of a staff
A cat is a member of a clowder
A sheep is a member of a flock
A kitten is a member of a litter
A letter is a member of a alphabet
A listener is a member of a
2024-07-30 02:18:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 02:20:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0205, -0.2646, -0.1206,  ...,  0.3923,  0.0817,  0.0587],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0938, -3.7188,  1.5088,  ...,  1.6797, -3.6660, -2.5117],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0569, -0.0045,  0.0021,  ...,  0.0302, -0.0122,  0.0143],
        [-0.0052,  0.0308, -0.0099,  ...,  0.0006, -0.0024, -0.0278],
        [ 0.0016, -0.0103,  0.0630,  ..., -0.0060,  0.0038,  0.0019],
        ...,
        [ 0.0126,  0.0170,  0.0151,  ...,  0.0666,  0.0178, -0.0181],
        [ 0.0190,  0.0223, -0.0018,  ..., -0.0072,  0.0546,  0.0017],
        [ 0.0041, -0.0182, -0.0250,  ...,  0.0176,  0.0114,  0.0721]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4238, -3.5840,  1.2588,  ...,  1.8486, -3.6504, -1.8945]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 02:20:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A shrub is a member of a shrubbery
A player is a member of a team
A employee is a member of a staff
A cat is a member of a clowder
A sheep is a member of a flock
A kitten is a member of a litter
A letter is a member of a alphabet
A listener is a member of a
2024-07-30 02:20:58 root INFO     [order_1_approx] starting weight calculation for A cat is a member of a clowder
A sheep is a member of a flock
A player is a member of a team
A shrub is a member of a shrubbery
A employee is a member of a staff
A listener is a member of a audience
A letter is a member of a alphabet
A kitten is a member of a
2024-07-30 02:20:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 02:23:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0010, -0.2291, -0.1467,  ...,  0.3977, -0.6792,  0.2354],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.9570, -2.8223, -0.3989,  ..., -0.4932, -0.2461, -2.5156],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0407, -0.0082,  0.0133,  ...,  0.0130, -0.0161,  0.0145],
        [ 0.0021,  0.0569,  0.0039,  ...,  0.0030,  0.0040, -0.0211],
        [-0.0079, -0.0006,  0.0693,  ..., -0.0138, -0.0222,  0.0066],
        ...,
        [ 0.0020,  0.0055,  0.0051,  ...,  0.0465,  0.0097, -0.0276],
        [ 0.0214,  0.0078, -0.0202,  ...,  0.0106,  0.0478, -0.0202],
        [-0.0199, -0.0192,  0.0012,  ..., -0.0293, -0.0160,  0.0543]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.0625, -2.9062, -0.3975,  ..., -0.3325, -0.4907, -2.4219]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 02:23:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A cat is a member of a clowder
A sheep is a member of a flock
A player is a member of a team
A shrub is a member of a shrubbery
A employee is a member of a staff
A listener is a member of a audience
A letter is a member of a alphabet
A kitten is a member of a
2024-07-30 02:23:11 root INFO     total operator prediction time: 1078.1548020839691 seconds
2024-07-30 02:23:11 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on antonyms - binary
2024-07-30 02:23:11 root INFO     building operator antonyms - binary
2024-07-30 02:23:11 root INFO     [order_1_approx] starting weight calculation for The opposite of below is above
The opposite of forget is remember
The opposite of ahead is behind
The opposite of dive is emerge
The opposite of before is after
The opposite of top is bottom
The opposite of decrement is increment
The opposite of descend is
2024-07-30 02:23:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 02:25:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0015,  0.0500, -0.0991,  ..., -0.0085, -0.2382, -0.4434],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4395, -1.1523,  0.1484,  ...,  1.7363, -6.2305, -2.6406],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.7617e-02, -4.0649e-02,  2.2736e-02,  ...,  2.7588e-02,
          9.3689e-03,  8.0032e-03],
        [ 6.3400e-03,  7.6782e-02, -1.5762e-02,  ..., -2.4384e-02,
          2.9846e-02,  2.1027e-02],
        [-2.7420e-02, -1.3443e-02,  2.3712e-02,  ..., -2.5085e-02,
         -2.0294e-02, -1.4282e-02],
        ...,
        [ 1.4648e-02,  1.8280e-02,  1.3275e-03,  ...,  1.8768e-02,
          1.1696e-02, -5.4474e-03],
        [ 4.7302e-03, -1.1841e-02,  2.2934e-02,  ...,  7.6294e-06,
          9.6359e-03,  6.3705e-03],
        [-1.5083e-02,  7.7591e-03,  1.8463e-03,  ..., -3.3691e-02,
         -3.5515e-03,  4.6875e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5283, -0.7290,  0.0831,  ...,  1.0000, -5.4844, -2.4453]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 02:25:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of below is above
The opposite of forget is remember
The opposite of ahead is behind
The opposite of dive is emerge
The opposite of before is after
The opposite of top is bottom
The opposite of decrement is increment
The opposite of descend is
2024-07-30 02:25:24 root INFO     [order_1_approx] starting weight calculation for The opposite of ahead is behind
The opposite of decrement is increment
The opposite of top is bottom
The opposite of dive is emerge
The opposite of descend is ascend
The opposite of forget is remember
The opposite of below is above
The opposite of before is
2024-07-30 02:25:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 02:27:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1044,  0.0656, -0.1589,  ..., -0.4521, -0.1338, -0.1549],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0820, -2.1484, -0.9541,  ...,  0.1802, -1.9922, -3.4609],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0779, -0.0228,  0.0289,  ...,  0.0132,  0.0185,  0.0273],
        [-0.0092,  0.0698, -0.0171,  ...,  0.0391, -0.0005, -0.0040],
        [ 0.0040, -0.0182,  0.0256,  ..., -0.0002, -0.0015, -0.0079],
        ...,
        [-0.0135, -0.0042, -0.0051,  ...,  0.0604,  0.0214, -0.0181],
        [-0.0026,  0.0099,  0.0236,  ..., -0.0062,  0.0419,  0.0197],
        [-0.0200, -0.0091, -0.0208,  ..., -0.0140,  0.0088,  0.0486]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3398, -1.9727, -0.7383,  ..., -0.4736, -2.1602, -2.7480]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 02:27:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of ahead is behind
The opposite of decrement is increment
The opposite of top is bottom
The opposite of dive is emerge
The opposite of descend is ascend
The opposite of forget is remember
The opposite of below is above
The opposite of before is
2024-07-30 02:27:37 root INFO     [order_1_approx] starting weight calculation for The opposite of top is bottom
The opposite of decrement is increment
The opposite of before is after
The opposite of descend is ascend
The opposite of ahead is behind
The opposite of dive is emerge
The opposite of below is above
The opposite of forget is
2024-07-30 02:27:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 02:29:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4038,  0.2590,  0.1826,  ..., -0.0790, -0.0494,  0.2126],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7109, -3.5625, -2.1113,  ..., -0.2451, -6.3320, -2.6836],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0640, -0.0113, -0.0133,  ...,  0.0257, -0.0265,  0.0019],
        [-0.0037,  0.0814, -0.0016,  ...,  0.0291, -0.0169, -0.0139],
        [-0.0064, -0.0274,  0.0495,  ..., -0.0077, -0.0171,  0.0189],
        ...,
        [ 0.0227,  0.0097,  0.0078,  ...,  0.0696,  0.0117, -0.0160],
        [-0.0179, -0.0148,  0.0082,  ..., -0.0106,  0.0550,  0.0260],
        [ 0.0033,  0.0447, -0.0031,  ...,  0.0208,  0.0002,  0.0680]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7622, -3.0781, -2.7441,  ...,  0.2356, -7.0117, -3.5000]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 02:29:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of top is bottom
The opposite of decrement is increment
The opposite of before is after
The opposite of descend is ascend
The opposite of ahead is behind
The opposite of dive is emerge
The opposite of below is above
The opposite of forget is
2024-07-30 02:29:50 root INFO     [order_1_approx] starting weight calculation for The opposite of forget is remember
The opposite of before is after
The opposite of dive is emerge
The opposite of top is bottom
The opposite of below is above
The opposite of decrement is increment
The opposite of descend is ascend
The opposite of ahead is
2024-07-30 02:29:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 02:32:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0685,  0.4155, -0.2443,  ...,  0.0304, -0.0647,  0.0147],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7910, -2.7383,  0.4526,  ..., -4.3477, -2.2910, -2.4922],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0773, -0.0091, -0.0010,  ...,  0.0501, -0.0006, -0.0213],
        [ 0.0083,  0.0612, -0.0100,  ...,  0.0054,  0.0143,  0.0032],
        [ 0.0041, -0.0181,  0.0174,  ...,  0.0029, -0.0392,  0.0056],
        ...,
        [ 0.0067,  0.0047,  0.0027,  ...,  0.0311,  0.0377, -0.0214],
        [-0.0068, -0.0266,  0.0486,  ..., -0.0143,  0.0563,  0.0271],
        [ 0.0033, -0.0165,  0.0030,  ...,  0.0048, -0.0041,  0.0181]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3730, -2.4141,  0.6411,  ..., -4.2773, -2.5879, -1.9141]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 02:32:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of forget is remember
The opposite of before is after
The opposite of dive is emerge
The opposite of top is bottom
The opposite of below is above
The opposite of decrement is increment
The opposite of descend is ascend
The opposite of ahead is
2024-07-30 02:32:03 root INFO     [order_1_approx] starting weight calculation for The opposite of decrement is increment
The opposite of ahead is behind
The opposite of dive is emerge
The opposite of forget is remember
The opposite of before is after
The opposite of top is bottom
The opposite of descend is ascend
The opposite of below is
2024-07-30 02:32:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 02:34:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2400, -0.4048,  0.1937,  ..., -0.2271,  0.0103, -0.3457],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5703, -2.0176,  0.6289,  ..., -0.0500,  1.6494, -1.0020],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 8.1055e-02, -3.0731e-02,  1.7883e-02,  ...,  2.1667e-02,
         -5.8632e-03, -1.1246e-02],
        [ 1.5366e-02,  8.7097e-02,  5.3101e-03,  ..., -3.5439e-03,
          1.4359e-02,  2.5787e-02],
        [-2.7084e-03, -8.2321e-03,  2.4857e-02,  ..., -2.9404e-02,
         -3.4607e-02,  9.8038e-03],
        ...,
        [-3.0479e-03,  2.6184e-02,  3.2883e-03,  ...,  3.5980e-02,
          1.5554e-03, -3.5286e-05],
        [ 4.7760e-03, -1.1887e-02,  7.1602e-03,  ..., -2.1759e-02,
          1.6510e-02,  6.4316e-03],
        [-1.8860e-02, -1.5678e-03,  2.1027e-02,  ..., -8.9569e-03,
          2.1378e-02,  6.3782e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7979, -1.9053,  0.6865,  ..., -0.3574,  1.4990, -1.1943]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 02:34:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of decrement is increment
The opposite of ahead is behind
The opposite of dive is emerge
The opposite of forget is remember
The opposite of before is after
The opposite of top is bottom
The opposite of descend is ascend
The opposite of below is
2024-07-30 02:34:16 root INFO     [order_1_approx] starting weight calculation for The opposite of descend is ascend
The opposite of before is after
The opposite of decrement is increment
The opposite of dive is emerge
The opposite of below is above
The opposite of ahead is behind
The opposite of forget is remember
The opposite of top is
2024-07-30 02:34:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 02:36:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2571, -0.2268,  0.2991,  ..., -0.1929, -0.0760,  0.0349],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0078, -1.8428, -0.6523,  ..., -2.3418,  1.7695, -4.2930],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0810, -0.0254,  0.0226,  ...,  0.0134,  0.0149,  0.0106],
        [ 0.0159,  0.0929, -0.0124,  ..., -0.0023,  0.0131, -0.0074],
        [ 0.0120,  0.0130,  0.0558,  ..., -0.0025, -0.0078,  0.0050],
        ...,
        [-0.0151,  0.0104, -0.0042,  ...,  0.0826,  0.0217,  0.0174],
        [-0.0037, -0.0369,  0.0098,  ..., -0.0241,  0.0457,  0.0448],
        [ 0.0161, -0.0194,  0.0153,  ..., -0.0058,  0.0105,  0.0472]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1387, -1.2070, -0.9014,  ..., -2.0898,  0.6650, -4.4375]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 02:36:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of descend is ascend
The opposite of before is after
The opposite of decrement is increment
The opposite of dive is emerge
The opposite of below is above
The opposite of ahead is behind
The opposite of forget is remember
The opposite of top is
2024-07-30 02:36:29 root INFO     [order_1_approx] starting weight calculation for The opposite of before is after
The opposite of dive is emerge
The opposite of ahead is behind
The opposite of forget is remember
The opposite of descend is ascend
The opposite of top is bottom
The opposite of below is above
The opposite of decrement is
2024-07-30 02:36:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 02:38:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1710,  0.4900, -0.0607,  ...,  0.1553, -0.2539, -0.1840],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0342, -0.7339, -1.0352,  ...,  0.6338, -2.5547, -1.0801],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0340, -0.0042, -0.0051,  ...,  0.0015, -0.0075,  0.0053],
        [-0.0051,  0.0686, -0.0078,  ...,  0.0405, -0.0124, -0.0284],
        [-0.0177, -0.0114,  0.0249,  ..., -0.0427, -0.0092,  0.0240],
        ...,
        [-0.0018,  0.0145, -0.0090,  ...,  0.0239,  0.0166,  0.0232],
        [ 0.0012,  0.0085,  0.0103,  ..., -0.0244,  0.0640,  0.0285],
        [ 0.0013,  0.0069, -0.0233,  ..., -0.0112,  0.0011,  0.0630]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2773, -1.0732, -1.1807,  ...,  0.2800, -2.9316, -1.2910]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 02:38:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of before is after
The opposite of dive is emerge
The opposite of ahead is behind
The opposite of forget is remember
The opposite of descend is ascend
The opposite of top is bottom
The opposite of below is above
The opposite of decrement is
2024-07-30 02:38:42 root INFO     [order_1_approx] starting weight calculation for The opposite of descend is ascend
The opposite of before is after
The opposite of below is above
The opposite of decrement is increment
The opposite of forget is remember
The opposite of ahead is behind
The opposite of top is bottom
The opposite of dive is
2024-07-30 02:38:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 02:40:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0613,  0.2007,  0.0642,  ...,  0.1255, -0.4219,  0.0417],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8730, -0.0977, -0.4541,  ...,  2.5879, -3.0586,  1.7490],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0589, -0.0434, -0.0033,  ...,  0.0269,  0.0199,  0.0163],
        [ 0.0158,  0.0712, -0.0202,  ...,  0.0191,  0.0150,  0.0226],
        [ 0.0039,  0.0052,  0.0256,  ..., -0.0084, -0.0330, -0.0197],
        ...,
        [-0.0050,  0.0195,  0.0214,  ...,  0.0348,  0.0136,  0.0205],
        [ 0.0055, -0.0099,  0.0269,  ..., -0.0324,  0.0202,  0.0212],
        [ 0.0042,  0.0234,  0.0020,  ..., -0.0413,  0.0056,  0.0356]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0059,  0.1158, -0.6367,  ...,  1.6973, -3.0156,  1.5391]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 02:41:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of descend is ascend
The opposite of before is after
The opposite of below is above
The opposite of decrement is increment
The opposite of forget is remember
The opposite of ahead is behind
The opposite of top is bottom
The opposite of dive is
2024-07-30 02:41:14 root INFO     total operator prediction time: 1082.7628681659698 seconds
2024-07-30 02:41:14 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hyponyms - misc
2024-07-30 02:41:14 root INFO     building operator hyponyms - misc
2024-07-30 02:41:14 root INFO     [order_1_approx] starting weight calculation for A more specific term for a seat is chair
A more specific term for a railway is monorail
A more specific term for a burger is hamburger
A more specific term for a tool is rake
A more specific term for a shirt is polo
A more specific term for a candy is lollipop
A more specific term for a backpack is daypack
A more specific term for a camera is
2024-07-30 02:41:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 02:43:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2378, -0.2422,  0.0337,  ..., -0.0545, -0.0008, -0.5298],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.4170, -3.3438,  0.9082,  ..., -0.1997,  1.5312, -0.6182],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0695,  0.0079,  0.0020,  ..., -0.0074, -0.0311, -0.0056],
        [ 0.0181,  0.0740, -0.0158,  ..., -0.0008,  0.0125, -0.0143],
        [-0.0137,  0.0077,  0.0800,  ..., -0.0045, -0.0071,  0.0036],
        ...,
        [ 0.0117, -0.0110, -0.0069,  ...,  0.0677,  0.0185,  0.0066],
        [-0.0305,  0.0073, -0.0145,  ..., -0.0083,  0.0594, -0.0230],
        [-0.0121,  0.0025, -0.0188,  ..., -0.0191, -0.0248,  0.0733]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6836, -3.1270,  1.1680,  ..., -0.3628,  1.8750, -0.6074]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 02:43:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a seat is chair
A more specific term for a railway is monorail
A more specific term for a burger is hamburger
A more specific term for a tool is rake
A more specific term for a shirt is polo
A more specific term for a candy is lollipop
A more specific term for a backpack is daypack
A more specific term for a camera is
2024-07-30 02:43:27 root INFO     [order_1_approx] starting weight calculation for A more specific term for a tool is rake
A more specific term for a candy is lollipop
A more specific term for a seat is chair
A more specific term for a burger is hamburger
A more specific term for a shirt is polo
A more specific term for a backpack is daypack
A more specific term for a camera is camcorder
A more specific term for a railway is
2024-07-30 02:43:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 02:45:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0789, -0.1365, -0.0553,  ...,  0.1848,  0.2566, -0.3782],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.9053, -7.4844,  2.6953,  ...,  2.3145, -1.1973,  0.6270],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0723, -0.0042,  0.0395,  ...,  0.0058, -0.0054,  0.0195],
        [-0.0114,  0.0591,  0.0195,  ...,  0.0009,  0.0397, -0.0281],
        [ 0.0313,  0.0230,  0.0353,  ..., -0.0229, -0.0177,  0.0229],
        ...,
        [ 0.0202,  0.0195, -0.0057,  ...,  0.0525,  0.0016, -0.0320],
        [-0.0194, -0.0016, -0.0180,  ..., -0.0063,  0.0476,  0.0125],
        [ 0.0190,  0.0252, -0.0160,  ..., -0.0311,  0.0082,  0.0501]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.3750, -7.0781,  2.4023,  ...,  2.1348, -1.1094,  0.8203]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 02:45:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a tool is rake
A more specific term for a candy is lollipop
A more specific term for a seat is chair
A more specific term for a burger is hamburger
A more specific term for a shirt is polo
A more specific term for a backpack is daypack
A more specific term for a camera is camcorder
A more specific term for a railway is
2024-07-30 02:45:40 root INFO     [order_1_approx] starting weight calculation for A more specific term for a seat is chair
A more specific term for a shirt is polo
A more specific term for a tool is rake
A more specific term for a candy is lollipop
A more specific term for a camera is camcorder
A more specific term for a railway is monorail
A more specific term for a burger is hamburger
A more specific term for a backpack is
2024-07-30 02:45:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 02:47:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1613,  0.0729,  0.0438,  ...,  0.3562, -0.4980,  0.0659],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1230, -3.2168, -1.6631,  ...,  1.6797,  2.1953, -0.3584],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0844,  0.0088, -0.0028,  ...,  0.0080, -0.0199,  0.0179],
        [-0.0088,  0.0718, -0.0107,  ..., -0.0160,  0.0210, -0.0193],
        [ 0.0073,  0.0034,  0.0573,  ...,  0.0106,  0.0051,  0.0144],
        ...,
        [ 0.0140,  0.0069, -0.0305,  ...,  0.0527, -0.0018, -0.0118],
        [-0.0046,  0.0067, -0.0069,  ..., -0.0035,  0.0435, -0.0186],
        [ 0.0037, -0.0051,  0.0048,  ..., -0.0199, -0.0261,  0.0712]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7637, -3.0332, -1.6025,  ...,  1.8486,  2.0723, -0.6309]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 02:47:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a seat is chair
A more specific term for a shirt is polo
A more specific term for a tool is rake
A more specific term for a candy is lollipop
A more specific term for a camera is camcorder
A more specific term for a railway is monorail
A more specific term for a burger is hamburger
A more specific term for a backpack is
2024-07-30 02:47:53 root INFO     [order_1_approx] starting weight calculation for A more specific term for a backpack is daypack
A more specific term for a railway is monorail
A more specific term for a candy is lollipop
A more specific term for a tool is rake
A more specific term for a camera is camcorder
A more specific term for a burger is hamburger
A more specific term for a seat is chair
A more specific term for a shirt is
2024-07-30 02:47:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 02:50:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0320, -0.1954, -0.3037,  ...,  0.6592, -0.5938,  0.0966],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3926, -2.3047, -0.3794,  ...,  2.3672, -0.2759, -0.5068],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0669, -0.0006,  0.0154,  ...,  0.0123,  0.0085, -0.0171],
        [-0.0090,  0.0514, -0.0043,  ...,  0.0105, -0.0116, -0.0191],
        [ 0.0276, -0.0209,  0.0634,  ..., -0.0043, -0.0047, -0.0082],
        ...,
        [ 0.0083,  0.0101,  0.0079,  ...,  0.0819,  0.0022, -0.0007],
        [-0.0124,  0.0113, -0.0120,  ...,  0.0072,  0.0755, -0.0160],
        [-0.0179,  0.0015,  0.0134,  ..., -0.0316, -0.0108,  0.0579]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3027, -2.5293, -0.4297,  ...,  2.2930, -0.6064, -0.6255]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 02:50:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a backpack is daypack
A more specific term for a railway is monorail
A more specific term for a candy is lollipop
A more specific term for a tool is rake
A more specific term for a camera is camcorder
A more specific term for a burger is hamburger
A more specific term for a seat is chair
A more specific term for a shirt is
2024-07-30 02:50:06 root INFO     [order_1_approx] starting weight calculation for A more specific term for a camera is camcorder
A more specific term for a railway is monorail
A more specific term for a candy is lollipop
A more specific term for a seat is chair
A more specific term for a backpack is daypack
A more specific term for a shirt is polo
A more specific term for a tool is rake
A more specific term for a burger is
2024-07-30 02:50:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 02:52:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0394,  0.6353,  0.0420,  ...,  0.4243,  0.0330, -0.3271],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0107, -4.6016,  2.0781,  ..., -1.9160, -4.6602, -2.3711],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0723,  0.0229,  0.0097,  ...,  0.0143, -0.0226,  0.0030],
        [ 0.0082,  0.0721,  0.0080,  ...,  0.0098,  0.0007, -0.0260],
        [ 0.0113, -0.0170,  0.0775,  ...,  0.0072, -0.0169, -0.0137],
        ...,
        [ 0.0268,  0.0150,  0.0064,  ...,  0.0780, -0.0051, -0.0095],
        [-0.0197, -0.0104, -0.0076,  ...,  0.0212,  0.0893, -0.0204],
        [ 0.0057,  0.0214, -0.0041,  ..., -0.0190, -0.0204,  0.0737]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4167, -4.6289,  1.9512,  ..., -1.8057, -4.4648, -2.7891]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 02:52:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a camera is camcorder
A more specific term for a railway is monorail
A more specific term for a candy is lollipop
A more specific term for a seat is chair
A more specific term for a backpack is daypack
A more specific term for a shirt is polo
A more specific term for a tool is rake
A more specific term for a burger is
2024-07-30 02:52:18 root INFO     [order_1_approx] starting weight calculation for A more specific term for a shirt is polo
A more specific term for a seat is chair
A more specific term for a candy is lollipop
A more specific term for a railway is monorail
A more specific term for a backpack is daypack
A more specific term for a burger is hamburger
A more specific term for a camera is camcorder
A more specific term for a tool is
2024-07-30 02:52:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 02:54:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1144, -0.5586, -0.1382,  ...,  0.3638,  0.0767, -0.0223],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4854, -3.3184,  0.2998,  ...,  1.4199, -3.6680,  1.4912],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 8.0933e-02,  8.6060e-03,  7.9041e-03,  ...,  1.0605e-02,
         -9.8114e-03,  1.9577e-02],
        [-5.4932e-03,  6.4636e-02,  5.5351e-03,  ..., -6.0883e-03,
          2.2781e-02, -6.6414e-03],
        [-5.1575e-03,  6.5079e-03,  5.1025e-02,  ...,  5.6305e-03,
          5.0735e-03,  5.4741e-03],
        ...,
        [ 1.0529e-02,  9.8419e-03,  8.1921e-04,  ...,  5.2368e-02,
         -2.1667e-03,  1.8930e-03],
        [-2.0027e-03, -9.5367e-05, -6.3553e-03,  ..., -9.4757e-03,
          5.0293e-02, -1.4954e-02],
        [-1.4107e-02,  2.2202e-02,  9.9945e-03,  ..., -1.7639e-02,
          1.6403e-02,  5.1697e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3679, -3.8594,  0.1610,  ...,  1.7285, -3.5000,  1.5684]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 02:54:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a shirt is polo
A more specific term for a seat is chair
A more specific term for a candy is lollipop
A more specific term for a railway is monorail
A more specific term for a backpack is daypack
A more specific term for a burger is hamburger
A more specific term for a camera is camcorder
A more specific term for a tool is
2024-07-30 02:54:30 root INFO     [order_1_approx] starting weight calculation for A more specific term for a shirt is polo
A more specific term for a burger is hamburger
A more specific term for a tool is rake
A more specific term for a railway is monorail
A more specific term for a camera is camcorder
A more specific term for a backpack is daypack
A more specific term for a seat is chair
A more specific term for a candy is
2024-07-30 02:54:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 02:56:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0082, -0.2280, -0.4185,  ...,  0.1631, -0.0563, -0.4983],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2646, -9.1016, -0.1592,  ..., -1.5273, -1.2939,  5.1641],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0647, -0.0018,  0.0059,  ...,  0.0230,  0.0007,  0.0127],
        [-0.0104,  0.0567, -0.0007,  ...,  0.0039,  0.0135, -0.0234],
        [ 0.0030,  0.0008,  0.0543,  ...,  0.0127,  0.0007, -0.0082],
        ...,
        [ 0.0040,  0.0074, -0.0145,  ...,  0.0667, -0.0132, -0.0200],
        [-0.0205,  0.0063, -0.0011,  ..., -0.0013,  0.0483, -0.0198],
        [-0.0087,  0.0067, -0.0052,  ..., -0.0199,  0.0169,  0.0828]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8867, -8.8594, -0.4805,  ..., -1.4951, -1.4746,  5.2227]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 02:56:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a shirt is polo
A more specific term for a burger is hamburger
A more specific term for a tool is rake
A more specific term for a railway is monorail
A more specific term for a camera is camcorder
A more specific term for a backpack is daypack
A more specific term for a seat is chair
A more specific term for a candy is
2024-07-30 02:56:43 root INFO     [order_1_approx] starting weight calculation for A more specific term for a camera is camcorder
A more specific term for a backpack is daypack
A more specific term for a burger is hamburger
A more specific term for a railway is monorail
A more specific term for a tool is rake
A more specific term for a shirt is polo
A more specific term for a candy is lollipop
A more specific term for a seat is
2024-07-30 02:56:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 02:58:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2893, -0.2964, -0.4558,  ...,  0.4893, -0.2184,  0.0596],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5376, -4.1367,  3.5957,  ...,  2.4766, -1.9404,  1.2998],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0940, -0.0325, -0.0029,  ...,  0.0054, -0.0211, -0.0189],
        [ 0.0323,  0.1048,  0.0142,  ...,  0.0130,  0.0345,  0.0109],
        [-0.0105, -0.0087,  0.0584,  ..., -0.0117, -0.0366, -0.0087],
        ...,
        [ 0.0022,  0.0282, -0.0009,  ...,  0.0902,  0.0063, -0.0214],
        [-0.0059,  0.0087, -0.0234,  ...,  0.0050,  0.0257,  0.0009],
        [ 0.0287,  0.0080,  0.0206,  ..., -0.0072, -0.0024,  0.0675]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5752, -4.7188,  3.4551,  ...,  2.7188, -1.9688,  1.0654]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 02:58:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a camera is camcorder
A more specific term for a backpack is daypack
A more specific term for a burger is hamburger
A more specific term for a railway is monorail
A more specific term for a tool is rake
A more specific term for a shirt is polo
A more specific term for a candy is lollipop
A more specific term for a seat is
2024-07-30 02:58:55 root INFO     total operator prediction time: 1061.1394646167755 seconds
2024-07-30 02:58:55 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hypernyms - animals
2024-07-30 02:58:55 root INFO     building operator hypernyms - animals
2024-07-30 02:58:55 root INFO     [order_1_approx] starting weight calculation for The cat falls into the category of feline
The jaguar falls into the category of feline
The ant falls into the category of insect
The buffalo falls into the category of bovid
The wolf falls into the category of canine
The cobra falls into the category of snake
The hawk falls into the category of raptor
The human falls into the category of
2024-07-30 02:58:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 03:01:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2361, -0.3157,  0.4482,  ...,  0.4702, -0.2852, -0.0706],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.2686, -6.1406,  2.2266,  ..., -1.2178, -8.2344, -0.8232],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.5685e-02,  1.4175e-02,  1.7939e-03,  ...,  4.1389e-03,
         -2.8343e-03, -7.2060e-03],
        [ 8.8120e-03,  4.4769e-02,  7.3204e-03,  ..., -8.4991e-03,
         -1.2650e-02, -1.8494e-02],
        [-9.1248e-03, -6.1646e-03,  2.3193e-02,  ...,  1.2428e-02,
          6.9046e-03,  6.5651e-03],
        ...,
        [ 1.1719e-02,  7.1068e-03,  1.3229e-02,  ...,  2.5970e-02,
         -9.7275e-05,  8.1329e-03],
        [-4.1580e-03,  3.5477e-03,  4.5395e-04,  ..., -6.6948e-03,
          3.0579e-02, -1.4793e-02],
        [ 4.6463e-03,  9.5062e-03, -7.6103e-03,  ..., -2.1286e-03,
         -9.3918e-03,  3.5706e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8340, -6.1562,  1.8994,  ..., -1.1572, -8.1016, -0.5610]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 03:01:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The cat falls into the category of feline
The jaguar falls into the category of feline
The ant falls into the category of insect
The buffalo falls into the category of bovid
The wolf falls into the category of canine
The cobra falls into the category of snake
The hawk falls into the category of raptor
The human falls into the category of
2024-07-30 03:01:08 root INFO     [order_1_approx] starting weight calculation for The buffalo falls into the category of bovid
The human falls into the category of primate
The ant falls into the category of insect
The hawk falls into the category of raptor
The cat falls into the category of feline
The cobra falls into the category of snake
The wolf falls into the category of canine
The jaguar falls into the category of
2024-07-30 03:01:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 03:03:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2273, -0.3433,  0.3203,  ...,  0.1179, -0.6025, -0.3062],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0166, -5.3750, -1.4062,  ..., -2.8984, -7.6328, -2.8340],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.4902e-02,  2.5139e-03, -4.6082e-03,  ..., -3.7479e-03,
         -5.4169e-03, -2.1896e-03],
        [ 3.0785e-03,  1.0437e-02,  8.7357e-04,  ..., -1.1932e-02,
          2.1172e-03, -1.1032e-02],
        [-9.8133e-04, -2.4872e-03,  2.8107e-02,  ..., -7.1487e-03,
         -7.2937e-03, -1.5621e-03],
        ...,
        [-2.7313e-03,  7.1001e-04,  5.2490e-03,  ...,  1.0353e-02,
          8.7280e-03, -4.2686e-03],
        [ 5.1117e-03, -1.0529e-02, -4.5280e-03,  ..., -1.1873e-03,
          1.6281e-02,  3.2425e-03],
        [-1.8559e-03,  2.3975e-03, -2.0981e-05,  ..., -6.7444e-03,
         -1.2846e-03,  1.2589e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0586, -5.3711, -1.4053,  ..., -2.9199, -7.7227, -2.8281]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 03:03:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The buffalo falls into the category of bovid
The human falls into the category of primate
The ant falls into the category of insect
The hawk falls into the category of raptor
The cat falls into the category of feline
The cobra falls into the category of snake
The wolf falls into the category of canine
The jaguar falls into the category of
2024-07-30 03:03:21 root INFO     [order_1_approx] starting weight calculation for The human falls into the category of primate
The buffalo falls into the category of bovid
The hawk falls into the category of raptor
The jaguar falls into the category of feline
The cobra falls into the category of snake
The cat falls into the category of feline
The wolf falls into the category of canine
The ant falls into the category of
2024-07-30 03:03:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 03:05:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2144, -0.3782,  0.0935,  ...,  0.0630, -0.1602, -0.3472],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0000, -4.1602,  1.4883,  ..., -1.4893, -5.6562, -1.6143],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0562,  0.0125, -0.0093,  ...,  0.0018, -0.0132, -0.0140],
        [ 0.0371,  0.0391,  0.0361,  ...,  0.0116, -0.0012, -0.0368],
        [ 0.0010, -0.0035,  0.0505,  ..., -0.0139, -0.0142,  0.0132],
        ...,
        [ 0.0367,  0.0071,  0.0218,  ...,  0.0623, -0.0049, -0.0050],
        [-0.0157, -0.0096, -0.0090,  ..., -0.0185,  0.0339,  0.0038],
        [-0.0110, -0.0031, -0.0051,  ..., -0.0186, -0.0067,  0.0300]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0905, -4.3633,  0.6963,  ..., -1.0400, -5.8203, -0.8823]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 03:05:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The human falls into the category of primate
The buffalo falls into the category of bovid
The hawk falls into the category of raptor
The jaguar falls into the category of feline
The cobra falls into the category of snake
The cat falls into the category of feline
The wolf falls into the category of canine
The ant falls into the category of
2024-07-30 03:05:34 root INFO     [order_1_approx] starting weight calculation for The hawk falls into the category of raptor
The cat falls into the category of feline
The wolf falls into the category of canine
The ant falls into the category of insect
The buffalo falls into the category of bovid
The jaguar falls into the category of feline
The human falls into the category of primate
The cobra falls into the category of
2024-07-30 03:05:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 03:07:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0248, -0.0414,  0.0699,  ...,  0.6460, -0.1414,  0.2133],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6353, -4.4453,  3.0195,  ..., -1.5059, -4.7344, -0.6050],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0351,  0.0051,  0.0024,  ..., -0.0158, -0.0070,  0.0033],
        [-0.0123,  0.0329,  0.0042,  ..., -0.0022,  0.0026, -0.0132],
        [ 0.0064,  0.0006,  0.0428,  ..., -0.0142,  0.0092, -0.0113],
        ...,
        [ 0.0068,  0.0056,  0.0085,  ...,  0.0386,  0.0129, -0.0090],
        [-0.0181, -0.0155, -0.0036,  ..., -0.0097,  0.0384, -0.0169],
        [-0.0163, -0.0079, -0.0083,  ..., -0.0141,  0.0170,  0.0372]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4624, -4.4766,  2.7344,  ..., -1.0771, -5.0547, -0.2539]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 03:07:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The hawk falls into the category of raptor
The cat falls into the category of feline
The wolf falls into the category of canine
The ant falls into the category of insect
The buffalo falls into the category of bovid
The jaguar falls into the category of feline
The human falls into the category of primate
The cobra falls into the category of
2024-07-30 03:07:47 root INFO     [order_1_approx] starting weight calculation for The wolf falls into the category of canine
The cat falls into the category of feline
The ant falls into the category of insect
The cobra falls into the category of snake
The hawk falls into the category of raptor
The jaguar falls into the category of feline
The human falls into the category of primate
The buffalo falls into the category of
2024-07-30 03:07:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 03:09:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3784, -0.1346,  0.0934,  ...,  0.7700, -0.6909,  0.3977],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0400, -6.0625,  3.0352,  ..., -0.4275, -8.6328, -1.2773],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.3234e-02,  1.2222e-02,  7.4387e-04,  ..., -3.0231e-03,
         -2.4246e-02, -1.6022e-02],
        [-1.3199e-03,  2.5330e-02,  1.9943e-02,  ..., -3.8147e-05,
         -9.8877e-03, -2.6749e-02],
        [ 1.4801e-02,  1.9501e-02,  2.3544e-02,  ...,  1.6022e-03,
          1.2085e-02, -9.0790e-03],
        ...,
        [ 3.4256e-03,  1.2856e-03,  8.9035e-03,  ...,  4.3945e-02,
          8.9340e-03, -1.4297e-02],
        [-7.6141e-03, -2.2324e-02, -1.2642e-02,  ..., -7.2861e-03,
          5.9082e-02, -1.7090e-02],
        [ 3.0403e-03, -1.4481e-02,  3.8929e-03,  ..., -2.7588e-02,
         -7.6103e-03,  4.7607e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0742, -5.6641,  2.5215,  ..., -0.2749, -8.6016, -0.9727]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 03:09:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The wolf falls into the category of canine
The cat falls into the category of feline
The ant falls into the category of insect
The cobra falls into the category of snake
The hawk falls into the category of raptor
The jaguar falls into the category of feline
The human falls into the category of primate
The buffalo falls into the category of
2024-07-30 03:09:59 root INFO     [order_1_approx] starting weight calculation for The human falls into the category of primate
The cobra falls into the category of snake
The buffalo falls into the category of bovid
The jaguar falls into the category of feline
The ant falls into the category of insect
The wolf falls into the category of canine
The cat falls into the category of feline
The hawk falls into the category of
2024-07-30 03:09:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 03:12:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2354, -0.1548,  0.1492,  ...,  0.6294, -0.1740,  0.0127],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4961, -4.2148,  4.0430,  ..., -1.4736, -6.8320,  0.4561],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0431,  0.0098, -0.0080,  ..., -0.0026, -0.0136, -0.0004],
        [ 0.0091,  0.0249,  0.0134,  ..., -0.0014,  0.0044, -0.0185],
        [ 0.0055, -0.0012,  0.0445,  ...,  0.0054, -0.0015, -0.0072],
        ...,
        [ 0.0076, -0.0042,  0.0114,  ...,  0.0244, -0.0077,  0.0033],
        [ 0.0091,  0.0026, -0.0031,  ..., -0.0004,  0.0388, -0.0077],
        [ 0.0046, -0.0061,  0.0033,  ..., -0.0117, -0.0081,  0.0370]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5674, -4.3750,  3.8359,  ..., -1.4766, -6.5625,  0.6348]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 03:12:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The human falls into the category of primate
The cobra falls into the category of snake
The buffalo falls into the category of bovid
The jaguar falls into the category of feline
The ant falls into the category of insect
The wolf falls into the category of canine
The cat falls into the category of feline
The hawk falls into the category of
2024-07-30 03:12:11 root INFO     [order_1_approx] starting weight calculation for The buffalo falls into the category of bovid
The jaguar falls into the category of feline
The cat falls into the category of feline
The ant falls into the category of insect
The hawk falls into the category of raptor
The human falls into the category of primate
The cobra falls into the category of snake
The wolf falls into the category of
2024-07-30 03:12:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 03:14:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4365,  0.0107,  0.3154,  ...,  0.3779, -0.3865, -0.0947],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4849, -5.1172,  1.1416,  ..., -3.7676, -6.0391,  0.8286],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0304,  0.0086, -0.0082,  ..., -0.0123, -0.0153,  0.0019],
        [ 0.0103,  0.0241,  0.0217,  ..., -0.0094, -0.0034, -0.0153],
        [-0.0002,  0.0081,  0.0424,  ..., -0.0033,  0.0064, -0.0102],
        ...,
        [ 0.0015,  0.0195,  0.0186,  ...,  0.0055,  0.0202,  0.0167],
        [ 0.0182, -0.0344, -0.0108,  ...,  0.0093,  0.0391, -0.0150],
        [-0.0012, -0.0046, -0.0077,  ..., -0.0025, -0.0062,  0.0178]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7686, -5.0039,  0.8311,  ..., -3.2285, -6.6914,  1.1484]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 03:14:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The buffalo falls into the category of bovid
The jaguar falls into the category of feline
The cat falls into the category of feline
The ant falls into the category of insect
The hawk falls into the category of raptor
The human falls into the category of primate
The cobra falls into the category of snake
The wolf falls into the category of
2024-07-30 03:14:36 root INFO     [order_1_approx] starting weight calculation for The cobra falls into the category of snake
The wolf falls into the category of canine
The human falls into the category of primate
The ant falls into the category of insect
The jaguar falls into the category of feline
The buffalo falls into the category of bovid
The hawk falls into the category of raptor
The cat falls into the category of
2024-07-30 03:14:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 03:16:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0756, -0.0330,  0.6602,  ..., -0.0127, -0.2142,  0.3420],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2168, -5.1055,  0.7588,  ..., -4.0352, -7.1758, -1.9863],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0244,  0.0012,  0.0034,  ...,  0.0051, -0.0004,  0.0003],
        [ 0.0085,  0.0020,  0.0037,  ..., -0.0049,  0.0017, -0.0032],
        [-0.0049, -0.0013,  0.0146,  ...,  0.0027,  0.0059, -0.0011],
        ...,
        [-0.0004, -0.0048,  0.0082,  ...,  0.0172,  0.0042, -0.0046],
        [ 0.0019,  0.0017, -0.0039,  ..., -0.0032,  0.0151,  0.0018],
        [ 0.0103, -0.0108,  0.0010,  ...,  0.0091,  0.0034,  0.0169]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3071, -4.9141,  0.6816,  ..., -4.0625, -7.0781, -1.8252]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 03:16:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The cobra falls into the category of snake
The wolf falls into the category of canine
The human falls into the category of primate
The ant falls into the category of insect
The jaguar falls into the category of feline
The buffalo falls into the category of bovid
The hawk falls into the category of raptor
The cat falls into the category of
2024-07-30 03:16:47 root INFO     total operator prediction time: 1071.9241797924042 seconds
2024-07-30 03:16:47 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on synonyms - intensity
2024-07-30 03:16:47 root INFO     building operator synonyms - intensity
2024-07-30 03:16:47 root INFO     [order_1_approx] starting weight calculation for A more intense word for strong is powerful
A more intense word for guilty is remorseful
A more intense word for pony is horse
A more intense word for bad is awful
A more intense word for rain is deluge
A more intense word for afraid is terrified
A more intense word for sad is desparate
A more intense word for dislike is
2024-07-30 03:16:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 03:18:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0468, -0.2695, -0.1750,  ...,  0.5557,  0.2627,  0.3435],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3574, -5.8281,  0.8105,  ..., -1.6641, -3.4219, -2.1953],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0908, -0.0104,  0.0075,  ...,  0.0075, -0.0188,  0.0248],
        [ 0.0024,  0.0707, -0.0073,  ..., -0.0125, -0.0082,  0.0137],
        [ 0.0068,  0.0093,  0.0409,  ..., -0.0038, -0.0036, -0.0237],
        ...,
        [ 0.0078,  0.0154, -0.0228,  ...,  0.0575,  0.0034, -0.0186],
        [-0.0104, -0.0210,  0.0079,  ...,  0.0157,  0.0473,  0.0037],
        [ 0.0004, -0.0133, -0.0175,  ..., -0.0204, -0.0038,  0.0764]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5430, -5.4414,  1.1201,  ..., -1.1367, -3.7832, -1.9941]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 03:18:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for strong is powerful
A more intense word for guilty is remorseful
A more intense word for pony is horse
A more intense word for bad is awful
A more intense word for rain is deluge
A more intense word for afraid is terrified
A more intense word for sad is desparate
A more intense word for dislike is
2024-07-30 03:18:59 root INFO     [order_1_approx] starting weight calculation for A more intense word for strong is powerful
A more intense word for bad is awful
A more intense word for dislike is hate
A more intense word for sad is desparate
A more intense word for pony is horse
A more intense word for rain is deluge
A more intense word for afraid is terrified
A more intense word for guilty is
2024-07-30 03:19:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 03:21:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0273,  0.2123, -0.2725,  ...,  0.1833, -0.1561,  0.3464],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1201, -2.6406,  1.5684,  ..., -2.1953, -2.5742,  0.4082],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0794, -0.0063,  0.0363,  ..., -0.0166, -0.0199,  0.0209],
        [-0.0015,  0.0587, -0.0100,  ..., -0.0022,  0.0131, -0.0271],
        [-0.0016, -0.0141,  0.0713,  ...,  0.0258, -0.0117,  0.0006],
        ...,
        [-0.0068,  0.0037, -0.0183,  ...,  0.0695,  0.0265, -0.0132],
        [-0.0146, -0.0162,  0.0107,  ...,  0.0077,  0.0535, -0.0029],
        [-0.0021, -0.0093, -0.0159,  ...,  0.0022,  0.0018,  0.0659]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8564, -2.3223,  1.4883,  ..., -2.0254, -2.4238, -0.1938]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 03:21:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for strong is powerful
A more intense word for bad is awful
A more intense word for dislike is hate
A more intense word for sad is desparate
A more intense word for pony is horse
A more intense word for rain is deluge
A more intense word for afraid is terrified
A more intense word for guilty is
2024-07-30 03:21:12 root INFO     [order_1_approx] starting weight calculation for A more intense word for bad is awful
A more intense word for rain is deluge
A more intense word for guilty is remorseful
A more intense word for strong is powerful
A more intense word for pony is horse
A more intense word for dislike is hate
A more intense word for sad is desparate
A more intense word for afraid is
2024-07-30 03:21:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 03:23:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3098,  0.0190, -0.6289,  ...,  0.2000, -0.3018,  0.4731],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7520, -4.6875,  3.4297,  ..., -2.0996, -1.8691, -1.5117],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0789,  0.0045, -0.0003,  ...,  0.0017,  0.0079,  0.0110],
        [ 0.0144,  0.0367,  0.0097,  ..., -0.0038, -0.0072, -0.0100],
        [-0.0059, -0.0090,  0.0747,  ..., -0.0004, -0.0054,  0.0114],
        ...,
        [ 0.0069,  0.0144, -0.0170,  ...,  0.0556,  0.0052, -0.0126],
        [-0.0077, -0.0112,  0.0139,  ..., -0.0230,  0.0274, -0.0214],
        [ 0.0054, -0.0192,  0.0008,  ..., -0.0042, -0.0135,  0.0505]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9199, -4.7969,  3.3691,  ..., -2.1504, -2.0938, -1.8135]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 03:23:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for bad is awful
A more intense word for rain is deluge
A more intense word for guilty is remorseful
A more intense word for strong is powerful
A more intense word for pony is horse
A more intense word for dislike is hate
A more intense word for sad is desparate
A more intense word for afraid is
2024-07-30 03:23:23 root INFO     [order_1_approx] starting weight calculation for A more intense word for rain is deluge
A more intense word for pony is horse
A more intense word for strong is powerful
A more intense word for afraid is terrified
A more intense word for dislike is hate
A more intense word for sad is desparate
A more intense word for guilty is remorseful
A more intense word for bad is
2024-07-30 03:23:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 03:25:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3784,  0.0068, -0.1510,  ...,  0.0898,  0.0727, -0.3076],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.2734, -1.4727,  0.0869,  ...,  0.0215, -4.2422,  0.0984],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0703, -0.0049,  0.0252,  ...,  0.0006, -0.0224,  0.0406],
        [-0.0081,  0.0650,  0.0316,  ..., -0.0108,  0.0304, -0.0222],
        [ 0.0070,  0.0066,  0.0704,  ...,  0.0182,  0.0253,  0.0035],
        ...,
        [ 0.0188,  0.0116, -0.0070,  ...,  0.0474, -0.0006, -0.0100],
        [-0.0124, -0.0139,  0.0149,  ...,  0.0162,  0.0526, -0.0233],
        [ 0.0048, -0.0375, -0.0020,  ..., -0.0060, -0.0201,  0.0478]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8047, -1.0781, -0.1653,  ..., -0.2781, -4.2656, -0.0091]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 03:25:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for rain is deluge
A more intense word for pony is horse
A more intense word for strong is powerful
A more intense word for afraid is terrified
A more intense word for dislike is hate
A more intense word for sad is desparate
A more intense word for guilty is remorseful
A more intense word for bad is
2024-07-30 03:25:33 root INFO     [order_1_approx] starting weight calculation for A more intense word for dislike is hate
A more intense word for bad is awful
A more intense word for afraid is terrified
A more intense word for strong is powerful
A more intense word for pony is horse
A more intense word for sad is desparate
A more intense word for guilty is remorseful
A more intense word for rain is
2024-07-30 03:25:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 03:27:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2466, -0.1750, -0.2620,  ..., -0.2067,  0.0454, -0.5771],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.9297, -4.8633, -1.1562,  ..., -0.6309,  2.1582, -2.6406],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0605, -0.0129, -0.0335,  ..., -0.0161,  0.0002, -0.0025],
        [-0.0149,  0.0664, -0.0003,  ...,  0.0121, -0.0223, -0.0370],
        [-0.0014, -0.0069,  0.0840,  ...,  0.0115, -0.0091,  0.0081],
        ...,
        [ 0.0002, -0.0151,  0.0050,  ...,  0.0600, -0.0078, -0.0164],
        [ 0.0015, -0.0074, -0.0182,  ...,  0.0131,  0.0718,  0.0055],
        [ 0.0071,  0.0007, -0.0128,  ..., -0.0066, -0.0109,  0.0642]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.2578, -4.5664, -1.3799,  ..., -0.6953,  1.7832, -2.5742]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 03:27:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for dislike is hate
A more intense word for bad is awful
A more intense word for afraid is terrified
A more intense word for strong is powerful
A more intense word for pony is horse
A more intense word for sad is desparate
A more intense word for guilty is remorseful
A more intense word for rain is
2024-07-30 03:27:45 root INFO     [order_1_approx] starting weight calculation for A more intense word for dislike is hate
A more intense word for pony is horse
A more intense word for strong is powerful
A more intense word for afraid is terrified
A more intense word for rain is deluge
A more intense word for guilty is remorseful
A more intense word for bad is awful
A more intense word for sad is
2024-07-30 03:27:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 03:29:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1932, -0.0972,  0.0707,  ...,  0.2729, -0.5820,  0.2603],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8984, -2.8320,  3.1660,  ..., -1.0908, -1.6104, -2.7559],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0620,  0.0162,  0.0027,  ...,  0.0080, -0.0115,  0.0225],
        [-0.0127,  0.0275, -0.0095,  ..., -0.0182,  0.0227, -0.0197],
        [ 0.0156,  0.0015,  0.0670,  ...,  0.0104, -0.0129, -0.0053],
        ...,
        [-0.0074, -0.0101, -0.0130,  ...,  0.0278,  0.0072, -0.0042],
        [-0.0041, -0.0131, -0.0083,  ...,  0.0135,  0.0317, -0.0144],
        [-0.0037, -0.0234,  0.0018,  ..., -0.0087,  0.0156,  0.0304]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0137, -2.7715,  2.7969,  ..., -1.1846, -1.4375, -2.8555]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 03:29:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for dislike is hate
A more intense word for pony is horse
A more intense word for strong is powerful
A more intense word for afraid is terrified
A more intense word for rain is deluge
A more intense word for guilty is remorseful
A more intense word for bad is awful
A more intense word for sad is
2024-07-30 03:29:59 root INFO     [order_1_approx] starting weight calculation for A more intense word for bad is awful
A more intense word for afraid is terrified
A more intense word for pony is horse
A more intense word for sad is desparate
A more intense word for rain is deluge
A more intense word for dislike is hate
A more intense word for guilty is remorseful
A more intense word for strong is
2024-07-30 03:29:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 03:32:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3325, -0.4404, -0.0715,  ..., -0.1455, -0.0018,  0.0870],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6787, -4.6719,  1.0840,  ..., -0.7300, -7.1055, -3.6211],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0645, -0.0110,  0.0014,  ..., -0.0243, -0.0010,  0.0139],
        [ 0.0323,  0.0681,  0.0257,  ..., -0.0061,  0.0292, -0.0011],
        [-0.0089, -0.0070,  0.0684,  ..., -0.0196, -0.0187,  0.0038],
        ...,
        [ 0.0074,  0.0162, -0.0179,  ...,  0.0825, -0.0065, -0.0013],
        [ 0.0014, -0.0176, -0.0086,  ..., -0.0102,  0.0434,  0.0154],
        [ 0.0014,  0.0027, -0.0055,  ...,  0.0251, -0.0061,  0.0446]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0977, -5.3438,  1.0713,  ..., -0.8159, -7.4414, -3.2715]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 03:32:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for bad is awful
A more intense word for afraid is terrified
A more intense word for pony is horse
A more intense word for sad is desparate
A more intense word for rain is deluge
A more intense word for dislike is hate
A more intense word for guilty is remorseful
A more intense word for strong is
2024-07-30 03:32:11 root INFO     [order_1_approx] starting weight calculation for A more intense word for sad is desparate
A more intense word for guilty is remorseful
A more intense word for strong is powerful
A more intense word for rain is deluge
A more intense word for afraid is terrified
A more intense word for dislike is hate
A more intense word for bad is awful
A more intense word for pony is
2024-07-30 03:32:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 03:34:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1078,  0.2739, -0.3877,  ..., -0.2810, -0.1682,  0.1841],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1973, -4.5781, -1.2500,  ...,  1.8984, -3.8301, -1.1777],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0986, -0.0380, -0.0037,  ...,  0.0029, -0.0377,  0.0431],
        [ 0.0013,  0.0892,  0.0065,  ..., -0.0096,  0.0476, -0.0098],
        [ 0.0692, -0.0335,  0.0807,  ..., -0.0553, -0.0349, -0.0132],
        ...,
        [-0.0216,  0.0146, -0.0109,  ...,  0.0984,  0.0176, -0.0515],
        [-0.0273, -0.0166, -0.0142,  ...,  0.0106,  0.0563,  0.0007],
        [-0.0048, -0.0254,  0.0153,  ..., -0.0303,  0.0218,  0.0301]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9053, -3.4277, -1.5156,  ...,  3.0586, -4.0781, -1.4717]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 03:34:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for sad is desparate
A more intense word for guilty is remorseful
A more intense word for strong is powerful
A more intense word for rain is deluge
A more intense word for afraid is terrified
A more intense word for dislike is hate
A more intense word for bad is awful
A more intense word for pony is
2024-07-30 03:34:24 root INFO     total operator prediction time: 1056.4472115039825 seconds
2024-07-30 03:34:24 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - substance
2024-07-30 03:34:24 root INFO     building operator meronyms - substance
2024-07-30 03:34:24 root INFO     [order_1_approx] starting weight calculation for A icicle is made up of ice
A water is made up of oxygen
A sea is made up of water
A lens is made up of glass
A yogurt is made up of milk
A desk is made up of wood
A bottle is made up of glass
A cloud is made up of
2024-07-30 03:34:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 03:36:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4221, -0.0137,  0.2073,  ..., -0.0168,  0.0215, -0.0681],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0938, -0.2275,  0.8281,  ..., -4.4844,  2.6797, -0.8564],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0554, -0.0066,  0.0024,  ...,  0.0023, -0.0043, -0.0106],
        [-0.0130,  0.0403, -0.0092,  ...,  0.0173, -0.0042, -0.0271],
        [ 0.0400,  0.0170,  0.0344,  ...,  0.0170, -0.0256,  0.0015],
        ...,
        [ 0.0076,  0.0161,  0.0080,  ...,  0.0437,  0.0048, -0.0085],
        [-0.0176, -0.0248,  0.0039,  ...,  0.0215,  0.0408,  0.0037],
        [ 0.0024, -0.0143, -0.0102,  ..., -0.0148,  0.0047,  0.0244]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2695, -0.5371,  0.4465,  ..., -4.4414,  2.6484, -0.8535]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 03:36:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A icicle is made up of ice
A water is made up of oxygen
A sea is made up of water
A lens is made up of glass
A yogurt is made up of milk
A desk is made up of wood
A bottle is made up of glass
A cloud is made up of
2024-07-30 03:36:38 root INFO     [order_1_approx] starting weight calculation for A sea is made up of water
A icicle is made up of ice
A bottle is made up of glass
A water is made up of oxygen
A desk is made up of wood
A cloud is made up of vapor
A yogurt is made up of milk
A lens is made up of
2024-07-30 03:36:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 03:38:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1726, -0.2344, -0.2385,  ...,  0.5732,  0.1071, -0.2351],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7207, -3.0898, -0.2417,  ..., -1.9824,  2.5215, -0.1768],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0665, -0.0098, -0.0113,  ...,  0.0258, -0.0239, -0.0213],
        [-0.0098,  0.0468, -0.0055,  ...,  0.0215,  0.0077, -0.0065],
        [ 0.0395,  0.0121,  0.0528,  ..., -0.0024,  0.0071, -0.0157],
        ...,
        [ 0.0332,  0.0036,  0.0059,  ...,  0.0475, -0.0039,  0.0214],
        [-0.0172,  0.0101, -0.0103,  ...,  0.0090,  0.0339,  0.0006],
        [ 0.0192, -0.0009,  0.0071,  ..., -0.0012,  0.0023,  0.0334]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9824, -3.4688, -0.1809,  ..., -2.4727,  1.9102, -0.1584]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 03:38:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A sea is made up of water
A icicle is made up of ice
A bottle is made up of glass
A water is made up of oxygen
A desk is made up of wood
A cloud is made up of vapor
A yogurt is made up of milk
A lens is made up of
2024-07-30 03:38:52 root INFO     [order_1_approx] starting weight calculation for A cloud is made up of vapor
A lens is made up of glass
A water is made up of oxygen
A yogurt is made up of milk
A sea is made up of water
A desk is made up of wood
A icicle is made up of ice
A bottle is made up of
2024-07-30 03:38:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 03:41:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3474, -0.0908, -0.5063,  ...,  0.3142, -0.2366, -0.2729],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9551, -6.2070,  0.8423,  ..., -2.1973,  1.3145,  1.6406],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0301, -0.0084, -0.0035,  ...,  0.0157, -0.0179,  0.0006],
        [-0.0024,  0.0285,  0.0033,  ...,  0.0092, -0.0072, -0.0162],
        [ 0.0132, -0.0059,  0.0157,  ...,  0.0107,  0.0153, -0.0115],
        ...,
        [ 0.0094,  0.0176,  0.0151,  ...,  0.0424, -0.0040, -0.0111],
        [-0.0152, -0.0004, -0.0084,  ...,  0.0213,  0.0321, -0.0071],
        [-0.0067,  0.0059,  0.0044,  ...,  0.0077, -0.0012,  0.0299]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8438, -6.2383,  0.7842,  ..., -2.5879,  1.0547,  1.5293]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 03:41:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A cloud is made up of vapor
A lens is made up of glass
A water is made up of oxygen
A yogurt is made up of milk
A sea is made up of water
A desk is made up of wood
A icicle is made up of ice
A bottle is made up of
2024-07-30 03:41:06 root INFO     [order_1_approx] starting weight calculation for A desk is made up of wood
A bottle is made up of glass
A cloud is made up of vapor
A sea is made up of water
A icicle is made up of ice
A lens is made up of glass
A yogurt is made up of milk
A water is made up of
2024-07-30 03:41:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 03:43:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0203, -0.1683, -0.2925,  ..., -0.3184, -0.2915, -0.5542],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0781, -2.3691,  1.4434,  ..., -4.9141,  2.3145,  1.0869],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0389, -0.0024, -0.0082,  ...,  0.0005, -0.0128, -0.0092],
        [-0.0178,  0.0342,  0.0072,  ...,  0.0021,  0.0038, -0.0004],
        [ 0.0223,  0.0005,  0.0055,  ...,  0.0119,  0.0110, -0.0028],
        ...,
        [-0.0039,  0.0032,  0.0168,  ...,  0.0150, -0.0071, -0.0067],
        [-0.0067,  0.0032, -0.0087,  ...,  0.0068,  0.0225,  0.0103],
        [-0.0048,  0.0036,  0.0021,  ..., -0.0164, -0.0031,  0.0264]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4531, -2.6191,  1.4678,  ..., -5.0391,  2.3496,  0.9253]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 03:43:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A desk is made up of wood
A bottle is made up of glass
A cloud is made up of vapor
A sea is made up of water
A icicle is made up of ice
A lens is made up of glass
A yogurt is made up of milk
A water is made up of
2024-07-30 03:43:20 root INFO     [order_1_approx] starting weight calculation for A lens is made up of glass
A icicle is made up of ice
A water is made up of oxygen
A yogurt is made up of milk
A cloud is made up of vapor
A desk is made up of wood
A bottle is made up of glass
A sea is made up of
2024-07-30 03:43:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 03:45:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0389,  0.0942, -0.0983,  ..., -0.2468, -0.2715,  0.1951],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0566, -2.8906,  0.7778,  ..., -4.8203,  2.4863, -1.0537],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0459,  0.0208,  0.0028,  ...,  0.0091,  0.0059,  0.0025],
        [-0.0113,  0.0242, -0.0003,  ..., -0.0030, -0.0098, -0.0182],
        [ 0.0134,  0.0012,  0.0279,  ...,  0.0047, -0.0081,  0.0151],
        ...,
        [-0.0043,  0.0151,  0.0277,  ...,  0.0279, -0.0064, -0.0090],
        [-0.0104,  0.0038, -0.0226,  ...,  0.0114,  0.0361,  0.0079],
        [-0.0131, -0.0077, -0.0004,  ..., -0.0008, -0.0083,  0.0373]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0117, -3.0234,  0.3750,  ..., -5.2031,  2.5684, -1.2695]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 03:45:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A lens is made up of glass
A icicle is made up of ice
A water is made up of oxygen
A yogurt is made up of milk
A cloud is made up of vapor
A desk is made up of wood
A bottle is made up of glass
A sea is made up of
2024-07-30 03:45:33 root INFO     [order_1_approx] starting weight calculation for A bottle is made up of glass
A desk is made up of wood
A water is made up of oxygen
A sea is made up of water
A lens is made up of glass
A cloud is made up of vapor
A yogurt is made up of milk
A icicle is made up of
2024-07-30 03:45:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 03:47:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0287,  0.0432, -0.4854,  ...,  0.1708, -0.5840, -0.0514],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4316, -3.9375, -0.3584,  ..., -4.4375,  1.3174, -0.6904],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0701, -0.0117,  0.0062,  ..., -0.0162, -0.0051, -0.0230],
        [-0.0169,  0.0351,  0.0172,  ..., -0.0108, -0.0011, -0.0403],
        [ 0.0217,  0.0124,  0.0324,  ...,  0.0097,  0.0026, -0.0127],
        ...,
        [ 0.0159,  0.0316,  0.0166,  ...,  0.0840,  0.0137, -0.0025],
        [-0.0267,  0.0208, -0.0054,  ...,  0.0419,  0.0338,  0.0183],
        [-0.0025, -0.0135,  0.0023,  ...,  0.0112,  0.0017,  0.0271]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5439, -3.9609, -0.3032,  ..., -4.1953,  1.4805, -0.3547]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 03:48:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A bottle is made up of glass
A desk is made up of wood
A water is made up of oxygen
A sea is made up of water
A lens is made up of glass
A cloud is made up of vapor
A yogurt is made up of milk
A icicle is made up of
2024-07-30 03:48:02 root INFO     [order_1_approx] starting weight calculation for A yogurt is made up of milk
A icicle is made up of ice
A cloud is made up of vapor
A water is made up of oxygen
A lens is made up of glass
A sea is made up of water
A bottle is made up of glass
A desk is made up of
2024-07-30 03:48:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 03:50:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0190, -0.0369, -0.3787,  ...,  0.2288, -0.7295, -0.3213],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5742, -4.7773,  2.5273,  ..., -4.6836,  0.0986, -1.7451],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0411, -0.0108,  0.0002,  ...,  0.0169, -0.0068, -0.0012],
        [-0.0167,  0.0529,  0.0065,  ..., -0.0070, -0.0002, -0.0126],
        [ 0.0157,  0.0037,  0.0324,  ...,  0.0177, -0.0009, -0.0086],
        ...,
        [ 0.0183,  0.0013,  0.0244,  ...,  0.0482, -0.0036, -0.0149],
        [-0.0032,  0.0084, -0.0159,  ..., -0.0029,  0.0373,  0.0022],
        [-0.0101, -0.0090,  0.0060,  ..., -0.0124,  0.0012,  0.0367]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2910, -5.0898,  2.0469,  ..., -4.4180, -0.0471, -1.6172]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 03:50:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A yogurt is made up of milk
A icicle is made up of ice
A cloud is made up of vapor
A water is made up of oxygen
A lens is made up of glass
A sea is made up of water
A bottle is made up of glass
A desk is made up of
2024-07-30 03:50:16 root INFO     [order_1_approx] starting weight calculation for A desk is made up of wood
A icicle is made up of ice
A lens is made up of glass
A sea is made up of water
A cloud is made up of vapor
A bottle is made up of glass
A water is made up of oxygen
A yogurt is made up of
2024-07-30 03:50:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 03:52:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3379, -0.0723,  0.2642,  ...,  0.2510, -0.4380, -0.3237],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5488, -4.0156,  2.1602,  ..., -4.4062, -0.8223, -0.4902],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0377, -0.0278,  0.0065,  ...,  0.0141, -0.0085,  0.0082],
        [-0.0046,  0.0432,  0.0068,  ..., -0.0042,  0.0118,  0.0012],
        [ 0.0032,  0.0042,  0.0133,  ...,  0.0119,  0.0042,  0.0112],
        ...,
        [ 0.0141,  0.0183,  0.0130,  ...,  0.0461, -0.0063, -0.0137],
        [-0.0277, -0.0013, -0.0144,  ...,  0.0216,  0.0678,  0.0230],
        [ 0.0052, -0.0019,  0.0072,  ..., -0.0293,  0.0163,  0.0583]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4512, -4.5156,  2.1992,  ..., -4.2812, -1.0146, -0.1465]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 03:52:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A desk is made up of wood
A icicle is made up of ice
A lens is made up of glass
A sea is made up of water
A cloud is made up of vapor
A bottle is made up of glass
A water is made up of oxygen
A yogurt is made up of
2024-07-30 03:52:29 root INFO     total operator prediction time: 1085.7170906066895 seconds
2024-07-30 03:52:29 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hypernyms - misc
2024-07-30 03:52:29 root INFO     building operator hypernyms - misc
2024-07-30 03:52:30 root INFO     [order_1_approx] starting weight calculation for The lemon falls into the category of citrus
The dress falls into the category of clothes
The hairnet falls into the category of net
The diary falls into the category of journal
The gasoline falls into the category of fuel
The skirt falls into the category of clothes
The computer falls into the category of device
The tub falls into the category of
2024-07-30 03:52:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 03:54:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1232, -0.5454,  0.5527,  ..., -0.2598,  0.0704,  0.1436],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1604, -2.2441,  3.4688,  ..., -0.5713, -2.4961,  0.6055],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1155, -0.0034, -0.0155,  ...,  0.0099,  0.0110, -0.0046],
        [ 0.0108,  0.0730,  0.0234,  ..., -0.0038, -0.0087, -0.0139],
        [-0.0089, -0.0113,  0.0450,  ...,  0.0029, -0.0213,  0.0226],
        ...,
        [ 0.0117,  0.0036,  0.0070,  ...,  0.0522,  0.0213, -0.0073],
        [ 0.0059, -0.0005, -0.0015,  ..., -0.0029,  0.0658, -0.0213],
        [-0.0002,  0.0027, -0.0125,  ..., -0.0225,  0.0086,  0.0530]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3623, -2.3340,  3.1309,  ..., -0.4602, -2.4395,  0.3452]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 03:54:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The lemon falls into the category of citrus
The dress falls into the category of clothes
The hairnet falls into the category of net
The diary falls into the category of journal
The gasoline falls into the category of fuel
The skirt falls into the category of clothes
The computer falls into the category of device
The tub falls into the category of
2024-07-30 03:54:42 root INFO     [order_1_approx] starting weight calculation for The diary falls into the category of journal
The hairnet falls into the category of net
The lemon falls into the category of citrus
The dress falls into the category of clothes
The computer falls into the category of device
The tub falls into the category of container
The skirt falls into the category of clothes
The gasoline falls into the category of
2024-07-30 03:54:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 03:56:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0146, -0.2690, -0.4243,  ..., -0.0278, -0.1008, -0.0957],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6377, -2.7852,  3.1367,  ..., -3.6953,  0.3643, -0.6895],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0757, -0.0238,  0.0174,  ..., -0.0182,  0.0009,  0.0078],
        [ 0.0088,  0.0626,  0.0032,  ...,  0.0036,  0.0260, -0.0013],
        [-0.0223,  0.0177,  0.0372,  ...,  0.0067, -0.0073, -0.0037],
        ...,
        [ 0.0127, -0.0046,  0.0040,  ...,  0.0338,  0.0194, -0.0251],
        [-0.0004, -0.0121, -0.0156,  ...,  0.0023,  0.0642, -0.0293],
        [ 0.0025,  0.0132, -0.0018,  ..., -0.0320, -0.0244,  0.0471]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9707, -2.7715,  2.7676,  ..., -3.1855,  0.3848, -0.6055]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 03:56:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The diary falls into the category of journal
The hairnet falls into the category of net
The lemon falls into the category of citrus
The dress falls into the category of clothes
The computer falls into the category of device
The tub falls into the category of container
The skirt falls into the category of clothes
The gasoline falls into the category of
2024-07-30 03:56:55 root INFO     [order_1_approx] starting weight calculation for The tub falls into the category of container
The hairnet falls into the category of net
The lemon falls into the category of citrus
The gasoline falls into the category of fuel
The computer falls into the category of device
The skirt falls into the category of clothes
The diary falls into the category of journal
The dress falls into the category of
2024-07-30 03:56:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 03:59:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0713, -0.4697,  0.1124,  ...,  0.1246, -0.1763, -0.1700],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0469, -5.7500,  0.2180,  ..., -0.0721, -4.6211, -0.5278],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0426,  0.0009, -0.0040,  ...,  0.0094,  0.0130, -0.0100],
        [ 0.0039,  0.0360,  0.0163,  ..., -0.0054, -0.0142, -0.0042],
        [ 0.0137, -0.0007,  0.0374,  ..., -0.0148,  0.0104,  0.0054],
        ...,
        [ 0.0010, -0.0027,  0.0123,  ...,  0.0405,  0.0189, -0.0179],
        [-0.0143,  0.0065, -0.0123,  ..., -0.0045,  0.0373, -0.0047],
        [ 0.0063,  0.0104, -0.0023,  ..., -0.0202, -0.0098,  0.0422]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1543, -5.7852,  0.3760,  ...,  0.1143, -4.3711, -0.5713]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 03:59:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The tub falls into the category of container
The hairnet falls into the category of net
The lemon falls into the category of citrus
The gasoline falls into the category of fuel
The computer falls into the category of device
The skirt falls into the category of clothes
The diary falls into the category of journal
The dress falls into the category of
2024-07-30 03:59:08 root INFO     [order_1_approx] starting weight calculation for The dress falls into the category of clothes
The diary falls into the category of journal
The skirt falls into the category of clothes
The hairnet falls into the category of net
The tub falls into the category of container
The gasoline falls into the category of fuel
The computer falls into the category of device
The lemon falls into the category of
2024-07-30 03:59:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 04:01:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2358, -0.4272, -0.3489,  ...,  0.0556, -0.0548, -0.4519],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9473, -4.4766, -0.8232,  ..., -4.7812, -2.4258, -2.1426],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0619, -0.0203, -0.0107,  ...,  0.0277,  0.0136,  0.0036],
        [ 0.0237,  0.0643,  0.0159,  ...,  0.0099,  0.0005, -0.0034],
        [-0.0096, -0.0003,  0.0510,  ...,  0.0127, -0.0115, -0.0026],
        ...,
        [ 0.0180,  0.0238,  0.0160,  ...,  0.0582,  0.0150, -0.0143],
        [ 0.0169, -0.0056, -0.0110,  ...,  0.0127,  0.0421, -0.0169],
        [ 0.0012,  0.0189, -0.0038,  ..., -0.0289, -0.0196,  0.0496]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8125, -4.4180, -0.8169,  ..., -4.4844, -2.1836, -2.0371]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 04:01:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The dress falls into the category of clothes
The diary falls into the category of journal
The skirt falls into the category of clothes
The hairnet falls into the category of net
The tub falls into the category of container
The gasoline falls into the category of fuel
The computer falls into the category of device
The lemon falls into the category of
2024-07-30 04:01:21 root INFO     [order_1_approx] starting weight calculation for The lemon falls into the category of citrus
The gasoline falls into the category of fuel
The skirt falls into the category of clothes
The diary falls into the category of journal
The computer falls into the category of device
The tub falls into the category of container
The dress falls into the category of clothes
The hairnet falls into the category of
2024-07-30 04:01:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 04:03:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2344, -0.1519, -0.3499,  ...,  0.2311, -0.4607,  0.0583],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2734, -2.8828,  2.9258,  ..., -1.6680, -3.7324,  3.2227],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0788, -0.0068,  0.0041,  ...,  0.0153, -0.0120,  0.0007],
        [ 0.0007,  0.0680, -0.0170,  ..., -0.0223, -0.0058, -0.0043],
        [-0.0018,  0.0115,  0.0573,  ...,  0.0202, -0.0073,  0.0119],
        ...,
        [ 0.0076, -0.0177,  0.0230,  ...,  0.0473,  0.0157,  0.0003],
        [-0.0006, -0.0132,  0.0188,  ..., -0.0078,  0.0455, -0.0295],
        [-0.0212,  0.0042, -0.0177,  ..., -0.0157, -0.0040,  0.0605]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0020, -3.1855,  2.5781,  ..., -1.0127, -3.6426,  2.8867]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 04:03:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The lemon falls into the category of citrus
The gasoline falls into the category of fuel
The skirt falls into the category of clothes
The diary falls into the category of journal
The computer falls into the category of device
The tub falls into the category of container
The dress falls into the category of clothes
The hairnet falls into the category of
2024-07-30 04:03:36 root INFO     [order_1_approx] starting weight calculation for The hairnet falls into the category of net
The lemon falls into the category of citrus
The gasoline falls into the category of fuel
The tub falls into the category of container
The skirt falls into the category of clothes
The dress falls into the category of clothes
The diary falls into the category of journal
The computer falls into the category of
2024-07-30 04:03:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 04:05:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0693, -0.2583,  0.3191,  ...,  0.3098, -0.0598, -0.2678],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.4844, -3.5664,  0.4353,  ..., -1.3418, -2.9219, -0.9863],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0581, -0.0195,  0.0021,  ...,  0.0020, -0.0057,  0.0244],
        [ 0.0123,  0.0480,  0.0015,  ...,  0.0056,  0.0137, -0.0005],
        [-0.0140,  0.0115,  0.0451,  ..., -0.0147,  0.0178,  0.0140],
        ...,
        [-0.0066,  0.0250,  0.0017,  ...,  0.0408,  0.0091, -0.0108],
        [-0.0046, -0.0178,  0.0009,  ...,  0.0157,  0.0283, -0.0138],
        [ 0.0043,  0.0107,  0.0004,  ..., -0.0254, -0.0121,  0.0423]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.3379, -3.7969,  0.6445,  ..., -1.0557, -2.6328, -0.6851]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 04:05:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The hairnet falls into the category of net
The lemon falls into the category of citrus
The gasoline falls into the category of fuel
The tub falls into the category of container
The skirt falls into the category of clothes
The dress falls into the category of clothes
The diary falls into the category of journal
The computer falls into the category of
2024-07-30 04:05:50 root INFO     [order_1_approx] starting weight calculation for The computer falls into the category of device
The lemon falls into the category of citrus
The tub falls into the category of container
The dress falls into the category of clothes
The gasoline falls into the category of fuel
The skirt falls into the category of clothes
The hairnet falls into the category of net
The diary falls into the category of
2024-07-30 04:05:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 04:08:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0500, -0.1895, -0.2617,  ...,  0.0492, -0.2817,  0.0555],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3098, -4.0430,  3.5469,  ..., -3.2832, -2.6641, -1.2695],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0804,  0.0011,  0.0150,  ..., -0.0065, -0.0002, -0.0095],
        [ 0.0032,  0.0388,  0.0101,  ..., -0.0035,  0.0134,  0.0095],
        [ 0.0045, -0.0028,  0.0585,  ...,  0.0339, -0.0107,  0.0205],
        ...,
        [ 0.0115,  0.0227,  0.0138,  ...,  0.0723,  0.0106, -0.0212],
        [-0.0130, -0.0136,  0.0067,  ...,  0.0166,  0.0592, -0.0193],
        [-0.0033,  0.0125,  0.0072,  ..., -0.0354, -0.0021,  0.0612]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0673, -3.9023,  3.5117,  ..., -2.8906, -2.5293, -1.1240]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 04:08:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The computer falls into the category of device
The lemon falls into the category of citrus
The tub falls into the category of container
The dress falls into the category of clothes
The gasoline falls into the category of fuel
The skirt falls into the category of clothes
The hairnet falls into the category of net
The diary falls into the category of
2024-07-30 04:08:03 root INFO     [order_1_approx] starting weight calculation for The dress falls into the category of clothes
The lemon falls into the category of citrus
The hairnet falls into the category of net
The tub falls into the category of container
The diary falls into the category of journal
The computer falls into the category of device
The gasoline falls into the category of fuel
The skirt falls into the category of
2024-07-30 04:08:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 04:10:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1174, -0.5190, -0.4551,  ...,  0.7368, -0.3916,  0.0880],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9082, -5.6406,  0.4456,  ..., -0.1897, -3.2402,  0.7266],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.2021e-02, -8.0109e-05,  2.2705e-02,  ...,  2.3537e-03,
          2.4429e-02, -1.4992e-02],
        [ 1.6571e-02,  4.4952e-02,  1.0780e-02,  ..., -3.0956e-03,
         -2.0905e-03,  1.7815e-03],
        [ 1.3924e-03,  8.7128e-03,  3.1036e-02,  ..., -1.1108e-02,
         -2.6093e-03, -1.0414e-03],
        ...,
        [ 3.3779e-03, -9.2773e-03,  2.5024e-02,  ...,  4.8340e-02,
          1.4587e-02, -1.4847e-02],
        [ 6.1646e-03, -1.2924e-02, -5.9738e-03,  ...,  3.1929e-03,
          7.3425e-02, -1.7517e-02],
        [ 8.0261e-03, -7.9193e-03,  1.3420e-02,  ..., -2.8564e-02,
         -1.6510e-02,  5.3375e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7646, -5.6094,  0.5947,  ..., -0.1783, -3.2168,  0.4854]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 04:10:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The dress falls into the category of clothes
The lemon falls into the category of citrus
The hairnet falls into the category of net
The tub falls into the category of container
The diary falls into the category of journal
The computer falls into the category of device
The gasoline falls into the category of fuel
The skirt falls into the category of
2024-07-30 04:10:16 root INFO     total operator prediction time: 1066.525069475174 seconds
2024-07-30 04:10:16 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on synonyms - exact
2024-07-30 04:10:16 root INFO     building operator synonyms - exact
2024-07-30 04:10:16 root INFO     [order_1_approx] starting weight calculation for Another word for list is listing
Another word for identical is same
Another word for harbor is seaport
Another word for railway is railroad
Another word for mother is mom
Another word for snake is serpent
Another word for organized is arranged
Another word for intelligent is
2024-07-30 04:10:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 04:12:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3982, -0.3511,  0.0906,  ...,  0.0161,  0.1545, -0.0198],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9727, -0.2091,  1.2695,  ...,  0.8501, -4.2109, -0.3843],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0543, -0.0071,  0.0110,  ..., -0.0006,  0.0032,  0.0145],
        [-0.0068,  0.0367,  0.0163,  ...,  0.0033,  0.0193,  0.0007],
        [-0.0016, -0.0195,  0.0647,  ...,  0.0052,  0.0139, -0.0040],
        ...,
        [ 0.0046,  0.0139, -0.0016,  ...,  0.0778,  0.0116, -0.0087],
        [-0.0066, -0.0106,  0.0080,  ..., -0.0093,  0.0164, -0.0023],
        [ 0.0076, -0.0172,  0.0057,  ..., -0.0065, -0.0047,  0.0600]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7407,  0.0288,  1.2773,  ...,  0.9346, -4.1172, -0.5703]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 04:12:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for list is listing
Another word for identical is same
Another word for harbor is seaport
Another word for railway is railroad
Another word for mother is mom
Another word for snake is serpent
Another word for organized is arranged
Another word for intelligent is
2024-07-30 04:12:46 root INFO     [order_1_approx] starting weight calculation for Another word for list is listing
Another word for harbor is seaport
Another word for intelligent is clever
Another word for railway is railroad
Another word for identical is same
Another word for snake is serpent
Another word for mother is mom
Another word for organized is
2024-07-30 04:12:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 04:14:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0869,  0.2832, -0.1909,  ..., -0.1831,  0.1451, -0.1222],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0439,  0.4375,  2.7695,  ...,  1.6348, -2.7422, -4.5156],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0820,  0.0343,  0.0282,  ..., -0.0197,  0.0156, -0.0187],
        [ 0.0120,  0.0522,  0.0067,  ..., -0.0003,  0.0326, -0.0055],
        [-0.0253,  0.0179,  0.0861,  ..., -0.0049,  0.0063,  0.0101],
        ...,
        [ 0.0239,  0.0202, -0.0335,  ...,  0.1270, -0.0190, -0.0292],
        [ 0.0033,  0.0249,  0.0042,  ...,  0.0160,  0.0967, -0.0556],
        [ 0.0040, -0.0085, -0.0209,  ..., -0.0058, -0.0135,  0.0690]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4536,  0.0527,  2.6133,  ...,  1.4199, -2.0215, -4.6523]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 04:15:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for list is listing
Another word for harbor is seaport
Another word for intelligent is clever
Another word for railway is railroad
Another word for identical is same
Another word for snake is serpent
Another word for mother is mom
Another word for organized is
2024-07-30 04:15:00 root INFO     [order_1_approx] starting weight calculation for Another word for organized is arranged
Another word for identical is same
Another word for intelligent is clever
Another word for harbor is seaport
Another word for railway is railroad
Another word for snake is serpent
Another word for mother is mom
Another word for list is
2024-07-30 04:15:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 04:17:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1508, -0.1282, -0.2959,  ...,  0.4219, -0.3450, -0.0204],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.3623, -2.7852,  3.0469,  ..., -1.0879, -1.7314, -3.5703],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0984, -0.0028,  0.0315,  ...,  0.0098,  0.0244, -0.0078],
        [-0.0132,  0.0498, -0.0037,  ...,  0.0323, -0.0014, -0.0042],
        [-0.0096, -0.0084,  0.0811,  ...,  0.0045,  0.0079, -0.0156],
        ...,
        [-0.0063,  0.0069, -0.0082,  ...,  0.1050, -0.0023, -0.0179],
        [-0.0211,  0.0267,  0.0102,  ..., -0.0059,  0.0783, -0.0076],
        [-0.0066, -0.0127,  0.0111,  ..., -0.0022, -0.0204,  0.0870]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.3252, -2.7363,  3.0938,  ..., -0.9570, -1.7256, -3.4707]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 04:17:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for organized is arranged
Another word for identical is same
Another word for intelligent is clever
Another word for harbor is seaport
Another word for railway is railroad
Another word for snake is serpent
Another word for mother is mom
Another word for list is
2024-07-30 04:17:14 root INFO     [order_1_approx] starting weight calculation for Another word for snake is serpent
Another word for mother is mom
Another word for identical is same
Another word for list is listing
Another word for intelligent is clever
Another word for harbor is seaport
Another word for organized is arranged
Another word for railway is
2024-07-30 04:17:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 04:19:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0818, -0.0827,  0.1959,  ...,  0.1018,  0.2925, -0.2759],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7661, -5.4297,  4.0039,  ...,  1.8281, -0.7920, -2.7812],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1110, -0.0041,  0.0381,  ...,  0.0041,  0.0328,  0.0172],
        [ 0.0139,  0.1039,  0.0041,  ..., -0.0106,  0.0433, -0.0192],
        [-0.0050,  0.0019,  0.0778,  ..., -0.0137, -0.0144,  0.0138],
        ...,
        [ 0.0275,  0.0010,  0.0120,  ...,  0.0839, -0.0079, -0.0426],
        [-0.0245,  0.0297,  0.0046,  ..., -0.0215,  0.1090,  0.0072],
        [ 0.0167,  0.0129,  0.0114,  ..., -0.0349, -0.0113,  0.0874]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.3926, -4.8711,  3.5742,  ...,  2.1309, -0.7158, -2.5059]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 04:19:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for snake is serpent
Another word for mother is mom
Another word for identical is same
Another word for list is listing
Another word for intelligent is clever
Another word for harbor is seaport
Another word for organized is arranged
Another word for railway is
2024-07-30 04:19:27 root INFO     [order_1_approx] starting weight calculation for Another word for intelligent is clever
Another word for list is listing
Another word for snake is serpent
Another word for organized is arranged
Another word for identical is same
Another word for harbor is seaport
Another word for railway is railroad
Another word for mother is
2024-07-30 04:19:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 04:21:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6777, -0.1865,  0.3860,  ...,  0.2498, -0.2051, -0.3718],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6670, -6.7266,  0.8369,  ..., -1.3779, -2.1660, -1.5508],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0685, -0.0406,  0.0250,  ...,  0.0043, -0.0072,  0.0033],
        [ 0.0229,  0.0544,  0.0098,  ...,  0.0201,  0.0144, -0.0297],
        [ 0.0172,  0.0025,  0.0600,  ...,  0.0076,  0.0154, -0.0183],
        ...,
        [-0.0177,  0.0319,  0.0332,  ...,  0.0551,  0.0089, -0.0105],
        [-0.0292,  0.0230, -0.0252,  ..., -0.0035,  0.0521, -0.0045],
        [-0.0032, -0.0126,  0.0069,  ..., -0.0290, -0.0262,  0.0533]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3486, -6.4180,  1.0576,  ..., -1.2021, -1.8643, -1.4688]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 04:21:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for intelligent is clever
Another word for list is listing
Another word for snake is serpent
Another word for organized is arranged
Another word for identical is same
Another word for harbor is seaport
Another word for railway is railroad
Another word for mother is
2024-07-30 04:21:38 root INFO     [order_1_approx] starting weight calculation for Another word for list is listing
Another word for snake is serpent
Another word for railway is railroad
Another word for harbor is seaport
Another word for organized is arranged
Another word for mother is mom
Another word for intelligent is clever
Another word for identical is
2024-07-30 04:21:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 04:23:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1259, -0.6870,  0.0089,  ...,  0.1022, -0.0447, -0.0498],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3862, -0.5527,  1.8936,  ..., -0.5063, -3.4375, -0.5039],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1074, -0.0029, -0.0069,  ...,  0.0217,  0.0102, -0.0142],
        [ 0.0031,  0.0915,  0.0220,  ...,  0.0104,  0.0010,  0.0081],
        [ 0.0193,  0.0182,  0.0925,  ..., -0.0062,  0.0065, -0.0182],
        ...,
        [ 0.0224,  0.0275, -0.0008,  ...,  0.1394, -0.0100,  0.0120],
        [ 0.0212, -0.0220,  0.0135,  ..., -0.0313,  0.0307,  0.0195],
        [ 0.0065, -0.0114, -0.0193,  ..., -0.0162, -0.0183,  0.0886]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2280, -0.3328,  1.7891,  ..., -0.1663, -3.2031, -0.6455]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 04:23:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for list is listing
Another word for snake is serpent
Another word for railway is railroad
Another word for harbor is seaport
Another word for organized is arranged
Another word for mother is mom
Another word for intelligent is clever
Another word for identical is
2024-07-30 04:23:52 root INFO     [order_1_approx] starting weight calculation for Another word for railway is railroad
Another word for list is listing
Another word for harbor is seaport
Another word for mother is mom
Another word for identical is same
Another word for organized is arranged
Another word for intelligent is clever
Another word for snake is
2024-07-30 04:23:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 04:26:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5039,  0.1764,  0.0092,  ..., -0.0775,  0.2225, -0.0477],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8989, -6.3359,  3.1035,  ..., -0.4004, -1.9912, -0.4329],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0609, -0.0170,  0.0106,  ..., -0.0209, -0.0313,  0.0039],
        [ 0.0329,  0.0814,  0.0025,  ...,  0.0044,  0.0117,  0.0007],
        [-0.0007,  0.0096,  0.0942,  ..., -0.0560, -0.0068, -0.0064],
        ...,
        [-0.0088,  0.0297,  0.0280,  ...,  0.0837,  0.0150, -0.0228],
        [-0.0040, -0.0131,  0.0013,  ...,  0.0054,  0.0693, -0.0209],
        [-0.0184,  0.0112, -0.0399,  ..., -0.0218, -0.0041,  0.0609]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.2852, -6.2344,  2.2480,  ...,  0.2979, -2.7266, -0.0981]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 04:26:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for railway is railroad
Another word for list is listing
Another word for harbor is seaport
Another word for mother is mom
Another word for identical is same
Another word for organized is arranged
Another word for intelligent is clever
Another word for snake is
2024-07-30 04:26:05 root INFO     [order_1_approx] starting weight calculation for Another word for snake is serpent
Another word for intelligent is clever
Another word for mother is mom
Another word for railway is railroad
Another word for list is listing
Another word for organized is arranged
Another word for identical is same
Another word for harbor is
2024-07-30 04:26:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 04:28:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0459, -0.2107, -0.3660,  ...,  0.1007, -0.0184,  0.1720],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7173, -6.1797, -0.0239,  ...,  1.8555, -3.6074,  2.4961],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.0876e-01,  1.8280e-02,  3.4313e-03,  ..., -4.5300e-05,
         -1.7059e-02, -2.7634e-02],
        [ 6.2561e-04,  9.6741e-02, -2.6588e-03,  ..., -3.1490e-03,
         -9.8267e-03, -3.4546e-02],
        [-1.8280e-02, -1.5503e-02,  9.5398e-02,  ..., -1.9196e-02,
          4.7874e-03,  2.2964e-02],
        ...,
        [-9.9182e-03,  2.0248e-02,  4.2152e-04,  ...,  1.1237e-01,
          9.7504e-03, -2.9984e-02],
        [-2.8564e-02,  2.4002e-02,  2.8717e-02,  ..., -3.4241e-02,
          9.0271e-02, -2.1423e-02],
        [ 7.9727e-04, -9.4299e-03, -7.4158e-03,  ...,  2.7199e-03,
         -1.4526e-02,  9.2346e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7026, -5.2969, -0.1537,  ...,  2.0547, -2.9805,  2.4512]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 04:28:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for snake is serpent
Another word for intelligent is clever
Another word for mother is mom
Another word for railway is railroad
Another word for list is listing
Another word for organized is arranged
Another word for identical is same
Another word for harbor is
2024-07-30 04:28:21 root INFO     total operator prediction time: 1085.0723440647125 seconds
2024-07-30 04:28:21 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - youth
2024-07-30 04:28:21 root INFO     building operator animal - youth
2024-07-30 04:28:23 root INFO     [order_1_approx] starting weight calculation for The offspring of a chimpanzee is referred to as a baby
The offspring of a weasel is referred to as a kit
The offspring of a fish is referred to as a fingerling
The offspring of a rabbit is referred to as a bunny
The offspring of a wolf is referred to as a cub
The offspring of a seal is referred to as a pup
The offspring of a beetle is referred to as a larva
The offspring of a ferret is referred to as a
2024-07-30 04:28:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 04:30:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0859, -0.4663,  0.3289,  ...,  0.1801, -0.7705,  0.0601],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8223, -1.1582, -1.3857,  ...,  1.2637, -2.6777,  0.9932],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0459, -0.0057,  0.0036,  ...,  0.0170, -0.0106,  0.0027],
        [ 0.0015,  0.0348,  0.0147,  ...,  0.0236,  0.0230, -0.0100],
        [ 0.0109,  0.0185,  0.0267,  ...,  0.0055, -0.0238, -0.0223],
        ...,
        [ 0.0009, -0.0047,  0.0065,  ...,  0.0531, -0.0026,  0.0189],
        [-0.0023, -0.0093,  0.0073,  ...,  0.0037,  0.0273, -0.0128],
        [-0.0024, -0.0062, -0.0055,  ..., -0.0054, -0.0148,  0.0388]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3359, -1.1650, -1.7158,  ...,  1.6270, -2.5195,  0.9282]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 04:30:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a chimpanzee is referred to as a baby
The offspring of a weasel is referred to as a kit
The offspring of a fish is referred to as a fingerling
The offspring of a rabbit is referred to as a bunny
The offspring of a wolf is referred to as a cub
The offspring of a seal is referred to as a pup
The offspring of a beetle is referred to as a larva
The offspring of a ferret is referred to as a
2024-07-30 04:30:35 root INFO     [order_1_approx] starting weight calculation for The offspring of a weasel is referred to as a kit
The offspring of a seal is referred to as a pup
The offspring of a ferret is referred to as a kit
The offspring of a wolf is referred to as a cub
The offspring of a rabbit is referred to as a bunny
The offspring of a fish is referred to as a fingerling
The offspring of a chimpanzee is referred to as a baby
The offspring of a beetle is referred to as a
2024-07-30 04:30:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 04:32:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1979,  0.3730,  0.1315,  ...,  0.2356, -0.2935, -0.2947],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5449, -1.3066, -0.7607,  ...,  1.4189, -0.8276, -0.4961],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0432, -0.0248, -0.0054,  ...,  0.0065,  0.0070, -0.0279],
        [ 0.0200,  0.0244,  0.0081,  ...,  0.0020, -0.0019, -0.0210],
        [ 0.0011, -0.0028,  0.0293,  ...,  0.0029, -0.0087, -0.0139],
        ...,
        [ 0.0168,  0.0067, -0.0066,  ...,  0.0315,  0.0201, -0.0021],
        [ 0.0043,  0.0122,  0.0142,  ...,  0.0108,  0.0057, -0.0195],
        [-0.0027, -0.0036, -0.0015,  ..., -0.0075, -0.0126,  0.0361]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8379, -1.5264, -1.0391,  ...,  1.6084, -0.7866, -0.5366]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 04:32:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a weasel is referred to as a kit
The offspring of a seal is referred to as a pup
The offspring of a ferret is referred to as a kit
The offspring of a wolf is referred to as a cub
The offspring of a rabbit is referred to as a bunny
The offspring of a fish is referred to as a fingerling
The offspring of a chimpanzee is referred to as a baby
The offspring of a beetle is referred to as a
2024-07-30 04:32:47 root INFO     [order_1_approx] starting weight calculation for The offspring of a seal is referred to as a pup
The offspring of a beetle is referred to as a larva
The offspring of a fish is referred to as a fingerling
The offspring of a rabbit is referred to as a bunny
The offspring of a chimpanzee is referred to as a baby
The offspring of a weasel is referred to as a kit
The offspring of a ferret is referred to as a kit
The offspring of a wolf is referred to as a
2024-07-30 04:32:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 04:34:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3906,  0.2947,  0.4702,  ...,  0.2418, -0.4531, -0.1871],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4004, -6.4922, -2.8848,  ...,  0.9854, -3.5938,  2.8398],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0397, -0.0109, -0.0197,  ...,  0.0079, -0.0117, -0.0088],
        [-0.0112,  0.0355,  0.0124,  ..., -0.0062,  0.0086, -0.0137],
        [-0.0154,  0.0042,  0.0399,  ...,  0.0025, -0.0091, -0.0152],
        ...,
        [-0.0156,  0.0035,  0.0043,  ...,  0.0468,  0.0133,  0.0013],
        [ 0.0026, -0.0169,  0.0173,  ...,  0.0081,  0.0207, -0.0131],
        [ 0.0114, -0.0035,  0.0025,  ..., -0.0201, -0.0218,  0.0285]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0039, -5.9570, -2.5703,  ...,  0.9209, -3.7617,  2.9551]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 04:34:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a seal is referred to as a pup
The offspring of a beetle is referred to as a larva
The offspring of a fish is referred to as a fingerling
The offspring of a rabbit is referred to as a bunny
The offspring of a chimpanzee is referred to as a baby
The offspring of a weasel is referred to as a kit
The offspring of a ferret is referred to as a kit
The offspring of a wolf is referred to as a
2024-07-30 04:34:59 root INFO     [order_1_approx] starting weight calculation for The offspring of a rabbit is referred to as a bunny
The offspring of a ferret is referred to as a kit
The offspring of a fish is referred to as a fingerling
The offspring of a beetle is referred to as a larva
The offspring of a wolf is referred to as a cub
The offspring of a weasel is referred to as a kit
The offspring of a chimpanzee is referred to as a baby
The offspring of a seal is referred to as a
2024-07-30 04:34:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 04:37:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7266, -0.3838,  0.1113,  ...,  0.2219, -0.6880,  0.2097],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3760, -3.8711, -2.6836,  ..., -0.6143, -3.5469,  2.8633],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0409, -0.0206, -0.0257,  ...,  0.0335, -0.0160, -0.0093],
        [ 0.0036,  0.0381, -0.0013,  ..., -0.0029,  0.0052, -0.0160],
        [ 0.0189, -0.0007,  0.0399,  ...,  0.0180, -0.0106, -0.0225],
        ...,
        [ 0.0124,  0.0032,  0.0292,  ...,  0.0505,  0.0159, -0.0012],
        [ 0.0054, -0.0050,  0.0186,  ...,  0.0359,  0.0376, -0.0072],
        [-0.0067, -0.0116,  0.0071,  ..., -0.0294, -0.0045,  0.0231]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9629, -3.5117, -2.7695,  ..., -0.6445, -3.8438,  2.7598]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 04:37:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a rabbit is referred to as a bunny
The offspring of a ferret is referred to as a kit
The offspring of a fish is referred to as a fingerling
The offspring of a beetle is referred to as a larva
The offspring of a wolf is referred to as a cub
The offspring of a weasel is referred to as a kit
The offspring of a chimpanzee is referred to as a baby
The offspring of a seal is referred to as a
2024-07-30 04:37:05 root INFO     [order_1_approx] starting weight calculation for The offspring of a seal is referred to as a pup
The offspring of a chimpanzee is referred to as a baby
The offspring of a weasel is referred to as a kit
The offspring of a wolf is referred to as a cub
The offspring of a beetle is referred to as a larva
The offspring of a rabbit is referred to as a bunny
The offspring of a ferret is referred to as a kit
The offspring of a fish is referred to as a
2024-07-30 04:37:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 04:39:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3696, -0.0631, -0.0765,  ...,  0.0186, -0.0351,  0.4707],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5176, -2.9395, -3.3438,  ..., -0.3721, -4.4375,  1.1328],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.4067e-02, -1.4999e-02,  9.2363e-04,  ...,  1.4503e-02,
          8.2779e-03, -2.3071e-02],
        [-1.3107e-02,  6.2286e-02,  7.5073e-03,  ..., -9.8991e-04,
          7.4081e-03, -6.4774e-03],
        [ 9.3384e-03,  1.4877e-02,  4.4434e-02,  ...,  2.4307e-02,
         -6.4087e-04,  3.8528e-03],
        ...,
        [-2.2171e-02,  9.6130e-03,  7.8964e-03,  ...,  3.8330e-02,
          6.7596e-03, -2.6169e-03],
        [-8.2169e-03,  1.9760e-02,  1.3565e-02,  ..., -2.6703e-05,
          1.3077e-02,  2.2430e-03],
        [ 7.5111e-03,  3.0193e-03, -1.4603e-02,  ..., -1.8372e-02,
          2.5368e-04,  2.0523e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4971, -2.9395, -3.5469,  ..., -0.5425, -4.4258,  1.3730]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 04:39:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a seal is referred to as a pup
The offspring of a chimpanzee is referred to as a baby
The offspring of a weasel is referred to as a kit
The offspring of a wolf is referred to as a cub
The offspring of a beetle is referred to as a larva
The offspring of a rabbit is referred to as a bunny
The offspring of a ferret is referred to as a kit
The offspring of a fish is referred to as a
2024-07-30 04:39:13 root INFO     [order_1_approx] starting weight calculation for The offspring of a fish is referred to as a fingerling
The offspring of a chimpanzee is referred to as a baby
The offspring of a beetle is referred to as a larva
The offspring of a ferret is referred to as a kit
The offspring of a wolf is referred to as a cub
The offspring of a seal is referred to as a pup
The offspring of a rabbit is referred to as a bunny
The offspring of a weasel is referred to as a
2024-07-30 04:39:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 04:41:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0438,  0.0137,  0.3091,  ..., -0.1558, -0.7246, -0.4277],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5059, -2.0098, -0.2061,  ...,  1.9551, -0.6143,  1.9043],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0180, -0.0060, -0.0048,  ..., -0.0021,  0.0009, -0.0038],
        [ 0.0041,  0.0204,  0.0031,  ...,  0.0073,  0.0116, -0.0053],
        [-0.0006,  0.0041,  0.0150,  ...,  0.0122, -0.0091, -0.0125],
        ...,
        [ 0.0066,  0.0043,  0.0041,  ...,  0.0255,  0.0114, -0.0045],
        [-0.0017, -0.0015,  0.0004,  ...,  0.0123,  0.0177, -0.0043],
        [ 0.0053, -0.0164,  0.0015,  ..., -0.0122, -0.0037,  0.0078]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5664, -2.0625, -0.3013,  ...,  1.9580, -0.6025,  1.9189]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 04:41:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a fish is referred to as a fingerling
The offspring of a chimpanzee is referred to as a baby
The offspring of a beetle is referred to as a larva
The offspring of a ferret is referred to as a kit
The offspring of a wolf is referred to as a cub
The offspring of a seal is referred to as a pup
The offspring of a rabbit is referred to as a bunny
The offspring of a weasel is referred to as a
2024-07-30 04:41:25 root INFO     [order_1_approx] starting weight calculation for The offspring of a rabbit is referred to as a bunny
The offspring of a wolf is referred to as a cub
The offspring of a weasel is referred to as a kit
The offspring of a ferret is referred to as a kit
The offspring of a beetle is referred to as a larva
The offspring of a seal is referred to as a pup
The offspring of a fish is referred to as a fingerling
The offspring of a chimpanzee is referred to as a
2024-07-30 04:41:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 04:43:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1545,  0.0326,  0.0876,  ..., -0.2456, -0.9668, -0.2100],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6406, -3.4609, -1.1709,  ...,  0.8628, -4.2969,  2.6230],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.2146e-02, -2.1973e-03, -1.7834e-03,  ...,  2.2049e-03,
          7.8487e-04, -2.9373e-03],
        [-1.1406e-02,  5.7144e-03,  6.1340e-03,  ..., -2.2259e-03,
          4.3411e-03, -4.6158e-04],
        [-5.8517e-03,  5.3978e-04,  8.2016e-03,  ..., -3.1090e-03,
          2.9926e-03, -6.6376e-04],
        ...,
        [-2.3613e-03,  1.2836e-03, -1.0195e-03,  ...,  1.1261e-02,
          4.5204e-04, -2.5101e-03],
        [-2.1362e-04,  2.6703e-03,  4.4327e-03,  ..., -1.0471e-03,
          4.7531e-03,  2.7409e-03],
        [-1.2112e-03, -1.7099e-03, -4.2496e-03,  ..., -8.3923e-03,
          5.1498e-05,  8.7891e-03]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6553, -3.4316, -1.1699,  ...,  0.8862, -4.2891,  2.6113]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 04:43:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a rabbit is referred to as a bunny
The offspring of a wolf is referred to as a cub
The offspring of a weasel is referred to as a kit
The offspring of a ferret is referred to as a kit
The offspring of a beetle is referred to as a larva
The offspring of a seal is referred to as a pup
The offspring of a fish is referred to as a fingerling
The offspring of a chimpanzee is referred to as a
2024-07-30 04:43:37 root INFO     [order_1_approx] starting weight calculation for The offspring of a weasel is referred to as a kit
The offspring of a seal is referred to as a pup
The offspring of a ferret is referred to as a kit
The offspring of a fish is referred to as a fingerling
The offspring of a chimpanzee is referred to as a baby
The offspring of a beetle is referred to as a larva
The offspring of a wolf is referred to as a cub
The offspring of a rabbit is referred to as a
2024-07-30 04:43:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 04:45:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1169,  0.0757,  0.3740,  ..., -0.1396, -0.4604, -0.5176],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.9961, -1.9355, -1.0010,  ...,  2.2637, -2.5000,  0.0654],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0189, -0.0128,  0.0022,  ...,  0.0082,  0.0089, -0.0089],
        [-0.0095,  0.0190,  0.0107,  ...,  0.0012,  0.0088, -0.0118],
        [-0.0049,  0.0012,  0.0108,  ..., -0.0039, -0.0028, -0.0082],
        ...,
        [-0.0003,  0.0066,  0.0039,  ...,  0.0195,  0.0104, -0.0020],
        [ 0.0071,  0.0016,  0.0011,  ..., -0.0038,  0.0075,  0.0031],
        [-0.0042, -0.0035, -0.0031,  ..., -0.0122, -0.0047,  0.0161]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.0000, -1.8496, -1.0303,  ...,  2.2754, -2.4844,  0.0912]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 04:46:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a weasel is referred to as a kit
The offspring of a seal is referred to as a pup
The offspring of a ferret is referred to as a kit
The offspring of a fish is referred to as a fingerling
The offspring of a chimpanzee is referred to as a baby
The offspring of a beetle is referred to as a larva
The offspring of a wolf is referred to as a cub
The offspring of a rabbit is referred to as a
2024-07-30 04:46:06 root INFO     total operator prediction time: 1064.7513172626495 seconds
2024-07-30 04:46:06 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - sound
2024-07-30 04:46:06 root INFO     building operator animal - sound
2024-07-30 04:46:06 root INFO     [order_1_approx] starting weight calculation for The sound that a rat makes is called a squeak
The sound that a wolf makes is called a howl
The sound that a goat makes is called a bleat
The sound that a fly makes is called a buzz
The sound that a seal makes is called a bark
The sound that a coyote makes is called a howl
The sound that a crow makes is called a caw
The sound that a horse makes is called a
2024-07-30 04:46:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 04:48:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2242, -0.2070,  0.7803,  ...,  0.0710,  0.1201,  0.2527],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2227, -1.4814, -1.5566,  ...,  1.6357,  0.0410,  2.1113],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0520, -0.0119, -0.0049,  ..., -0.0060, -0.0040, -0.0008],
        [-0.0006,  0.0454, -0.0033,  ...,  0.0122,  0.0247, -0.0130],
        [-0.0074, -0.0010,  0.0578,  ..., -0.0253,  0.0002, -0.0140],
        ...,
        [ 0.0291,  0.0109,  0.0128,  ...,  0.0381, -0.0016, -0.0008],
        [-0.0185,  0.0119,  0.0069,  ...,  0.0161,  0.0387, -0.0121],
        [ 0.0056,  0.0003,  0.0142,  ..., -0.0135, -0.0069,  0.0127]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0388, -1.1973, -1.3496,  ...,  1.2207, -0.6431,  1.7295]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 04:48:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a rat makes is called a squeak
The sound that a wolf makes is called a howl
The sound that a goat makes is called a bleat
The sound that a fly makes is called a buzz
The sound that a seal makes is called a bark
The sound that a coyote makes is called a howl
The sound that a crow makes is called a caw
The sound that a horse makes is called a
2024-07-30 04:48:18 root INFO     [order_1_approx] starting weight calculation for The sound that a wolf makes is called a howl
The sound that a seal makes is called a bark
The sound that a fly makes is called a buzz
The sound that a goat makes is called a bleat
The sound that a coyote makes is called a howl
The sound that a horse makes is called a neigh
The sound that a crow makes is called a caw
The sound that a rat makes is called a
2024-07-30 04:48:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 04:50:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2072, -0.3547,  0.4868,  ..., -0.4121, -0.1676, -0.3511],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8867, -0.4622,  1.2734,  ..., -3.3105,  0.1230,  1.7031],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0594, -0.0154,  0.0125,  ..., -0.0048, -0.0278, -0.0081],
        [ 0.0027,  0.0749, -0.0010,  ...,  0.0117, -0.0004, -0.0316],
        [ 0.0077,  0.0101,  0.0648,  ..., -0.0153, -0.0130, -0.0289],
        ...,
        [ 0.0008, -0.0097,  0.0125,  ...,  0.0429, -0.0112, -0.0159],
        [ 0.0020, -0.0161, -0.0023,  ...,  0.0083,  0.0313,  0.0058],
        [ 0.0128,  0.0026, -0.0132,  ..., -0.0388, -0.0108,  0.0381]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8398, -0.7451,  1.0674,  ..., -3.6719,  0.1289,  1.7324]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 04:50:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a wolf makes is called a howl
The sound that a seal makes is called a bark
The sound that a fly makes is called a buzz
The sound that a goat makes is called a bleat
The sound that a coyote makes is called a howl
The sound that a horse makes is called a neigh
The sound that a crow makes is called a caw
The sound that a rat makes is called a
2024-07-30 04:50:31 root INFO     [order_1_approx] starting weight calculation for The sound that a fly makes is called a buzz
The sound that a rat makes is called a squeak
The sound that a goat makes is called a bleat
The sound that a crow makes is called a caw
The sound that a coyote makes is called a howl
The sound that a seal makes is called a bark
The sound that a horse makes is called a neigh
The sound that a wolf makes is called a
2024-07-30 04:50:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 04:52:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3774,  0.1683,  0.6436,  ...,  0.0354, -0.2688, -0.1343],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2363, -5.9297, -2.7500,  ..., -3.4512, -0.2349,  3.5332],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0427, -0.0154,  0.0036,  ..., -0.0061, -0.0306,  0.0104],
        [-0.0149,  0.0383,  0.0037,  ...,  0.0104,  0.0045, -0.0212],
        [ 0.0051, -0.0032,  0.0509,  ..., -0.0166, -0.0168, -0.0111],
        ...,
        [ 0.0052,  0.0069,  0.0128,  ...,  0.0635,  0.0006, -0.0046],
        [ 0.0045, -0.0088, -0.0120,  ..., -0.0026,  0.0234, -0.0074],
        [-0.0126, -0.0122, -0.0252,  ..., -0.0338,  0.0015,  0.0206]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2539, -5.6875, -2.4453,  ..., -3.7734, -0.6045,  3.4922]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 04:52:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a fly makes is called a buzz
The sound that a rat makes is called a squeak
The sound that a goat makes is called a bleat
The sound that a crow makes is called a caw
The sound that a coyote makes is called a howl
The sound that a seal makes is called a bark
The sound that a horse makes is called a neigh
The sound that a wolf makes is called a
2024-07-30 04:52:41 root INFO     [order_1_approx] starting weight calculation for The sound that a rat makes is called a squeak
The sound that a crow makes is called a caw
The sound that a coyote makes is called a howl
The sound that a wolf makes is called a howl
The sound that a fly makes is called a buzz
The sound that a seal makes is called a bark
The sound that a horse makes is called a neigh
The sound that a goat makes is called a
2024-07-30 04:52:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 04:54:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0526, -0.1718,  0.8179,  ..., -0.1110, -0.4680,  0.1653],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3145, -2.6719,  2.9297,  ..., -1.2725, -0.3291,  0.3530],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0499, -0.0139, -0.0111,  ..., -0.0196, -0.0208, -0.0056],
        [-0.0056,  0.0531, -0.0414,  ...,  0.0141,  0.0150,  0.0011],
        [-0.0028,  0.0090,  0.0562,  ..., -0.0263, -0.0155,  0.0007],
        ...,
        [ 0.0137,  0.0277, -0.0137,  ...,  0.0522, -0.0020, -0.0166],
        [ 0.0157,  0.0297, -0.0175,  ...,  0.0144,  0.0289, -0.0180],
        [ 0.0068, -0.0383,  0.0219,  ..., -0.0242,  0.0064,  0.0278]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4277, -2.6211,  2.9961,  ..., -1.4990, -0.3584,  0.4165]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 04:54:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a rat makes is called a squeak
The sound that a crow makes is called a caw
The sound that a coyote makes is called a howl
The sound that a wolf makes is called a howl
The sound that a fly makes is called a buzz
The sound that a seal makes is called a bark
The sound that a horse makes is called a neigh
The sound that a goat makes is called a
2024-07-30 04:54:54 root INFO     [order_1_approx] starting weight calculation for The sound that a rat makes is called a squeak
The sound that a horse makes is called a neigh
The sound that a goat makes is called a bleat
The sound that a fly makes is called a buzz
The sound that a coyote makes is called a howl
The sound that a crow makes is called a caw
The sound that a wolf makes is called a howl
The sound that a seal makes is called a
2024-07-30 04:54:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 04:57:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5215, -0.3474,  0.4780,  ...,  0.0445, -0.6279,  0.2361],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0869,  0.3650,  0.1484,  ..., -1.4961, -0.0947,  1.8418],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0713, -0.0210, -0.0170,  ..., -0.0143, -0.0227, -0.0139],
        [ 0.0197,  0.0652, -0.0154,  ..., -0.0069, -0.0263, -0.0542],
        [ 0.0392,  0.0113,  0.0495,  ..., -0.0267, -0.0254, -0.0338],
        ...,
        [ 0.0063,  0.0060,  0.0274,  ...,  0.0469, -0.0045, -0.0104],
        [-0.0211, -0.0033, -0.0157,  ...,  0.0202,  0.0497, -0.0006],
        [-0.0115, -0.0058, -0.0173,  ..., -0.0014, -0.0016,  0.0529]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8496, -0.4675, -0.0854,  ..., -1.7139,  0.0850,  1.9814]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 04:57:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a rat makes is called a squeak
The sound that a horse makes is called a neigh
The sound that a goat makes is called a bleat
The sound that a fly makes is called a buzz
The sound that a coyote makes is called a howl
The sound that a crow makes is called a caw
The sound that a wolf makes is called a howl
The sound that a seal makes is called a
2024-07-30 04:57:07 root INFO     [order_1_approx] starting weight calculation for The sound that a wolf makes is called a howl
The sound that a goat makes is called a bleat
The sound that a seal makes is called a bark
The sound that a crow makes is called a caw
The sound that a coyote makes is called a howl
The sound that a horse makes is called a neigh
The sound that a rat makes is called a squeak
The sound that a fly makes is called a
2024-07-30 04:57:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 04:59:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4702, -0.2124, -0.2661,  ...,  0.2869, -0.1132,  0.2338],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2109, -0.2607,  2.5156,  ..., -1.9258, -1.3633,  1.4248],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0486, -0.0078,  0.0033,  ..., -0.0014, -0.0234, -0.0065],
        [ 0.0014,  0.0529, -0.0143,  ..., -0.0013,  0.0026, -0.0162],
        [ 0.0019, -0.0041,  0.0558,  ...,  0.0010,  0.0112, -0.0119],
        ...,
        [ 0.0177,  0.0072,  0.0196,  ...,  0.0552, -0.0162, -0.0159],
        [-0.0069, -0.0160,  0.0129,  ...,  0.0072,  0.0259, -0.0044],
        [ 0.0071, -0.0077, -0.0083,  ..., -0.0283, -0.0047,  0.0446]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2754, -0.1635,  2.4570,  ..., -2.3203, -1.7607,  1.3838]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 04:59:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a wolf makes is called a howl
The sound that a goat makes is called a bleat
The sound that a seal makes is called a bark
The sound that a crow makes is called a caw
The sound that a coyote makes is called a howl
The sound that a horse makes is called a neigh
The sound that a rat makes is called a squeak
The sound that a fly makes is called a
2024-07-30 04:59:19 root INFO     [order_1_approx] starting weight calculation for The sound that a crow makes is called a caw
The sound that a horse makes is called a neigh
The sound that a rat makes is called a squeak
The sound that a seal makes is called a bark
The sound that a goat makes is called a bleat
The sound that a fly makes is called a buzz
The sound that a wolf makes is called a howl
The sound that a coyote makes is called a
2024-07-30 04:59:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 05:01:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1450,  0.3516,  0.0792,  ..., -0.2058, -0.2253, -0.2842],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5063, -5.4297, -0.8022,  ..., -2.8203,  0.0925,  1.9629],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0376, -0.0147, -0.0012,  ..., -0.0184, -0.0200,  0.0137],
        [-0.0179,  0.0301, -0.0007,  ...,  0.0024,  0.0056, -0.0214],
        [ 0.0281,  0.0092,  0.0316,  ..., -0.0225, -0.0174, -0.0056],
        ...,
        [-0.0007,  0.0114,  0.0066,  ...,  0.0518, -0.0018,  0.0012],
        [-0.0040, -0.0123, -0.0055,  ..., -0.0096,  0.0260, -0.0118],
        [-0.0022, -0.0149, -0.0286,  ..., -0.0201, -0.0004,  0.0196]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4172, -5.1328, -0.8276,  ..., -2.7910,  0.1311,  1.9902]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 05:01:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a crow makes is called a caw
The sound that a horse makes is called a neigh
The sound that a rat makes is called a squeak
The sound that a seal makes is called a bark
The sound that a goat makes is called a bleat
The sound that a fly makes is called a buzz
The sound that a wolf makes is called a howl
The sound that a coyote makes is called a
2024-07-30 05:01:31 root INFO     [order_1_approx] starting weight calculation for The sound that a horse makes is called a neigh
The sound that a seal makes is called a bark
The sound that a rat makes is called a squeak
The sound that a goat makes is called a bleat
The sound that a wolf makes is called a howl
The sound that a coyote makes is called a howl
The sound that a fly makes is called a buzz
The sound that a crow makes is called a
2024-07-30 05:01:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 05:03:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3318,  0.0356,  0.7441,  ...,  0.1564, -0.2084,  0.1971],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4434, -4.1445,  2.4941,  ..., -2.2852,  0.2075,  1.3594],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0632, -0.0003,  0.0207,  ..., -0.0099, -0.0364, -0.0033],
        [-0.0246,  0.0516,  0.0022,  ...,  0.0300,  0.0325, -0.0212],
        [ 0.0139, -0.0019,  0.0693,  ...,  0.0060, -0.0133, -0.0074],
        ...,
        [ 0.0023, -0.0006,  0.0077,  ...,  0.0603,  0.0108, -0.0106],
        [-0.0158, -0.0026, -0.0386,  ..., -0.0146,  0.0436, -0.0025],
        [ 0.0198, -0.0107,  0.0006,  ..., -0.0182, -0.0088,  0.0360]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1182, -3.7520,  2.4199,  ..., -2.6836, -0.1138,  1.0078]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 05:03:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a horse makes is called a neigh
The sound that a seal makes is called a bark
The sound that a rat makes is called a squeak
The sound that a goat makes is called a bleat
The sound that a wolf makes is called a howl
The sound that a coyote makes is called a howl
The sound that a fly makes is called a buzz
The sound that a crow makes is called a
2024-07-30 05:03:43 root INFO     total operator prediction time: 1057.3645997047424 seconds
2024-07-30 05:03:43 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on things - color
2024-07-30 05:03:43 root INFO     building operator things - color
2024-07-30 05:03:43 root INFO     [order_1_approx] starting weight calculation for The ant is colored black
The spinach is colored green
The sugar is colored white
The pepper is colored black
The celery is colored green
The emerald is colored green
The leaves is colored green
The chocolate is colored
2024-07-30 05:03:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 05:05:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1274, -0.6670, -0.3096,  ...,  0.0690, -0.5723,  0.0267],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3311, -5.0430, -0.9756,  ..., -3.1250, -3.6719,  1.8398],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0338, -0.0046,  0.0046,  ..., -0.0016,  0.0026,  0.0008],
        [ 0.0044,  0.0248,  0.0103,  ..., -0.0019, -0.0025, -0.0156],
        [-0.0052,  0.0012,  0.0172,  ...,  0.0077, -0.0025,  0.0025],
        ...,
        [ 0.0037,  0.0012,  0.0022,  ...,  0.0223, -0.0058, -0.0013],
        [ 0.0007,  0.0060, -0.0098,  ...,  0.0104,  0.0242, -0.0039],
        [-0.0014, -0.0057, -0.0040,  ...,  0.0126,  0.0032,  0.0282]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4414, -4.8984, -1.0527,  ..., -3.0020, -3.5332,  1.9170]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 05:05:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The ant is colored black
The spinach is colored green
The sugar is colored white
The pepper is colored black
The celery is colored green
The emerald is colored green
The leaves is colored green
The chocolate is colored
2024-07-30 05:05:57 root INFO     [order_1_approx] starting weight calculation for The spinach is colored green
The emerald is colored green
The pepper is colored black
The chocolate is colored white
The sugar is colored white
The leaves is colored green
The celery is colored green
The ant is colored
2024-07-30 05:05:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 05:08:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2720, -0.2966, -0.0458,  ..., -0.2437, -0.3652, -0.2136],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5288, -4.3164,  0.1121,  ..., -0.7217, -1.7705, -2.2891],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0554, -0.0074,  0.0067,  ..., -0.0059,  0.0089,  0.0037],
        [ 0.0159,  0.0367,  0.0054,  ...,  0.0026,  0.0114, -0.0084],
        [-0.0048, -0.0073,  0.0235,  ...,  0.0134, -0.0146,  0.0051],
        ...,
        [ 0.0031, -0.0006,  0.0046,  ...,  0.0481, -0.0046, -0.0093],
        [ 0.0042,  0.0065, -0.0026,  ...,  0.0185,  0.0229, -0.0002],
        [ 0.0029, -0.0011, -0.0070,  ..., -0.0069, -0.0064,  0.0352]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4539, -4.4180, -0.3789,  ..., -0.3325, -1.8447, -2.2285]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 05:08:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The spinach is colored green
The emerald is colored green
The pepper is colored black
The chocolate is colored white
The sugar is colored white
The leaves is colored green
The celery is colored green
The ant is colored
2024-07-30 05:08:10 root INFO     [order_1_approx] starting weight calculation for The celery is colored green
The leaves is colored green
The chocolate is colored white
The spinach is colored green
The pepper is colored black
The ant is colored black
The emerald is colored green
The sugar is colored
2024-07-30 05:08:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 05:10:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1638, -0.4707, -0.2247,  ..., -0.0834, -0.2544, -0.4639],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.1328, -5.1602,  0.6719,  ..., -3.0195, -1.4219, -0.9868],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0622, -0.0137,  0.0088,  ...,  0.0064,  0.0041,  0.0091],
        [ 0.0227,  0.0711,  0.0153,  ...,  0.0005,  0.0279, -0.0216],
        [-0.0055, -0.0134,  0.0431,  ...,  0.0270, -0.0150,  0.0054],
        ...,
        [ 0.0066,  0.0007,  0.0144,  ...,  0.0495,  0.0040, -0.0076],
        [-0.0212,  0.0200, -0.0097,  ...,  0.0134,  0.0478, -0.0157],
        [-0.0099, -0.0217,  0.0082,  ..., -0.0003, -0.0169,  0.0435]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.0342, -4.7812,  0.2754,  ..., -2.8457, -1.1572, -0.4907]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 05:10:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The celery is colored green
The leaves is colored green
The chocolate is colored white
The spinach is colored green
The pepper is colored black
The ant is colored black
The emerald is colored green
The sugar is colored
2024-07-30 05:10:23 root INFO     [order_1_approx] starting weight calculation for The pepper is colored black
The spinach is colored green
The emerald is colored green
The celery is colored green
The chocolate is colored white
The sugar is colored white
The ant is colored black
The leaves is colored
2024-07-30 05:10:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 05:12:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5107, -0.1284, -0.4902,  ..., -0.1443,  0.0475, -0.1722],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2654, -6.5859, -0.5967,  ..., -0.0361, -0.3193, -4.0625],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0804, -0.0043,  0.0027,  ..., -0.0018,  0.0049,  0.0007],
        [ 0.0172,  0.0464,  0.0042,  ...,  0.0082,  0.0091, -0.0207],
        [-0.0018, -0.0045,  0.0446,  ..., -0.0071, -0.0040,  0.0083],
        ...,
        [ 0.0062,  0.0001,  0.0073,  ...,  0.0538, -0.0083,  0.0048],
        [-0.0114,  0.0032, -0.0004,  ...,  0.0193,  0.0500, -0.0076],
        [ 0.0002, -0.0052, -0.0025,  ..., -0.0002, -0.0161,  0.0564]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0361, -6.6250, -0.8086,  ...,  0.1304, -0.6436, -4.0586]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 05:12:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The pepper is colored black
The spinach is colored green
The emerald is colored green
The celery is colored green
The chocolate is colored white
The sugar is colored white
The ant is colored black
The leaves is colored
2024-07-30 05:12:36 root INFO     [order_1_approx] starting weight calculation for The sugar is colored white
The ant is colored black
The chocolate is colored white
The pepper is colored black
The spinach is colored green
The emerald is colored green
The leaves is colored green
The celery is colored
2024-07-30 05:12:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 05:14:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1586, -0.4287,  0.1016,  ..., -0.4082, -0.7310,  0.1625],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2634, -3.2559, -1.6953,  ..., -2.1797, -1.6494, -2.6055],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0753, -0.0149,  0.0072,  ..., -0.0118,  0.0150, -0.0137],
        [ 0.0075,  0.0464,  0.0142,  ...,  0.0197,  0.0143, -0.0303],
        [-0.0175, -0.0129,  0.0555,  ...,  0.0220, -0.0238,  0.0003],
        ...,
        [ 0.0063, -0.0095, -0.0021,  ...,  0.0722, -0.0036, -0.0158],
        [ 0.0094,  0.0180, -0.0139,  ...,  0.0189,  0.0722, -0.0035],
        [-0.0156, -0.0161,  0.0020,  ..., -0.0145,  0.0092,  0.0540]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1217, -3.2422, -1.7158,  ..., -1.6016, -1.6348, -2.2031]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 05:14:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sugar is colored white
The ant is colored black
The chocolate is colored white
The pepper is colored black
The spinach is colored green
The emerald is colored green
The leaves is colored green
The celery is colored
2024-07-30 05:14:49 root INFO     [order_1_approx] starting weight calculation for The leaves is colored green
The celery is colored green
The chocolate is colored white
The ant is colored black
The sugar is colored white
The pepper is colored black
The emerald is colored green
The spinach is colored
2024-07-30 05:14:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 05:16:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1279, -0.2354, -0.0656,  ...,  0.1389, -0.5493,  0.1515],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7275, -4.4453, -1.9043,  ..., -1.4883, -1.2207, -3.0625],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.3059e-02,  1.1810e-02, -3.8414e-03,  ..., -1.1047e-02,
          2.8133e-03,  2.7580e-03],
        [ 1.9470e-02,  3.4729e-02,  2.3132e-02,  ...,  8.8043e-03,
          1.5083e-02, -2.0370e-02],
        [-2.7676e-03, -1.9272e-02,  5.5206e-02,  ...,  8.3237e-03,
         -2.0676e-02, -2.7657e-05],
        ...,
        [ 9.2621e-03, -5.7945e-03, -1.4000e-02,  ...,  6.1676e-02,
          7.1793e-03, -1.4133e-03],
        [ 2.8458e-03,  1.5015e-02, -7.9803e-03,  ...,  2.0889e-02,
          5.7983e-02, -1.5350e-02],
        [-1.0979e-02, -7.2098e-04,  2.1763e-03,  ..., -1.4732e-02,
          7.8278e-03,  4.8187e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5459, -4.2734, -2.4043,  ..., -1.0234, -1.1592, -2.3340]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 05:16:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The leaves is colored green
The celery is colored green
The chocolate is colored white
The ant is colored black
The sugar is colored white
The pepper is colored black
The emerald is colored green
The spinach is colored
2024-07-30 05:16:59 root INFO     [order_1_approx] starting weight calculation for The emerald is colored green
The spinach is colored green
The chocolate is colored white
The ant is colored black
The celery is colored green
The leaves is colored green
The sugar is colored white
The pepper is colored
2024-07-30 05:16:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 05:19:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2903, -0.0066, -0.2598,  ..., -0.0500, -0.3599, -0.2729],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.9067, -5.6797, -1.9844,  ..., -2.4219, -0.7471, -3.6543],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0865, -0.0103,  0.0077,  ..., -0.0251,  0.0339,  0.0029],
        [ 0.0323,  0.0672,  0.0260,  ..., -0.0089,  0.0213, -0.0075],
        [-0.0121, -0.0173,  0.0385,  ...,  0.0178, -0.0098, -0.0011],
        ...,
        [ 0.0212,  0.0062,  0.0174,  ...,  0.0542, -0.0078, -0.0027],
        [ 0.0121,  0.0112, -0.0299,  ...,  0.0156,  0.0608, -0.0099],
        [ 0.0061,  0.0051,  0.0080,  ..., -0.0084, -0.0090,  0.0502]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6631, -5.2461, -2.2930,  ..., -2.1836, -0.6699, -3.4316]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 05:19:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The emerald is colored green
The spinach is colored green
The chocolate is colored white
The ant is colored black
The celery is colored green
The leaves is colored green
The sugar is colored white
The pepper is colored
2024-07-30 05:19:25 root INFO     [order_1_approx] starting weight calculation for The spinach is colored green
The leaves is colored green
The chocolate is colored white
The ant is colored black
The celery is colored green
The sugar is colored white
The pepper is colored black
The emerald is colored
2024-07-30 05:19:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 05:21:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1403, -0.6353, -0.5244,  ..., -0.2339,  0.3027,  0.1110],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0820, -0.8555, -2.0156,  ..., -0.0938,  2.4844, -0.4395],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0731, -0.0054,  0.0025,  ..., -0.0108,  0.0157,  0.0081],
        [ 0.0121,  0.0413,  0.0116,  ...,  0.0130,  0.0066, -0.0164],
        [-0.0014, -0.0199,  0.0479,  ..., -0.0016, -0.0042,  0.0052],
        ...,
        [-0.0078, -0.0006,  0.0257,  ...,  0.0812, -0.0048, -0.0274],
        [ 0.0058,  0.0130,  0.0057,  ...,  0.0427,  0.0555,  0.0005],
        [-0.0162, -0.0164, -0.0044,  ..., -0.0015, -0.0220,  0.0463]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9736, -1.0215, -2.2012,  ..., -0.1426,  2.3203, -0.4797]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 05:21:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The spinach is colored green
The leaves is colored green
The chocolate is colored white
The ant is colored black
The celery is colored green
The sugar is colored white
The pepper is colored black
The emerald is colored
2024-07-30 05:21:39 root INFO     total operator prediction time: 1075.7275092601776 seconds
2024-07-30 05:21:39 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on country - capital
2024-07-30 05:21:39 root INFO     building operator country - capital
2024-07-30 05:21:39 root INFO     [order_1_approx] starting weight calculation for The country with baghdad as its capital is known as iraq
The country with london as its capital is known as england
The country with kabul as its capital is known as afghanistan
The country with madrid as its capital is known as spain
The country with dhaka as its capital is known as bangladesh
The country with zagreb as its capital is known as croatia
The country with berlin as its capital is known as germany
The country with vienna as its capital is known as
2024-07-30 05:21:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 05:23:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5464, -0.1229, -0.0642,  ...,  0.3296,  0.3638,  0.0144],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4229, -5.9766, -0.4595,  ..., -0.0100,  1.0723, -2.7598],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0300, -0.0109, -0.0033,  ...,  0.0108, -0.0033,  0.0048],
        [-0.0167,  0.0279,  0.0024,  ..., -0.0009, -0.0115, -0.0141],
        [-0.0011, -0.0039,  0.0258,  ...,  0.0190, -0.0059, -0.0109],
        ...,
        [-0.0033,  0.0128, -0.0057,  ...,  0.0342,  0.0067, -0.0049],
        [ 0.0226,  0.0133, -0.0050,  ...,  0.0084,  0.0155,  0.0037],
        [-0.0127,  0.0090,  0.0088,  ...,  0.0056, -0.0067,  0.0086]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3691, -5.8945, -0.4719,  ...,  0.0505,  1.2354, -2.5098]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 05:23:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with baghdad as its capital is known as iraq
The country with london as its capital is known as england
The country with kabul as its capital is known as afghanistan
The country with madrid as its capital is known as spain
The country with dhaka as its capital is known as bangladesh
The country with zagreb as its capital is known as croatia
The country with berlin as its capital is known as germany
The country with vienna as its capital is known as
2024-07-30 05:23:51 root INFO     [order_1_approx] starting weight calculation for The country with kabul as its capital is known as afghanistan
The country with london as its capital is known as england
The country with madrid as its capital is known as spain
The country with zagreb as its capital is known as croatia
The country with berlin as its capital is known as germany
The country with vienna as its capital is known as austria
The country with baghdad as its capital is known as iraq
The country with dhaka as its capital is known as
2024-07-30 05:23:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 05:26:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0047, -0.0349, -0.5068,  ...,  0.6562, -0.3774,  0.1487],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4043, -5.6797, -0.3076,  ..., -1.9746, -0.3457, -4.9297],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0291, -0.0054, -0.0058,  ..., -0.0025, -0.0133,  0.0013],
        [-0.0142,  0.0339,  0.0068,  ..., -0.0069,  0.0164, -0.0203],
        [-0.0114,  0.0168,  0.0365,  ..., -0.0095,  0.0023, -0.0209],
        ...,
        [-0.0059,  0.0005,  0.0023,  ...,  0.0380,  0.0098, -0.0002],
        [-0.0017,  0.0155, -0.0032,  ..., -0.0045,  0.0172,  0.0034],
        [-0.0251,  0.0039, -0.0039,  ...,  0.0035,  0.0127,  0.0153]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4780, -5.7070, -0.4539,  ..., -1.8906, -0.0378, -4.6094]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 05:26:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with kabul as its capital is known as afghanistan
The country with london as its capital is known as england
The country with madrid as its capital is known as spain
The country with zagreb as its capital is known as croatia
The country with berlin as its capital is known as germany
The country with vienna as its capital is known as austria
The country with baghdad as its capital is known as iraq
The country with dhaka as its capital is known as
2024-07-30 05:26:04 root INFO     [order_1_approx] starting weight calculation for The country with vienna as its capital is known as austria
The country with madrid as its capital is known as spain
The country with london as its capital is known as england
The country with berlin as its capital is known as germany
The country with zagreb as its capital is known as croatia
The country with dhaka as its capital is known as bangladesh
The country with baghdad as its capital is known as iraq
The country with kabul as its capital is known as
2024-07-30 05:26:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 05:28:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0939,  0.1458, -0.3677,  ...,  0.4673, -0.4761,  0.2401],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1582, -4.2969, -0.7183,  ..., -0.2568,  0.1445, -1.7656],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0341, -0.0115, -0.0077,  ...,  0.0102, -0.0125, -0.0063],
        [-0.0032,  0.0262,  0.0231,  ..., -0.0083,  0.0028, -0.0202],
        [ 0.0005,  0.0200,  0.0251,  ...,  0.0134, -0.0039,  0.0020],
        ...,
        [ 0.0051,  0.0022, -0.0021,  ...,  0.0390,  0.0125,  0.0079],
        [ 0.0033,  0.0046, -0.0132,  ..., -0.0020,  0.0195, -0.0019],
        [-0.0083,  0.0155, -0.0036,  ...,  0.0188,  0.0152,  0.0174]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3154, -3.9023, -1.1836,  ..., -0.2125, -0.0897, -2.1387]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 05:28:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with vienna as its capital is known as austria
The country with madrid as its capital is known as spain
The country with london as its capital is known as england
The country with berlin as its capital is known as germany
The country with zagreb as its capital is known as croatia
The country with dhaka as its capital is known as bangladesh
The country with baghdad as its capital is known as iraq
The country with kabul as its capital is known as
2024-07-30 05:28:16 root INFO     [order_1_approx] starting weight calculation for The country with zagreb as its capital is known as croatia
The country with vienna as its capital is known as austria
The country with berlin as its capital is known as germany
The country with dhaka as its capital is known as bangladesh
The country with kabul as its capital is known as afghanistan
The country with london as its capital is known as england
The country with baghdad as its capital is known as iraq
The country with madrid as its capital is known as
2024-07-30 05:28:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 05:30:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5732, -0.1516, -0.6895,  ...,  0.7583,  0.4429,  0.1182],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3125, -5.2891, -1.7324,  ...,  1.1279,  1.1387, -5.2344],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.1097e-02,  1.9054e-03, -4.6082e-03,  ...,  5.7564e-03,
         -9.8877e-03,  7.1487e-03],
        [-3.9902e-03,  3.4485e-02,  1.7120e-02,  ...,  2.2554e-04,
         -6.4240e-03, -1.5541e-02],
        [-2.5387e-03,  9.8877e-03,  4.5929e-02,  ...,  1.4435e-02,
          1.4084e-02, -7.9422e-03],
        ...,
        [-2.8133e-03,  9.5520e-03,  1.1978e-03,  ...,  3.2043e-02,
          7.4043e-03, -1.3023e-02],
        [ 1.0284e-02, -8.3313e-03, -1.1223e-02,  ..., -8.3160e-03,
          8.1863e-03, -1.6251e-03],
        [-1.3237e-02, -8.7738e-05, -4.4594e-03,  ...,  1.4915e-02,
         -6.0616e-03,  1.8021e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2188, -4.9453, -1.8594,  ...,  0.8960,  1.2832, -5.0938]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 05:30:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with zagreb as its capital is known as croatia
The country with vienna as its capital is known as austria
The country with berlin as its capital is known as germany
The country with dhaka as its capital is known as bangladesh
The country with kabul as its capital is known as afghanistan
The country with london as its capital is known as england
The country with baghdad as its capital is known as iraq
The country with madrid as its capital is known as
2024-07-30 05:30:27 root INFO     [order_1_approx] starting weight calculation for The country with dhaka as its capital is known as bangladesh
The country with london as its capital is known as england
The country with kabul as its capital is known as afghanistan
The country with baghdad as its capital is known as iraq
The country with vienna as its capital is known as austria
The country with madrid as its capital is known as spain
The country with berlin as its capital is known as germany
The country with zagreb as its capital is known as
2024-07-30 05:30:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 05:32:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4712, -0.2104, -0.6782,  ...,  0.3840, -0.0087,  0.2382],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8457, -6.8164, -3.1426,  ..., -2.2930,  2.4609, -1.5000],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0348, -0.0040,  0.0004,  ...,  0.0271, -0.0073,  0.0025],
        [ 0.0007,  0.0359,  0.0254,  ...,  0.0057,  0.0058, -0.0207],
        [-0.0007,  0.0142,  0.0526,  ...,  0.0044,  0.0035, -0.0010],
        ...,
        [ 0.0040,  0.0035,  0.0015,  ...,  0.0346,  0.0014, -0.0106],
        [ 0.0110,  0.0135, -0.0070,  ...,  0.0020,  0.0078,  0.0045],
        [-0.0081, -0.0039,  0.0013,  ...,  0.0051,  0.0045,  0.0054]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9707, -6.5000, -2.8613,  ..., -2.2637,  1.7852, -1.3457]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 05:32:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with dhaka as its capital is known as bangladesh
The country with london as its capital is known as england
The country with kabul as its capital is known as afghanistan
The country with baghdad as its capital is known as iraq
The country with vienna as its capital is known as austria
The country with madrid as its capital is known as spain
The country with berlin as its capital is known as germany
The country with zagreb as its capital is known as
2024-07-30 05:32:37 root INFO     [order_1_approx] starting weight calculation for The country with zagreb as its capital is known as croatia
The country with kabul as its capital is known as afghanistan
The country with dhaka as its capital is known as bangladesh
The country with london as its capital is known as england
The country with vienna as its capital is known as austria
The country with madrid as its capital is known as spain
The country with baghdad as its capital is known as iraq
The country with berlin as its capital is known as
2024-07-30 05:32:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 05:34:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6318,  0.1649, -0.2898,  ...,  0.7114,  0.2290, -0.0173],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0112, -5.5742, -0.6284,  ..., -0.0940,  1.1025, -4.5469],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.5574e-02, -1.6727e-03, -6.0425e-03,  ...,  5.5389e-03,
         -7.9956e-03,  4.0436e-03],
        [-2.1774e-02,  3.1738e-02,  1.8188e-02,  ...,  7.6485e-03,
         -6.5918e-03, -2.8778e-02],
        [-4.8676e-03,  1.3023e-02,  5.5389e-02,  ...,  1.7960e-02,
         -5.5237e-03, -1.7715e-02],
        ...,
        [-1.1131e-02, -4.7150e-03,  2.8706e-03,  ...,  5.1178e-02,
         -2.8229e-03, -4.5929e-03],
        [ 1.9974e-02, -2.0142e-03, -8.1062e-05,  ..., -1.7929e-04,
          5.1117e-03, -1.5106e-02],
        [-1.7548e-02,  3.0098e-03, -1.1082e-03,  ...,  3.4485e-03,
         -1.0147e-02,  2.1896e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1560e-01, -5.5664e+00, -6.5967e-01,  ...,  3.5400e-03,
          8.9160e-01, -4.2734e+00]], device='cuda:1', dtype=torch.float16,
       grad_fn=<SubBackward0>) 

                    
2024-07-30 05:34:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with zagreb as its capital is known as croatia
The country with kabul as its capital is known as afghanistan
The country with dhaka as its capital is known as bangladesh
The country with london as its capital is known as england
The country with vienna as its capital is known as austria
The country with madrid as its capital is known as spain
The country with baghdad as its capital is known as iraq
The country with berlin as its capital is known as
2024-07-30 05:34:49 root INFO     [order_1_approx] starting weight calculation for The country with vienna as its capital is known as austria
The country with london as its capital is known as england
The country with zagreb as its capital is known as croatia
The country with madrid as its capital is known as spain
The country with kabul as its capital is known as afghanistan
The country with berlin as its capital is known as germany
The country with dhaka as its capital is known as bangladesh
The country with baghdad as its capital is known as
2024-07-30 05:34:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 05:37:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0826,  0.0900, -0.4956,  ...,  0.0066,  0.1719,  0.1190],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5151, -1.9883, -0.4626,  ..., -0.1855,  0.5156, -4.1523],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0104, -0.0061, -0.0020,  ...,  0.0039, -0.0044, -0.0046],
        [-0.0119,  0.0232,  0.0020,  ..., -0.0076,  0.0038, -0.0141],
        [ 0.0012,  0.0052,  0.0226,  ...,  0.0083,  0.0033, -0.0077],
        ...,
        [-0.0034,  0.0065, -0.0066,  ...,  0.0216,  0.0083, -0.0064],
        [-0.0019, -0.0023,  0.0038,  ..., -0.0041,  0.0018, -0.0041],
        [ 0.0003,  0.0025, -0.0111,  ...,  0.0085,  0.0005,  0.0092]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4795, -1.8701, -0.4453,  ..., -0.1592,  0.5620, -4.1836]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 05:37:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with vienna as its capital is known as austria
The country with london as its capital is known as england
The country with zagreb as its capital is known as croatia
The country with madrid as its capital is known as spain
The country with kabul as its capital is known as afghanistan
The country with berlin as its capital is known as germany
The country with dhaka as its capital is known as bangladesh
The country with baghdad as its capital is known as
2024-07-30 05:37:01 root INFO     [order_1_approx] starting weight calculation for The country with kabul as its capital is known as afghanistan
The country with dhaka as its capital is known as bangladesh
The country with madrid as its capital is known as spain
The country with berlin as its capital is known as germany
The country with zagreb as its capital is known as croatia
The country with vienna as its capital is known as austria
The country with baghdad as its capital is known as iraq
The country with london as its capital is known as
2024-07-30 05:37:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 05:39:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3896, -0.1536, -0.1392,  ...,  0.5957,  0.6436, -0.1423],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4844, -5.7969, -1.2520,  ..., -3.6133,  1.3232, -5.8438],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0283, -0.0086,  0.0046,  ...,  0.0031,  0.0019,  0.0055],
        [-0.0096,  0.0276,  0.0050,  ..., -0.0012, -0.0124, -0.0016],
        [-0.0046,  0.0060,  0.0317,  ...,  0.0112,  0.0093, -0.0017],
        ...,
        [-0.0055, -0.0003,  0.0046,  ...,  0.0269,  0.0048, -0.0105],
        [-0.0022,  0.0026, -0.0006,  ..., -0.0069,  0.0174, -0.0050],
        [-0.0046, -0.0101, -0.0059,  ..., -0.0054, -0.0131,  0.0201]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4512, -5.6406, -1.3672,  ..., -3.4375,  1.3271, -5.7227]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 05:39:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with kabul as its capital is known as afghanistan
The country with dhaka as its capital is known as bangladesh
The country with madrid as its capital is known as spain
The country with berlin as its capital is known as germany
The country with zagreb as its capital is known as croatia
The country with vienna as its capital is known as austria
The country with baghdad as its capital is known as iraq
The country with london as its capital is known as
2024-07-30 05:39:13 root INFO     total operator prediction time: 1053.810557126999 seconds
2024-07-30 05:39:13 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on name - occupation
2024-07-30 05:39:13 root INFO     building operator name - occupation
2024-07-30 05:39:13 root INFO     [order_1_approx] starting weight calculation for depp was known for their work as a  actor
balzac was known for their work as a  novelist
hume was known for their work as a  philosopher
truman was known for their work as a  president
picasso was known for their work as a  painter
dante was known for their work as a  poet
wagner was known for their work as a  composer
moses was known for their work as a 
2024-07-30 05:39:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 05:41:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1591,  0.0608, -0.0996,  ...,  0.1943, -0.2048,  0.5928],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6006, -5.2031,  0.7197,  ..., -5.2969,  2.7344, -0.7188],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0486, -0.0105,  0.0050,  ..., -0.0234, -0.0310,  0.0102],
        [ 0.0096,  0.0449,  0.0049,  ..., -0.0270,  0.0124,  0.0034],
        [ 0.0327, -0.0068,  0.0583,  ..., -0.0134, -0.0145, -0.0076],
        ...,
        [ 0.0276,  0.0218,  0.0071,  ...,  0.0733, -0.0036,  0.0070],
        [ 0.0322,  0.0073,  0.0174,  ...,  0.0020,  0.0303,  0.0064],
        [-0.0237,  0.0011, -0.0153,  ...,  0.0019, -0.0201,  0.0486]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5596, -5.1406,  1.0967,  ..., -5.2812,  2.3652, -0.5322]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 05:41:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for depp was known for their work as a  actor
balzac was known for their work as a  novelist
hume was known for their work as a  philosopher
truman was known for their work as a  president
picasso was known for their work as a  painter
dante was known for their work as a  poet
wagner was known for their work as a  composer
moses was known for their work as a 
2024-07-30 05:41:26 root INFO     [order_1_approx] starting weight calculation for balzac was known for their work as a  novelist
depp was known for their work as a  actor
moses was known for their work as a  prophet
picasso was known for their work as a  painter
wagner was known for their work as a  composer
hume was known for their work as a  philosopher
truman was known for their work as a  president
dante was known for their work as a 
2024-07-30 05:41:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 05:43:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0966, -0.5225, -0.5273,  ...,  0.7031,  0.0399,  0.4995],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5156, -7.8203,  2.0293,  ..., -4.3242, -0.7275, -0.1807],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0529, -0.0107,  0.0070,  ...,  0.0015, -0.0233,  0.0067],
        [ 0.0031,  0.0303, -0.0041,  ..., -0.0251, -0.0039, -0.0042],
        [ 0.0100, -0.0029,  0.0515,  ...,  0.0021, -0.0039, -0.0030],
        ...,
        [ 0.0116,  0.0109, -0.0130,  ...,  0.0649,  0.0052,  0.0007],
        [ 0.0011,  0.0191, -0.0031,  ...,  0.0125,  0.0375,  0.0046],
        [-0.0044, -0.0057, -0.0015,  ..., -0.0038, -0.0067,  0.0499]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5059, -7.2227,  2.1934,  ..., -4.2695, -0.5156, -0.2556]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 05:43:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for balzac was known for their work as a  novelist
depp was known for their work as a  actor
moses was known for their work as a  prophet
picasso was known for their work as a  painter
wagner was known for their work as a  composer
hume was known for their work as a  philosopher
truman was known for their work as a  president
dante was known for their work as a 
2024-07-30 05:43:38 root INFO     [order_1_approx] starting weight calculation for wagner was known for their work as a  composer
depp was known for their work as a  actor
picasso was known for their work as a  painter
moses was known for their work as a  prophet
balzac was known for their work as a  novelist
hume was known for their work as a  philosopher
dante was known for their work as a  poet
truman was known for their work as a 
2024-07-30 05:43:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 05:45:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1323, -0.1436, -0.1455,  ...,  0.4688, -0.2152,  0.3452],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.4258, -2.9492,  3.3926,  ..., -2.6758,  0.2520, -0.0581],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0731, -0.0016,  0.0138,  ...,  0.0179,  0.0014, -0.0005],
        [-0.0263,  0.0536,  0.0135,  ..., -0.0016, -0.0070,  0.0186],
        [ 0.0225, -0.0114,  0.0657,  ..., -0.0066,  0.0013,  0.0092],
        ...,
        [ 0.0037, -0.0013,  0.0066,  ...,  0.0789, -0.0145,  0.0212],
        [ 0.0093,  0.0318, -0.0035,  ...,  0.0157,  0.0463,  0.0037],
        [-0.0041, -0.0063, -0.0106,  ..., -0.0038, -0.0200,  0.0776]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 6.3516, -3.4375,  3.1621,  ..., -2.7871,  0.5205, -0.4604]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 05:45:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for wagner was known for their work as a  composer
depp was known for their work as a  actor
picasso was known for their work as a  painter
moses was known for their work as a  prophet
balzac was known for their work as a  novelist
hume was known for their work as a  philosopher
dante was known for their work as a  poet
truman was known for their work as a 
2024-07-30 05:45:47 root INFO     [order_1_approx] starting weight calculation for wagner was known for their work as a  composer
depp was known for their work as a  actor
moses was known for their work as a  prophet
dante was known for their work as a  poet
picasso was known for their work as a  painter
hume was known for their work as a  philosopher
truman was known for their work as a  president
balzac was known for their work as a 
2024-07-30 05:45:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 05:47:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2974, -0.2808, -0.3186,  ...,  0.1541, -0.2372,  0.1804],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2949, -4.0977,  3.2617,  ..., -2.9551, -1.2764,  0.4512],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0703, -0.0068,  0.0144,  ..., -0.0120, -0.0029,  0.0003],
        [ 0.0003,  0.0314,  0.0087,  ..., -0.0053, -0.0054,  0.0021],
        [ 0.0097, -0.0018,  0.0599,  ...,  0.0042,  0.0067,  0.0026],
        ...,
        [ 0.0017, -0.0023, -0.0087,  ...,  0.0886,  0.0003, -0.0055],
        [ 0.0051,  0.0219,  0.0100,  ..., -0.0024,  0.0505, -0.0070],
        [-0.0110, -0.0175,  0.0042,  ...,  0.0165, -0.0141,  0.0648]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6553, -4.1016,  3.1699,  ..., -3.0332, -1.1514,  0.4014]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 05:48:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for wagner was known for their work as a  composer
depp was known for their work as a  actor
moses was known for their work as a  prophet
dante was known for their work as a  poet
picasso was known for their work as a  painter
hume was known for their work as a  philosopher
truman was known for their work as a  president
balzac was known for their work as a 
2024-07-30 05:48:00 root INFO     [order_1_approx] starting weight calculation for truman was known for their work as a  president
balzac was known for their work as a  novelist
wagner was known for their work as a  composer
picasso was known for their work as a  painter
depp was known for their work as a  actor
moses was known for their work as a  prophet
dante was known for their work as a  poet
hume was known for their work as a 
2024-07-30 05:48:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 05:50:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2856,  0.3408,  0.2720,  ...,  0.2308,  0.0695,  0.1748],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0508, -3.5273,  3.4141,  ..., -4.9336,  0.0400, -2.3340],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0820, -0.0003,  0.0066,  ...,  0.0171, -0.0083, -0.0079],
        [ 0.0030,  0.0517,  0.0015,  ..., -0.0088, -0.0143,  0.0047],
        [ 0.0152, -0.0145,  0.1046,  ..., -0.0034,  0.0039, -0.0113],
        ...,
        [ 0.0064,  0.0118,  0.0021,  ...,  0.1037,  0.0281,  0.0266],
        [ 0.0234,  0.0127, -0.0102,  ...,  0.0198,  0.0629,  0.0060],
        [-0.0144,  0.0101, -0.0101,  ...,  0.0026, -0.0392,  0.0750]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1035, -3.7246,  3.1621,  ..., -5.3906, -0.0980, -1.9883]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 05:50:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for truman was known for their work as a  president
balzac was known for their work as a  novelist
wagner was known for their work as a  composer
picasso was known for their work as a  painter
depp was known for their work as a  actor
moses was known for their work as a  prophet
dante was known for their work as a  poet
hume was known for their work as a 
2024-07-30 05:50:12 root INFO     [order_1_approx] starting weight calculation for dante was known for their work as a  poet
hume was known for their work as a  philosopher
truman was known for their work as a  president
balzac was known for their work as a  novelist
wagner was known for their work as a  composer
depp was known for their work as a  actor
moses was known for their work as a  prophet
picasso was known for their work as a 
2024-07-30 05:50:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 05:52:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0195, -0.3098, -0.1285,  ...,  0.5537, -0.2068,  0.0184],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6973, -6.8984,  0.7495,  ..., -3.6445, -0.8423, -2.0938],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.0375e-02, -6.3553e-03,  6.5727e-03,  ...,  3.9291e-03,
         -1.3466e-02,  1.4477e-03],
        [ 2.2182e-03,  3.9490e-02, -6.1226e-03,  ..., -2.0020e-02,
          2.0065e-03,  7.3433e-04],
        [ 1.2611e-02, -1.0815e-03,  5.3986e-02,  ..., -1.1459e-02,
          3.3875e-03,  2.3117e-03],
        ...,
        [ 1.0605e-03,  1.1444e-05, -9.2392e-03,  ...,  5.0232e-02,
         -1.1120e-03,  3.3474e-03],
        [-3.2101e-03,  2.6207e-03,  5.5771e-03,  ...,  6.1951e-03,
          2.2964e-02, -1.0567e-02],
        [-5.2109e-03,  5.8861e-03,  3.4370e-03,  ..., -2.2766e-02,
          1.2321e-03,  3.3630e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7227, -6.7852,  0.9834,  ..., -3.6758, -0.8296, -1.9961]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 05:52:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for dante was known for their work as a  poet
hume was known for their work as a  philosopher
truman was known for their work as a  president
balzac was known for their work as a  novelist
wagner was known for their work as a  composer
depp was known for their work as a  actor
moses was known for their work as a  prophet
picasso was known for their work as a 
2024-07-30 05:52:25 root INFO     [order_1_approx] starting weight calculation for balzac was known for their work as a  novelist
moses was known for their work as a  prophet
wagner was known for their work as a  composer
dante was known for their work as a  poet
picasso was known for their work as a  painter
truman was known for their work as a  president
hume was known for their work as a  philosopher
depp was known for their work as a 
2024-07-30 05:52:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 05:54:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1133,  0.2622,  0.0429,  ...,  0.6797, -0.6089,  0.1522],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2773, -3.1797,  1.9297,  ..., -3.0391,  0.1011, -0.2754],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0715, -0.0131, -0.0006,  ...,  0.0032, -0.0045,  0.0126],
        [ 0.0071,  0.0692,  0.0028,  ...,  0.0054, -0.0087, -0.0051],
        [ 0.0145,  0.0154,  0.0602,  ...,  0.0023,  0.0098, -0.0017],
        ...,
        [ 0.0217,  0.0195,  0.0103,  ...,  0.0809, -0.0160,  0.0096],
        [-0.0026,  0.0080,  0.0027,  ...,  0.0083,  0.0249,  0.0071],
        [-0.0050, -0.0078,  0.0120,  ..., -0.0135, -0.0160,  0.0433]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2305, -3.4316,  2.0723,  ..., -3.1602,  0.0718, -0.0994]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 05:54:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for balzac was known for their work as a  novelist
moses was known for their work as a  prophet
wagner was known for their work as a  composer
dante was known for their work as a  poet
picasso was known for their work as a  painter
truman was known for their work as a  president
hume was known for their work as a  philosopher
depp was known for their work as a 
2024-07-30 05:54:38 root INFO     [order_1_approx] starting weight calculation for moses was known for their work as a  prophet
depp was known for their work as a  actor
picasso was known for their work as a  painter
hume was known for their work as a  philosopher
balzac was known for their work as a  novelist
dante was known for their work as a  poet
truman was known for their work as a  president
wagner was known for their work as a 
2024-07-30 05:54:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 05:56:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5112,  0.3059,  0.6387,  ...,  0.3523, -0.1544,  0.0373],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.3359, -6.2539,  2.6523,  ..., -2.1309, -0.2944, -2.0039],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.2460e-02, -1.7090e-02,  1.0628e-02,  ..., -2.5269e-02,
         -2.2461e-02, -6.7825e-03],
        [ 8.3160e-03,  4.9561e-02, -3.5882e-05,  ..., -3.6182e-03,
          1.0681e-02, -1.0155e-02],
        [ 1.4168e-02, -9.2506e-04,  6.8115e-02,  ...,  4.9858e-03,
         -5.7869e-03, -6.5041e-03],
        ...,
        [ 1.6747e-03,  1.4236e-02,  1.0460e-02,  ...,  7.8979e-02,
          5.0011e-03,  2.5997e-03],
        [ 1.7838e-02,  2.2339e-02,  7.2403e-03,  ..., -9.1095e-03,
          4.9316e-02,  2.7161e-03],
        [-2.3880e-02, -7.5264e-03, -9.1934e-03,  ...,  1.7090e-03,
         -2.2202e-03,  5.3467e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.2852, -5.9961,  2.0801,  ..., -2.1250, -0.0964, -1.7314]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 05:56:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for moses was known for their work as a  prophet
depp was known for their work as a  actor
picasso was known for their work as a  painter
hume was known for their work as a  philosopher
balzac was known for their work as a  novelist
dante was known for their work as a  poet
truman was known for their work as a  president
wagner was known for their work as a 
2024-07-30 05:56:50 root INFO     total operator prediction time: 1057.2291705608368 seconds
2024-07-30 05:56:50 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on male - female
2024-07-30 05:56:50 root INFO     building operator male - female
2024-07-30 05:56:50 root INFO     [order_1_approx] starting weight calculation for A female grandson is known as a granddaughter
A female son is known as a daughter
A female nephew is known as a niece
A female policeman is known as a policewoman
A female bull is known as a cow
A female grandfather is known as a grandmother
A female emperor is known as a empress
A female brother is known as a
2024-07-30 05:56:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 05:59:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2974,  0.4924,  0.1812,  ...,  0.2422, -0.1636, -0.1105],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1641, -2.1426, -2.5781,  ...,  0.2871,  0.7104, -0.2715],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.0476e-02, -1.8326e-02,  2.0844e-02,  ...,  3.1036e-02,
          2.7771e-03,  1.6647e-02],
        [ 1.5160e-02,  2.9587e-02,  6.4278e-03,  ...,  1.7288e-02,
         -4.6005e-03, -1.1604e-02],
        [ 1.9928e-02, -1.1879e-02,  6.2256e-02,  ..., -6.3095e-03,
          1.3580e-02, -3.0479e-03],
        ...,
        [-4.4441e-03,  2.7275e-03, -2.6970e-03,  ...,  6.8054e-02,
         -1.0826e-02, -2.3327e-03],
        [ 1.1597e-03,  1.3924e-02,  1.4252e-02,  ...,  1.9348e-02,
          2.7161e-02, -3.2425e-05],
        [ 8.3389e-03, -1.3412e-02, -1.1581e-02,  ..., -1.5297e-02,
          8.3237e-03,  3.5095e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7578, -1.7402, -2.5508,  ...,  0.6157,  0.1016, -0.4539]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 05:59:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female grandson is known as a granddaughter
A female son is known as a daughter
A female nephew is known as a niece
A female policeman is known as a policewoman
A female bull is known as a cow
A female grandfather is known as a grandmother
A female emperor is known as a empress
A female brother is known as a
2024-07-30 05:59:03 root INFO     [order_1_approx] starting weight calculation for A female bull is known as a cow
A female policeman is known as a policewoman
A female grandfather is known as a grandmother
A female brother is known as a sister
A female son is known as a daughter
A female nephew is known as a niece
A female emperor is known as a empress
A female grandson is known as a
2024-07-30 05:59:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 06:01:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1660,  0.8569,  0.4937,  ...,  0.0632, -0.1854, -0.0908],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5352, -0.9907, -2.3906,  ...,  1.0811, -2.0215, -1.9434],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0591,  0.0039,  0.0021,  ...,  0.0052, -0.0017, -0.0093],
        [ 0.0078,  0.0326, -0.0063,  ..., -0.0006,  0.0079, -0.0104],
        [ 0.0073, -0.0141,  0.0469,  ...,  0.0017, -0.0057,  0.0026],
        ...,
        [-0.0111,  0.0057, -0.0047,  ...,  0.0703, -0.0013,  0.0061],
        [ 0.0120,  0.0112, -0.0111,  ..., -0.0154,  0.0329, -0.0123],
        [-0.0006, -0.0096,  0.0001,  ...,  0.0035,  0.0062,  0.0428]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3516, -0.6689, -2.3281,  ...,  1.0381, -2.1113, -2.0039]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 06:01:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female bull is known as a cow
A female policeman is known as a policewoman
A female grandfather is known as a grandmother
A female brother is known as a sister
A female son is known as a daughter
A female nephew is known as a niece
A female emperor is known as a empress
A female grandson is known as a
2024-07-30 06:01:15 root INFO     [order_1_approx] starting weight calculation for A female policeman is known as a policewoman
A female bull is known as a cow
A female grandson is known as a granddaughter
A female son is known as a daughter
A female nephew is known as a niece
A female grandfather is known as a grandmother
A female brother is known as a sister
A female emperor is known as a
2024-07-30 06:01:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 06:03:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7529,  0.4868, -0.1108,  ...,  0.0905, -0.8540,  0.4424],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1118, -5.3203,  1.5820,  ..., -2.6152, -1.5254, -0.7607],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0322, -0.0200, -0.0032,  ..., -0.0063, -0.0109,  0.0010],
        [-0.0160,  0.0321,  0.0202,  ..., -0.0003,  0.0247, -0.0107],
        [ 0.0007,  0.0010,  0.0459,  ...,  0.0144, -0.0070,  0.0099],
        ...,
        [-0.0194,  0.0170,  0.0078,  ...,  0.0551,  0.0057, -0.0094],
        [ 0.0072, -0.0029, -0.0034,  ..., -0.0012,  0.0353, -0.0117],
        [-0.0068, -0.0031,  0.0041,  ..., -0.0019,  0.0033,  0.0291]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4221, -5.1914,  1.2373,  ..., -2.5762, -1.7539, -1.0225]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 06:03:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female policeman is known as a policewoman
A female bull is known as a cow
A female grandson is known as a granddaughter
A female son is known as a daughter
A female nephew is known as a niece
A female grandfather is known as a grandmother
A female brother is known as a sister
A female emperor is known as a
2024-07-30 06:03:27 root INFO     [order_1_approx] starting weight calculation for A female son is known as a daughter
A female policeman is known as a policewoman
A female emperor is known as a empress
A female nephew is known as a niece
A female brother is known as a sister
A female grandson is known as a granddaughter
A female bull is known as a cow
A female grandfather is known as a
2024-07-30 06:03:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 06:05:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7256,  0.5054,  0.0223,  ..., -0.0343, -0.0873, -0.2056],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.7227, -0.7441, -0.5728,  ...,  0.4360, -2.1992, -2.8770],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0362, -0.0064,  0.0145,  ...,  0.0204, -0.0206,  0.0026],
        [ 0.0116,  0.0139, -0.0068,  ...,  0.0174,  0.0047, -0.0063],
        [ 0.0016, -0.0076,  0.0386,  ...,  0.0184,  0.0081, -0.0003],
        ...,
        [-0.0055,  0.0079, -0.0035,  ...,  0.0321, -0.0047, -0.0041],
        [ 0.0093, -0.0009,  0.0036,  ..., -0.0016,  0.0223,  0.0042],
        [-0.0109, -0.0122, -0.0003,  ...,  0.0084,  0.0075,  0.0229]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.4336, -0.7402, -0.5620,  ...,  0.5649, -2.1250, -2.9238]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 06:05:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female son is known as a daughter
A female policeman is known as a policewoman
A female emperor is known as a empress
A female nephew is known as a niece
A female brother is known as a sister
A female grandson is known as a granddaughter
A female bull is known as a cow
A female grandfather is known as a
2024-07-30 06:05:38 root INFO     [order_1_approx] starting weight calculation for A female grandfather is known as a grandmother
A female policeman is known as a policewoman
A female emperor is known as a empress
A female son is known as a daughter
A female grandson is known as a granddaughter
A female nephew is known as a niece
A female brother is known as a sister
A female bull is known as a
2024-07-30 06:05:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 06:07:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3608, -0.1525,  0.3755,  ...,  0.1040, -0.3540,  0.5938],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.8789, -5.4297, -0.9404,  ...,  0.6807,  1.2266,  0.4766],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0642, -0.0054, -0.0314,  ...,  0.0074,  0.0130, -0.0146],
        [-0.0013,  0.0682,  0.0018,  ...,  0.0111,  0.0307, -0.0283],
        [-0.0002, -0.0018,  0.0548,  ..., -0.0106, -0.0050, -0.0205],
        ...,
        [ 0.0116, -0.0037,  0.0120,  ...,  0.0847,  0.0035, -0.0337],
        [-0.0227,  0.0398,  0.0078,  ...,  0.0328,  0.0461, -0.0059],
        [ 0.0176, -0.0124,  0.0112,  ..., -0.0381,  0.0072,  0.0595]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.2734, -4.9492, -0.8643,  ...,  0.5049,  0.3652,  0.5879]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 06:07:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female grandfather is known as a grandmother
A female policeman is known as a policewoman
A female emperor is known as a empress
A female son is known as a daughter
A female grandson is known as a granddaughter
A female nephew is known as a niece
A female brother is known as a sister
A female bull is known as a
2024-07-30 06:07:51 root INFO     [order_1_approx] starting weight calculation for A female bull is known as a cow
A female grandfather is known as a grandmother
A female emperor is known as a empress
A female grandson is known as a granddaughter
A female son is known as a daughter
A female nephew is known as a niece
A female brother is known as a sister
A female policeman is known as a
2024-07-30 06:07:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 06:10:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6074,  0.4766, -0.3406,  ...,  0.1654, -0.7783, -0.1270],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.7656, -5.8438,  2.8398,  ..., -0.3740,  0.4854, -0.3882],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0367, -0.0085,  0.0128,  ...,  0.0134, -0.0133, -0.0007],
        [ 0.0036,  0.0388,  0.0050,  ..., -0.0080,  0.0106, -0.0177],
        [ 0.0069,  0.0084,  0.0327,  ...,  0.0197, -0.0136,  0.0208],
        ...,
        [-0.0057,  0.0147,  0.0061,  ...,  0.0221, -0.0145,  0.0025],
        [ 0.0006,  0.0126, -0.0046,  ...,  0.0064,  0.0261, -0.0033],
        [-0.0086, -0.0059, -0.0093,  ..., -0.0227, -0.0080,  0.0229]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.5312, -5.5742,  2.8555,  ..., -0.5073,  0.5649, -0.4448]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 06:10:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female bull is known as a cow
A female grandfather is known as a grandmother
A female emperor is known as a empress
A female grandson is known as a granddaughter
A female son is known as a daughter
A female nephew is known as a niece
A female brother is known as a sister
A female policeman is known as a
2024-07-30 06:10:04 root INFO     [order_1_approx] starting weight calculation for A female emperor is known as a empress
A female son is known as a daughter
A female bull is known as a cow
A female grandfather is known as a grandmother
A female brother is known as a sister
A female policeman is known as a policewoman
A female grandson is known as a granddaughter
A female nephew is known as a
2024-07-30 06:10:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 06:12:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 4.6387e-03,  7.4316e-01,  4.7998e-01,  ...,  5.4932e-04,
        -4.9609e-01, -1.0583e-01], device='cuda:1', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1367, -1.6318, -0.7324,  ..., -0.7134, -2.3652, -1.6484],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.7781e-02, -6.8245e-03,  1.6708e-02,  ...,  1.9958e-02,
          2.7866e-03,  1.7746e-02],
        [ 2.1992e-03,  2.4551e-02, -5.0201e-03,  ...,  3.0518e-03,
          7.3395e-03, -1.0780e-02],
        [ 7.4730e-03, -1.4206e-02,  3.3417e-02,  ..., -7.9584e-04,
          4.2076e-03, -1.4143e-03],
        ...,
        [-3.5515e-03,  6.4850e-05, -7.7782e-03,  ...,  3.3112e-02,
         -5.6076e-03,  1.7095e-04],
        [ 1.3466e-03, -3.7384e-04,  5.2872e-03,  ...,  8.1940e-03,
          2.0004e-02,  5.8136e-03],
        [-5.1155e-03,  6.2943e-03, -2.9106e-03,  ..., -4.4136e-03,
         -3.5400e-03,  1.4473e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8262, -1.4346, -0.4573,  ..., -0.7319, -2.4746, -1.5586]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 06:12:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female emperor is known as a empress
A female son is known as a daughter
A female bull is known as a cow
A female grandfather is known as a grandmother
A female brother is known as a sister
A female policeman is known as a policewoman
A female grandson is known as a granddaughter
A female nephew is known as a
2024-07-30 06:12:15 root INFO     [order_1_approx] starting weight calculation for A female emperor is known as a empress
A female policeman is known as a policewoman
A female grandfather is known as a grandmother
A female nephew is known as a niece
A female brother is known as a sister
A female grandson is known as a granddaughter
A female bull is known as a cow
A female son is known as a
2024-07-30 06:12:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 06:14:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1160,  0.7070,  0.6753,  ...,  0.2666, -0.3398, -0.1931],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.5391, -1.7695, -1.3770,  ...,  1.1768, -1.9932, -0.0288],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0493, -0.0214,  0.0065,  ...,  0.0106, -0.0008,  0.0038],
        [ 0.0130,  0.0424, -0.0044,  ..., -0.0075,  0.0099, -0.0342],
        [-0.0052, -0.0092,  0.0546,  ..., -0.0131,  0.0105, -0.0168],
        ...,
        [-0.0111,  0.0048, -0.0030,  ...,  0.0588, -0.0096, -0.0106],
        [ 0.0091,  0.0073,  0.0052,  ..., -0.0111,  0.0329, -0.0050],
        [ 0.0014, -0.0021, -0.0055,  ...,  0.0007, -0.0144,  0.0356]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.4219, -1.2637, -1.3193,  ...,  1.3535, -2.1445,  0.1558]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 06:14:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female emperor is known as a empress
A female policeman is known as a policewoman
A female grandfather is known as a grandmother
A female nephew is known as a niece
A female brother is known as a sister
A female grandson is known as a granddaughter
A female bull is known as a cow
A female son is known as a
2024-07-30 06:14:28 root INFO     total operator prediction time: 1057.8173184394836 seconds
2024-07-30 06:14:28 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - shelter
2024-07-30 06:14:28 root INFO     building operator animal - shelter
2024-07-30 06:14:28 root INFO     [order_1_approx] starting weight calculation for The place whale lives in is called sea
The place mallard lives in is called nest
The place dog lives in is called doghouse
The place mouse lives in is called nest
The place hornet lives in is called nest
The place baboon lives in is called grove
The place scorpion lives in is called nest
The place rabbit lives in is called
2024-07-30 06:14:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 06:16:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1743, -0.5034,  0.1118,  ...,  0.1610, -0.2649, -0.3145],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1719, -6.4453,  1.0967,  ..., -1.8086,  0.2089, -0.2227],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0266,  0.0016,  0.0005,  ...,  0.0147, -0.0021,  0.0082],
        [-0.0149,  0.0292,  0.0072,  ...,  0.0051, -0.0073, -0.0027],
        [-0.0013,  0.0078,  0.0312,  ...,  0.0043, -0.0033,  0.0015],
        ...,
        [-0.0010, -0.0116,  0.0067,  ...,  0.0284,  0.0011,  0.0076],
        [ 0.0073,  0.0066, -0.0018,  ..., -0.0040,  0.0333, -0.0016],
        [ 0.0025,  0.0025,  0.0023,  ..., -0.0062, -0.0238,  0.0389]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0078, -6.4297,  1.0479,  ..., -1.8828,  0.2209, -0.3486]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 06:16:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place whale lives in is called sea
The place mallard lives in is called nest
The place dog lives in is called doghouse
The place mouse lives in is called nest
The place hornet lives in is called nest
The place baboon lives in is called grove
The place scorpion lives in is called nest
The place rabbit lives in is called
2024-07-30 06:16:42 root INFO     [order_1_approx] starting weight calculation for The place mallard lives in is called nest
The place mouse lives in is called nest
The place hornet lives in is called nest
The place rabbit lives in is called burrow
The place dog lives in is called doghouse
The place scorpion lives in is called nest
The place whale lives in is called sea
The place baboon lives in is called
2024-07-30 06:16:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 06:18:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4954, -0.2915,  0.2903,  ...,  0.5679, -0.9883,  0.3105],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.8594, -6.6484,  1.0645,  ..., -1.2129, -1.4883, -0.6016],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0259,  0.0196, -0.0235,  ...,  0.0143,  0.0105,  0.0007],
        [-0.0085,  0.0474,  0.0112,  ...,  0.0225,  0.0115, -0.0139],
        [-0.0125,  0.0026,  0.0498,  ..., -0.0028,  0.0042, -0.0133],
        ...,
        [ 0.0021,  0.0102,  0.0217,  ...,  0.0741,  0.0068,  0.0156],
        [ 0.0078, -0.0046, -0.0073,  ..., -0.0019,  0.0361, -0.0001],
        [-0.0044,  0.0063, -0.0144,  ..., -0.0043, -0.0136,  0.0663]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.7812, -6.6094,  0.6172,  ..., -1.1611, -1.5713, -0.3857]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 06:18:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place mallard lives in is called nest
The place mouse lives in is called nest
The place hornet lives in is called nest
The place rabbit lives in is called burrow
The place dog lives in is called doghouse
The place scorpion lives in is called nest
The place whale lives in is called sea
The place baboon lives in is called
2024-07-30 06:18:55 root INFO     [order_1_approx] starting weight calculation for The place hornet lives in is called nest
The place rabbit lives in is called burrow
The place scorpion lives in is called nest
The place mouse lives in is called nest
The place baboon lives in is called grove
The place mallard lives in is called nest
The place whale lives in is called sea
The place dog lives in is called
2024-07-30 06:18:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 06:21:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0964, -0.4878,  0.0179,  ...,  0.3418, -0.3076, -0.0224],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1914, -6.8516,  3.0293,  ..., -2.2266,  0.0757,  0.1641],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0317, -0.0106, -0.0103,  ...,  0.0159, -0.0252,  0.0083],
        [ 0.0041,  0.0427,  0.0003,  ..., -0.0148, -0.0109, -0.0159],
        [ 0.0009,  0.0022,  0.0545,  ...,  0.0194,  0.0119, -0.0047],
        ...,
        [-0.0034, -0.0130,  0.0178,  ...,  0.0351,  0.0037, -0.0074],
        [-0.0035, -0.0064, -0.0119,  ...,  0.0109,  0.0481, -0.0253],
        [ 0.0003, -0.0193, -0.0010,  ..., -0.0026, -0.0146,  0.0508]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5410, -6.6992,  3.0039,  ..., -2.3223, -0.1102,  0.0987]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 06:21:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place hornet lives in is called nest
The place rabbit lives in is called burrow
The place scorpion lives in is called nest
The place mouse lives in is called nest
The place baboon lives in is called grove
The place mallard lives in is called nest
The place whale lives in is called sea
The place dog lives in is called
2024-07-30 06:21:09 root INFO     [order_1_approx] starting weight calculation for The place mouse lives in is called nest
The place dog lives in is called doghouse
The place mallard lives in is called nest
The place baboon lives in is called grove
The place rabbit lives in is called burrow
The place hornet lives in is called nest
The place whale lives in is called sea
The place scorpion lives in is called
2024-07-30 06:21:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 06:23:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 1.2488e-01, -2.0056e-01, -6.2927e-02,  ..., -1.8311e-04,
        -2.7686e-01, -2.6123e-01], device='cuda:1', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2578, -2.9277,  1.6299,  ..., -2.9492,  0.7222, -0.6074],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0185,  0.0017, -0.0007,  ...,  0.0094, -0.0030, -0.0002],
        [-0.0114,  0.0072,  0.0003,  ...,  0.0003,  0.0109, -0.0071],
        [-0.0057,  0.0121,  0.0168,  ...,  0.0004, -0.0023,  0.0075],
        ...,
        [-0.0006, -0.0027,  0.0019,  ...,  0.0131,  0.0040,  0.0010],
        [ 0.0023,  0.0044,  0.0004,  ...,  0.0029,  0.0156, -0.0048],
        [-0.0033, -0.0024, -0.0065,  ..., -0.0013, -0.0037,  0.0198]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2207, -2.9746,  1.6025,  ..., -2.9473,  0.7339, -0.6548]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 06:23:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place mouse lives in is called nest
The place dog lives in is called doghouse
The place mallard lives in is called nest
The place baboon lives in is called grove
The place rabbit lives in is called burrow
The place hornet lives in is called nest
The place whale lives in is called sea
The place scorpion lives in is called
2024-07-30 06:23:20 root INFO     [order_1_approx] starting weight calculation for The place hornet lives in is called nest
The place whale lives in is called sea
The place baboon lives in is called grove
The place dog lives in is called doghouse
The place mouse lives in is called nest
The place rabbit lives in is called burrow
The place scorpion lives in is called nest
The place mallard lives in is called
2024-07-30 06:23:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 06:25:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1964, -0.1844, -0.5352,  ...,  0.2299, -0.0990,  0.1022],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.2695, -7.3047,  1.3174,  ..., -1.1475, -0.8311,  0.6465],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0299,  0.0052, -0.0319,  ..., -0.0022, -0.0142, -0.0081],
        [-0.0062,  0.0628,  0.0049,  ..., -0.0133, -0.0052, -0.0654],
        [ 0.0035,  0.0068,  0.0524,  ...,  0.0167, -0.0097, -0.0206],
        ...,
        [ 0.0053, -0.0139,  0.0279,  ...,  0.0648,  0.0177,  0.0039],
        [ 0.0183,  0.0125, -0.0018,  ...,  0.0149,  0.0488, -0.0102],
        [-0.0235, -0.0122,  0.0061,  ..., -0.0019, -0.0081,  0.0669]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.4336, -7.1602,  1.0215,  ..., -1.2871, -1.0088,  0.2585]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 06:25:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place hornet lives in is called nest
The place whale lives in is called sea
The place baboon lives in is called grove
The place dog lives in is called doghouse
The place mouse lives in is called nest
The place rabbit lives in is called burrow
The place scorpion lives in is called nest
The place mallard lives in is called
2024-07-30 06:25:31 root INFO     [order_1_approx] starting weight calculation for The place hornet lives in is called nest
The place whale lives in is called sea
The place dog lives in is called doghouse
The place scorpion lives in is called nest
The place mallard lives in is called nest
The place baboon lives in is called grove
The place rabbit lives in is called burrow
The place mouse lives in is called
2024-07-30 06:25:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 06:27:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2137, -0.4429,  0.6157,  ...,  0.0330, -0.1398, -0.1887],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5273, -4.9375,  1.0039,  ..., -1.3770, -1.3682,  1.3115],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0398, -0.0128,  0.0230,  ...,  0.0077, -0.0169, -0.0037],
        [-0.0146,  0.0611, -0.0153,  ..., -0.0004,  0.0108, -0.0294],
        [-0.0102,  0.0273,  0.0418,  ..., -0.0074, -0.0054,  0.0190],
        ...,
        [ 0.0040, -0.0138,  0.0201,  ...,  0.0463,  0.0134, -0.0108],
        [ 0.0103,  0.0035, -0.0134,  ...,  0.0133,  0.0430, -0.0063],
        [-0.0188,  0.0030,  0.0011,  ..., -0.0161, -0.0220,  0.0672]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2578, -4.9961,  0.6870,  ..., -1.3369, -1.6270,  0.9526]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 06:27:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place hornet lives in is called nest
The place whale lives in is called sea
The place dog lives in is called doghouse
The place scorpion lives in is called nest
The place mallard lives in is called nest
The place baboon lives in is called grove
The place rabbit lives in is called burrow
The place mouse lives in is called
2024-07-30 06:27:42 root INFO     [order_1_approx] starting weight calculation for The place baboon lives in is called grove
The place dog lives in is called doghouse
The place scorpion lives in is called nest
The place mouse lives in is called nest
The place mallard lives in is called nest
The place whale lives in is called sea
The place rabbit lives in is called burrow
The place hornet lives in is called
2024-07-30 06:27:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 06:29:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2247, -0.1080,  0.3469,  ...,  0.6797, -0.0629,  0.0543],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0410, -5.2891,  3.1055,  ..., -3.1680,  0.6006, -0.4053],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0720, -0.0031, -0.0050,  ...,  0.0122, -0.0033,  0.0063],
        [-0.0287,  0.0581,  0.0239,  ...,  0.0319, -0.0009, -0.0336],
        [ 0.0076,  0.0274,  0.0673,  ...,  0.0052, -0.0099,  0.0186],
        ...,
        [ 0.0067, -0.0145,  0.0232,  ...,  0.0716,  0.0109,  0.0048],
        [-0.0028,  0.0022, -0.0007,  ...,  0.0184,  0.0197,  0.0191],
        [-0.0169,  0.0033, -0.0125,  ...,  0.0041, -0.0125,  0.0615]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3359, -5.4023,  2.7305,  ..., -3.4043,  0.6138, -0.3984]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 06:29:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place baboon lives in is called grove
The place dog lives in is called doghouse
The place scorpion lives in is called nest
The place mouse lives in is called nest
The place mallard lives in is called nest
The place whale lives in is called sea
The place rabbit lives in is called burrow
The place hornet lives in is called
2024-07-30 06:29:53 root INFO     [order_1_approx] starting weight calculation for The place hornet lives in is called nest
The place mallard lives in is called nest
The place baboon lives in is called grove
The place dog lives in is called doghouse
The place mouse lives in is called nest
The place rabbit lives in is called burrow
The place scorpion lives in is called nest
The place whale lives in is called
2024-07-30 06:29:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 06:32:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5635, -0.4290,  0.1115,  ..., -0.0115, -0.0867,  0.0778],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2266, -4.0703, -1.1318,  ..., -2.1270, -1.4531,  0.3574],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0343, -0.0127, -0.0076,  ...,  0.0100, -0.0280, -0.0001],
        [ 0.0022,  0.0444,  0.0035,  ...,  0.0162, -0.0077, -0.0142],
        [-0.0333,  0.0270,  0.0374,  ..., -0.0138, -0.0047, -0.0182],
        ...,
        [ 0.0076,  0.0021,  0.0142,  ...,  0.0549,  0.0073,  0.0059],
        [ 0.0059,  0.0075, -0.0018,  ...,  0.0104,  0.0106, -0.0033],
        [ 0.0059, -0.0184, -0.0067,  ...,  0.0040, -0.0018,  0.0386]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6680, -4.0742, -1.2070,  ..., -2.2363, -1.2676,  0.0874]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 06:32:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place hornet lives in is called nest
The place mallard lives in is called nest
The place baboon lives in is called grove
The place dog lives in is called doghouse
The place mouse lives in is called nest
The place rabbit lives in is called burrow
The place scorpion lives in is called nest
The place whale lives in is called
2024-07-30 06:32:03 root INFO     total operator prediction time: 1055.5519688129425 seconds
2024-07-30 06:32:03 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on country - language
2024-07-30 06:32:03 root INFO     building operator country - language
2024-07-30 06:32:03 root INFO     [order_1_approx] starting weight calculation for The country of canada primarily speaks the language of english
The country of kazakhstan primarily speaks the language of kazak
The country of bolivia primarily speaks the language of spanish
The country of switzerland primarily speaks the language of german
The country of guatemala primarily speaks the language of spanish
The country of guyana primarily speaks the language of english
The country of barbados primarily speaks the language of english
The country of kuwait primarily speaks the language of
2024-07-30 06:32:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 06:34:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0215,  0.0089, -0.4668,  ...,  0.8179, -0.3875,  0.5547],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0967, -2.9727,  0.0076,  ..., -0.8765,  0.0527, -1.6387],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0266, -0.0158,  0.0074,  ...,  0.0075, -0.0033, -0.0033],
        [ 0.0067,  0.0178,  0.0112,  ..., -0.0063,  0.0092, -0.0203],
        [-0.0100,  0.0008,  0.0365,  ...,  0.0017,  0.0091,  0.0024],
        ...,
        [-0.0025,  0.0031,  0.0006,  ...,  0.0350,  0.0188,  0.0010],
        [ 0.0097, -0.0080,  0.0049,  ...,  0.0003,  0.0184, -0.0125],
        [ 0.0032, -0.0110, -0.0060,  ...,  0.0164, -0.0056,  0.0170]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8818, -2.8105,  0.0747,  ..., -0.8262, -0.0216, -1.6768]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 06:34:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of canada primarily speaks the language of english
The country of kazakhstan primarily speaks the language of kazak
The country of bolivia primarily speaks the language of spanish
The country of switzerland primarily speaks the language of german
The country of guatemala primarily speaks the language of spanish
The country of guyana primarily speaks the language of english
The country of barbados primarily speaks the language of english
The country of kuwait primarily speaks the language of
2024-07-30 06:34:20 root INFO     [order_1_approx] starting weight calculation for The country of guatemala primarily speaks the language of spanish
The country of kuwait primarily speaks the language of arabic
The country of bolivia primarily speaks the language of spanish
The country of barbados primarily speaks the language of english
The country of kazakhstan primarily speaks the language of kazak
The country of canada primarily speaks the language of english
The country of switzerland primarily speaks the language of german
The country of guyana primarily speaks the language of
2024-07-30 06:34:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 06:36:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1976, -0.1714,  0.4717,  ...,  0.3501, -0.7515, -0.0427],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1289, -0.2051,  1.2529,  ...,  0.8784,  0.2344, -3.4570],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0295,  0.0040, -0.0109,  ..., -0.0007, -0.0102, -0.0043],
        [-0.0029,  0.0347,  0.0073,  ..., -0.0018,  0.0035, -0.0246],
        [-0.0030, -0.0047,  0.0399,  ...,  0.0209,  0.0213,  0.0060],
        ...,
        [-0.0066, -0.0106, -0.0019,  ...,  0.0437,  0.0062, -0.0018],
        [ 0.0061,  0.0076, -0.0087,  ..., -0.0184,  0.0294, -0.0211],
        [ 0.0194, -0.0072, -0.0027,  ..., -0.0031,  0.0020,  0.0381]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2305, -0.0548,  1.0156,  ...,  0.5986,  0.3760, -2.9688]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 06:36:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of guatemala primarily speaks the language of spanish
The country of kuwait primarily speaks the language of arabic
The country of bolivia primarily speaks the language of spanish
The country of barbados primarily speaks the language of english
The country of kazakhstan primarily speaks the language of kazak
The country of canada primarily speaks the language of english
The country of switzerland primarily speaks the language of german
The country of guyana primarily speaks the language of
2024-07-30 06:36:32 root INFO     [order_1_approx] starting weight calculation for The country of switzerland primarily speaks the language of german
The country of canada primarily speaks the language of english
The country of barbados primarily speaks the language of english
The country of guatemala primarily speaks the language of spanish
The country of kuwait primarily speaks the language of arabic
The country of bolivia primarily speaks the language of spanish
The country of guyana primarily speaks the language of english
The country of kazakhstan primarily speaks the language of
2024-07-30 06:36:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 06:38:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0786, -0.2388, -0.1559,  ...,  0.3115, -0.7041,  0.0331],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.3711, -3.3047, -1.4482,  ..., -3.2051, -2.6641, -1.2793],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0150, -0.0010,  0.0008,  ...,  0.0075, -0.0081,  0.0031],
        [-0.0057,  0.0089,  0.0023,  ...,  0.0018,  0.0001, -0.0006],
        [-0.0031, -0.0010,  0.0190,  ...,  0.0126,  0.0032, -0.0034],
        ...,
        [-0.0022,  0.0009,  0.0002,  ...,  0.0252,  0.0051, -0.0006],
        [ 0.0094,  0.0016,  0.0023,  ...,  0.0013,  0.0032, -0.0085],
        [-0.0011, -0.0050, -0.0003,  ...,  0.0091, -0.0028,  0.0113]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.2930, -3.2930, -1.3857,  ..., -3.1641, -2.6152, -1.1992]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 06:38:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of switzerland primarily speaks the language of german
The country of canada primarily speaks the language of english
The country of barbados primarily speaks the language of english
The country of guatemala primarily speaks the language of spanish
The country of kuwait primarily speaks the language of arabic
The country of bolivia primarily speaks the language of spanish
The country of guyana primarily speaks the language of english
The country of kazakhstan primarily speaks the language of
2024-07-30 06:38:44 root INFO     [order_1_approx] starting weight calculation for The country of kuwait primarily speaks the language of arabic
The country of kazakhstan primarily speaks the language of kazak
The country of guatemala primarily speaks the language of spanish
The country of switzerland primarily speaks the language of german
The country of bolivia primarily speaks the language of spanish
The country of canada primarily speaks the language of english
The country of guyana primarily speaks the language of english
The country of barbados primarily speaks the language of
2024-07-30 06:38:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 06:40:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5664, -0.0222, -0.1306,  ...,  0.8999, -0.2678,  0.1321],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8203, -0.6396,  1.2227,  ...,  1.3057,  1.0693, -3.1562],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0338,  0.0052,  0.0090,  ...,  0.0186, -0.0034, -0.0033],
        [-0.0083,  0.0151,  0.0069,  ..., -0.0095, -0.0024, -0.0102],
        [-0.0135, -0.0062,  0.0446,  ...,  0.0140,  0.0053,  0.0117],
        ...,
        [-0.0057, -0.0007,  0.0080,  ...,  0.0447,  0.0123,  0.0103],
        [-0.0034, -0.0023, -0.0010,  ...,  0.0040,  0.0146, -0.0010],
        [ 0.0052, -0.0136, -0.0045,  ..., -0.0026,  0.0061,  0.0269]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9727, -0.6782,  1.1025,  ...,  1.0840,  1.0166, -3.1387]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 06:40:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of kuwait primarily speaks the language of arabic
The country of kazakhstan primarily speaks the language of kazak
The country of guatemala primarily speaks the language of spanish
The country of switzerland primarily speaks the language of german
The country of bolivia primarily speaks the language of spanish
The country of canada primarily speaks the language of english
The country of guyana primarily speaks the language of english
The country of barbados primarily speaks the language of
2024-07-30 06:40:56 root INFO     [order_1_approx] starting weight calculation for The country of switzerland primarily speaks the language of german
The country of bolivia primarily speaks the language of spanish
The country of kuwait primarily speaks the language of arabic
The country of guatemala primarily speaks the language of spanish
The country of kazakhstan primarily speaks the language of kazak
The country of barbados primarily speaks the language of english
The country of guyana primarily speaks the language of english
The country of canada primarily speaks the language of
2024-07-30 06:40:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 06:43:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([0.1481, 0.0468, 0.0799,  ..., 0.1035, 0.1614, 0.2085], device='cuda:1',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9756, -4.0820,  1.4170,  ..., -0.0864,  1.2266, -1.6953],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.8147e-02, -6.3400e-03,  1.1307e-02,  ...,  1.8372e-02,
          6.2370e-04, -5.2605e-03],
        [-7.9584e-04,  2.8137e-02,  1.5717e-02,  ...,  6.5231e-03,
         -1.5335e-02, -1.2650e-02],
        [-1.5289e-02, -6.8092e-03,  4.0222e-02,  ...,  2.0752e-02,
          2.3254e-02,  6.8398e-03],
        ...,
        [-4.7379e-03,  2.8419e-03,  1.2054e-03,  ...,  3.6407e-02,
         -2.3155e-03, -1.2741e-03],
        [-7.6532e-05, -5.0735e-04, -6.2408e-03,  ..., -2.5864e-03,
          2.1652e-02, -1.0323e-02],
        [ 2.2240e-03, -1.2314e-02,  3.0975e-03,  ...,  5.6076e-03,
          7.9498e-03,  2.4170e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1523, -3.7949,  1.1670,  ..., -0.0953,  0.9561, -1.4932]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 06:43:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of switzerland primarily speaks the language of german
The country of bolivia primarily speaks the language of spanish
The country of kuwait primarily speaks the language of arabic
The country of guatemala primarily speaks the language of spanish
The country of kazakhstan primarily speaks the language of kazak
The country of barbados primarily speaks the language of english
The country of guyana primarily speaks the language of english
The country of canada primarily speaks the language of
2024-07-30 06:43:06 root INFO     [order_1_approx] starting weight calculation for The country of kazakhstan primarily speaks the language of kazak
The country of guyana primarily speaks the language of english
The country of bolivia primarily speaks the language of spanish
The country of canada primarily speaks the language of english
The country of guatemala primarily speaks the language of spanish
The country of kuwait primarily speaks the language of arabic
The country of barbados primarily speaks the language of english
The country of switzerland primarily speaks the language of
2024-07-30 06:43:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 06:45:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3762,  0.0609, -0.1826,  ...,  0.7837, -0.0513,  0.2341],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0723, -7.3281, -0.3770,  ..., -1.1846,  0.3730, -0.9902],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.2114e-02, -9.9792e-03, -4.2648e-03,  ...,  8.6060e-03,
         -1.0483e-02,  0.0000e+00],
        [ 2.9945e-03,  2.3422e-02,  1.6220e-02,  ..., -7.7705e-03,
          4.7913e-03, -9.8190e-03],
        [-9.6970e-03,  4.7684e-03,  2.9251e-02,  ...,  2.0386e-02,
          2.0477e-02,  4.7302e-03],
        ...,
        [-1.7578e-02, -1.1635e-04,  3.2501e-03,  ...,  3.6316e-02,
          1.1032e-02, -4.2686e-03],
        [ 1.1833e-02, -3.8147e-06,  7.5874e-03,  ...,  9.1553e-03,
          1.7883e-02, -1.6769e-02],
        [-1.0612e-02, -1.3443e-02, -1.1238e-02,  ...,  8.4076e-03,
         -9.4986e-04,  2.9984e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4023, -6.9102, -0.9761,  ..., -1.4580,  0.5674, -1.0400]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 06:45:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of kazakhstan primarily speaks the language of kazak
The country of guyana primarily speaks the language of english
The country of bolivia primarily speaks the language of spanish
The country of canada primarily speaks the language of english
The country of guatemala primarily speaks the language of spanish
The country of kuwait primarily speaks the language of arabic
The country of barbados primarily speaks the language of english
The country of switzerland primarily speaks the language of
2024-07-30 06:45:18 root INFO     [order_1_approx] starting weight calculation for The country of switzerland primarily speaks the language of german
The country of guatemala primarily speaks the language of spanish
The country of kuwait primarily speaks the language of arabic
The country of guyana primarily speaks the language of english
The country of kazakhstan primarily speaks the language of kazak
The country of canada primarily speaks the language of english
The country of barbados primarily speaks the language of english
The country of bolivia primarily speaks the language of
2024-07-30 06:45:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 06:47:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2354, -0.1761, -0.0293,  ...,  0.3215, -0.3057, -0.1624],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7231, -2.2656,  1.4404,  ...,  1.1396, -0.2676, -2.1895],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0218, -0.0023, -0.0005,  ..., -0.0007, -0.0055, -0.0014],
        [-0.0005,  0.0098,  0.0133,  ...,  0.0031, -0.0009, -0.0062],
        [-0.0004,  0.0013,  0.0128,  ...,  0.0168,  0.0042,  0.0081],
        ...,
        [-0.0068, -0.0030, -0.0011,  ...,  0.0258,  0.0052,  0.0081],
        [ 0.0087, -0.0048,  0.0016,  ..., -0.0030,  0.0118, -0.0053],
        [-0.0037, -0.0054,  0.0055,  ..., -0.0062, -0.0052,  0.0176]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6357, -2.2344,  1.5371,  ...,  1.1719, -0.2983, -2.0449]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 06:47:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of switzerland primarily speaks the language of german
The country of guatemala primarily speaks the language of spanish
The country of kuwait primarily speaks the language of arabic
The country of guyana primarily speaks the language of english
The country of kazakhstan primarily speaks the language of kazak
The country of canada primarily speaks the language of english
The country of barbados primarily speaks the language of english
The country of bolivia primarily speaks the language of
2024-07-30 06:47:30 root INFO     [order_1_approx] starting weight calculation for The country of switzerland primarily speaks the language of german
The country of kuwait primarily speaks the language of arabic
The country of barbados primarily speaks the language of english
The country of bolivia primarily speaks the language of spanish
The country of canada primarily speaks the language of english
The country of guyana primarily speaks the language of english
The country of kazakhstan primarily speaks the language of kazak
The country of guatemala primarily speaks the language of
2024-07-30 06:47:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 06:49:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2568, -0.1210, -0.0725,  ...,  0.3818, -0.4763, -0.0347],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0627, -1.2168,  0.8467,  ..., -0.8735, -1.6855, -4.6758],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0225, -0.0014,  0.0020,  ..., -0.0025, -0.0043, -0.0012],
        [ 0.0030,  0.0116,  0.0098,  ...,  0.0029, -0.0075, -0.0058],
        [-0.0028, -0.0062,  0.0208,  ...,  0.0129,  0.0117,  0.0063],
        ...,
        [-0.0047, -0.0004, -0.0031,  ...,  0.0139,  0.0056,  0.0019],
        [-0.0017,  0.0012, -0.0060,  ..., -0.0090,  0.0118, -0.0096],
        [-0.0032, -0.0023,  0.0020,  ..., -0.0050, -0.0060,  0.0165]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0112, -1.1660,  0.7900,  ..., -1.0068, -1.8066, -4.5391]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 06:49:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of switzerland primarily speaks the language of german
The country of kuwait primarily speaks the language of arabic
The country of barbados primarily speaks the language of english
The country of bolivia primarily speaks the language of spanish
The country of canada primarily speaks the language of english
The country of guyana primarily speaks the language of english
The country of kazakhstan primarily speaks the language of kazak
The country of guatemala primarily speaks the language of
2024-07-30 06:49:41 root INFO     total operator prediction time: 1058.1646537780762 seconds
2024-07-30 06:49:41 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on name - nationality
2024-07-30 06:49:41 root INFO     building operator name - nationality
2024-07-30 06:49:42 root INFO     [order_1_approx] starting weight calculation for locke was english
galilei was italian
tchaikovsky was russian
plato was greek
hitler was german
lennon was english
leibniz was german
michelangelo was
2024-07-30 06:49:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 06:51:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1288,  0.0808, -0.2440,  ...,  0.3184, -0.3374,  0.7939],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6543, -5.2266,  1.3906,  ..., -3.1992, -1.8848, -0.2002],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0765, -0.0073,  0.0034,  ..., -0.0070, -0.0150, -0.0042],
        [-0.0008,  0.0687,  0.0134,  ..., -0.0060,  0.0050, -0.0293],
        [-0.0042,  0.0089,  0.0729,  ...,  0.0163, -0.0057, -0.0019],
        ...,
        [-0.0059,  0.0080, -0.0167,  ...,  0.0508,  0.0067,  0.0020],
        [ 0.0134,  0.0174,  0.0160,  ..., -0.0223,  0.0786,  0.0009],
        [-0.0054, -0.0013, -0.0050,  ...,  0.0020,  0.0159,  0.0719]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6855, -5.1484,  0.9258,  ..., -2.9746, -1.5771, -0.1819]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 06:51:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for locke was english
galilei was italian
tchaikovsky was russian
plato was greek
hitler was german
lennon was english
leibniz was german
michelangelo was
2024-07-30 06:51:55 root INFO     [order_1_approx] starting weight calculation for locke was english
leibniz was german
plato was greek
hitler was german
galilei was italian
tchaikovsky was russian
michelangelo was italian
lennon was
2024-07-30 06:51:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 06:54:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1666,  0.3108, -0.0437,  ...,  0.4944, -0.5020,  0.4419],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9355, -3.3711,  0.2041,  ..., -2.6133, -0.0312, -1.9766],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0660,  0.0094,  0.0116,  ...,  0.0045, -0.0014, -0.0032],
        [ 0.0181,  0.0549,  0.0093,  ...,  0.0080,  0.0097, -0.0246],
        [-0.0063, -0.0159,  0.0527,  ..., -0.0032,  0.0020,  0.0133],
        ...,
        [-0.0013,  0.0109, -0.0029,  ...,  0.0756,  0.0019,  0.0008],
        [-0.0058, -0.0072,  0.0041,  ..., -0.0276,  0.0440,  0.0148],
        [ 0.0008, -0.0010, -0.0070,  ...,  0.0171,  0.0063,  0.0704]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7500, -3.3652, -0.0959,  ..., -3.0156,  0.2891, -2.2461]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 06:54:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for locke was english
leibniz was german
plato was greek
hitler was german
galilei was italian
tchaikovsky was russian
michelangelo was italian
lennon was
2024-07-30 06:54:09 root INFO     [order_1_approx] starting weight calculation for leibniz was german
lennon was english
michelangelo was italian
locke was english
tchaikovsky was russian
galilei was italian
plato was greek
hitler was
2024-07-30 06:54:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 06:56:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2786,  0.0827, -0.1689,  ...,  0.5391, -0.1267,  0.3823],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1719, -6.0469, -0.5166,  ..., -2.5664, -0.8789, -1.4473],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.4941e-02, -3.5324e-03, -2.7428e-03,  ..., -1.1414e-02,
         -3.2272e-03,  5.5122e-03],
        [ 2.0813e-02,  4.3243e-02,  5.5466e-03,  ...,  8.0109e-03,
          3.9825e-03, -2.7832e-02],
        [ 1.1200e-02, -1.2527e-02,  6.2744e-02,  ..., -1.4740e-02,
         -3.1471e-05,  1.4847e-02],
        ...,
        [ 1.1353e-02,  3.9864e-03, -7.7820e-03,  ...,  8.1909e-02,
         -1.1246e-02, -4.5586e-03],
        [ 3.6964e-03,  7.5722e-04,  1.8463e-02,  ..., -4.4670e-03,
          5.2032e-02, -6.7215e-03],
        [-1.0468e-02, -4.6997e-03,  6.9962e-03,  ...,  9.5596e-03,
          1.2215e-02,  6.7749e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9131, -5.7734, -0.7510,  ..., -2.5840, -0.6426, -1.2314]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 06:56:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for leibniz was german
lennon was english
michelangelo was italian
locke was english
tchaikovsky was russian
galilei was italian
plato was greek
hitler was
2024-07-30 06:56:22 root INFO     [order_1_approx] starting weight calculation for michelangelo was italian
hitler was german
galilei was italian
tchaikovsky was russian
leibniz was german
lennon was english
locke was english
plato was
2024-07-30 06:56:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 06:58:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3120, -0.2861, -0.6963,  ...,  0.5830, -0.0634,  0.3325],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5156, -3.8789, -0.0577,  ..., -4.8047, -1.1543, -0.5010],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0915,  0.0045, -0.0110,  ..., -0.0166, -0.0143,  0.0058],
        [-0.0038,  0.0598,  0.0138,  ...,  0.0320, -0.0019, -0.0260],
        [-0.0029, -0.0072,  0.0807,  ..., -0.0019,  0.0073, -0.0054],
        ...,
        [-0.0030,  0.0181, -0.0166,  ...,  0.0532,  0.0139, -0.0543],
        [ 0.0125,  0.0097,  0.0114,  ...,  0.0041,  0.0594, -0.0059],
        [ 0.0061,  0.0094,  0.0011,  ...,  0.0202, -0.0166,  0.0707]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4980, -3.8906, -0.2246,  ..., -4.9180, -0.8516, -1.0703]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 06:58:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for michelangelo was italian
hitler was german
galilei was italian
tchaikovsky was russian
leibniz was german
lennon was english
locke was english
plato was
2024-07-30 06:58:38 root INFO     [order_1_approx] starting weight calculation for michelangelo was italian
leibniz was german
hitler was german
lennon was english
galilei was italian
plato was greek
locke was english
tchaikovsky was
2024-07-30 06:58:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 07:00:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3723, -0.4187, -0.3979,  ...,  0.1676, -0.5767,  0.0500],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4238, -2.8496, -0.9819,  ..., -5.6836, -0.0215, -2.2930],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0655,  0.0018,  0.0035,  ..., -0.0170,  0.0024, -0.0099],
        [ 0.0080,  0.0456,  0.0253,  ...,  0.0072,  0.0142, -0.0189],
        [ 0.0115, -0.0071,  0.0558,  ...,  0.0050,  0.0015,  0.0104],
        ...,
        [ 0.0096, -0.0013, -0.0178,  ...,  0.0567, -0.0039, -0.0085],
        [ 0.0035,  0.0147, -0.0021,  ..., -0.0169,  0.0474,  0.0011],
        [ 0.0028, -0.0008, -0.0054,  ..., -0.0013,  0.0011,  0.0506]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4971, -2.4668, -0.9468,  ..., -5.5352,  0.1335, -2.3770]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 07:00:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for michelangelo was italian
leibniz was german
hitler was german
lennon was english
galilei was italian
plato was greek
locke was english
tchaikovsky was
2024-07-30 07:00:52 root INFO     [order_1_approx] starting weight calculation for lennon was english
tchaikovsky was russian
hitler was german
galilei was italian
plato was greek
leibniz was german
michelangelo was italian
locke was
2024-07-30 07:00:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 07:03:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2369, -0.0047, -0.5312,  ...,  0.2939, -0.4404,  0.1119],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9023, -2.1191,  0.7563,  ..., -4.4570,  0.7236, -3.6484],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0627,  0.0086, -0.0197,  ...,  0.0011, -0.0131, -0.0064],
        [ 0.0026,  0.0491,  0.0200,  ...,  0.0254, -0.0135, -0.0044],
        [ 0.0059,  0.0010,  0.0494,  ...,  0.0020,  0.0147,  0.0126],
        ...,
        [ 0.0062,  0.0078, -0.0078,  ...,  0.0553, -0.0069, -0.0230],
        [-0.0041,  0.0147,  0.0032,  ..., -0.0118,  0.0674,  0.0043],
        [ 0.0049,  0.0044, -0.0149,  ...,  0.0083, -0.0128,  0.0646]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8535, -2.6738,  0.7402,  ..., -4.3711,  1.0176, -3.6523]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 07:03:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for lennon was english
tchaikovsky was russian
hitler was german
galilei was italian
plato was greek
leibniz was german
michelangelo was italian
locke was
2024-07-30 07:03:05 root INFO     [order_1_approx] starting weight calculation for plato was greek
lennon was english
michelangelo was italian
hitler was german
leibniz was german
locke was english
tchaikovsky was russian
galilei was
2024-07-30 07:03:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 07:05:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0909, -0.4985, -0.6260,  ...,  0.2184, -0.7427,  0.8706],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6914, -3.2305,  1.4834,  ..., -0.2532, -2.1543,  0.9204],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0758,  0.0072, -0.0195,  ..., -0.0061, -0.0081,  0.0074],
        [ 0.0136,  0.0740,  0.0198,  ...,  0.0040,  0.0203, -0.0244],
        [ 0.0052, -0.0054,  0.0618,  ...,  0.0242,  0.0088,  0.0166],
        ...,
        [ 0.0114,  0.0056, -0.0081,  ...,  0.0720,  0.0084, -0.0058],
        [ 0.0291,  0.0036,  0.0020,  ..., -0.0197,  0.0607, -0.0116],
        [-0.0081, -0.0026, -0.0132,  ...,  0.0100,  0.0076,  0.0723]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4062, -3.1562,  1.2578,  ..., -0.5117, -2.0215,  0.2705]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 07:05:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for plato was greek
lennon was english
michelangelo was italian
hitler was german
leibniz was german
locke was english
tchaikovsky was russian
galilei was
2024-07-30 07:05:19 root INFO     [order_1_approx] starting weight calculation for plato was greek
michelangelo was italian
lennon was english
hitler was german
tchaikovsky was russian
locke was english
galilei was italian
leibniz was
2024-07-30 07:05:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 07:07:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1581,  0.1641, -0.0414,  ...,  0.0463, -0.3896,  0.3345],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2207, -4.4883,  1.1094,  ..., -2.6602, -1.3535, -0.6099],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0685, -0.0122, -0.0193,  ..., -0.0059,  0.0017,  0.0021],
        [ 0.0162,  0.0645,  0.0167,  ...,  0.0184, -0.0167, -0.0215],
        [ 0.0101,  0.0016,  0.0614,  ...,  0.0184,  0.0050,  0.0201],
        ...,
        [ 0.0068,  0.0006, -0.0070,  ...,  0.0538,  0.0006, -0.0119],
        [ 0.0158,  0.0225,  0.0005,  ..., -0.0178,  0.0782, -0.0019],
        [ 0.0030,  0.0046, -0.0108,  ...,  0.0088, -0.0090,  0.0714]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3809, -4.7539,  0.7295,  ..., -2.4609, -1.2119, -0.7461]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 07:07:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for plato was greek
michelangelo was italian
lennon was english
hitler was german
tchaikovsky was russian
locke was english
galilei was italian
leibniz was
2024-07-30 07:07:34 root INFO     total operator prediction time: 1072.9142591953278 seconds
2024-07-30 07:07:34 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on UK_city - county
2024-07-30 07:07:34 root INFO     building operator UK_city - county
2024-07-30 07:07:36 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of wakefield is in the county of yorkshire
In the United Kingdom, the city of ely is in the county of cambridgeshire
In the United Kingdom, the city of salisbury is in the county of wiltshire
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of reading is in the county of
2024-07-30 07:07:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 07:09:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0221, -0.0103, -0.3525,  ...,  0.8188, -0.1770,  0.1255],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7676, -4.8594,  2.1992,  ..., -2.7773,  2.6211, -2.7383],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.0264e-02, -5.1613e-03,  2.5620e-02,  ...,  1.0063e-02,
         -1.7414e-03, -1.9089e-02],
        [-1.0071e-02,  3.5191e-03,  2.5421e-02,  ..., -1.2589e-02,
          1.9703e-03,  1.1398e-02],
        [ 4.0131e-03, -9.1705e-03,  3.2928e-02,  ...,  1.8330e-03,
         -1.2751e-03,  8.1635e-03],
        ...,
        [-2.4509e-04, -7.9575e-03,  2.4033e-03,  ...,  4.2053e-02,
          1.5244e-02, -9.2926e-03],
        [-2.2888e-03, -7.6294e-05, -3.7937e-03,  ...,  1.8280e-02,
          1.4114e-02, -1.7853e-02],
        [-2.1149e-02, -3.5820e-03,  8.1787e-03,  ..., -1.2177e-02,
          8.6517e-03,  2.3483e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6406, -4.8633,  2.1152,  ..., -2.5430,  2.5039, -2.7148]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 07:09:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of wakefield is in the county of yorkshire
In the United Kingdom, the city of ely is in the county of cambridgeshire
In the United Kingdom, the city of salisbury is in the county of wiltshire
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of reading is in the county of
2024-07-30 07:09:56 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of ely is in the county of cambridgeshire
In the United Kingdom, the city of reading is in the county of berkshire
In the United Kingdom, the city of salisbury is in the county of wiltshire
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of wakefield is in the county of yorkshire
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of newcastle is in the county of
2024-07-30 07:09:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 07:12:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4480,  0.4397, -0.1982,  ...,  0.6133, -0.4316,  0.3545],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1660, -1.4160,  2.0332,  ..., -2.0488, -2.5234, -0.7256],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0258, -0.0058,  0.0131,  ...,  0.0048, -0.0100, -0.0186],
        [ 0.0046,  0.0176,  0.0160,  ..., -0.0070,  0.0159, -0.0075],
        [-0.0058, -0.0072,  0.0316,  ...,  0.0231,  0.0026, -0.0106],
        ...,
        [ 0.0092, -0.0084, -0.0117,  ...,  0.0323, -0.0006,  0.0026],
        [ 0.0062, -0.0100, -0.0160,  ...,  0.0043,  0.0170, -0.0036],
        [ 0.0185, -0.0076, -0.0170,  ..., -0.0230, -0.0200,  0.0242]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4219, -1.4102,  1.5410,  ..., -2.1660, -1.7031, -0.5825]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 07:12:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of ely is in the county of cambridgeshire
In the United Kingdom, the city of reading is in the county of berkshire
In the United Kingdom, the city of salisbury is in the county of wiltshire
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of wakefield is in the county of yorkshire
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of newcastle is in the county of
2024-07-30 07:12:16 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of salisbury is in the county of wiltshire
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of wakefield is in the county of yorkshire
In the United Kingdom, the city of reading is in the county of berkshire
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of ely is in the county of
2024-07-30 07:12:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 07:14:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4219, -0.3386, -0.1823,  ...,  0.2410,  0.0342,  0.1686],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5737, -2.1504,  0.3877,  ..., -4.6484, -0.6348,  0.7109],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0203, -0.0029, -0.0170,  ..., -0.0109, -0.0157, -0.0279],
        [-0.0258,  0.0479, -0.0139,  ..., -0.0007,  0.0200, -0.0134],
        [-0.0087, -0.0346,  0.0391,  ...,  0.0418,  0.0147,  0.0098],
        ...,
        [ 0.0424,  0.0197,  0.0127,  ...,  0.0564,  0.0151, -0.0602],
        [-0.0049, -0.0212,  0.0329,  ...,  0.0134,  0.0289, -0.0424],
        [-0.0428, -0.0138, -0.0178,  ..., -0.0126,  0.0180,  0.0206]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0957, -1.5879,  0.3003,  ..., -4.4766,  0.5107,  0.3311]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 07:14:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of salisbury is in the county of wiltshire
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of wakefield is in the county of yorkshire
In the United Kingdom, the city of reading is in the county of berkshire
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of ely is in the county of
2024-07-30 07:14:35 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of salisbury is in the county of wiltshire
In the United Kingdom, the city of ely is in the county of cambridgeshire
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of reading is in the county of berkshire
In the United Kingdom, the city of wakefield is in the county of
2024-07-30 07:14:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 07:16:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6450,  0.0124, -0.5195,  ...,  0.4229, -0.4333,  0.5249],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9414, -2.9395, -0.6924,  ..., -1.4404,  0.8672, -0.6323],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0237,  0.0036,  0.0138,  ...,  0.0130,  0.0087, -0.0142],
        [ 0.0041, -0.0019, -0.0067,  ..., -0.0156,  0.0008, -0.0147],
        [ 0.0020, -0.0104,  0.0171,  ...,  0.0147, -0.0030, -0.0156],
        ...,
        [ 0.0260,  0.0023, -0.0080,  ...,  0.0340, -0.0028, -0.0090],
        [ 0.0075, -0.0013,  0.0030,  ...,  0.0263,  0.0034, -0.0047],
        [-0.0060, -0.0013, -0.0322,  ..., -0.0107, -0.0098,  0.0298]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8408, -2.9102, -0.5488,  ..., -1.2842,  1.1260, -1.0527]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 07:16:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of salisbury is in the county of wiltshire
In the United Kingdom, the city of ely is in the county of cambridgeshire
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of reading is in the county of berkshire
In the United Kingdom, the city of wakefield is in the county of
2024-07-30 07:16:56 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of wakefield is in the county of yorkshire
In the United Kingdom, the city of reading is in the county of berkshire
In the United Kingdom, the city of ely is in the county of cambridgeshire
In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of salisbury is in the county of wiltshire
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of swansea is in the county of
2024-07-30 07:16:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 07:19:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6064, -0.2269, -0.3621,  ...,  0.7393, -0.4565, -0.2017],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0078, -3.9785,  0.2432,  ..., -2.3594, -1.1553,  2.1953],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0079,  0.0086,  0.0051,  ..., -0.0011, -0.0028,  0.0068],
        [-0.0024,  0.0148, -0.0067,  ..., -0.0047, -0.0039, -0.0047],
        [ 0.0070, -0.0006,  0.0100,  ...,  0.0077,  0.0079, -0.0017],
        ...,
        [ 0.0051, -0.0078, -0.0086,  ...,  0.0155,  0.0133, -0.0042],
        [-0.0062, -0.0017,  0.0032,  ..., -0.0070, -0.0020, -0.0048],
        [-0.0087, -0.0062, -0.0033,  ..., -0.0097,  0.0029,  0.0122]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9336, -4.2109,  0.2505,  ..., -2.1562, -1.3545,  2.1875]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 07:19:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of wakefield is in the county of yorkshire
In the United Kingdom, the city of reading is in the county of berkshire
In the United Kingdom, the city of ely is in the county of cambridgeshire
In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of salisbury is in the county of wiltshire
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of swansea is in the county of
2024-07-30 07:19:16 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of salisbury is in the county of wiltshire
In the United Kingdom, the city of ely is in the county of cambridgeshire
In the United Kingdom, the city of wakefield is in the county of yorkshire
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of reading is in the county of berkshire
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of carlisle is in the county of
2024-07-30 07:19:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 07:21:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.6128,  0.0719, -0.3906,  ...,  0.0528, -0.5498,  0.2983],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8477, -2.5820,  1.8965,  ..., -4.7773,  1.1826,  0.3923],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.5594e-02, -4.2496e-03,  1.5434e-02,  ..., -2.8191e-03,
         -1.1444e-02, -7.4997e-03],
        [-7.9632e-05,  1.1307e-02,  3.5706e-03,  ...,  1.9083e-03,
          9.6035e-04, -1.0201e-02],
        [-1.0628e-02,  3.4676e-03,  2.5726e-02,  ...,  1.2314e-02,
          5.7106e-03, -5.7411e-04],
        ...,
        [ 5.4855e-03, -1.6708e-02, -1.4069e-02,  ...,  3.6530e-02,
          1.1826e-02,  6.2866e-03],
        [-5.2795e-03, -3.3760e-03, -8.0032e-03,  ..., -5.8603e-04,
          6.2180e-03,  9.9945e-04],
        [ 3.5400e-03, -1.7410e-02, -6.3248e-03,  ..., -1.2939e-02,
          3.6888e-03,  1.2268e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8853, -2.6582,  1.9434,  ..., -4.6133,  1.2744,  0.3228]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 07:21:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of salisbury is in the county of wiltshire
In the United Kingdom, the city of ely is in the county of cambridgeshire
In the United Kingdom, the city of wakefield is in the county of yorkshire
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of reading is in the county of berkshire
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of carlisle is in the county of
2024-07-30 07:21:36 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of ely is in the county of cambridgeshire
In the United Kingdom, the city of reading is in the county of berkshire
In the United Kingdom, the city of salisbury is in the county of wiltshire
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of wakefield is in the county of yorkshire
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of aberdeen is in the county of
2024-07-30 07:21:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 07:23:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4739, -0.0510, -0.1948,  ...,  0.3225, -0.3594,  0.0837],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2240, -3.2852,  0.9658,  ..., -3.9141, -1.4502, -1.3086],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0074,  0.0013,  0.0114,  ...,  0.0061, -0.0037, -0.0066],
        [-0.0004,  0.0093,  0.0007,  ...,  0.0014,  0.0022, -0.0005],
        [ 0.0037,  0.0003,  0.0231,  ...,  0.0168,  0.0067,  0.0013],
        ...,
        [ 0.0024, -0.0043, -0.0054,  ...,  0.0216,  0.0134,  0.0059],
        [-0.0074, -0.0088,  0.0044,  ..., -0.0019, -0.0040, -0.0049],
        [ 0.0028, -0.0061, -0.0098,  ..., -0.0057,  0.0028,  0.0188]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2125, -3.4766,  0.8408,  ..., -3.7578, -1.3037, -1.2637]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 07:23:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of ely is in the county of cambridgeshire
In the United Kingdom, the city of reading is in the county of berkshire
In the United Kingdom, the city of salisbury is in the county of wiltshire
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of wakefield is in the county of yorkshire
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of aberdeen is in the county of
2024-07-30 07:23:56 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of wakefield is in the county of yorkshire
In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of reading is in the county of berkshire
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of ely is in the county of cambridgeshire
In the United Kingdom, the city of salisbury is in the county of
2024-07-30 07:23:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 07:26:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5771, -0.2961, -0.1288,  ...,  0.2168, -0.6040,  0.1174],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9395, -3.4375,  0.6094,  ..., -0.8530, -0.8799, -0.5571],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0147, -0.0049,  0.0068,  ..., -0.0118,  0.0008, -0.0130],
        [-0.0019,  0.0325,  0.0057,  ...,  0.0097, -0.0044, -0.0118],
        [-0.0069, -0.0023,  0.0259,  ...,  0.0165,  0.0064, -0.0219],
        ...,
        [ 0.0074, -0.0036, -0.0157,  ...,  0.0365,  0.0067, -0.0003],
        [-0.0149, -0.0095,  0.0019,  ...,  0.0136,  0.0140, -0.0016],
        [-0.0126, -0.0042, -0.0010,  ..., -0.0007,  0.0036,  0.0186]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9004, -3.3691,  0.4829,  ..., -0.9585, -0.3638, -0.6934]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 07:26:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of wakefield is in the county of yorkshire
In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of reading is in the county of berkshire
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of newcastle is in the county of northumberland
In the United Kingdom, the city of ely is in the county of cambridgeshire
In the United Kingdom, the city of salisbury is in the county of
2024-07-30 07:26:16 root INFO     total operator prediction time: 1121.6426084041595 seconds
2024-07-30 07:26:16 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+ment_irreg
2024-07-30 07:26:16 root INFO     building operator verb+ment_irreg
2024-07-30 07:26:16 root INFO     [order_1_approx] starting weight calculation for To acknowledge results in a acknowledgement
To embarrass results in a embarrassment
To commit results in a commitment
To assign results in a assignment
To adjust results in a adjustment
To fulfill results in a fulfillment
To displace results in a displacement
To enjoy results in a
2024-07-30 07:26:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 07:28:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1244, -0.0897, -0.0753,  ..., -0.1995, -0.0573, -0.3425],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8203, -1.6680,  0.2222,  ...,  1.9600, -1.4697, -1.4688],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0845, -0.0006,  0.0083,  ..., -0.0123, -0.0079,  0.0129],
        [-0.0014,  0.0797,  0.0102,  ...,  0.0307,  0.0056,  0.0141],
        [-0.0002,  0.0028,  0.0609,  ..., -0.0006, -0.0352, -0.0081],
        ...,
        [-0.0122, -0.0181, -0.0217,  ...,  0.0717,  0.0167, -0.0006],
        [ 0.0032,  0.0175,  0.0147,  ..., -0.0071,  0.0593, -0.0127],
        [-0.0133,  0.0007, -0.0094,  ..., -0.0047, -0.0126,  0.0623]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1406, -1.9404,  0.3188,  ...,  2.3809, -1.5010, -1.6982]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 07:28:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To acknowledge results in a acknowledgement
To embarrass results in a embarrassment
To commit results in a commitment
To assign results in a assignment
To adjust results in a adjustment
To fulfill results in a fulfillment
To displace results in a displacement
To enjoy results in a
2024-07-30 07:28:30 root INFO     [order_1_approx] starting weight calculation for To adjust results in a adjustment
To commit results in a commitment
To displace results in a displacement
To embarrass results in a embarrassment
To acknowledge results in a acknowledgement
To fulfill results in a fulfillment
To enjoy results in a enjoyment
To assign results in a
2024-07-30 07:28:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 07:30:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3972,  0.1576,  0.1035,  ...,  0.1429, -0.0715, -0.4033],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0195, -3.5352, -0.6519,  ...,  2.4707, -1.6152, -2.7188],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0432,  0.0220, -0.0069,  ...,  0.0055,  0.0090,  0.0252],
        [ 0.0180,  0.0399,  0.0395,  ...,  0.0302,  0.0006, -0.0160],
        [-0.0026, -0.0045,  0.0408,  ..., -0.0036, -0.0013, -0.0116],
        ...,
        [ 0.0103,  0.0117, -0.0190,  ...,  0.0761,  0.0099, -0.0069],
        [-0.0063,  0.0294,  0.0039,  ..., -0.0021,  0.0594,  0.0048],
        [ 0.0017, -0.0100,  0.0017,  ..., -0.0068, -0.0372,  0.0509]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2988, -2.8086, -0.7075,  ...,  1.6367, -1.7314, -2.6113]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 07:30:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To adjust results in a adjustment
To commit results in a commitment
To displace results in a displacement
To embarrass results in a embarrassment
To acknowledge results in a acknowledgement
To fulfill results in a fulfillment
To enjoy results in a enjoyment
To assign results in a
2024-07-30 07:30:41 root INFO     [order_1_approx] starting weight calculation for To enjoy results in a enjoyment
To assign results in a assignment
To commit results in a commitment
To acknowledge results in a acknowledgement
To displace results in a displacement
To adjust results in a adjustment
To embarrass results in a embarrassment
To fulfill results in a
2024-07-30 07:30:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 07:32:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0042,  0.1709,  0.0815,  ...,  0.1223, -0.2566, -0.2015],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.1602, -3.5234,  2.9180,  ...,  0.7090, -3.9199, -1.5830],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0650, -0.0040,  0.0257,  ..., -0.0197,  0.0072,  0.0175],
        [ 0.0278,  0.0981,  0.0045,  ...,  0.0328,  0.0071, -0.0136],
        [ 0.0056, -0.0184,  0.0435,  ..., -0.0086, -0.0047, -0.0272],
        ...,
        [ 0.0098,  0.0143, -0.0108,  ...,  0.0865,  0.0159,  0.0097],
        [-0.0166,  0.0157,  0.0124,  ...,  0.0092,  0.0570, -0.0089],
        [ 0.0183,  0.0078, -0.0017,  ..., -0.0092, -0.0197,  0.0618]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.9141, -2.9219,  2.8047,  ...,  0.9312, -3.4785, -1.6338]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 07:32:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To enjoy results in a enjoyment
To assign results in a assignment
To commit results in a commitment
To acknowledge results in a acknowledgement
To displace results in a displacement
To adjust results in a adjustment
To embarrass results in a embarrassment
To fulfill results in a
2024-07-30 07:32:53 root INFO     [order_1_approx] starting weight calculation for To enjoy results in a enjoyment
To adjust results in a adjustment
To assign results in a assignment
To commit results in a commitment
To acknowledge results in a acknowledgement
To embarrass results in a embarrassment
To fulfill results in a fulfillment
To displace results in a
2024-07-30 07:32:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 07:34:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1592,  0.0220, -0.5898,  ...,  0.2010, -0.0144,  0.1846],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.2422, -2.8828, -0.0486,  ...,  1.6387, -1.6660, -1.7031],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0807,  0.0068,  0.0149,  ...,  0.0049, -0.0140,  0.0133],
        [ 0.0091,  0.0779,  0.0027,  ...,  0.0350,  0.0100,  0.0050],
        [-0.0063, -0.0115,  0.0447,  ..., -0.0168,  0.0024, -0.0347],
        ...,
        [ 0.0159,  0.0253,  0.0010,  ...,  0.0919,  0.0148,  0.0198],
        [ 0.0078,  0.0099, -0.0061,  ..., -0.0045,  0.0800, -0.0096],
        [ 0.0305,  0.0092,  0.0141,  ..., -0.0215, -0.0299,  0.0931]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.1016, -2.4434,  0.0174,  ...,  1.0479, -1.8125, -2.6445]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 07:34:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To enjoy results in a enjoyment
To adjust results in a adjustment
To assign results in a assignment
To commit results in a commitment
To acknowledge results in a acknowledgement
To embarrass results in a embarrassment
To fulfill results in a fulfillment
To displace results in a
2024-07-30 07:34:55 root INFO     [order_1_approx] starting weight calculation for To commit results in a commitment
To assign results in a assignment
To displace results in a displacement
To fulfill results in a fulfillment
To embarrass results in a embarrassment
To enjoy results in a enjoyment
To acknowledge results in a acknowledgement
To adjust results in a
2024-07-30 07:34:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 07:37:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0699, -0.0118, -0.2861,  ...,  0.0917,  0.0494, -0.1030],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8594, -2.7891, -2.3457,  ...,  1.5020, -3.1504, -1.5586],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0449,  0.0156, -0.0212,  ..., -0.0287,  0.0304,  0.0028],
        [ 0.0384,  0.0683,  0.0510,  ...,  0.0429,  0.0009,  0.0379],
        [-0.0105, -0.0023,  0.0250,  ..., -0.0046,  0.0092, -0.0342],
        ...,
        [ 0.0209,  0.0079,  0.0228,  ...,  0.0994,  0.0054,  0.0247],
        [-0.0121,  0.0025, -0.0032,  ..., -0.0119,  0.0556, -0.0276],
        [ 0.0281,  0.0068,  0.0175,  ...,  0.0016, -0.0322,  0.0679]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9375, -2.0547, -2.1602,  ...,  1.5479, -3.1914, -1.0869]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 07:37:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To commit results in a commitment
To assign results in a assignment
To displace results in a displacement
To fulfill results in a fulfillment
To embarrass results in a embarrassment
To enjoy results in a enjoyment
To acknowledge results in a acknowledgement
To adjust results in a
2024-07-30 07:37:08 root INFO     [order_1_approx] starting weight calculation for To displace results in a displacement
To assign results in a assignment
To commit results in a commitment
To fulfill results in a fulfillment
To adjust results in a adjustment
To enjoy results in a enjoyment
To embarrass results in a embarrassment
To acknowledge results in a
2024-07-30 07:37:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 07:39:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0294,  0.6904, -0.2698,  ..., -0.0039, -0.2524, -0.5239],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7793, -2.4629, -0.9355,  ...,  1.0215, -3.0508,  1.1602],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0431,  0.0060, -0.0265,  ..., -0.0102, -0.0026,  0.0003],
        [ 0.0134,  0.0411,  0.0281,  ...,  0.0042,  0.0092,  0.0199],
        [ 0.0029, -0.0034,  0.0190,  ..., -0.0070, -0.0081, -0.0085],
        ...,
        [ 0.0054,  0.0058,  0.0088,  ...,  0.0488,  0.0094,  0.0171],
        [-0.0057,  0.0065,  0.0131,  ..., -0.0083,  0.0325, -0.0056],
        [ 0.0053, -0.0082,  0.0036,  ..., -0.0046, -0.0187,  0.0459]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2910, -2.0938, -1.1758,  ...,  1.4766, -3.1133,  0.8379]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 07:39:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To displace results in a displacement
To assign results in a assignment
To commit results in a commitment
To fulfill results in a fulfillment
To adjust results in a adjustment
To enjoy results in a enjoyment
To embarrass results in a embarrassment
To acknowledge results in a
2024-07-30 07:39:22 root INFO     [order_1_approx] starting weight calculation for To embarrass results in a embarrassment
To acknowledge results in a acknowledgement
To enjoy results in a enjoyment
To fulfill results in a fulfillment
To adjust results in a adjustment
To displace results in a displacement
To assign results in a assignment
To commit results in a
2024-07-30 07:39:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 07:41:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2532,  0.1514, -0.0569,  ...,  0.1482, -0.2720, -0.1920],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8750, -4.0430, -1.2412,  ..., -0.6396, -1.8965, -1.7969],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0636,  0.0012, -0.0116,  ..., -0.0237, -0.0059,  0.0157],
        [ 0.0069,  0.0836,  0.0366,  ...,  0.0468,  0.0197, -0.0166],
        [ 0.0092, -0.0070,  0.0435,  ..., -0.0053, -0.0087, -0.0074],
        ...,
        [ 0.0064,  0.0210,  0.0015,  ...,  0.0806,  0.0145,  0.0093],
        [ 0.0028, -0.0002,  0.0106,  ..., -0.0048,  0.0395, -0.0253],
        [-0.0029, -0.0066,  0.0030,  ..., -0.0081, -0.0141,  0.0549]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2031, -2.9297, -1.4619,  ..., -0.0190, -1.9824, -1.2754]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 07:41:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To embarrass results in a embarrassment
To acknowledge results in a acknowledgement
To enjoy results in a enjoyment
To fulfill results in a fulfillment
To adjust results in a adjustment
To displace results in a displacement
To assign results in a assignment
To commit results in a
2024-07-30 07:41:36 root INFO     [order_1_approx] starting weight calculation for To fulfill results in a fulfillment
To acknowledge results in a acknowledgement
To adjust results in a adjustment
To displace results in a displacement
To assign results in a assignment
To enjoy results in a enjoyment
To commit results in a commitment
To embarrass results in a
2024-07-30 07:41:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 07:43:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4392,  0.2126, -0.4924,  ..., -0.0500, -0.1881,  0.0544],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.4609, -1.5430,  1.1611,  ...,  1.5166,  1.7422, -2.3320],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0599, -0.0064, -0.0105,  ..., -0.0088, -0.0071, -0.0094],
        [ 0.0391,  0.0761,  0.0085,  ...,  0.0271,  0.0008,  0.0099],
        [-0.0075, -0.0116,  0.0478,  ..., -0.0091,  0.0019,  0.0051],
        ...,
        [ 0.0100,  0.0141, -0.0109,  ...,  0.0659, -0.0032,  0.0012],
        [ 0.0006, -0.0062,  0.0084,  ..., -0.0126,  0.0527, -0.0022],
        [ 0.0108,  0.0029,  0.0008,  ...,  0.0052, -0.0164,  0.0649]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.2969, -1.4795,  0.7104,  ...,  1.7070,  1.1016, -2.5215]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 07:43:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To fulfill results in a fulfillment
To acknowledge results in a acknowledgement
To adjust results in a adjustment
To displace results in a displacement
To assign results in a assignment
To enjoy results in a enjoyment
To commit results in a commitment
To embarrass results in a
2024-07-30 07:43:50 root INFO     total operator prediction time: 1053.6920404434204 seconds
2024-07-30 07:43:50 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun+less_reg
2024-07-30 07:43:50 root INFO     building operator noun+less_reg
2024-07-30 07:43:50 root INFO     [order_1_approx] starting weight calculation for Something without penny is penniless
Something without carbon is carbonless
Something without talent is talentless
Something without death is deathless
Something without hair is hairless
Something without wit is witless
Something without effort is effortless
Something without mirth is
2024-07-30 07:43:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 07:46:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1250, -0.0313,  0.3940,  ...,  0.0568, -0.6787,  0.0685],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5674, -2.7148, -1.2646,  ..., -1.7021, -4.2617, -2.3945],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0411, -0.0166, -0.0013,  ..., -0.0024,  0.0135,  0.0054],
        [ 0.0009,  0.0305, -0.0043,  ...,  0.0210, -0.0121,  0.0066],
        [ 0.0124, -0.0142,  0.0565,  ...,  0.0055,  0.0030, -0.0077],
        ...,
        [ 0.0264,  0.0244,  0.0168,  ...,  0.0384,  0.0236,  0.0014],
        [ 0.0139, -0.0006,  0.0068,  ..., -0.0139,  0.0521, -0.0332],
        [ 0.0179,  0.0007,  0.0082,  ...,  0.0225, -0.0105,  0.0287]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7295, -2.3555, -1.4580,  ..., -1.7139, -3.9336, -2.1406]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 07:46:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without penny is penniless
Something without carbon is carbonless
Something without talent is talentless
Something without death is deathless
Something without hair is hairless
Something without wit is witless
Something without effort is effortless
Something without mirth is
2024-07-30 07:46:03 root INFO     [order_1_approx] starting weight calculation for Something without death is deathless
Something without hair is hairless
Something without penny is penniless
Something without mirth is mirthless
Something without talent is talentless
Something without carbon is carbonless
Something without wit is witless
Something without effort is
2024-07-30 07:46:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 07:48:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1338, -0.1099, -0.0280,  ..., -0.3472, -0.4961,  0.2578],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9688, -5.3672, -1.3252,  ..., -2.1367, -3.9160, -4.7227],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0079, -0.0065,  0.0111,  ..., -0.0113,  0.0083, -0.0040],
        [ 0.0280,  0.0419, -0.0257,  ...,  0.0254, -0.0138,  0.0063],
        [ 0.0103, -0.0182,  0.0363,  ...,  0.0031, -0.0169, -0.0034],
        ...,
        [ 0.0026,  0.0284, -0.0170,  ...,  0.0408,  0.0011,  0.0066],
        [ 0.0003,  0.0094, -0.0062,  ..., -0.0011,  0.0453, -0.0155],
        [ 0.0221, -0.0005,  0.0007,  ...,  0.0099, -0.0186,  0.0298]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2422, -5.5000, -1.2627,  ..., -2.0742, -3.7676, -4.7148]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 07:48:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without death is deathless
Something without hair is hairless
Something without penny is penniless
Something without mirth is mirthless
Something without talent is talentless
Something without carbon is carbonless
Something without wit is witless
Something without effort is
2024-07-30 07:48:16 root INFO     [order_1_approx] starting weight calculation for Something without hair is hairless
Something without death is deathless
Something without effort is effortless
Something without carbon is carbonless
Something without talent is talentless
Something without penny is penniless
Something without mirth is mirthless
Something without wit is
2024-07-30 07:48:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 07:50:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0754,  0.1383,  0.6357,  ...,  0.0027,  0.3335, -0.1965],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6172, -4.5586,  0.2119,  ..., -2.2070, -3.4609,  0.5352],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0049, -0.0190, -0.0074,  ...,  0.0113,  0.0143, -0.0237],
        [ 0.0170,  0.0277,  0.0132,  ..., -0.0022, -0.0110,  0.0248],
        [ 0.0104, -0.0212,  0.0397,  ...,  0.0020, -0.0124, -0.0077],
        ...,
        [ 0.0337,  0.0437,  0.0154,  ...,  0.0363, -0.0010,  0.0213],
        [ 0.0106,  0.0066,  0.0173,  ..., -0.0165,  0.0386, -0.0190],
        [ 0.0319, -0.0009, -0.0033,  ..., -0.0056, -0.0168,  0.0424]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5684, -4.8242,  0.1202,  ..., -2.1992, -3.2695,  0.1995]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 07:50:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without hair is hairless
Something without death is deathless
Something without effort is effortless
Something without carbon is carbonless
Something without talent is talentless
Something without penny is penniless
Something without mirth is mirthless
Something without wit is
2024-07-30 07:50:29 root INFO     [order_1_approx] starting weight calculation for Something without mirth is mirthless
Something without talent is talentless
Something without wit is witless
Something without carbon is carbonless
Something without hair is hairless
Something without effort is effortless
Something without death is deathless
Something without penny is
2024-07-30 07:50:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 07:52:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4775, -0.1025, -0.2617,  ..., -0.3423, -0.2544,  0.0073],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1333, -3.7227,  0.2666,  ..., -4.9844, -5.1641, -2.4551],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0448, -0.0091,  0.0142,  ..., -0.0071, -0.0004,  0.0143],
        [-0.0033,  0.0345,  0.0125,  ...,  0.0268,  0.0031, -0.0191],
        [ 0.0041,  0.0186,  0.0323,  ..., -0.0024,  0.0068,  0.0062],
        ...,
        [-0.0081,  0.0048,  0.0040,  ...,  0.0268, -0.0002,  0.0253],
        [-0.0118,  0.0092,  0.0003,  ..., -0.0072,  0.0290, -0.0115],
        [-0.0209,  0.0034, -0.0065,  ..., -0.0024,  0.0050,  0.0453]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3286, -4.0039, -0.0134,  ..., -4.7578, -4.9492, -2.1406]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 07:52:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without mirth is mirthless
Something without talent is talentless
Something without wit is witless
Something without carbon is carbonless
Something without hair is hairless
Something without effort is effortless
Something without death is deathless
Something without penny is
2024-07-30 07:52:42 root INFO     [order_1_approx] starting weight calculation for Something without hair is hairless
Something without effort is effortless
Something without mirth is mirthless
Something without talent is talentless
Something without wit is witless
Something without penny is penniless
Something without carbon is carbonless
Something without death is
2024-07-30 07:52:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 07:54:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2028, -0.5464, -0.0682,  ..., -0.0812,  0.1561, -0.0868],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9341, -4.0312, -0.9644,  ..., -1.9453, -3.0273, -2.6270],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0089, -0.0101, -0.0062,  ...,  0.0155,  0.0202,  0.0118],
        [ 0.0073,  0.0374, -0.0110,  ...,  0.0081, -0.0074, -0.0130],
        [ 0.0238, -0.0047,  0.0324,  ...,  0.0018, -0.0082, -0.0118],
        ...,
        [ 0.0155,  0.0269, -0.0040,  ...,  0.0302,  0.0074,  0.0064],
        [-0.0079, -0.0087,  0.0184,  ..., -0.0194,  0.0447, -0.0178],
        [ 0.0238, -0.0017, -0.0055,  ...,  0.0033, -0.0096,  0.0323]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1475, -3.5664, -0.8135,  ..., -2.1738, -3.1797, -2.2871]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 07:54:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without hair is hairless
Something without effort is effortless
Something without mirth is mirthless
Something without talent is talentless
Something without wit is witless
Something without penny is penniless
Something without carbon is carbonless
Something without death is
2024-07-30 07:54:55 root INFO     [order_1_approx] starting weight calculation for Something without death is deathless
Something without mirth is mirthless
Something without effort is effortless
Something without hair is hairless
Something without talent is talentless
Something without wit is witless
Something without penny is penniless
Something without carbon is
2024-07-30 07:54:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 07:57:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.7295, -0.2549, -0.8901,  ..., -0.3660,  0.1135, -0.0196],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0342, -2.3496,  1.5088,  ..., -4.5156, -2.0371, -1.1602],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0840, -0.0043, -0.0212,  ...,  0.0286,  0.0057,  0.0048],
        [-0.0029,  0.0424, -0.0089,  ...,  0.0004,  0.0131,  0.0042],
        [ 0.0204, -0.0191,  0.0320,  ...,  0.0121,  0.0081,  0.0095],
        ...,
        [ 0.0100,  0.0342,  0.0247,  ...,  0.0123, -0.0145,  0.0055],
        [ 0.0149,  0.0016,  0.0136,  ...,  0.0163,  0.0490, -0.0280],
        [ 0.0064,  0.0176,  0.0122,  ..., -0.0085, -0.0169,  0.0189]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5776, -1.7852,  1.1143,  ..., -4.1914, -1.7119, -1.1182]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 07:57:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without death is deathless
Something without mirth is mirthless
Something without effort is effortless
Something without hair is hairless
Something without talent is talentless
Something without wit is witless
Something without penny is penniless
Something without carbon is
2024-07-30 07:57:08 root INFO     [order_1_approx] starting weight calculation for Something without carbon is carbonless
Something without hair is hairless
Something without wit is witless
Something without penny is penniless
Something without mirth is mirthless
Something without death is deathless
Something without effort is effortless
Something without talent is
2024-07-30 07:57:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 07:59:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5352, -0.3447,  0.0992,  ..., -0.4292,  0.2473, -0.1127],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4355, -1.1562,  1.1895,  ..., -4.0781, -4.3555, -2.2031],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0019, -0.0151,  0.0202,  ..., -0.0003,  0.0192,  0.0231],
        [ 0.0227,  0.0505, -0.0004,  ...,  0.0182, -0.0055,  0.0046],
        [-0.0057, -0.0069,  0.0295,  ...,  0.0055, -0.0046, -0.0178],
        ...,
        [ 0.0216,  0.0305,  0.0091,  ...,  0.0272,  0.0024,  0.0024],
        [-0.0127,  0.0120,  0.0362,  ..., -0.0058,  0.0499, -0.0175],
        [ 0.0478, -0.0082, -0.0015,  ...,  0.0055, -0.0018,  0.0274]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5703, -1.1973,  1.0781,  ..., -3.7773, -4.4531, -1.9209]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 07:59:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without carbon is carbonless
Something without hair is hairless
Something without wit is witless
Something without penny is penniless
Something without mirth is mirthless
Something without death is deathless
Something without effort is effortless
Something without talent is
2024-07-30 07:59:21 root INFO     [order_1_approx] starting weight calculation for Something without penny is penniless
Something without death is deathless
Something without wit is witless
Something without effort is effortless
Something without carbon is carbonless
Something without mirth is mirthless
Something without talent is talentless
Something without hair is
2024-07-30 07:59:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 08:01:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4238, -0.5464, -0.0306,  ...,  0.0840,  0.2698, -0.0102],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7559, -3.2305, -2.0312,  ..., -2.2715, -4.0195, -2.1016],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0350, -0.0170,  0.0073,  ..., -0.0132,  0.0091,  0.0020],
        [-0.0027,  0.0433,  0.0021,  ...,  0.0057,  0.0012, -0.0115],
        [ 0.0063, -0.0075,  0.0387,  ...,  0.0035, -0.0111, -0.0069],
        ...,
        [ 0.0188,  0.0214,  0.0039,  ...,  0.0370,  0.0027, -0.0003],
        [-0.0179,  0.0107,  0.0112,  ..., -0.0214,  0.0458, -0.0307],
        [ 0.0049, -0.0094,  0.0065,  ...,  0.0022, -0.0134,  0.0373]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1016, -2.8535, -1.9609,  ..., -2.1992, -3.9668, -2.1914]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 08:01:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without penny is penniless
Something without death is deathless
Something without wit is witless
Something without effort is effortless
Something without carbon is carbonless
Something without mirth is mirthless
Something without talent is talentless
Something without hair is
2024-07-30 08:01:32 root INFO     total operator prediction time: 1062.1226139068604 seconds
2024-07-30 08:01:32 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj+ness_reg
2024-07-30 08:01:32 root INFO     building operator adj+ness_reg
2024-07-30 08:01:32 root INFO     [order_1_approx] starting weight calculation for The state of being prepared is preparedness
The state of being foreign is foreignness
The state of being useful is usefulness
The state of being impressive is impressiveness
The state of being pure is pureness
The state of being vast is vastness
The state of being aware is awareness
The state of being reasonable is
2024-07-30 08:01:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 08:03:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0649, -0.4915, -0.1553,  ..., -0.4072, -0.0554, -0.2452],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0000, -1.2910, -1.2354,  ..., -2.9609, -6.3047, -2.3164],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0569, -0.0064, -0.0035,  ...,  0.0065, -0.0061,  0.0192],
        [-0.0118,  0.0607, -0.0026,  ...,  0.0191,  0.0193, -0.0009],
        [ 0.0249, -0.0129,  0.0634,  ..., -0.0076, -0.0031,  0.0057],
        ...,
        [ 0.0221,  0.0185,  0.0254,  ...,  0.0604,  0.0036,  0.0128],
        [ 0.0066,  0.0075,  0.0231,  ..., -0.0034,  0.0457, -0.0109],
        [ 0.0097,  0.0177,  0.0005,  ...,  0.0072, -0.0035,  0.0510]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5938, -1.5156, -1.0742,  ..., -2.6055, -6.1328, -2.1641]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 08:03:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being prepared is preparedness
The state of being foreign is foreignness
The state of being useful is usefulness
The state of being impressive is impressiveness
The state of being pure is pureness
The state of being vast is vastness
The state of being aware is awareness
The state of being reasonable is
2024-07-30 08:03:41 root INFO     [order_1_approx] starting weight calculation for The state of being impressive is impressiveness
The state of being useful is usefulness
The state of being prepared is preparedness
The state of being pure is pureness
The state of being reasonable is reasonableness
The state of being foreign is foreignness
The state of being aware is awareness
The state of being vast is
2024-07-30 08:03:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 08:05:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2603, -0.2554,  0.1973,  ..., -0.0763, -0.1960, -0.0723],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0312, -2.8633, -2.7480,  ..., -4.6406, -6.4609, -1.9004],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.1829e-02, -6.3858e-03, -1.8417e-02,  ..., -3.3188e-04,
         -1.7986e-03,  1.5545e-03],
        [-6.0349e-03,  6.1890e-02,  2.0798e-02,  ...,  2.9419e-02,
         -6.5041e-04,  2.4887e-02],
        [-4.3640e-03, -3.7415e-02,  4.8279e-02,  ..., -2.6360e-03,
         -1.3016e-02,  4.4937e-03],
        ...,
        [ 1.1993e-02,  2.9724e-02,  2.2873e-02,  ...,  6.3232e-02,
          4.1962e-05,  9.4376e-03],
        [ 1.2115e-02, -9.1934e-04,  1.7929e-04,  ..., -2.4185e-02,
          6.3599e-02, -1.2169e-03],
        [ 4.3297e-04,  2.6642e-02,  2.3697e-02,  ...,  6.7444e-03,
         -1.1841e-02,  4.4891e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8330, -2.5527, -2.7109,  ..., -4.3984, -6.6836, -1.6543]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 08:05:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being impressive is impressiveness
The state of being useful is usefulness
The state of being prepared is preparedness
The state of being pure is pureness
The state of being reasonable is reasonableness
The state of being foreign is foreignness
The state of being aware is awareness
The state of being vast is
2024-07-30 08:05:49 root INFO     [order_1_approx] starting weight calculation for The state of being impressive is impressiveness
The state of being reasonable is reasonableness
The state of being useful is usefulness
The state of being foreign is foreignness
The state of being pure is pureness
The state of being vast is vastness
The state of being prepared is preparedness
The state of being aware is
2024-07-30 08:05:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 08:08:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0563, -0.0995, -0.3081,  ...,  0.0304, -0.0768,  0.0473],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6191, -1.7559, -0.8735,  ..., -0.6704, -4.7461,  1.6133],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0623,  0.0033, -0.0116,  ...,  0.0140, -0.0196,  0.0036],
        [-0.0021,  0.0374,  0.0092,  ...,  0.0194,  0.0169,  0.0071],
        [ 0.0107, -0.0228,  0.0628,  ..., -0.0073, -0.0177,  0.0114],
        ...,
        [ 0.0154,  0.0232, -0.0057,  ...,  0.0377, -0.0012,  0.0230],
        [ 0.0180, -0.0007,  0.0102,  ..., -0.0169,  0.0455, -0.0108],
        [ 0.0071,  0.0122,  0.0027,  ..., -0.0024, -0.0162,  0.0613]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9727, -1.3877, -1.0234,  ..., -0.8296, -4.9141,  1.2656]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 08:08:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being impressive is impressiveness
The state of being reasonable is reasonableness
The state of being useful is usefulness
The state of being foreign is foreignness
The state of being pure is pureness
The state of being vast is vastness
The state of being prepared is preparedness
The state of being aware is
2024-07-30 08:08:01 root INFO     [order_1_approx] starting weight calculation for The state of being aware is awareness
The state of being reasonable is reasonableness
The state of being useful is usefulness
The state of being pure is pureness
The state of being foreign is foreignness
The state of being impressive is impressiveness
The state of being vast is vastness
The state of being prepared is
2024-07-30 08:08:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 08:10:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0726, -0.3152, -0.1912,  ...,  0.2600, -0.3457,  0.2180],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.5547, -6.0156, -2.1172,  ...,  0.4241, -3.7656, -2.3965],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0734, -0.0201, -0.0042,  ...,  0.0018, -0.0100, -0.0001],
        [ 0.0034,  0.0646, -0.0049,  ...,  0.0300,  0.0088,  0.0047],
        [-0.0037, -0.0171,  0.0705,  ...,  0.0161,  0.0016, -0.0010],
        ...,
        [-0.0001,  0.0029, -0.0134,  ...,  0.0719,  0.0075,  0.0159],
        [ 0.0028,  0.0115,  0.0137,  ..., -0.0132,  0.0717, -0.0247],
        [ 0.0050, -0.0030, -0.0083,  ..., -0.0102, -0.0061,  0.0782]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.7617, -6.0078, -2.1289,  ...,  0.3027, -3.7344, -2.4512]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 08:10:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being aware is awareness
The state of being reasonable is reasonableness
The state of being useful is usefulness
The state of being pure is pureness
The state of being foreign is foreignness
The state of being impressive is impressiveness
The state of being vast is vastness
The state of being prepared is
2024-07-30 08:10:11 root INFO     [order_1_approx] starting weight calculation for The state of being foreign is foreignness
The state of being reasonable is reasonableness
The state of being vast is vastness
The state of being prepared is preparedness
The state of being pure is pureness
The state of being aware is awareness
The state of being useful is usefulness
The state of being impressive is
2024-07-30 08:10:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 08:12:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0349, -0.2554, -0.2004,  ...,  0.0673, -0.2319,  0.0350],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.7227, -1.9785, -2.4316,  ..., -0.5039, -4.3359, -3.6328],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.9937e-02, -1.2474e-03,  1.6083e-02,  ..., -4.1237e-03,
         -6.1340e-03, -3.5477e-04],
        [ 2.9259e-03,  4.2786e-02,  2.6817e-03,  ...,  7.1411e-03,
          2.8000e-02,  6.7902e-04],
        [ 1.0262e-03, -9.8114e-03,  5.4474e-02,  ..., -7.7477e-03,
         -1.7044e-02, -1.3527e-02],
        ...,
        [ 2.6764e-02,  1.6525e-02,  7.5912e-03,  ...,  3.6591e-02,
          1.1551e-02,  1.4732e-02],
        [ 5.3787e-03,  2.6718e-02,  8.0566e-03,  ..., -3.4332e-05,
          3.2654e-02,  1.2264e-03],
        [ 8.4152e-03,  1.2932e-03,  3.5172e-03,  ..., -1.1299e-02,
         -1.1284e-02,  3.3661e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.8828, -1.8809, -2.4883,  ..., -0.3835, -4.3164, -3.4844]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 08:12:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being foreign is foreignness
The state of being reasonable is reasonableness
The state of being vast is vastness
The state of being prepared is preparedness
The state of being pure is pureness
The state of being aware is awareness
The state of being useful is usefulness
The state of being impressive is
2024-07-30 08:12:19 root INFO     [order_1_approx] starting weight calculation for The state of being aware is awareness
The state of being impressive is impressiveness
The state of being pure is pureness
The state of being prepared is preparedness
The state of being vast is vastness
The state of being reasonable is reasonableness
The state of being foreign is foreignness
The state of being useful is
2024-07-30 08:12:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 08:14:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1423, -0.1278,  0.6191,  ..., -0.0258, -0.2172, -0.1396],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1016, -1.7246, -2.5332,  ..., -2.5039, -5.4375, -1.6660],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0565,  0.0032, -0.0006,  ...,  0.0078,  0.0087,  0.0024],
        [-0.0152,  0.0566,  0.0105,  ...,  0.0304,  0.0147, -0.0012],
        [ 0.0055, -0.0093,  0.0520,  ..., -0.0081, -0.0038, -0.0098],
        ...,
        [ 0.0071,  0.0099,  0.0079,  ...,  0.0384, -0.0051, -0.0064],
        [-0.0004,  0.0244,  0.0103,  ..., -0.0131,  0.0346, -0.0104],
        [ 0.0160,  0.0014, -0.0061,  ..., -0.0172, -0.0190,  0.0475]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.2383, -1.1914, -2.5176,  ..., -2.4121, -5.6953, -1.6553]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 08:14:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being aware is awareness
The state of being impressive is impressiveness
The state of being pure is pureness
The state of being prepared is preparedness
The state of being vast is vastness
The state of being reasonable is reasonableness
The state of being foreign is foreignness
The state of being useful is
2024-07-30 08:14:32 root INFO     [order_1_approx] starting weight calculation for The state of being prepared is preparedness
The state of being impressive is impressiveness
The state of being foreign is foreignness
The state of being aware is awareness
The state of being useful is usefulness
The state of being vast is vastness
The state of being reasonable is reasonableness
The state of being pure is
2024-07-30 08:14:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 08:16:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-4.6631e-02, -4.0063e-01,  9.5117e-01,  ..., -1.8311e-04,
        -4.6692e-02,  3.6133e-01], device='cuda:1', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0625, -1.1387, -2.6543,  ..., -2.8711, -4.5352, -3.3242],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0680, -0.0124, -0.0089,  ..., -0.0079, -0.0148, -0.0099],
        [ 0.0096,  0.0637,  0.0335,  ...,  0.0272,  0.0119, -0.0010],
        [ 0.0163, -0.0023,  0.0526,  ...,  0.0260, -0.0093,  0.0098],
        ...,
        [ 0.0126,  0.0120,  0.0104,  ...,  0.0313,  0.0138,  0.0075],
        [-0.0175,  0.0037, -0.0182,  ..., -0.0078,  0.0514, -0.0092],
        [ 0.0161,  0.0121, -0.0019,  ...,  0.0016, -0.0029,  0.0791]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0391, -0.8950, -2.8750,  ..., -2.6875, -4.4453, -3.5098]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 08:16:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being prepared is preparedness
The state of being impressive is impressiveness
The state of being foreign is foreignness
The state of being aware is awareness
The state of being useful is usefulness
The state of being vast is vastness
The state of being reasonable is reasonableness
The state of being pure is
2024-07-30 08:16:46 root INFO     [order_1_approx] starting weight calculation for The state of being vast is vastness
The state of being useful is usefulness
The state of being prepared is preparedness
The state of being aware is awareness
The state of being impressive is impressiveness
The state of being pure is pureness
The state of being reasonable is reasonableness
The state of being foreign is
2024-07-30 08:16:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 08:18:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0020, -0.0690,  0.1544,  ..., -0.2200,  0.3970,  0.3069],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5215, -3.6484,  0.0449,  ..., -2.5312, -4.0273, -1.1953],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.7109e-02,  3.3607e-03, -1.8204e-02,  ...,  2.5101e-02,
          1.6327e-03, -2.7603e-02],
        [ 2.4841e-02,  5.0079e-02,  3.0289e-02,  ..., -6.7596e-03,
          1.7136e-02,  3.2043e-02],
        [-1.1269e-02,  4.5242e-03,  3.1311e-02,  ...,  3.7060e-03,
         -8.4114e-04, -6.0425e-03],
        ...,
        [ 1.3321e-02,  1.9257e-02,  1.1078e-02,  ...,  1.9211e-02,
          1.1169e-02,  8.7585e-03],
        [ 6.3553e-03,  1.1330e-03, -5.9891e-04,  ..., -6.7115e-05,
          4.4678e-02, -1.9257e-02],
        [ 1.4938e-02,  1.3481e-02,  5.7945e-03,  ..., -4.7684e-03,
         -6.6452e-03,  6.0394e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0151, -2.5430, -0.0909,  ..., -1.8730, -4.1914, -0.9902]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 08:19:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being vast is vastness
The state of being useful is usefulness
The state of being prepared is preparedness
The state of being aware is awareness
The state of being impressive is impressiveness
The state of being pure is pureness
The state of being reasonable is reasonableness
The state of being foreign is
2024-07-30 08:19:00 root INFO     total operator prediction time: 1048.4003701210022 seconds
2024-07-30 08:19:00 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on re+verb_reg
2024-07-30 08:19:00 root INFO     building operator re+verb_reg
2024-07-30 08:19:00 root INFO     [order_1_approx] starting weight calculation for To unite again is to reunite
To engage again is to reengage
To consider again is to reconsider
To assess again is to reassess
To adjust again is to readjust
To appear again is to reappear
To organize again is to reorganize
To interpret again is to
2024-07-30 08:19:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 08:21:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1980,  0.0828,  0.2043,  ...,  0.2803, -0.3271,  0.4734],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1666, -1.8555,  0.5913,  ...,  0.1934, -1.9619, -3.8242],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0557, -0.0037,  0.0190,  ...,  0.0080, -0.0053,  0.0076],
        [ 0.0083,  0.0559,  0.0069,  ...,  0.0074,  0.0016, -0.0065],
        [-0.0046, -0.0048,  0.0394,  ..., -0.0013,  0.0049, -0.0084],
        ...,
        [ 0.0128, -0.0029, -0.0032,  ...,  0.0545,  0.0083, -0.0039],
        [-0.0070, -0.0078,  0.0125,  ..., -0.0132,  0.0457, -0.0108],
        [-0.0110,  0.0038,  0.0057,  ..., -0.0045, -0.0218,  0.0497]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1019, -1.8994,  0.6133,  ...,  0.2563, -1.8906, -4.0078]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 08:21:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To unite again is to reunite
To engage again is to reengage
To consider again is to reconsider
To assess again is to reassess
To adjust again is to readjust
To appear again is to reappear
To organize again is to reorganize
To interpret again is to
2024-07-30 08:21:14 root INFO     [order_1_approx] starting weight calculation for To interpret again is to reinterpret
To organize again is to reorganize
To assess again is to reassess
To adjust again is to readjust
To engage again is to reengage
To consider again is to reconsider
To appear again is to reappear
To unite again is to
2024-07-30 08:21:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 08:23:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3762,  0.0789, -0.0464,  ...,  0.3845, -0.4958,  0.4932],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2964, -3.2695,  1.4551,  ...,  2.8516, -3.7949, -2.1855],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.4026e-02, -5.3444e-03,  1.7014e-02,  ...,  8.5144e-03,
          1.4000e-03,  1.4130e-02],
        [ 5.9967e-03,  5.3497e-02,  2.3842e-03,  ...,  3.6869e-03,
         -1.7853e-02, -6.2943e-05],
        [-2.9373e-04,  1.1536e-02,  4.9316e-02,  ...,  3.8357e-03,
         -6.6328e-04, -6.9122e-03],
        ...,
        [-5.8136e-03, -1.5402e-03, -7.8354e-03,  ...,  5.4047e-02,
         -9.1553e-03, -1.2016e-02],
        [-3.4122e-03,  9.2697e-03,  7.2479e-03,  ..., -8.6975e-03,
          4.8218e-02, -1.2917e-02],
        [ 7.0381e-03, -9.3765e-03,  8.7357e-03,  ...,  4.7951e-03,
         -1.3596e-02,  6.6284e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1343, -3.4219,  1.4580,  ...,  3.0137, -3.8594, -2.3418]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 08:23:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To interpret again is to reinterpret
To organize again is to reorganize
To assess again is to reassess
To adjust again is to readjust
To engage again is to reengage
To consider again is to reconsider
To appear again is to reappear
To unite again is to
2024-07-30 08:23:26 root INFO     [order_1_approx] starting weight calculation for To appear again is to reappear
To consider again is to reconsider
To unite again is to reunite
To interpret again is to reinterpret
To adjust again is to readjust
To engage again is to reengage
To organize again is to reorganize
To assess again is to
2024-07-30 08:23:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 08:25:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0752, -0.0580,  0.0046,  ...,  0.3250, -0.2527, -0.1111],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1660, -3.1191,  0.4448,  ...,  0.3672, -4.2227, -3.1445],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0662, -0.0021,  0.0225,  ..., -0.0063,  0.0021,  0.0134],
        [ 0.0133,  0.0481,  0.0057,  ...,  0.0166, -0.0016,  0.0070],
        [-0.0015,  0.0043,  0.0518,  ...,  0.0006,  0.0159, -0.0011],
        ...,
        [ 0.0075,  0.0003,  0.0063,  ...,  0.0685,  0.0015, -0.0054],
        [-0.0139,  0.0098,  0.0170,  ...,  0.0132,  0.0526, -0.0075],
        [ 0.0017,  0.0035, -0.0018,  ..., -0.0103, -0.0163,  0.0391]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0176, -3.2871,  0.4126,  ...,  0.7681, -4.4297, -3.0020]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 08:25:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To appear again is to reappear
To consider again is to reconsider
To unite again is to reunite
To interpret again is to reinterpret
To adjust again is to readjust
To engage again is to reengage
To organize again is to reorganize
To assess again is to
2024-07-30 08:25:37 root INFO     [order_1_approx] starting weight calculation for To appear again is to reappear
To engage again is to reengage
To organize again is to reorganize
To assess again is to reassess
To interpret again is to reinterpret
To adjust again is to readjust
To unite again is to reunite
To consider again is to
2024-07-30 08:25:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 08:27:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1265, -0.0102,  0.0061,  ...,  0.1425, -0.2817, -0.1063],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1848, -3.5352,  1.2686,  ...,  0.3672, -2.3105, -1.8281],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0654,  0.0027,  0.0044,  ..., -0.0030,  0.0040,  0.0229],
        [ 0.0043,  0.0229,  0.0115,  ...,  0.0268, -0.0135,  0.0029],
        [-0.0098,  0.0015,  0.0512,  ..., -0.0175,  0.0096, -0.0060],
        ...,
        [ 0.0093, -0.0145,  0.0208,  ...,  0.0710, -0.0061, -0.0084],
        [ 0.0085,  0.0229,  0.0064,  ..., -0.0244,  0.0532, -0.0046],
        [-0.0089, -0.0131,  0.0104,  ...,  0.0004, -0.0191,  0.0393]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3538, -3.4414,  1.0488,  ...,  1.3096, -2.5078, -1.3418]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 08:27:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To appear again is to reappear
To engage again is to reengage
To organize again is to reorganize
To assess again is to reassess
To interpret again is to reinterpret
To adjust again is to readjust
To unite again is to reunite
To consider again is to
2024-07-30 08:27:51 root INFO     [order_1_approx] starting weight calculation for To interpret again is to reinterpret
To adjust again is to readjust
To assess again is to reassess
To engage again is to reengage
To organize again is to reorganize
To unite again is to reunite
To consider again is to reconsider
To appear again is to
2024-07-30 08:27:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 08:30:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0040, -0.2283, -0.2642,  ..., -0.0209, -0.0610, -0.2759],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4336, -2.3770,  0.9033,  ...,  3.9434, -6.1523, -1.5430],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0790, -0.0002,  0.0104,  ...,  0.0134, -0.0065,  0.0123],
        [-0.0065,  0.0450,  0.0074,  ...,  0.0174, -0.0064,  0.0007],
        [-0.0080, -0.0045,  0.0641,  ..., -0.0067,  0.0068, -0.0154],
        ...,
        [-0.0265, -0.0170,  0.0079,  ...,  0.0735, -0.0104, -0.0045],
        [ 0.0068,  0.0327, -0.0142,  ..., -0.0277,  0.0635, -0.0215],
        [-0.0104, -0.0145,  0.0164,  ..., -0.0089, -0.0184,  0.0668]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1885, -2.8027,  0.9141,  ...,  4.1680, -5.9961, -1.6719]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 08:30:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To interpret again is to reinterpret
To adjust again is to readjust
To assess again is to reassess
To engage again is to reengage
To organize again is to reorganize
To unite again is to reunite
To consider again is to reconsider
To appear again is to
2024-07-30 08:30:02 root INFO     [order_1_approx] starting weight calculation for To interpret again is to reinterpret
To unite again is to reunite
To engage again is to reengage
To appear again is to reappear
To assess again is to reassess
To adjust again is to readjust
To consider again is to reconsider
To organize again is to
2024-07-30 08:30:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 08:32:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4910,  0.6431,  0.2603,  ..., -0.0884, -0.1479, -0.1105],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3667, -4.3047,  1.8447,  ...,  2.4141, -3.0762, -4.7578],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0568,  0.0078,  0.0163,  ..., -0.0038,  0.0002,  0.0065],
        [ 0.0069,  0.0490,  0.0038,  ...,  0.0106, -0.0042,  0.0028],
        [ 0.0016,  0.0119,  0.0311,  ...,  0.0011,  0.0003, -0.0055],
        ...,
        [ 0.0012, -0.0008, -0.0040,  ...,  0.0413, -0.0066, -0.0017],
        [-0.0062,  0.0114, -0.0032,  ...,  0.0051,  0.0427, -0.0062],
        [ 0.0086, -0.0084,  0.0001,  ..., -0.0038, -0.0054,  0.0390]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4858, -4.3555,  1.8760,  ...,  2.5410, -3.1582, -4.6641]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 08:32:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To interpret again is to reinterpret
To unite again is to reunite
To engage again is to reengage
To appear again is to reappear
To assess again is to reassess
To adjust again is to readjust
To consider again is to reconsider
To organize again is to
2024-07-30 08:32:15 root INFO     [order_1_approx] starting weight calculation for To consider again is to reconsider
To unite again is to reunite
To engage again is to reengage
To assess again is to reassess
To interpret again is to reinterpret
To organize again is to reorganize
To appear again is to reappear
To adjust again is to
2024-07-30 08:32:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 08:34:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3909, -0.0175, -0.7285,  ...,  0.1154, -0.1206,  0.0800],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2949, -2.1895, -2.6914,  ...,  1.9043, -3.4316, -2.8125],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0840,  0.0148,  0.0164,  ..., -0.0208,  0.0083,  0.0282],
        [ 0.0195,  0.0724,  0.0038,  ...,  0.0103, -0.0106,  0.0157],
        [ 0.0004,  0.0082,  0.0371,  ..., -0.0104,  0.0048, -0.0079],
        ...,
        [ 0.0075, -0.0054, -0.0100,  ...,  0.0813,  0.0064, -0.0098],
        [-0.0128, -0.0017, -0.0102,  ..., -0.0081,  0.0636, -0.0188],
        [ 0.0010,  0.0109, -0.0050,  ..., -0.0275, -0.0141,  0.0590]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8198, -2.1914, -2.3906,  ...,  2.1680, -3.2129, -2.6680]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 08:34:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To consider again is to reconsider
To unite again is to reunite
To engage again is to reengage
To assess again is to reassess
To interpret again is to reinterpret
To organize again is to reorganize
To appear again is to reappear
To adjust again is to
2024-07-30 08:34:29 root INFO     [order_1_approx] starting weight calculation for To appear again is to reappear
To unite again is to reunite
To adjust again is to readjust
To organize again is to reorganize
To assess again is to reassess
To interpret again is to reinterpret
To consider again is to reconsider
To engage again is to
2024-07-30 08:34:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 08:36:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2299,  0.3130,  0.2216,  ...,  0.2362, -0.5273,  0.0350],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6602, -2.5898,  1.2285,  ...,  2.3633, -3.8574, -5.2422],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0644,  0.0136,  0.0054,  ...,  0.0101, -0.0013,  0.0110],
        [-0.0009,  0.0430,  0.0046,  ...,  0.0008, -0.0108,  0.0065],
        [ 0.0003,  0.0071,  0.0366,  ..., -0.0154,  0.0014, -0.0071],
        ...,
        [ 0.0020, -0.0091, -0.0005,  ...,  0.0434, -0.0023,  0.0015],
        [ 0.0030,  0.0210, -0.0010,  ..., -0.0033,  0.0560, -0.0157],
        [-0.0018, -0.0091, -0.0100,  ..., -0.0103, -0.0179,  0.0396]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5557, -2.6426,  1.1855,  ...,  2.6914, -3.9863, -5.1406]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 08:36:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To appear again is to reappear
To unite again is to reunite
To adjust again is to readjust
To organize again is to reorganize
To assess again is to reassess
To interpret again is to reinterpret
To consider again is to reconsider
To engage again is to
2024-07-30 08:36:42 root INFO     total operator prediction time: 1062.166339635849 seconds
2024-07-30 08:36:42 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on un+adj_reg
2024-07-30 08:36:42 root INFO     building operator un+adj_reg
2024-07-30 08:36:43 root INFO     [order_1_approx] starting weight calculation for The opposite of acceptable is unacceptable
The opposite of veiled is unveiled
The opposite of intended is unintended
The opposite of controlled is uncontrolled
The opposite of biased is unbiased
The opposite of conscious is unconscious
The opposite of desirable is undesirable
The opposite of certain is
2024-07-30 08:36:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 08:38:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2808,  0.0157, -0.0706,  ...,  0.0448,  0.1323, -0.3027],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3105, -1.5430,  1.4814,  ..., -0.0894, -0.7656, -3.5938],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0471,  0.0055,  0.0218,  ...,  0.0013, -0.0155,  0.0078],
        [ 0.0109,  0.0648, -0.0124,  ...,  0.0465,  0.0161,  0.0379],
        [-0.0023,  0.0089,  0.0516,  ...,  0.0214, -0.0191, -0.0054],
        ...,
        [ 0.0103,  0.0324, -0.0030,  ...,  0.0381, -0.0044,  0.0105],
        [-0.0056,  0.0128, -0.0100,  ..., -0.0092,  0.0415, -0.0011],
        [-0.0039,  0.0187, -0.0280,  ..., -0.0090,  0.0069,  0.0530]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0801, -1.6338,  1.9424,  ..., -0.4971, -1.4961, -3.9258]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 08:38:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of acceptable is unacceptable
The opposite of veiled is unveiled
The opposite of intended is unintended
The opposite of controlled is uncontrolled
The opposite of biased is unbiased
The opposite of conscious is unconscious
The opposite of desirable is undesirable
The opposite of certain is
2024-07-30 08:38:54 root INFO     [order_1_approx] starting weight calculation for The opposite of intended is unintended
The opposite of conscious is unconscious
The opposite of desirable is undesirable
The opposite of biased is unbiased
The opposite of controlled is uncontrolled
The opposite of veiled is unveiled
The opposite of certain is uncertain
The opposite of acceptable is
2024-07-30 08:38:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 08:41:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1107,  0.2490, -0.1698,  ...,  0.0548, -0.5312,  0.0645],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5391, -3.3242,  1.6406,  ..., -0.6709, -3.1133, -2.8164],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0460,  0.0001,  0.0138,  ...,  0.0254, -0.0110, -0.0043],
        [-0.0127,  0.0621, -0.0261,  ..., -0.0117,  0.0130,  0.0163],
        [-0.0071,  0.0200,  0.0224,  ...,  0.0082, -0.0324, -0.0288],
        ...,
        [ 0.0042,  0.0435, -0.0161,  ...,  0.0551,  0.0041, -0.0170],
        [ 0.0006, -0.0020,  0.0179,  ..., -0.0184,  0.0301, -0.0168],
        [ 0.0002,  0.0096, -0.0111,  ..., -0.0057, -0.0215,  0.0660]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4688, -3.1855,  1.6777,  ..., -0.2969, -2.7871, -2.3516]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 08:41:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of intended is unintended
The opposite of conscious is unconscious
The opposite of desirable is undesirable
The opposite of biased is unbiased
The opposite of controlled is uncontrolled
The opposite of veiled is unveiled
The opposite of certain is uncertain
The opposite of acceptable is
2024-07-30 08:41:07 root INFO     [order_1_approx] starting weight calculation for The opposite of desirable is undesirable
The opposite of acceptable is unacceptable
The opposite of certain is uncertain
The opposite of controlled is uncontrolled
The opposite of veiled is unveiled
The opposite of biased is unbiased
The opposite of intended is unintended
The opposite of conscious is
2024-07-30 08:41:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 08:43:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0739, -0.1630,  0.0209,  ..., -0.2129, -0.0139,  0.2493],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5469, -0.8105,  4.0938,  ..., -1.8691,  1.6758, -1.6016],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.7852e-02, -3.4828e-03,  2.3327e-03,  ...,  3.7964e-02,
         -3.1342e-02, -1.3199e-03],
        [-3.1052e-02,  2.8748e-02, -9.7046e-03,  ..., -1.2417e-03,
          1.6068e-02,  8.7585e-03],
        [-1.1658e-02, -3.2013e-02,  2.5513e-02,  ...,  1.3733e-04,
         -2.9922e-02,  5.7220e-05],
        ...,
        [ 8.0032e-03,  2.7832e-02,  9.9945e-03,  ...,  4.7302e-02,
         -7.1259e-03, -1.1826e-03],
        [-5.2414e-03, -8.0414e-03,  1.5717e-02,  ..., -1.4008e-02,
          5.0720e-02, -1.9562e-02],
        [-3.5172e-03, -9.8419e-03, -2.4490e-03,  ..., -6.9160e-03,
         -8.5068e-03,  5.3223e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3125, -0.9062,  3.2598,  ..., -1.9717,  1.1758, -1.9492]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 08:43:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of desirable is undesirable
The opposite of acceptable is unacceptable
The opposite of certain is uncertain
The opposite of controlled is uncontrolled
The opposite of veiled is unveiled
The opposite of biased is unbiased
The opposite of intended is unintended
The opposite of conscious is
2024-07-30 08:43:21 root INFO     [order_1_approx] starting weight calculation for The opposite of certain is uncertain
The opposite of conscious is unconscious
The opposite of controlled is uncontrolled
The opposite of intended is unintended
The opposite of acceptable is unacceptable
The opposite of veiled is unveiled
The opposite of biased is unbiased
The opposite of desirable is
2024-07-30 08:43:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 08:45:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1252, -0.0667,  0.0185,  ...,  0.0142, -0.1157,  0.0563],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8481, -4.1016,  0.3823,  ..., -0.8340, -4.9648, -4.2617],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0434,  0.0152, -0.0022,  ...,  0.0118, -0.0210, -0.0083],
        [-0.0173,  0.0584, -0.0288,  ...,  0.0316,  0.0042, -0.0041],
        [-0.0062,  0.0091,  0.0259,  ..., -0.0037, -0.0072, -0.0147],
        ...,
        [ 0.0033,  0.0400,  0.0125,  ...,  0.0157,  0.0106, -0.0169],
        [-0.0063, -0.0131,  0.0448,  ..., -0.0170,  0.0670,  0.0255],
        [-0.0047,  0.0002, -0.0188,  ..., -0.0032, -0.0183,  0.0327]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2949, -3.5469,  0.3801,  ..., -0.7153, -4.8438, -4.0547]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 08:45:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of certain is uncertain
The opposite of conscious is unconscious
The opposite of controlled is uncontrolled
The opposite of intended is unintended
The opposite of acceptable is unacceptable
The opposite of veiled is unveiled
The opposite of biased is unbiased
The opposite of desirable is
2024-07-30 08:45:34 root INFO     [order_1_approx] starting weight calculation for The opposite of intended is unintended
The opposite of controlled is uncontrolled
The opposite of veiled is unveiled
The opposite of acceptable is unacceptable
The opposite of desirable is undesirable
The opposite of certain is uncertain
The opposite of conscious is unconscious
The opposite of biased is
2024-07-30 08:45:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 08:47:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3848, -0.4458, -0.3450,  ...,  0.8154, -0.0613,  0.3855],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5098, -0.1105, -0.7168,  ..., -1.3047, -3.9102, -2.9844],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0589, -0.0254, -0.0140,  ...,  0.0120,  0.0036,  0.0100],
        [-0.0167,  0.0782,  0.0131,  ...,  0.0145,  0.0058, -0.0083],
        [-0.0064, -0.0213,  0.0357,  ...,  0.0124, -0.0032, -0.0098],
        ...,
        [ 0.0128,  0.0376,  0.0117,  ...,  0.0537, -0.0037, -0.0043],
        [ 0.0046, -0.0030,  0.0160,  ..., -0.0263,  0.0367,  0.0205],
        [-0.0102,  0.0087,  0.0313,  ...,  0.0002,  0.0020,  0.0569]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2578,  0.1671, -0.8018,  ..., -1.2920, -3.7969, -3.1504]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 08:47:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of intended is unintended
The opposite of controlled is uncontrolled
The opposite of veiled is unveiled
The opposite of acceptable is unacceptable
The opposite of desirable is undesirable
The opposite of certain is uncertain
The opposite of conscious is unconscious
The opposite of biased is
2024-07-30 08:47:49 root INFO     [order_1_approx] starting weight calculation for The opposite of intended is unintended
The opposite of certain is uncertain
The opposite of conscious is unconscious
The opposite of acceptable is unacceptable
The opposite of veiled is unveiled
The opposite of biased is unbiased
The opposite of desirable is undesirable
The opposite of controlled is
2024-07-30 08:47:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 08:50:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0808, -0.3281, -0.0695,  ..., -0.1702,  0.0599, -0.0923],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6260, -0.2920,  0.5669,  ...,  0.7686,  1.7598, -2.9102],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0634, -0.0066, -0.0272,  ...,  0.0174,  0.0088,  0.0145],
        [ 0.0002,  0.0508,  0.0185,  ...,  0.0325,  0.0245, -0.0023],
        [-0.0134,  0.0050,  0.0335,  ...,  0.0404, -0.0018, -0.0120],
        ...,
        [-0.0031,  0.0305,  0.0046,  ...,  0.0316, -0.0103, -0.0079],
        [ 0.0083, -0.0004,  0.0147,  ..., -0.0132,  0.0367, -0.0075],
        [-0.0275, -0.0014,  0.0153,  ..., -0.0049, -0.0065,  0.0586]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0547, -0.5625,  0.3516,  ...,  1.1924,  1.7578, -2.5645]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 08:50:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of intended is unintended
The opposite of certain is uncertain
The opposite of conscious is unconscious
The opposite of acceptable is unacceptable
The opposite of veiled is unveiled
The opposite of biased is unbiased
The opposite of desirable is undesirable
The opposite of controlled is
2024-07-30 08:50:02 root INFO     [order_1_approx] starting weight calculation for The opposite of desirable is undesirable
The opposite of intended is unintended
The opposite of controlled is uncontrolled
The opposite of conscious is unconscious
The opposite of acceptable is unacceptable
The opposite of biased is unbiased
The opposite of certain is uncertain
The opposite of veiled is
2024-07-30 08:50:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 08:52:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2278, -0.7842,  0.1306,  ...,  0.0869, -0.0264,  0.2296],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5723,  0.3594,  0.2891,  ...,  2.6875, -3.3984,  0.0859],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0499, -0.0069,  0.0143,  ...,  0.0285,  0.0063, -0.0078],
        [-0.0105,  0.0516, -0.0064,  ...,  0.0171, -0.0113, -0.0094],
        [ 0.0087, -0.0240,  0.0483,  ...,  0.0204,  0.0014,  0.0102],
        ...,
        [ 0.0066,  0.0012,  0.0169,  ...,  0.0587,  0.0155,  0.0201],
        [ 0.0248, -0.0183,  0.0188,  ..., -0.0101,  0.0742,  0.0116],
        [-0.0124, -0.0053, -0.0009,  ..., -0.0031,  0.0002,  0.0784]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9512,  0.7217, -0.2388,  ...,  2.6602, -3.8438, -0.0268]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 08:52:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of desirable is undesirable
The opposite of intended is unintended
The opposite of controlled is uncontrolled
The opposite of conscious is unconscious
The opposite of acceptable is unacceptable
The opposite of biased is unbiased
The opposite of certain is uncertain
The opposite of veiled is
2024-07-30 08:52:14 root INFO     [order_1_approx] starting weight calculation for The opposite of conscious is unconscious
The opposite of certain is uncertain
The opposite of veiled is unveiled
The opposite of biased is unbiased
The opposite of acceptable is unacceptable
The opposite of controlled is uncontrolled
The opposite of desirable is undesirable
The opposite of intended is
2024-07-30 08:52:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 08:54:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3140, -0.0725,  0.0642,  ...,  0.2344,  0.1650, -0.1304],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4111, -0.6689, -0.3936,  ...,  0.3833,  0.0576, -4.3281],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0359,  0.0076,  0.0058,  ...,  0.0150, -0.0177,  0.0003],
        [-0.0203,  0.0453, -0.0182,  ...,  0.0051,  0.0164, -0.0214],
        [-0.0054, -0.0142,  0.0563,  ...,  0.0047, -0.0010, -0.0162],
        ...,
        [-0.0242, -0.0030,  0.0100,  ...,  0.0305, -0.0053, -0.0232],
        [-0.0126, -0.0018,  0.0076,  ..., -0.0228,  0.0402, -0.0013],
        [ 0.0090,  0.0148,  0.0247,  ..., -0.0032, -0.0012,  0.0630]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6836, -0.4397, -0.6650,  ...,  0.0227, -0.1624, -4.5117]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 08:54:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of conscious is unconscious
The opposite of certain is uncertain
The opposite of veiled is unveiled
The opposite of biased is unbiased
The opposite of acceptable is unacceptable
The opposite of controlled is uncontrolled
The opposite of desirable is undesirable
The opposite of intended is
2024-07-30 08:54:27 root INFO     total operator prediction time: 1064.361200094223 seconds
2024-07-30 08:54:27 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+able_reg
2024-07-30 08:54:27 root INFO     building operator verb+able_reg
2024-07-30 08:54:27 root INFO     [order_1_approx] starting weight calculation for If you can prefer something, that thing is preferable
If you can afford something, that thing is affordable
If you can sustain something, that thing is sustainable
If you can renew something, that thing is renewable
If you can predict something, that thing is predictable
If you can explain something, that thing is explainable
If you can identify something, that thing is identifiable
If you can expect something, that thing is
2024-07-30 08:54:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 08:56:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1787, -0.1072,  0.0382,  ..., -0.1842,  0.2474, -0.3870],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1602,  0.4304, -5.7305,  ..., -2.9219, -8.1953, -3.3125],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0463,  0.0138,  0.0082,  ...,  0.0241, -0.0015,  0.0105],
        [-0.0336,  0.0439,  0.0220,  ...,  0.0201,  0.0058, -0.0170],
        [-0.0037, -0.0088,  0.0086,  ..., -0.0123,  0.0138, -0.0280],
        ...,
        [-0.0210,  0.0142,  0.0044,  ...,  0.0485,  0.0056, -0.0092],
        [ 0.0120,  0.0053, -0.0136,  ..., -0.0270,  0.0347, -0.0109],
        [ 0.0087,  0.0077,  0.0119,  ...,  0.0003, -0.0114,  0.0316]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7773,  0.6162, -5.6797,  ..., -2.8730, -8.3281, -3.4316]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 08:56:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can prefer something, that thing is preferable
If you can afford something, that thing is affordable
If you can sustain something, that thing is sustainable
If you can renew something, that thing is renewable
If you can predict something, that thing is predictable
If you can explain something, that thing is explainable
If you can identify something, that thing is identifiable
If you can expect something, that thing is
2024-07-30 08:56:40 root INFO     [order_1_approx] starting weight calculation for If you can expect something, that thing is expectable
If you can afford something, that thing is affordable
If you can explain something, that thing is explainable
If you can prefer something, that thing is preferable
If you can predict something, that thing is predictable
If you can sustain something, that thing is sustainable
If you can renew something, that thing is renewable
If you can identify something, that thing is
2024-07-30 08:56:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 08:58:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0574, -0.1089,  0.0511,  ...,  0.4126, -0.2791, -0.5293],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0728,  1.0488,  0.5176,  ..., -2.1094, -9.4688, -1.4424],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.3853e-02, -3.3607e-03, -4.1809e-03,  ...,  2.4231e-02,
         -4.5547e-03,  7.6447e-03],
        [-1.9928e-02,  5.3375e-02,  1.3702e-02,  ...,  1.5396e-02,
          2.6550e-03, -5.5733e-03],
        [ 1.3832e-02, -2.8061e-02,  7.3608e-02,  ...,  3.2463e-03,
          6.7291e-03, -1.0910e-02],
        ...,
        [ 2.7481e-02,  2.2675e-02,  5.7106e-03,  ...,  9.2224e-02,
         -5.2834e-04,  7.2479e-05],
        [-5.3749e-03, -2.5520e-03, -5.3406e-05,  ..., -2.7222e-02,
          5.8624e-02, -5.6152e-03],
        [ 1.0788e-02,  1.0590e-02,  1.8005e-02,  ...,  1.1925e-02,
         -3.3234e-02,  6.2103e-02]], device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0384,  0.8276,  0.2866,  ..., -2.1348, -9.1562, -1.6631]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 08:58:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can expect something, that thing is expectable
If you can afford something, that thing is affordable
If you can explain something, that thing is explainable
If you can prefer something, that thing is preferable
If you can predict something, that thing is predictable
If you can sustain something, that thing is sustainable
If you can renew something, that thing is renewable
If you can identify something, that thing is
2024-07-30 08:58:52 root INFO     [order_1_approx] starting weight calculation for If you can sustain something, that thing is sustainable
If you can identify something, that thing is identifiable
If you can afford something, that thing is affordable
If you can prefer something, that thing is preferable
If you can renew something, that thing is renewable
If you can expect something, that thing is expectable
If you can explain something, that thing is explainable
If you can predict something, that thing is
2024-07-30 08:58:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 09:01:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1794,  0.4646,  0.5908,  ..., -0.1027,  0.2761, -0.3306],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3496,  0.6582, -2.2363,  ..., -2.7305, -7.0586, -1.9482],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0591,  0.0095,  0.0029,  ...,  0.0113, -0.0175,  0.0057],
        [-0.0228,  0.0348,  0.0179,  ...,  0.0134,  0.0062, -0.0109],
        [-0.0099,  0.0090,  0.0277,  ..., -0.0097, -0.0073, -0.0215],
        ...,
        [-0.0023,  0.0063,  0.0012,  ...,  0.0456, -0.0021,  0.0030],
        [ 0.0096,  0.0013, -0.0098,  ..., -0.0267,  0.0338, -0.0158],
        [-0.0005,  0.0085,  0.0163,  ..., -0.0117, -0.0186,  0.0393]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2930,  0.6455, -2.3672,  ..., -2.8926, -7.2383, -2.3652]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 09:01:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can sustain something, that thing is sustainable
If you can identify something, that thing is identifiable
If you can afford something, that thing is affordable
If you can prefer something, that thing is preferable
If you can renew something, that thing is renewable
If you can expect something, that thing is expectable
If you can explain something, that thing is explainable
If you can predict something, that thing is
2024-07-30 09:01:05 root INFO     [order_1_approx] starting weight calculation for If you can identify something, that thing is identifiable
If you can expect something, that thing is expectable
If you can explain something, that thing is explainable
If you can predict something, that thing is predictable
If you can prefer something, that thing is preferable
If you can afford something, that thing is affordable
If you can renew something, that thing is renewable
If you can sustain something, that thing is
2024-07-30 09:01:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 09:03:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3013,  0.3296,  0.2974,  ..., -0.3267,  0.3669,  0.1295],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4766, -2.0332, -1.4238,  ..., -4.7891, -6.2695, -2.1074],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0439,  0.0052,  0.0095,  ...,  0.0064,  0.0021, -0.0014],
        [-0.0154,  0.0331,  0.0024,  ...,  0.0007,  0.0056, -0.0060],
        [ 0.0004, -0.0024,  0.0367,  ...,  0.0017, -0.0026, -0.0134],
        ...,
        [ 0.0228,  0.0163, -0.0062,  ...,  0.0359,  0.0027,  0.0048],
        [ 0.0056,  0.0041, -0.0063,  ..., -0.0314,  0.0221, -0.0096],
        [-0.0009, -0.0088,  0.0002,  ..., -0.0244, -0.0114,  0.0113]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2656, -1.9512, -1.5439,  ..., -4.5195, -6.5234, -2.2422]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 09:03:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can identify something, that thing is identifiable
If you can expect something, that thing is expectable
If you can explain something, that thing is explainable
If you can predict something, that thing is predictable
If you can prefer something, that thing is preferable
If you can afford something, that thing is affordable
If you can renew something, that thing is renewable
If you can sustain something, that thing is
2024-07-30 09:03:19 root INFO     [order_1_approx] starting weight calculation for If you can prefer something, that thing is preferable
If you can expect something, that thing is expectable
If you can sustain something, that thing is sustainable
If you can afford something, that thing is affordable
If you can identify something, that thing is identifiable
If you can predict something, that thing is predictable
If you can explain something, that thing is explainable
If you can renew something, that thing is
2024-07-30 09:03:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
2024-07-30 09:05:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1118,  0.0027, -0.3799,  ..., -0.0907, -0.0450,  0.0906],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.4883, -2.5898, -0.2739,  ..., -3.9609, -6.2422, -3.5723],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0813,  0.0050,  0.0191,  ...,  0.0360, -0.0109,  0.0141],
        [-0.0219,  0.0598,  0.0123,  ...,  0.0201, -0.0080, -0.0095],
        [ 0.0099, -0.0073,  0.0630,  ..., -0.0045,  0.0032, -0.0138],
        ...,
        [ 0.0114, -0.0099,  0.0041,  ...,  0.0688,  0.0058, -0.0024],
        [ 0.0103,  0.0038,  0.0001,  ..., -0.0387,  0.0545, -0.0060],
        [-0.0174, -0.0103, -0.0096,  ..., -0.0327, -0.0138,  0.0460]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.0742, -2.6914, -0.4680,  ..., -3.5742, -6.4297, -3.6113]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-30 09:05:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can prefer something, that thing is preferable
If you can expect something, that thing is expectable
If you can sustain something, that thing is sustainable
If you can afford something, that thing is affordable
If you can identify something, that thing is identifiable
If you can predict something, that thing is predictable
If you can explain something, that thing is explainable
If you can renew something, that thing is
2024-07-30 09:05:31 root INFO     [order_1_approx] starting weight calculation for If you can explain something, that thing is explainable
If you can predict something, that thing is predictable
If you can sustain something, that thing is sustainable
If you can renew something, that thing is renewable
If you can identify something, that thing is identifiable
If you can expect something, that thing is expectable
If you can prefer something, that thing is preferable
If you can afford something, that thing is
2024-07-30 09:05:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.13
