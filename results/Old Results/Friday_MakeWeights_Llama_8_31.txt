2024-07-26 10:58:51 root INFO     loading model + tokenizer
2024-07-26 10:58:55 root INFO     model + tokenizer loaded
2024-07-26 10:58:55 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - part
2024-07-26 10:58:55 root INFO     building operator meronyms - part
2024-07-26 11:00:07 root INFO     loading model + tokenizer
2024-07-26 11:00:25 root INFO     loading model + tokenizer
2024-07-26 11:00:29 root INFO     model + tokenizer loaded
2024-07-26 11:00:29 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - part
2024-07-26 11:00:29 root INFO     building operator meronyms - part
2024-07-26 11:02:34 root INFO     loading model + tokenizer
2024-07-26 11:02:38 root INFO     model + tokenizer loaded
2024-07-26 11:02:38 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - part
2024-07-26 11:02:38 root INFO     building operator meronyms - part
2024-07-26 11:02:38 root INFO     [order_1_approx] starting weight calculation for A part of a tonne is a kilogram
A part of a table is a tabletop
A part of a brush is a bristle
A part of a seafront is a harbor
A part of a radio is a receiver
A part of a shilling is a pence
A part of a academia is a college
A part of a jail is a
2024-07-26 11:02:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 11:05:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1274,  0.0350, -0.2373,  ..., -0.0634, -0.3208,  0.0579],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3066, -6.3984,  1.2227,  ..., -0.7734, -1.0908,  0.9941],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0462, -0.0106,  0.0247,  ..., -0.0176,  0.0143, -0.0076],
        [-0.0022,  0.0336, -0.0322,  ...,  0.0104, -0.0037, -0.0008],
        [ 0.0123, -0.0091,  0.0474,  ..., -0.0196, -0.0176,  0.0106],
        ...,
        [-0.0018,  0.0013, -0.0181,  ...,  0.0717,  0.0037, -0.0232],
        [-0.0296, -0.0123, -0.0256,  ..., -0.0025,  0.0313, -0.0083],
        [ 0.0037,  0.0149, -0.0104,  ..., -0.0043, -0.0074,  0.0119]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0000, -5.8945,  1.0928,  ..., -0.4175, -1.3809,  0.9590]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 11:05:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a tonne is a kilogram
A part of a table is a tabletop
A part of a brush is a bristle
A part of a seafront is a harbor
A part of a radio is a receiver
A part of a shilling is a pence
A part of a academia is a college
A part of a jail is a
2024-07-26 11:05:23 root INFO     [order_1_approx] starting weight calculation for A part of a seafront is a harbor
A part of a tonne is a kilogram
A part of a brush is a bristle
A part of a radio is a receiver
A part of a academia is a college
A part of a table is a tabletop
A part of a jail is a cell
A part of a shilling is a
2024-07-26 11:05:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 11:08:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0513, -0.0158, -0.1750,  ...,  0.0543,  0.3694, -0.3401],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2402,  1.1309, -1.4482,  ...,  0.2542, -1.1992,  0.1191],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.2347e-01, -3.4760e-02,  5.4398e-03,  ..., -4.0131e-03,
         -5.5847e-03, -1.5915e-02],
        [-1.3657e-02,  3.6411e-03,  1.9112e-03,  ...,  1.9684e-02,
          3.5828e-02, -3.5645e-02],
        [ 2.6184e-02, -3.1036e-02,  2.6947e-02,  ..., -1.2688e-02,
         -1.2314e-02,  2.0203e-02],
        ...,
        [ 3.3340e-03,  5.4626e-02, -9.9182e-05,  ...,  4.1077e-02,
          1.4076e-03, -4.9255e-02],
        [ 4.2450e-02,  4.0314e-02,  1.7700e-02,  ...,  1.5991e-02,
          2.4734e-02, -3.3646e-03],
        [-8.3542e-03, -1.2756e-02, -4.1199e-04,  ...,  2.1267e-04,
          1.5274e-02,  3.4760e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0535,  1.1582, -1.0449,  ...,  1.8408, -0.5825,  0.0941]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 11:08:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a seafront is a harbor
A part of a tonne is a kilogram
A part of a brush is a bristle
A part of a radio is a receiver
A part of a academia is a college
A part of a table is a tabletop
A part of a jail is a cell
A part of a shilling is a
2024-07-26 11:08:11 root INFO     [order_1_approx] starting weight calculation for A part of a tonne is a kilogram
A part of a brush is a bristle
A part of a academia is a college
A part of a jail is a cell
A part of a shilling is a pence
A part of a table is a tabletop
A part of a seafront is a harbor
A part of a radio is a
2024-07-26 11:08:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 11:10:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3223, -0.1863,  0.0175,  ..., -0.1504, -0.1093, -0.0693],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7471, -3.2773,  0.9966,  ...,  3.8477,  0.6318,  1.0146],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0639, -0.0186,  0.0040,  ...,  0.0189,  0.0161,  0.0111],
        [ 0.0011,  0.0116, -0.0163,  ...,  0.0172,  0.0447, -0.0292],
        [ 0.0250,  0.0097,  0.0127,  ..., -0.0059, -0.0396,  0.0198],
        ...,
        [ 0.0240,  0.0468,  0.0139,  ...,  0.0659,  0.0136,  0.0404],
        [-0.0091, -0.0052, -0.0125,  ..., -0.0057, -0.0007, -0.0060],
        [-0.0224,  0.0134,  0.0024,  ...,  0.0092,  0.0068,  0.0221]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8613, -3.0312,  1.2158,  ...,  3.1270,  0.1299,  1.4268]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 11:10:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a tonne is a kilogram
A part of a brush is a bristle
A part of a academia is a college
A part of a jail is a cell
A part of a shilling is a pence
A part of a table is a tabletop
A part of a seafront is a harbor
A part of a radio is a
2024-07-26 11:10:55 root INFO     [order_1_approx] starting weight calculation for A part of a table is a tabletop
A part of a shilling is a pence
A part of a academia is a college
A part of a seafront is a harbor
A part of a radio is a receiver
A part of a jail is a cell
A part of a brush is a bristle
A part of a tonne is a
2024-07-26 11:10:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 11:13:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2384, -0.1260,  0.2224,  ...,  0.0096, -0.1057,  0.3572],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7344, -5.4922,  2.2637,  ..., -2.5547, -0.0322,  0.0959],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1130, -0.0473,  0.0185,  ..., -0.0171,  0.0337,  0.0359],
        [-0.0161,  0.0230, -0.0196,  ...,  0.0033,  0.0319, -0.0382],
        [-0.0239,  0.0158,  0.0519,  ..., -0.0246, -0.0177, -0.0135],
        ...,
        [ 0.0050,  0.0083,  0.0215,  ...,  0.0630,  0.0457,  0.0225],
        [ 0.0356,  0.0107,  0.0427,  ..., -0.0061,  0.0228,  0.0137],
        [-0.0364, -0.0544, -0.0706,  ...,  0.0346,  0.0106, -0.0345]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0703, -5.1641,  2.0996,  ..., -1.5459, -0.1489,  0.7520]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 11:13:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a table is a tabletop
A part of a shilling is a pence
A part of a academia is a college
A part of a seafront is a harbor
A part of a radio is a receiver
A part of a jail is a cell
A part of a brush is a bristle
A part of a tonne is a
2024-07-26 11:13:40 root INFO     [order_1_approx] starting weight calculation for A part of a radio is a receiver
A part of a academia is a college
A part of a table is a tabletop
A part of a shilling is a pence
A part of a brush is a bristle
A part of a tonne is a kilogram
A part of a jail is a cell
A part of a seafront is a
2024-07-26 11:13:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 11:16:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0761, -0.0942, -0.1180,  ...,  0.1489, -0.2703, -0.2957],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4082, -4.2148, -3.2852,  ...,  6.3945, -3.2539, -0.5820],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0562, -0.0179,  0.0283,  ..., -0.0010, -0.0100,  0.0163],
        [-0.0072,  0.0447, -0.0149,  ...,  0.0143, -0.0094, -0.0191],
        [-0.0017, -0.0142,  0.0496,  ..., -0.0202, -0.0037,  0.0303],
        ...,
        [ 0.0215,  0.0082,  0.0034,  ...,  0.0469, -0.0277, -0.0064],
        [-0.0100, -0.0042,  0.0037,  ..., -0.0071,  0.0284, -0.0170],
        [-0.0213, -0.0168, -0.0092,  ...,  0.0040, -0.0135,  0.0384]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4180, -3.8125, -3.4785,  ...,  6.1602, -3.0898, -0.6943]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 11:16:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a radio is a receiver
A part of a academia is a college
A part of a table is a tabletop
A part of a shilling is a pence
A part of a brush is a bristle
A part of a tonne is a kilogram
A part of a jail is a cell
A part of a seafront is a
2024-07-26 11:16:28 root INFO     [order_1_approx] starting weight calculation for A part of a table is a tabletop
A part of a seafront is a harbor
A part of a shilling is a pence
A part of a jail is a cell
A part of a radio is a receiver
A part of a brush is a bristle
A part of a tonne is a kilogram
A part of a academia is a
2024-07-26 11:16:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 11:19:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0701, -0.1333, -0.3115,  ...,  0.2053, -0.2021, -0.0010],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8345, -4.0625,  4.9688,  ...,  0.9570, -1.9551, -1.9746],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.2979e-02,  7.4654e-03, -3.5019e-03,  ..., -1.1826e-03,
          2.2064e-02,  2.1881e-02],
        [ 3.9612e-02,  3.4241e-02,  1.5297e-02,  ...,  1.4778e-02,
          2.9144e-03, -1.7975e-02],
        [-1.9135e-02,  4.1351e-03,  1.3374e-02,  ...,  3.0708e-03,
         -3.5004e-02,  1.5236e-02],
        ...,
        [ 2.6062e-02,  1.0887e-02,  1.3374e-02,  ...,  2.8763e-02,
         -1.8188e-02, -8.0338e-03],
        [-2.7588e-02,  4.9055e-05, -2.6321e-02,  ...,  9.6283e-03,
          9.5062e-03,  1.6235e-02],
        [ 4.5898e-02, -3.2806e-03,  2.6611e-02,  ..., -3.0022e-03,
          1.4160e-02,  2.7100e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.9302, -4.0039,  5.2227,  ...,  0.9375, -1.8447, -1.9482]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 11:19:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a table is a tabletop
A part of a seafront is a harbor
A part of a shilling is a pence
A part of a jail is a cell
A part of a radio is a receiver
A part of a brush is a bristle
A part of a tonne is a kilogram
A part of a academia is a
2024-07-26 11:19:12 root INFO     [order_1_approx] starting weight calculation for A part of a shilling is a pence
A part of a radio is a receiver
A part of a tonne is a kilogram
A part of a brush is a bristle
A part of a seafront is a harbor
A part of a academia is a college
A part of a jail is a cell
A part of a table is a
2024-07-26 11:19:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 11:22:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1022, -0.2876, -0.1038,  ...,  0.0319, -0.1659,  0.0942],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3906, -4.5469,  0.5952,  ..., -0.8066, -1.9404, -0.1294],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0568, -0.0818,  0.0231,  ..., -0.0109,  0.0334,  0.0347],
        [ 0.0432, -0.0278,  0.0188,  ..., -0.0315,  0.0213,  0.0228],
        [ 0.0144,  0.0682, -0.0038,  ..., -0.0271, -0.0686,  0.0369],
        ...,
        [ 0.0199, -0.0222,  0.0222,  ...,  0.0598,  0.0094,  0.0148],
        [-0.0251,  0.0664, -0.0063,  ...,  0.0037,  0.0157, -0.0690],
        [-0.0172, -0.0363,  0.0128,  ..., -0.0319, -0.0079,  0.0244]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8066, -4.3047,  0.5542,  ..., -0.8496, -2.6035,  0.3354]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 11:22:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a shilling is a pence
A part of a radio is a receiver
A part of a tonne is a kilogram
A part of a brush is a bristle
A part of a seafront is a harbor
A part of a academia is a college
A part of a jail is a cell
A part of a table is a
2024-07-26 11:22:03 root INFO     [order_1_approx] starting weight calculation for A part of a shilling is a pence
A part of a tonne is a kilogram
A part of a seafront is a harbor
A part of a table is a tabletop
A part of a academia is a college
A part of a radio is a receiver
A part of a jail is a cell
A part of a brush is a
2024-07-26 11:22:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 11:24:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1117, -0.0182,  0.0574,  ..., -0.0922, -0.0029,  0.0556],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1797, -2.6250, -0.9600,  ...,  1.8760, -2.6016, -0.9717],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0801, -0.0292, -0.0016,  ..., -0.0227, -0.0421,  0.0158],
        [-0.0062, -0.0103,  0.0220,  ..., -0.0233,  0.0032,  0.0130],
        [-0.0174, -0.0117,  0.0241,  ...,  0.0035, -0.0079, -0.0152],
        ...,
        [-0.0124, -0.0161,  0.0076,  ...,  0.0724, -0.0138,  0.0073],
        [-0.0208,  0.0180, -0.0832,  ...,  0.0228,  0.0432, -0.0671],
        [-0.0313,  0.0004,  0.0083,  ..., -0.0037,  0.0249,  0.0446]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.1367, -2.3516, -0.4551,  ...,  2.7871, -2.6289, -0.0747]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 11:24:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a shilling is a pence
A part of a tonne is a kilogram
A part of a seafront is a harbor
A part of a table is a tabletop
A part of a academia is a college
A part of a radio is a receiver
A part of a jail is a cell
A part of a brush is a
2024-07-26 11:30:08 root INFO     loading model + tokenizer
2024-07-26 11:30:12 root INFO     model + tokenizer loaded
2024-07-26 11:30:12 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on synonyms - exact
2024-07-26 11:30:12 root INFO     building operator synonyms - exact
2024-07-26 11:31:07 root INFO     loading model + tokenizer
2024-07-26 11:31:11 root INFO     model + tokenizer loaded
2024-07-26 11:31:11 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on synonyms - exact
2024-07-26 11:31:11 root INFO     building operator synonyms - exact
2024-07-26 11:31:12 root INFO     [order_1_approx] starting weight calculation for Another word for cloth is fabric
Another word for style is manner
Another word for mend is repair
Another word for lady is madam
Another word for loyal is faithful
Another word for lazy is indolent
Another word for mesh is gauze
Another word for incorrect is
2024-07-26 11:31:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 11:34:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0682,  0.0194, -0.3052,  ...,  0.0247, -0.2876,  0.2539],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7827, -0.1641,  2.7305,  ...,  1.2998, -2.2539, -2.2930],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0386, -0.0571,  0.0560,  ..., -0.0121, -0.0169,  0.0350],
        [-0.0186,  0.0083,  0.0164,  ..., -0.0422,  0.0020,  0.0141],
        [ 0.0028, -0.0264,  0.0361,  ...,  0.0127,  0.0211,  0.0042],
        ...,
        [ 0.0004,  0.0210, -0.0094,  ...,  0.0344,  0.0034,  0.0221],
        [-0.0318, -0.0112,  0.0297,  ...,  0.0305, -0.0056, -0.0731],
        [-0.0134, -0.0060, -0.0077,  ..., -0.0230,  0.0059,  0.0295]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9688, -0.2793,  2.3145,  ...,  1.2920, -2.6055, -2.0664]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 11:34:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for cloth is fabric
Another word for style is manner
Another word for mend is repair
Another word for lady is madam
Another word for loyal is faithful
Another word for lazy is indolent
Another word for mesh is gauze
Another word for incorrect is
2024-07-26 11:34:02 root INFO     [order_1_approx] starting weight calculation for Another word for cloth is fabric
Another word for loyal is faithful
Another word for incorrect is wrong
Another word for lady is madam
Another word for lazy is indolent
Another word for mesh is gauze
Another word for style is manner
Another word for mend is
2024-07-26 11:34:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 11:36:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2130,  0.3667, -0.1713,  ..., -0.0907, -0.4351,  0.2314],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0742, -6.6875,  1.0898,  ...,  3.7617, -5.6680,  0.2715],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.3056e-02, -5.2643e-02,  4.2786e-02,  ..., -5.8670e-03,
         -1.1078e-02, -2.8931e-02],
        [ 1.2726e-02,  5.1941e-02,  3.1013e-03,  ..., -1.9188e-03,
          1.1139e-02,  2.1957e-02],
        [-3.0518e-05, -4.1962e-02,  3.7384e-02,  ..., -1.7303e-02,
         -1.6876e-02, -2.3804e-03],
        ...,
        [ 4.4922e-02,  3.5309e-02,  3.3356e-02,  ...,  5.9082e-02,
          1.1978e-02, -2.0920e-02],
        [ 1.9165e-02,  8.0261e-03, -1.5274e-02,  ...,  4.6158e-03,
          2.9251e-02, -2.3132e-02],
        [ 3.4851e-02, -1.6861e-02, -2.5528e-02,  ...,  8.3008e-03,
         -1.3489e-02,  3.9368e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.1250, -5.7578,  1.2783,  ...,  3.2812, -5.5820,  0.0487]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 11:36:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for cloth is fabric
Another word for loyal is faithful
Another word for incorrect is wrong
Another word for lady is madam
Another word for lazy is indolent
Another word for mesh is gauze
Another word for style is manner
Another word for mend is
2024-07-26 11:36:50 root INFO     [order_1_approx] starting weight calculation for Another word for lazy is indolent
Another word for cloth is fabric
Another word for mend is repair
Another word for lady is madam
Another word for mesh is gauze
Another word for style is manner
Another word for incorrect is wrong
Another word for loyal is
2024-07-26 11:36:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 11:39:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0531,  0.1118, -0.0840,  ..., -0.2739,  0.1066,  0.2568],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9180, -4.4180,  0.0098,  ..., -1.4219, -6.8828, -1.2178],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0375, -0.0001,  0.0099,  ..., -0.0133,  0.0016, -0.0013],
        [-0.0079,  0.0632, -0.0016,  ..., -0.0583,  0.0184, -0.0199],
        [-0.0027, -0.0349,  0.0479,  ...,  0.0262, -0.0137, -0.0109],
        ...,
        [-0.0045,  0.0266,  0.0097,  ..., -0.0032,  0.0092,  0.0016],
        [ 0.0073, -0.0062,  0.0062,  ..., -0.0379,  0.0213, -0.0069],
        [-0.0168, -0.0005, -0.0158,  ..., -0.0129, -0.0189,  0.0457]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6514, -3.6562, -0.4622,  ..., -1.1211, -7.1719, -1.2041]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 11:39:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for lazy is indolent
Another word for cloth is fabric
Another word for mend is repair
Another word for lady is madam
Another word for mesh is gauze
Another word for style is manner
Another word for incorrect is wrong
Another word for loyal is
2024-07-26 11:39:38 root INFO     [order_1_approx] starting weight calculation for Another word for mend is repair
Another word for incorrect is wrong
Another word for cloth is fabric
Another word for style is manner
Another word for loyal is faithful
Another word for mesh is gauze
Another word for lady is madam
Another word for lazy is
2024-07-26 11:39:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 11:42:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3066, -0.0720, -0.0422,  ..., -0.1982, -0.0903,  0.2385],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4082, -2.6289,  0.9199,  ..., -2.5547, -3.5488, -2.5781],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0454,  0.0085, -0.0046,  ..., -0.0336,  0.0362,  0.0003],
        [ 0.0172,  0.0083, -0.0118,  ..., -0.0474, -0.0162,  0.0331],
        [-0.0063, -0.0105,  0.0539,  ...,  0.0677,  0.0015,  0.0107],
        ...,
        [-0.0134,  0.0096,  0.0165,  ...,  0.0318, -0.0260,  0.0064],
        [ 0.0328,  0.0340,  0.0248,  ...,  0.0425,  0.0164, -0.0309],
        [ 0.0404, -0.0138,  0.0035,  ...,  0.0171, -0.0003,  0.0317]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3496, -1.8750,  0.1821,  ..., -1.8184, -3.8047, -2.3945]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 11:42:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for mend is repair
Another word for incorrect is wrong
Another word for cloth is fabric
Another word for style is manner
Another word for loyal is faithful
Another word for mesh is gauze
Another word for lady is madam
Another word for lazy is
2024-07-26 11:42:27 root INFO     [order_1_approx] starting weight calculation for Another word for mesh is gauze
Another word for lazy is indolent
Another word for lady is madam
Another word for style is manner
Another word for loyal is faithful
Another word for mend is repair
Another word for incorrect is wrong
Another word for cloth is
2024-07-26 11:42:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 11:45:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1155, -0.0648, -0.1396,  ...,  0.1982, -0.1567,  0.2039],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7617, -3.6797,  1.6895,  ..., -0.5049, -2.8516,  0.9814],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0423, -0.0091,  0.0131,  ..., -0.0225,  0.0081,  0.0158],
        [ 0.0208,  0.0258,  0.0100,  ..., -0.0146,  0.0038, -0.0242],
        [-0.0149, -0.0043,  0.0333,  ..., -0.0192, -0.0034, -0.0208],
        ...,
        [ 0.0204,  0.0160,  0.0222,  ...,  0.0352, -0.0314, -0.0111],
        [-0.0285,  0.0025, -0.0105,  ...,  0.0358,  0.0314,  0.0017],
        [-0.0071,  0.0216,  0.0049,  ..., -0.0165,  0.0040,  0.0309]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5078, -3.4004,  1.2344,  ..., -0.3433, -2.8730,  1.3086]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 11:45:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for mesh is gauze
Another word for lazy is indolent
Another word for lady is madam
Another word for style is manner
Another word for loyal is faithful
Another word for mend is repair
Another word for incorrect is wrong
Another word for cloth is
2024-07-26 11:45:15 root INFO     [order_1_approx] starting weight calculation for Another word for mend is repair
Another word for lady is madam
Another word for loyal is faithful
Another word for incorrect is wrong
Another word for lazy is indolent
Another word for cloth is fabric
Another word for mesh is gauze
Another word for style is
2024-07-26 11:45:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 11:48:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1561, -0.2168, -0.0894,  ...,  0.0809,  0.0455,  0.2485],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7061, -1.9023,  0.0559,  ...,  2.9141, -5.8125, -1.6797],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0720,  0.0033,  0.0105,  ..., -0.0107,  0.0290, -0.0381],
        [ 0.0010,  0.0406,  0.0083,  ...,  0.0071,  0.0218, -0.0080],
        [ 0.0051, -0.0099,  0.0641,  ..., -0.0008,  0.0171, -0.0113],
        ...,
        [-0.0097, -0.0060,  0.0160,  ...,  0.0413, -0.0349, -0.0313],
        [ 0.0058, -0.0257,  0.0059,  ...,  0.0112,  0.0761,  0.0305],
        [ 0.0009,  0.0569, -0.0250,  ..., -0.0153, -0.0048,  0.0204]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0107, -1.2109,  0.5654,  ...,  3.2109, -6.3242, -1.8242]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 11:48:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for mend is repair
Another word for lady is madam
Another word for loyal is faithful
Another word for incorrect is wrong
Another word for lazy is indolent
Another word for cloth is fabric
Another word for mesh is gauze
Another word for style is
2024-07-26 11:48:03 root INFO     [order_1_approx] starting weight calculation for Another word for cloth is fabric
Another word for mend is repair
Another word for lazy is indolent
Another word for style is manner
Another word for incorrect is wrong
Another word for loyal is faithful
Another word for lady is madam
Another word for mesh is
2024-07-26 11:48:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 11:50:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2556, -0.0560,  0.0323,  ...,  0.2339, -0.1759,  0.1445],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8125, -2.0508,  1.6621,  ...,  0.5181, -3.1914,  1.5273],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0690,  0.0193, -0.0077,  ..., -0.0224,  0.0173, -0.0124],
        [-0.0119,  0.0320,  0.0149,  ..., -0.0119, -0.0065, -0.0126],
        [ 0.0435, -0.0147,  0.0579,  ..., -0.0231,  0.0037, -0.0446],
        ...,
        [-0.0072, -0.0019,  0.0361,  ...,  0.0726, -0.0370, -0.0051],
        [-0.0206, -0.0381, -0.0366,  ...,  0.0219,  0.0376, -0.0222],
        [-0.0489,  0.0192, -0.0191,  ...,  0.0012,  0.0023,  0.0708]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1670, -2.3008,  1.2324,  ...,  0.6436, -3.1523,  1.6230]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 11:50:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for cloth is fabric
Another word for mend is repair
Another word for lazy is indolent
Another word for style is manner
Another word for incorrect is wrong
Another word for loyal is faithful
Another word for lady is madam
Another word for mesh is
2024-07-26 11:50:52 root INFO     [order_1_approx] starting weight calculation for Another word for lazy is indolent
Another word for mend is repair
Another word for loyal is faithful
Another word for mesh is gauze
Another word for incorrect is wrong
Another word for cloth is fabric
Another word for style is manner
Another word for lady is
2024-07-26 11:50:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
is referred to as a larva
The offspring of a rabbit is referred to as a bunny
The offspring of a seal is referred to as a pup
The offspring of a goat is referred to as a
2024-07-26 11:48:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 11:48:56 root INFO     loading model + tokenizer
2024-07-26 11:48:59 root INFO     model + tokenizer loaded
2024-07-26 11:48:59 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - youth
2024-07-26 11:48:59 root INFO     building operator animal - youth
2024-07-26 11:49:00 root INFO     [order_1_approx] starting weight calculation for The offspring of a cat is referred to as a kitten
The offspring of a beaver is referred to as a kit
The offspring of a cockroach is referred to as a nymph
The offspring of a insect is referred to as a larva
The offspring of a buffalo is referred to as a calf
The offspring of a fox is referred to as a cub
The offspring of a woodchuck is referred to as a kit
The offspring of a whale is referred to as a
2024-07-26 11:49:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 11:49:44 root INFO     loading model + tokenizer
2024-07-26 11:49:47 root INFO     model + tokenizer loaded
2024-07-26 11:49:48 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+ment_irreg
2024-07-26 11:49:48 root INFO     building operator verb+ment_irreg
2024-07-26 11:49:48 root INFO     [order_1_approx] starting weight calculation for To reinforce results in a reinforcement
To announce results in a announcement
To reimburse results in a reimbursement
To amuse results in a amusement
To invest results in a investment
To resent results in a resentment
To develop results in a development
To manage results in a
2024-07-26 11:49:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 11:53:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1365,  0.2939, -0.2002,  ..., -0.0907,  0.0706, -0.1221],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6177, -1.2373, -2.0215,  ..., -1.7949, -3.9512, -1.3545],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.8250e-02, -4.0710e-02,  2.4139e-02,  ...,  1.8417e-02,
         -3.5583e-02, -5.9509e-03],
        [ 3.5934e-03,  3.2990e-02,  2.1301e-02,  ..., -2.8107e-02,
          7.4158e-02,  3.4302e-02],
        [ 1.0277e-02, -3.1342e-02,  1.3138e-02,  ...,  3.3203e-02,
         -2.2247e-02, -1.7181e-02],
        ...,
        [ 3.9978e-03,  5.7526e-03,  2.8687e-03,  ..., -9.5673e-03,
          3.8727e-02, -1.4252e-02],
        [-7.5912e-03,  8.0185e-03,  2.6302e-03,  ...,  7.6408e-03,
          9.9182e-05, -2.7954e-02],
        [-1.3641e-02,  5.3482e-03, -7.3242e-03,  ..., -2.1164e-02,
         -2.5208e-02, -7.7896e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5459, -0.5981, -2.0078,  ..., -1.3691, -4.2617, -1.4189]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 11:53:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for lazy is indolent
Another word for mend is repair
Another word for loyal is faithful
Another word for mesh is gauze
Another word for incorrect is wrong
Another word for cloth is fabric
Another word for style is manner
Another word for lady is
2024-07-26 11:53:39 root INFO     total operator prediction time: 1348.4714620113373 seconds
2024-07-26 11:53:39 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hypernyms - misc
2024-07-26 11:53:39 root INFO     building operator hypernyms - misc
2024-07-26 11:53:40 root INFO     [order_1_approx] starting weight calculation for The mascara falls into the category of makeup
The croissant falls into the category of pastry
The sofa falls into the category of furniture
The dishwasher falls into the category of appliance
The juicer falls into the category of utensil
The plum falls into the category of fruit
The diary falls into the category of journal
The hamburger falls into the category of
2024-07-26 11:53:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
or([-0.0935,  0.4360,  0.0589,  ...,  0.0676, -0.0822, -0.1030],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9727, -3.9766,  2.3184,  ...,  1.3916, -1.0088, -3.4180],
       device='cuda:1', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0367,  0.0078,  0.0019,  ..., -0.0155, -0.0080,  0.0065],
        [-0.0275,  0.0291, -0.0042,  ...,  0.0307,  0.0264,  0.0055],
        [-0.0051, -0.0069,  0.0101,  ...,  0.0324, -0.0095,  0.0126],
        ...,
        [ 0.0059,  0.0041,  0.0131,  ...,  0.0530,  0.0282, -0.0002],
        [-0.0195, -0.0123,  0.0167,  ..., -0.0434,  0.0177, -0.0341],
        [ 0.0209, -0.0095,  0.0100,  ...,  0.0194,  0.0123,  0.0260]],
       device='cuda:1', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1270, -3.5352,  2.4844,  ...,  1.1113, -1.7207, -3.1406]],
       device='cuda:1', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 11:52:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To reinforce results in a reinforcement
To announce results in a announcement
To reimburse results in a reimbursement
To amuse results in a amusement
To invest results in a investment
To resent results in a resentment
To develop results in a development
To manage results in a
2024-07-26 11:52:32 root INFO     [order_1_approx] starting weight calculation for To amuse results in a amusement
To develop results in a development
To invest results in a investment
To resent results in a resentment
To reinforce results in a reinforcement
To announce results in a announcement
To manage results in a management
To reimburse results in a
2024-07-26 11:52:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 11:56:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2512,  0.2063, -0.2109,  ...,  0.1924, -0.2085, -0.1553],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1230, -4.9531,  0.8105,  ..., -2.1523, -3.6523, -1.7617],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0067,  0.0065,  0.0143,  ..., -0.0293, -0.0184, -0.0186],
        [-0.0019,  0.0355,  0.0077,  ...,  0.0035, -0.0051,  0.0141],
        [ 0.0035, -0.0007,  0.0101,  ...,  0.0077,  0.0034, -0.0242],
        ...,
        [ 0.0029,  0.0078,  0.0169,  ...,  0.0388, -0.0020,  0.0054],
        [ 0.0198, -0.0355,  0.0064,  ...,  0.0059,  0.0358, -0.0033],
        [ 0.0222, -0.0251,  0.0143,  ...,  0.0039,  0.0054,  0.0695]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1934, -5.0469,  0.6455,  ..., -2.0293, -3.3359, -1.6494]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 11:56:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The mascara falls into the category of makeup
The croissant falls into the category of pastry
The sofa falls into the category of furniture
The dishwasher falls into the category of appliance
The juicer falls into the category of utensil
The plum falls into the category of fruit
The diary falls into the category of journal
The hamburger falls into the category of
2024-07-26 11:56:25 root INFO     [order_1_approx] starting weight calculation for The plum falls into the category of fruit
The hamburger falls into the category of sandwich
The juicer falls into the category of utensil
The croissant falls into the category of pastry
The diary falls into the category of journal
The dishwasher falls into the category of appliance
The sofa falls into the category of furniture
The mascara falls into the category of
2024-07-26 11:56:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 11:59:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3955, -0.6934, -0.4763,  ...,  0.1033, -0.3018, -0.1962],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1562, -2.2812, -0.0338,  ..., -0.0444, -1.4453,  2.2656],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0364,  0.0050,  0.0039,  ..., -0.0164, -0.0206,  0.0142],
        [-0.0112,  0.0098, -0.0119,  ...,  0.0139,  0.0083,  0.0103],
        [-0.0211,  0.0069,  0.0280,  ..., -0.0172, -0.0332, -0.0035],
        ...,
        [ 0.0217, -0.0077,  0.0226,  ...,  0.0382,  0.0215,  0.0018],
        [-0.0184,  0.0125,  0.0076,  ..., -0.0075,  0.0352, -0.0062],
        [ 0.0188, -0.0006, -0.0021,  ..., -0.0292, -0.0414,  0.0420]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1074, -2.3184,  0.3433,  ..., -0.2101, -1.8359,  2.8086]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 11:59:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plum falls into the category of fruit
The hamburger falls into the category of sandwich
The juicer falls into the category of utensil
The croissant falls into the category of pastry
The diary falls into the category of journal
The dishwasher falls into the category of appliance
The sofa falls into the category of furniture
The mascara falls into the category of
2024-07-26 11:59:10 root INFO     [order_1_approx] starting weight calculation for The plum falls into the category of fruit
The dishwasher falls into the category of appliance
The mascara falls into the category of makeup
The juicer falls into the category of utensil
The sofa falls into the category of furniture
The hamburger falls into the category of sandwich
The croissant falls into the category of pastry
The diary falls into the category of
2024-07-26 11:59:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 12:01:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1111, -0.0503, -0.1144,  ..., -0.0685, -0.2598,  0.1163],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7690, -4.1953,  1.0547,  ..., -3.0859, -2.3281, -0.2817],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0433,  0.0037,  0.0143,  ...,  0.0165,  0.0275,  0.0006],
        [-0.0461,  0.0401,  0.0160,  ..., -0.0128, -0.0140,  0.0299],
        [-0.0025, -0.0298,  0.0090,  ...,  0.0305, -0.0289,  0.0126],
        ...,
        [ 0.0030,  0.0227, -0.0085,  ...,  0.0539,  0.0187,  0.0043],
        [-0.0008, -0.0113,  0.0208,  ...,  0.0170,  0.0488, -0.0110],
        [ 0.0149,  0.0105, -0.0074,  ..., -0.0296, -0.0035,  0.0514]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4585, -4.3594,  0.9536,  ..., -2.7949, -2.0312, -0.4727]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 12:01:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plum falls into the category of fruit
The dishwasher falls into the category of appliance
The mascara falls into the category of makeup
The juicer falls into the category of utensil
The sofa falls into the category of furniture
The hamburger falls into the category of sandwich
The croissant falls into the category of pastry
The diary falls into the category of
2024-07-26 12:01:54 root INFO     [order_1_approx] starting weight calculation for The plum falls into the category of fruit
The mascara falls into the category of makeup
The diary falls into the category of journal
The croissant falls into the category of pastry
The hamburger falls into the category of sandwich
The sofa falls into the category of furniture
The dishwasher falls into the category of appliance
The juicer falls into the category of
2024-07-26 12:01:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 12:04:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0442, -0.2383, -0.0939,  ..., -0.0458, -0.2137, -0.2247],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7617, -4.7109, -0.1272,  ..., -2.3086, -1.8594,  0.4990],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0184, -0.0043, -0.0097,  ...,  0.0088, -0.0018,  0.0147],
        [-0.0080,  0.0321,  0.0082,  ...,  0.0023, -0.0121, -0.0270],
        [-0.0021, -0.0011,  0.0094,  ..., -0.0044, -0.0172,  0.0063],
        ...,
        [ 0.0045,  0.0035,  0.0046,  ...,  0.0200, -0.0148,  0.0100],
        [-0.0067, -0.0006, -0.0023,  ...,  0.0142,  0.0249, -0.0263],
        [-0.0087,  0.0030,  0.0047,  ..., -0.0026, -0.0054, -0.0013]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8887, -4.7031,  0.1216,  ..., -2.3984, -1.8135,  0.5703]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 12:04:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plum falls into the category of fruit
The mascara falls into the category of makeup
The diary falls into the category of journal
The croissant falls into the category of pastry
The hamburger falls into the category of sandwich
The sofa falls into the category of furniture
The dishwasher falls into the category of appliance
The juicer falls into the category of
2024-07-26 12:04:39 root INFO     [order_1_approx] starting weight calculation for The hamburger falls into the category of sandwich
The diary falls into the category of journal
The sofa falls into the category of furniture
The mascara falls into the category of makeup
The dishwasher falls into the category of appliance
The croissant falls into the category of pastry
The juicer falls into the category of utensil
The plum falls into the category of
2024-07-26 12:04:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            2024-07-26 12:07:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1088, -0.2666, -0.4644,  ...,  0.1462, -0.0877, -0.3252],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8579, -5.9570,  1.4033,  ..., -2.1250, -0.4355, -1.3086],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0599,  0.0173, -0.0216,  ...,  0.0327, -0.0060,  0.0045],
        [-0.0094, -0.0176,  0.0468,  ..., -0.0331, -0.0598,  0.0066],
        [-0.0375,  0.0079,  0.0010,  ...,  0.0393, -0.0213,  0.0106],
        ...,
        [ 0.0130,  0.0350,  0.0148,  ...,  0.0460, -0.0317,  0.0026],
        [ 0.0087, -0.0269, -0.0107,  ...,  0.0280,  0.0753, -0.0195],
        [ 0.0015, -0.0230,  0.0519,  ..., -0.0610, -0.0537,  0.0109]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7759, -5.7422,  1.7119,  ..., -2.5430, -0.3713, -0.6309]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 12:07:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The hamburger falls into the category of sandwich
The diary falls into the category of journal
The sofa falls into the category of furniture
The mascara falls into the category of makeup
The dishwasher falls into the category of appliance
The croissant falls into the category of pastry
The juicer falls into the category of utensil
The plum falls into the category of
2024-07-26 12:07:26 root INFO     [order_1_approx] starting weight calculation for The mascara falls into the category of makeup
The diary falls into the category of journal
The plum falls into the category of fruit
The hamburger falls into the category of sandwich
The croissant falls into the category of pastry
The dishwasher falls into the category of appliance
The juicer falls into the category of utensil
The sofa falls into the category of
2024-07-26 12:07:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 12:10:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0340, -0.2050, -0.0451,  ...,  0.1635, -0.1189, -0.0635],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8320, -6.0938,  2.6348,  ..., -1.4297, -2.8516,  0.8223],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0475, -0.0364, -0.0102,  ...,  0.0090,  0.0149,  0.0050],
        [-0.0118,  0.0139,  0.0206,  ..., -0.0049, -0.0213,  0.0118],
        [-0.0149,  0.0131,  0.0163,  ..., -0.0130, -0.0243,  0.0048],
        ...,
        [ 0.0042,  0.0222,  0.0051,  ...,  0.0471,  0.0058, -0.0297],
        [-0.0102,  0.0197, -0.0021,  ...,  0.0089,  0.0423, -0.0334],
        [ 0.0181, -0.0416,  0.0275,  ..., -0.0427,  0.0127,  0.0269]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2505, -6.1211,  2.8340,  ..., -1.5957, -2.1758,  1.1846]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 12:10:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The mascara falls into the category of makeup
The diary falls into the category of journal
The plum falls into the category of fruit
The hamburger falls into the category of sandwich
The croissant falls into the category of pastry
The dishwasher falls into the category of appliance
The juicer falls into the category of utensil
The sofa falls into the category of
2024-07-26 12:10:14 root INFO     [order_1_approx] starting weight calculation for The plum falls into the category of fruit
The juicer falls into the category of utensil
The sofa falls into the category of furniture
The hamburger falls into the category of sandwich
The mascara falls into the category of makeup
The diary falls into the category of journal
The dishwasher falls into the category of appliance
The croissant falls into the category of
2024-07-26 12:10:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
          2024-07-26 12:12:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0698, -0.1606, -0.3804,  ...,  0.1250, -0.2563, -0.0292],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9844, -5.5430, -1.0781,  ..., -1.5361, -3.1699,  1.4209],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0646,  0.0085, -0.0274,  ..., -0.0227, -0.0313,  0.0047],
        [ 0.0178,  0.0432,  0.0008,  ..., -0.0347,  0.0322,  0.0123],
        [ 0.0032, -0.0489,  0.0199,  ...,  0.0024, -0.0076,  0.0022],
        ...,
        [ 0.0041,  0.0230, -0.0034,  ...,  0.0785, -0.0146, -0.0139],
        [-0.0112, -0.0015,  0.0064,  ...,  0.0121,  0.0667, -0.0066],
        [ 0.0100,  0.0318,  0.0005,  ..., -0.0135,  0.0267,  0.0750]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2871, -6.0156, -0.8184,  ..., -1.6143, -2.4531,  1.3291]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 12:13:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plum falls into the category of fruit
The juicer falls into the category of utensil
The sofa falls into the category of furniture
The hamburger falls into the category of sandwich
The mascara falls into the category of makeup
The diary falls into the category of journal
The dishwasher falls into the category of appliance
The croissant falls into the category of
2024-07-26 12:13:00 root INFO     [order_1_approx] starting weight calculation for The diary falls into the category of journal
The juicer falls into the category of utensil
The hamburger falls into the category of sandwich
The sofa falls into the category of furniture
The croissant falls into the category of pastry
The plum falls into the category of fruit
The mascara falls into the category of makeup
The dishwasher falls into the category of
2024-07-26 12:13:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
                                                                                                     2024-07-26 12:15:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1221,  0.0378, -0.3894,  ...,  0.1678, -0.2920, -0.1787],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9199, -3.6504,  2.0488,  ..., -1.1094, -3.7441,  1.8965],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0178,  0.0017, -0.0002,  ...,  0.0128,  0.0022,  0.0071],
        [ 0.0095, -0.0028,  0.0089,  ...,  0.0019, -0.0108,  0.0098],
        [ 0.0030, -0.0024, -0.0040,  ..., -0.0112, -0.0147,  0.0128],
        ...,
        [ 0.0017,  0.0028,  0.0118,  ...,  0.0120, -0.0019,  0.0058],
        [-0.0012, -0.0015, -0.0058,  ...,  0.0031,  0.0125, -0.0124],
        [ 0.0051, -0.0047,  0.0069,  ..., -0.0114, -0.0063,  0.0087]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9165, -3.3867,  2.0137,  ..., -1.1445, -3.6152,  2.0723]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 12:15:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The diary falls into the category of journal
The juicer falls into the category of utensil
The hamburger falls into the category of sandwich
The sofa falls into the category of furniture
The croissant falls into the category of pastry
The plum falls into the category of fruit
The mascara falls into the category of makeup
The dishwasher falls into the category of
2024-07-26 12:15:46 root INFO     total operator prediction time: 1326.9287102222443 seconds
2024-07-26 12:15:46 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - substance
2024-07-26 12:15:46 root INFO     building operator meronyms - substance
2024-07-26 12:15:47 root INFO     [order_1_approx] starting weight calculation for A body is made up of flesh
A wig is made up of hair
A snow is made up of water
A diamond is made up of carbon
A steel is made up of iron
A mirror is made up of glass
A glass is made up of silicone
A wine is made up of
2024-07-26 12:15:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 12:18:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0808,  0.2423, -0.1699,  ..., -0.1050,  0.1152, -0.1284],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3184, -5.4023,  0.4685,  ..., -3.4258,  0.5488, -4.0781],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0519, -0.0008,  0.0201,  ..., -0.0111,  0.0118, -0.0005],
        [-0.0156,  0.0720,  0.0100,  ..., -0.0101,  0.0106,  0.0053],
        [-0.0218, -0.0345,  0.0116,  ..., -0.0071,  0.0147,  0.0251],
        ...,
        [ 0.0136, -0.0003,  0.0054,  ...,  0.0520,  0.0052, -0.0086],
        [ 0.0455,  0.0084, -0.0740,  ...,  0.0097, -0.0020,  0.0307],
        [ 0.0096,  0.0172,  0.0302,  ..., -0.0262,  0.0219,  0.0432]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4492, -5.7891,  0.1411,  ..., -3.8516,  0.6001, -4.1523]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 12:18:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A body is made up of flesh
A wig is made up of hair
A snow is made up of water
A diamond is made up of carbon
A steel is made up of iron
A mirror is made up of glass
A glass is made up of silicone
A wine is made up of
2024-07-26 12:18:36 root INFO     [order_1_approx] starting weight calculation for A diamond is made up of carbon
A steel is made up of iron
A wine is made up of grapes
A glass is made up of silicone
A wig is made up of hair
A body is made up of flesh
A mirror is made up of glass
A snow is made up of
2024-07-26 12:18:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
t error is
2024-07-26 12:17:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 12:17:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1267,  0.0739,  0.1475,  ...,  0.1453, -0.1486,  0.0317],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2207, -6.6172, -1.1035,  ...,  0.3916, -2.3477,  2.7305],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0198, -0.0334,  0.0029,  ...,  0.0274, -0.0202,  0.0062],
        [-0.0083,  0.0082,  0.0194,  ..., -0.0418,  0.0024, -0.0029],
        [ 0.0077,  0.0148,  0.0269,  ..., -0.0254,  0.0098, -0.0302],
        ...,
        [ 0.0010,  0.0059,  0.0025,  ...,  0.0281,  0.0138, -0.0133],
        [ 0.0182,  0.0058,  0.0005,  ...,  0.0182,  0.0293, -0.0103],
        [ 0.0113, -0.0257,  0.0005,  ...,  0.0224, -0.0080,  0.0300]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3711, -6.1914, -0.7500,  ...,  0.6797, -2.4824,  2.4082]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 12:17:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a rabbit is referred to as a bunny
The offspring of a gorilla is referred to as a infant
The offspring of a goat is referred to as a kid
The offspring of a bear is referred to as a cub
The offspring of a beetle is referred to as a larva
The offspring of a seal is referred to as a pup
The offspring of a monkey is referred to as a infant
The offspring of a dog is referred to as a
2024-07-26 12:17:49 root INFO     [order_1_approx] starting weight calculation for The offspring of a seal is referred to as a pup
The offspring of a beetle is referred to as a larva
The offspring of a goat is referred to as a kid
The offspring of a monkey is referred to as a infant
The offspring of a dog is referred to as a puppy
The offspring of a bear is referred to as a cub
The offspring of a rabbit is referred to as a bunny
The offspring of a gorilla is referred to as a
2024-07-26 12:17:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 12:21:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3811,  0.3193, -0.1392,  ..., -0.1965,  0.0436,  0.0360],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9775, -3.0527,  0.1201,  ..., -5.3984,  1.0908, -0.6787],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0288, -0.0368, -0.0131,  ...,  0.0012,  0.0049, -0.0343],
        [-0.0077,  0.0088,  0.0018,  ...,  0.0147,  0.0046, -0.0100],
        [ 0.0081, -0.0222,  0.0160,  ...,  0.0236,  0.0048,  0.0292],
        ...,
        [ 0.0203,  0.0130, -0.0030,  ...,  0.0337, -0.0058, -0.0224],
        [ 0.0172,  0.0117, -0.0192,  ...,  0.0366, -0.0012, -0.0066],
        [-0.0113, -0.0124, -0.0173,  ..., -0.0108, -0.0017, -0.0186]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3818, -3.2441,  0.0854,  ..., -5.3438,  0.8174, -0.3098]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 12:21:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A diamond is made up of carbon
A steel is made up of iron
A wine is made up of grapes
A glass is made up of silicone
A wig is made up of hair
A body is made up of flesh
A mirror is made up of glass
A snow is made up of
2024-07-26 12:21:23 root INFO     [order_1_approx] starting weight calculation for A steel is made up of iron
A wine is made up of grapes
A snow is made up of water
A body is made up of flesh
A mirror is made up of glass
A diamond is made up of carbon
A glass is made up of silicone
A wig is made up of
2024-07-26 12:21:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
 home is
2024-07-26 12:20:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 12:24:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1489,  0.1326, -0.0865,  ...,  0.0743,  0.0635, -0.0240],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2051, -6.9883, -2.0840,  ..., -1.2910, -1.8057, -0.2979],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0337, -0.0399, -0.0190,  ...,  0.0299, -0.0047,  0.0222],
        [-0.0362,  0.0486, -0.0189,  ..., -0.0115,  0.0057, -0.0220],
        [-0.0147, -0.0052,  0.0311,  ...,  0.0209, -0.0044, -0.0234],
        ...,
        [ 0.0308, -0.0004,  0.0087,  ...,  0.0232, -0.0150, -0.0157],
        [-0.0036,  0.0114, -0.0183,  ...,  0.0202,  0.0247, -0.0331],
        [ 0.0132, -0.0351,  0.0273,  ...,  0.0021,  0.0229,  0.0540]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4111, -6.5508, -2.0156,  ..., -1.1133, -1.4102, -0.3579]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 12:24:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A steel is made up of iron
A wine is made up of grapes
A snow is made up of water
A body is made up of flesh
A mirror is made up of glass
A diamond is made up of carbon
A glass is made up of silicone
A wig is made up of
2024-07-26 12:24:09 root INFO     [order_1_approx] starting weight calculation for A mirror is made up of glass
A steel is made up of iron
A snow is made up of water
A diamond is made up of carbon
A wine is made up of grapes
A wig is made up of hair
A glass is made up of silicone
A body is made up of
2024-07-26 12:24:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
child is
2024-07-26 12:22:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 12:26:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1915,  0.1335, -0.0549,  ..., -0.1738, -0.0552, -0.2235],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5273, -6.1602,  2.4648,  ..., -3.8203, -3.4395,  1.1777],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0055, -0.0023,  0.0022,  ...,  0.0278,  0.0340, -0.0046],
        [-0.0133,  0.0238,  0.0097,  ..., -0.0242, -0.0220,  0.0114],
        [ 0.0016, -0.0006, -0.0078,  ..., -0.0111, -0.0050, -0.0163],
        ...,
        [-0.0056,  0.0047,  0.0168,  ...,  0.0264,  0.0175, -0.0162],
        [ 0.0054, -0.0032,  0.0110,  ..., -0.0282,  0.0043,  0.0061],
        [ 0.0141, -0.0092,  0.0066,  ..., -0.0121, -0.0035,  0.0143]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1797, -5.8594,  2.6680,  ..., -3.6211, -3.1953,  1.8193]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 12:26:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A mirror is made up of glass
A steel is made up of iron
A snow is made up of water
A diamond is made up of carbon
A wine is made up of grapes
A wig is made up of hair
A glass is made up of silicone
A body is made up of
2024-07-26 12:26:57 root INFO     [order_1_approx] starting weight calculation for A wine is made up of grapes
A wig is made up of hair
A snow is made up of water
A body is made up of flesh
A glass is made up of silicone
A mirror is made up of glass
A diamond is made up of carbon
A steel is made up of
2024-07-26 12:26:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
hing without error is errorless
Something without law is lawless
Something without odor is odorless
Something without child is childless
Something without home is homeless
Something without penny is
2024-07-26 12:25:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 12:29:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0454,  0.0276, -0.3291,  ..., -0.0140,  0.2284,  0.1304],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1641, -5.4883,  0.9688,  ..., -5.6953, -1.5039, -2.0332],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.2858e-02, -4.2511e-02, -4.7073e-03,  ...,  1.7700e-02,
         -3.2867e-02, -4.4006e-02],
        [-6.6719e-03,  3.6682e-02, -1.2764e-02,  ..., -1.5869e-02,
          1.4938e-02,  1.0590e-02],
        [ 1.6113e-02,  2.5269e-02,  2.0142e-02,  ...,  2.7557e-02,
          2.4292e-02,  5.1003e-03],
        ...,
        [ 2.4689e-02, -3.0731e-02,  3.1860e-02,  ..., -7.6294e-06,
          1.0674e-02, -1.7059e-02],
        [-3.2837e-02,  2.1027e-02, -4.8340e-02,  ...,  5.1575e-02,
          2.2675e-02, -1.1322e-02],
        [ 1.5656e-02,  9.4986e-04, -2.0737e-02,  ..., -4.9866e-02,
         -6.4392e-03,  2.7237e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7383, -5.5742,  0.5728,  ..., -4.4883, -2.5078, -1.9385]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 12:29:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A wine is made up of grapes
A wig is made up of hair
A snow is made up of water
A body is made up of flesh
A glass is made up of silicone
A mirror is made up of glass
A diamond is made up of carbon
A steel is made up of
2024-07-26 12:29:45 root INFO     [order_1_approx] starting weight calculation for A wig is made up of hair
A glass is made up of silicone
A snow is made up of water
A body is made up of flesh
A diamond is made up of carbon
A steel is made up of iron
A wine is made up of grapes
A mirror is made up of
2024-07-26 12:29:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 12:32:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1152,  0.0271, -0.1582,  ...,  0.0477, -0.0864, -0.1271],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3047, -4.1992, -0.4612,  ..., -2.6523, -2.6230,  0.9492],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0218, -0.0248,  0.0065,  ...,  0.0195,  0.0009, -0.0212],
        [-0.0044,  0.0651,  0.0015,  ...,  0.0245, -0.0081,  0.0005],
        [ 0.0216, -0.0095,  0.0362,  ...,  0.0222, -0.0320, -0.0046],
        ...,
        [ 0.0280,  0.0330, -0.0050,  ...,  0.0224, -0.0252, -0.0066],
        [-0.0325, -0.0053, -0.0490,  ..., -0.0121,  0.0158, -0.0414],
        [ 0.0111,  0.0037, -0.0011,  ..., -0.0030,  0.0140,  0.0495]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5098, -4.4336, -0.6147,  ..., -2.6504, -3.5996,  1.3730]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 12:32:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A wig is made up of hair
A glass is made up of silicone
A snow is made up of water
A body is made up of flesh
A diamond is made up of carbon
A steel is made up of iron
A wine is made up of grapes
A mirror is made up of
2024-07-26 12:32:34 root INFO     [order_1_approx] starting weight calculation for A body is made up of flesh
A snow is made up of water
A steel is made up of iron
A glass is made up of silicone
A wig is made up of hair
A wine is made up of grapes
A mirror is made up of glass
A diamond is made up of
2024-07-26 12:32:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
thout law is
2024-07-26 12:30:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 12:31:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0515, -0.2253, -0.1637,  ..., -0.2986, -0.2600,  0.0728],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2490, -4.2656, -0.8228,  ...,  1.1719, -3.1172,  1.8809],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0343, -0.0075, -0.0106,  ..., -0.0023, -0.0067,  0.0083],
        [-0.0107,  0.0038,  0.0076,  ..., -0.0018, -0.0104,  0.0041],
        [ 0.0032, -0.0010,  0.0297,  ..., -0.0020,  0.0024, -0.0160],
        ...,
        [-0.0065,  0.0226, -0.0018,  ...,  0.0105, -0.0064, -0.0008],
        [ 0.0182, -0.0110,  0.0141,  ...,  0.0177,  0.0302,  0.0359],
        [-0.0064, -0.0021, -0.0082,  ...,  0.0048, -0.0117,  0.0190]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3838, -4.1055, -0.5386,  ...,  1.2676, -2.9297,  1.6543]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 12:31:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a seal is referred to as a pup
The offspring of a beetle is referred to as a larva
The offspring of a goat is referred to as a kid
The offspring of a monkey is referred to as a infant
The offspring of a dog is referred to as a puppy
The offspring of a bear is referred to as a cub
The offspring of a rabbit is referred to as a bunny
The offspring of a gorilla is referred to as a
2024-07-26 12:31:11 root INFO     [order_1_approx] starting weight calculation for The offspring of a monkey is referred to as a infant
The offspring of a dog is referred to as a puppy
The offspring of a goat is referred to as a kid
The offspring of a beetle is referred to as a larva
The offspring of a bear is referred to as a cub
The offspring of a gorilla is referred to as a infant
The offspring of a seal is referred to as a pup
The offspring of a rabbit is referred to as a
2024-07-26 12:31:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 12:35:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1440,  0.0098, -0.3733,  ..., -0.1334,  0.1495,  0.0702],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4336, -3.3164,  0.4543,  ..., -6.7812,  2.4961, -1.1055],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0184, -0.0180, -0.0078,  ..., -0.0011,  0.0026, -0.0052],
        [ 0.0072,  0.0179,  0.0082,  ...,  0.0030,  0.0111,  0.0302],
        [ 0.0059,  0.0014,  0.0125,  ..., -0.0098,  0.0042,  0.0027],
        ...,
        [ 0.0214,  0.0163,  0.0004,  ..., -0.0002, -0.0083, -0.0129],
        [-0.0051,  0.0090, -0.0193,  ...,  0.0120,  0.0057, -0.0039],
        [ 0.0089,  0.0079, -0.0031,  ..., -0.0188, -0.0123,  0.0075]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8555, -3.4648, -0.1306,  ..., -6.6875,  1.6680, -0.7188]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 12:35:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A body is made up of flesh
A snow is made up of water
A steel is made up of iron
A glass is made up of silicone
A wig is made up of hair
A wine is made up of grapes
A mirror is made up of glass
A diamond is made up of
2024-07-26 12:35:24 root INFO     [order_1_approx] starting weight calculation for A mirror is made up of glass
A steel is made up of iron
A snow is made up of water
A body is made up of flesh
A wig is made up of hair
A wine is made up of grapes
A diamond is made up of carbon
A glass is made up of
2024-07-26 12:35:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
lculation for The state of being marked is markedness
The state of being righteous is righteousness
The state of being devoted is devotedness
The state of being random is randomness
The state of being pure is pureness
The state of being same is sameness
The state of being sacred is sacredness
The state of being competitive is
2024-07-26 12:33:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 12:38:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1499, -0.2050, -0.1466,  ...,  0.1763, -0.1412, -0.3794],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.7344, -5.1172,  0.3098,  ..., -4.2734,  1.5195, -1.4609],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0150, -0.0167,  0.0054,  ...,  0.0098, -0.0505, -0.0263],
        [ 0.0232,  0.0584, -0.0148,  ..., -0.0132,  0.0244,  0.0194],
        [ 0.0158,  0.0008,  0.0253,  ...,  0.0123, -0.0142,  0.0087],
        ...,
        [ 0.0269, -0.0182, -0.0030,  ...,  0.0093, -0.0110, -0.0131],
        [-0.0483,  0.0127,  0.0043,  ...,  0.0100, -0.0097, -0.0231],
        [-0.0015,  0.0136, -0.0098,  ..., -0.0195,  0.0108,  0.0310]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.8281, -5.5469,  0.4055,  ..., -4.0781,  1.3398, -1.3643]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 12:38:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A mirror is made up of glass
A steel is made up of iron
A snow is made up of water
A body is made up of flesh
A wig is made up of hair
A wine is made up of grapes
A diamond is made up of carbon
A glass is made up of
2024-07-26 12:38:11 root INFO     total operator prediction time: 1344.5038249492645 seconds
2024-07-26 12:38:11 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on synonyms - intensity
2024-07-26 12:38:11 root INFO     building operator synonyms - intensity
2024-07-26 12:38:11 root INFO     [order_1_approx] starting weight calculation for A more intense word for pony is horse
A more intense word for interesting is exciting
A more intense word for nap is sleep
A more intense word for love is adore
A more intense word for sad is desparate
A more intense word for cry is scream
A more intense word for pain is torment
A more intense word for want is
2024-07-26 12:38:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 12:40:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1326, -0.1750,  0.0431,  ..., -0.0119, -0.1008,  0.3115],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1523, -4.5234, -0.4707,  ..., -2.3672, -6.6602, -3.4766],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 9.7656e-04, -4.5532e-02, -2.3773e-02,  ...,  3.1311e-02,
         -1.1139e-03, -4.1389e-03],
        [-6.3858e-03,  2.7405e-02,  8.3923e-05,  ...,  2.8915e-03,
         -5.4901e-02,  2.1942e-02],
        [-9.2163e-03, -2.4292e-02, -3.0396e-02,  ...,  2.6794e-02,
         -2.9953e-02, -1.8959e-03],
        ...,
        [ 2.5955e-02, -9.5901e-03,  5.3375e-02,  ...,  4.2023e-02,
         -6.5536e-03, -3.1219e-02],
        [ 5.3070e-02, -3.3081e-02,  2.0905e-02,  ...,  2.9984e-02,
          4.1008e-04,  6.1569e-03],
        [-1.3504e-02, -8.0032e-03, -8.7891e-03,  ...,  8.7662e-03,
         -1.2482e-02,  3.6987e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.5781, -4.8203,  0.2510,  ..., -2.5781, -6.8828, -3.6582]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 12:40:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for pony is horse
A more intense word for interesting is exciting
A more intense word for nap is sleep
A more intense word for love is adore
A more intense word for sad is desparate
A more intense word for cry is scream
A more intense word for pain is torment
A more intense word for want is
2024-07-26 12:40:59 root INFO     [order_1_approx] starting weight calculation for A more intense word for love is adore
A more intense word for cry is scream
A more intense word for interesting is exciting
A more intense word for pain is torment
A more intense word for want is crave
A more intense word for pony is horse
A more intense word for nap is sleep
A more intense word for sad is
2024-07-26 12:40:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 12:43:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0523, -0.1321, -0.0453,  ...,  0.1456, -0.4258,  0.1904],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2715, -3.8301,  2.8223,  ..., -0.7026, -0.7490, -2.4590],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0394, -0.0044, -0.0044,  ..., -0.0084,  0.0147,  0.0287],
        [-0.0163,  0.0235,  0.0167,  ..., -0.0049, -0.0199, -0.0271],
        [-0.0209, -0.0073,  0.0382,  ...,  0.0211, -0.0095,  0.0122],
        ...,
        [-0.0032, -0.0246, -0.0149,  ...,  0.0234, -0.0127, -0.0242],
        [-0.0023, -0.0159, -0.0117,  ...,  0.0208,  0.0258, -0.0322],
        [ 0.0098, -0.0345, -0.0233,  ...,  0.0021, -0.0197,  0.0020]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0156, -4.0547,  2.5293,  ..., -0.6216, -0.4390, -2.7441]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 12:43:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for love is adore
A more intense word for cry is scream
A more intense word for interesting is exciting
A more intense word for pain is torment
A more intense word for want is crave
A more intense word for pony is horse
A more intense word for nap is sleep
A more intense word for sad is
2024-07-26 12:43:44 root INFO     [order_1_approx] starting weight calculation for A more intense word for want is crave
A more intense word for interesting is exciting
A more intense word for nap is sleep
A more intense word for cry is scream
A more intense word for love is adore
A more intense word for pony is horse
A more intense word for sad is desparate
A more intense word for pain is
2024-07-26 12:43:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
                2024-07-26 12:46:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0392, -0.2600, -0.0345,  ..., -0.0759, -0.4771,  0.2446],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.2344, -5.2500,  0.6309,  ..., -1.5918,  0.1855, -2.4473],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.5206e-02, -2.8458e-02, -9.9564e-03,  ..., -5.1880e-04,
         -1.0468e-02,  1.9211e-02],
        [-9.6207e-03,  2.1469e-02,  6.9714e-04,  ...,  9.4604e-04,
         -5.5695e-03, -1.1185e-02],
        [ 1.0590e-02, -1.3618e-02,  2.7176e-02,  ...,  7.6828e-03,
         -1.6449e-02,  1.3504e-02],
        ...,
        [-9.0790e-03, -6.6528e-03, -8.3923e-05,  ...,  1.4000e-02,
         -3.1376e-03, -2.9968e-02],
        [-6.8207e-03,  8.6746e-03, -2.0218e-03,  ...,  8.1940e-03,
          9.4299e-03, -1.3802e-02],
        [ 6.1150e-03, -1.8875e-02, -5.0545e-03,  ...,  2.6321e-03,
         -6.1455e-03,  2.2949e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.8867, -5.1406,  0.8276,  ..., -1.3184,  0.0911, -2.0293]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 12:46:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for want is crave
A more intense word for interesting is exciting
A more intense word for nap is sleep
A more intense word for cry is scream
A more intense word for love is adore
A more intense word for pony is horse
A more intense word for sad is desparate
A more intense word for pain is
2024-07-26 12:46:30 root INFO     [order_1_approx] starting weight calculation for A more intense word for cry is scream
A more intense word for pain is torment
A more intense word for sad is desparate
A more intense word for interesting is exciting
A more intense word for pony is horse
A more intense word for want is crave
A more intense word for nap is sleep
A more intense word for love is
2024-07-26 12:46:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
,
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.2227, -2.7832, -0.9155,  ...,  1.4639, -2.4023, -0.7383],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0287, -0.0205, -0.0003,  ...,  0.0135, -0.0024,  0.0176],
        [ 0.0085,  0.0152,  0.0346,  ...,  0.0096, -0.0017, -0.0124],
        [ 0.0081,  0.0156,  0.0212,  ..., -0.0096,  0.0067, -0.0039],
        ...,
        [ 0.0030,  0.0103, -0.0037,  ...,  0.0179,  0.0201, -0.0034],
        [ 0.0061,  0.0008,  0.0095,  ..., -0.0015,  0.0148,  0.0150],
        [-0.0014,  0.0069, -0.0112,  ..., -0.0149, -0.0084,  0.0069]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.0977, -2.4512, -1.1816,  ...,  1.4746, -2.0312, -0.7241]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 12:46:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a monkey is referred to as a infant
The offspring of a dog is referred to as a puppy
The offspring of a goat is referred to as a kid
The offspring of a beetle is referred to as a larva
The offspring of a bear is referred to as a cub
The offspring of a gorilla is referred to as a infant
The offspring of a seal is referred to as a pup
The offspring of a rabbit is referred to as a
2024-07-26 12:46:08 root INFO     [order_1_approx] starting weight calculation for The offspring of a monkey is referred to as a infant
The offspring of a beetle is referred to as a larva
The offspring of a goat is referred to as a kid
The offspring of a rabbit is referred to as a bunny
The offspring of a seal is referred to as a pup
The offspring of a dog is referred to as a puppy
The offspring of a gorilla is referred to as a infant
The offspring of a bear is referred to as a
2024-07-26 12:46:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 12:49:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0103,  0.0132,  0.1458,  ..., -0.1235, -0.1621,  0.0379],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.5391, -5.6016, -1.6309,  ..., -0.6455, -4.1758,  0.3604],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0062, -0.0112,  0.0203,  ...,  0.0037, -0.0237,  0.0126],
        [-0.0215,  0.0131,  0.0329,  ...,  0.0122,  0.0003, -0.0003],
        [ 0.0082, -0.0138,  0.0134,  ...,  0.0052, -0.0122,  0.0030],
        ...,
        [-0.0054,  0.0067,  0.0057,  ...,  0.0146,  0.0148, -0.0247],
        [ 0.0199, -0.0129,  0.0097,  ...,  0.0117,  0.0336,  0.0093],
        [ 0.0074, -0.0012, -0.0219,  ...,  0.0175, -0.0125,  0.0202]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.6680, -5.8398, -1.5439,  ..., -0.9590, -4.3945,  0.2333]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 12:49:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for cry is scream
A more intense word for pain is torment
A more intense word for sad is desparate
A more intense word for interesting is exciting
A more intense word for pony is horse
A more intense word for want is crave
A more intense word for nap is sleep
A more intense word for love is
2024-07-26 12:49:16 root INFO     [order_1_approx] starting weight calculation for A more intense word for sad is desparate
A more intense word for want is crave
A more intense word for nap is sleep
A more intense word for pain is torment
A more intense word for interesting is exciting
A more intense word for pony is horse
A more intense word for love is adore
A more intense word for cry is
2024-07-26 12:49:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
andom is randomness
The state of being competitive is competitiveness
The state of being marked is
2024-07-26 12:47:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 12:52:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0829, -0.2852, -0.1951,  ..., -0.2487, -0.4214,  0.3057],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.6602, -6.5508,  2.4219,  ..., -0.1760, -0.8662, -0.4580],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0265, -0.0493, -0.0253,  ..., -0.0136, -0.0231,  0.0089],
        [-0.0097,  0.0350,  0.0341,  ...,  0.0056,  0.0157, -0.0010],
        [ 0.0176, -0.0283,  0.0047,  ...,  0.0147, -0.0420, -0.0047],
        ...,
        [ 0.0102,  0.0245,  0.0433,  ...,  0.0012,  0.0481, -0.0406],
        [ 0.0163,  0.0184, -0.0065,  ...,  0.0331,  0.0175, -0.0083],
        [ 0.0112,  0.0028,  0.0256,  ..., -0.0104,  0.0091,  0.0055]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.7930, -6.6641,  2.8105,  ..., -1.0000, -1.0166, -0.5361]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 12:52:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for sad is desparate
A more intense word for want is crave
A more intense word for nap is sleep
A more intense word for pain is torment
A more intense word for interesting is exciting
A more intense word for pony is horse
A more intense word for love is adore
A more intense word for cry is
2024-07-26 12:52:01 root INFO     [order_1_approx] starting weight calculation for A more intense word for nap is sleep
A more intense word for sad is desparate
A more intense word for love is adore
A more intense word for pony is horse
A more intense word for pain is torment
A more intense word for cry is scream
A more intense word for want is crave
A more intense word for interesting is
2024-07-26 12:52:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
                  2024-07-26 12:54:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0112,  0.1593,  0.1221,  ...,  0.1036, -0.4424,  0.1744],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.2930,  0.3906,  1.7734,  ..., -0.3643, -6.0078, -1.7119],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0138, -0.0254, -0.0006,  ...,  0.0005,  0.0108,  0.0203],
        [-0.0173,  0.0231, -0.0394,  ..., -0.0608, -0.0254, -0.0506],
        [ 0.0357, -0.0278,  0.0417,  ..., -0.0174,  0.0197,  0.0161],
        ...,
        [ 0.0203,  0.0073, -0.0314,  ...,  0.0591, -0.0113, -0.0134],
        [ 0.0472, -0.0248,  0.0681,  ...,  0.0247, -0.0054, -0.0149],
        [-0.0049, -0.0324, -0.0355,  ..., -0.0279, -0.0132,  0.0222]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.5586,  0.6318,  1.9590,  ..., -0.3979, -6.4102, -1.0137]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 12:54:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for nap is sleep
A more intense word for sad is desparate
A more intense word for love is adore
A more intense word for pony is horse
A more intense word for pain is torment
A more intense word for cry is scream
A more intense word for want is crave
A more intense word for interesting is
2024-07-26 12:54:45 root INFO     [order_1_approx] starting weight calculation for A more intense word for nap is sleep
A more intense word for love is adore
A more intense word for pain is torment
A more intense word for interesting is exciting
A more intense word for want is crave
A more intense word for cry is scream
A more intense word for sad is desparate
A more intense word for pony is
2024-07-26 12:54:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
                                                                                                                                                                                                                2024-07-26 12:57:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0371,  0.1760, -0.1934,  ..., -0.2510, -0.0184,  0.1129],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6855, -5.3203, -0.8867,  ...,  1.7627, -4.5703, -0.9492],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.9326e-02,  6.1111e-03, -1.6022e-03,  ..., -2.0309e-02,
         -9.1248e-03,  5.4657e-02],
        [-4.0741e-02,  2.3865e-02, -2.1210e-02,  ...,  1.3824e-02,
         -1.9821e-02,  4.0833e-02],
        [ 9.7717e-02, -2.7878e-02,  6.9092e-02,  ..., -4.1443e-02,
         -4.7485e-02, -2.9190e-02],
        ...,
        [-9.3460e-05, -6.7673e-03, -1.0742e-02,  ...,  4.9530e-02,
         -1.3535e-02, -2.0447e-02],
        [ 2.7466e-02, -2.3071e-02,  2.0172e-02,  ...,  6.5689e-03,
          2.6703e-04, -4.6326e-02],
        [-2.9434e-02, -1.8600e-02,  2.1622e-02,  ..., -1.0727e-02,
         -1.5343e-02,  8.4717e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3223, -4.9453, -1.1924,  ...,  1.8369, -4.5039, -0.5713]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 12:57:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for nap is sleep
A more intense word for love is adore
A more intense word for pain is torment
A more intense word for interesting is exciting
A more intense word for want is crave
A more intense word for cry is scream
A more intense word for sad is desparate
A more intense word for pony is
2024-07-26 12:57:27 root INFO     [order_1_approx] starting weight calculation for A more intense word for interesting is exciting
A more intense word for pain is torment
A more intense word for sad is desparate
A more intense word for want is crave
A more intense word for cry is scream
A more intense word for love is adore
A more intense word for pony is horse
A more intense word for nap is
2024-07-26 12:57:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
                      2024-07-26 13:00:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1027, -0.0267,  0.2690,  ...,  0.0527, -0.5044,  0.0458],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6094, -5.1641,  4.4883,  ...,  0.3159, -1.0098, -1.7744],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0263, -0.0282, -0.0308,  ...,  0.0558,  0.0168,  0.0370],
        [-0.0410,  0.0443,  0.0311,  ..., -0.0204, -0.0283, -0.0449],
        [-0.0267, -0.0126, -0.0018,  ...,  0.0067, -0.0276, -0.0170],
        ...,
        [ 0.0145,  0.0188,  0.0521,  ...,  0.0080, -0.0016, -0.0360],
        [ 0.0348, -0.0582,  0.0228,  ...,  0.0396,  0.0128,  0.0077],
        [-0.0017, -0.0163, -0.0050,  ...,  0.0240,  0.0016,  0.0030]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1187, -5.1250,  4.8594,  ...,  0.4502, -1.3906, -1.6729]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 13:00:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for interesting is exciting
A more intense word for pain is torment
A more intense word for sad is desparate
A more intense word for want is crave
A more intense word for cry is scream
A more intense word for love is adore
A more intense word for pony is horse
A more intense word for nap is
2024-07-26 13:00:12 root INFO     total operator prediction time: 1321.2276163101196 seconds
2024-07-26 13:00:12 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hypernyms - animals
2024-07-26 13:00:12 root INFO     building operator hypernyms - animals
2024-07-26 13:00:13 root INFO     [order_1_approx] starting weight calculation for The allosaurus falls into the category of dinosaur
The orangutan falls into the category of primate
The vulture falls into the category of raptor
The deer falls into the category of bovid
The mamba falls into the category of snake
The turkey falls into the category of fowl
The porcupine falls into the category of rodent
The triceratops falls into the category of
2024-07-26 13:00:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 13:02:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1132,  0.0154, -0.1877,  ..., -0.1885, -0.4285,  0.2585],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8086, -4.0352,  0.0740,  ..., -1.4316, -3.9961, -3.0039],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0254,  0.0071, -0.0164,  ...,  0.0162, -0.0236, -0.0105],
        [-0.0011,  0.0261, -0.0206,  ...,  0.0016, -0.0078, -0.0273],
        [ 0.0109, -0.0058,  0.0283,  ..., -0.0207, -0.0123,  0.0054],
        ...,
        [-0.0062, -0.0151,  0.0121,  ...,  0.0443, -0.0052,  0.0207],
        [-0.0175,  0.0192,  0.0111,  ...,  0.0115,  0.0271, -0.0204],
        [ 0.0024, -0.0149,  0.0059,  ..., -0.0110,  0.0121,  0.0137]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4385, -3.8613,  0.2139,  ..., -0.8164, -3.8496, -3.1641]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 13:02:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The allosaurus falls into the category of dinosaur
The orangutan falls into the category of primate
The vulture falls into the category of raptor
The deer falls into the category of bovid
The mamba falls into the category of snake
The turkey falls into the category of fowl
The porcupine falls into the category of rodent
The triceratops falls into the category of
2024-07-26 13:02:59 root INFO     [order_1_approx] starting weight calculation for The triceratops falls into the category of dinosaur
The mamba falls into the category of snake
The deer falls into the category of bovid
The allosaurus falls into the category of dinosaur
The turkey falls into the category of fowl
The porcupine falls into the category of rodent
The orangutan falls into the category of primate
The vulture falls into the category of
2024-07-26 13:02:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
) 

                        o_j1=tensor([ 3.5098, -5.3164, -1.3965,  ..., -0.6104, -2.2793,  2.2656],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.8946e-02, -2.5970e-02, -1.9073e-05,  ...,  6.8817e-03,
         -1.7120e-02,  2.4292e-02],
        [-1.4572e-02,  2.7802e-02,  1.3657e-02,  ..., -1.9722e-03,
         -1.1932e-02, -3.0670e-02],
        [-5.4741e-03, -1.6079e-03,  4.1229e-02,  ...,  8.3466e-03,
         -1.2589e-02, -1.1101e-02],
        ...,
        [-1.3290e-02,  1.7212e-02, -1.3069e-02,  ...,  2.5848e-02,
          1.7380e-02, -7.6752e-03],
        [-9.8724e-03,  2.1500e-02,  3.0029e-02,  ...,  7.5500e-02,
          1.2741e-02, -2.7771e-02],
        [ 1.3847e-02, -1.8707e-02, -1.0895e-02,  ...,  1.6861e-03,
         -3.1982e-02,  3.3539e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4219, -5.0664, -0.7021,  ..., -0.3184, -1.9004,  1.6299]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 13:01:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a monkey is referred to as a infant
The offspring of a beetle is referred to as a larva
The offspring of a goat is referred to as a kid
The offspring of a rabbit is referred to as a bunny
The offspring of a seal is referred to as a pup
The offspring of a dog is referred to as a puppy
The offspring of a gorilla is referred to as a infant
The offspring of a bear is referred to as a
2024-07-26 13:01:36 root INFO     [order_1_approx] starting weight calculation for The offspring of a bear is referred to as a cub
The offspring of a beetle is referred to as a larva
The offspring of a goat is referred to as a kid
The offspring of a dog is referred to as a puppy
The offspring of a monkey is referred to as a infant
The offspring of a rabbit is referred to as a bunny
The offspring of a gorilla is referred to as a infant
The offspring of a seal is referred to as a
2024-07-26 13:01:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 13:05:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2747, -0.1981, -0.3281,  ...,  0.0224, -0.4163,  0.0546],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1738, -2.1660,  4.0391,  ..., -1.0215, -5.2461,  1.3389],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0623, -0.0145, -0.0364,  ..., -0.0073,  0.0368, -0.0021],
        [-0.0131,  0.0187,  0.0189,  ..., -0.0025, -0.0075,  0.0212],
        [-0.0213,  0.0035,  0.0480,  ...,  0.0060,  0.0035,  0.0029],
        ...,
        [ 0.0156,  0.0240,  0.0277,  ...,  0.0472, -0.0326, -0.0168],
        [-0.0133,  0.0013, -0.0046,  ...,  0.0570,  0.0202,  0.0054],
        [ 0.0432, -0.0181, -0.0025,  ..., -0.0189,  0.0483,  0.0503]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1426, -2.5117,  3.7891,  ..., -0.7368, -5.3828,  1.3662]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 13:05:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The triceratops falls into the category of dinosaur
The mamba falls into the category of snake
The deer falls into the category of bovid
The allosaurus falls into the category of dinosaur
The turkey falls into the category of fowl
The porcupine falls into the category of rodent
The orangutan falls into the category of primate
The vulture falls into the category of
2024-07-26 13:05:45 root INFO     [order_1_approx] starting weight calculation for The vulture falls into the category of raptor
The allosaurus falls into the category of dinosaur
The mamba falls into the category of snake
The deer falls into the category of bovid
The porcupine falls into the category of rodent
The triceratops falls into the category of dinosaur
The orangutan falls into the category of primate
The turkey falls into the category of
2024-07-26 13:05:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 13:08:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0759, -0.1477, -0.1631,  ...,  0.0709, -0.1211,  0.2944],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2734, -4.6367,  3.8945,  ..., -1.2588, -8.4375,  0.4160],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0350,  0.0045,  0.0018,  ..., -0.0108, -0.0049,  0.0007],
        [ 0.0036,  0.0457,  0.0087,  ...,  0.0147, -0.0102, -0.0359],
        [ 0.0240, -0.0208,  0.0349,  ..., -0.0116, -0.0230, -0.0104],
        ...,
        [ 0.0063,  0.0034,  0.0131,  ...,  0.0080, -0.0185,  0.0125],
        [ 0.0169,  0.0160,  0.0094,  ...,  0.0273,  0.0150, -0.0240],
        [ 0.0201,  0.0071,  0.0085,  ..., -0.0028, -0.0029,  0.0023]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5820, -4.3164,  3.5137,  ..., -0.8711, -8.6797,  0.7256]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 13:08:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The vulture falls into the category of raptor
The allosaurus falls into the category of dinosaur
The mamba falls into the category of snake
The deer falls into the category of bovid
The porcupine falls into the category of rodent
The triceratops falls into the category of dinosaur
The orangutan falls into the category of primate
The turkey falls into the category of
2024-07-26 13:08:25 root INFO     [order_1_approx] starting weight calculation for The turkey falls into the category of fowl
The deer falls into the category of bovid
The orangutan falls into the category of primate
The vulture falls into the category of raptor
The triceratops falls into the category of dinosaur
The allosaurus falls into the category of dinosaur
The mamba falls into the category of snake
The porcupine falls into the category of
2024-07-26 13:08:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 13:11:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0641, -0.4912, -0.1963,  ..., -0.0863, -0.1896,  0.2333],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1602, -3.2070,  0.6562,  ..., -2.0703, -3.8633, -1.3135],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.6672e-02, -8.9493e-03, -9.9945e-03,  ..., -6.1750e-05,
         -8.2855e-03, -2.3117e-03],
        [ 3.0041e-03, -4.4785e-03,  9.8572e-03,  ...,  7.4081e-03,
          2.3594e-03, -1.7548e-03],
        [-2.7466e-02,  2.2949e-02,  1.8433e-02,  ..., -1.3809e-02,
          1.4267e-03, -1.6663e-02],
        ...,
        [ 3.1357e-03,  5.7030e-03,  2.5940e-04,  ...,  1.1101e-02,
          8.5983e-03,  3.3379e-05],
        [ 9.1553e-04, -1.0586e-03, -9.2163e-03,  ..., -6.5689e-03,
          3.2471e-02, -2.1133e-02],
        [ 7.8583e-03, -1.9562e-02,  2.9716e-03,  ...,  5.0201e-03,
         -3.1853e-04,  1.7136e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7744, -2.9746,  0.5537,  ..., -2.3359, -3.5938, -1.0713]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 13:11:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The turkey falls into the category of fowl
The deer falls into the category of bovid
The orangutan falls into the category of primate
The vulture falls into the category of raptor
The triceratops falls into the category of dinosaur
The allosaurus falls into the category of dinosaur
The mamba falls into the category of snake
The porcupine falls into the category of
2024-07-26 13:11:09 root INFO     [order_1_approx] starting weight calculation for The triceratops falls into the category of dinosaur
The vulture falls into the category of raptor
The turkey falls into the category of fowl
The deer falls into the category of bovid
The allosaurus falls into the category of dinosaur
The porcupine falls into the category of rodent
The mamba falls into the category of snake
The orangutan falls into the category of
2024-07-26 13:11:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 13:13:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0140, -0.2573, -0.3159,  ...,  0.0006, -0.2542,  0.2222],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5264, -4.5859, -0.0684,  ..., -3.7207, -6.3594,  1.1396],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 9.2621e-03, -9.8267e-03,  3.4065e-03,  ...,  4.3983e-03,
          1.1778e-04,  5.6305e-03],
        [ 4.5929e-03, -5.1117e-04,  5.8136e-03,  ..., -9.1400e-03,
          4.2801e-03,  1.1749e-03],
        [ 2.0485e-03, -8.5373e-03,  8.0414e-03,  ..., -3.5820e-03,
         -3.7384e-03,  6.9542e-03],
        ...,
        [ 1.5297e-03, -4.9591e-05,  5.9128e-03,  ..., -5.4474e-03,
         -2.4147e-03,  9.3746e-04],
        [-4.0894e-03,  0.0000e+00, -1.9798e-03,  ...,  3.5744e-03,
          9.7656e-03, -8.7357e-03],
        [ 2.7313e-03, -3.5744e-03, -1.5793e-03,  ..., -5.2376e-03,
         -3.3798e-03,  1.1444e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5259, -4.6445,  0.1299,  ..., -3.9199, -6.4531,  1.2207]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 13:13:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The triceratops falls into the category of dinosaur
The vulture falls into the category of raptor
The turkey falls into the category of fowl
The deer falls into the category of bovid
The allosaurus falls into the category of dinosaur
The porcupine falls into the category of rodent
The mamba falls into the category of snake
The orangutan falls into the category of
2024-07-26 13:13:52 root INFO     [order_1_approx] starting weight calculation for The allosaurus falls into the category of dinosaur
The orangutan falls into the category of primate
The deer falls into the category of bovid
The vulture falls into the category of raptor
The triceratops falls into the category of dinosaur
The porcupine falls into the category of rodent
The turkey falls into the category of fowl
The mamba falls into the category of
2024-07-26 13:13:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 13:16:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0393, -0.1271, -0.1143,  ..., -0.1090, -0.4050, -0.3003],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7510, -4.1250,  2.0898,  ..., -0.4492, -4.0664, -0.3159],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0614, -0.0320,  0.0203,  ..., -0.0013, -0.0064,  0.0361],
        [-0.0616,  0.0357, -0.0061,  ...,  0.0181, -0.0028,  0.0043],
        [-0.0146, -0.0594,  0.0762,  ..., -0.0351, -0.0378,  0.0036],
        ...,
        [-0.0074,  0.0288,  0.0213,  ...,  0.0812,  0.0285,  0.0045],
        [ 0.0212,  0.0231,  0.0194,  ...,  0.0061,  0.0266, -0.0346],
        [-0.0023,  0.0221, -0.0258,  ...,  0.0170,  0.0207,  0.0322]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0020, -4.1484,  2.5000,  ..., -0.3667, -4.6992, -0.9131]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 13:16:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The allosaurus falls into the category of dinosaur
The orangutan falls into the category of primate
The deer falls into the category of bovid
The vulture falls into the category of raptor
The triceratops falls into the category of dinosaur
The porcupine falls into the category of rodent
The turkey falls into the category of fowl
The mamba falls into the category of
2024-07-26 13:16:37 root INFO     [order_1_approx] starting weight calculation for The triceratops falls into the category of dinosaur
The mamba falls into the category of snake
The porcupine falls into the category of rodent
The turkey falls into the category of fowl
The deer falls into the category of bovid
The vulture falls into the category of raptor
The orangutan falls into the category of primate
The allosaurus falls into the category of
2024-07-26 13:16:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8

                        o_j1=tensor([ 1.2090, -4.9023, -2.7305,  ..., -0.8853, -4.2969,  1.4463],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0781, -0.0107, -0.0336,  ...,  0.0561, -0.0153,  0.0166],
        [ 0.0074,  0.0597, -0.0071,  ...,  0.0067, -0.0315, -0.0266],
        [ 0.0292,  0.0019,  0.0530,  ..., -0.0047, -0.0150, -0.0148],
        ...,
        [ 0.0190,  0.0018, -0.0014,  ...,  0.0493, -0.0021, -0.0133],
        [-0.0083, -0.0294,  0.0037,  ...,  0.0386,  0.0061, -0.0005],
        [-0.0296, -0.0088,  0.0229,  ..., -0.0198,  0.0119,  0.0161]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2012, -4.6836, -2.3730,  ..., -0.3774, -3.7871,  0.9458]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 13:17:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a bear is referred to as a cub
The offspring of a beetle is referred to as a larva
The offspring of a goat is referred to as a kid
The offspring of a dog is referred to as a puppy
The offspring of a monkey is referred to as a infant
The offspring of a rabbit is referred to as a bunny
The offspring of a gorilla is referred to as a infant
The offspring of a seal is referred to as a
2024-07-26 13:17:04 root INFO     total operator prediction time: 5449.748383760452 seconds
2024-07-26 13:17:04 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - sound
2024-07-26 13:17:04 root INFO     building operator animal - sound
2024-07-26 13:17:04 root INFO     [order_1_approx] starting weight calculation for The sound that a fly makes is called a buzz
The sound that a coyote makes is called a howl
The sound that a donkey makes is called a bray
The sound that a mallard makes is called a quack
The sound that a dog makes is called a bark
The sound that a beetle makes is called a drone
The sound that a turkey makes is called a gobble
The sound that a elk makes is called a
2024-07-26 13:17:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 13:19:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0654, -0.1406, -0.4258,  ..., -0.1367, -0.4988,  0.0521],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5605, -3.3555,  2.1758,  ..., -1.5273, -5.9375, -0.9336],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0266, -0.0204, -0.0133,  ...,  0.0135, -0.0076,  0.0011],
        [ 0.0083,  0.0107, -0.0016,  ..., -0.0101, -0.0074, -0.0114],
        [ 0.0170, -0.0113,  0.0034,  ..., -0.0144, -0.0093,  0.0040],
        ...,
        [-0.0036, -0.0085,  0.0197,  ...,  0.0217, -0.0017,  0.0256],
        [-0.0151,  0.0107, -0.0005,  ...,  0.0088,  0.0206, -0.0400],
        [ 0.0031, -0.0175,  0.0085,  ..., -0.0074,  0.0053,  0.0341]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9722, -3.4590,  2.5938,  ..., -0.6431, -6.5820, -0.4648]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 13:19:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The triceratops falls into the category of dinosaur
The mamba falls into the category of snake
The porcupine falls into the category of rodent
The turkey falls into the category of fowl
The deer falls into the category of bovid
The vulture falls into the category of raptor
The orangutan falls into the category of primate
The allosaurus falls into the category of
2024-07-26 13:19:21 root INFO     [order_1_approx] starting weight calculation for The mamba falls into the category of snake
The vulture falls into the category of raptor
The porcupine falls into the category of rodent
The allosaurus falls into the category of dinosaur
The turkey falls into the category of fowl
The orangutan falls into the category of primate
The triceratops falls into the category of dinosaur
The deer falls into the category of
2024-07-26 13:19:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
e.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 13:22:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0376,  0.0224, -0.3086,  ...,  0.1438, -0.2113,  0.0314],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7178, -4.8086,  0.7803,  ..., -0.5449, -7.0859, -0.8364],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0310, -0.0006,  0.0089,  ..., -0.0080,  0.0079,  0.0018],
        [ 0.0255,  0.0142,  0.0067,  ...,  0.0104, -0.0351,  0.0121],
        [ 0.0006, -0.0023,  0.0466,  ..., -0.0148, -0.0006, -0.0045],
        ...,
        [ 0.0116,  0.0111, -0.0081,  ...,  0.0178, -0.0135,  0.0010],
        [ 0.0017, -0.0025, -0.0113,  ...,  0.0137,  0.0453, -0.0147],
        [ 0.0049, -0.0113,  0.0011,  ..., -0.0587,  0.0019,  0.0021]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7236, -4.3008,  0.6504,  ..., -0.2424, -7.1719, -0.5068]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 13:22:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The mamba falls into the category of snake
The vulture falls into the category of raptor
The porcupine falls into the category of rodent
The allosaurus falls into the category of dinosaur
The turkey falls into the category of fowl
The orangutan falls into the category of primate
The triceratops falls into the category of dinosaur
The deer falls into the category of
2024-07-26 13:22:05 root INFO     total operator prediction time: 1312.92112326622 seconds
2024-07-26 13:22:05 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hyponyms - misc
2024-07-26 13:22:05 root INFO     building operator hyponyms - misc
2024-07-26 13:22:05 root INFO     [order_1_approx] starting weight calculation for A more specific term for a color is white
A more specific term for a month is january
A more specific term for a song is lullaby
A more specific term for a tool is rake
A more specific term for a flask is thermos
A more specific term for a weapon is gun
A more specific term for a computer is laptop
A more specific term for a railway is
2024-07-26 13:22:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 13:24:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0461,  0.1725,  0.1050,  ..., -0.1127,  0.2429, -0.1621],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.0898, -8.9141,  2.3242,  ...,  2.3203, -1.2930, -0.1821],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0461, -0.0358,  0.0471,  ..., -0.0288, -0.0125,  0.0116],
        [ 0.0144,  0.0399, -0.0462,  ...,  0.0272,  0.0319, -0.0080],
        [ 0.0099,  0.0202,  0.0447,  ..., -0.0435, -0.0185,  0.0146],
        ...,
        [ 0.0141,  0.0524, -0.0115,  ...,  0.0603,  0.0127, -0.0249],
        [-0.0292, -0.0246, -0.0101,  ...,  0.0248,  0.0363,  0.0133],
        [ 0.0324,  0.0430, -0.0397,  ...,  0.0190,  0.0256,  0.0293]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.2012, -8.6953,  2.3379,  ...,  1.8818, -1.2656,  0.2756]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 13:24:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a color is white
A more specific term for a month is january
A more specific term for a song is lullaby
A more specific term for a tool is rake
A more specific term for a flask is thermos
A more specific term for a weapon is gun
A more specific term for a computer is laptop
A more specific term for a railway is
2024-07-26 13:24:49 root INFO     [order_1_approx] starting weight calculation for A more specific term for a railway is monorail
A more specific term for a flask is thermos
A more specific term for a song is lullaby
A more specific term for a month is january
A more specific term for a weapon is gun
A more specific term for a tool is rake
A more specific term for a computer is laptop
A more specific term for a color is
2024-07-26 13:24:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 13:27:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1924, -0.1727, -0.1247,  ...,  0.1786, -0.0551, -0.0352],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.3008, -3.7461,  0.4504,  ...,  1.2383, -2.9355,  0.3220],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0493, -0.0075,  0.0352,  ...,  0.0266,  0.0059, -0.0008],
        [-0.0125,  0.0026, -0.0353,  ..., -0.0015,  0.0050,  0.0180],
        [-0.0234,  0.0216,  0.0208,  ..., -0.0114, -0.0182,  0.0022],
        ...,
        [-0.0007, -0.0275, -0.0390,  ...,  0.0177, -0.0195, -0.0015],
        [-0.0114,  0.0122,  0.0175,  ...,  0.0046,  0.0292, -0.0064],
        [-0.0148, -0.0309, -0.0430,  ..., -0.0206,  0.0033,  0.0322]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.3496, -2.1465, -0.6025,  ...,  1.7354, -3.2246,  1.3018]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 13:27:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a railway is monorail
A more specific term for a flask is thermos
A more specific term for a song is lullaby
A more specific term for a month is january
A more specific term for a weapon is gun
A more specific term for a tool is rake
A more specific term for a computer is laptop
A more specific term for a color is
2024-07-26 13:27:30 root INFO     [order_1_approx] starting weight calculation for A more specific term for a month is january
A more specific term for a weapon is gun
A more specific term for a flask is thermos
A more specific term for a railway is monorail
A more specific term for a song is lullaby
A more specific term for a color is white
A more specific term for a computer is laptop
A more specific term for a tool is
2024-07-26 13:27:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 13:30:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2059, -0.3049, -0.0428,  ...,  0.0167, -0.1191,  0.1240],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3257, -4.0547, -0.3545,  ...,  1.7314, -3.9375,  1.1484],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0338, -0.0200, -0.0057,  ...,  0.0147, -0.0012,  0.0027],
        [ 0.0025,  0.0006, -0.0007,  ..., -0.0121,  0.0310,  0.0044],
        [-0.0143,  0.0061,  0.0059,  ..., -0.0095,  0.0015, -0.0015],
        ...,
        [ 0.0079, -0.0014, -0.0001,  ...,  0.0262,  0.0003,  0.0074],
        [-0.0168, -0.0139, -0.0248,  ..., -0.0173,  0.0294, -0.0166],
        [-0.0089,  0.0055,  0.0058,  ..., -0.0180,  0.0256,  0.0202]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0466, -3.6523, -0.2493,  ...,  1.7236, -3.7598,  1.4531]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 13:30:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a month is january
A more specific term for a weapon is gun
A more specific term for a flask is thermos
A more specific term for a railway is monorail
A more specific term for a song is lullaby
A more specific term for a color is white
A more specific term for a computer is laptop
A more specific term for a tool is
2024-07-26 13:30:10 root INFO     [order_1_approx] starting weight calculation for A more specific term for a song is lullaby
A more specific term for a weapon is gun
A more specific term for a computer is laptop
A more specific term for a month is january
A more specific term for a railway is monorail
A more specific term for a tool is rake
A more specific term for a color is white
A more specific term for a flask is
2024-07-26 13:30:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 13:32:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0798, -0.2751, -0.2922,  ..., -0.1963,  0.1202,  0.0107],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0020, -3.7812,  0.5610,  ..., -0.2212,  2.6484, -1.3037],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0953,  0.0276,  0.0258,  ...,  0.0717, -0.0490,  0.0352],
        [ 0.0146,  0.0690, -0.0062,  ..., -0.0222,  0.0330, -0.0010],
        [ 0.0051,  0.0018,  0.1146,  ...,  0.0056,  0.0069,  0.0296],
        ...,
        [ 0.0325,  0.0591, -0.0151,  ...,  0.0746,  0.0047,  0.0105],
        [-0.0521,  0.0024, -0.0574,  ..., -0.0219,  0.0703, -0.0684],
        [ 0.0191,  0.0449, -0.0234,  ...,  0.0340,  0.0310,  0.0868]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6016, -3.5156,  0.5161,  ..., -0.1870,  2.9199, -1.5918]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 13:32:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a song is lullaby
A more specific term for a weapon is gun
A more specific term for a computer is laptop
A more specific term for a month is january
A more specific term for a railway is monorail
A more specific term for a tool is rake
A more specific term for a color is white
A more specific term for a flask is
2024-07-26 13:32:53 root INFO     [order_1_approx] starting weight calculation for A more specific term for a flask is thermos
A more specific term for a railway is monorail
A more specific term for a weapon is gun
A more specific term for a tool is rake
A more specific term for a computer is laptop
A more specific term for a color is white
A more specific term for a month is january
A more specific term for a song is
2024-07-26 13:32:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 13:35:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1060,  0.2072, -0.1089,  ..., -0.0047, -0.3325, -0.3096],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4111, -9.4219,  2.8008,  ..., -0.9761, -1.7451, -1.1416],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0165, -0.0256,  0.0076,  ...,  0.0235, -0.0092,  0.0237],
        [-0.0467,  0.0402, -0.0565,  ..., -0.0121,  0.0515,  0.0317],
        [ 0.0257, -0.0073,  0.0743,  ...,  0.0098, -0.0500, -0.0089],
        ...,
        [-0.0076,  0.0112, -0.0257,  ...,  0.0202,  0.0078,  0.0026],
        [-0.0222, -0.0133,  0.0064,  ..., -0.0081,  0.0218,  0.0274],
        [-0.0253,  0.0248, -0.0392,  ..., -0.0308,  0.0643,  0.0761]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8057, -9.5391,  2.7793,  ..., -1.1006, -2.1484, -1.0977]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 13:35:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a flask is thermos
A more specific term for a railway is monorail
A more specific term for a weapon is gun
A more specific term for a tool is rake
A more specific term for a computer is laptop
A more specific term for a color is white
A more specific term for a month is january
A more specific term for a song is
2024-07-26 13:35:36 root INFO     [order_1_approx] starting weight calculation for A more specific term for a month is january
A more specific term for a tool is rake
A more specific term for a computer is laptop
A more specific term for a song is lullaby
A more specific term for a color is white
A more specific term for a flask is thermos
A more specific term for a railway is monorail
A more specific term for a weapon is
2024-07-26 13:35:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 13:38:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1071,  0.0587,  0.0727,  ..., -0.0581, -0.2112, -0.1080],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-3.0195, -6.6094, -0.2480,  ...,  0.5537, -3.3691,  0.8926],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.2410e-02, -1.4587e-02,  1.9073e-05,  ..., -8.7357e-03,
         -2.3746e-03, -6.2141e-03],
        [-2.4643e-02,  1.2909e-02, -1.8066e-02,  ...,  1.0536e-02,
          3.9444e-03, -3.3234e-02],
        [-4.1885e-03,  9.6436e-03,  3.8727e-02,  ..., -8.1253e-03,
         -6.5575e-03,  6.8512e-03],
        ...,
        [ 1.6937e-02, -9.7351e-03, -8.7204e-03,  ...,  4.2755e-02,
         -5.2490e-03,  9.3231e-03],
        [-4.2572e-02, -6.8893e-03, -1.0277e-02,  ...,  3.9673e-02,
          3.0853e-02, -1.9165e-02],
        [ 4.5853e-03, -3.4447e-03,  1.8692e-02,  ..., -3.3325e-02,
          8.1329e-03,  4.0100e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-3.1348, -6.1484, -0.1558,  ...,  0.5166, -3.3457,  1.0234]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 13:38:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a month is january
A more specific term for a tool is rake
A more specific term for a computer is laptop
A more specific term for a song is lullaby
A more specific term for a color is white
A more specific term for a flask is thermos
A more specific term for a railway is monorail
A more specific term for a weapon is
2024-07-26 13:38:21 root INFO     [order_1_approx] starting weight calculation for A more specific term for a flask is thermos
A more specific term for a weapon is gun
A more specific term for a tool is rake
A more specific term for a color is white
A more specific term for a railway is monorail
A more specific term for a song is lullaby
A more specific term for a month is january
A more specific term for a computer is
2024-07-26 13:38:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 13:41:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1301, -0.1279,  0.1431,  ...,  0.2294, -0.1816, -0.0186],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1528, -4.1406, -0.0955,  ..., -1.4316, -2.3184, -0.7588],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0247, -0.0129, -0.0173,  ...,  0.0023, -0.0052,  0.0605],
        [ 0.0054,  0.0058,  0.0056,  ...,  0.0096, -0.0019, -0.0072],
        [-0.0006,  0.0184,  0.0597,  ...,  0.0074,  0.0150,  0.0169],
        ...,
        [-0.0198,  0.0213, -0.0581,  ...,  0.0314, -0.0031, -0.0186],
        [-0.0168, -0.0240, -0.0155,  ...,  0.0044,  0.0176, -0.0167],
        [ 0.0167, -0.0054, -0.0409,  ..., -0.0026, -0.0043,  0.0318]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2952, -4.0352,  0.1412,  ..., -1.6543, -2.1836, -0.2310]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 13:41:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a flask is thermos
A more specific term for a weapon is gun
A more specific term for a tool is rake
A more specific term for a color is white
A more specific term for a railway is monorail
A more specific term for a song is lullaby
A more specific term for a month is january
A more specific term for a computer is
2024-07-26 13:41:06 root INFO     [order_1_approx] starting weight calculation for A more specific term for a computer is laptop
A more specific term for a railway is monorail
A more specific term for a tool is rake
A more specific term for a song is lullaby
A more specific term for a flask is thermos
A more specific term for a weapon is gun
A more specific term for a color is white
A more specific term for a month is
2024-07-26 13:41:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 13:43:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1293,  0.0264, -0.3745,  ..., -0.1870, -0.1104,  0.1279],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6289, -5.5859,  4.9375,  ..., -0.6733,  0.7617, -0.4150],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-2.1286e-02,  2.0355e-02, -6.4545e-03,  ..., -1.2192e-02,
         -8.1329e-03,  2.6749e-02],
        [ 6.5155e-03,  9.9869e-03, -9.7275e-05,  ..., -2.1423e-02,
          7.5989e-03,  3.4714e-04],
        [-3.5492e-02,  2.1622e-02,  2.5131e-02,  ..., -7.6008e-04,
         -4.6539e-04,  9.8572e-03],
        ...,
        [ 1.6724e-02,  1.1230e-02, -3.9177e-03,  ...,  3.8483e-02,
          3.5477e-04,  4.4289e-03],
        [-2.1423e-02,  4.0436e-03,  4.6326e-02,  ...,  4.5242e-03,
          5.6488e-02,  6.5575e-03],
        [ 1.5717e-02, -1.1818e-02, -3.6163e-02,  ...,  2.8809e-02,
         -3.8055e-02,  3.6682e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8369, -5.4922,  4.2930,  ..., -0.6499, -0.6533,  0.2642]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 13:43:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a computer is laptop
A more specific term for a railway is monorail
A more specific term for a tool is rake
A more specific term for a song is lullaby
A more specific term for a flask is thermos
A more specific term for a weapon is gun
A more specific term for a color is white
A more specific term for a month is
2024-07-26 13:43:49 root INFO     total operator prediction time: 1304.4369404315948 seconds
2024-07-26 13:43:49 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on antonyms - binary
2024-07-26 13:43:49 root INFO     building operator antonyms - binary
2024-07-26 13:43:50 root INFO     [order_1_approx] starting weight calculation for The opposite of dead is alive
The opposite of in is out
The opposite of southeast is southwest
The opposite of forward is backward
The opposite of previously is subsequently
The opposite of below is above
The opposite of top is bottom
The opposite of mortal is
2024-07-26 13:43:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 13:46:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2590, -0.0803, -0.1095,  ..., -0.4226, -0.3535,  0.1243],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7500, -3.0781,  0.8418,  ..., -4.0742, -3.4961, -3.6445],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.1525e-02,  3.9291e-03,  3.9246e-02,  ..., -9.1858e-03,
          6.5155e-03,  2.9640e-03],
        [ 1.3676e-03, -1.3313e-03,  1.3618e-02,  ...,  2.3514e-02,
          3.4690e-05, -9.3231e-03],
        [ 9.6436e-03, -5.8838e-02,  1.1711e-02,  ..., -1.9318e-02,
         -1.4160e-02, -9.7656e-03],
        ...,
        [ 3.5400e-02, -5.0735e-03,  2.3590e-02,  ..., -4.8248e-02,
          2.2755e-03,  1.8188e-02],
        [ 1.7609e-02, -4.0436e-02,  1.9424e-02,  ..., -1.1826e-03,
          1.5831e-03,  2.7943e-03],
        [ 3.6560e-02, -2.1057e-02, -4.7150e-03,  ...,  5.4932e-03,
         -6.3858e-03,  8.3313e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8770, -3.3320,  0.6274,  ..., -4.0977, -3.6250, -3.8281]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 13:46:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of dead is alive
The opposite of in is out
The opposite of southeast is southwest
The opposite of forward is backward
The opposite of previously is subsequently
The opposite of below is above
The opposite of top is bottom
The opposite of mortal is
2024-07-26 13:46:35 root INFO     [order_1_approx] starting weight calculation for The opposite of forward is backward
The opposite of mortal is immortal
The opposite of southeast is southwest
The opposite of previously is subsequently
The opposite of below is above
The opposite of top is bottom
The opposite of dead is alive
The opposite of in is
2024-07-26 13:46:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 13:49:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0087, -0.1050,  0.0066,  ..., -0.0195, -0.2256,  0.0558],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8018, -4.0312,  1.7529,  ..., -3.3145,  0.4893, -4.8398],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0095,  0.0069, -0.0779,  ...,  0.0708,  0.0117,  0.0374],
        [ 0.0029,  0.0412,  0.0041,  ..., -0.0024, -0.0109,  0.0268],
        [ 0.0201, -0.0194, -0.0166,  ...,  0.0671,  0.0209,  0.0401],
        ...,
        [-0.0254, -0.0212, -0.0030,  ...,  0.0271,  0.0552, -0.0114],
        [ 0.0114, -0.0122,  0.0538,  ..., -0.0325, -0.0293, -0.0479],
        [ 0.0163, -0.0150, -0.0393,  ...,  0.0453,  0.0527,  0.0510]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4802, -4.0391,  2.4258,  ..., -2.0996,  0.2683, -4.5391]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 13:49:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of forward is backward
The opposite of mortal is immortal
The opposite of southeast is southwest
The opposite of previously is subsequently
The opposite of below is above
The opposite of top is bottom
The opposite of dead is alive
The opposite of in is
2024-07-26 13:49:16 root INFO     [order_1_approx] starting weight calculation for The opposite of below is above
The opposite of forward is backward
The opposite of southeast is southwest
The opposite of in is out
The opposite of top is bottom
The opposite of previously is subsequently
The opposite of mortal is immortal
The opposite of dead is
2024-07-26 13:49:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 13:52:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0403,  0.0067, -0.0074,  ..., -0.3599, -0.3726,  0.0793],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2715, -2.5938,  1.2949,  ..., -3.6680, -3.1953, -2.2070],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0356,  0.0013, -0.0115,  ...,  0.0243,  0.0217,  0.0339],
        [-0.0247,  0.0014,  0.0440,  ...,  0.0106,  0.0162,  0.0030],
        [ 0.0273, -0.0313,  0.0052,  ...,  0.0015, -0.0399, -0.0043],
        ...,
        [ 0.0274,  0.0056, -0.0097,  ..., -0.0127,  0.0112, -0.0187],
        [-0.0137, -0.0370,  0.0366,  ...,  0.0010,  0.0258, -0.0071],
        [ 0.0178,  0.0104,  0.0058,  ...,  0.0370, -0.0138,  0.0086]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1826, -2.7637,  1.1221,  ..., -3.0039, -3.0996, -2.7891]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 13:52:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of below is above
The opposite of forward is backward
The opposite of southeast is southwest
The opposite of in is out
The opposite of top is bottom
The opposite of previously is subsequently
The opposite of mortal is immortal
The opposite of dead is
2024-07-26 13:52:02 root INFO     [order_1_approx] starting weight calculation for The opposite of in is out
The opposite of dead is alive
The opposite of mortal is immortal
The opposite of previously is subsequently
The opposite of forward is backward
The opposite of top is bottom
The opposite of below is above
The opposite of southeast is
2024-07-26 13:52:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 13:54:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1219, -0.1815, -0.0469,  ...,  0.0410, -0.0509, -0.0121],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5879, -2.5000,  2.7891,  ..., -0.9097, -1.3760, -1.0957],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0228, -0.0528,  0.0205,  ...,  0.0069,  0.0095,  0.0354],
        [-0.0211,  0.0098,  0.0392,  ...,  0.0283,  0.0185, -0.0067],
        [-0.0248,  0.0007, -0.0112,  ..., -0.0017, -0.0418, -0.0153],
        ...,
        [ 0.0118,  0.0170,  0.0021,  ...,  0.0067,  0.0197,  0.0124],
        [-0.0136, -0.0141,  0.0175,  ...,  0.0156,  0.0594,  0.0302],
        [-0.0090,  0.0274,  0.0469,  ...,  0.0058, -0.0006,  0.0331]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.2812, -2.9336,  2.4023,  ..., -0.6689, -1.9062, -0.7822]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 13:54:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of in is out
The opposite of dead is alive
The opposite of mortal is immortal
The opposite of previously is subsequently
The opposite of forward is backward
The opposite of top is bottom
The opposite of below is above
The opposite of southeast is
2024-07-26 13:54:47 root INFO     [order_1_approx] starting weight calculation for The opposite of dead is alive
The opposite of in is out
The opposite of forward is backward
The opposite of below is above
The opposite of mortal is immortal
The opposite of southeast is southwest
The opposite of top is bottom
The opposite of previously is
2024-07-26 13:54:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 13:57:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0465, -0.1682,  0.0342,  ..., -0.2834, -0.4141,  0.2588],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8799, -3.3438,  0.4617,  ..., -2.1211, -2.8516, -4.9531],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0319, -0.0322, -0.0201,  ..., -0.0149, -0.0264,  0.0168],
        [-0.0509,  0.0310, -0.0588,  ...,  0.0178,  0.0369,  0.0244],
        [ 0.0247, -0.0291, -0.0019,  ...,  0.0386, -0.0178, -0.0306],
        ...,
        [-0.0002, -0.0337, -0.0513,  ...,  0.0254,  0.0167,  0.0131],
        [ 0.0568, -0.0328,  0.0346,  ...,  0.0653, -0.0243, -0.0414],
        [-0.0476, -0.0106, -0.0634,  ...,  0.0244,  0.0192,  0.0815]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1836, -2.7148,  0.8311,  ..., -1.5449, -3.4395, -4.7383]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 13:57:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of dead is alive
The opposite of in is out
The opposite of forward is backward
The opposite of below is above
The opposite of mortal is immortal
The opposite of southeast is southwest
The opposite of top is bottom
The opposite of previously is
2024-07-26 13:57:32 root INFO     [order_1_approx] starting weight calculation for The opposite of in is out
The opposite of southeast is southwest
The opposite of forward is backward
The opposite of below is above
The opposite of previously is subsequently
The opposite of dead is alive
The opposite of mortal is immortal
The opposite of top is
2024-07-26 13:57:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 14:00:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0559, -0.2290,  0.2542,  ...,  0.1008, -0.2050,  0.2590],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9805, -2.1992,  0.8262,  ..., -3.2754,  3.3242, -4.0859],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0686, -0.0430, -0.0036,  ..., -0.0114,  0.0292,  0.0337],
        [ 0.0269,  0.0393,  0.0202,  ..., -0.0093, -0.0311, -0.0223],
        [ 0.0232,  0.0066, -0.0236,  ...,  0.0093, -0.0236,  0.0166],
        ...,
        [ 0.0224, -0.0067,  0.0306,  ...,  0.0282,  0.0293, -0.0121],
        [ 0.0487, -0.0022, -0.0203,  ...,  0.0029,  0.0043, -0.0375],
        [ 0.0294, -0.0213,  0.0016,  ...,  0.0032,  0.0395,  0.0411]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3457, -2.1660,  0.1660,  ..., -2.9727,  3.7656, -3.3516]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 14:00:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of in is out
The opposite of southeast is southwest
The opposite of forward is backward
The opposite of below is above
The opposite of previously is subsequently
The opposite of dead is alive
The opposite of mortal is immortal
The opposite of top is
2024-07-26 14:00:17 root INFO     [order_1_approx] starting weight calculation for The opposite of mortal is immortal
The opposite of forward is backward
The opposite of in is out
The opposite of dead is alive
The opposite of previously is subsequently
The opposite of southeast is southwest
The opposite of top is bottom
The opposite of below is
2024-07-26 14:00:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 14:03:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1650, -0.3342,  0.1410,  ..., -0.2356, -0.3005,  0.0143],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5430, -1.9941,  1.7754,  ..., -0.3945,  2.7949, -0.6729],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0631, -0.0167, -0.0274,  ...,  0.0069,  0.0132,  0.0430],
        [ 0.0122,  0.0204,  0.0291,  ...,  0.0094, -0.0122,  0.0118],
        [ 0.0146, -0.0366,  0.0093,  ...,  0.0098, -0.0052,  0.0032],
        ...,
        [ 0.0364,  0.0057,  0.0238,  ..., -0.0157, -0.0004, -0.0319],
        [ 0.0421, -0.0153,  0.0104,  ..., -0.0057,  0.0155,  0.0028],
        [ 0.0002, -0.0066,  0.0450,  ...,  0.0097, -0.0098,  0.0082]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8130, -2.3262,  1.7656,  ...,  0.4429,  2.3223, -0.4255]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 14:03:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of mortal is immortal
The opposite of forward is backward
The opposite of in is out
The opposite of dead is alive
The opposite of previously is subsequently
The opposite of southeast is southwest
The opposite of top is bottom
The opposite of below is
2024-07-26 14:03:03 root INFO     [order_1_approx] starting weight calculation for The opposite of in is out
The opposite of dead is alive
The opposite of top is bottom
The opposite of mortal is immortal
The opposite of southeast is southwest
The opposite of previously is subsequently
The opposite of below is above
The opposite of forward is
2024-07-26 14:03:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 14:05:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0063, -0.0291, -0.1702,  ..., -0.1051,  0.0419,  0.3340],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1992, -2.9805,  0.9893,  ..., -1.7070, -2.1914, -1.7197],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0822, -0.0023,  0.0360,  ...,  0.0219,  0.0483,  0.0714],
        [-0.0057,  0.0369,  0.0127,  ...,  0.0061, -0.0093,  0.0146],
        [ 0.0217, -0.0163,  0.0110,  ...,  0.0316, -0.0315,  0.0075],
        ...,
        [ 0.0133,  0.0199, -0.0399,  ...,  0.0433,  0.0358, -0.0360],
        [ 0.0049, -0.0074, -0.0219,  ..., -0.0074,  0.0876, -0.0493],
        [-0.0129, -0.0039, -0.0324,  ...,  0.0019,  0.0145,  0.0232]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1349, -3.7305,  0.9707,  ..., -1.2979, -2.7695, -1.4863]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 14:05:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of in is out
The opposite of dead is alive
The opposite of top is bottom
The opposite of mortal is immortal
The opposite of southeast is southwest
The opposite of previously is subsequently
The opposite of below is above
The opposite of forward is
2024-07-26 14:05:47 root INFO     total operator prediction time: 1317.823011636734 seconds
2024-07-26 14:05:47 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - member
2024-07-26 14:05:47 root INFO     building operator meronyms - member
2024-07-26 14:05:48 root INFO     [order_1_approx] starting weight calculation for A bird is a member of a flock
A nomad is a member of a horde
A elephant is a member of a herd
A car is a member of a train
A citizen is a member of a citizenry
A senator is a member of a senate
A letter is a member of a alphabet
A secretary is a member of a
2024-07-26 14:05:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 14:08:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1104,  0.0307, -0.2947,  ..., -0.1013, -0.1052,  0.0972],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3945, -2.0332,  2.3066,  ...,  1.0537, -1.4180, -1.8438],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0129, -0.0004,  0.0355,  ...,  0.0081, -0.0067,  0.0401],
        [ 0.0303,  0.0274,  0.0026,  ...,  0.0266, -0.0035, -0.0411],
        [-0.0064,  0.0101,  0.0345,  ...,  0.0045,  0.0029,  0.0352],
        ...,
        [ 0.0186,  0.0619,  0.0465,  ...,  0.0426,  0.0333, -0.0135],
        [ 0.0163, -0.0065, -0.0306,  ...,  0.0157,  0.0106, -0.0266],
        [ 0.0138, -0.0246,  0.0055,  ..., -0.0159,  0.0086,  0.0243]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9834, -0.8066,  2.4785,  ...,  1.0908, -0.9937, -1.4229]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 14:08:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A bird is a member of a flock
A nomad is a member of a horde
A elephant is a member of a herd
A car is a member of a train
A citizen is a member of a citizenry
A senator is a member of a senate
A letter is a member of a alphabet
A secretary is a member of a
2024-07-26 14:08:33 root INFO     [order_1_approx] starting weight calculation for A letter is a member of a alphabet
A car is a member of a train
A senator is a member of a senate
A citizen is a member of a citizenry
A nomad is a member of a horde
A secretary is a member of a staff
A bird is a member of a flock
A elephant is a member of a
2024-07-26 14:08:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 14:11:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0505,  0.0012, -0.0667,  ..., -0.0946, -0.2888, -0.1301],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 8.5391, -3.3730,  1.3164,  ..., -2.6660, -3.9648, -0.7974],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0063,  0.0250,  0.0152,  ...,  0.0195, -0.0043, -0.0099],
        [-0.0097,  0.0075, -0.0008,  ..., -0.0057, -0.0096,  0.0046],
        [-0.0210, -0.0030,  0.0028,  ...,  0.0055,  0.0054, -0.0154],
        ...,
        [-0.0021, -0.0019, -0.0004,  ...,  0.0104,  0.0073, -0.0077],
        [ 0.0251,  0.0026,  0.0094,  ..., -0.0073,  0.0053, -0.0050],
        [ 0.0217, -0.0243,  0.0012,  ..., -0.0270, -0.0060,  0.0308]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 8.2422, -3.1543,  1.1484,  ..., -2.5781, -3.8828, -0.5928]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 14:11:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A letter is a member of a alphabet
A car is a member of a train
A senator is a member of a senate
A citizen is a member of a citizenry
A nomad is a member of a horde
A secretary is a member of a staff
A bird is a member of a flock
A elephant is a member of a
2024-07-26 14:11:18 root INFO     [order_1_approx] starting weight calculation for A car is a member of a train
A elephant is a member of a herd
A senator is a member of a senate
A secretary is a member of a staff
A nomad is a member of a horde
A citizen is a member of a citizenry
A letter is a member of a alphabet
A bird is a member of a
2024-07-26 14:11:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 14:14:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0078,  0.0764,  0.1256,  ...,  0.0550, -0.0303, -0.2146],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0234, -3.5938,  2.4688,  ..., -1.9785, -4.3867, -0.5684],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0437,  0.0068,  0.0348,  ..., -0.0071, -0.0086,  0.0450],
        [-0.0023,  0.0493,  0.0226,  ...,  0.0077,  0.0130, -0.0286],
        [-0.0159, -0.0160,  0.0474,  ...,  0.0029,  0.0064,  0.0118],
        ...,
        [ 0.0253,  0.0283, -0.0082,  ...,  0.0344,  0.0122, -0.0094],
        [ 0.0267, -0.0182,  0.0125,  ...,  0.0117,  0.0443,  0.0061],
        [ 0.0056,  0.0041,  0.0132,  ..., -0.0048, -0.0134,  0.0391]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7402, -3.4668,  2.2383,  ..., -2.0938, -4.1250, -0.6318]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 14:14:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A car is a member of a train
A elephant is a member of a herd
A senator is a member of a senate
A secretary is a member of a staff
A nomad is a member of a horde
A citizen is a member of a citizenry
A letter is a member of a alphabet
A bird is a member of a
2024-07-26 14:14:03 root INFO     [order_1_approx] starting weight calculation for A secretary is a member of a staff
A car is a member of a train
A bird is a member of a flock
A senator is a member of a senate
A citizen is a member of a citizenry
A elephant is a member of a herd
A letter is a member of a alphabet
A nomad is a member of a
2024-07-26 14:14:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 14:16:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0048,  0.0395, -0.3140,  ...,  0.1758, -0.1340,  0.2196],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7021, -1.8857,  0.3726,  ..., -1.3711, -2.2227, -0.0054],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0535, -0.0251,  0.0349,  ..., -0.0157, -0.0166, -0.0412],
        [ 0.0088,  0.0450, -0.0057,  ...,  0.0310, -0.0179,  0.0081],
        [ 0.0179, -0.0045,  0.0369,  ..., -0.0301, -0.0099,  0.0042],
        ...,
        [ 0.0043,  0.0044,  0.0068,  ...,  0.0699,  0.0013, -0.0037],
        [ 0.0114,  0.0018, -0.0358,  ..., -0.0270,  0.0211,  0.0064],
        [-0.0076,  0.0105,  0.0047,  ...,  0.0293,  0.0037,  0.0758]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1904, -1.2480,  0.2849,  ..., -1.3701, -1.8057,  0.4365]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 14:16:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A secretary is a member of a staff
A car is a member of a train
A bird is a member of a flock
A senator is a member of a senate
A citizen is a member of a citizenry
A elephant is a member of a herd
A letter is a member of a alphabet
A nomad is a member of a
2024-07-26 14:16:48 root INFO     [order_1_approx] starting weight calculation for A nomad is a member of a horde
A senator is a member of a senate
A secretary is a member of a staff
A bird is a member of a flock
A citizen is a member of a citizenry
A letter is a member of a alphabet
A elephant is a member of a herd
A car is a member of a
2024-07-26 14:16:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 14:19:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1523,  0.0768, -0.1150,  ...,  0.0532, -0.0592, -0.0383],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9756, -3.7930,  2.9492,  ..., -0.8228, -1.3066, -0.5781],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0043,  0.0092, -0.0013,  ...,  0.0001,  0.0044, -0.0025],
        [ 0.0021,  0.0015, -0.0418,  ..., -0.0160, -0.0130,  0.0031],
        [ 0.0109,  0.0250,  0.0367,  ...,  0.0162,  0.0175,  0.0027],
        ...,
        [ 0.0293, -0.0170, -0.0377,  ...,  0.0146,  0.0127,  0.0060],
        [-0.0328,  0.0518,  0.0739,  ...,  0.0629,  0.0389, -0.0492],
        [ 0.0387, -0.0746, -0.0624,  ..., -0.0523, -0.0110,  0.0778]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8691, -2.9473,  2.9922,  ..., -0.3992, -2.3398,  0.7002]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 14:19:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A nomad is a member of a horde
A senator is a member of a senate
A secretary is a member of a staff
A bird is a member of a flock
A citizen is a member of a citizenry
A letter is a member of a alphabet
A elephant is a member of a herd
A car is a member of a
2024-07-26 14:19:34 root INFO     [order_1_approx] starting weight calculation for A nomad is a member of a horde
A car is a member of a train
A senator is a member of a senate
A secretary is a member of a staff
A letter is a member of a alphabet
A bird is a member of a flock
A elephant is a member of a herd
A citizen is a member of a
2024-07-26 14:19:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 14:22:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0802,  0.1033, -0.2394,  ..., -0.0838,  0.0785, -0.1019],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4434, -6.5195,  2.9551,  ..., -4.5234,  0.7607, -1.1211],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0357,  0.0172,  0.0181,  ...,  0.0273,  0.0397, -0.0160],
        [ 0.0469, -0.0278, -0.0003,  ..., -0.0161, -0.0370,  0.0266],
        [-0.0096,  0.0121,  0.0079,  ..., -0.0037,  0.0171, -0.0124],
        ...,
        [ 0.0518, -0.0341, -0.0023,  ..., -0.0148, -0.0400,  0.0077],
        [-0.0141,  0.0117, -0.0121,  ..., -0.0011,  0.0279, -0.0038],
        [ 0.0255, -0.0130, -0.0032,  ..., -0.0137, -0.0230,  0.0109]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9028, -5.9375,  2.7715,  ..., -3.9570,  0.5010, -0.9307]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 14:22:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A nomad is a member of a horde
A car is a member of a train
A senator is a member of a senate
A secretary is a member of a staff
A letter is a member of a alphabet
A bird is a member of a flock
A elephant is a member of a herd
A citizen is a member of a
2024-07-26 14:22:17 root INFO     [order_1_approx] starting weight calculation for A elephant is a member of a herd
A car is a member of a train
A letter is a member of a alphabet
A bird is a member of a flock
A nomad is a member of a horde
A citizen is a member of a citizenry
A secretary is a member of a staff
A senator is a member of a
2024-07-26 14:22:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 14:25:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0391,  0.3689, -0.2318,  ...,  0.0895, -0.0862,  0.2373],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7207, -3.5625,  4.2148,  ..., -0.8042,  0.5527,  0.0557],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0268, -0.0112,  0.0019,  ..., -0.0029, -0.0138,  0.0363],
        [ 0.0137, -0.0141,  0.0073,  ..., -0.0434,  0.0048,  0.0416],
        [-0.0262,  0.0129,  0.0220,  ...,  0.0320, -0.0141, -0.0319],
        ...,
        [ 0.0331,  0.0073,  0.0132,  ...,  0.0314,  0.0089, -0.0231],
        [-0.0129,  0.0084, -0.0191,  ...,  0.0255,  0.0147, -0.0146],
        [ 0.0037, -0.0427,  0.0059,  ..., -0.0621, -0.0035,  0.0745]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9834, -2.8164,  4.0273,  ..., -0.9805,  0.1631,  0.5986]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 14:25:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A elephant is a member of a herd
A car is a member of a train
A letter is a member of a alphabet
A bird is a member of a flock
A nomad is a member of a horde
A citizen is a member of a citizenry
A secretary is a member of a staff
A senator is a member of a
2024-07-26 14:25:03 root INFO     [order_1_approx] starting weight calculation for A bird is a member of a flock
A senator is a member of a senate
A citizen is a member of a citizenry
A nomad is a member of a horde
A elephant is a member of a herd
A car is a member of a train
A secretary is a member of a staff
A letter is a member of a
2024-07-26 14:25:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 14:27:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1118,  0.0728, -0.3950,  ..., -0.1088, -0.0856, -0.0343],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1953, -2.8398, -0.5693,  ...,  0.5596, -3.5254, -1.9590],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0667,  0.0301,  0.0175,  ..., -0.0300,  0.0002, -0.0028],
        [ 0.0060,  0.0220, -0.0121,  ...,  0.0162, -0.0098,  0.0142],
        [ 0.0261, -0.0529, -0.0068,  ...,  0.0552, -0.0062,  0.0056],
        ...,
        [ 0.0272,  0.0101, -0.0015,  ...,  0.0294,  0.0144, -0.0485],
        [ 0.0114, -0.0037, -0.0165,  ..., -0.0129,  0.0107,  0.0051],
        [-0.0062, -0.0812, -0.0057,  ...,  0.0159,  0.0160,  0.0474]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7568, -2.5664,  0.0352,  ...,  0.6187, -3.7969, -1.0898]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 14:27:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A bird is a member of a flock
A senator is a member of a senate
A citizen is a member of a citizenry
A nomad is a member of a horde
A elephant is a member of a herd
A car is a member of a train
A secretary is a member of a staff
A letter is a member of a
2024-07-26 14:27:48 root INFO     total operator prediction time: 1320.5834953784943 seconds
2024-07-26 14:27:48 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun - plural_irreg
2024-07-26 14:27:48 root INFO     building operator noun - plural_irreg
2024-07-26 14:27:48 root INFO     [order_1_approx] starting weight calculation for The plural form of category is categories
The plural form of technology is technologies
The plural form of success is successes
The plural form of property is properties
The plural form of society is societies
The plural form of economy is economies
The plural form of child is children
The plural form of series is
2024-07-26 14:27:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 14:30:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0792, -0.2549, -0.1187,  ...,  0.0219, -0.1602,  0.3149],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6562, -2.3594, -0.0283,  ..., -1.6279, -0.4258, -2.7852],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0450, -0.0168, -0.0336,  ..., -0.0256,  0.0032, -0.0171],
        [ 0.0268,  0.0298,  0.0029,  ..., -0.0015, -0.0018,  0.0044],
        [-0.0165,  0.0212,  0.0146,  ...,  0.0073,  0.0030,  0.0352],
        ...,
        [ 0.0082,  0.0327,  0.0350,  ...,  0.0199,  0.0013,  0.0167],
        [ 0.0033,  0.0070, -0.0211,  ...,  0.0311,  0.0220,  0.0011],
        [ 0.0332, -0.0164, -0.0163,  ..., -0.0003,  0.0078,  0.0423]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2029, -2.4961,  0.1881,  ..., -1.3252, -0.0269, -2.7598]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 14:30:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of category is categories
The plural form of technology is technologies
The plural form of success is successes
The plural form of property is properties
The plural form of society is societies
The plural form of economy is economies
The plural form of child is children
The plural form of series is
2024-07-26 14:30:34 root INFO     [order_1_approx] starting weight calculation for The plural form of category is categories
The plural form of technology is technologies
The plural form of child is children
The plural form of series is series
The plural form of society is societies
The plural form of success is successes
The plural form of property is properties
The plural form of economy is
2024-07-26 14:30:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 14:33:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1785,  0.2520, -0.1768,  ..., -0.2103, -0.1423,  0.1270],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5254, -0.9219, -1.5547,  ..., -2.0703, -2.3926, -2.5410],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0499, -0.0010, -0.0047,  ...,  0.0202,  0.0083, -0.0185],
        [ 0.0082,  0.0578,  0.0253,  ...,  0.0007, -0.0275,  0.0088],
        [-0.0354, -0.0020,  0.0246,  ..., -0.0315, -0.0149,  0.0070],
        ...,
        [ 0.0111,  0.0255,  0.0050,  ...,  0.0128,  0.0138, -0.0083],
        [-0.0219, -0.0234, -0.0162,  ...,  0.0073,  0.0264,  0.0093],
        [-0.0034,  0.0036, -0.0284,  ...,  0.0431, -0.0164,  0.0117]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4263, -1.0596, -1.6113,  ..., -2.3047, -2.5371, -2.3828]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 14:33:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of category is categories
The plural form of technology is technologies
The plural form of child is children
The plural form of series is series
The plural form of society is societies
The plural form of success is successes
The plural form of property is properties
The plural form of economy is
2024-07-26 14:33:21 root INFO     [order_1_approx] starting weight calculation for The plural form of category is categories
The plural form of success is successes
The plural form of economy is economies
The plural form of property is properties
The plural form of technology is technologies
The plural form of society is societies
The plural form of series is series
The plural form of child is
2024-07-26 14:33:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 14:36:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1061, -0.1479,  0.0947,  ..., -0.0647, -0.5547,  0.1685],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4355, -2.2891,  1.7695,  ..., -1.1836, -0.4351, -2.4531],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0120, -0.0141, -0.0161,  ...,  0.0193, -0.0022, -0.0082],
        [-0.0016,  0.0160,  0.0032,  ...,  0.0186, -0.0513, -0.0116],
        [ 0.0032, -0.0169, -0.0015,  ...,  0.0027, -0.0215,  0.0127],
        ...,
        [-0.0135, -0.0047, -0.0172,  ..., -0.0019, -0.0172,  0.0082],
        [-0.0289,  0.0220, -0.0036,  ...,  0.0122,  0.0128, -0.0313],
        [ 0.0140, -0.0583, -0.0288,  ...,  0.0240, -0.0648,  0.0141]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1602, -2.1387,  1.5977,  ..., -1.3477, -0.7114, -2.2227]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 14:36:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of category is categories
The plural form of success is successes
The plural form of economy is economies
The plural form of property is properties
The plural form of technology is technologies
The plural form of society is societies
The plural form of series is series
The plural form of child is
2024-07-26 14:36:07 root INFO     [order_1_approx] starting weight calculation for The plural form of success is successes
The plural form of society is societies
The plural form of economy is economies
The plural form of child is children
The plural form of series is series
The plural form of technology is technologies
The plural form of category is categories
The plural form of property is
2024-07-26 14:36:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 14:38:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0609, -0.2588, -0.0428,  ..., -0.1588, -0.0452,  0.0807],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5938, -3.4844,  1.0312,  ..., -0.8804, -2.5078, -1.5547],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.4810e-02, -4.2458e-03, -1.5656e-02,  ...,  8.8806e-03,
          2.4826e-02,  3.7659e-02],
        [ 5.6076e-03,  2.2339e-02,  2.2827e-02,  ..., -3.3989e-03,
         -1.2062e-02,  1.0277e-02],
        [-9.1553e-05,  1.4099e-02,  1.5152e-02,  ..., -5.5771e-03,
         -7.2632e-03, -5.2109e-03],
        ...,
        [ 1.8845e-02,  1.8799e-02,  6.2752e-04,  ..., -1.1215e-03,
         -3.3264e-03, -3.6255e-02],
        [ 2.2583e-03, -1.5778e-02, -2.3529e-02,  ..., -7.5684e-03,
          7.8011e-03, -2.5299e-02],
        [ 2.4628e-02,  3.9825e-03,  5.6763e-03,  ...,  2.1332e-02,
         -2.2461e-02,  1.6357e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9404, -3.5996,  0.7871,  ..., -1.1465, -2.6113, -1.5293]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 14:38:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of success is successes
The plural form of society is societies
The plural form of economy is economies
The plural form of child is children
The plural form of series is series
The plural form of technology is technologies
The plural form of category is categories
The plural form of property is
2024-07-26 14:38:54 root INFO     [order_1_approx] starting weight calculation for The plural form of child is children
The plural form of success is successes
The plural form of economy is economies
The plural form of series is series
The plural form of society is societies
The plural form of property is properties
The plural form of technology is technologies
The plural form of category is
2024-07-26 14:38:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 14:41:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2551,  0.0214,  0.0626,  ...,  0.1091, -0.4524,  0.1592],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6870, -2.6133,  1.8125,  ..., -0.8340,  0.0347, -2.0801],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0365, -0.0048, -0.0536,  ..., -0.0049, -0.0405, -0.0012],
        [-0.0104,  0.0682,  0.0448,  ..., -0.0042, -0.0266,  0.0196],
        [-0.0179,  0.0009,  0.0145,  ..., -0.0018,  0.0075, -0.0032],
        ...,
        [-0.0113,  0.0149,  0.0211,  ...,  0.0181,  0.0042,  0.0105],
        [ 0.0020, -0.0030,  0.0013,  ..., -0.0058,  0.0422, -0.0011],
        [ 0.0345, -0.0088, -0.0306,  ...,  0.0193, -0.0624,  0.0257]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6021, -2.8164,  1.5117,  ..., -0.9424, -0.2253, -2.2051]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 14:41:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of child is children
The plural form of success is successes
The plural form of economy is economies
The plural form of series is series
The plural form of society is societies
The plural form of property is properties
The plural form of technology is technologies
The plural form of category is
2024-07-26 14:41:40 root INFO     [order_1_approx] starting weight calculation for The plural form of property is properties
The plural form of success is successes
The plural form of child is children
The plural form of series is series
The plural form of category is categories
The plural form of society is societies
The plural form of economy is economies
The plural form of technology is
2024-07-26 14:41:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 14:44:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1947, -0.0452,  0.1346,  ...,  0.1193, -0.1599,  0.1235],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3164, -0.6729,  0.5366,  ...,  1.2988, -4.3516, -2.3242],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0164, -0.0073, -0.0126,  ...,  0.0216, -0.0067, -0.0157],
        [-0.0005,  0.0388, -0.0149,  ...,  0.0053, -0.0153, -0.0058],
        [ 0.0084,  0.0072, -0.0088,  ..., -0.0062, -0.0057,  0.0077],
        ...,
        [-0.0026,  0.0298, -0.0060,  ...,  0.0508, -0.0199,  0.0018],
        [ 0.0241, -0.0189, -0.0106,  ..., -0.0050,  0.0543,  0.0212],
        [ 0.0339, -0.0245, -0.0117,  ...,  0.0113, -0.0136, -0.0054]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3438, -0.8315,  0.0593,  ...,  0.3218, -3.9531, -2.0586]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 14:44:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of property is properties
The plural form of success is successes
The plural form of child is children
The plural form of series is series
The plural form of category is categories
The plural form of society is societies
The plural form of economy is economies
The plural form of technology is
2024-07-26 14:44:27 root INFO     [order_1_approx] starting weight calculation for The plural form of category is categories
The plural form of technology is technologies
The plural form of series is series
The plural form of economy is economies
The plural form of property is properties
The plural form of success is successes
The plural form of child is children
The plural form of society is
2024-07-26 14:44:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 14:47:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0575, -0.0996, -0.1469,  ...,  0.0300, -0.2590,  0.0848],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3193, -0.6387,  1.2500,  ..., -2.3477, -0.3315, -2.0156],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0382, -0.0203, -0.0119,  ...,  0.0164,  0.0052, -0.0381],
        [ 0.0346,  0.0230,  0.0248,  ..., -0.0007, -0.0311,  0.0043],
        [-0.0079, -0.0154,  0.0138,  ...,  0.0119, -0.0249,  0.0013],
        ...,
        [ 0.0132,  0.0100,  0.0067,  ...,  0.0510, -0.0063,  0.0016],
        [ 0.0199, -0.0283, -0.0454,  ...,  0.0293,  0.0176, -0.0324],
        [ 0.0203, -0.0172, -0.0211,  ...,  0.0083, -0.0118,  0.0175]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7012, -0.6304,  1.2490,  ..., -2.4492, -0.3093, -2.3828]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 14:47:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of category is categories
The plural form of technology is technologies
The plural form of series is series
The plural form of economy is economies
The plural form of property is properties
The plural form of success is successes
The plural form of child is children
The plural form of society is
2024-07-26 14:47:13 root INFO     [order_1_approx] starting weight calculation for The plural form of economy is economies
The plural form of child is children
The plural form of technology is technologies
The plural form of society is societies
The plural form of series is series
The plural form of category is categories
The plural form of property is properties
The plural form of success is
2024-07-26 14:47:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 14:49:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2477,  0.0142,  0.1069,  ...,  0.1530, -0.2107,  0.3413],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1074, -0.1523, -1.3945,  ..., -1.2764, -2.8965, -2.5879],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0440, -0.0026, -0.0006,  ..., -0.0070, -0.0047, -0.0066],
        [-0.0161,  0.0348, -0.0029,  ...,  0.0213, -0.0120,  0.0059],
        [ 0.0143, -0.0080, -0.0009,  ..., -0.0177, -0.0139,  0.0151],
        ...,
        [ 0.0081,  0.0089, -0.0002,  ...,  0.0058, -0.0118,  0.0023],
        [-0.0107,  0.0002, -0.0240,  ..., -0.0129, -0.0076, -0.0212],
        [ 0.0133, -0.0280, -0.0240,  ...,  0.0580,  0.0150,  0.0145]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0508, -0.7373, -1.4590,  ..., -1.1855, -2.8809, -2.2734]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 14:49:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of economy is economies
The plural form of child is children
The plural form of technology is technologies
The plural form of society is societies
The plural form of series is series
The plural form of category is categories
The plural form of property is properties
The plural form of success is
2024-07-26 14:49:58 root INFO     total operator prediction time: 1330.0538609027863 seconds
2024-07-26 14:49:58 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on Ving - verb_inf
2024-07-26 14:49:58 root INFO     building operator Ving - verb_inf
2024-07-26 14:49:58 root INFO     [order_1_approx] starting weight calculation for losing is the active form of lose
developing is the active form of develop
encouraging is the active form of encourage
achieving is the active form of achieve
managing is the active form of manage
learning is the active form of learn
involving is the active form of involve
promoting is the active form of
2024-07-26 14:49:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 14:52:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0438,  0.1998,  0.0153,  ..., -0.0608, -0.0316, -0.0255],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5859, -3.6250, -0.0283,  ...,  2.5254, -2.4414, -2.4102],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0402, -0.0113,  0.0072,  ..., -0.0242, -0.0435, -0.0059],
        [-0.0204,  0.0235, -0.0051,  ...,  0.0050, -0.0079, -0.0004],
        [ 0.0021, -0.0157,  0.0138,  ..., -0.0106, -0.0216, -0.0120],
        ...,
        [ 0.0125,  0.0063, -0.0037,  ...,  0.0265, -0.0047, -0.0122],
        [-0.0089,  0.0008, -0.0085,  ...,  0.0336,  0.0289,  0.0047],
        [ 0.0123,  0.0033, -0.0198,  ...,  0.0136, -0.0046,  0.0324]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3535, -3.6504, -0.1870,  ...,  2.8086, -2.4941, -2.5684]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 14:52:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for losing is the active form of lose
developing is the active form of develop
encouraging is the active form of encourage
achieving is the active form of achieve
managing is the active form of manage
learning is the active form of learn
involving is the active form of involve
promoting is the active form of
2024-07-26 14:52:44 root INFO     [order_1_approx] starting weight calculation for involving is the active form of involve
encouraging is the active form of encourage
developing is the active form of develop
achieving is the active form of achieve
losing is the active form of lose
managing is the active form of manage
promoting is the active form of promote
learning is the active form of
2024-07-26 14:52:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 14:55:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0121,  0.0352, -0.0176,  ...,  0.0817, -0.2856, -0.0137],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7598, -4.5430,  1.4590,  ...,  3.1836, -1.0635, -6.2109],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0410, -0.0077, -0.0172,  ...,  0.0005, -0.0081, -0.0088],
        [-0.0215,  0.0235,  0.0201,  ..., -0.0153, -0.0068, -0.0065],
        [-0.0129,  0.0045,  0.0153,  ..., -0.0124, -0.0134, -0.0202],
        ...,
        [-0.0301,  0.0176,  0.0099,  ...,  0.0171, -0.0092, -0.0094],
        [-0.0030,  0.0074,  0.0229,  ...,  0.0195,  0.0435,  0.0016],
        [ 0.0406, -0.0057,  0.0185,  ..., -0.0030,  0.0150,  0.0266]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9043, -5.1836,  1.3457,  ...,  2.6543, -1.0420, -6.3828]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 14:55:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for involving is the active form of involve
encouraging is the active form of encourage
developing is the active form of develop
achieving is the active form of achieve
losing is the active form of lose
managing is the active form of manage
promoting is the active form of promote
learning is the active form of
2024-07-26 14:55:30 root INFO     [order_1_approx] starting weight calculation for promoting is the active form of promote
losing is the active form of lose
managing is the active form of manage
involving is the active form of involve
achieving is the active form of achieve
developing is the active form of develop
learning is the active form of learn
encouraging is the active form of
2024-07-26 14:55:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 14:58:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2861,  0.0577, -0.0189,  ...,  0.0764, -0.2878, -0.1193],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7168, -3.3398, -0.8701,  ...,  3.9512, -1.3076, -3.4297],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.9940e-03, -2.4948e-03, -4.3373e-03,  ..., -2.1858e-03,
         -1.9974e-02,  1.7059e-02],
        [ 4.3201e-04,  7.2746e-03, -3.4332e-03,  ...,  7.6981e-03,
         -1.0315e-02, -7.1411e-03],
        [ 2.4834e-03,  5.6801e-03,  1.6434e-02,  ...,  7.3910e-05,
          4.5624e-03, -1.2909e-02],
        ...,
        [ 1.3638e-03,  6.2637e-03,  3.5229e-03,  ...,  2.7557e-02,
          1.8311e-04, -4.7226e-03],
        [-1.1681e-02, -3.6640e-03, -9.9258e-03,  ..., -1.5678e-03,
          1.2222e-02, -5.8784e-03],
        [-4.0131e-03, -1.3748e-02, -1.5808e-02,  ...,  3.2463e-03,
          3.6983e-03,  1.6251e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8525, -3.4199, -0.6260,  ...,  3.9883, -1.4014, -3.5312]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 14:58:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for promoting is the active form of promote
losing is the active form of lose
managing is the active form of manage
involving is the active form of involve
achieving is the active form of achieve
developing is the active form of develop
learning is the active form of learn
encouraging is the active form of
2024-07-26 14:58:15 root INFO     [order_1_approx] starting weight calculation for managing is the active form of manage
learning is the active form of learn
developing is the active form of develop
losing is the active form of lose
achieving is the active form of achieve
encouraging is the active form of encourage
promoting is the active form of promote
involving is the active form of
2024-07-26 14:58:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 15:01:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0315,  0.0343,  0.0614,  ...,  0.1775, -0.4973,  0.0265],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2910, -2.1426,  1.5459,  ...,  2.1895,  0.2091, -5.0938],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0277, -0.0184, -0.0095,  ...,  0.0033,  0.0035, -0.0062],
        [ 0.0044,  0.0346,  0.0036,  ..., -0.0079, -0.0306,  0.0109],
        [-0.0035, -0.0048,  0.0132,  ..., -0.0006, -0.0037, -0.0078],
        ...,
        [-0.0106,  0.0103,  0.0077,  ...,  0.0331, -0.0052, -0.0025],
        [ 0.0009, -0.0158, -0.0069,  ...,  0.0101,  0.0090,  0.0076],
        [ 0.0133,  0.0038,  0.0012,  ..., -0.0199,  0.0116,  0.0267]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4626, -2.6914,  1.4434,  ...,  2.0547,  0.0842, -5.2070]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 15:01:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for managing is the active form of manage
learning is the active form of learn
developing is the active form of develop
losing is the active form of lose
achieving is the active form of achieve
encouraging is the active form of encourage
promoting is the active form of promote
involving is the active form of
2024-07-26 15:01:02 root INFO     [order_1_approx] starting weight calculation for learning is the active form of learn
involving is the active form of involve
promoting is the active form of promote
achieving is the active form of achieve
managing is the active form of manage
losing is the active form of lose
encouraging is the active form of encourage
developing is the active form of
2024-07-26 15:01:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 15:03:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2849,  0.1122,  0.1763,  ..., -0.0812, -0.1702, -0.0858],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.2305, -4.0781,  2.5234,  ...,  2.2500, -1.8535, -3.0039],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0170, -0.0086, -0.0046,  ...,  0.0013, -0.0164, -0.0072],
        [-0.0015,  0.0096,  0.0033,  ...,  0.0080,  0.0069,  0.0004],
        [-0.0141, -0.0153, -0.0032,  ..., -0.0023, -0.0007, -0.0073],
        ...,
        [-0.0033, -0.0012, -0.0036,  ...,  0.0173, -0.0073,  0.0025],
        [ 0.0007,  0.0054,  0.0048,  ..., -0.0005,  0.0206,  0.0031],
        [-0.0001,  0.0074,  0.0022,  ..., -0.0009, -0.0100,  0.0153]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.3164, -4.0742,  2.4746,  ...,  2.1777, -2.0078, -3.0820]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 15:03:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for learning is the active form of learn
involving is the active form of involve
promoting is the active form of promote
achieving is the active form of achieve
managing is the active form of manage
losing is the active form of lose
encouraging is the active form of encourage
developing is the active form of
2024-07-26 15:03:50 root INFO     [order_1_approx] starting weight calculation for achieving is the active form of achieve
promoting is the active form of promote
involving is the active form of involve
learning is the active form of learn
developing is the active form of develop
managing is the active form of manage
encouraging is the active form of encourage
losing is the active form of
2024-07-26 15:03:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 15:06:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0101,  0.0684,  0.0900,  ...,  0.0195,  0.0695,  0.0375],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4668, -2.8086, -0.2930,  ...,  1.1650,  1.1875, -2.2109],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0208, -0.0177, -0.0172,  ...,  0.0168, -0.0132, -0.0145],
        [-0.0053,  0.0411,  0.0084,  ..., -0.0181,  0.0003, -0.0116],
        [-0.0014,  0.0040,  0.0100,  ..., -0.0035, -0.0087, -0.0236],
        ...,
        [ 0.0052, -0.0130, -0.0120,  ...,  0.0128, -0.0146,  0.0078],
        [-0.0015,  0.0134,  0.0145,  ..., -0.0010,  0.0213, -0.0066],
        [-0.0064,  0.0232,  0.0177,  ..., -0.0044, -0.0006,  0.0292]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6904, -3.0078, -0.2812,  ...,  1.0850,  0.9883, -2.2852]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 15:06:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for achieving is the active form of achieve
promoting is the active form of promote
involving is the active form of involve
learning is the active form of learn
developing is the active form of develop
managing is the active form of manage
encouraging is the active form of encourage
losing is the active form of
2024-07-26 15:06:37 root INFO     [order_1_approx] starting weight calculation for learning is the active form of learn
losing is the active form of lose
involving is the active form of involve
encouraging is the active form of encourage
developing is the active form of develop
promoting is the active form of promote
achieving is the active form of achieve
managing is the active form of
2024-07-26 15:06:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 15:09:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0916,  0.4944,  0.0735,  ...,  0.0920, -0.2646, -0.2463],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9941, -4.1562,  1.2861,  ...,  2.4531, -1.6543, -3.5664],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0281, -0.0045,  0.0040,  ...,  0.0058, -0.0099, -0.0008],
        [-0.0020,  0.0113, -0.0019,  ...,  0.0022, -0.0091,  0.0051],
        [-0.0137, -0.0100,  0.0191,  ..., -0.0037, -0.0230, -0.0143],
        ...,
        [ 0.0046,  0.0260,  0.0010,  ...,  0.0175, -0.0040,  0.0041],
        [-0.0051,  0.0291, -0.0081,  ...,  0.0129,  0.0246,  0.0280],
        [ 0.0136, -0.0071, -0.0015,  ...,  0.0030, -0.0096,  0.0253]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0820, -4.1445,  1.1738,  ...,  2.4199, -1.6689, -3.6855]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 15:09:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for learning is the active form of learn
losing is the active form of lose
involving is the active form of involve
encouraging is the active form of encourage
developing is the active form of develop
promoting is the active form of promote
achieving is the active form of achieve
managing is the active form of
2024-07-26 15:09:18 root INFO     [order_1_approx] starting weight calculation for developing is the active form of develop
losing is the active form of lose
encouraging is the active form of encourage
promoting is the active form of promote
managing is the active form of manage
involving is the active form of involve
learning is the active form of learn
achieving is the active form of
2024-07-26 15:09:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 15:12:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0222,  0.3325,  0.1272,  ..., -0.0546, -0.3474,  0.0039],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3379, -2.2148, -0.2949,  ...,  1.2139, -1.9355, -3.2012],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0135,  0.0006,  0.0074,  ...,  0.0116, -0.0137,  0.0004],
        [-0.0249,  0.0257, -0.0019,  ...,  0.0018, -0.0083,  0.0047],
        [ 0.0028,  0.0072,  0.0125,  ..., -0.0114, -0.0091, -0.0094],
        ...,
        [ 0.0127,  0.0069,  0.0061,  ...,  0.0296, -0.0054, -0.0125],
        [-0.0138, -0.0085, -0.0028,  ...,  0.0187,  0.0174, -0.0017],
        [ 0.0311,  0.0070, -0.0154,  ..., -0.0057,  0.0035,  0.0260]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8516, -2.0723, -0.3547,  ...,  1.4688, -2.1055, -3.3711]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 15:12:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for developing is the active form of develop
losing is the active form of lose
encouraging is the active form of encourage
promoting is the active form of promote
managing is the active form of manage
involving is the active form of involve
learning is the active form of learn
achieving is the active form of
2024-07-26 15:12:04 root INFO     total operator prediction time: 1325.566172838211 seconds
2024-07-26 15:12:04 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_Ving - Ved
2024-07-26 15:12:04 root INFO     building operator verb_Ving - Ved
2024-07-26 15:12:04 root INFO     [order_1_approx] starting weight calculation for After something is improving, it has improved
After something is deciding, it has decided
After something is failing, it has failed
After something is understanding, it has understood
After something is relating, it has related
After something is marrying, it has married
After something is creating, it has created
After something is containing, it has
2024-07-26 15:12:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 15:14:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1165, -0.1418, -0.1004,  ...,  0.0387, -0.2278, -0.2391],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0000,  1.3945,  2.7715,  ..., -2.9922, -0.9580, -2.8398],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0062,  0.0025, -0.0330,  ...,  0.0324, -0.0152, -0.0073],
        [-0.0444,  0.0381,  0.0181,  ..., -0.0130, -0.0267,  0.0124],
        [ 0.0125, -0.0138,  0.0234,  ..., -0.0282, -0.0025, -0.0091],
        ...,
        [ 0.0038,  0.0196,  0.0038,  ..., -0.0073, -0.0075, -0.0062],
        [ 0.0304, -0.0319, -0.0143,  ..., -0.0055,  0.0588,  0.0176],
        [ 0.0024,  0.0129, -0.0106,  ...,  0.0070, -0.0276, -0.0043]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4629,  1.0449,  3.3242,  ..., -2.6934, -0.3560, -2.8711]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 15:14:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is improving, it has improved
After something is deciding, it has decided
After something is failing, it has failed
After something is understanding, it has understood
After something is relating, it has related
After something is marrying, it has married
After something is creating, it has created
After something is containing, it has
2024-07-26 15:14:50 root INFO     [order_1_approx] starting weight calculation for After something is creating, it has created
After something is improving, it has improved
After something is marrying, it has married
After something is containing, it has contained
After something is relating, it has related
After something is deciding, it has decided
After something is failing, it has failed
After something is understanding, it has
2024-07-26 15:14:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 15:17:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2157,  0.3359,  0.0866,  ...,  0.2262, -0.1960,  0.0054],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5137,  2.4668,  1.7822,  ..., -1.4854, -1.7998,  1.2285],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0103, -0.0003,  0.0081,  ..., -0.0082, -0.0072,  0.0233],
        [-0.0337,  0.0195,  0.0036,  ..., -0.0280, -0.0064, -0.0238],
        [ 0.0351, -0.0217,  0.0085,  ...,  0.0011,  0.0106, -0.0099],
        ...,
        [ 0.0186,  0.0102, -0.0188,  ...,  0.0294,  0.0024,  0.0032],
        [ 0.0163,  0.0062,  0.0236,  ..., -0.0244,  0.0308, -0.0327],
        [-0.0129,  0.0041, -0.0200,  ..., -0.0199, -0.0426, -0.0392]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7148,  2.5312,  1.9814,  ..., -1.6523, -1.6904,  0.7686]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 15:17:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is creating, it has created
After something is improving, it has improved
After something is marrying, it has married
After something is containing, it has contained
After something is relating, it has related
After something is deciding, it has decided
After something is failing, it has failed
After something is understanding, it has
2024-07-26 15:17:36 root INFO     [order_1_approx] starting weight calculation for After something is containing, it has contained
After something is failing, it has failed
After something is understanding, it has understood
After something is relating, it has related
After something is marrying, it has married
After something is deciding, it has decided
After something is improving, it has improved
After something is creating, it has
2024-07-26 15:17:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 15:20:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1128,  0.2202,  0.0112,  ...,  0.0165, -0.0347, -0.1046],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6782, -0.2554,  1.4209,  ..., -0.9756, -1.7793,  0.0762],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0048,  0.0059, -0.0314,  ...,  0.0374,  0.0007, -0.0052],
        [-0.0056,  0.0494,  0.0241,  ...,  0.0048, -0.0330, -0.0325],
        [ 0.0026, -0.0146,  0.0114,  ...,  0.0052,  0.0278,  0.0028],
        ...,
        [ 0.0166,  0.0133,  0.0045,  ...,  0.0053,  0.0148,  0.0078],
        [ 0.0092,  0.0152, -0.0151,  ...,  0.0007,  0.0153, -0.0068],
        [ 0.0003, -0.0035, -0.0006,  ..., -0.0135, -0.0130,  0.0158]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4258, -0.5542,  1.3691,  ..., -0.7935, -1.6582, -0.2114]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 15:20:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is containing, it has contained
After something is failing, it has failed
After something is understanding, it has understood
After something is relating, it has related
After something is marrying, it has married
After something is deciding, it has decided
After something is improving, it has improved
After something is creating, it has
2024-07-26 15:20:22 root INFO     [order_1_approx] starting weight calculation for After something is understanding, it has understood
After something is containing, it has contained
After something is deciding, it has decided
After something is creating, it has created
After something is failing, it has failed
After something is marrying, it has married
After something is improving, it has improved
After something is relating, it has
2024-07-26 15:20:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 15:23:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0886,  0.2339, -0.0295,  ...,  0.0743, -0.3213, -0.2048],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5952,  0.8027,  0.4790,  ..., -0.3735, -3.3750, -0.8164],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0021,  0.0179, -0.0196,  ...,  0.0415,  0.0304,  0.0365],
        [-0.0307,  0.0104,  0.0354,  ...,  0.0187, -0.0390, -0.0126],
        [-0.0077, -0.0039, -0.0243,  ...,  0.0178,  0.0288, -0.0193],
        ...,
        [ 0.0057,  0.0455, -0.0054,  ..., -0.0150,  0.0147,  0.0174],
        [ 0.0175, -0.0184,  0.0120,  ...,  0.0161,  0.0281, -0.0124],
        [ 0.0144,  0.0204, -0.0034,  ...,  0.0153, -0.0200,  0.0028]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0532,  0.6831,  0.7085,  ..., -0.4036, -3.4160, -0.6772]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 15:23:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is understanding, it has understood
After something is containing, it has contained
After something is deciding, it has decided
After something is creating, it has created
After something is failing, it has failed
After something is marrying, it has married
After something is improving, it has improved
After something is relating, it has
2024-07-26 15:23:08 root INFO     [order_1_approx] starting weight calculation for After something is containing, it has contained
After something is deciding, it has decided
After something is understanding, it has understood
After something is creating, it has created
After something is marrying, it has married
After something is relating, it has related
After something is improving, it has improved
After something is failing, it has
2024-07-26 15:23:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 15:25:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0622,  0.1113, -0.1663,  ..., -0.1085,  0.1637,  0.0142],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1582, -0.1274,  3.2734,  ..., -2.5566, -1.5254, -1.4336],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0163, -0.0245,  0.0092,  ...,  0.0125,  0.0085,  0.0212],
        [-0.0399,  0.0234, -0.0134,  ...,  0.0303,  0.0018, -0.0286],
        [ 0.0022, -0.0336, -0.0170,  ..., -0.0317,  0.0286, -0.0008],
        ...,
        [-0.0054, -0.0115, -0.0159,  ..., -0.0054,  0.0007, -0.0078],
        [ 0.0150, -0.0180,  0.0193,  ...,  0.0012,  0.0269,  0.0158],
        [-0.0342,  0.0101, -0.0054,  ..., -0.0034, -0.0152, -0.0094]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5088, -0.3977,  3.1562,  ..., -2.6309, -1.3828, -1.6328]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 15:25:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is containing, it has contained
After something is deciding, it has decided
After something is understanding, it has understood
After something is creating, it has created
After something is marrying, it has married
After something is relating, it has related
After something is improving, it has improved
After something is failing, it has
2024-07-26 15:25:53 root INFO     [order_1_approx] starting weight calculation for After something is failing, it has failed
After something is containing, it has contained
After something is relating, it has related
After something is improving, it has improved
After something is creating, it has created
After something is understanding, it has understood
After something is marrying, it has married
After something is deciding, it has
2024-07-26 15:25:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 15:28:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0243,  0.1749,  0.0158,  ...,  0.0352, -0.0934, -0.0946],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2754, -1.7480,  1.0996,  ..., -1.0977, -2.7109,  0.9980],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0117, -0.0244, -0.0334,  ...,  0.0215,  0.0016,  0.0013],
        [-0.0276,  0.0073,  0.0306,  ..., -0.0131,  0.0031, -0.0314],
        [-0.0044, -0.0042, -0.0338,  ..., -0.0099, -0.0069, -0.0051],
        ...,
        [ 0.0105,  0.0127,  0.0176,  ...,  0.0260,  0.0091,  0.0054],
        [-0.0072,  0.0029, -0.0168,  ..., -0.0171, -0.0012, -0.0208],
        [ 0.0083,  0.0051,  0.0041,  ..., -0.0207, -0.0309, -0.0149]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3809, -1.6934,  0.8115,  ..., -0.8921, -2.9258,  0.6499]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 15:28:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is failing, it has failed
After something is containing, it has contained
After something is relating, it has related
After something is improving, it has improved
After something is creating, it has created
After something is understanding, it has understood
After something is marrying, it has married
After something is deciding, it has
2024-07-26 15:28:38 root INFO     [order_1_approx] starting weight calculation for After something is creating, it has created
After something is failing, it has failed
After something is relating, it has related
After something is deciding, it has decided
After something is understanding, it has understood
After something is improving, it has improved
After something is containing, it has contained
After something is marrying, it has
2024-07-26 15:28:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 15:31:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0328,  0.4229,  0.0037,  ..., -0.0208, -0.0833, -0.1299],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3164, -1.5303,  2.0625,  ..., -1.6533, -2.3047, -0.6035],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0031, -0.0025,  0.0031,  ...,  0.0180, -0.0067, -0.0036],
        [-0.0095,  0.0057,  0.0167,  ..., -0.0039,  0.0182,  0.0056],
        [-0.0010, -0.0231, -0.0029,  ..., -0.0355, -0.0287, -0.0141],
        ...,
        [-0.0075,  0.0209,  0.0068,  ...,  0.0034,  0.0008,  0.0031],
        [ 0.0063, -0.0025, -0.0002,  ..., -0.0237, -0.0081,  0.0247],
        [ 0.0040,  0.0234,  0.0333,  ..., -0.0051, -0.0115, -0.0183]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4062, -1.7930,  2.2422,  ..., -1.4316, -2.3555, -0.9214]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 15:31:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is creating, it has created
After something is failing, it has failed
After something is relating, it has related
After something is deciding, it has decided
After something is understanding, it has understood
After something is improving, it has improved
After something is containing, it has contained
After something is marrying, it has
2024-07-26 15:31:24 root INFO     [order_1_approx] starting weight calculation for After something is understanding, it has understood
After something is relating, it has related
After something is failing, it has failed
After something is marrying, it has married
After something is creating, it has created
After something is containing, it has contained
After something is deciding, it has decided
After something is improving, it has
2024-07-26 15:31:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 15:34:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0410,  0.0691,  0.1931,  ..., -0.0541,  0.0681,  0.1144],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3633, -0.4656,  0.5059,  ..., -1.8701, -1.0684, -1.5410],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0005,  0.0063, -0.0135,  ...,  0.0336, -0.0229,  0.0191],
        [-0.0256,  0.0535,  0.0049,  ...,  0.0201,  0.0030,  0.0045],
        [ 0.0091,  0.0060, -0.0294,  ..., -0.0042,  0.0053, -0.0158],
        ...,
        [ 0.0250,  0.0211, -0.0181,  ...,  0.0266,  0.0143,  0.0235],
        [ 0.0113, -0.0097,  0.0113,  ..., -0.0226,  0.0085, -0.0277],
        [ 0.0022, -0.0133,  0.0160,  ..., -0.0141, -0.0366, -0.0056]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7910, -0.3091,  0.6885,  ..., -2.1328, -1.1855, -2.0605]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 15:34:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is understanding, it has understood
After something is relating, it has related
After something is failing, it has failed
After something is marrying, it has married
After something is creating, it has created
After something is containing, it has contained
After something is deciding, it has decided
After something is improving, it has
2024-07-26 15:34:05 root INFO     total operator prediction time: 1321.02778673172 seconds
2024-07-26 15:34:05 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_inf - Ved
2024-07-26 15:34:05 root INFO     building operator verb_inf - Ved
2024-07-26 15:34:05 root INFO     [order_1_approx] starting weight calculation for If the present form is attend, the past form is attended
If the present form is ensure, the past form is ensured
If the present form is improve, the past form is improved
If the present form is continue, the past form is continued
If the present form is publish, the past form is published
If the present form is require, the past form is required
If the present form is apply, the past form is applied
If the present form is reduce, the past form is
2024-07-26 15:34:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 15:36:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0880, -0.0475, -0.0714,  ..., -0.0933,  0.0558,  0.0430],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.5039,  0.1306,  1.1533,  ..., -4.2891, -1.1201, -4.0625],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0323, -0.0078,  0.0004,  ...,  0.0045, -0.0046, -0.0135],
        [-0.0276,  0.0373,  0.0020,  ...,  0.0171,  0.0063, -0.0189],
        [ 0.0054, -0.0002, -0.0237,  ..., -0.0303, -0.0024, -0.0039],
        ...,
        [ 0.0303, -0.0044, -0.0147,  ...,  0.0289, -0.0195,  0.0259],
        [ 0.0128, -0.0128,  0.0108,  ..., -0.0210,  0.0499, -0.0050],
        [ 0.0148,  0.0113,  0.0279,  ..., -0.0011, -0.0198,  0.0037]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.7910, -0.0424,  0.4766,  ..., -4.3750, -0.6465, -3.5996]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 15:36:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is attend, the past form is attended
If the present form is ensure, the past form is ensured
If the present form is improve, the past form is improved
If the present form is continue, the past form is continued
If the present form is publish, the past form is published
If the present form is require, the past form is required
If the present form is apply, the past form is applied
If the present form is reduce, the past form is
2024-07-26 15:36:50 root INFO     [order_1_approx] starting weight calculation for If the present form is ensure, the past form is ensured
If the present form is attend, the past form is attended
If the present form is continue, the past form is continued
If the present form is require, the past form is required
If the present form is reduce, the past form is reduced
If the present form is improve, the past form is improved
If the present form is publish, the past form is published
If the present form is apply, the past form is
2024-07-26 15:36:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 15:39:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1464,  0.0078,  0.2345,  ...,  0.0681, -0.4741,  0.0182],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6816, -0.7861, -0.8691,  ..., -0.0459, -2.9805, -1.5479],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0169, -0.0154,  0.0063,  ..., -0.0099,  0.0017, -0.0214],
        [ 0.0039,  0.0129, -0.0076,  ..., -0.0024, -0.0386, -0.0215],
        [ 0.0047, -0.0269, -0.0082,  ..., -0.0182, -0.0359, -0.0082],
        ...,
        [ 0.0023,  0.0009,  0.0069,  ...,  0.0257,  0.0027,  0.0018],
        [-0.0013, -0.0300,  0.0047,  ..., -0.0169,  0.0286,  0.0040],
        [ 0.0204,  0.0024, -0.0131,  ...,  0.0044, -0.0287, -0.0243]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4343, -0.7905, -0.7393,  ...,  0.1031, -2.9395, -1.2861]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 15:39:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is ensure, the past form is ensured
If the present form is attend, the past form is attended
If the present form is continue, the past form is continued
If the present form is require, the past form is required
If the present form is reduce, the past form is reduced
If the present form is improve, the past form is improved
If the present form is publish, the past form is published
If the present form is apply, the past form is
2024-07-26 15:39:34 root INFO     [order_1_approx] starting weight calculation for If the present form is require, the past form is required
If the present form is publish, the past form is published
If the present form is reduce, the past form is reduced
If the present form is improve, the past form is improved
If the present form is ensure, the past form is ensured
If the present form is attend, the past form is attended
If the present form is apply, the past form is applied
If the present form is continue, the past form is
2024-07-26 15:39:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 15:42:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0004, -0.1727,  0.0446,  ..., -0.1437, -0.3291,  0.3704],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8242, -1.3828,  2.5547,  ..., -1.1416,  1.1514, -1.6602],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0020,  0.0151,  0.0048,  ..., -0.0153, -0.0110, -0.0092],
        [-0.0382,  0.0307, -0.0228,  ..., -0.0263, -0.0396, -0.0050],
        [ 0.0105,  0.0203, -0.0131,  ..., -0.0183,  0.0101, -0.0063],
        ...,
        [-0.0242,  0.0177,  0.0179,  ...,  0.0507,  0.0092,  0.0006],
        [ 0.0146,  0.0046,  0.0004,  ...,  0.0422,  0.0751, -0.0252],
        [ 0.0003, -0.0093,  0.0272,  ..., -0.0134, -0.0140,  0.0002]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0781, -1.6992,  2.6191,  ..., -0.2720,  1.2344, -1.6260]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 15:42:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is require, the past form is required
If the present form is publish, the past form is published
If the present form is reduce, the past form is reduced
If the present form is improve, the past form is improved
If the present form is ensure, the past form is ensured
If the present form is attend, the past form is attended
If the present form is apply, the past form is applied
If the present form is continue, the past form is
2024-07-26 15:42:18 root INFO     [order_1_approx] starting weight calculation for If the present form is attend, the past form is attended
If the present form is apply, the past form is applied
If the present form is improve, the past form is improved
If the present form is require, the past form is required
If the present form is reduce, the past form is reduced
If the present form is publish, the past form is published
If the present form is continue, the past form is continued
If the present form is ensure, the past form is
2024-07-26 15:42:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 15:45:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0745, -0.0146, -0.2271,  ...,  0.1290, -0.1865,  0.1746],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2744,  0.3027,  0.9468,  ...,  0.3081, -2.3301, -2.5469],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0110,  0.0117,  0.0002,  ..., -0.0293, -0.0228, -0.0095],
        [-0.0061,  0.0334,  0.0069,  ...,  0.0148,  0.0104, -0.0213],
        [-0.0108,  0.0036,  0.0127,  ..., -0.0272, -0.0105, -0.0041],
        ...,
        [-0.0177, -0.0162,  0.0007,  ...,  0.0284,  0.0265,  0.0045],
        [ 0.0354, -0.0235,  0.0182,  ..., -0.0284,  0.0298, -0.0003],
        [ 0.0334,  0.0014,  0.0273,  ...,  0.0089, -0.0232,  0.0091]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1035,  0.2375,  1.2178,  ...,  0.5820, -2.3262, -2.1562]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 15:45:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is attend, the past form is attended
If the present form is apply, the past form is applied
If the present form is improve, the past form is improved
If the present form is require, the past form is required
If the present form is reduce, the past form is reduced
If the present form is publish, the past form is published
If the present form is continue, the past form is continued
If the present form is ensure, the past form is
2024-07-26 15:45:03 root INFO     [order_1_approx] starting weight calculation for If the present form is reduce, the past form is reduced
If the present form is continue, the past form is continued
If the present form is attend, the past form is attended
If the present form is require, the past form is required
If the present form is publish, the past form is published
If the present form is ensure, the past form is ensured
If the present form is apply, the past form is applied
If the present form is improve, the past form is
2024-07-26 15:45:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 15:47:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0148,  0.1282,  0.1296,  ..., -0.0352, -0.2347,  0.3816],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0107, -0.3921,  0.9233,  ..., -0.6538, -0.8638, -2.5410],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0056,  0.0207, -0.0072,  ..., -0.0111, -0.0070,  0.0027],
        [-0.0048,  0.0380,  0.0057,  ...,  0.0409, -0.0235, -0.0037],
        [ 0.0125,  0.0152, -0.0054,  ..., -0.0201, -0.0206, -0.0151],
        ...,
        [-0.0010, -0.0096, -0.0046,  ...,  0.0344,  0.0316,  0.0151],
        [ 0.0173,  0.0048,  0.0326,  ...,  0.0066, -0.0039, -0.0080],
        [ 0.0383, -0.0275,  0.0492,  ...,  0.0213, -0.0448,  0.0022]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4873, -0.9780,  1.1426,  ..., -0.6982, -0.7168, -3.4863]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 15:47:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is reduce, the past form is reduced
If the present form is continue, the past form is continued
If the present form is attend, the past form is attended
If the present form is require, the past form is required
If the present form is publish, the past form is published
If the present form is ensure, the past form is ensured
If the present form is apply, the past form is applied
If the present form is improve, the past form is
2024-07-26 15:47:48 root INFO     [order_1_approx] starting weight calculation for If the present form is publish, the past form is published
If the present form is apply, the past form is applied
If the present form is attend, the past form is attended
If the present form is ensure, the past form is ensured
If the present form is reduce, the past form is reduced
If the present form is improve, the past form is improved
If the present form is continue, the past form is continued
If the present form is require, the past form is
2024-07-26 15:47:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 15:50:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1978, -0.0186, -0.1095,  ..., -0.0740, -0.3193,  0.3350],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.6855,  0.7607,  1.3193,  ..., -1.6445, -3.3809, -1.6328],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0017,  0.0040,  0.0212,  ..., -0.0073, -0.0068,  0.0101],
        [-0.0280,  0.0571, -0.0138,  ..., -0.0190, -0.0266, -0.0020],
        [ 0.0098, -0.0159,  0.0265,  ..., -0.0402, -0.0341, -0.0101],
        ...,
        [-0.0055,  0.0159, -0.0144,  ...,  0.0390,  0.0269, -0.0019],
        [ 0.0486, -0.0164, -0.0009,  ..., -0.0217,  0.0088,  0.0007],
        [ 0.0080,  0.0173,  0.0158,  ..., -0.0058, -0.0074, -0.0089]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.3750,  0.7476,  1.5586,  ..., -1.2988, -2.7480, -1.0488]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 15:50:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is publish, the past form is published
If the present form is apply, the past form is applied
If the present form is attend, the past form is attended
If the present form is ensure, the past form is ensured
If the present form is reduce, the past form is reduced
If the present form is improve, the past form is improved
If the present form is continue, the past form is continued
If the present form is require, the past form is
2024-07-26 15:50:33 root INFO     [order_1_approx] starting weight calculation for If the present form is improve, the past form is improved
If the present form is attend, the past form is attended
If the present form is apply, the past form is applied
If the present form is ensure, the past form is ensured
If the present form is require, the past form is required
If the present form is reduce, the past form is reduced
If the present form is continue, the past form is continued
If the present form is publish, the past form is
2024-07-26 15:50:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 15:53:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2576,  0.1082,  0.3037,  ...,  0.0763, -0.1523,  0.4905],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3340, -2.2324,  1.1504,  ..., -1.9902, -1.6914,  0.8320],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0388, -0.0240,  0.0181,  ...,  0.0118,  0.0238,  0.0249],
        [-0.0437,  0.0380, -0.0027,  ..., -0.0131, -0.0160, -0.0206],
        [ 0.0302,  0.0018,  0.0095,  ..., -0.0241, -0.0369,  0.0085],
        ...,
        [ 0.0034,  0.0142,  0.0210,  ...,  0.0372, -0.0019,  0.0248],
        [ 0.0442, -0.0116, -0.0235,  ..., -0.0069,  0.0102, -0.0196],
        [ 0.0333,  0.0205,  0.0097,  ..., -0.0133, -0.0249, -0.0257]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1172, -2.4355,  1.7461,  ..., -1.9551, -1.1934,  0.7344]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 15:53:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is improve, the past form is improved
If the present form is attend, the past form is attended
If the present form is apply, the past form is applied
If the present form is ensure, the past form is ensured
If the present form is require, the past form is required
If the present form is reduce, the past form is reduced
If the present form is continue, the past form is continued
If the present form is publish, the past form is
2024-07-26 15:53:18 root INFO     [order_1_approx] starting weight calculation for If the present form is publish, the past form is published
If the present form is continue, the past form is continued
If the present form is apply, the past form is applied
If the present form is reduce, the past form is reduced
If the present form is improve, the past form is improved
If the present form is require, the past form is required
If the present form is ensure, the past form is ensured
If the present form is attend, the past form is
2024-07-26 15:53:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 15:56:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2141,  0.3198, -0.2551,  ..., -0.0555, -0.4468,  0.0884],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1406,  2.2793,  0.1836,  ..., -0.1279, -4.8438, -1.5635],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0230, -0.0035, -0.0164,  ..., -0.0016, -0.0026, -0.0246],
        [-0.0401,  0.0512, -0.0046,  ...,  0.0096, -0.0102, -0.0005],
        [ 0.0224,  0.0012,  0.0108,  ..., -0.0085, -0.0130, -0.0045],
        ...,
        [ 0.0148,  0.0097, -0.0094,  ...,  0.0251, -0.0154, -0.0018],
        [ 0.0228, -0.0349,  0.0075,  ..., -0.0074,  0.0151, -0.0309],
        [ 0.0278,  0.0010,  0.0012,  ...,  0.0101, -0.0207, -0.0026]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9287,  2.8496,  0.1595,  ..., -0.2808, -4.4727, -1.4141]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 15:56:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is publish, the past form is published
If the present form is continue, the past form is continued
If the present form is apply, the past form is applied
If the present form is reduce, the past form is reduced
If the present form is improve, the past form is improved
If the present form is require, the past form is required
If the present form is ensure, the past form is ensured
If the present form is attend, the past form is
2024-07-26 15:56:02 root INFO     total operator prediction time: 1317.3054556846619 seconds
2024-07-26 15:56:02 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_inf - 3pSg
2024-07-26 15:56:02 root INFO     building operator verb_inf - 3pSg
2024-07-26 15:56:02 root INFO     [order_1_approx] starting weight calculation for I receive, he receives
I represent, he represents
I create, he creates
I believe, he believes
I describe, he describes
I identify, he identifies
I become, he becomes
I follow, he
2024-07-26 15:56:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 15:58:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0803,  0.2473,  0.0021,  ..., -0.0944, -0.0346,  0.0248],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8945, -3.2500,  0.2344,  ..., -1.5186, -7.3438, -0.7539],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0479,  0.0225, -0.0226,  ...,  0.0298, -0.0145,  0.0088],
        [-0.0187,  0.0212, -0.0010,  ...,  0.0038,  0.0302, -0.0168],
        [-0.0068,  0.0068,  0.0179,  ..., -0.0334, -0.0193,  0.0016],
        ...,
        [ 0.0053,  0.0002, -0.0034,  ..., -0.0006,  0.0002,  0.0073],
        [ 0.0139, -0.0232, -0.0077,  ..., -0.0416,  0.0285, -0.0183],
        [-0.0085,  0.0175,  0.0009,  ...,  0.0063, -0.0193, -0.0121]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3828, -3.1777, -0.0693,  ..., -1.6182, -7.8789, -0.8760]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 15:58:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I receive, he receives
I represent, he represents
I create, he creates
I believe, he believes
I describe, he describes
I identify, he identifies
I become, he becomes
I follow, he
2024-07-26 15:58:48 root INFO     [order_1_approx] starting weight calculation for I believe, he believes
I describe, he describes
I identify, he identifies
I follow, he follows
I receive, he receives
I become, he becomes
I represent, he represents
I create, he
2024-07-26 15:58:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 16:01:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0890,  0.2593,  0.0664,  ..., -0.0756, -0.0471, -0.0864],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7725, -2.8809,  1.3984,  ..., -1.0840, -7.1953,  0.5723],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.9699e-02, -1.8692e-03, -1.7120e-02,  ...,  1.0429e-02,
         -1.7670e-02,  6.6757e-04],
        [ 1.0315e-02, -3.8795e-03,  1.9211e-02,  ..., -1.3100e-02,
          1.1292e-02, -9.5978e-03],
        [-1.2703e-02, -1.0080e-03,  3.9978e-03,  ...,  9.1553e-03,
          2.4796e-03, -1.5707e-03],
        ...,
        [ 1.2558e-02, -1.5278e-03,  1.2894e-02,  ...,  5.2795e-03,
         -9.4528e-03,  2.3022e-03],
        [ 1.1581e-02, -8.7738e-05, -3.1555e-02,  ..., -2.6031e-02,
          1.2856e-02, -2.2186e-02],
        [ 1.0757e-02,  2.4139e-02, -1.1757e-02,  ..., -9.5444e-03,
         -1.4153e-02, -7.8354e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9458, -3.2598,  1.2725,  ..., -0.8496, -7.1875,  0.3884]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 16:01:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I believe, he believes
I describe, he describes
I identify, he identifies
I follow, he follows
I receive, he receives
I become, he becomes
I represent, he represents
I create, he
2024-07-26 16:01:33 root INFO     [order_1_approx] starting weight calculation for I follow, he follows
I identify, he identifies
I believe, he believes
I create, he creates
I represent, he represents
I become, he becomes
I receive, he receives
I describe, he
2024-07-26 16:01:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 16:04:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0432,  0.0334,  0.1387,  ..., -0.2266, -0.0553, -0.2681],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7773, -3.7793,  3.4414,  ..., -1.3867, -5.8867, -0.4238],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0255,  0.0157, -0.0116,  ...,  0.0174, -0.0024,  0.0020],
        [-0.0351,  0.0048, -0.0078,  ..., -0.0276,  0.0125,  0.0040],
        [ 0.0282,  0.0059, -0.0207,  ..., -0.0092, -0.0005, -0.0012],
        ...,
        [ 0.0031, -0.0032,  0.0107,  ...,  0.0229,  0.0056, -0.0075],
        [ 0.0055, -0.0292, -0.0068,  ..., -0.0058, -0.0042, -0.0237],
        [-0.0059,  0.0133,  0.0118,  ..., -0.0003, -0.0262, -0.0110]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0605, -4.0430,  3.2383,  ..., -1.1113, -6.2305, -0.6992]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 16:04:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I follow, he follows
I identify, he identifies
I believe, he believes
I create, he creates
I represent, he represents
I become, he becomes
I receive, he receives
I describe, he
2024-07-26 16:04:18 root INFO     [order_1_approx] starting weight calculation for I create, he creates
I describe, he describes
I believe, he believes
I follow, he follows
I identify, he identifies
I become, he becomes
I represent, he represents
I receive, he
2024-07-26 16:04:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 16:07:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1010,  0.1438, -0.1093,  ..., -0.4114, -0.1660, -0.0817],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8130, -1.7295, -2.9551,  ..., -3.1211, -7.3281, -2.4219],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0341,  0.0061,  0.0255,  ...,  0.0005, -0.0265,  0.0279],
        [-0.0154,  0.0392, -0.0131,  ..., -0.0039,  0.0304, -0.0263],
        [-0.0007,  0.0043,  0.0029,  ...,  0.0056,  0.0077,  0.0112],
        ...,
        [-0.0033,  0.0257,  0.0084,  ...,  0.0011,  0.0083, -0.0268],
        [ 0.0023, -0.0089,  0.0112,  ..., -0.0319,  0.0415,  0.0025],
        [-0.0096,  0.0036, -0.0073,  ...,  0.0009,  0.0134, -0.0022]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7412, -1.3242, -3.3184,  ..., -2.6914, -7.7305, -1.8984]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 16:07:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I create, he creates
I describe, he describes
I believe, he believes
I follow, he follows
I identify, he identifies
I become, he becomes
I represent, he represents
I receive, he
2024-07-26 16:07:03 root INFO     [order_1_approx] starting weight calculation for I describe, he describes
I follow, he follows
I create, he creates
I identify, he identifies
I believe, he believes
I receive, he receives
I represent, he represents
I become, he
2024-07-26 16:07:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 16:09:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0587,  0.3049,  0.1191,  ..., -0.1152, -0.2673,  0.0347],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7051, -2.1406,  0.0840,  ..., -0.0293, -2.7832, -1.0088],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0158,  0.0147,  0.0055,  ...,  0.0327,  0.0008,  0.0087],
        [-0.0006,  0.0083,  0.0085,  ..., -0.0154, -0.0134,  0.0071],
        [-0.0110, -0.0050, -0.0049,  ...,  0.0040,  0.0002, -0.0106],
        ...,
        [ 0.0028, -0.0004, -0.0013,  ...,  0.0180, -0.0158, -0.0024],
        [ 0.0002, -0.0093,  0.0080,  ..., -0.0181,  0.0226, -0.0106],
        [ 0.0036, -0.0047, -0.0025,  ...,  0.0106, -0.0147, -0.0041]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5918, -2.1289,  0.0124,  ...,  0.5381, -3.4824, -1.1631]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 16:09:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I describe, he describes
I follow, he follows
I create, he creates
I identify, he identifies
I believe, he believes
I receive, he receives
I represent, he represents
I become, he
2024-07-26 16:09:49 root INFO     [order_1_approx] starting weight calculation for I describe, he describes
I become, he becomes
I follow, he follows
I create, he creates
I identify, he identifies
I represent, he represents
I receive, he receives
I believe, he
2024-07-26 16:09:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 16:12:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1351,  0.2275,  0.0744,  ..., -0.1215, -0.5137,  0.2612],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1230, -4.6250,  0.9473,  ..., -0.2871, -4.2656,  0.1777],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0022,  0.0125, -0.0093,  ...,  0.0012, -0.0033,  0.0059],
        [-0.0022,  0.0008, -0.0018,  ...,  0.0036,  0.0146,  0.0044],
        [-0.0136,  0.0070,  0.0168,  ...,  0.0021, -0.0042,  0.0113],
        ...,
        [ 0.0087,  0.0021,  0.0157,  ...,  0.0034, -0.0127, -0.0072],
        [-0.0274, -0.0120,  0.0145,  ..., -0.0156,  0.0179, -0.0172],
        [ 0.0052,  0.0090,  0.0009,  ..., -0.0137, -0.0217, -0.0193]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0547, -4.3711,  0.4531,  ...,  0.1702, -4.5781,  0.0559]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 16:12:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I describe, he describes
I become, he becomes
I follow, he follows
I create, he creates
I identify, he identifies
I represent, he represents
I receive, he receives
I believe, he
2024-07-26 16:12:35 root INFO     [order_1_approx] starting weight calculation for I represent, he represents
I describe, he describes
I become, he becomes
I believe, he believes
I follow, he follows
I create, he creates
I receive, he receives
I identify, he
2024-07-26 16:12:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 16:15:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1786, -0.1047, -0.0370,  ...,  0.3430, -0.3337,  0.1212],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7168, -2.7930,  3.4375,  ..., -1.6953, -6.0469,  1.5332],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0156,  0.0249, -0.0245,  ..., -0.0023, -0.0182, -0.0142],
        [-0.0110,  0.0072, -0.0050,  ..., -0.0213,  0.0005, -0.0163],
        [-0.0083, -0.0282,  0.0302,  ..., -0.0040, -0.0100,  0.0363],
        ...,
        [-0.0239,  0.0102, -0.0115,  ...,  0.0156,  0.0162, -0.0263],
        [ 0.0241, -0.0690,  0.0192,  ..., -0.0287, -0.0163,  0.0385],
        [ 0.0182, -0.0057,  0.0063,  ..., -0.0058, -0.0265,  0.0024]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6602, -2.7383,  3.3672,  ..., -1.1641, -6.9297,  1.0049]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 16:15:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I represent, he represents
I describe, he describes
I become, he becomes
I believe, he believes
I follow, he follows
I create, he creates
I receive, he receives
I identify, he
2024-07-26 16:15:22 root INFO     [order_1_approx] starting weight calculation for I describe, he describes
I receive, he receives
I identify, he identifies
I believe, he believes
I follow, he follows
I become, he becomes
I create, he creates
I represent, he
2024-07-26 16:15:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 16:18:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0938,  0.2229, -0.1265,  ..., -0.1218, -0.0692, -0.1653],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4609, -3.4297,  1.4629,  ..., -2.1172, -7.6875,  0.6621],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0221,  0.0030, -0.0120,  ...,  0.0184,  0.0017,  0.0126],
        [-0.0059,  0.0262,  0.0002,  ..., -0.0135,  0.0254, -0.0049],
        [-0.0017,  0.0250,  0.0185,  ..., -0.0162,  0.0032,  0.0073],
        ...,
        [-0.0051, -0.0083, -0.0068,  ...,  0.0327, -0.0192,  0.0019],
        [ 0.0155, -0.0039, -0.0152,  ..., -0.0141,  0.0477, -0.0211],
        [ 0.0097, -0.0131, -0.0051,  ..., -0.0120, -0.0136,  0.0086]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3477, -3.5586,  1.3457,  ..., -1.8105, -7.9961,  0.6128]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 16:18:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I describe, he describes
I receive, he receives
I identify, he identifies
I believe, he believes
I follow, he follows
I become, he becomes
I create, he creates
I represent, he
2024-07-26 16:18:07 root INFO     total operator prediction time: 1325.4978737831116 seconds
2024-07-26 16:18:07 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_Ving - 3pSg
2024-07-26 16:18:07 root INFO     building operator verb_Ving - 3pSg
2024-07-26 16:18:08 root INFO     [order_1_approx] starting weight calculation for When something is believing, it believes
When something is containing, it contains
When something is including, it includes
When something is happening, it happens
When something is involving, it involves
When something is learning, it learns
When something is managing, it manages
When something is teaching, it
2024-07-26 16:18:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 16:20:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2417,  0.3555,  0.0698,  ...,  0.0138, -0.2686, -0.0363],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1172, -1.6719,  1.3555,  ...,  0.3535, -7.3320, -3.1641],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0165,  0.0255,  0.0094,  ..., -0.0020, -0.0173,  0.0103],
        [-0.0025,  0.0331, -0.0483,  ..., -0.0246, -0.0059,  0.0213],
        [ 0.0066,  0.0011,  0.0201,  ...,  0.0047,  0.0034, -0.0368],
        ...,
        [ 0.0138,  0.0038,  0.0012,  ...,  0.0227, -0.0054, -0.0108],
        [ 0.0278, -0.0318, -0.0023,  ...,  0.0058,  0.0172, -0.0304],
        [-0.0022,  0.0110, -0.0223,  ...,  0.0129, -0.0101,  0.0111]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9180, -1.8711,  1.1484,  ...,  0.6504, -6.8594, -3.4102]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 16:20:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is believing, it believes
When something is containing, it contains
When something is including, it includes
When something is happening, it happens
When something is involving, it involves
When something is learning, it learns
When something is managing, it manages
When something is teaching, it
2024-07-26 16:20:54 root INFO     [order_1_approx] starting weight calculation for When something is learning, it learns
When something is teaching, it teaches
When something is containing, it contains
When something is including, it includes
When something is believing, it believes
When something is involving, it involves
When something is happening, it happens
When something is managing, it
2024-07-26 16:20:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 16:23:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0198,  0.5732, -0.0272,  ...,  0.0562, -0.2008, -0.2517],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9004, -2.6465,  0.2754,  ..., -1.5508, -7.8828, -3.2344],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0100,  0.0015, -0.0079,  ..., -0.0056,  0.0283,  0.0175],
        [ 0.0028, -0.0009,  0.0141,  ...,  0.0038,  0.0051,  0.0116],
        [-0.0262,  0.0075,  0.0099,  ..., -0.0069,  0.0008, -0.0298],
        ...,
        [ 0.0127,  0.0166,  0.0252,  ...,  0.0214, -0.0092,  0.0325],
        [ 0.0038, -0.0095, -0.0088,  ..., -0.0461,  0.0189, -0.0316],
        [ 0.0209, -0.0052, -0.0076,  ..., -0.0182, -0.0446, -0.0231]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.2773, -2.9551,  0.3770,  ..., -1.4756, -7.9609, -3.5332]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 16:23:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is learning, it learns
When something is teaching, it teaches
When something is containing, it contains
When something is including, it includes
When something is believing, it believes
When something is involving, it involves
When something is happening, it happens
When something is managing, it
2024-07-26 16:23:40 root INFO     [order_1_approx] starting weight calculation for When something is including, it includes
When something is teaching, it teaches
When something is happening, it happens
When something is learning, it learns
When something is containing, it contains
When something is involving, it involves
When something is managing, it manages
When something is believing, it
2024-07-26 16:23:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 16:26:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0731,  0.3462,  0.1208,  ..., -0.1234, -0.3022,  0.1836],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6875, -3.8125,  0.7949,  ..., -0.3867, -3.8828, -0.1699],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0064, -0.0039, -0.0114,  ...,  0.0157,  0.0088,  0.0133],
        [ 0.0018,  0.0381, -0.0041,  ...,  0.0071,  0.0083,  0.0150],
        [-0.0067, -0.0042,  0.0189,  ..., -0.0015, -0.0306,  0.0012],
        ...,
        [ 0.0125,  0.0224,  0.0116,  ...,  0.0101,  0.0016,  0.0038],
        [ 0.0037, -0.0013, -0.0050,  ..., -0.0227, -0.0012, -0.0442],
        [-0.0052,  0.0160,  0.0020,  ..., -0.0115, -0.0101, -0.0081]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7188, -3.6133,  0.6704,  ...,  0.0762, -4.0469, -0.5698]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 16:26:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is including, it includes
When something is teaching, it teaches
When something is happening, it happens
When something is learning, it learns
When something is containing, it contains
When something is involving, it involves
When something is managing, it manages
When something is believing, it
2024-07-26 16:26:26 root INFO     [order_1_approx] starting weight calculation for When something is happening, it happens
When something is containing, it contains
When something is believing, it believes
When something is managing, it manages
When something is involving, it involves
When something is learning, it learns
When something is teaching, it teaches
When something is including, it
2024-07-26 16:26:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 16:29:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1311,  0.0977,  0.1349,  ...,  0.0638, -0.1760, -0.2159],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7383, -1.8252,  0.5508,  ..., -1.3232, -5.0625, -2.0938],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0321,  0.0068, -0.0054,  ...,  0.0295,  0.0041, -0.0051],
        [ 0.0143,  0.0530,  0.0102,  ...,  0.0203, -0.0317,  0.0098],
        [ 0.0050, -0.0104,  0.0274,  ..., -0.0374, -0.0317, -0.0462],
        ...,
        [-0.0004,  0.0076, -0.0104,  ...,  0.0312,  0.0110, -0.0054],
        [ 0.0102, -0.0172, -0.0001,  ..., -0.0375,  0.0191, -0.0220],
        [ 0.0118,  0.0281, -0.0087,  ...,  0.0145, -0.0507,  0.0444]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0371, -2.1172,  0.6738,  ..., -1.1250, -5.3359, -2.4219]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 16:29:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is happening, it happens
When something is containing, it contains
When something is believing, it believes
When something is managing, it manages
When something is involving, it involves
When something is learning, it learns
When something is teaching, it teaches
When something is including, it
2024-07-26 16:29:13 root INFO     [order_1_approx] starting weight calculation for When something is teaching, it teaches
When something is believing, it believes
When something is containing, it contains
When something is including, it includes
When something is managing, it manages
When something is happening, it happens
When something is learning, it learns
When something is involving, it
2024-07-26 16:29:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 16:31:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1017,  0.2354,  0.0036,  ...,  0.0141, -0.4131, -0.2474],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9717, -0.7461,  2.2031,  ..., -0.9478, -4.0352, -2.6367],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0087,  0.0232, -0.0012,  ...,  0.0108, -0.0055,  0.0010],
        [-0.0228,  0.0409,  0.0165,  ...,  0.0031, -0.0095,  0.0146],
        [ 0.0095, -0.0060,  0.0144,  ..., -0.0176, -0.0117, -0.0250],
        ...,
        [ 0.0388,  0.0210, -0.0146,  ...,  0.0280,  0.0037, -0.0101],
        [-0.0072, -0.0141, -0.0179,  ..., -0.0500,  0.0157, -0.0371],
        [-0.0066,  0.0354,  0.0031,  ..., -0.0139, -0.0539,  0.0017]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7793, -1.1992,  2.3359,  ..., -0.9824, -4.2109, -3.0430]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 16:31:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is teaching, it teaches
When something is believing, it believes
When something is containing, it contains
When something is including, it includes
When something is managing, it manages
When something is happening, it happens
When something is learning, it learns
When something is involving, it
2024-07-26 16:31:59 root INFO     [order_1_approx] starting weight calculation for When something is learning, it learns
When something is happening, it happens
When something is teaching, it teaches
When something is managing, it manages
When something is involving, it involves
When something is believing, it believes
When something is including, it includes
When something is containing, it
2024-07-26 16:31:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 16:34:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1440, -0.0435, -0.0260,  ..., -0.0317, -0.2700, -0.2307],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2891, -2.4395,  0.4648,  ..., -2.2988, -4.1133, -1.5488],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0177,  0.0119, -0.0122,  ...,  0.0111, -0.0345,  0.0329],
        [-0.0399,  0.0311,  0.0065,  ..., -0.0258, -0.0346,  0.0302],
        [ 0.0306, -0.0035,  0.0111,  ..., -0.0353,  0.0068, -0.0622],
        ...,
        [-0.0079, -0.0091,  0.0128,  ...,  0.0244,  0.0153,  0.0014],
        [ 0.0324, -0.0620, -0.0319,  ..., -0.0397,  0.0427, -0.0517],
        [ 0.0274,  0.0115, -0.0167,  ...,  0.0006, -0.0547, -0.0040]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3662, -2.6621,  0.5083,  ..., -2.1777, -3.4492, -1.7080]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 16:34:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is learning, it learns
When something is happening, it happens
When something is teaching, it teaches
When something is managing, it manages
When something is involving, it involves
When something is believing, it believes
When something is including, it includes
When something is containing, it
2024-07-26 16:34:46 root INFO     [order_1_approx] starting weight calculation for When something is involving, it involves
When something is learning, it learns
When something is believing, it believes
When something is teaching, it teaches
When something is including, it includes
When something is containing, it contains
When something is managing, it manages
When something is happening, it
2024-07-26 16:34:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 16:37:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2216,  0.1307,  0.1777,  ...,  0.0262, -0.1254, -0.3459],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6445, -2.7402,  0.0352,  ...,  0.3638, -7.0391, -0.8633],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0590, -0.0026,  0.0092,  ...,  0.0037, -0.0032,  0.0245],
        [ 0.0022,  0.0299,  0.0167,  ...,  0.0123, -0.0161, -0.0075],
        [-0.0034,  0.0175,  0.0277,  ...,  0.0163, -0.0012, -0.0083],
        ...,
        [ 0.0025,  0.0039, -0.0250,  ...,  0.0778,  0.0066, -0.0231],
        [ 0.0211, -0.0111, -0.0014,  ..., -0.0499,  0.0002,  0.0061],
        [-0.0420, -0.0008, -0.0135,  ...,  0.0054,  0.0188,  0.0222]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7520, -2.7012, -0.1624,  ...,  0.8506, -7.3477, -1.0664]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 16:37:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is involving, it involves
When something is learning, it learns
When something is believing, it believes
When something is teaching, it teaches
When something is including, it includes
When something is containing, it contains
When something is managing, it manages
When something is happening, it
2024-07-26 16:37:32 root INFO     [order_1_approx] starting weight calculation for When something is believing, it believes
When something is happening, it happens
When something is teaching, it teaches
When something is containing, it contains
When something is managing, it manages
When something is including, it includes
When something is involving, it involves
When something is learning, it
2024-07-26 16:37:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 16:40:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0994,  0.1682,  0.0062,  ..., -0.2341, -0.1605, -0.0229],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6855, -2.8438,  0.3047,  ...,  0.9800, -5.4258, -4.6562],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.3407e-02, -2.7618e-02,  3.7048e-02,  ...,  1.2329e-02,
         -4.7982e-05,  1.1192e-02],
        [ 1.3954e-02,  3.9734e-02,  1.0406e-02,  ..., -2.7084e-04,
         -1.3000e-02,  3.4851e-02],
        [-2.2537e-02,  1.2512e-03,  3.0838e-02,  ..., -1.0727e-02,
          2.2797e-02, -1.1978e-02],
        ...,
        [ 3.1555e-02,  1.2634e-02,  1.0376e-03,  ...,  6.6223e-02,
          1.4915e-02,  7.9880e-03],
        [-1.0513e-02, -1.7334e-02, -4.6234e-02,  ..., -3.7048e-02,
          5.0415e-02, -3.9673e-02],
        [ 2.5925e-02,  1.3985e-02,  6.1913e-03,  ..., -1.4938e-02,
         -1.5656e-02,  5.9280e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9941, -2.8555,  0.1459,  ...,  1.4180, -5.7695, -4.9609]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 16:40:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is believing, it believes
When something is happening, it happens
When something is teaching, it teaches
When something is containing, it contains
When something is managing, it manages
When something is including, it includes
When something is involving, it involves
When something is learning, it
2024-07-26 16:40:17 root INFO     total operator prediction time: 1329.7539012432098 seconds
2024-07-26 16:40:17 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun - plural_reg
2024-07-26 16:40:17 root INFO     building operator noun - plural_reg
2024-07-26 16:40:18 root INFO     [order_1_approx] starting weight calculation for The plural form of problem is problems
The plural form of system is systems
The plural form of example is examples
The plural form of department is departments
The plural form of customer is customers
The plural form of development is developments
The plural form of language is languages
The plural form of application is
2024-07-26 16:40:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 16:43:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0999, -0.0087,  0.0637,  ...,  0.1641, -0.4148,  0.0493],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9775, -1.8379, -0.9854,  ..., -0.5244, -3.4570, -1.1387],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0219, -0.0102,  0.0102,  ...,  0.0282,  0.0303,  0.0138],
        [ 0.0064,  0.0330,  0.0313,  ..., -0.0075, -0.0076, -0.0079],
        [-0.0039, -0.0021, -0.0035,  ..., -0.0038,  0.0062,  0.0262],
        ...,
        [ 0.0144,  0.0472,  0.0247,  ...,  0.0452, -0.0133, -0.0081],
        [ 0.0022,  0.0168, -0.0439,  ..., -0.0061,  0.0190, -0.0278],
        [ 0.0202, -0.0070, -0.0046,  ...,  0.0201, -0.0071,  0.0235]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2246, -1.8184, -0.5747,  ..., -0.8174, -3.4531, -0.8145]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 16:43:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of problem is problems
The plural form of system is systems
The plural form of example is examples
The plural form of department is departments
The plural form of customer is customers
The plural form of development is developments
The plural form of language is languages
The plural form of application is
2024-07-26 16:43:01 root INFO     [order_1_approx] starting weight calculation for The plural form of application is applications
The plural form of example is examples
The plural form of customer is customers
The plural form of language is languages
The plural form of department is departments
The plural form of system is systems
The plural form of development is developments
The plural form of problem is
2024-07-26 16:43:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 16:45:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2954, -0.0808,  0.0984,  ..., -0.0699, -0.5098,  0.3923],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7051, -3.0371,  0.9043,  ...,  0.3047, -0.2969, -0.6465],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0005,  0.0114,  0.0221,  ...,  0.0136,  0.0034,  0.0085],
        [-0.0016,  0.0072,  0.0048,  ...,  0.0256, -0.0100,  0.0091],
        [-0.0223, -0.0010,  0.0017,  ..., -0.0272, -0.0083,  0.0050],
        ...,
        [ 0.0141,  0.0100,  0.0078,  ...,  0.0368, -0.0097,  0.0090],
        [-0.0005,  0.0081, -0.0287,  ...,  0.0006,  0.0204, -0.0254],
        [ 0.0018,  0.0009,  0.0106,  ...,  0.0163, -0.0051,  0.0104]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6162, -3.6445,  1.1133,  ...,  0.5366, -0.4204, -0.4363]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 16:45:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of application is applications
The plural form of example is examples
The plural form of customer is customers
The plural form of language is languages
The plural form of department is departments
The plural form of system is systems
The plural form of development is developments
The plural form of problem is
2024-07-26 16:45:47 root INFO     [order_1_approx] starting weight calculation for The plural form of problem is problems
The plural form of department is departments
The plural form of application is applications
The plural form of development is developments
The plural form of example is examples
The plural form of customer is customers
The plural form of language is languages
The plural form of system is
2024-07-26 16:45:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 16:48:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1538,  0.0607,  0.0414,  ...,  0.0715, -0.3186,  0.2079],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9961, -2.0762,  0.2383,  ..., -0.8418, -0.7275, -1.4453],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0066, -0.0061,  0.0391,  ..., -0.0085,  0.0062,  0.0276],
        [ 0.0094,  0.0279, -0.0008,  ...,  0.0041, -0.0060, -0.0116],
        [-0.0217,  0.0093,  0.0030,  ..., -0.0004,  0.0123,  0.0113],
        ...,
        [-0.0115,  0.0138,  0.0110,  ...,  0.0289,  0.0244,  0.0023],
        [ 0.0011,  0.0186, -0.0053,  ...,  0.0117,  0.0197, -0.0135],
        [ 0.0250, -0.0187,  0.0126,  ...,  0.0134, -0.0111,  0.0111]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1914, -2.4219,  0.2166,  ..., -0.7754, -0.7334, -1.4258]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 16:48:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of problem is problems
The plural form of department is departments
The plural form of application is applications
The plural form of development is developments
The plural form of example is examples
The plural form of customer is customers
The plural form of language is languages
The plural form of system is
2024-07-26 16:48:33 root INFO     [order_1_approx] starting weight calculation for The plural form of system is systems
The plural form of example is examples
The plural form of application is applications
The plural form of language is languages
The plural form of problem is problems
The plural form of development is developments
The plural form of customer is customers
The plural form of department is
2024-07-26 16:48:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 16:51:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1135,  0.0484,  0.0321,  ..., -0.0145, -0.0018,  0.0250],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0371, -3.1387,  2.8906,  ..., -1.2295,  1.3018, -2.2734],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.9337e-02,  7.1945e-03, -1.7151e-02,  ..., -2.4475e-02,
         -9.1553e-05, -7.7057e-03],
        [ 5.9357e-03,  1.3687e-02, -9.9373e-04,  ...,  5.7716e-03,
         -2.2308e-02,  6.6757e-03],
        [-3.3936e-02,  1.9806e-02,  7.7477e-03,  ...,  4.1771e-03,
         -2.4643e-02,  1.8570e-02],
        ...,
        [-1.5747e-02,  1.3466e-02, -3.4084e-03,  ...,  3.1372e-02,
          4.2877e-03,  2.3590e-02],
        [-7.1411e-03, -1.0750e-02, -1.3474e-02,  ...,  2.0264e-02,
          8.2626e-03, -2.6886e-02],
        [ 1.0086e-02, -4.7989e-03,  1.1909e-02,  ..., -4.3182e-03,
         -6.8665e-03,  2.6260e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3945, -3.0508,  3.0859,  ..., -1.4434,  1.0723, -2.2012]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 16:51:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of system is systems
The plural form of example is examples
The plural form of application is applications
The plural form of language is languages
The plural form of problem is problems
The plural form of development is developments
The plural form of customer is customers
The plural form of department is
2024-07-26 16:51:16 root INFO     [order_1_approx] starting weight calculation for The plural form of application is applications
The plural form of system is systems
The plural form of problem is problems
The plural form of example is examples
The plural form of department is departments
The plural form of language is languages
The plural form of development is developments
The plural form of customer is
2024-07-26 16:51:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 16:53:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0978, -0.0768, -0.0415,  ..., -0.1163, -0.0458,  0.1406],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5488, -1.1689,  1.8896,  ..., -1.9141, -1.6689, -0.5127],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0180, -0.0318, -0.0215,  ...,  0.0279, -0.0326, -0.0129],
        [ 0.0064,  0.0317,  0.0249,  ...,  0.0008,  0.0025, -0.0036],
        [-0.0173,  0.0031,  0.0322,  ..., -0.0089,  0.0148,  0.0359],
        ...,
        [-0.0117,  0.0136,  0.0197,  ...,  0.0226,  0.0038,  0.0183],
        [ 0.0023,  0.0121, -0.0210,  ..., -0.0307,  0.0358,  0.0058],
        [ 0.0068, -0.0061, -0.0283,  ...,  0.0125,  0.0035,  0.0144]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6191, -1.1953,  2.0605,  ..., -1.8604, -1.8496, -0.4688]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 16:53:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of application is applications
The plural form of system is systems
The plural form of problem is problems
The plural form of example is examples
The plural form of department is departments
The plural form of language is languages
The plural form of development is developments
The plural form of customer is
2024-07-26 16:53:58 root INFO     [order_1_approx] starting weight calculation for The plural form of customer is customers
The plural form of system is systems
The plural form of example is examples
The plural form of development is developments
The plural form of department is departments
The plural form of application is applications
The plural form of problem is problems
The plural form of language is
2024-07-26 16:53:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 16:56:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2236,  0.0129, -0.1047,  ...,  0.1707, -0.1399,  0.1030],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0420, -2.5898,  1.2305,  ...,  1.6289, -2.0352, -3.1953],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.0869e-02, -1.9257e-02,  9.3384e-03,  ...,  1.7380e-02,
          1.0246e-02,  9.3460e-04],
        [ 3.4119e-02,  1.0811e-02,  7.3891e-03,  ...,  1.3649e-02,
         -4.3335e-02,  2.4414e-04],
        [-1.0429e-02, -1.0216e-02,  1.9440e-02,  ...,  7.8278e-03,
         -2.2629e-02,  3.0994e-03],
        ...,
        [-2.7832e-02,  1.6266e-02, -9.1553e-05,  ...,  5.1361e-02,
          4.0070e-02,  1.7654e-02],
        [-1.8311e-04, -7.7515e-03, -4.3274e-02,  ...,  1.3475e-03,
          2.2202e-02, -1.4473e-02],
        [ 3.6560e-02,  7.4387e-03, -4.7302e-03,  ..., -1.4969e-02,
         -3.3569e-02, -1.9058e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4355, -2.9531,  1.6367,  ...,  0.5195, -1.9971, -2.6445]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 16:56:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of customer is customers
The plural form of system is systems
The plural form of example is examples
The plural form of development is developments
The plural form of department is departments
The plural form of application is applications
The plural form of problem is problems
The plural form of language is
2024-07-26 16:56:45 root INFO     [order_1_approx] starting weight calculation for The plural form of example is examples
The plural form of system is systems
The plural form of language is languages
The plural form of department is departments
The plural form of application is applications
The plural form of problem is problems
The plural form of customer is customers
The plural form of development is
2024-07-26 16:56:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 16:59:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0909,  0.1222,  0.1569,  ...,  0.0277, -0.1194,  0.2021],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0703, -1.9648, -0.0049,  ..., -1.6660, -2.7305, -2.2070],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0209,  0.0232, -0.0295,  ..., -0.0033, -0.0395, -0.0331],
        [ 0.0093,  0.0361,  0.0101,  ...,  0.0092, -0.0199,  0.0078],
        [-0.0101, -0.0134,  0.0008,  ..., -0.0061, -0.0182,  0.0274],
        ...,
        [-0.0072,  0.0023,  0.0094,  ...,  0.0314, -0.0154,  0.0009],
        [ 0.0058,  0.0083, -0.0199,  ..., -0.0002,  0.0635,  0.0003],
        [ 0.0152, -0.0150, -0.0159,  ...,  0.0204,  0.0090,  0.0390]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7373, -2.2168, -0.0611,  ..., -1.6885, -3.1191, -2.1875]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 16:59:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of example is examples
The plural form of system is systems
The plural form of language is languages
The plural form of department is departments
The plural form of application is applications
The plural form of problem is problems
The plural form of customer is customers
The plural form of development is
2024-07-26 16:59:30 root INFO     [order_1_approx] starting weight calculation for The plural form of customer is customers
The plural form of department is departments
The plural form of system is systems
The plural form of language is languages
The plural form of problem is problems
The plural form of application is applications
The plural form of development is developments
The plural form of example is
2024-07-26 16:59:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 17:02:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1544, -0.3081,  0.0006,  ...,  0.1151, -0.2173,  0.0779],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5381, -1.2910, -0.0879,  ..., -0.5493, -1.7891, -2.5410],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0237, -0.0557, -0.0299,  ...,  0.0083,  0.0271,  0.0193],
        [ 0.0002,  0.0479,  0.0162,  ..., -0.0085, -0.0089, -0.0139],
        [-0.0266, -0.0091,  0.0272,  ..., -0.0090, -0.0138,  0.0111],
        ...,
        [-0.0255,  0.0056,  0.0216,  ...,  0.0385, -0.0071,  0.0007],
        [ 0.0271,  0.0311,  0.0111,  ..., -0.0014, -0.0080, -0.0358],
        [ 0.0099, -0.0011, -0.0375,  ...,  0.0244, -0.0103,  0.0238]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2739, -1.4932, -0.4768,  ..., -0.4646, -2.5078, -2.1367]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 17:02:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of customer is customers
The plural form of department is departments
The plural form of system is systems
The plural form of language is languages
The plural form of problem is problems
The plural form of application is applications
The plural form of development is developments
The plural form of example is
2024-07-26 17:02:17 root INFO     total operator prediction time: 1319.3581757545471 seconds
2024-07-26 17:02:17 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_3pSg - Ved
2024-07-26 17:02:17 root INFO     building operator verb_3pSg - Ved
2024-07-26 17:02:17 root INFO     [order_1_approx] starting weight calculation for When he agrees something, something has been agreed
When he seems something, something has been seemed
When he proposes something, something has been proposed
When he develops something, something has been developed
When he contains something, something has been contained
When he introduces something, something has been introduced
When he hears something, something has been heard
When he publishes something, something has been
2024-07-26 17:02:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 17:04:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2177,  0.3044,  0.0044,  ...,  0.1759, -0.0584,  0.0617],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0215, -2.7539,  2.2188,  ..., -2.5723, -3.0625,  0.6758],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0011,  0.0162,  0.0008,  ..., -0.0054,  0.0143,  0.0057],
        [-0.0125, -0.0018,  0.0014,  ..., -0.0180,  0.0154,  0.0070],
        [ 0.0194,  0.0025, -0.0212,  ..., -0.0091, -0.0113,  0.0066],
        ...,
        [ 0.0002,  0.0267,  0.0029,  ..., -0.0014,  0.0276,  0.0033],
        [ 0.0152, -0.0125, -0.0143,  ..., -0.0220,  0.0054, -0.0243],
        [-0.0092,  0.0234,  0.0052,  ..., -0.0055, -0.0081, -0.0302]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0430, -2.5195,  2.5547,  ..., -2.7715, -3.3398,  0.2725]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 17:05:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he agrees something, something has been agreed
When he seems something, something has been seemed
When he proposes something, something has been proposed
When he develops something, something has been developed
When he contains something, something has been contained
When he introduces something, something has been introduced
When he hears something, something has been heard
When he publishes something, something has been
2024-07-26 17:05:00 root INFO     [order_1_approx] starting weight calculation for When he publishes something, something has been published
When he hears something, something has been heard
When he contains something, something has been contained
When he introduces something, something has been introduced
When he agrees something, something has been agreed
When he develops something, something has been developed
When he proposes something, something has been proposed
When he seems something, something has been
2024-07-26 17:05:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 17:07:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2583,  0.0103, -0.0863,  ...,  0.2461, -0.3062, -0.0501],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7930,  1.6094,  0.7339,  ...,  0.6670, -2.0664, -1.2227],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0079, -0.0250,  0.0097,  ..., -0.0100,  0.0188,  0.0310],
        [-0.0251,  0.0251,  0.0083,  ..., -0.0524, -0.0130, -0.0052],
        [ 0.0085, -0.0069,  0.0113,  ...,  0.0374, -0.0128, -0.0160],
        ...,
        [-0.0223,  0.0102, -0.0060,  ...,  0.0005,  0.0327,  0.0248],
        [-0.0053, -0.0034, -0.0507,  ..., -0.0489,  0.0364, -0.0278],
        [-0.0125,  0.0273, -0.0022,  ...,  0.0473, -0.0154, -0.0249]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7324,  1.4873,  0.8394,  ...,  0.6724, -2.5957, -1.8281]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 17:07:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he publishes something, something has been published
When he hears something, something has been heard
When he contains something, something has been contained
When he introduces something, something has been introduced
When he agrees something, something has been agreed
When he develops something, something has been developed
When he proposes something, something has been proposed
When he seems something, something has been
2024-07-26 17:07:44 root INFO     [order_1_approx] starting weight calculation for When he seems something, something has been seemed
When he proposes something, something has been proposed
When he introduces something, something has been introduced
When he contains something, something has been contained
When he publishes something, something has been published
When he develops something, something has been developed
When he hears something, something has been heard
When he agrees something, something has been
2024-07-26 17:07:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 17:10:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4194,  0.2029, -0.0213,  ...,  0.2399, -0.3315, -0.0177],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.2656, -1.5078,  1.8613,  ...,  0.1545, -1.6836,  0.5762],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0329, -0.0079,  0.0190,  ...,  0.0160,  0.0021,  0.0166],
        [-0.0137,  0.0429, -0.0053,  ...,  0.0087,  0.0033, -0.0184],
        [-0.0080, -0.0050,  0.0026,  ..., -0.0045, -0.0113, -0.0184],
        ...,
        [ 0.0177, -0.0016,  0.0037,  ...,  0.0016,  0.0137, -0.0013],
        [-0.0079, -0.0033, -0.0156,  ..., -0.0290, -0.0034, -0.0404],
        [ 0.0078,  0.0080,  0.0068,  ...,  0.0237, -0.0013, -0.0039]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.4258, -1.5693,  2.3066,  ...,  0.3442, -2.1367,  0.4817]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 17:10:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he seems something, something has been seemed
When he proposes something, something has been proposed
When he introduces something, something has been introduced
When he contains something, something has been contained
When he publishes something, something has been published
When he develops something, something has been developed
When he hears something, something has been heard
When he agrees something, something has been
2024-07-26 17:10:27 root INFO     [order_1_approx] starting weight calculation for When he seems something, something has been seemed
When he publishes something, something has been published
When he agrees something, something has been agreed
When he introduces something, something has been introduced
When he develops something, something has been developed
When he hears something, something has been heard
When he proposes something, something has been proposed
When he contains something, something has been
2024-07-26 17:10:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 17:13:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0241, -0.1263,  0.1096,  ...,  0.0512, -0.3906, -0.3213],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5361,  1.4932,  3.0449,  ..., -2.3008, -1.2246, -3.2383],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0086, -0.0058, -0.0030,  ...,  0.0033,  0.0245,  0.0513],
        [-0.0316,  0.0438,  0.0149,  ..., -0.0016, -0.0024,  0.0122],
        [ 0.0251, -0.0295,  0.0142,  ..., -0.0375,  0.0033, -0.0389],
        ...,
        [-0.0084,  0.0383,  0.0146,  ...,  0.0103,  0.0214, -0.0159],
        [ 0.0345, -0.0499, -0.0245,  ..., -0.0050,  0.0198,  0.0022],
        [ 0.0101, -0.0128, -0.0036,  ..., -0.0098, -0.0315, -0.0125]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4639,  1.3457,  3.0293,  ..., -2.8047, -0.9238, -3.2012]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 17:13:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he seems something, something has been seemed
When he publishes something, something has been published
When he agrees something, something has been agreed
When he introduces something, something has been introduced
When he develops something, something has been developed
When he hears something, something has been heard
When he proposes something, something has been proposed
When he contains something, something has been
2024-07-26 17:13:10 root INFO     [order_1_approx] starting weight calculation for When he seems something, something has been seemed
When he agrees something, something has been agreed
When he publishes something, something has been published
When he introduces something, something has been introduced
When he contains something, something has been contained
When he proposes something, something has been proposed
When he hears something, something has been heard
When he develops something, something has been
2024-07-26 17:13:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 17:15:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1033, -0.0337,  0.0903,  ...,  0.0201, -0.1000, -0.0041],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6992, -0.8960,  4.2617,  ..., -1.5107, -1.8340, -1.7559],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0112, -0.0069,  0.0022,  ..., -0.0088, -0.0012,  0.0202],
        [-0.0078,  0.0107, -0.0069,  ...,  0.0011,  0.0147,  0.0042],
        [-0.0131, -0.0042,  0.0044,  ...,  0.0002,  0.0051, -0.0043],
        ...,
        [ 0.0107,  0.0056,  0.0176,  ...,  0.0141,  0.0069,  0.0246],
        [ 0.0040, -0.0141, -0.0072,  ..., -0.0179, -0.0246, -0.0072],
        [ 0.0017,  0.0028, -0.0115,  ...,  0.0027, -0.0101, -0.0236]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6035, -0.7319,  4.3359,  ..., -1.6777, -1.9590, -1.8750]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 17:15:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he seems something, something has been seemed
When he agrees something, something has been agreed
When he publishes something, something has been published
When he introduces something, something has been introduced
When he contains something, something has been contained
When he proposes something, something has been proposed
When he hears something, something has been heard
When he develops something, something has been
2024-07-26 17:15:53 root INFO     [order_1_approx] starting weight calculation for When he proposes something, something has been proposed
When he develops something, something has been developed
When he seems something, something has been seemed
When he publishes something, something has been published
When he contains something, something has been contained
When he agrees something, something has been agreed
When he introduces something, something has been introduced
When he hears something, something has been
2024-07-26 17:15:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 17:18:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2469,  0.2393,  0.1041,  ..., -0.0260, -0.0788,  0.0588],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3135, -0.3896,  1.9902,  ...,  0.1639, -5.0078, -2.1191],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0248,  0.0010,  0.0161,  ..., -0.0043,  0.0180,  0.0130],
        [-0.0190,  0.0418,  0.0032,  ...,  0.0162, -0.0104, -0.0121],
        [ 0.0187, -0.0006, -0.0143,  ...,  0.0087,  0.0119, -0.0078],
        ...,
        [ 0.0115,  0.0308, -0.0089,  ...,  0.0036,  0.0179, -0.0038],
        [ 0.0064, -0.0258, -0.0040,  ...,  0.0007,  0.0166, -0.0168],
        [-0.0275,  0.0345,  0.0177,  ...,  0.0157,  0.0230, -0.0116]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6416, -0.3662,  1.8867,  ..., -0.0275, -4.8125, -2.6953]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 17:18:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he proposes something, something has been proposed
When he develops something, something has been developed
When he seems something, something has been seemed
When he publishes something, something has been published
When he contains something, something has been contained
When he agrees something, something has been agreed
When he introduces something, something has been introduced
When he hears something, something has been
2024-07-26 17:18:36 root INFO     [order_1_approx] starting weight calculation for When he introduces something, something has been introduced
When he contains something, something has been contained
When he develops something, something has been developed
When he seems something, something has been seemed
When he agrees something, something has been agreed
When he publishes something, something has been published
When he hears something, something has been heard
When he proposes something, something has been
2024-07-26 17:18:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 17:21:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0620,  0.1635, -0.0079,  ...,  0.1022, -0.2295,  0.0473],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3086, -2.3926,  1.7246,  ..., -0.7642, -2.2109,  0.9316],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0073, -0.0010, -0.0090,  ..., -0.0029,  0.0125,  0.0073],
        [ 0.0036,  0.0098, -0.0023,  ..., -0.0067, -0.0059,  0.0089],
        [-0.0078, -0.0048, -0.0126,  ..., -0.0174,  0.0045, -0.0041],
        ...,
        [-0.0100,  0.0086,  0.0085,  ...,  0.0125,  0.0265, -0.0014],
        [ 0.0006,  0.0068, -0.0089,  ..., -0.0047, -0.0164, -0.0234],
        [ 0.0151,  0.0210, -0.0019,  ...,  0.0077, -0.0254, -0.0182]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6230, -2.4062,  1.8672,  ..., -0.8340, -2.5059,  0.8374]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 17:21:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he introduces something, something has been introduced
When he contains something, something has been contained
When he develops something, something has been developed
When he seems something, something has been seemed
When he agrees something, something has been agreed
When he publishes something, something has been published
When he hears something, something has been heard
When he proposes something, something has been
2024-07-26 17:21:18 root INFO     [order_1_approx] starting weight calculation for When he hears something, something has been heard
When he proposes something, something has been proposed
When he publishes something, something has been published
When he contains something, something has been contained
When he seems something, something has been seemed
When he agrees something, something has been agreed
When he develops something, something has been developed
When he introduces something, something has been
2024-07-26 17:21:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 17:23:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2235,  0.1836,  0.0959,  ...,  0.1819, -0.0697,  0.0612],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4219,  0.9697,  2.6680,  ...,  0.6621, -2.0781,  0.4180],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0016, -0.0034,  0.0086,  ...,  0.0090,  0.0122,  0.0191],
        [-0.0089,  0.0123, -0.0054,  ...,  0.0006, -0.0026, -0.0213],
        [ 0.0178,  0.0032,  0.0030,  ..., -0.0025,  0.0102, -0.0083],
        ...,
        [ 0.0199,  0.0153,  0.0058,  ...,  0.0228,  0.0117, -0.0011],
        [ 0.0205,  0.0094,  0.0065,  ..., -0.0074,  0.0008, -0.0115],
        [ 0.0269,  0.0155,  0.0078,  ..., -0.0091, -0.0344, -0.0116]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4180,  0.9790,  2.8262,  ...,  0.2585, -2.1133,  0.1440]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 17:23:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he hears something, something has been heard
When he proposes something, something has been proposed
When he publishes something, something has been published
When he contains something, something has been contained
When he seems something, something has been seemed
When he agrees something, something has been agreed
When he develops something, something has been developed
When he introduces something, something has been
2024-07-26 17:23:59 root INFO     total operator prediction time: 1302.066647529602 seconds
2024-07-26 17:23:59 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj - superlative
2024-07-26 17:23:59 root INFO     building operator adj - superlative
2024-07-26 17:23:59 root INFO     [order_1_approx] starting weight calculation for If something is the most tiny, it is tiniest
If something is the most nice, it is nicest
If something is the most tricky, it is trickiest
If something is the most pure, it is purest
If something is the most lengthy, it is lengthiest
If something is the most rare, it is rarest
If something is the most weird, it is weirdest
If something is the most noisy, it is
2024-07-26 17:23:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 17:26:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1157,  0.0767, -0.0126,  ...,  0.2122, -0.1233,  0.1323],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-4.6094, -3.8535, -0.1001,  ..., -1.5010, -1.9004,  0.0161],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0060, -0.0169,  0.0322,  ...,  0.0265,  0.0013,  0.0355],
        [ 0.0047,  0.0044,  0.0250,  ..., -0.0129, -0.0087,  0.0199],
        [ 0.0119, -0.0153, -0.0064,  ...,  0.0172, -0.0134,  0.0090],
        ...,
        [ 0.0179,  0.0028,  0.0244,  ...,  0.0210, -0.0263,  0.0032],
        [ 0.0128, -0.0081, -0.0035,  ..., -0.0085,  0.0018, -0.0202],
        [ 0.0074,  0.0224,  0.0034,  ...,  0.0086, -0.0116, -0.0153]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-4.5977, -3.9434, -0.2426,  ..., -1.2607, -1.8711, -0.0290]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 17:26:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most tiny, it is tiniest
If something is the most nice, it is nicest
If something is the most tricky, it is trickiest
If something is the most pure, it is purest
If something is the most lengthy, it is lengthiest
If something is the most rare, it is rarest
If something is the most weird, it is weirdest
If something is the most noisy, it is
2024-07-26 17:26:44 root INFO     [order_1_approx] starting weight calculation for If something is the most nice, it is nicest
If something is the most rare, it is rarest
If something is the most pure, it is purest
If something is the most lengthy, it is lengthiest
If something is the most weird, it is weirdest
If something is the most tricky, it is trickiest
If something is the most noisy, it is noisiest
If something is the most tiny, it is
2024-07-26 17:26:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 17:29:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1405,  0.0199, -0.2113,  ...,  0.0770,  0.0228, -0.3164],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.9395,  0.1620, -0.9326,  ..., -4.1992, -2.1074, -0.5913],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0044, -0.0185, -0.0160,  ..., -0.0108,  0.0075,  0.0268],
        [ 0.0195,  0.0125,  0.0233,  ..., -0.0016, -0.0175, -0.0126],
        [ 0.0219, -0.0032, -0.0035,  ..., -0.0166, -0.0292, -0.0208],
        ...,
        [-0.0202, -0.0095, -0.0134,  ...,  0.0306, -0.0134, -0.0218],
        [ 0.0367, -0.0195,  0.0023,  ...,  0.0290,  0.0370, -0.0089],
        [ 0.0024,  0.0200,  0.0115,  ...,  0.0235, -0.0107, -0.0108]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.4512,  0.9082, -0.3574,  ..., -3.9492, -2.3652, -0.6299]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 17:29:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most nice, it is nicest
If something is the most rare, it is rarest
If something is the most pure, it is purest
If something is the most lengthy, it is lengthiest
If something is the most weird, it is weirdest
If something is the most tricky, it is trickiest
If something is the most noisy, it is noisiest
If something is the most tiny, it is
2024-07-26 17:29:27 root INFO     [order_1_approx] starting weight calculation for If something is the most noisy, it is noisiest
If something is the most weird, it is weirdest
If something is the most pure, it is purest
If something is the most tiny, it is tiniest
If something is the most nice, it is nicest
If something is the most lengthy, it is lengthiest
If something is the most tricky, it is trickiest
If something is the most rare, it is
2024-07-26 17:29:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 17:32:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1604,  0.2461, -0.1161,  ..., -0.1953,  0.2394, -0.3823],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-3.6367, -3.9531, -1.6865,  ..., -4.1484, -1.6211, -2.6406],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0149, -0.0005,  0.0063,  ..., -0.0332, -0.0006,  0.0348],
        [-0.0066,  0.0078,  0.0112,  ..., -0.0004,  0.0106,  0.0269],
        [ 0.0099, -0.0139,  0.0083,  ...,  0.0153, -0.0232, -0.0026],
        ...,
        [-0.0107,  0.0205,  0.0103,  ...,  0.0204,  0.0007, -0.0132],
        [-0.0041,  0.0001,  0.0012,  ..., -0.0010,  0.0261, -0.0220],
        [ 0.0166,  0.0201, -0.0107,  ...,  0.0208,  0.0032, -0.0013]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-4.1914, -4.0859, -1.4531,  ..., -4.3633, -1.3369, -2.6836]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 17:32:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most noisy, it is noisiest
If something is the most weird, it is weirdest
If something is the most pure, it is purest
If something is the most tiny, it is tiniest
If something is the most nice, it is nicest
If something is the most lengthy, it is lengthiest
If something is the most tricky, it is trickiest
If something is the most rare, it is
2024-07-26 17:32:13 root INFO     [order_1_approx] starting weight calculation for If something is the most rare, it is rarest
If something is the most weird, it is weirdest
If something is the most noisy, it is noisiest
If something is the most pure, it is purest
If something is the most nice, it is nicest
If something is the most tiny, it is tiniest
If something is the most tricky, it is trickiest
If something is the most lengthy, it is
2024-07-26 17:32:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 17:34:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2220, -0.1465,  0.0952,  ..., -0.1461, -0.0788, -0.2849],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.6270, -5.0586, -1.2578,  ..., -3.1055, -1.3770, -3.0898],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0109, -0.0286, -0.0025,  ...,  0.0006, -0.0256,  0.0114],
        [-0.0201,  0.0125,  0.0095,  ...,  0.0013,  0.0201,  0.0070],
        [ 0.0145, -0.0004,  0.0120,  ...,  0.0212, -0.0179,  0.0142],
        ...,
        [ 0.0042,  0.0022,  0.0326,  ...,  0.0109, -0.0226,  0.0042],
        [ 0.0575,  0.0120,  0.0113,  ...,  0.0186,  0.0144, -0.0307],
        [-0.0230,  0.0213,  0.0090,  ...,  0.0072, -0.0020, -0.0310]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.5879, -4.9805, -1.2705,  ..., -3.1055, -1.3428, -3.2695]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 17:34:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most rare, it is rarest
If something is the most weird, it is weirdest
If something is the most noisy, it is noisiest
If something is the most pure, it is purest
If something is the most nice, it is nicest
If something is the most tiny, it is tiniest
If something is the most tricky, it is trickiest
If something is the most lengthy, it is
2024-07-26 17:34:57 root INFO     [order_1_approx] starting weight calculation for If something is the most lengthy, it is lengthiest
If something is the most tiny, it is tiniest
If something is the most tricky, it is trickiest
If something is the most weird, it is weirdest
If something is the most rare, it is rarest
If something is the most pure, it is purest
If something is the most noisy, it is noisiest
If something is the most nice, it is
2024-07-26 17:34:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 17:37:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0016,  0.0390, -0.0207,  ...,  0.0206, -0.0213, -0.2925],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1797, -0.8203, -4.2656,  ...,  0.6807, -4.6719, -1.5703],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0017, -0.0246,  0.0136,  ..., -0.0080,  0.0138,  0.0198],
        [ 0.0059, -0.0153,  0.0156,  ..., -0.0143, -0.0113, -0.0198],
        [ 0.0352, -0.0230,  0.0242,  ..., -0.0126, -0.0427,  0.0097],
        ...,
        [ 0.0066, -0.0323,  0.0038,  ...,  0.0282,  0.0105, -0.0294],
        [ 0.0048,  0.0030,  0.0138,  ..., -0.0074,  0.0162,  0.0045],
        [ 0.0125,  0.0136,  0.0212,  ...,  0.0202, -0.0311, -0.0101]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1852, -1.2490, -4.4062,  ...,  0.9810, -4.7812, -2.1777]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 17:37:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most lengthy, it is lengthiest
If something is the most tiny, it is tiniest
If something is the most tricky, it is trickiest
If something is the most weird, it is weirdest
If something is the most rare, it is rarest
If something is the most pure, it is purest
If something is the most noisy, it is noisiest
If something is the most nice, it is
2024-07-26 17:37:44 root INFO     [order_1_approx] starting weight calculation for If something is the most tricky, it is trickiest
If something is the most rare, it is rarest
If something is the most weird, it is weirdest
If something is the most lengthy, it is lengthiest
If something is the most tiny, it is tiniest
If something is the most noisy, it is noisiest
If something is the most nice, it is nicest
If something is the most pure, it is
2024-07-26 17:37:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 17:40:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0157,  0.2134,  0.0754,  ..., -0.0638, -0.2029, -0.0914],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0625, -3.8984, -2.3867,  ..., -2.0781, -1.7549, -1.5547],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0074, -0.0260,  0.0315,  ..., -0.0289, -0.0026,  0.0013],
        [-0.0033,  0.0135,  0.0112,  ..., -0.0133,  0.0061,  0.0222],
        [ 0.0034, -0.0180,  0.0152,  ...,  0.0240, -0.0206,  0.0111],
        ...,
        [-0.0030, -0.0059, -0.0132,  ...,  0.0127, -0.0057, -0.0312],
        [ 0.0034, -0.0163, -0.0194,  ..., -0.0008,  0.0102, -0.0325],
        [ 0.0074,  0.0021, -0.0064,  ...,  0.0092, -0.0114, -0.0062]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0469, -3.9023, -2.1602,  ..., -2.0820, -1.6309, -1.3350]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 17:40:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most tricky, it is trickiest
If something is the most rare, it is rarest
If something is the most weird, it is weirdest
If something is the most lengthy, it is lengthiest
If something is the most tiny, it is tiniest
If something is the most noisy, it is noisiest
If something is the most nice, it is nicest
If something is the most pure, it is
2024-07-26 17:40:29 root INFO     [order_1_approx] starting weight calculation for If something is the most nice, it is nicest
If something is the most rare, it is rarest
If something is the most tricky, it is trickiest
If something is the most pure, it is purest
If something is the most tiny, it is tiniest
If something is the most lengthy, it is lengthiest
If something is the most noisy, it is noisiest
If something is the most weird, it is
2024-07-26 17:40:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 17:43:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1207,  0.1587,  0.2764,  ...,  0.0497, -0.0964,  0.0446],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1838, -4.6836, -0.8857,  ..., -1.6963, -1.0801, -2.0898],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0093, -0.0037,  0.0273,  ..., -0.0051, -0.0032,  0.0168],
        [ 0.0192,  0.0039,  0.0172,  ...,  0.0185, -0.0159,  0.0190],
        [ 0.0052, -0.0272,  0.0095,  ...,  0.0114, -0.0372, -0.0087],
        ...,
        [-0.0017, -0.0065,  0.0006,  ...,  0.0377, -0.0151, -0.0180],
        [-0.0047,  0.0093,  0.0158,  ..., -0.0034,  0.0222, -0.0146],
        [ 0.0095,  0.0235,  0.0178,  ...,  0.0153, -0.0039, -0.0015]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1360, -5.1562, -0.9482,  ..., -1.6992, -0.9839, -2.3848]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 17:43:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most nice, it is nicest
If something is the most rare, it is rarest
If something is the most tricky, it is trickiest
If something is the most pure, it is purest
If something is the most tiny, it is tiniest
If something is the most lengthy, it is lengthiest
If something is the most noisy, it is noisiest
If something is the most weird, it is
2024-07-26 17:43:15 root INFO     [order_1_approx] starting weight calculation for If something is the most noisy, it is noisiest
If something is the most lengthy, it is lengthiest
If something is the most weird, it is weirdest
If something is the most pure, it is purest
If something is the most nice, it is nicest
If something is the most rare, it is rarest
If something is the most tiny, it is tiniest
If something is the most tricky, it is
2024-07-26 17:43:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 17:46:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0896,  0.1038,  0.0052,  ...,  0.0864, -0.2549, -0.2162],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8428, -4.1016, -0.8853,  ..., -0.6777, -2.0195,  0.2451],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0026,  0.0010, -0.0471,  ...,  0.0668, -0.0241,  0.0610],
        [ 0.0190, -0.0011, -0.0035,  ..., -0.0062, -0.0448,  0.0458],
        [ 0.0328, -0.0208, -0.0002,  ...,  0.0537, -0.0299, -0.0004],
        ...,
        [-0.0027,  0.0392, -0.0072,  ...,  0.0173, -0.0276, -0.0235],
        [-0.0096, -0.0221,  0.0316,  ..., -0.0454,  0.0025, -0.0378],
        [ 0.0441, -0.0153,  0.0097,  ..., -0.0088, -0.0304, -0.0305]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8140, -4.5273, -0.9531,  ..., -0.1846, -2.3574,  0.0968]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 17:46:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most noisy, it is noisiest
If something is the most lengthy, it is lengthiest
If something is the most weird, it is weirdest
If something is the most pure, it is purest
If something is the most nice, it is nicest
If something is the most rare, it is rarest
If something is the most tiny, it is tiniest
If something is the most tricky, it is
2024-07-26 17:46:02 root INFO     total operator prediction time: 1323.4142262935638 seconds
2024-07-26 17:46:02 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+er_irreg
2024-07-26 17:46:02 root INFO     building operator verb+er_irreg
2024-07-26 17:46:02 root INFO     [order_1_approx] starting weight calculation for If you choreograph something, you are a choreographer
If you manage something, you are a manager
If you examine something, you are a examiner
If you molest something, you are a molester
If you believe something, you are a believer
If you send something, you are a sender
If you tell something, you are a teller
If you entertain something, you are a
2024-07-26 17:46:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 17:48:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1177,  0.2686, -0.0955,  ..., -0.1136, -0.1665, -0.0671],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7715, -1.5869,  0.3691,  ..., -0.6611, -1.5166, -4.2969],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0201, -0.0069,  0.0103,  ..., -0.0050,  0.0112, -0.0213],
        [-0.0201,  0.0242, -0.0095,  ...,  0.0041,  0.0163,  0.0082],
        [ 0.0221,  0.0045,  0.0146,  ...,  0.0124,  0.0089, -0.0094],
        ...,
        [ 0.0311,  0.0058, -0.0132,  ...,  0.0487, -0.0221,  0.0260],
        [-0.0174,  0.0228,  0.0183,  ..., -0.0264, -0.0021,  0.0012],
        [ 0.0072,  0.0260, -0.0221,  ..., -0.0012, -0.0294,  0.0080]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7617, -2.0195,  0.6406,  ..., -0.7129, -0.6919, -4.3242]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 17:48:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you choreograph something, you are a choreographer
If you manage something, you are a manager
If you examine something, you are a examiner
If you molest something, you are a molester
If you believe something, you are a believer
If you send something, you are a sender
If you tell something, you are a teller
If you entertain something, you are a
2024-07-26 17:48:48 root INFO     [order_1_approx] starting weight calculation for If you tell something, you are a teller
If you choreograph something, you are a choreographer
If you send something, you are a sender
If you manage something, you are a manager
If you examine something, you are a examiner
If you believe something, you are a believer
If you entertain something, you are a entertainer
If you molest something, you are a
2024-07-26 17:48:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 17:51:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1580,  0.1387, -0.1971,  ..., -0.1572, -0.2715,  0.0381],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4160, -2.3438, -0.8281,  ..., -2.0781, -2.6758, -0.1738],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.0472e-02,  6.8474e-03,  4.4159e-02,  ...,  1.3290e-02,
         -1.0017e-02,  1.1780e-02],
        [-2.9709e-02,  8.0719e-03,  1.3084e-03,  ...,  8.5831e-03,
         -3.5782e-03,  3.3783e-02],
        [ 1.1864e-02, -2.2003e-02, -6.4278e-03,  ...,  2.7313e-03,
          4.1290e-02,  3.4065e-03],
        ...,
        [ 1.0658e-02,  5.0232e-02,  9.5444e-03,  ...,  1.8921e-02,
          3.9642e-02,  1.7456e-02],
        [ 2.5864e-02, -5.3253e-02, -8.4534e-03,  ..., -3.5339e-02,
          2.8610e-05, -2.0943e-03],
        [ 1.0117e-02,  4.3335e-02, -1.6403e-02,  ..., -3.7384e-02,
         -9.7580e-03,  1.2474e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4824, -1.9307, -0.5986,  ..., -1.4863, -2.7148, -0.1252]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 17:51:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you tell something, you are a teller
If you choreograph something, you are a choreographer
If you send something, you are a sender
If you manage something, you are a manager
If you examine something, you are a examiner
If you believe something, you are a believer
If you entertain something, you are a entertainer
If you molest something, you are a
2024-07-26 17:51:33 root INFO     [order_1_approx] starting weight calculation for If you manage something, you are a manager
If you tell something, you are a teller
If you entertain something, you are a entertainer
If you believe something, you are a believer
If you molest something, you are a molester
If you examine something, you are a examiner
If you choreograph something, you are a choreographer
If you send something, you are a
2024-07-26 17:51:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 17:54:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1404,  0.1838,  0.2749,  ...,  0.1171, -0.1450, -0.2686],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0117, -2.3242, -1.5703,  ..., -0.1787, -1.0107, -3.5020],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0229, -0.0329,  0.0115,  ...,  0.0057,  0.0102, -0.0216],
        [-0.0047,  0.0059,  0.0193,  ..., -0.0172,  0.0128, -0.0127],
        [ 0.0006,  0.0165,  0.0179,  ..., -0.0002,  0.0025,  0.0331],
        ...,
        [ 0.0121,  0.0458, -0.0153,  ...,  0.0108,  0.0064, -0.0035],
        [-0.0165,  0.0185,  0.0049,  ..., -0.0328,  0.0246,  0.0119],
        [ 0.0131,  0.0171,  0.0252,  ..., -0.0044, -0.0284,  0.0041]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3438, -2.6484, -1.1826,  ..., -0.3779, -1.8438, -3.5410]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 17:54:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you manage something, you are a manager
If you tell something, you are a teller
If you entertain something, you are a entertainer
If you believe something, you are a believer
If you molest something, you are a molester
If you examine something, you are a examiner
If you choreograph something, you are a choreographer
If you send something, you are a
2024-07-26 17:54:19 root INFO     [order_1_approx] starting weight calculation for If you manage something, you are a manager
If you send something, you are a sender
If you molest something, you are a molester
If you choreograph something, you are a choreographer
If you examine something, you are a examiner
If you tell something, you are a teller
If you entertain something, you are a entertainer
If you believe something, you are a
2024-07-26 17:54:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 17:57:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0704,  0.2496,  0.1798,  ...,  0.0178, -0.2428,  0.0687],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.5977, -4.9375,  2.6094,  ..., -0.8418, -3.7402, -2.9180],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0135, -0.0120, -0.0128,  ...,  0.0182,  0.0234,  0.0061],
        [-0.0067,  0.0166,  0.0278,  ..., -0.0005,  0.0214,  0.0168],
        [ 0.0119, -0.0152,  0.0278,  ...,  0.0260, -0.0081,  0.0405],
        ...,
        [-0.0146,  0.0011,  0.0146,  ..., -0.0160, -0.0212, -0.0287],
        [ 0.0235, -0.0066, -0.0001,  ..., -0.0024, -0.0060,  0.0089],
        [ 0.0106,  0.0145,  0.0033,  ..., -0.0222, -0.0121,  0.0001]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.7578, -4.8398,  2.2207,  ..., -0.4009, -3.6660, -3.2051]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 17:57:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you manage something, you are a manager
If you send something, you are a sender
If you molest something, you are a molester
If you choreograph something, you are a choreographer
If you examine something, you are a examiner
If you tell something, you are a teller
If you entertain something, you are a entertainer
If you believe something, you are a
2024-07-26 17:57:03 root INFO     [order_1_approx] starting weight calculation for If you tell something, you are a teller
If you molest something, you are a molester
If you believe something, you are a believer
If you examine something, you are a examiner
If you send something, you are a sender
If you entertain something, you are a entertainer
If you choreograph something, you are a choreographer
If you manage something, you are a
2024-07-26 17:57:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 17:59:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1230,  0.4883,  0.0350,  ...,  0.0394, -0.0515, -0.2876],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4980, -2.5352,  2.3359,  ..., -0.7368, -3.7227, -4.2266],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0193,  0.0002,  0.0004,  ..., -0.0129, -0.0039, -0.0072],
        [ 0.0093,  0.0272,  0.0052,  ..., -0.0138,  0.0170,  0.0021],
        [-0.0111, -0.0069,  0.0217,  ..., -0.0020,  0.0020,  0.0024],
        ...,
        [ 0.0139,  0.0266,  0.0067,  ...,  0.0258,  0.0103,  0.0048],
        [-0.0339,  0.0135,  0.0002,  ...,  0.0014,  0.0103,  0.0118],
        [ 0.0235, -0.0040,  0.0205,  ..., -0.0206, -0.0156, -0.0122]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7891, -2.7637,  2.4316,  ..., -0.7280, -3.5410, -4.6562]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 17:59:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you tell something, you are a teller
If you molest something, you are a molester
If you believe something, you are a believer
If you examine something, you are a examiner
If you send something, you are a sender
If you entertain something, you are a entertainer
If you choreograph something, you are a choreographer
If you manage something, you are a
2024-07-26 17:59:48 root INFO     [order_1_approx] starting weight calculation for If you tell something, you are a teller
If you manage something, you are a manager
If you entertain something, you are a entertainer
If you send something, you are a sender
If you choreograph something, you are a choreographer
If you believe something, you are a believer
If you molest something, you are a molester
If you examine something, you are a
2024-07-26 17:59:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 18:02:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0800,  0.0233,  0.0550,  ..., -0.0923,  0.0258, -0.1355],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5156, -2.2383,  0.2520,  ..., -2.5430, -2.6641, -5.1953],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0255, -0.0121, -0.0086,  ...,  0.0170,  0.0097, -0.0051],
        [-0.0337,  0.0089,  0.0367,  ..., -0.0035,  0.0176,  0.0059],
        [ 0.0048,  0.0308, -0.0010,  ...,  0.0215,  0.0197,  0.0141],
        ...,
        [ 0.0209,  0.0138,  0.0041,  ...,  0.0289,  0.0121,  0.0054],
        [-0.0052, -0.0118, -0.0017,  ..., -0.0364, -0.0081, -0.0023],
        [-0.0204,  0.0170,  0.0193,  ...,  0.0226,  0.0007,  0.0129]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5664, -2.6973,  0.2544,  ..., -2.4141, -2.7109, -5.4219]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 18:02:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you tell something, you are a teller
If you manage something, you are a manager
If you entertain something, you are a entertainer
If you send something, you are a sender
If you choreograph something, you are a choreographer
If you believe something, you are a believer
If you molest something, you are a molester
If you examine something, you are a
2024-07-26 18:02:30 root INFO     [order_1_approx] starting weight calculation for If you examine something, you are a examiner
If you molest something, you are a molester
If you manage something, you are a manager
If you entertain something, you are a entertainer
If you choreograph something, you are a choreographer
If you send something, you are a sender
If you believe something, you are a believer
If you tell something, you are a
2024-07-26 18:02:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 18:05:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1987,  0.0732,  0.1213,  ...,  0.1017, -0.0486, -0.2795],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7188, -1.7451,  2.1875,  ...,  2.9395, -3.8594, -2.3398],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0081, -0.0107, -0.0089,  ...,  0.0092,  0.0141,  0.0147],
        [-0.0110,  0.0180,  0.0089,  ..., -0.0201,  0.0111,  0.0151],
        [ 0.0183, -0.0179,  0.0007,  ...,  0.0269, -0.0081,  0.0409],
        ...,
        [ 0.0119, -0.0015,  0.0307,  ...,  0.0079,  0.0127, -0.0028],
        [-0.0188,  0.0014, -0.0084,  ..., -0.0031,  0.0185,  0.0100],
        [-0.0070,  0.0067,  0.0160,  ..., -0.0217,  0.0143, -0.0078]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.2188, -2.1758,  2.5898,  ...,  2.9941, -3.7812, -2.9766]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 18:05:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you examine something, you are a examiner
If you molest something, you are a molester
If you manage something, you are a manager
If you entertain something, you are a entertainer
If you choreograph something, you are a choreographer
If you send something, you are a sender
If you believe something, you are a believer
If you tell something, you are a
2024-07-26 18:05:15 root INFO     [order_1_approx] starting weight calculation for If you entertain something, you are a entertainer
If you send something, you are a sender
If you molest something, you are a molester
If you examine something, you are a examiner
If you tell something, you are a teller
If you believe something, you are a believer
If you manage something, you are a manager
If you choreograph something, you are a
2024-07-26 18:05:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 18:07:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0667,  0.4048, -0.1327,  ...,  0.0111, -0.2974, -0.0771],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5044, -3.9277,  2.3809,  ..., -1.2236, -3.1328, -1.5391],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0275, -0.0121,  0.0023,  ...,  0.0054,  0.0237, -0.0092],
        [-0.0075,  0.0222, -0.0217,  ...,  0.0159,  0.0206, -0.0041],
        [-0.0152, -0.0058,  0.0096,  ..., -0.0113, -0.0028,  0.0026],
        ...,
        [ 0.0119,  0.0265, -0.0070,  ...,  0.0116,  0.0037, -0.0075],
        [-0.0027,  0.0048, -0.0097,  ..., -0.0299,  0.0145,  0.0105],
        [ 0.0008, -0.0039,  0.0172,  ..., -0.0100, -0.0134,  0.0244]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3223, -3.9961,  2.5586,  ..., -1.3252, -2.8711, -1.4355]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 18:07:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you entertain something, you are a entertainer
If you send something, you are a sender
If you molest something, you are a molester
If you examine something, you are a examiner
If you tell something, you are a teller
If you believe something, you are a believer
If you manage something, you are a manager
If you choreograph something, you are a
2024-07-26 18:07:59 root INFO     total operator prediction time: 1316.5653338432312 seconds
2024-07-26 18:07:59 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on over+adj_reg
2024-07-26 18:07:59 root INFO     building operator over+adj_reg
2024-07-26 18:07:59 root INFO     [order_1_approx] starting weight calculation for If something is too dressed, it is overdressed
If something is too stimulated, it is overstimulated
If something is too heated, it is overheated
If something is too ambitious, it is overambitious
If something is too thrown, it is overthrown
If something is too confident, it is overconfident
If something is too written, it is overwritten
If something is too arching, it is
2024-07-26 18:07:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 18:10:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0835, -0.4148,  0.0414,  ...,  0.0456, -0.4165, -0.4863],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9766, -3.3203,  2.7480,  ...,  1.4854, -1.8320, -3.0625],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0500,  0.0116, -0.0254,  ...,  0.0133, -0.0014,  0.0216],
        [-0.0238,  0.0549,  0.0049,  ...,  0.0052, -0.0062,  0.0059],
        [-0.0209,  0.0278,  0.0240,  ..., -0.0060, -0.0092, -0.0193],
        ...,
        [-0.0095,  0.0321,  0.0087,  ...,  0.0438, -0.0035,  0.0085],
        [ 0.0130, -0.0167,  0.0439,  ..., -0.0226,  0.0609, -0.0250],
        [-0.0422,  0.0040, -0.0296,  ...,  0.0106, -0.0257,  0.0191]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3633, -3.6270,  2.1758,  ...,  1.5361, -1.7891, -2.8867]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 18:10:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too dressed, it is overdressed
If something is too stimulated, it is overstimulated
If something is too heated, it is overheated
If something is too ambitious, it is overambitious
If something is too thrown, it is overthrown
If something is too confident, it is overconfident
If something is too written, it is overwritten
If something is too arching, it is
2024-07-26 18:10:40 root INFO     [order_1_approx] starting weight calculation for If something is too thrown, it is overthrown
If something is too ambitious, it is overambitious
If something is too dressed, it is overdressed
If something is too heated, it is overheated
If something is too confident, it is overconfident
If something is too arching, it is overarching
If something is too written, it is overwritten
If something is too stimulated, it is
2024-07-26 18:10:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 18:13:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0797, -0.2959, -0.2368,  ...,  0.0078, -0.5137,  0.1693],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2891, -2.5859,  0.9390,  ...,  0.5752, -1.7080, -2.8359],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0246,  0.0255,  0.0114,  ..., -0.0029, -0.0120,  0.0186],
        [-0.0022,  0.0475,  0.0285,  ..., -0.0201, -0.0125, -0.0007],
        [ 0.0191,  0.0179,  0.0079,  ...,  0.0094,  0.0068, -0.0117],
        ...,
        [-0.0029,  0.0172, -0.0069,  ...,  0.0525,  0.0022, -0.0091],
        [-0.0057, -0.0113, -0.0106,  ..., -0.0239, -0.0004, -0.0100],
        [-0.0185, -0.0013,  0.0042,  ...,  0.0115, -0.0169,  0.0124]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1641, -2.4902,  0.8643,  ...,  0.5986, -1.3750, -2.9551]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 18:13:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too thrown, it is overthrown
If something is too ambitious, it is overambitious
If something is too dressed, it is overdressed
If something is too heated, it is overheated
If something is too confident, it is overconfident
If something is too arching, it is overarching
If something is too written, it is overwritten
If something is too stimulated, it is
2024-07-26 18:13:22 root INFO     [order_1_approx] starting weight calculation for If something is too heated, it is overheated
If something is too arching, it is overarching
If something is too thrown, it is overthrown
If something is too ambitious, it is overambitious
If something is too dressed, it is overdressed
If something is too stimulated, it is overstimulated
If something is too confident, it is overconfident
If something is too written, it is
2024-07-26 18:13:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 18:16:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1395, -0.1316, -0.0647,  ..., -0.1904, -0.2419, -0.1306],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7754, -3.0430,  1.5996,  ...,  0.3423, -2.2227, -2.2305],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0349,  0.0219,  0.0151,  ..., -0.0128,  0.0016,  0.0184],
        [-0.0325,  0.0319,  0.0085,  ...,  0.0023, -0.0216, -0.0184],
        [ 0.0072,  0.0240,  0.0355,  ...,  0.0266,  0.0190, -0.0009],
        ...,
        [ 0.0118,  0.0121,  0.0188,  ...,  0.0352, -0.0126, -0.0078],
        [-0.0143,  0.0300,  0.0101,  ..., -0.0057,  0.0027, -0.0196],
        [ 0.0150,  0.0172,  0.0015,  ..., -0.0017, -0.0168,  0.0082]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9355, -2.7285,  2.3711,  ...,  0.6108, -2.3965, -2.2480]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 18:16:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too heated, it is overheated
If something is too arching, it is overarching
If something is too thrown, it is overthrown
If something is too ambitious, it is overambitious
If something is too dressed, it is overdressed
If something is too stimulated, it is overstimulated
If something is too confident, it is overconfident
If something is too written, it is
2024-07-26 18:16:04 root INFO     [order_1_approx] starting weight calculation for If something is too thrown, it is overthrown
If something is too arching, it is overarching
If something is too stimulated, it is overstimulated
If something is too heated, it is overheated
If something is too dressed, it is overdressed
If something is too written, it is overwritten
If something is too ambitious, it is overambitious
If something is too confident, it is
2024-07-26 18:16:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 18:18:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0649, -0.0846, -0.0148,  ...,  0.3804, -0.2339,  0.0215],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5166, -3.9238,  1.5205,  ...,  2.4609, -1.3516, -1.7031],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.5970e-02,  3.0727e-03,  2.0027e-03,  ...,  8.7662e-03,
         -6.5231e-03,  8.4839e-03],
        [-1.2970e-02,  2.0721e-02,  7.0572e-03,  ..., -7.3624e-03,
          3.2623e-02,  3.0579e-02],
        [ 7.5150e-03,  1.2589e-04,  3.1799e-02,  ..., -1.0651e-02,
         -2.0721e-02, -7.7553e-03],
        ...,
        [ 3.6049e-03,  8.5449e-04,  1.2123e-02,  ...,  5.0262e-02,
          3.8071e-03,  5.3864e-03],
        [-8.8043e-03, -2.5487e-04,  1.9211e-02,  ..., -2.3178e-02,
          3.5767e-02, -4.1077e-02],
        [-1.5747e-02,  1.1721e-03, -5.8365e-04,  ...,  4.8637e-05,
         -1.5457e-02,  4.7913e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7979, -4.2422,  1.2227,  ...,  2.3379, -1.9346, -1.9287]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 18:18:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too thrown, it is overthrown
If something is too arching, it is overarching
If something is too stimulated, it is overstimulated
If something is too heated, it is overheated
If something is too dressed, it is overdressed
If something is too written, it is overwritten
If something is too ambitious, it is overambitious
If something is too confident, it is
2024-07-26 18:18:43 root INFO     [order_1_approx] starting weight calculation for If something is too heated, it is overheated
If something is too ambitious, it is overambitious
If something is too confident, it is overconfident
If something is too dressed, it is overdressed
If something is too written, it is overwritten
If something is too arching, it is overarching
If something is too stimulated, it is overstimulated
If something is too thrown, it is
2024-07-26 18:18:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 18:21:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2800, -0.1678, -0.0311,  ...,  0.0164, -0.3870,  0.1281],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2812, -4.0547,  0.8799,  ...,  0.9292, -2.0352, -2.3652],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.8391e-02,  5.7068e-02, -5.9128e-04,  ..., -2.7466e-04,
          1.9836e-02, -6.3705e-03],
        [-2.9083e-02,  5.5603e-02, -1.1969e-03,  ...,  1.6222e-03,
         -6.6452e-03,  8.0872e-04],
        [ 1.8845e-03,  1.2474e-02,  2.1988e-02,  ..., -1.4153e-03,
         -8.5831e-05,  3.0518e-05],
        ...,
        [ 5.0659e-03,  1.7365e-02, -1.1703e-02,  ...,  1.4503e-02,
         -1.5244e-02, -1.1139e-02],
        [ 2.2430e-02, -2.8534e-02,  7.8888e-03,  ..., -4.1962e-04,
          2.0172e-02, -7.4844e-03],
        [-3.4088e-02,  4.1161e-03,  3.2692e-03,  ...,  3.0613e-04,
         -3.6163e-03,  1.9821e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8145, -4.0938,  0.9146,  ...,  0.6030, -1.7324, -2.5273]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 18:21:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too heated, it is overheated
If something is too ambitious, it is overambitious
If something is too confident, it is overconfident
If something is too dressed, it is overdressed
If something is too written, it is overwritten
If something is too arching, it is overarching
If something is too stimulated, it is overstimulated
If something is too thrown, it is
2024-07-26 18:21:27 root INFO     [order_1_approx] starting weight calculation for If something is too written, it is overwritten
If something is too ambitious, it is overambitious
If something is too heated, it is overheated
If something is too stimulated, it is overstimulated
If something is too thrown, it is overthrown
If something is too confident, it is overconfident
If something is too arching, it is overarching
If something is too dressed, it is
2024-07-26 18:21:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 18:24:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0902, -0.3582, -0.1553,  ..., -0.0427, -0.3354, -0.1121],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2246, -4.0820, -0.4922,  ...,  1.9395, -4.7344, -2.1738],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.5068e-02, -1.9913e-02, -1.5137e-02,  ..., -1.1696e-02,
          2.5711e-03, -1.1063e-02],
        [-2.8839e-02,  2.2430e-02,  4.9973e-03,  ..., -1.6876e-02,
         -1.1131e-02, -3.0518e-05],
        [ 2.3407e-02,  1.9196e-02,  1.6754e-02,  ...,  1.8158e-02,
         -1.9836e-03,  5.6763e-03],
        ...,
        [ 1.1520e-02,  2.7771e-02,  1.9592e-02,  ...,  6.9702e-02,
          2.1667e-03, -2.3376e-02],
        [ 1.3779e-02, -7.3853e-03, -1.6327e-03,  ..., -1.4648e-02,
          2.6993e-02,  5.4779e-03],
        [-1.8356e-02,  1.2131e-03,  6.3438e-03,  ...,  3.2562e-02,
         -1.2283e-02, -3.4065e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2695, -3.9023, -0.5410,  ...,  2.1055, -4.2070, -2.2559]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 18:24:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too written, it is overwritten
If something is too ambitious, it is overambitious
If something is too heated, it is overheated
If something is too stimulated, it is overstimulated
If something is too thrown, it is overthrown
If something is too confident, it is overconfident
If something is too arching, it is overarching
If something is too dressed, it is
2024-07-26 18:24:12 root INFO     [order_1_approx] starting weight calculation for If something is too arching, it is overarching
If something is too written, it is overwritten
If something is too dressed, it is overdressed
If something is too confident, it is overconfident
If something is too stimulated, it is overstimulated
If something is too thrown, it is overthrown
If something is too ambitious, it is overambitious
If something is too heated, it is
2024-07-26 18:24:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 18:26:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2177, -0.4062, -0.0663,  ...,  0.0894, -0.4329,  0.1353],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3438, -2.0195,  0.4546,  ..., -0.0215, -2.1094, -2.5195],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0387,  0.0088,  0.0146,  ..., -0.0331, -0.0037,  0.0057],
        [ 0.0035,  0.0443,  0.0306,  ...,  0.0144, -0.0168,  0.0240],
        [ 0.0044,  0.0019,  0.0070,  ...,  0.0167,  0.0010, -0.0017],
        ...,
        [-0.0075,  0.0396,  0.0011,  ...,  0.0550,  0.0010, -0.0086],
        [ 0.0377, -0.0109, -0.0150,  ...,  0.0088,  0.0241, -0.0039],
        [-0.0269, -0.0208,  0.0009,  ...,  0.0282, -0.0228,  0.0157]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2656, -2.1406,  0.0247,  ...,  0.1328, -2.3223, -2.5059]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 18:26:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too arching, it is overarching
If something is too written, it is overwritten
If something is too dressed, it is overdressed
If something is too confident, it is overconfident
If something is too stimulated, it is overstimulated
If something is too thrown, it is overthrown
If something is too ambitious, it is overambitious
If something is too heated, it is
2024-07-26 18:26:56 root INFO     [order_1_approx] starting weight calculation for If something is too arching, it is overarching
If something is too written, it is overwritten
If something is too heated, it is overheated
If something is too thrown, it is overthrown
If something is too confident, it is overconfident
If something is too stimulated, it is overstimulated
If something is too dressed, it is overdressed
If something is too ambitious, it is
2024-07-26 18:26:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 18:29:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1270, -0.0657, -0.2291,  ...,  0.1707, -0.2323,  0.0966],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5195, -3.2285,  0.1777,  ...,  0.8164, -1.5879, -2.7227],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.6934e-04, -2.7027e-03,  7.0381e-03,  ..., -9.7198e-03,
          6.6876e-05, -4.5471e-03],
        [-5.4321e-03,  2.0660e-02,  8.1177e-03,  ..., -6.4926e-03,
          4.3449e-03,  1.1581e-02],
        [ 9.3689e-03,  2.0142e-02,  3.3386e-02,  ...,  8.0795e-03,
          1.6418e-02, -1.1314e-02],
        ...,
        [ 1.5533e-02,  1.5427e-02,  4.0054e-03,  ...,  8.3160e-03,
         -1.0033e-02, -1.0422e-02],
        [ 2.0889e-02,  1.4175e-02,  2.8809e-02,  ...,  1.7532e-02,
          8.4076e-03,  1.1444e-04],
        [-1.2436e-02, -1.0765e-02, -1.5625e-02,  ...,  4.8866e-03,
          7.6218e-03,  9.2621e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5762, -2.9746, -0.0950,  ...,  0.8896, -1.6299, -2.6758]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 18:29:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too arching, it is overarching
If something is too written, it is overwritten
If something is too heated, it is overheated
If something is too thrown, it is overthrown
If something is too confident, it is overconfident
If something is too stimulated, it is overstimulated
If something is too dressed, it is overdressed
If something is too ambitious, it is
2024-07-26 18:29:40 root INFO     total operator prediction time: 1301.4015271663666 seconds
2024-07-26 18:29:40 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj+ly_reg
2024-07-26 18:29:40 root INFO     building operator adj+ly_reg
2024-07-26 18:29:40 root INFO     [order_1_approx] starting weight calculation for The adjective form of effective is effectively
The adjective form of rare is rarely
The adjective form of popular is popularly
The adjective form of interesting is interestingly
The adjective form of visual is visually
The adjective form of apparent is apparently
The adjective form of extensive is extensively
The adjective form of subsequent is
2024-07-26 18:29:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 18:32:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0421, -0.0082, -0.1399,  ..., -0.1267, -0.3865,  0.4211],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8154,  0.4438,  1.7432,  ..., -0.4944,  1.4873, -3.4023],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0060, -0.0227,  0.0241,  ..., -0.0131,  0.0103,  0.0277],
        [-0.0377, -0.0028,  0.0300,  ..., -0.0286,  0.0292, -0.0079],
        [ 0.0353, -0.0195,  0.0143,  ..., -0.0323, -0.0289, -0.0068],
        ...,
        [ 0.0147,  0.0081,  0.0282,  ...,  0.0720,  0.0049,  0.0194],
        [ 0.0012,  0.0511,  0.0316,  ...,  0.0356,  0.0476, -0.0512],
        [ 0.0014,  0.0360, -0.0183,  ..., -0.0316, -0.0345, -0.0010]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1279,  1.0859,  2.2051,  ..., -0.0774,  1.5107, -3.3145]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 18:32:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of effective is effectively
The adjective form of rare is rarely
The adjective form of popular is popularly
The adjective form of interesting is interestingly
The adjective form of visual is visually
The adjective form of apparent is apparently
The adjective form of extensive is extensively
The adjective form of subsequent is
2024-07-26 18:32:25 root INFO     [order_1_approx] starting weight calculation for The adjective form of rare is rarely
The adjective form of interesting is interestingly
The adjective form of subsequent is subsequently
The adjective form of extensive is extensively
The adjective form of popular is popularly
The adjective form of effective is effectively
The adjective form of apparent is apparently
The adjective form of visual is
2024-07-26 18:32:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 18:35:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0529, -0.0500,  0.1136,  ...,  0.0737, -0.2341, -0.0854],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1523, -2.4883,  1.0029,  ..., -2.0742, -1.3184, -1.3281],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0540, -0.0753,  0.0107,  ..., -0.0053, -0.0109,  0.0534],
        [-0.0039,  0.0305,  0.0361,  ..., -0.0302, -0.0241,  0.0004],
        [ 0.0165, -0.0225,  0.0146,  ...,  0.0017, -0.0252,  0.0229],
        ...,
        [ 0.0088,  0.0332, -0.0252,  ...,  0.0413,  0.0044, -0.0404],
        [ 0.0032,  0.0457, -0.0442,  ...,  0.0103,  0.0229, -0.0358],
        [-0.0079,  0.0178, -0.0018,  ...,  0.0407, -0.0262,  0.0076]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9668, -1.7871,  1.3037,  ..., -2.2324, -2.5039, -1.0352]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 18:35:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of rare is rarely
The adjective form of interesting is interestingly
The adjective form of subsequent is subsequently
The adjective form of extensive is extensively
The adjective form of popular is popularly
The adjective form of effective is effectively
The adjective form of apparent is apparently
The adjective form of visual is
2024-07-26 18:35:09 root INFO     [order_1_approx] starting weight calculation for The adjective form of rare is rarely
The adjective form of subsequent is subsequently
The adjective form of apparent is apparently
The adjective form of popular is popularly
The adjective form of interesting is interestingly
The adjective form of visual is visually
The adjective form of extensive is extensively
The adjective form of effective is
2024-07-26 18:35:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 18:37:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1995,  0.0067,  0.0128,  ..., -0.0328, -0.3855,  0.0565],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6611, -1.9785,  0.5752,  ..., -0.3904, -1.6074, -4.6445],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0156, -0.0160,  0.0020,  ..., -0.0276,  0.0267,  0.0133],
        [-0.0178,  0.0287,  0.0077,  ..., -0.0059,  0.0332, -0.0128],
        [ 0.0263, -0.0070,  0.0004,  ..., -0.0231, -0.0224,  0.0104],
        ...,
        [ 0.0372,  0.0122,  0.0207,  ...,  0.0481,  0.0010, -0.0214],
        [ 0.0158,  0.0064, -0.0047,  ..., -0.0050,  0.0522, -0.0217],
        [ 0.0017,  0.0019,  0.0178,  ...,  0.0074, -0.0012, -0.0112]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4238, -1.5771,  0.5923,  ...,  0.3982, -2.1289, -4.4062]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 18:37:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of rare is rarely
The adjective form of subsequent is subsequently
The adjective form of apparent is apparently
The adjective form of popular is popularly
The adjective form of interesting is interestingly
The adjective form of visual is visually
The adjective form of extensive is extensively
The adjective form of effective is
2024-07-26 18:37:55 root INFO     [order_1_approx] starting weight calculation for The adjective form of apparent is apparently
The adjective form of popular is popularly
The adjective form of extensive is extensively
The adjective form of rare is rarely
The adjective form of visual is visually
The adjective form of effective is effectively
The adjective form of subsequent is subsequently
The adjective form of interesting is
2024-07-26 18:37:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 18:40:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0862,  0.0574,  0.0038,  ...,  0.2188, -0.4243,  0.2311],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9629, -1.6162,  1.2617,  ..., -1.6143, -1.9072, -1.9111],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0003, -0.0204, -0.0024,  ..., -0.0347,  0.0115,  0.0288],
        [-0.0184,  0.0208,  0.0265,  ..., -0.0454,  0.0076, -0.0118],
        [ 0.0274, -0.0050, -0.0011,  ..., -0.0014, -0.0067,  0.0087],
        ...,
        [ 0.0398, -0.0307, -0.0006,  ...,  0.0681,  0.0074, -0.0172],
        [ 0.0751,  0.0154, -0.0021,  ...,  0.0496,  0.0114, -0.0472],
        [ 0.0182,  0.0157,  0.0275,  ...,  0.0098, -0.0023, -0.0248]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1006, -1.3066,  0.9844,  ..., -1.4287, -2.2637, -1.9434]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 18:40:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of apparent is apparently
The adjective form of popular is popularly
The adjective form of extensive is extensively
The adjective form of rare is rarely
The adjective form of visual is visually
The adjective form of effective is effectively
The adjective form of subsequent is subsequently
The adjective form of interesting is
2024-07-26 18:40:41 root INFO     [order_1_approx] starting weight calculation for The adjective form of subsequent is subsequently
The adjective form of effective is effectively
The adjective form of apparent is apparently
The adjective form of interesting is interestingly
The adjective form of popular is popularly
The adjective form of extensive is extensively
The adjective form of visual is visually
The adjective form of rare is
2024-07-26 18:40:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 18:43:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1252, -0.0127, -0.2505,  ..., -0.1877, -0.0349, -0.0760],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.8516, -3.2734, -0.3027,  ..., -3.9375, -3.8867, -4.7070],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0570,  0.0247,  0.0319,  ...,  0.0552, -0.0019,  0.0210],
        [-0.0073,  0.0183,  0.0808,  ...,  0.0417,  0.0144, -0.0087],
        [ 0.0245, -0.0356,  0.0279,  ..., -0.0146, -0.0058,  0.0415],
        ...,
        [ 0.0323,  0.0073,  0.0247,  ...,  0.0826,  0.0179, -0.0518],
        [ 0.0290, -0.0006, -0.0113,  ..., -0.0123,  0.0124, -0.0216],
        [-0.0012,  0.0303,  0.0198,  ..., -0.0157, -0.0043, -0.0255]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-3.6641, -4.5625, -0.2578,  ..., -4.1562, -3.6367, -5.4336]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 18:43:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of subsequent is subsequently
The adjective form of effective is effectively
The adjective form of apparent is apparently
The adjective form of interesting is interestingly
The adjective form of popular is popularly
The adjective form of extensive is extensively
The adjective form of visual is visually
The adjective form of rare is
2024-07-26 18:43:25 root INFO     [order_1_approx] starting weight calculation for The adjective form of apparent is apparently
The adjective form of rare is rarely
The adjective form of popular is popularly
The adjective form of visual is visually
The adjective form of effective is effectively
The adjective form of interesting is interestingly
The adjective form of subsequent is subsequently
The adjective form of extensive is
2024-07-26 18:43:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 18:46:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1230, -0.0479, -0.1065,  ..., -0.1849, -0.2273, -0.0186],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1680, -1.0811, -1.5820,  ..., -1.7832, -1.2393, -3.9551],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0140, -0.0153,  0.0056,  ...,  0.0216,  0.0137,  0.0075],
        [-0.0016,  0.0392,  0.0221,  ..., -0.0299,  0.0012, -0.0093],
        [ 0.0296, -0.0105,  0.0315,  ..., -0.0113,  0.0080,  0.0312],
        ...,
        [ 0.0274,  0.0025,  0.0107,  ...,  0.0400,  0.0026, -0.0015],
        [ 0.0160,  0.0040, -0.0116,  ...,  0.0156,  0.0392, -0.0159],
        [ 0.0079,  0.0199,  0.0151,  ..., -0.0236, -0.0103, -0.0008]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5547, -0.9370, -1.3311,  ..., -1.3281, -1.2939, -3.9746]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 18:46:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of apparent is apparently
The adjective form of rare is rarely
The adjective form of popular is popularly
The adjective form of visual is visually
The adjective form of effective is effectively
The adjective form of interesting is interestingly
The adjective form of subsequent is subsequently
The adjective form of extensive is
2024-07-26 18:46:12 root INFO     [order_1_approx] starting weight calculation for The adjective form of subsequent is subsequently
The adjective form of visual is visually
The adjective form of extensive is extensively
The adjective form of rare is rarely
The adjective form of effective is effectively
The adjective form of interesting is interestingly
The adjective form of popular is popularly
The adjective form of apparent is
2024-07-26 18:46:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 18:48:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3296,  0.1375,  0.0801,  ...,  0.0389, -0.5327,  0.1519],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1279, -1.8496, -0.1895,  ...,  0.9702, -1.8604, -0.2422],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0888,  0.0078,  0.0023,  ...,  0.0077, -0.0512,  0.0584],
        [ 0.0061,  0.0291, -0.0191,  ...,  0.0015,  0.0041, -0.0258],
        [ 0.0323, -0.0164,  0.0866,  ..., -0.0190, -0.0125,  0.0243],
        ...,
        [ 0.0016, -0.0064,  0.0427,  ...,  0.0669, -0.0145,  0.0238],
        [ 0.0661, -0.0297,  0.0063,  ...,  0.0025,  0.0093, -0.0071],
        [-0.0240,  0.0207,  0.0168,  ...,  0.0063, -0.0148, -0.0295]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0801, -1.5723,  0.1572,  ...,  1.0605, -1.8223, -0.4121]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 18:48:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of subsequent is subsequently
The adjective form of visual is visually
The adjective form of extensive is extensively
The adjective form of rare is rarely
The adjective form of effective is effectively
The adjective form of interesting is interestingly
The adjective form of popular is popularly
The adjective form of apparent is
2024-07-26 18:48:56 root INFO     [order_1_approx] starting weight calculation for The adjective form of rare is rarely
The adjective form of apparent is apparently
The adjective form of subsequent is subsequently
The adjective form of visual is visually
The adjective form of extensive is extensively
The adjective form of interesting is interestingly
The adjective form of effective is effectively
The adjective form of popular is
2024-07-26 18:48:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 18:51:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0828,  0.0808,  0.1005,  ...,  0.3152, -0.2703,  0.2081],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5605, -1.9902, -1.3242,  ..., -1.1279, -2.4180, -1.2266],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0026,  0.0014,  0.0324,  ..., -0.0243,  0.0358,  0.0461],
        [-0.0177,  0.0298,  0.0122,  ..., -0.0213, -0.0039, -0.0082],
        [ 0.0327, -0.0155,  0.0199,  ..., -0.0164,  0.0150,  0.0160],
        ...,
        [ 0.0185,  0.0016,  0.0025,  ...,  0.1028, -0.0107, -0.0007],
        [ 0.0295, -0.0313,  0.0119,  ...,  0.0056, -0.0024, -0.0443],
        [-0.0156,  0.0132,  0.0130,  ...,  0.0238,  0.0056, -0.0129]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9512, -2.1562, -1.6875,  ..., -0.6895, -2.4238, -1.7754]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 18:51:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of rare is rarely
The adjective form of apparent is apparently
The adjective form of subsequent is subsequently
The adjective form of visual is visually
The adjective form of extensive is extensively
The adjective form of interesting is interestingly
The adjective form of effective is effectively
The adjective form of popular is
2024-07-26 18:51:40 root INFO     total operator prediction time: 1320.430861711502 seconds
2024-07-26 18:51:40 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+tion_irreg
2024-07-26 18:51:40 root INFO     building operator verb+tion_irreg
2024-07-26 18:51:41 root INFO     [order_1_approx] starting weight calculation for To reorganize results in reorganization
To privatize results in privatization
To allege results in allegation
To install results in installation
To continue results in continuation
To improvize results in improvization
To authorize results in authorization
To observe results in
2024-07-26 18:51:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 18:54:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0143,  0.4277,  0.1525,  ...,  0.0695, -0.3677, -0.0072],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.6367, -4.4062,  1.7812,  ...,  1.1914, -1.2275, -0.9077],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0155,  0.0032,  0.0092,  ..., -0.0520, -0.0125,  0.0164],
        [ 0.0365,  0.0435, -0.0151,  ...,  0.0970, -0.0258, -0.0339],
        [-0.0139, -0.0085,  0.0206,  ...,  0.0153, -0.0173,  0.0220],
        ...,
        [ 0.0007,  0.0225,  0.0045,  ...,  0.0875,  0.0107, -0.0110],
        [-0.0141, -0.0102,  0.0303,  ...,  0.0100,  0.0617, -0.0006],
        [ 0.0300, -0.0115, -0.0005,  ...,  0.1060, -0.0238,  0.0027]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.4336, -3.0391,  1.9629,  ...,  1.2822, -2.2363,  0.1792]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 18:54:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To reorganize results in reorganization
To privatize results in privatization
To allege results in allegation
To install results in installation
To continue results in continuation
To improvize results in improvization
To authorize results in authorization
To observe results in
2024-07-26 18:54:25 root INFO     [order_1_approx] starting weight calculation for To allege results in allegation
To install results in installation
To authorize results in authorization
To observe results in observation
To privatize results in privatization
To improvize results in improvization
To reorganize results in reorganization
To continue results in
2024-07-26 18:54:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 18:57:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0355,  0.2380, -0.0686,  ...,  0.0604, -0.5420,  0.2039],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0498, -7.7227,  1.6602,  ...,  1.2354, -0.6543, -2.1699],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0110,  0.0049, -0.0025,  ..., -0.1643, -0.0034, -0.0441],
        [ 0.0389,  0.0216,  0.0109,  ...,  0.1429, -0.0375,  0.0555],
        [-0.0121,  0.0067,  0.0069,  ..., -0.0278,  0.0171, -0.0027],
        ...,
        [ 0.0520,  0.0057,  0.0228,  ...,  0.1602, -0.0329,  0.0763],
        [-0.0024, -0.0066,  0.0257,  ..., -0.0317,  0.0216, -0.0550],
        [ 0.0453, -0.0159,  0.0161,  ...,  0.0939, -0.0222,  0.1007]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0410, -6.6758,  1.5742,  ...,  1.5723, -1.2676, -1.8691]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 18:57:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To allege results in allegation
To install results in installation
To authorize results in authorization
To observe results in observation
To privatize results in privatization
To improvize results in improvization
To reorganize results in reorganization
To continue results in
2024-07-26 18:57:10 root INFO     [order_1_approx] starting weight calculation for To improvize results in improvization
To continue results in continuation
To reorganize results in reorganization
To install results in installation
To observe results in observation
To authorize results in authorization
To allege results in allegation
To privatize results in
2024-07-26 18:57:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 18:59:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2317, -0.1198, -0.1855,  ..., -0.1486, -0.0304, -0.0011],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8086, -5.4219,  2.4688,  ..., -0.7949,  0.0708, -2.3086],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0518,  0.0168,  0.0133,  ...,  0.0221, -0.0020,  0.0104],
        [-0.0207,  0.0291, -0.0084,  ...,  0.0073,  0.0017,  0.0020],
        [-0.0008, -0.0023,  0.0110,  ...,  0.0159, -0.0033, -0.0040],
        ...,
        [ 0.0060, -0.0174, -0.0067,  ...,  0.0295,  0.0068,  0.0192],
        [-0.0050, -0.0026,  0.0019,  ...,  0.0253,  0.0376, -0.0079],
        [ 0.0088, -0.0214, -0.0102,  ...,  0.0093, -0.0210,  0.0258]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.0068, -5.1211,  2.6465,  ..., -1.0020, -0.2517, -2.0508]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 18:59:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To improvize results in improvization
To continue results in continuation
To reorganize results in reorganization
To install results in installation
To observe results in observation
To authorize results in authorization
To allege results in allegation
To privatize results in
2024-07-26 18:59:53 root INFO     [order_1_approx] starting weight calculation for To reorganize results in reorganization
To authorize results in authorization
To continue results in continuation
To privatize results in privatization
To observe results in observation
To improvize results in improvization
To install results in installation
To allege results in
2024-07-26 18:59:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 19:02:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0157,  0.2920, -0.0171,  ...,  0.0844, -0.4829,  0.1705],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.2520, -5.8594, -0.5117,  ...,  3.2988, -1.5605, -0.7734],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0613,  0.0279,  0.0135,  ..., -0.0147, -0.0840,  0.0641],
        [-0.0400,  0.0228, -0.0232,  ...,  0.0370,  0.0381, -0.0626],
        [-0.0128, -0.0343,  0.0282,  ..., -0.0087,  0.0067, -0.0181],
        ...,
        [-0.0289, -0.0040,  0.0266,  ...,  0.0204, -0.0020,  0.0255],
        [ 0.0362,  0.0032, -0.0154,  ...,  0.0064,  0.0332, -0.0281],
        [-0.0179,  0.0071,  0.0316,  ...,  0.0298, -0.0256,  0.0406]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.6064, -5.1016, -0.6123,  ...,  3.7031, -1.6387, -0.8931]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 19:02:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To reorganize results in reorganization
To authorize results in authorization
To continue results in continuation
To privatize results in privatization
To observe results in observation
To improvize results in improvization
To install results in installation
To allege results in
2024-07-26 19:02:36 root INFO     [order_1_approx] starting weight calculation for To improvize results in improvization
To privatize results in privatization
To install results in installation
To observe results in observation
To reorganize results in reorganization
To allege results in allegation
To continue results in continuation
To authorize results in
2024-07-26 19:02:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 19:05:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0714,  0.5396, -0.0729,  ..., -0.1172, -0.2201,  0.1172],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.5195, -4.8672,  1.0938,  ...,  1.2910, -2.4961, -2.3652],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0516,  0.0093,  0.0366,  ..., -0.0190, -0.0178, -0.0037],
        [-0.0428,  0.0021, -0.0454,  ...,  0.0042,  0.0193,  0.0021],
        [ 0.0042, -0.0082, -0.0214,  ..., -0.0005, -0.0070, -0.0136],
        ...,
        [-0.0022,  0.0044, -0.0287,  ...,  0.0102,  0.0065,  0.0029],
        [-0.0015, -0.0132,  0.0073,  ...,  0.0016,  0.0287,  0.0023],
        [-0.0165, -0.0120, -0.0309,  ...,  0.0252, -0.0071,  0.0040]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.0859, -4.0977,  1.0693,  ...,  1.6514, -2.8555, -1.8047]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 19:05:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To improvize results in improvization
To privatize results in privatization
To install results in installation
To observe results in observation
To reorganize results in reorganization
To allege results in allegation
To continue results in continuation
To authorize results in
2024-07-26 19:05:20 root INFO     [order_1_approx] starting weight calculation for To allege results in allegation
To observe results in observation
To improvize results in improvization
To continue results in continuation
To authorize results in authorization
To privatize results in privatization
To reorganize results in reorganization
To install results in
2024-07-26 19:05:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 19:08:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0240,  0.0159,  0.0367,  ...,  0.0034, -0.3018,  0.1504],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.6348, -3.9492,  2.5918,  ...,  3.0586, -3.8535, -1.7695],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0350, -0.0102, -0.0013,  ..., -0.0019, -0.0294,  0.0257],
        [-0.0163,  0.0018,  0.0159,  ...,  0.0333,  0.0157,  0.0013],
        [ 0.0168, -0.0103,  0.0172,  ..., -0.0157, -0.0157, -0.0002],
        ...,
        [-0.0072,  0.0186, -0.0360,  ...,  0.0374, -0.0064, -0.0093],
        [-0.0337,  0.0202,  0.0100,  ..., -0.0277,  0.0292,  0.0058],
        [-0.0112, -0.0142, -0.0260,  ...,  0.0233, -0.0175,  0.0099]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.6475, -3.2734,  2.3340,  ...,  2.3184, -3.2109, -2.1465]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 19:08:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To allege results in allegation
To observe results in observation
To improvize results in improvization
To continue results in continuation
To authorize results in authorization
To privatize results in privatization
To reorganize results in reorganization
To install results in
2024-07-26 19:08:03 root INFO     [order_1_approx] starting weight calculation for To allege results in allegation
To observe results in observation
To privatize results in privatization
To continue results in continuation
To authorize results in authorization
To install results in installation
To improvize results in improvization
To reorganize results in
2024-07-26 19:08:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 19:10:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1153,  0.2188, -0.2134,  ..., -0.0458, -0.2417,  0.0377],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.6543, -3.0508,  1.5381,  ...,  1.2705,  0.2375, -3.9414],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0096, -0.0146,  0.0034,  ..., -0.0079, -0.0098, -0.0110],
        [-0.0085,  0.0146,  0.0073,  ...,  0.0133,  0.0072,  0.0133],
        [-0.0039,  0.0090, -0.0150,  ...,  0.0007, -0.0176, -0.0011],
        ...,
        [-0.0007,  0.0035,  0.0077,  ...,  0.0133, -0.0007,  0.0073],
        [-0.0101, -0.0190, -0.0108,  ...,  0.0127,  0.0020, -0.0153],
        [-0.0011,  0.0059,  0.0137,  ...,  0.0172,  0.0059,  0.0047]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.6523, -2.4121,  1.8447,  ...,  1.1758, -0.3738, -3.9609]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 19:10:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To allege results in allegation
To observe results in observation
To privatize results in privatization
To continue results in continuation
To authorize results in authorization
To install results in installation
To improvize results in improvization
To reorganize results in
2024-07-26 19:10:46 root INFO     [order_1_approx] starting weight calculation for To allege results in allegation
To reorganize results in reorganization
To continue results in continuation
To authorize results in authorization
To observe results in observation
To privatize results in privatization
To install results in installation
To improvize results in
2024-07-26 19:10:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 19:13:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0544,  0.1119, -0.1826,  ..., -0.2568, -0.2993,  0.0078],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4580, -3.6133,  1.0137,  ...,  3.6797, -0.5859, -2.1562],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0406,  0.0016, -0.0038,  ...,  0.0072, -0.0462, -0.0123],
        [-0.0324,  0.0186,  0.0074,  ..., -0.0040,  0.0266,  0.0062],
        [-0.0279,  0.0020,  0.0073,  ...,  0.0279,  0.0074, -0.0039],
        ...,
        [-0.0213, -0.0073,  0.0008,  ...,  0.0324,  0.0120,  0.0073],
        [-0.0054,  0.0074, -0.0123,  ..., -0.0033,  0.0760,  0.0123],
        [-0.0049,  0.0012, -0.0061,  ..., -0.0234,  0.0067,  0.0440]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6196, -2.5195,  1.2031,  ...,  4.1758,  0.1157, -1.7520]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 19:13:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To allege results in allegation
To reorganize results in reorganization
To continue results in continuation
To authorize results in authorization
To observe results in observation
To privatize results in privatization
To install results in installation
To improvize results in
2024-07-26 19:13:30 root INFO     total operator prediction time: 1309.2830700874329 seconds
2024-07-26 19:13:30 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+able_reg
2024-07-26 19:13:30 root INFO     building operator verb+able_reg
2024-07-26 19:13:30 root INFO     [order_1_approx] starting weight calculation for If you can write something, that thing is writeable
If you can expand something, that thing is expandable
If you can adjust something, that thing is adjustable
If you can protect something, that thing is protectable
If you can contain something, that thing is containable
If you can inflate something, that thing is inflatable
If you can believe something, that thing is believeable
If you can prefer something, that thing is
2024-07-26 19:13:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 19:16:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0902,  0.0347,  0.1953,  ..., -0.0142, -0.0612,  0.3247],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1758,  0.1777, -1.8330,  ..., -0.1339, -6.6992, -4.9688],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0195, -0.0318, -0.0426,  ...,  0.0028,  0.0447,  0.0292],
        [-0.0089,  0.0468,  0.0158,  ..., -0.0236, -0.0462,  0.0294],
        [ 0.0106, -0.0222,  0.0030,  ..., -0.0002, -0.0325,  0.0056],
        ...,
        [ 0.0302, -0.0040,  0.0190,  ...,  0.0268, -0.0036, -0.0111],
        [ 0.0212,  0.0141,  0.0236,  ..., -0.0510, -0.0198, -0.0045],
        [ 0.0064,  0.0098,  0.0189,  ..., -0.0018, -0.0119,  0.0087]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0762e+00,  3.6621e-03, -1.8525e+00,  ..., -7.2021e-03,
         -6.8867e+00, -5.2734e+00]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SubBackward0>) 

                    
2024-07-26 19:16:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can write something, that thing is writeable
If you can expand something, that thing is expandable
If you can adjust something, that thing is adjustable
If you can protect something, that thing is protectable
If you can contain something, that thing is containable
If you can inflate something, that thing is inflatable
If you can believe something, that thing is believeable
If you can prefer something, that thing is
2024-07-26 19:16:16 root INFO     [order_1_approx] starting weight calculation for If you can adjust something, that thing is adjustable
If you can contain something, that thing is containable
If you can prefer something, that thing is preferable
If you can believe something, that thing is believeable
If you can protect something, that thing is protectable
If you can inflate something, that thing is inflatable
If you can write something, that thing is writeable
If you can expand something, that thing is
2024-07-26 19:16:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 19:18:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0903, -0.1570, -0.0636,  ..., -0.0088, -0.2490,  0.1637],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3877, -2.4219,  0.5732,  ..., -1.6738, -7.0391, -4.2344],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0071,  0.0066, -0.0495,  ...,  0.0101,  0.0321, -0.0057],
        [-0.0242,  0.0532,  0.0107,  ..., -0.0011, -0.0199, -0.0158],
        [ 0.0314, -0.0095,  0.0178,  ..., -0.0029, -0.0082, -0.0277],
        ...,
        [ 0.0182, -0.0047,  0.0131,  ...,  0.0275,  0.0249, -0.0006],
        [ 0.0071, -0.0101, -0.0125,  ..., -0.0239,  0.0305,  0.0453],
        [-0.0211, -0.0092, -0.0136,  ...,  0.0061, -0.0254,  0.0414]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0566, -2.1523,  0.8115,  ..., -2.6875, -7.0586, -4.0430]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 19:18:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can adjust something, that thing is adjustable
If you can contain something, that thing is containable
If you can prefer something, that thing is preferable
If you can believe something, that thing is believeable
If you can protect something, that thing is protectable
If you can inflate something, that thing is inflatable
If you can write something, that thing is writeable
If you can expand something, that thing is
2024-07-26 19:19:00 root INFO     [order_1_approx] starting weight calculation for If you can inflate something, that thing is inflatable
If you can protect something, that thing is protectable
If you can adjust something, that thing is adjustable
If you can contain something, that thing is containable
If you can prefer something, that thing is preferable
If you can expand something, that thing is expandable
If you can write something, that thing is writeable
If you can believe something, that thing is
2024-07-26 19:19:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 19:21:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0798,  0.2539,  0.3845,  ...,  0.0175, -0.3613,  0.2468],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0469, -1.9443,  0.5986,  ..., -2.2227, -7.0547, -3.4297],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.3987e-02, -9.0790e-03, -1.2260e-02,  ...,  1.3985e-02,
          2.3010e-02,  3.3752e-02],
        [-3.5343e-03,  2.3376e-02,  8.3160e-03,  ..., -6.2561e-03,
         -5.1117e-04,  1.0529e-03],
        [ 1.4565e-02, -1.9257e-02,  1.1642e-02,  ...,  7.3090e-03,
         -2.7466e-02,  2.1500e-02],
        ...,
        [ 6.0654e-03,  8.6823e-03,  7.8049e-03,  ...,  2.0935e-02,
         -1.2306e-02, -2.3071e-02],
        [-9.5367e-07, -5.4588e-03, -6.4850e-04,  ..., -7.5836e-03,
          1.7738e-03, -1.0704e-02],
        [ 1.9516e-02,  7.3776e-03, -4.8752e-03,  ..., -1.7548e-02,
          3.5629e-03,  1.3283e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8779, -1.8428,  0.6865,  ..., -1.8945, -7.0547, -3.5430]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 19:21:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can inflate something, that thing is inflatable
If you can protect something, that thing is protectable
If you can adjust something, that thing is adjustable
If you can contain something, that thing is containable
If you can prefer something, that thing is preferable
If you can expand something, that thing is expandable
If you can write something, that thing is writeable
If you can believe something, that thing is
2024-07-26 19:21:44 root INFO     [order_1_approx] starting weight calculation for If you can adjust something, that thing is adjustable
If you can inflate something, that thing is inflatable
If you can believe something, that thing is believeable
If you can prefer something, that thing is preferable
If you can expand something, that thing is expandable
If you can protect something, that thing is protectable
If you can write something, that thing is writeable
If you can contain something, that thing is
2024-07-26 19:21:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 19:24:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0875, -0.2195,  0.2080,  ...,  0.0122, -0.2291, -0.2559],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9727, -1.1768,  0.1226,  ..., -3.6211, -4.3516, -3.8965],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0225,  0.0146, -0.0122,  ...,  0.0281, -0.0002,  0.0119],
        [-0.0354,  0.0452,  0.0367,  ...,  0.0132, -0.0383,  0.0279],
        [ 0.0198, -0.0302,  0.0299,  ..., -0.0542,  0.0241, -0.0180],
        ...,
        [ 0.0318, -0.0093,  0.0219,  ...,  0.0164,  0.0136, -0.0111],
        [ 0.0161, -0.0202,  0.0074,  ..., -0.0246,  0.0134,  0.0098],
        [ 0.0171,  0.0160, -0.0085,  ...,  0.0112, -0.0398,  0.0027]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4807, -1.1836,  0.2090,  ..., -3.9492, -4.2148, -3.9180]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 19:24:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can adjust something, that thing is adjustable
If you can inflate something, that thing is inflatable
If you can believe something, that thing is believeable
If you can prefer something, that thing is preferable
If you can expand something, that thing is expandable
If you can protect something, that thing is protectable
If you can write something, that thing is writeable
If you can contain something, that thing is
2024-07-26 19:24:25 root INFO     [order_1_approx] starting weight calculation for If you can write something, that thing is writeable
If you can prefer something, that thing is preferable
If you can contain something, that thing is containable
If you can believe something, that thing is believeable
If you can adjust something, that thing is adjustable
If you can protect something, that thing is protectable
If you can expand something, that thing is expandable
If you can inflate something, that thing is
2024-07-26 19:24:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 19:27:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0360,  0.0906, -0.0505,  ..., -0.0125,  0.0008,  0.4565],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0078, -1.4727,  1.7061,  ..., -0.5825, -5.0039, -1.5205],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0177,  0.0210, -0.0021,  ..., -0.0022,  0.0083, -0.0003],
        [ 0.0067,  0.0301, -0.0113,  ..., -0.0052, -0.0051, -0.0117],
        [ 0.0192, -0.0015, -0.0012,  ..., -0.0107,  0.0046, -0.0154],
        ...,
        [ 0.0197,  0.0274,  0.0205,  ...,  0.0173,  0.0059, -0.0080],
        [ 0.0168, -0.0085,  0.0005,  ..., -0.0085,  0.0157, -0.0146],
        [-0.0094,  0.0329,  0.0378,  ..., -0.0119, -0.0290,  0.0058]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1934, -1.5977,  1.7422,  ..., -0.7651, -5.3398, -1.8877]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 19:27:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can write something, that thing is writeable
If you can prefer something, that thing is preferable
If you can contain something, that thing is containable
If you can believe something, that thing is believeable
If you can adjust something, that thing is adjustable
If you can protect something, that thing is protectable
If you can expand something, that thing is expandable
If you can inflate something, that thing is
2024-07-26 19:27:11 root INFO     [order_1_approx] starting weight calculation for If you can inflate something, that thing is inflatable
If you can believe something, that thing is believeable
If you can prefer something, that thing is preferable
If you can expand something, that thing is expandable
If you can write something, that thing is writeable
If you can contain something, that thing is containable
If you can adjust something, that thing is adjustable
If you can protect something, that thing is
2024-07-26 19:27:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 19:29:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0424, -0.1008,  0.0543,  ...,  0.1121, -0.0055, -0.0186],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3105, -3.8945, -1.4863,  ..., -0.4695, -5.5469, -3.2930],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0317,  0.0229, -0.0118,  ...,  0.0093, -0.0077,  0.0032],
        [-0.0154,  0.0113,  0.0260,  ...,  0.0075, -0.0177,  0.0199],
        [ 0.0231, -0.0243, -0.0025,  ..., -0.0179, -0.0009, -0.0087],
        ...,
        [ 0.0446,  0.0178,  0.0023,  ...,  0.0087, -0.0096, -0.0221],
        [ 0.0180, -0.0154,  0.0139,  ..., -0.0225, -0.0017,  0.0031],
        [ 0.0001,  0.0001,  0.0157,  ...,  0.0087, -0.0094,  0.0107]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3545, -3.7715, -1.7168,  ..., -0.1145, -5.5352, -3.6680]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 19:29:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can inflate something, that thing is inflatable
If you can believe something, that thing is believeable
If you can prefer something, that thing is preferable
If you can expand something, that thing is expandable
If you can write something, that thing is writeable
If you can contain something, that thing is containable
If you can adjust something, that thing is adjustable
If you can protect something, that thing is
2024-07-26 19:29:54 root INFO     [order_1_approx] starting weight calculation for If you can expand something, that thing is expandable
If you can believe something, that thing is believeable
If you can prefer something, that thing is preferable
If you can write something, that thing is writeable
If you can inflate something, that thing is inflatable
If you can contain something, that thing is containable
If you can protect something, that thing is protectable
If you can adjust something, that thing is
2024-07-26 19:29:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 19:32:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2053,  0.1000, -0.0886,  ..., -0.1196, -0.0090,  0.0139],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3633, -1.8945, -2.6602,  ..., -1.0254, -7.2539, -1.4619],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0193,  0.0162,  0.0008,  ...,  0.0190, -0.0079,  0.0072],
        [-0.0106,  0.0612, -0.0155,  ..., -0.0044, -0.0194, -0.0083],
        [ 0.0123, -0.0307,  0.0088,  ..., -0.0040, -0.0230,  0.0159],
        ...,
        [ 0.0374, -0.0176, -0.0017,  ...,  0.0423,  0.0255, -0.0030],
        [-0.0173, -0.0251,  0.0034,  ..., -0.0269,  0.0146, -0.0134],
        [ 0.0079,  0.0008,  0.0311,  ..., -0.0094, -0.0263,  0.0115]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5645, -2.1211, -2.9297,  ..., -1.3623, -6.6914, -1.6758]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 19:32:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can expand something, that thing is expandable
If you can believe something, that thing is believeable
If you can prefer something, that thing is preferable
If you can write something, that thing is writeable
If you can inflate something, that thing is inflatable
If you can contain something, that thing is containable
If you can protect something, that thing is protectable
If you can adjust something, that thing is
2024-07-26 19:32:32 root INFO     [order_1_approx] starting weight calculation for If you can inflate something, that thing is inflatable
If you can expand something, that thing is expandable
If you can prefer something, that thing is preferable
If you can believe something, that thing is believeable
If you can adjust something, that thing is adjustable
If you can protect something, that thing is protectable
If you can contain something, that thing is containable
If you can write something, that thing is
2024-07-26 19:32:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 19:35:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2007,  0.0455, -0.0070,  ...,  0.0279,  0.0396, -0.0435],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1128, -1.7793, -1.3809,  ..., -1.4902, -7.5078, -0.9414],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0311, -0.0074,  0.0133,  ...,  0.0039,  0.0219,  0.0352],
        [ 0.0013,  0.0050,  0.0021,  ..., -0.0069, -0.0213, -0.0047],
        [ 0.0104, -0.0053,  0.0357,  ...,  0.0005, -0.0073,  0.0346],
        ...,
        [ 0.0217,  0.0045, -0.0067,  ...,  0.0319,  0.0032, -0.0123],
        [-0.0153, -0.0054, -0.0037,  ..., -0.0325,  0.0146,  0.0105],
        [ 0.0087,  0.0034,  0.0048,  ..., -0.0111, -0.0164, -0.0061]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4854, -1.5068, -1.5664,  ..., -1.5166, -6.9141, -1.0195]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 19:35:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can inflate something, that thing is inflatable
If you can expand something, that thing is expandable
If you can prefer something, that thing is preferable
If you can believe something, that thing is believeable
If you can adjust something, that thing is adjustable
If you can protect something, that thing is protectable
If you can contain something, that thing is containable
If you can write something, that thing is
2024-07-26 19:35:12 root INFO     total operator prediction time: 1301.796882867813 seconds
2024-07-26 19:35:12 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on un+adj_reg
2024-07-26 19:35:12 root INFO     building operator un+adj_reg
2024-07-26 19:35:12 root INFO     [order_1_approx] starting weight calculation for The opposite of authorized is unauthorized
The opposite of lucky is unlucky
The opposite of published is unpublished
The opposite of acceptable is unacceptable
The opposite of lawful is unlawful
The opposite of used is unused
The opposite of forgettable is unforgettable
The opposite of controlled is
2024-07-26 19:35:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 19:37:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0624, -0.1069, -0.2332,  ..., -0.1444, -0.2263,  0.1221],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5645, -0.3975,  1.1465,  ...,  0.5688,  1.6719, -2.2109],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0344,  0.0052, -0.0463,  ...,  0.0240, -0.0454, -0.0012],
        [-0.0038, -0.0087,  0.0305,  ...,  0.0103, -0.0378, -0.0167],
        [-0.0030,  0.0092,  0.0312,  ...,  0.0490,  0.0076,  0.0117],
        ...,
        [-0.0115,  0.0213, -0.0032,  ..., -0.0209, -0.0315, -0.0380],
        [ 0.0003,  0.0334,  0.0565,  ..., -0.0325,  0.0208, -0.0532],
        [-0.0422, -0.0097,  0.0117,  ...,  0.0128,  0.0206, -0.0059]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1543, -1.0879,  0.7524,  ...,  0.9365,  1.7080, -2.5605]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 19:37:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of authorized is unauthorized
The opposite of lucky is unlucky
The opposite of published is unpublished
The opposite of acceptable is unacceptable
The opposite of lawful is unlawful
The opposite of used is unused
The opposite of forgettable is unforgettable
The opposite of controlled is
2024-07-26 19:37:59 root INFO     [order_1_approx] starting weight calculation for The opposite of used is unused
The opposite of controlled is uncontrolled
The opposite of lucky is unlucky
The opposite of acceptable is unacceptable
The opposite of published is unpublished
The opposite of forgettable is unforgettable
The opposite of lawful is unlawful
The opposite of authorized is
2024-07-26 19:37:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 19:40:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0828,  0.0455, -0.0804,  ..., -0.2261, -0.2905,  0.2861],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1802, -1.8623,  1.1992,  ..., -0.2043,  0.0361, -1.4346],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.5004e-02, -1.0132e-02, -4.8370e-03,  ...,  3.1738e-02,
         -2.6917e-02, -1.9073e-06],
        [ 5.0888e-03,  2.2980e-02,  3.8757e-03,  ..., -2.6321e-04,
         -9.7656e-04,  7.4005e-04],
        [-2.9633e-02, -4.2343e-04,  1.0128e-03,  ..., -1.2909e-02,
         -3.0151e-02, -3.2562e-02],
        ...,
        [ 2.0050e-02,  1.4214e-02, -5.2948e-03,  ...,  2.9831e-02,
         -2.8076e-03,  2.3468e-02],
        [ 4.5853e-03, -1.7719e-03,  2.6531e-03,  ...,  1.0025e-02,
          3.6804e-02, -7.6828e-03],
        [-1.9379e-02, -5.4588e-03, -1.4748e-02,  ..., -1.4793e-02,
         -7.7820e-03,  2.0676e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-4.7607e-02, -1.8076e+00,  1.4551e+00,  ..., -6.1035e-04,
         -1.6760e-01, -1.0918e+00]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SubBackward0>) 

                    
2024-07-26 19:40:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of used is unused
The opposite of controlled is uncontrolled
The opposite of lucky is unlucky
The opposite of acceptable is unacceptable
The opposite of published is unpublished
The opposite of forgettable is unforgettable
The opposite of lawful is unlawful
The opposite of authorized is
2024-07-26 19:40:45 root INFO     [order_1_approx] starting weight calculation for The opposite of forgettable is unforgettable
The opposite of controlled is uncontrolled
The opposite of used is unused
The opposite of authorized is unauthorized
The opposite of acceptable is unacceptable
The opposite of published is unpublished
The opposite of lawful is unlawful
The opposite of lucky is
2024-07-26 19:40:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 19:43:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1829,  0.0924,  0.0501,  ..., -0.2112, -0.0110,  0.0050],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4229, -0.3296, -0.5596,  ..., -2.2402, -0.0537, -2.0449],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0457, -0.0365, -0.0134,  ...,  0.0158, -0.0146,  0.0299],
        [-0.0011,  0.0244, -0.0127,  ...,  0.0507,  0.0146,  0.0278],
        [ 0.0044, -0.0233,  0.0206,  ...,  0.0485, -0.0378,  0.0133],
        ...,
        [ 0.0396,  0.0104,  0.0454,  ..., -0.0150,  0.0050, -0.0083],
        [-0.0235,  0.0351,  0.0158,  ...,  0.0076,  0.0086, -0.0612],
        [-0.0030,  0.0015, -0.0339,  ...,  0.0542,  0.0217,  0.0198]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0137, -0.3965,  0.0254,  ..., -2.7812, -0.7837, -1.9082]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 19:43:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of forgettable is unforgettable
The opposite of controlled is uncontrolled
The opposite of used is unused
The opposite of authorized is unauthorized
The opposite of acceptable is unacceptable
The opposite of published is unpublished
The opposite of lawful is unlawful
The opposite of lucky is
2024-07-26 19:43:31 root INFO     [order_1_approx] starting weight calculation for The opposite of published is unpublished
The opposite of forgettable is unforgettable
The opposite of lawful is unlawful
The opposite of authorized is unauthorized
The opposite of controlled is uncontrolled
The opposite of used is unused
The opposite of lucky is unlucky
The opposite of acceptable is
2024-07-26 19:43:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 19:46:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0830,  0.1755, -0.2000,  ..., -0.0302, -0.4666,  0.0612],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6816, -2.8398,  1.9453,  ...,  0.6323, -2.4805, -1.4795],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0177, -0.0117, -0.0490,  ...,  0.0351, -0.0291,  0.0433],
        [-0.0161,  0.0209, -0.0180,  ..., -0.0315, -0.0090,  0.0152],
        [-0.0184, -0.0054,  0.0147,  ...,  0.0352, -0.0205,  0.0149],
        ...,
        [-0.0212,  0.0264,  0.0323,  ..., -0.0006,  0.0192, -0.0376],
        [-0.0154,  0.0041,  0.0140,  ...,  0.0282,  0.0235, -0.0374],
        [-0.0538,  0.0262, -0.0050,  ..., -0.0298, -0.0538, -0.0043]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5654, -3.8789,  1.9814,  ...,  0.7466, -2.0625, -1.4834]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 19:46:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of published is unpublished
The opposite of forgettable is unforgettable
The opposite of lawful is unlawful
The opposite of authorized is unauthorized
The opposite of controlled is uncontrolled
The opposite of used is unused
The opposite of lucky is unlucky
The opposite of acceptable is
2024-07-26 19:46:16 root INFO     [order_1_approx] starting weight calculation for The opposite of used is unused
The opposite of acceptable is unacceptable
The opposite of lucky is unlucky
The opposite of lawful is unlawful
The opposite of controlled is uncontrolled
The opposite of forgettable is unforgettable
The opposite of authorized is unauthorized
The opposite of published is
2024-07-26 19:46:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 19:48:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2061,  0.0085,  0.0030,  ...,  0.0194, -0.2299,  0.1815],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8164, -1.5957,  0.4727,  ..., -1.9629, -1.9746,  1.6299],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0446,  0.0181, -0.0078,  ...,  0.0223, -0.0017,  0.0006],
        [ 0.0035,  0.0429,  0.0166,  ...,  0.0077, -0.0119,  0.0134],
        [ 0.0081, -0.0433,  0.0090,  ..., -0.0140, -0.0002, -0.0283],
        ...,
        [ 0.0220,  0.0194, -0.0024,  ...,  0.0124, -0.0205,  0.0330],
        [-0.0071, -0.0174,  0.0086,  ...,  0.0144,  0.0591,  0.0235],
        [-0.0233,  0.0428, -0.0360,  ..., -0.0058, -0.0139, -0.0435]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3066, -1.9961,  1.0166,  ..., -1.8662, -2.1699,  1.4961]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 19:49:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of used is unused
The opposite of acceptable is unacceptable
The opposite of lucky is unlucky
The opposite of lawful is unlawful
The opposite of controlled is uncontrolled
The opposite of forgettable is unforgettable
The opposite of authorized is unauthorized
The opposite of published is
2024-07-26 19:49:00 root INFO     [order_1_approx] starting weight calculation for The opposite of authorized is unauthorized
The opposite of acceptable is unacceptable
The opposite of controlled is uncontrolled
The opposite of lucky is unlucky
The opposite of published is unpublished
The opposite of used is unused
The opposite of forgettable is unforgettable
The opposite of lawful is
2024-07-26 19:49:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 19:51:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0876,  0.1262, -0.1812,  ..., -0.1083, -0.3479,  0.1082],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4917, -2.2969,  0.7744,  ...,  2.5352,  0.5767, -1.3857],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0725, -0.0013, -0.0014,  ...,  0.0494, -0.0321,  0.0111],
        [-0.0039,  0.0400, -0.0098,  ...,  0.0052, -0.0034, -0.0014],
        [ 0.0037, -0.0035,  0.0130,  ...,  0.0393, -0.0366,  0.0150],
        ...,
        [ 0.0272,  0.0125, -0.0087,  ..., -0.0333, -0.0144, -0.0363],
        [ 0.0461,  0.0048,  0.0382,  ..., -0.0149, -0.0223, -0.0318],
        [-0.0473,  0.0175, -0.0178,  ..., -0.0044, -0.0481, -0.0011]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7461, -2.7695,  1.3086,  ...,  3.4512,  0.7109, -1.0332]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 19:51:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of authorized is unauthorized
The opposite of acceptable is unacceptable
The opposite of controlled is uncontrolled
The opposite of lucky is unlucky
The opposite of published is unpublished
The opposite of used is unused
The opposite of forgettable is unforgettable
The opposite of lawful is
2024-07-26 19:51:45 root INFO     [order_1_approx] starting weight calculation for The opposite of controlled is uncontrolled
The opposite of lucky is unlucky
The opposite of lawful is unlawful
The opposite of authorized is unauthorized
The opposite of forgettable is unforgettable
The opposite of acceptable is unacceptable
The opposite of published is unpublished
The opposite of used is
2024-07-26 19:51:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 19:54:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3352, -0.1858, -0.1406,  ...,  0.0420, -0.5791,  0.1874],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1309, -2.5312,  0.1504,  ..., -2.4297, -2.7383, -1.1055],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.0925e-02, -3.6438e-02,  1.4633e-02,  ...,  2.9495e-02,
         -4.2053e-02,  4.9744e-03],
        [-7.4158e-03,  8.1482e-02,  5.5115e-02,  ...,  1.7731e-02,
         -5.3406e-05,  3.0945e-02],
        [-1.5060e-02, -2.7084e-02,  3.3264e-02,  ...,  2.5299e-02,
          8.4686e-04, -6.7673e-03],
        ...,
        [ 4.8828e-04,  1.3170e-03,  7.2365e-03,  ..., -8.2397e-04,
          3.6469e-03,  2.4719e-02],
        [-3.7842e-03, -2.0691e-02,  3.9429e-02,  ...,  3.7415e-02,
          9.4788e-02,  5.8929e-02],
        [-1.6968e-02,  5.1041e-03, -5.5969e-02,  ...,  2.9190e-02,
         -1.2970e-04, -1.9409e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7227, -3.0664,  1.3057,  ..., -3.5078, -4.1406, -0.4927]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 19:54:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of controlled is uncontrolled
The opposite of lucky is unlucky
The opposite of lawful is unlawful
The opposite of authorized is unauthorized
The opposite of forgettable is unforgettable
The opposite of acceptable is unacceptable
The opposite of published is unpublished
The opposite of used is
2024-07-26 19:54:30 root INFO     [order_1_approx] starting weight calculation for The opposite of lucky is unlucky
The opposite of lawful is unlawful
The opposite of used is unused
The opposite of acceptable is unacceptable
The opposite of published is unpublished
The opposite of controlled is uncontrolled
The opposite of authorized is unauthorized
The opposite of forgettable is
2024-07-26 19:54:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 19:57:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3408, -0.1993, -0.1980,  ..., -0.1710, -0.3608, -0.0061],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6582, -1.3379, -1.3877,  ..., -0.7886, -6.2852, -3.9941],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.6865e-02,  2.8961e-02, -1.0971e-02,  ...,  1.7807e-02,
          6.3095e-03,  3.0304e-02],
        [-5.2460e-02,  4.4983e-02, -1.7105e-02,  ...,  6.4468e-04,
          5.3139e-03, -2.1698e-02],
        [-2.1515e-03,  1.9470e-02,  1.5289e-02,  ...,  1.0422e-02,
         -1.9241e-02,  7.8049e-03],
        ...,
        [-1.2016e-04, -1.3901e-02,  1.3214e-02,  ..., -5.3520e-03,
          1.7090e-02, -1.6174e-02],
        [ 6.6338e-03, -7.2784e-03,  4.0833e-02,  ...,  3.0518e-05,
          4.2084e-02,  1.5656e-02],
        [-3.3760e-03,  3.8208e-02, -2.7298e-02,  ...,  1.9119e-02,
         -6.1684e-03, -2.5558e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4153, -1.4531, -1.4883,  ..., -0.3562, -6.4414, -4.1367]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 19:57:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of lucky is unlucky
The opposite of lawful is unlawful
The opposite of used is unused
The opposite of acceptable is unacceptable
The opposite of published is unpublished
The opposite of controlled is uncontrolled
The opposite of authorized is unauthorized
The opposite of forgettable is
2024-07-26 19:57:15 root INFO     total operator prediction time: 1323.3780088424683 seconds
2024-07-26 19:57:15 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on re+verb_reg
2024-07-26 19:57:15 root INFO     building operator re+verb_reg
2024-07-26 19:57:15 root INFO     [order_1_approx] starting weight calculation for To assess again is to reassess
To marry again is to remarry
To organize again is to reorganize
To appoint again is to reappoint
To consider again is to reconsider
To invest again is to reinvest
To appear again is to reappear
To investigate again is to
2024-07-26 19:57:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 19:59:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-3.3936e-02,  3.0664e-01, -1.3354e-01,  ...,  1.2207e-04,
        -2.9492e-01,  1.6479e-02], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7798, -3.1172,  1.3574,  ...,  0.2856, -0.4326, -3.4609],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0190, -0.0070,  0.0487,  ...,  0.0053,  0.0316, -0.0064],
        [ 0.0061, -0.0018, -0.0039,  ...,  0.0166, -0.0233,  0.0217],
        [ 0.0008,  0.0180,  0.0298,  ..., -0.0125,  0.0127, -0.0312],
        ...,
        [ 0.0129,  0.0078, -0.0056,  ...,  0.0156,  0.0177, -0.0168],
        [-0.0093,  0.0082, -0.0191,  ...,  0.0084, -0.0134, -0.0041],
        [-0.0053, -0.0020, -0.0010,  ..., -0.0021,  0.0071,  0.0013]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6191, -3.1113,  1.6846,  ...,  0.0454, -0.2001, -3.4746]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 20:00:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To assess again is to reassess
To marry again is to remarry
To organize again is to reorganize
To appoint again is to reappoint
To consider again is to reconsider
To invest again is to reinvest
To appear again is to reappear
To investigate again is to
2024-07-26 20:00:01 root INFO     [order_1_approx] starting weight calculation for To investigate again is to reinvestigate
To marry again is to remarry
To consider again is to reconsider
To appear again is to reappear
To invest again is to reinvest
To organize again is to reorganize
To assess again is to reassess
To appoint again is to
2024-07-26 20:00:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 20:02:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1899,  0.4058, -0.0732,  ...,  0.1121, -0.3452,  0.0186],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4712, -3.7734, -0.0745,  ...,  2.5000, -5.1055, -4.1016],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0484, -0.0030,  0.0195,  ...,  0.0165,  0.0018,  0.0153],
        [ 0.0053,  0.0197,  0.0040,  ...,  0.0098,  0.0028, -0.0005],
        [-0.0069, -0.0111,  0.0214,  ..., -0.0115, -0.0146, -0.0251],
        ...,
        [ 0.0113,  0.0017,  0.0103,  ...,  0.0276, -0.0035,  0.0083],
        [ 0.0005, -0.0081, -0.0092,  ..., -0.0095, -0.0036, -0.0114],
        [-0.0002, -0.0072,  0.0017,  ..., -0.0115, -0.0277,  0.0375]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5415, -3.8984, -0.4268,  ...,  2.2852, -5.1758, -4.0781]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 20:02:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To investigate again is to reinvestigate
To marry again is to remarry
To consider again is to reconsider
To appear again is to reappear
To invest again is to reinvest
To organize again is to reorganize
To assess again is to reassess
To appoint again is to
2024-07-26 20:02:45 root INFO     [order_1_approx] starting weight calculation for To investigate again is to reinvestigate
To consider again is to reconsider
To organize again is to reorganize
To marry again is to remarry
To invest again is to reinvest
To assess again is to reassess
To appoint again is to reappoint
To appear again is to
2024-07-26 20:02:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 20:05:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2925,  0.1592, -0.1697,  ...,  0.0678, -0.1635,  0.0233],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7109, -1.8184, -0.0979,  ...,  3.6387, -4.3047, -2.4629],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0360, -0.0115,  0.0246,  ..., -0.0141, -0.0210,  0.0122],
        [-0.0211,  0.0142, -0.0028,  ...,  0.0405,  0.0052,  0.0036],
        [ 0.0079,  0.0026,  0.0297,  ...,  0.0186,  0.0077, -0.0196],
        ...,
        [-0.0056, -0.0126,  0.0121,  ...,  0.0559, -0.0148,  0.0260],
        [-0.0356, -0.0082, -0.0135,  ..., -0.0460,  0.0274, -0.0317],
        [-0.0176, -0.0304, -0.0214,  ..., -0.0052, -0.0093,  0.0178]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5586, -1.6377, -0.2441,  ...,  3.3359, -4.0898, -2.4180]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 20:05:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To investigate again is to reinvestigate
To consider again is to reconsider
To organize again is to reorganize
To marry again is to remarry
To invest again is to reinvest
To assess again is to reassess
To appoint again is to reappoint
To appear again is to
2024-07-26 20:05:31 root INFO     [order_1_approx] starting weight calculation for To investigate again is to reinvestigate
To appear again is to reappear
To consider again is to reconsider
To invest again is to reinvest
To appoint again is to reappoint
To assess again is to reassess
To organize again is to reorganize
To marry again is to
2024-07-26 20:05:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 20:08:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0737,  0.3022, -0.0473,  ..., -0.0266, -0.2345, -0.0127],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4080, -3.2031,  2.4121,  ..., -0.9863, -3.8535, -3.8906],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0453, -0.0168,  0.0317,  ..., -0.0046, -0.0018,  0.0165],
        [-0.0051,  0.0179,  0.0022,  ...,  0.0003,  0.0055,  0.0081],
        [ 0.0013,  0.0021,  0.0117,  ...,  0.0050,  0.0082, -0.0148],
        ...,
        [ 0.0129,  0.0010,  0.0319,  ...,  0.0134, -0.0005, -0.0056],
        [-0.0040, -0.0137,  0.0043,  ..., -0.0023, -0.0088,  0.0194],
        [ 0.0086, -0.0069, -0.0191,  ...,  0.0058,  0.0018,  0.0361]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5581, -3.0801,  2.4863,  ..., -0.9438, -3.5156, -3.9004]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 20:08:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To investigate again is to reinvestigate
To appear again is to reappear
To consider again is to reconsider
To invest again is to reinvest
To appoint again is to reappoint
To assess again is to reassess
To organize again is to reorganize
To marry again is to
2024-07-26 20:08:15 root INFO     [order_1_approx] starting weight calculation for To appoint again is to reappoint
To assess again is to reassess
To consider again is to reconsider
To marry again is to remarry
To appear again is to reappear
To invest again is to reinvest
To investigate again is to reinvestigate
To organize again is to
2024-07-26 20:08:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 20:11:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0840,  0.4666, -0.0558,  ..., -0.1814, -0.0891,  0.1250],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8506, -3.3398,  0.8345,  ...,  2.1523, -1.4727, -4.3672],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0335,  0.0116,  0.0250,  ...,  0.0029, -0.0120, -0.0142],
        [-0.0071,  0.0190, -0.0075,  ..., -0.0091, -0.0267,  0.0067],
        [-0.0112,  0.0616, -0.0015,  ...,  0.0287,  0.0195, -0.0192],
        ...,
        [ 0.0152, -0.0086,  0.0087,  ...,  0.0118, -0.0152,  0.0044],
        [-0.0105,  0.0056, -0.0143,  ..., -0.0102,  0.0092, -0.0132],
        [-0.0073, -0.0136,  0.0074,  ..., -0.0072, -0.0006,  0.0356]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.9087, -3.0547,  1.0703,  ...,  1.9453, -1.2559, -4.3164]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 20:11:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To appoint again is to reappoint
To assess again is to reassess
To consider again is to reconsider
To marry again is to remarry
To appear again is to reappear
To invest again is to reinvest
To investigate again is to reinvestigate
To organize again is to
2024-07-26 20:11:01 root INFO     [order_1_approx] starting weight calculation for To invest again is to reinvest
To appear again is to reappear
To organize again is to reorganize
To marry again is to remarry
To appoint again is to reappoint
To assess again is to reassess
To investigate again is to reinvestigate
To consider again is to
2024-07-26 20:11:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 20:13:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0766,  0.2421, -0.0703,  ...,  0.1726, -0.1820,  0.1082],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2534, -4.1719,  0.7598,  ...,  0.9224, -2.3945, -3.4043],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0148, -0.0253,  0.0359,  ...,  0.0072,  0.0112,  0.0298],
        [-0.0040,  0.0053, -0.0204,  ...,  0.0075, -0.0045,  0.0018],
        [-0.0026,  0.0052,  0.0418,  ..., -0.0284,  0.0024, -0.0145],
        ...,
        [ 0.0096,  0.0201, -0.0027,  ...,  0.0280,  0.0220,  0.0201],
        [ 0.0132,  0.0110, -0.0018,  ..., -0.0058, -0.0083, -0.0284],
        [ 0.0050,  0.0058, -0.0047,  ..., -0.0166, -0.0275, -0.0115]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3337, -4.4609,  1.1387,  ...,  0.8608, -2.5020, -3.1680]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 20:13:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To invest again is to reinvest
To appear again is to reappear
To organize again is to reorganize
To marry again is to remarry
To appoint again is to reappoint
To assess again is to reassess
To investigate again is to reinvestigate
To consider again is to
2024-07-26 20:13:45 root INFO     [order_1_approx] starting weight calculation for To organize again is to reorganize
To appear again is to reappear
To consider again is to reconsider
To marry again is to remarry
To investigate again is to reinvestigate
To assess again is to reassess
To appoint again is to reappoint
To invest again is to
2024-07-26 20:13:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 20:16:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0689,  0.0541,  0.0818,  ..., -0.0367, -0.2014,  0.0189],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0205, -2.7324,  0.2817,  ...,  1.0791, -2.6289, -3.6875],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0267, -0.0054,  0.0142,  ...,  0.0075, -0.0088, -0.0125],
        [-0.0182,  0.0124, -0.0266,  ..., -0.0006,  0.0124,  0.0080],
        [ 0.0235,  0.0333,  0.0563,  ..., -0.0278, -0.0004, -0.0070],
        ...,
        [ 0.0043, -0.0011,  0.0038,  ..., -0.0002,  0.0027, -0.0044],
        [-0.0200, -0.0054,  0.0105,  ..., -0.0142,  0.0063,  0.0036],
        [-0.0202, -0.0283,  0.0029,  ..., -0.0267,  0.0148,  0.0135]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2461, -2.9648,  0.2590,  ...,  0.5791, -2.7520, -4.0781]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 20:16:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To organize again is to reorganize
To appear again is to reappear
To consider again is to reconsider
To marry again is to remarry
To investigate again is to reinvestigate
To assess again is to reassess
To appoint again is to reappoint
To invest again is to
2024-07-26 20:16:30 root INFO     [order_1_approx] starting weight calculation for To invest again is to reinvest
To appear again is to reappear
To marry again is to remarry
To organize again is to reorganize
To investigate again is to reinvestigate
To consider again is to reconsider
To appoint again is to reappoint
To assess again is to
2024-07-26 20:16:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 20:19:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0491,  0.1209,  0.1226,  ...,  0.1388, -0.2336, -0.1106],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9917, -2.3320, -0.9243,  ...,  0.8213, -4.9531, -4.3555],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0188, -0.0378,  0.0291,  ...,  0.0042, -0.0092,  0.0042],
        [-0.0191,  0.0129,  0.0143,  ...,  0.0126,  0.0023,  0.0253],
        [-0.0229,  0.0004,  0.0251,  ...,  0.0127,  0.0104, -0.0159],
        ...,
        [ 0.0068,  0.0089, -0.0221,  ...,  0.0429,  0.0202,  0.0028],
        [-0.0427, -0.0250, -0.0065,  ...,  0.0123,  0.0263, -0.0074],
        [-0.0123,  0.0179, -0.0260,  ..., -0.0020, -0.0174,  0.0032]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0615, -2.9277, -0.7529,  ...,  0.9312, -4.9023, -4.1953]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 20:19:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To invest again is to reinvest
To appear again is to reappear
To marry again is to remarry
To organize again is to reorganize
To investigate again is to reinvestigate
To consider again is to reconsider
To appoint again is to reappoint
To assess again is to
2024-07-26 20:19:14 root INFO     total operator prediction time: 1319.1375029087067 seconds
2024-07-26 20:19:14 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj+ness_reg
2024-07-26 20:19:14 root INFO     building operator adj+ness_reg
2024-07-26 20:19:14 root INFO     [order_1_approx] starting weight calculation for The state of being distinct is distinctness
The state of being marked is markedness
The state of being situated is situatedness
The state of being rare is rareness
The state of being aware is awareness
The state of being attractive is attractiveness
The state of being fixed is fixedness
The state of being cheap is
2024-07-26 20:19:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 20:21:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1239, -0.0261,  0.0208,  ...,  0.1526, -0.1975,  0.1021],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.7773, -0.0967, -1.9170,  ..., -4.1641, -6.6797, -2.2891],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0249, -0.0175,  0.0046,  ..., -0.0465, -0.0096,  0.0160],
        [-0.0129,  0.0027,  0.0210,  ...,  0.0074,  0.0137,  0.0107],
        [-0.0035,  0.0008,  0.0070,  ..., -0.0108, -0.0139,  0.0041],
        ...,
        [ 0.0118, -0.0322,  0.0004,  ...,  0.0127,  0.0137,  0.0206],
        [ 0.0163, -0.0263, -0.0007,  ..., -0.0383,  0.0187,  0.0148],
        [-0.0163, -0.0182, -0.0595,  ...,  0.0170,  0.0191,  0.0314]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.7988,  0.0281, -2.1855,  ..., -4.0273, -7.2109, -2.2441]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 20:21:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being distinct is distinctness
The state of being marked is markedness
The state of being situated is situatedness
The state of being rare is rareness
The state of being aware is awareness
The state of being attractive is attractiveness
The state of being fixed is fixedness
The state of being cheap is
2024-07-26 20:21:59 root INFO     [order_1_approx] starting weight calculation for The state of being attractive is attractiveness
The state of being marked is markedness
The state of being fixed is fixedness
The state of being situated is situatedness
The state of being distinct is distinctness
The state of being aware is awareness
The state of being cheap is cheapness
The state of being rare is
2024-07-26 20:22:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 20:24:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0845,  0.1671, -0.2031,  ..., -0.0526,  0.0031, -0.1553],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-4.0195, -2.9473, -2.5391,  ..., -5.1289, -5.3594, -5.0898],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0310, -0.0255, -0.0195,  ..., -0.0251, -0.0083,  0.0098],
        [-0.0246, -0.0043,  0.0097,  ..., -0.0005,  0.0202,  0.0303],
        [-0.0014, -0.0446, -0.0060,  ...,  0.0047,  0.0070,  0.0146],
        ...,
        [ 0.0168,  0.0251, -0.0033,  ...,  0.0437, -0.0013,  0.0149],
        [-0.0053,  0.0192,  0.0128,  ..., -0.0206,  0.0125, -0.0245],
        [ 0.0164, -0.0023, -0.0367,  ...,  0.0507, -0.0098,  0.0437]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-3.8711, -2.5352, -2.7520,  ..., -5.4375, -5.8281, -5.6875]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 20:24:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being attractive is attractiveness
The state of being marked is markedness
The state of being fixed is fixedness
The state of being situated is situatedness
The state of being distinct is distinctness
The state of being aware is awareness
The state of being cheap is cheapness
The state of being rare is
2024-07-26 20:24:43 root INFO     [order_1_approx] starting weight calculation for The state of being attractive is attractiveness
The state of being cheap is cheapness
The state of being marked is markedness
The state of being situated is situatedness
The state of being aware is awareness
The state of being rare is rareness
The state of being fixed is fixedness
The state of being distinct is
2024-07-26 20:24:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 20:27:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2578,  0.1125, -0.0533,  ...,  0.1593, -0.1808,  0.0637],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2676, -1.8008, -1.0400,  ..., -2.8906, -4.7656, -0.9878],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0201, -0.0152, -0.0204,  ..., -0.0061,  0.0131,  0.0034],
        [ 0.0007, -0.0001,  0.0131,  ..., -0.0046, -0.0168,  0.0034],
        [ 0.0077, -0.0213,  0.0224,  ..., -0.0228, -0.0206, -0.0122],
        ...,
        [ 0.0001,  0.0095,  0.0203,  ...,  0.0336,  0.0104, -0.0279],
        [ 0.0134, -0.0490,  0.0026,  ..., -0.0237,  0.0215,  0.0098],
        [ 0.0057,  0.0042,  0.0152,  ...,  0.0101, -0.0095,  0.0212]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0151, -1.6562, -0.9897,  ..., -2.5098, -5.2031, -1.1279]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 20:27:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being attractive is attractiveness
The state of being cheap is cheapness
The state of being marked is markedness
The state of being situated is situatedness
The state of being aware is awareness
The state of being rare is rareness
The state of being fixed is fixedness
The state of being distinct is
2024-07-26 20:27:27 root INFO     [order_1_approx] starting weight calculation for The state of being situated is situatedness
The state of being distinct is distinctness
The state of being cheap is cheapness
The state of being attractive is attractiveness
The state of being rare is rareness
The state of being marked is markedness
The state of being aware is awareness
The state of being fixed is
2024-07-26 20:27:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 20:30:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0040, -0.0375, -0.3228,  ..., -0.0632, -0.1136,  0.1993],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2988, -3.6641,  0.1267,  ...,  0.1182, -4.5625, -3.0547],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0092, -0.0244, -0.0265,  ..., -0.0263,  0.0012,  0.0043],
        [-0.0010,  0.0266, -0.0088,  ...,  0.0143,  0.0246,  0.0080],
        [-0.0271, -0.0340,  0.0071,  ..., -0.0070, -0.0114,  0.0035],
        ...,
        [ 0.0029,  0.0250,  0.0363,  ...,  0.0310, -0.0263, -0.0545],
        [-0.0297, -0.0037,  0.0015,  ..., -0.0137,  0.0332, -0.0190],
        [ 0.0133,  0.0278,  0.0146,  ...,  0.0066, -0.0142,  0.0331]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5352, -3.8105, -0.1445,  ...,  0.5615, -4.4180, -3.3203]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 20:30:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being situated is situatedness
The state of being distinct is distinctness
The state of being cheap is cheapness
The state of being attractive is attractiveness
The state of being rare is rareness
The state of being marked is markedness
The state of being aware is awareness
The state of being fixed is
2024-07-26 20:30:11 root INFO     [order_1_approx] starting weight calculation for The state of being rare is rareness
The state of being attractive is attractiveness
The state of being situated is situatedness
The state of being cheap is cheapness
The state of being distinct is distinctness
The state of being aware is awareness
The state of being fixed is fixedness
The state of being marked is
2024-07-26 20:30:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 20:32:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2778,  0.0787, -0.2773,  ...,  0.2169, -0.3252,  0.0997],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.0293, -2.4023, -3.0039,  ..., -2.8613, -1.9922, -1.3076],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0252,  0.0071, -0.0051,  ..., -0.0141,  0.0066,  0.0397],
        [ 0.0148,  0.0471, -0.0193,  ..., -0.0165, -0.0057, -0.0033],
        [-0.0171, -0.0022,  0.0216,  ..., -0.0094, -0.0307,  0.0166],
        ...,
        [ 0.0449,  0.0211,  0.0159,  ...,  0.0382,  0.0027, -0.0005],
        [ 0.0120, -0.0529,  0.0076,  ..., -0.0025,  0.0968,  0.0138],
        [ 0.0103,  0.0396, -0.0076,  ...,  0.0274, -0.0440,  0.0161]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.0059, -2.0312, -3.1309,  ..., -2.7559, -2.9375, -1.5000]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 20:32:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being rare is rareness
The state of being attractive is attractiveness
The state of being situated is situatedness
The state of being cheap is cheapness
The state of being distinct is distinctness
The state of being aware is awareness
The state of being fixed is fixedness
The state of being marked is
2024-07-26 20:32:56 root INFO     [order_1_approx] starting weight calculation for The state of being rare is rareness
The state of being fixed is fixedness
The state of being situated is situatedness
The state of being attractive is attractiveness
The state of being cheap is cheapness
The state of being marked is markedness
The state of being distinct is distinctness
The state of being aware is
2024-07-26 20:32:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 20:35:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1658,  0.1796, -0.1401,  ...,  0.1093, -0.2600, -0.0524],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3711, -2.6211, -0.9038,  ..., -1.0176, -4.7812,  0.2578],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0430,  0.0150, -0.0129,  ..., -0.0010, -0.0047,  0.0026],
        [ 0.0277,  0.0096, -0.0118,  ...,  0.0021, -0.0027, -0.0070],
        [-0.0117, -0.0228, -0.0082,  ..., -0.0238, -0.0277,  0.0037],
        ...,
        [ 0.0133,  0.0061,  0.0099,  ...,  0.0215,  0.0027, -0.0166],
        [ 0.0178,  0.0310,  0.0161,  ..., -0.0336,  0.0139, -0.0318],
        [ 0.0012,  0.0437,  0.0206,  ...,  0.0077, -0.0314,  0.0212]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1388, -2.7910, -1.3525,  ..., -1.3984, -5.0938, -0.0828]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 20:35:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being rare is rareness
The state of being fixed is fixedness
The state of being situated is situatedness
The state of being attractive is attractiveness
The state of being cheap is cheapness
The state of being marked is markedness
The state of being distinct is distinctness
The state of being aware is
2024-07-26 20:35:41 root INFO     [order_1_approx] starting weight calculation for The state of being attractive is attractiveness
The state of being distinct is distinctness
The state of being aware is awareness
The state of being cheap is cheapness
The state of being rare is rareness
The state of being marked is markedness
The state of being fixed is fixedness
The state of being situated is
2024-07-26 20:35:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 20:38:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1726,  0.2292,  0.0790,  ...,  0.1603, -0.3530, -0.0760],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5508, -2.3047, -2.5723,  ..., -2.5586, -4.3398, -2.7949],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0080,  0.0012,  0.0121,  ..., -0.0353,  0.0265, -0.0319],
        [ 0.0188,  0.0611, -0.0015,  ...,  0.0012, -0.0003,  0.0103],
        [-0.0246, -0.0043,  0.0037,  ..., -0.0220, -0.0187, -0.0087],
        ...,
        [ 0.0035,  0.0085,  0.0277,  ...,  0.0396, -0.0287,  0.0043],
        [-0.0433, -0.0258,  0.0130,  ..., -0.0007,  0.0435, -0.0356],
        [-0.0029,  0.0422,  0.0146,  ...,  0.0312, -0.0355,  0.0447]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9922, -2.2129, -2.8965,  ..., -2.8105, -4.7891, -3.1504]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 20:38:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being attractive is attractiveness
The state of being distinct is distinctness
The state of being aware is awareness
The state of being cheap is cheapness
The state of being rare is rareness
The state of being marked is markedness
The state of being fixed is fixedness
The state of being situated is
2024-07-26 20:38:28 root INFO     [order_1_approx] starting weight calculation for The state of being aware is awareness
The state of being rare is rareness
The state of being cheap is cheapness
The state of being distinct is distinctness
The state of being fixed is fixedness
The state of being marked is markedness
The state of being situated is situatedness
The state of being attractive is
2024-07-26 20:38:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 20:41:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0790,  0.1772, -0.0531,  ...,  0.1991, -0.0323, -0.1461],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2275, -1.0537, -3.5000,  ..., -0.6729, -4.2891, -3.5410],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0249, -0.0029,  0.0056,  ..., -0.0063, -0.0134,  0.0026],
        [-0.0315,  0.0138,  0.0043,  ...,  0.0051,  0.0173,  0.0029],
        [ 0.0124, -0.0074,  0.0010,  ..., -0.0238,  0.0013, -0.0093],
        ...,
        [ 0.0014,  0.0212, -0.0016,  ...,  0.0296,  0.0088, -0.0269],
        [ 0.0107,  0.0101,  0.0132,  ..., -0.0163, -0.0062, -0.0107],
        [ 0.0062,  0.0025, -0.0029,  ...,  0.0096, -0.0058,  0.0235]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3428, -0.9336, -3.5547,  ..., -0.4487, -4.5938, -3.5410]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 20:41:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being aware is awareness
The state of being rare is rareness
The state of being cheap is cheapness
The state of being distinct is distinctness
The state of being fixed is fixedness
The state of being marked is markedness
The state of being situated is situatedness
The state of being attractive is
2024-07-26 20:41:11 root INFO     total operator prediction time: 1316.6091153621674 seconds
2024-07-26 20:41:11 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun+less_reg
2024-07-26 20:41:11 root INFO     building operator noun+less_reg
2024-07-26 20:41:11 root INFO     [order_1_approx] starting weight calculation for Something without guilt is guiltless
Something without defence is defenceless
Something without speech is speechless
Something without sleeve is sleeveless
Something without window is windowless
Something without friction is frictionless
Something without bone is boneless
Something without effort is
2024-07-26 20:41:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 20:43:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1098,  0.0003,  0.0262,  ..., -0.0396, -0.2122,  0.1331],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6602, -3.7812, -1.7031,  ..., -1.5254, -4.1797, -4.3477],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0032,  0.0151,  0.0105,  ...,  0.0093,  0.0024, -0.0039],
        [ 0.0064,  0.0358,  0.0078,  ...,  0.0100,  0.0102,  0.0155],
        [ 0.0026,  0.0179,  0.0167,  ..., -0.0126, -0.0126, -0.0101],
        ...,
        [ 0.0098,  0.0116, -0.0217,  ...,  0.0144,  0.0076,  0.0190],
        [ 0.0159, -0.0064,  0.0160,  ..., -0.0237, -0.0096,  0.0131],
        [ 0.0157, -0.0002, -0.0088,  ..., -0.0255,  0.0038,  0.0169]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2305, -3.1914, -1.4600,  ..., -1.2842, -4.7188, -4.8438]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 20:43:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without guilt is guiltless
Something without defence is defenceless
Something without speech is speechless
Something without sleeve is sleeveless
Something without window is windowless
Something without friction is frictionless
Something without bone is boneless
Something without effort is
2024-07-26 20:43:56 root INFO     [order_1_approx] starting weight calculation for Something without speech is speechless
Something without effort is effortless
Something without friction is frictionless
Something without guilt is guiltless
Something without window is windowless
Something without sleeve is sleeveless
Something without defence is defenceless
Something without bone is
2024-07-26 20:43:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 20:46:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1218, -0.1108, -0.1121,  ...,  0.0862, -0.3191,  0.0612],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0601, -0.9927, -0.0312,  ..., -1.5928, -2.1777, -2.0605],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.5990e-02, -2.0966e-02,  2.4429e-02,  ...,  2.4605e-03,
         -1.9379e-03,  3.4058e-02],
        [-1.3828e-03,  3.4515e-02, -7.6637e-03,  ...,  2.1805e-02,
          2.3071e-02, -1.3977e-02],
        [-3.1147e-03, -1.9089e-02,  2.0332e-03,  ...,  3.0117e-03,
         -8.5144e-03,  8.9417e-03],
        ...,
        [ 1.7288e-02,  4.2450e-02,  1.8829e-02,  ...,  2.6733e-02,
         -8.7433e-03,  2.3483e-02],
        [ 1.2230e-02,  3.5339e-02, -2.7130e-02,  ...,  2.8057e-03,
          7.9269e-03, -3.6713e-02],
        [ 4.1962e-05,  3.7537e-02,  9.9716e-03,  ...,  2.2751e-02,
          1.1269e-02, -1.4343e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2175, -0.9927,  0.4480,  ..., -1.2344, -1.7998, -2.0527]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 20:46:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without speech is speechless
Something without effort is effortless
Something without friction is frictionless
Something without guilt is guiltless
Something without window is windowless
Something without sleeve is sleeveless
Something without defence is defenceless
Something without bone is
2024-07-26 20:46:40 root INFO     [order_1_approx] starting weight calculation for Something without guilt is guiltless
Something without bone is boneless
Something without speech is speechless
Something without effort is effortless
Something without window is windowless
Something without friction is frictionless
Something without defence is defenceless
Something without sleeve is
2024-07-26 20:46:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 20:49:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0610, -0.4287,  0.1697,  ..., -0.0541, -0.0091, -0.2240],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3281, -3.7344, -2.0469,  ...,  0.3921, -1.7900,  1.0020],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0086,  0.0066,  0.0203,  ...,  0.0007,  0.0041,  0.0082],
        [-0.0040,  0.0114, -0.0059,  ...,  0.0008, -0.0024, -0.0071],
        [ 0.0228, -0.0016,  0.0099,  ...,  0.0165, -0.0207,  0.0144],
        ...,
        [ 0.0244,  0.0114,  0.0050,  ...,  0.0194,  0.0273,  0.0076],
        [-0.0038,  0.0135,  0.0005,  ...,  0.0048,  0.0022, -0.0240],
        [-0.0218,  0.0223, -0.0094,  ...,  0.0019,  0.0054, -0.0202]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6758, -3.7910, -1.9199,  ...,  0.3135, -1.9580,  1.0625]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 20:49:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without guilt is guiltless
Something without bone is boneless
Something without speech is speechless
Something without effort is effortless
Something without window is windowless
Something without friction is frictionless
Something without defence is defenceless
Something without sleeve is
2024-07-26 20:49:24 root INFO     [order_1_approx] starting weight calculation for Something without effort is effortless
Something without window is windowless
Something without guilt is guiltless
Something without bone is boneless
Something without sleeve is sleeveless
Something without speech is speechless
Something without defence is defenceless
Something without friction is
2024-07-26 20:49:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 20:52:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0167, -0.1832, -0.1703,  ..., -0.0925,  0.0457,  0.1125],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5117, -0.7998,  1.3623,  ..., -1.5283, -3.0938,  0.4268],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0245,  0.0019,  0.0303,  ...,  0.0132,  0.0190, -0.0125],
        [-0.0127,  0.0190, -0.0251,  ...,  0.0090, -0.0223,  0.0083],
        [-0.0171,  0.0240,  0.0192,  ..., -0.0105, -0.0132, -0.0008],
        ...,
        [ 0.0040,  0.0251, -0.0123,  ...,  0.0649, -0.0031,  0.0110],
        [ 0.0141,  0.0187,  0.0045,  ..., -0.0073,  0.0284,  0.0008],
        [-0.0161,  0.0204, -0.0157,  ..., -0.0002,  0.0073,  0.0138]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7969, -0.8486,  1.3232,  ..., -1.4619, -2.7031,  0.5474]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 20:52:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without effort is effortless
Something without window is windowless
Something without guilt is guiltless
Something without bone is boneless
Something without sleeve is sleeveless
Something without speech is speechless
Something without defence is defenceless
Something without friction is
2024-07-26 20:52:06 root INFO     [order_1_approx] starting weight calculation for Something without speech is speechless
Something without bone is boneless
Something without friction is frictionless
Something without window is windowless
Something without effort is effortless
Something without sleeve is sleeveless
Something without defence is defenceless
Something without guilt is
2024-07-26 20:52:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 20:54:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0645, -0.1176, -0.2050,  ...,  0.0725, -0.0745,  0.3809],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3145, -3.1602,  1.0684,  ..., -1.8330, -1.3574, -1.5664],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0324, -0.0103,  0.0122,  ...,  0.0174, -0.0044,  0.0335],
        [ 0.0001,  0.0039,  0.0100,  ..., -0.0064, -0.0155, -0.0007],
        [ 0.0087, -0.0175,  0.0073,  ..., -0.0039, -0.0034,  0.0067],
        ...,
        [ 0.0255,  0.0098,  0.0055,  ..., -0.0019, -0.0086, -0.0100],
        [-0.0071, -0.0126,  0.0134,  ..., -0.0282,  0.0036, -0.0090],
        [ 0.0075,  0.0067, -0.0010,  ...,  0.0016, -0.0023,  0.0217]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5859, -3.4355,  0.8726,  ..., -1.4111, -1.6406, -1.5254]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 20:54:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without speech is speechless
Something without bone is boneless
Something without friction is frictionless
Something without window is windowless
Something without effort is effortless
Something without sleeve is sleeveless
Something without defence is defenceless
Something without guilt is
2024-07-26 20:54:49 root INFO     [order_1_approx] starting weight calculation for Something without guilt is guiltless
Something without sleeve is sleeveless
Something without speech is speechless
Something without defence is defenceless
Something without friction is frictionless
Something without bone is boneless
Something without effort is effortless
Something without window is
2024-07-26 20:54:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 20:57:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2546, -0.4973, -0.1954,  ...,  0.2231,  0.1510, -0.0118],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8369, -4.2148, -0.5083,  ..., -1.1230, -3.8164,  2.5820],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0325, -0.0247,  0.0071,  ...,  0.0031,  0.0056,  0.0327],
        [ 0.0319, -0.0064,  0.0052,  ..., -0.0026,  0.0062,  0.0253],
        [ 0.0010,  0.0092,  0.0019,  ..., -0.0046, -0.0103, -0.0050],
        ...,
        [-0.0016,  0.0218,  0.0122,  ..., -0.0255, -0.0130, -0.0322],
        [-0.0160, -0.0236, -0.0157,  ...,  0.0069,  0.0230,  0.0046],
        [-0.0417,  0.0281, -0.0268,  ..., -0.0096, -0.0014, -0.0378]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2241, -5.1289, -1.0215,  ..., -1.9277, -3.4570,  2.6836]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 20:57:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without guilt is guiltless
Something without sleeve is sleeveless
Something without speech is speechless
Something without defence is defenceless
Something without friction is frictionless
Something without bone is boneless
Something without effort is effortless
Something without window is
2024-07-26 20:57:34 root INFO     [order_1_approx] starting weight calculation for Something without window is windowless
Something without bone is boneless
Something without defence is defenceless
Something without friction is frictionless
Something without sleeve is sleeveless
Something without effort is effortless
Something without guilt is guiltless
Something without speech is
2024-07-26 20:57:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 21:00:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0831, -0.0749,  0.1101,  ...,  0.0508,  0.0891,  0.2866],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.9053, -2.6094,  0.0696,  ...,  0.0674, -1.5508, -0.4385],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0262, -0.0183,  0.0091,  ..., -0.0120,  0.0307,  0.0241],
        [-0.0034,  0.0343,  0.0065,  ..., -0.0019, -0.0213, -0.0014],
        [ 0.0146, -0.0386,  0.0214,  ...,  0.0125, -0.0178, -0.0007],
        ...,
        [ 0.0062, -0.0036,  0.0156,  ..., -0.0069,  0.0101,  0.0035],
        [-0.0137, -0.0339, -0.0074,  ..., -0.0330,  0.0198, -0.0224],
        [-0.0144,  0.0022, -0.0071,  ...,  0.0052, -0.0086, -0.0075]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5762, -3.1934, -0.4167,  ...,  0.0141, -1.6934, -0.6763]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 21:00:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without window is windowless
Something without bone is boneless
Something without defence is defenceless
Something without friction is frictionless
Something without sleeve is sleeveless
Something without effort is effortless
Something without guilt is guiltless
Something without speech is
2024-07-26 21:00:20 root INFO     [order_1_approx] starting weight calculation for Something without guilt is guiltless
Something without sleeve is sleeveless
Something without effort is effortless
Something without speech is speechless
Something without window is windowless
Something without friction is frictionless
Something without bone is boneless
Something without defence is
2024-07-26 21:00:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 21:03:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2223, -0.0936,  0.1665,  ..., -0.0146,  0.0441, -0.0988],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5479, -3.9336,  0.6504,  ..., -1.5127, -3.1992, -2.5508],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0199,  0.0100,  0.0153,  ...,  0.0281, -0.0036, -0.0078],
        [-0.0137, -0.0137,  0.0074,  ..., -0.0356, -0.0055,  0.0236],
        [ 0.0013, -0.0093,  0.0136,  ..., -0.0018, -0.0386, -0.0216],
        ...,
        [ 0.0123,  0.0027,  0.0115,  ..., -0.0240,  0.0313,  0.0089],
        [-0.0035, -0.0113, -0.0372,  ..., -0.0030,  0.0265, -0.0143],
        [ 0.0117, -0.0099,  0.0015,  ..., -0.0172, -0.0114, -0.0016]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6602, -4.1211,  1.1289,  ..., -1.8320, -3.2383, -2.8066]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 21:03:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without guilt is guiltless
Something without sleeve is sleeveless
Something without effort is effortless
Something without speech is speechless
Something without window is windowless
Something without friction is frictionless
Something without bone is boneless
Something without defence is
2024-07-26 21:03:03 root INFO     total operator prediction time: 1312.1114130020142 seconds
2024-07-26 21:03:03 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+ment_irreg
2024-07-26 21:03:03 root INFO     building operator verb+ment_irreg
2024-07-26 21:03:03 root INFO     [order_1_approx] starting weight calculation for To enroll results in a enrollment
To manage results in a management
To develop results in a development
To resent results in a resentment
To commit results in a commitment
To reinforce results in a reinforcement
To appoint results in a appointment
To detach results in a
2024-07-26 21:03:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 21:05:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1146,  0.0958, -0.1107,  ..., -0.0737, -0.0491,  0.0444],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6172, -4.2109, -0.8794,  ...,  2.5977, -2.1523, -2.6309],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0383, -0.0062,  0.0039,  ..., -0.0065, -0.0115,  0.0009],
        [-0.0256,  0.0215,  0.0041,  ...,  0.0156,  0.0321,  0.0318],
        [ 0.0080, -0.0256,  0.0022,  ...,  0.0120, -0.0108, -0.0295],
        ...,
        [ 0.0229,  0.0205,  0.0170,  ...,  0.0421,  0.0146,  0.0146],
        [ 0.0043, -0.0232, -0.0220,  ..., -0.0101, -0.0127, -0.0084],
        [ 0.0149,  0.0166,  0.0146,  ...,  0.0053, -0.0397,  0.0352]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8672, -4.2695, -1.1406,  ...,  2.6602, -2.0449, -2.8789]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 21:05:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To enroll results in a enrollment
To manage results in a management
To develop results in a development
To resent results in a resentment
To commit results in a commitment
To reinforce results in a reinforcement
To appoint results in a appointment
To detach results in a
2024-07-26 21:05:48 root INFO     [order_1_approx] starting weight calculation for To develop results in a development
To reinforce results in a reinforcement
To detach results in a detachment
To manage results in a management
To commit results in a commitment
To appoint results in a appointment
To enroll results in a enrollment
To resent results in a
2024-07-26 21:05:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 21:08:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0289,  0.1533, -0.1924,  ..., -0.1475, -0.2991, -0.1986],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3633, -3.2227, -0.5859,  ..., -0.9727, -0.6567, -1.3135],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0642, -0.0244, -0.0176,  ..., -0.0030, -0.0234, -0.0220],
        [-0.0887,  0.0517,  0.0103,  ..., -0.0092,  0.0541,  0.0482],
        [-0.0168, -0.0137,  0.0145,  ...,  0.0012, -0.0344, -0.0359],
        ...,
        [-0.0338,  0.0223,  0.0123,  ..., -0.0028,  0.0691,  0.0505],
        [ 0.0183, -0.0223, -0.0077,  ...,  0.0050,  0.0343, -0.0509],
        [-0.0700,  0.0272,  0.0045,  ..., -0.0047,  0.0220,  0.0743]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3613, -2.6172, -0.6499,  ..., -0.5449, -0.8599, -1.4053]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 21:08:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To develop results in a development
To reinforce results in a reinforcement
To detach results in a detachment
To manage results in a management
To commit results in a commitment
To appoint results in a appointment
To enroll results in a enrollment
To resent results in a
2024-07-26 21:08:34 root INFO     [order_1_approx] starting weight calculation for To commit results in a commitment
To reinforce results in a reinforcement
To manage results in a management
To detach results in a detachment
To resent results in a resentment
To appoint results in a appointment
To develop results in a development
To enroll results in a
2024-07-26 21:08:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 21:11:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1901,  0.1682,  0.0426,  ...,  0.1019, -0.0718, -0.1101],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2998, -2.7812, -1.5410,  ...,  1.6602, -1.7441, -4.7031],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0334,  0.0016,  0.0326,  ..., -0.0164,  0.0168, -0.0073],
        [-0.0101,  0.0313,  0.0097,  ..., -0.0037, -0.0011, -0.0066],
        [-0.0289, -0.0248,  0.0317,  ..., -0.0121,  0.0108, -0.0277],
        ...,
        [ 0.0279,  0.0195, -0.0013,  ...,  0.0327, -0.0088,  0.0096],
        [ 0.0072, -0.0046,  0.0128,  ...,  0.0105,  0.0042,  0.0136],
        [-0.0270,  0.0059,  0.0027,  ..., -0.0027, -0.0201,  0.0362]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6479, -2.5840, -1.7549,  ...,  1.3613, -2.0918, -4.9375]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 21:11:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To commit results in a commitment
To reinforce results in a reinforcement
To manage results in a management
To detach results in a detachment
To resent results in a resentment
To appoint results in a appointment
To develop results in a development
To enroll results in a
2024-07-26 21:11:19 root INFO     [order_1_approx] starting weight calculation for To develop results in a development
To manage results in a management
To resent results in a resentment
To detach results in a detachment
To enroll results in a enrollment
To reinforce results in a reinforcement
To commit results in a commitment
To appoint results in a
2024-07-26 21:11:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 21:14:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2079,  0.4114, -0.0283,  ...,  0.0616, -0.2256, -0.2175],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1348, -3.9043,  0.3184,  ...,  3.7930, -2.5820, -1.9297],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0401, -0.0264, -0.0017,  ..., -0.0095,  0.0083, -0.0073],
        [-0.0340,  0.0516, -0.0021,  ...,  0.0161,  0.0150,  0.0095],
        [-0.0157, -0.0146, -0.0213,  ..., -0.0071, -0.0274, -0.0195],
        ...,
        [ 0.0144,  0.0276,  0.0342,  ..., -0.0026, -0.0056,  0.0240],
        [ 0.0378, -0.0135,  0.0035,  ..., -0.0058, -0.0080, -0.0031],
        [ 0.0145,  0.0090, -0.0195,  ...,  0.0365, -0.0222,  0.0417]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3193, -3.4316,  0.1237,  ...,  3.4590, -2.7266, -2.0938]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 21:14:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To develop results in a development
To manage results in a management
To resent results in a resentment
To detach results in a detachment
To enroll results in a enrollment
To reinforce results in a reinforcement
To commit results in a commitment
To appoint results in a
2024-07-26 21:14:05 root INFO     [order_1_approx] starting weight calculation for To enroll results in a enrollment
To develop results in a development
To commit results in a commitment
To appoint results in a appointment
To resent results in a resentment
To detach results in a detachment
To manage results in a management
To reinforce results in a
2024-07-26 21:14:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 21:16:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0469, -0.0015,  0.2178,  ...,  0.0496, -0.1404,  0.2544],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4629, -3.5723,  2.1719,  ...,  3.8594, -2.8848, -4.1055],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0408, -0.0152, -0.0037,  ..., -0.0072, -0.0195,  0.0132],
        [-0.0602,  0.0609, -0.0065,  ...,  0.0043,  0.0300, -0.0009],
        [ 0.0199, -0.0276,  0.0069,  ...,  0.0160, -0.0061, -0.0007],
        ...,
        [ 0.0244, -0.0016,  0.0167,  ...,  0.0335, -0.0029,  0.0128],
        [ 0.0190, -0.0160,  0.0077,  ...,  0.0007,  0.0329,  0.0002],
        [ 0.0031, -0.0088, -0.0093,  ...,  0.0391, -0.0318,  0.0345]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4258, -3.5215,  2.2812,  ...,  3.7305, -3.2188, -3.9824]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 21:16:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To enroll results in a enrollment
To develop results in a development
To commit results in a commitment
To appoint results in a appointment
To resent results in a resentment
To detach results in a detachment
To manage results in a management
To reinforce results in a
2024-07-26 21:16:50 root INFO     [order_1_approx] starting weight calculation for To reinforce results in a reinforcement
To detach results in a detachment
To resent results in a resentment
To enroll results in a enrollment
To manage results in a management
To commit results in a commitment
To appoint results in a appointment
To develop results in a
2024-07-26 21:16:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 21:19:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0152,  0.1725,  0.1974,  ...,  0.0781, -0.0185,  0.0848],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5840, -4.2891,  0.7036,  ...,  2.5957, -0.0098, -2.5352],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0267,  0.0030, -0.0128,  ...,  0.0103, -0.0110, -0.0077],
        [-0.0134,  0.0332,  0.0129,  ...,  0.0258,  0.0270,  0.0042],
        [ 0.0006, -0.0137,  0.0039,  ...,  0.0219, -0.0062,  0.0195],
        ...,
        [-0.0244, -0.0085,  0.0160,  ...,  0.0185, -0.0037,  0.0161],
        [-0.0048, -0.0133, -0.0011,  ..., -0.0092,  0.0250, -0.0031],
        [ 0.0123, -0.0191,  0.0032,  ...,  0.0009, -0.0446,  0.0337]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6758, -3.8457,  0.4343,  ...,  2.2461, -0.2874, -2.1562]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 21:19:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To reinforce results in a reinforcement
To detach results in a detachment
To resent results in a resentment
To enroll results in a enrollment
To manage results in a management
To commit results in a commitment
To appoint results in a appointment
To develop results in a
2024-07-26 21:19:36 root INFO     [order_1_approx] starting weight calculation for To appoint results in a appointment
To develop results in a development
To reinforce results in a reinforcement
To enroll results in a enrollment
To manage results in a management
To detach results in a detachment
To resent results in a resentment
To commit results in a
2024-07-26 21:19:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 21:22:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1752,  0.3557, -0.0532,  ...,  0.2303, -0.3262, -0.2009],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1719, -4.6211, -0.9619,  ..., -0.3921, -1.8740, -1.8359],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0136,  0.0202,  0.0131,  ..., -0.0155, -0.0132, -0.0032],
        [-0.0154,  0.0492,  0.0164,  ...,  0.0085,  0.0219,  0.0133],
        [ 0.0091, -0.0169,  0.0041,  ..., -0.0066, -0.0086,  0.0040],
        ...,
        [ 0.0143,  0.0099,  0.0193,  ...,  0.0229,  0.0402,  0.0125],
        [ 0.0091, -0.0018,  0.0106,  ..., -0.0193, -0.0047, -0.0137],
        [ 0.0136, -0.0108,  0.0014,  ..., -0.0068, -0.0530,  0.0120]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.5469, -4.4570, -1.3477,  ..., -0.6104, -1.8525, -1.5938]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 21:22:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To appoint results in a appointment
To develop results in a development
To reinforce results in a reinforcement
To enroll results in a enrollment
To manage results in a management
To detach results in a detachment
To resent results in a resentment
To commit results in a
2024-07-26 21:22:23 root INFO     [order_1_approx] starting weight calculation for To detach results in a detachment
To reinforce results in a reinforcement
To enroll results in a enrollment
To resent results in a resentment
To commit results in a commitment
To appoint results in a appointment
To develop results in a development
To manage results in a
2024-07-26 21:22:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 21:25:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1594,  0.4019,  0.1093,  ...,  0.1001, -0.1199, -0.1123],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5039, -4.0039,  1.7051,  ...,  1.6514, -2.1074, -3.1504],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0197,  0.0014,  0.0057,  ..., -0.0100,  0.0002,  0.0197],
        [-0.0101,  0.0275,  0.0065,  ...,  0.0014,  0.0053, -0.0156],
        [-0.0210, -0.0140,  0.0195,  ...,  0.0313, -0.0156,  0.0032],
        ...,
        [ 0.0031,  0.0032,  0.0151,  ...,  0.0301,  0.0411,  0.0031],
        [ 0.0044, -0.0027,  0.0044,  ..., -0.0217,  0.0104, -0.0217],
        [ 0.0143,  0.0021,  0.0147,  ...,  0.0181,  0.0017,  0.0129]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9238, -4.0625,  1.7998,  ...,  1.2881, -2.6270, -3.0508]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 21:25:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To detach results in a detachment
To reinforce results in a reinforcement
To enroll results in a enrollment
To resent results in a resentment
To commit results in a commitment
To appoint results in a appointment
To develop results in a development
To manage results in a
2024-07-26 21:25:03 root INFO     total operator prediction time: 1320.2185895442963 seconds
2024-07-26 21:25:03 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on UK_city - county
2024-07-26 21:25:03 root INFO     building operator UK_city - county
2024-07-26 21:25:03 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of salisbury is in the county of wiltshire
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of portsmouth is in the county of hampshire
In the United Kingdom, the city of newport is in the county of gwent
In the United Kingdom, the city of crawley is in the county of sussex
In the United Kingdom, the city of plymouth is in the county of devon
In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of sheffield is in the county of
2024-07-26 21:25:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 21:28:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1437, -0.1169, -0.2566,  ...,  0.1389,  0.0876,  0.1145],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6016, -4.1172,  1.4014,  ..., -2.3906, -0.0352,  0.8525],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0125,  0.0058,  0.0213,  ...,  0.0009, -0.0036,  0.0018],
        [-0.0104,  0.0109, -0.0062,  ..., -0.0081, -0.0096, -0.0086],
        [-0.0245,  0.0200,  0.0027,  ...,  0.0115,  0.0056, -0.0354],
        ...,
        [-0.0104,  0.0155, -0.0067,  ...,  0.0115,  0.0052, -0.0212],
        [ 0.0222, -0.0042,  0.0090,  ...,  0.0065, -0.0204,  0.0123],
        [-0.0153, -0.0015, -0.0156,  ...,  0.0037, -0.0055, -0.0229]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3916, -4.1953,  1.2773,  ..., -2.4297,  0.2407,  0.9023]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 21:28:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of salisbury is in the county of wiltshire
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of portsmouth is in the county of hampshire
In the United Kingdom, the city of newport is in the county of gwent
In the United Kingdom, the city of crawley is in the county of sussex
In the United Kingdom, the city of plymouth is in the county of devon
In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of sheffield is in the county of
2024-07-26 21:28:39 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of salisbury is in the county of wiltshire
In the United Kingdom, the city of portsmouth is in the county of hampshire
In the United Kingdom, the city of sheffield is in the county of yorkshire
In the United Kingdom, the city of crawley is in the county of sussex
In the United Kingdom, the city of newport is in the county of gwent
In the United Kingdom, the city of plymouth is in the county of devon
In the United Kingdom, the city of carlisle is in the county of
2024-07-26 21:28:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 21:31:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2169,  0.0490, -0.3362,  ..., -0.0970, -0.4377,  0.3506],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3877, -2.7910,  1.7559,  ..., -5.0273,  0.8838,  0.7256],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0296,  0.0063,  0.0217,  ..., -0.0153, -0.0091,  0.0079],
        [-0.0174,  0.0190,  0.0139,  ...,  0.0413,  0.0094, -0.0605],
        [-0.0287, -0.0043,  0.0062,  ...,  0.0140,  0.0046, -0.0122],
        ...,
        [ 0.0088, -0.0016, -0.0049,  ...,  0.0369,  0.0101, -0.0258],
        [ 0.0277, -0.0118, -0.0068,  ..., -0.0057, -0.0317,  0.0448],
        [ 0.0146, -0.0127, -0.0009,  ..., -0.0031,  0.0152, -0.0261]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5039, -3.4688,  1.6807,  ..., -4.9492,  1.1016,  0.7104]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 21:31:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of salisbury is in the county of wiltshire
In the United Kingdom, the city of portsmouth is in the county of hampshire
In the United Kingdom, the city of sheffield is in the county of yorkshire
In the United Kingdom, the city of crawley is in the county of sussex
In the United Kingdom, the city of newport is in the county of gwent
In the United Kingdom, the city of plymouth is in the county of devon
In the United Kingdom, the city of carlisle is in the county of
2024-07-26 21:31:55 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of newport is in the county of gwent
In the United Kingdom, the city of salisbury is in the county of wiltshire
In the United Kingdom, the city of plymouth is in the county of devon
In the United Kingdom, the city of sheffield is in the county of yorkshire
In the United Kingdom, the city of portsmouth is in the county of hampshire
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of crawley is in the county of
2024-07-26 21:31:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 21:35:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2454, -0.0894, -0.2466,  ...,  0.2642, -0.0414,  0.0109],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9443, -3.9570, -0.5571,  ..., -3.1074,  1.0889, -0.5757],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0424,  0.0166,  0.0076,  ..., -0.0175, -0.0183, -0.0339],
        [-0.0073,  0.0454,  0.0054,  ...,  0.0100, -0.0055, -0.0388],
        [-0.0072, -0.0082, -0.0046,  ...,  0.0113,  0.0137,  0.0229],
        ...,
        [-0.0123,  0.0297, -0.0244,  ...,  0.0248, -0.0120, -0.0348],
        [ 0.0204, -0.0004,  0.0288,  ...,  0.0432, -0.0132,  0.0056],
        [-0.0149,  0.0236, -0.0416,  ..., -0.0191, -0.0070, -0.0248]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7871, -4.2266, -0.8291,  ..., -3.3613,  0.9546, -0.8994]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 21:35:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of newport is in the county of gwent
In the United Kingdom, the city of salisbury is in the county of wiltshire
In the United Kingdom, the city of plymouth is in the county of devon
In the United Kingdom, the city of sheffield is in the county of yorkshire
In the United Kingdom, the city of portsmouth is in the county of hampshire
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of crawley is in the county of
2024-07-26 21:35:16 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of portsmouth is in the county of hampshire
In the United Kingdom, the city of newport is in the county of gwent
In the United Kingdom, the city of crawley is in the county of sussex
In the United Kingdom, the city of sheffield is in the county of yorkshire
In the United Kingdom, the city of plymouth is in the county of devon
In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of salisbury is in the county of
2024-07-26 21:35:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 21:38:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1115, -0.1027, -0.1860,  ..., -0.0110, -0.4553,  0.0202],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2695, -3.6738,  0.2900,  ..., -0.8716, -1.1436, -1.0078],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0126, -0.0022,  0.0109,  ..., -0.0141, -0.0231, -0.0063],
        [ 0.0022,  0.0147,  0.0162,  ...,  0.0363, -0.0110, -0.0201],
        [-0.0388,  0.0011,  0.0183,  ...,  0.0234,  0.0210, -0.0439],
        ...,
        [ 0.0102,  0.0041, -0.0206,  ...,  0.0296,  0.0189, -0.0185],
        [ 0.0170, -0.0175, -0.0003,  ..., -0.0004, -0.0381,  0.0331],
        [-0.0112,  0.0013, -0.0119,  ...,  0.0035,  0.0292, -0.0159]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0508, -3.8320, -0.0056,  ..., -0.7900, -0.6680, -1.2510]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 21:38:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of portsmouth is in the county of hampshire
In the United Kingdom, the city of newport is in the county of gwent
In the United Kingdom, the city of crawley is in the county of sussex
In the United Kingdom, the city of sheffield is in the county of yorkshire
In the United Kingdom, the city of plymouth is in the county of devon
In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of salisbury is in the county of
2024-07-26 21:38:29 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of crawley is in the county of sussex
In the United Kingdom, the city of portsmouth is in the county of hampshire
In the United Kingdom, the city of sheffield is in the county of yorkshire
In the United Kingdom, the city of salisbury is in the county of wiltshire
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of newport is in the county of gwent
In the United Kingdom, the city of plymouth is in the county of
2024-07-26 21:38:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 21:41:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0285,  0.1437, -0.0220,  ...,  0.1268, -0.1274,  0.0952],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6660, -4.4570,  2.1738,  ..., -4.3672,  0.5254, -1.1973],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0110,  0.0018,  0.0063,  ..., -0.0042,  0.0024, -0.0057],
        [-0.0065,  0.0069, -0.0025,  ...,  0.0070,  0.0080, -0.0219],
        [-0.0301, -0.0014, -0.0152,  ...,  0.0303,  0.0250, -0.0374],
        ...,
        [-0.0149,  0.0099, -0.0072,  ...,  0.0102,  0.0142, -0.0278],
        [ 0.0124,  0.0032,  0.0117,  ..., -0.0043, -0.0150,  0.0261],
        [-0.0147, -0.0041, -0.0152,  ...,  0.0035,  0.0074, -0.0332]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4258, -4.5820,  2.0039,  ..., -4.3633,  0.7603, -1.3340]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 21:41:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of crawley is in the county of sussex
In the United Kingdom, the city of portsmouth is in the county of hampshire
In the United Kingdom, the city of sheffield is in the county of yorkshire
In the United Kingdom, the city of salisbury is in the county of wiltshire
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of newport is in the county of gwent
In the United Kingdom, the city of plymouth is in the county of
2024-07-26 21:41:51 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of salisbury is in the county of wiltshire
In the United Kingdom, the city of sheffield is in the county of yorkshire
In the United Kingdom, the city of crawley is in the county of sussex
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of plymouth is in the county of devon
In the United Kingdom, the city of portsmouth is in the county of hampshire
In the United Kingdom, the city of newport is in the county of
2024-07-26 21:41:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 21:45:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3037,  0.0038, -0.1083,  ...,  0.0710, -0.0558,  0.0728],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8750, -3.0039,  1.9971,  ..., -1.8691,  0.5405,  1.6787],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0124,  0.0194,  0.0247,  ..., -0.0008, -0.0180, -0.0311],
        [ 0.0279, -0.0108,  0.0141,  ...,  0.0562,  0.0084,  0.0218],
        [ 0.0077, -0.0126,  0.0187,  ...,  0.0200,  0.0407, -0.0020],
        ...,
        [ 0.0114, -0.0052, -0.0033,  ...,  0.0505,  0.0161, -0.0276],
        [ 0.0284,  0.0100,  0.0135,  ...,  0.0167, -0.0007,  0.0031],
        [ 0.0310, -0.0149,  0.0086,  ..., -0.0466,  0.0038, -0.0094]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.2109, -2.7969,  1.6895,  ..., -1.9229,  0.3594,  1.5361]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 21:45:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of salisbury is in the county of wiltshire
In the United Kingdom, the city of sheffield is in the county of yorkshire
In the United Kingdom, the city of crawley is in the county of sussex
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of plymouth is in the county of devon
In the United Kingdom, the city of portsmouth is in the county of hampshire
In the United Kingdom, the city of newport is in the county of
2024-07-26 21:45:08 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of crawley is in the county of sussex
In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of sheffield is in the county of yorkshire
In the United Kingdom, the city of salisbury is in the county of wiltshire
In the United Kingdom, the city of newport is in the county of gwent
In the United Kingdom, the city of portsmouth is in the county of hampshire
In the United Kingdom, the city of plymouth is in the county of devon
In the United Kingdom, the city of aberdeen is in the county of
2024-07-26 21:45:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 21:48:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0316,  0.0533, -0.1658,  ..., -0.0703, -0.2327,  0.2751],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0162, -3.6211,  1.0078,  ..., -4.1328, -1.3213, -1.3467],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.4786e-02,  4.6387e-03,  1.2115e-02,  ..., -7.0572e-05,
         -5.6076e-03,  5.7220e-03],
        [-1.2589e-02,  8.3847e-03,  1.3222e-02,  ...,  8.8577e-03,
          4.1122e-03, -2.9007e-02],
        [-1.4008e-02, -1.3763e-02,  2.4200e-02,  ...,  2.2156e-02,
          5.0964e-03, -2.8305e-02],
        ...,
        [ 4.9782e-04,  2.7733e-03,  5.8289e-03,  ...,  8.4076e-03,
          1.1902e-03, -8.5297e-03],
        [ 2.4963e-02, -3.7994e-03,  4.7455e-03,  ..., -5.5695e-04,
         -2.1164e-02,  1.9928e-02],
        [ 2.3758e-02, -1.2924e-02,  3.5439e-03,  ..., -1.2863e-02,
         -9.1934e-03,  1.8463e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1066, -3.8066,  0.8579,  ..., -4.0977, -1.1572, -1.2637]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 21:48:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of crawley is in the county of sussex
In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of sheffield is in the county of yorkshire
In the United Kingdom, the city of salisbury is in the county of wiltshire
In the United Kingdom, the city of newport is in the county of gwent
In the United Kingdom, the city of portsmouth is in the county of hampshire
In the United Kingdom, the city of plymouth is in the county of devon
In the United Kingdom, the city of aberdeen is in the county of
2024-07-26 21:48:24 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of plymouth is in the county of devon
In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of sheffield is in the county of yorkshire
In the United Kingdom, the city of crawley is in the county of sussex
In the United Kingdom, the city of newport is in the county of gwent
In the United Kingdom, the city of salisbury is in the county of wiltshire
In the United Kingdom, the city of portsmouth is in the county of
2024-07-26 21:48:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 21:51:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1754, -0.0044, -0.0634,  ...,  0.0228, -0.0938,  0.1949],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5645, -4.5352,  1.3213,  ..., -3.5156, -0.4458, -1.5605],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0146,  0.0089, -0.0051,  ...,  0.0110, -0.0063, -0.0173],
        [-0.0061,  0.0050,  0.0010,  ...,  0.0010,  0.0025, -0.0067],
        [ 0.0059, -0.0195, -0.0012,  ...,  0.0075,  0.0208, -0.0163],
        ...,
        [-0.0137,  0.0101,  0.0083,  ..., -0.0079, -0.0005,  0.0008],
        [ 0.0072, -0.0077,  0.0052,  ...,  0.0137, -0.0174,  0.0080],
        [ 0.0006, -0.0020,  0.0031,  ...,  0.0026,  0.0081, -0.0053]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7422, -4.5273,  1.3389,  ..., -3.4238, -0.3091, -1.5840]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 21:51:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of plymouth is in the county of devon
In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of aberdeen is in the county of aberdeenshire
In the United Kingdom, the city of sheffield is in the county of yorkshire
In the United Kingdom, the city of crawley is in the county of sussex
In the United Kingdom, the city of newport is in the county of gwent
In the United Kingdom, the city of salisbury is in the county of wiltshire
In the United Kingdom, the city of portsmouth is in the county of
2024-07-26 21:51:41 root INFO     total operator prediction time: 1598.0151059627533 seconds
2024-07-26 21:51:41 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on name - nationality
2024-07-26 21:51:41 root INFO     building operator name - nationality
2024-07-26 21:51:41 root INFO     [order_1_approx] starting weight calculation for aristotle was greek
euclid was greek
raphael was italian
lincoln was american
locke was english
wagner was german
caesar was roman
marx was
2024-07-26 21:51:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 21:54:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([0.0590, 0.0905, 0.0538,  ..., 0.1520, 0.0359, 0.1920], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6382, -5.4258, -0.6357,  ..., -5.5781,  1.1055, -1.0547],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.3162e-02, -2.2980e-02,  6.5842e-03,  ..., -3.4210e-02,
         -4.1687e-02, -9.8610e-04],
        [ 3.1113e-02,  1.9028e-02,  8.2092e-03,  ..., -2.3529e-02,
         -5.3894e-02, -2.4506e-02],
        [-2.2926e-03, -1.0040e-02,  2.8290e-02,  ..., -4.2496e-03,
         -5.2605e-03,  6.6376e-03],
        ...,
        [ 1.0803e-02, -1.8387e-02,  3.0380e-02,  ...,  2.8229e-02,
         -2.0493e-02,  1.1337e-02],
        [-7.6294e-05, -2.0691e-02,  8.4915e-03,  ...,  1.4236e-02,
         -2.5330e-02, -5.4321e-03],
        [-2.5452e-02,  4.0161e-02, -1.7672e-03,  ...,  1.5671e-02,
          4.0161e-02,  3.4302e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0615, -5.2227, -0.5298,  ..., -5.4336,  0.8535,  0.0293]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 21:54:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for aristotle was greek
euclid was greek
raphael was italian
lincoln was american
locke was english
wagner was german
caesar was roman
marx was
2024-07-26 21:54:26 root INFO     [order_1_approx] starting weight calculation for wagner was german
aristotle was greek
lincoln was american
caesar was roman
locke was english
marx was german
raphael was italian
euclid was
2024-07-26 21:54:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 21:57:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1136, -0.0671, -0.1114,  ..., -0.2236, -0.0237, -0.1425],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5547, -3.2539, -0.2480,  ..., -4.6875, -0.8555, -1.0557],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0792, -0.0201,  0.0072,  ..., -0.0175, -0.0199, -0.0396],
        [-0.0607,  0.0698,  0.0092,  ...,  0.0074,  0.0005,  0.0428],
        [ 0.0120,  0.0054,  0.0510,  ...,  0.0061, -0.0332, -0.0032],
        ...,
        [ 0.0132,  0.0361,  0.0116,  ...,  0.0439, -0.0177,  0.0049],
        [ 0.0164, -0.0046,  0.0006,  ...,  0.0045,  0.0425, -0.0317],
        [-0.0609,  0.0073,  0.0115,  ...,  0.0011, -0.0081,  0.0696]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1738, -3.0000, -0.5498,  ..., -4.3477, -0.9004, -0.8213]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 21:57:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for wagner was german
aristotle was greek
lincoln was american
caesar was roman
locke was english
marx was german
raphael was italian
euclid was
2024-07-26 21:57:04 root INFO     [order_1_approx] starting weight calculation for euclid was greek
caesar was roman
raphael was italian
aristotle was greek
lincoln was american
marx was german
wagner was german
locke was
2024-07-26 21:57:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 21:59:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1155,  0.0651, -0.4656,  ..., -0.2278, -0.0631,  0.0323],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1055, -2.2539,  0.9302,  ..., -5.4922,  0.1553, -4.5469],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0269,  0.0101, -0.0112,  ...,  0.0048, -0.0309, -0.0201],
        [ 0.0246,  0.0349,  0.0226,  ...,  0.0078, -0.0261, -0.0270],
        [-0.0191, -0.0062,  0.0493,  ..., -0.0010, -0.0139, -0.0448],
        ...,
        [ 0.0112, -0.0043,  0.0027,  ...,  0.0510, -0.0045,  0.0084],
        [ 0.0085, -0.0165, -0.0103,  ...,  0.0099, -0.0017, -0.0097],
        [-0.0403, -0.0002, -0.0099,  ..., -0.0149,  0.0291,  0.1031]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1055, -2.3203,  0.5469,  ..., -4.7891, -0.1877, -4.0430]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 21:59:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for euclid was greek
caesar was roman
raphael was italian
aristotle was greek
lincoln was american
marx was german
wagner was german
locke was
2024-07-26 21:59:45 root INFO     [order_1_approx] starting weight calculation for marx was german
raphael was italian
aristotle was greek
wagner was german
euclid was greek
locke was english
caesar was roman
lincoln was
2024-07-26 21:59:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 22:02:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0240,  0.0552, -0.3979,  ..., -0.0749, -0.1655, -0.0224],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5625, -2.0742,  1.1094,  ..., -3.0762,  2.0527, -2.9180],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0349,  0.0304, -0.0186,  ..., -0.0180, -0.0744,  0.0096],
        [-0.0017,  0.0323,  0.0092,  ...,  0.0055, -0.0090, -0.0215],
        [-0.0082,  0.0020,  0.0407,  ...,  0.0082, -0.0380, -0.0035],
        ...,
        [ 0.0023,  0.0115,  0.0148,  ...,  0.0403,  0.0296, -0.0092],
        [-0.0042, -0.0176, -0.0007,  ...,  0.0083, -0.0062, -0.0062],
        [-0.0150,  0.0186,  0.0025,  ...,  0.0090,  0.0420,  0.0404]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3008, -1.6191,  1.3223,  ..., -3.2129,  2.1211, -2.4102]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 22:02:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for marx was german
raphael was italian
aristotle was greek
wagner was german
euclid was greek
locke was english
caesar was roman
lincoln was
2024-07-26 22:02:26 root INFO     [order_1_approx] starting weight calculation for raphael was italian
marx was german
locke was english
lincoln was american
caesar was roman
euclid was greek
wagner was german
aristotle was
2024-07-26 22:02:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 22:05:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2457, -0.0149, -0.5508,  ..., -0.3853, -0.2101,  0.1335],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2832, -5.4609, -1.5654,  ..., -4.1406, -1.2031, -0.4316],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0426, -0.0269,  0.0242,  ..., -0.0260, -0.0139,  0.0169],
        [ 0.0066,  0.0196,  0.0106,  ..., -0.0094, -0.0100,  0.0138],
        [-0.0183,  0.0033,  0.0212,  ..., -0.0037,  0.0131, -0.0122],
        ...,
        [ 0.0674, -0.0281,  0.0178,  ...,  0.0240, -0.0483,  0.0378],
        [ 0.0198,  0.0064,  0.0053,  ..., -0.0151, -0.0031,  0.0134],
        [-0.0431,  0.0149, -0.0021,  ..., -0.0087, -0.0024,  0.0006]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4707, -5.0469, -1.7607,  ..., -3.4980, -1.0273, -0.3496]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 22:05:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for raphael was italian
marx was german
locke was english
lincoln was american
caesar was roman
euclid was greek
wagner was german
aristotle was
2024-07-26 22:05:11 root INFO     [order_1_approx] starting weight calculation for marx was german
locke was english
aristotle was greek
caesar was roman
euclid was greek
raphael was italian
lincoln was american
wagner was
2024-07-26 22:05:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 22:07:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2925,  0.4380,  0.0180,  ...,  0.0868, -0.0400,  0.0524],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1211, -6.2188,  0.4023,  ..., -3.0098, -1.5410, -0.8438],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0925, -0.0646, -0.0318,  ..., -0.0643, -0.0592,  0.0027],
        [-0.0313,  0.1042,  0.0199,  ...,  0.0562,  0.0194, -0.0724],
        [-0.0454,  0.0332,  0.0512,  ...,  0.0566,  0.0072, -0.0100],
        ...,
        [ 0.0072,  0.0420,  0.0536,  ...,  0.0594, -0.0140,  0.0109],
        [ 0.0291, -0.0054,  0.0259,  ...,  0.0074,  0.0192,  0.0109],
        [-0.0297,  0.0250,  0.0122,  ...,  0.0367,  0.0168,  0.0483]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3242, -5.9844,  0.4077,  ..., -2.7734, -1.7031, -0.1836]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 22:07:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for marx was german
locke was english
aristotle was greek
caesar was roman
euclid was greek
raphael was italian
lincoln was american
wagner was
2024-07-26 22:07:56 root INFO     [order_1_approx] starting weight calculation for marx was german
locke was english
wagner was german
aristotle was greek
euclid was greek
raphael was italian
lincoln was american
caesar was
2024-07-26 22:07:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 22:10:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1573,  0.1465, -0.2374,  ...,  0.0797, -0.5151,  0.1901],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9883, -3.5664, -0.1378,  ..., -2.0586,  1.7012, -1.2930],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0787,  0.0038, -0.0123,  ..., -0.0196, -0.0129,  0.0057],
        [-0.0153,  0.0644,  0.0083,  ...,  0.0206, -0.0612,  0.0058],
        [-0.0395, -0.0400,  0.0427,  ...,  0.0017, -0.0022, -0.0149],
        ...,
        [ 0.0287,  0.0095,  0.0192,  ...,  0.1052, -0.0213, -0.0667],
        [-0.0034, -0.0014, -0.0026,  ..., -0.0146,  0.0596, -0.0085],
        [-0.0122,  0.0150,  0.0063,  ..., -0.0277, -0.0316,  0.0402]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8975, -3.2207, -0.2549,  ..., -2.2598,  1.6367, -0.9268]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 22:10:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for marx was german
locke was english
wagner was german
aristotle was greek
euclid was greek
raphael was italian
lincoln was american
caesar was
2024-07-26 22:10:42 root INFO     [order_1_approx] starting weight calculation for lincoln was american
marx was german
wagner was german
euclid was greek
aristotle was greek
caesar was roman
locke was english
raphael was
2024-07-26 22:10:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 22:13:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4084, -0.0482, -0.0970,  ..., -0.1948, -0.0869, -0.0233],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.6406, -3.8594,  2.0938,  ..., -4.3125, -1.1064, -1.2402],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0782,  0.0122,  0.0191,  ..., -0.0042, -0.0034, -0.0399],
        [ 0.0010,  0.0381,  0.0267,  ..., -0.0188, -0.0211,  0.0208],
        [-0.0008, -0.0079,  0.0502,  ...,  0.0015,  0.0140, -0.0317],
        ...,
        [ 0.0217,  0.0096, -0.0111,  ...,  0.0327, -0.0279,  0.0209],
        [-0.0011,  0.0077,  0.0230,  ..., -0.0092,  0.0065,  0.0252],
        [-0.0156, -0.0053, -0.0311,  ..., -0.0197, -0.0587,  0.0715]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.7930, -3.1602,  1.7402,  ..., -3.6699, -0.7197, -0.8975]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 22:13:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for lincoln was american
marx was german
wagner was german
euclid was greek
aristotle was greek
caesar was roman
locke was english
raphael was
2024-07-26 22:13:27 root INFO     total operator prediction time: 1305.9738230705261 seconds
2024-07-26 22:13:27 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on country - language
2024-07-26 22:13:27 root INFO     building operator country - language
2024-07-26 22:13:27 root INFO     [order_1_approx] starting weight calculation for The country of cyprus primarily speaks the language of greek
The country of venezuela primarily speaks the language of spanish
The country of kosovo primarily speaks the language of albanian
The country of israel primarily speaks the language of hebrew
The country of jordan primarily speaks the language of arabic
The country of colombia primarily speaks the language of spanish
The country of bahamas primarily speaks the language of english
The country of guyana primarily speaks the language of
2024-07-26 22:13:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 22:16:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3003, -0.0964,  0.0944,  ...,  0.0545, -0.4470, -0.1995],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9961, -0.2197,  1.3906,  ...,  1.1035,  0.7148, -2.9629],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0060,  0.0109,  0.0033,  ...,  0.0005,  0.0120,  0.0016],
        [-0.0029,  0.0293, -0.0084,  ...,  0.0143, -0.0175, -0.0146],
        [-0.0120,  0.0221,  0.0422,  ..., -0.0328, -0.0047, -0.0253],
        ...,
        [ 0.0018, -0.0065, -0.0254,  ...,  0.0479, -0.0095, -0.0344],
        [-0.0147,  0.0296, -0.0053,  ..., -0.0013,  0.0195,  0.0177],
        [ 0.0183, -0.0157, -0.0111,  ..., -0.0061,  0.0099,  0.0218]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8408, -0.2374,  1.5088,  ...,  0.8701,  0.5342, -2.6074]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 22:16:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of cyprus primarily speaks the language of greek
The country of venezuela primarily speaks the language of spanish
The country of kosovo primarily speaks the language of albanian
The country of israel primarily speaks the language of hebrew
The country of jordan primarily speaks the language of arabic
The country of colombia primarily speaks the language of spanish
The country of bahamas primarily speaks the language of english
The country of guyana primarily speaks the language of
2024-07-26 22:16:11 root INFO     [order_1_approx] starting weight calculation for The country of bahamas primarily speaks the language of english
The country of guyana primarily speaks the language of english
The country of kosovo primarily speaks the language of albanian
The country of israel primarily speaks the language of hebrew
The country of jordan primarily speaks the language of arabic
The country of colombia primarily speaks the language of spanish
The country of cyprus primarily speaks the language of greek
The country of venezuela primarily speaks the language of
2024-07-26 22:16:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 22:18:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0643, -0.3367, -0.3977,  ...,  0.2808, -0.5176, -0.1667],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2451, -3.9102,  1.1416,  ...,  0.5703,  0.0762, -1.5547],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0165, -0.0174,  0.0173,  ..., -0.0367,  0.0063,  0.0232],
        [ 0.0111,  0.0098,  0.0079,  ..., -0.0015, -0.0038,  0.0035],
        [-0.0495,  0.0336, -0.0111,  ...,  0.0076,  0.0117, -0.0505],
        ...,
        [-0.0320,  0.0258, -0.0291,  ...,  0.0478,  0.0084, -0.0396],
        [ 0.0144, -0.0202,  0.0235,  ..., -0.0094,  0.0149,  0.0245],
        [ 0.0116, -0.0117,  0.0059,  ..., -0.0066, -0.0096,  0.0254]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5781, -3.9160,  0.7002,  ...,  0.2744,  0.1639, -1.0859]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 22:18:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of bahamas primarily speaks the language of english
The country of guyana primarily speaks the language of english
The country of kosovo primarily speaks the language of albanian
The country of israel primarily speaks the language of hebrew
The country of jordan primarily speaks the language of arabic
The country of colombia primarily speaks the language of spanish
The country of cyprus primarily speaks the language of greek
The country of venezuela primarily speaks the language of
2024-07-26 22:18:57 root INFO     [order_1_approx] starting weight calculation for The country of israel primarily speaks the language of hebrew
The country of colombia primarily speaks the language of spanish
The country of guyana primarily speaks the language of english
The country of cyprus primarily speaks the language of greek
The country of kosovo primarily speaks the language of albanian
The country of venezuela primarily speaks the language of spanish
The country of bahamas primarily speaks the language of english
The country of jordan primarily speaks the language of
2024-07-26 22:18:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 22:21:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0696, -0.0867, -0.2812,  ...,  0.1248, -0.5322, -0.0658],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.4062, -2.2402,  0.3335,  ..., -0.7334,  0.9014, -1.1992],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0443,  0.0140,  0.0128,  ..., -0.0310, -0.0246,  0.0340],
        [-0.0027,  0.0208,  0.0084,  ..., -0.0060, -0.0038,  0.0036],
        [-0.0249, -0.0050,  0.0197,  ..., -0.0032, -0.0043, -0.0139],
        ...,
        [-0.0429,  0.0244, -0.0376,  ...,  0.0317,  0.0272, -0.0350],
        [-0.0005,  0.0044,  0.0215,  ..., -0.0126, -0.0036,  0.0175],
        [ 0.0019, -0.0076,  0.0159,  ...,  0.0009, -0.0084,  0.0183]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.7637, -1.8223,  0.2546,  ..., -1.2188,  0.9370, -1.0312]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 22:21:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of israel primarily speaks the language of hebrew
The country of colombia primarily speaks the language of spanish
The country of guyana primarily speaks the language of english
The country of cyprus primarily speaks the language of greek
The country of kosovo primarily speaks the language of albanian
The country of venezuela primarily speaks the language of spanish
The country of bahamas primarily speaks the language of english
The country of jordan primarily speaks the language of
2024-07-26 22:21:45 root INFO     [order_1_approx] starting weight calculation for The country of cyprus primarily speaks the language of greek
The country of venezuela primarily speaks the language of spanish
The country of colombia primarily speaks the language of spanish
The country of jordan primarily speaks the language of arabic
The country of bahamas primarily speaks the language of english
The country of guyana primarily speaks the language of english
The country of kosovo primarily speaks the language of albanian
The country of israel primarily speaks the language of
2024-07-26 22:21:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 22:24:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0605,  0.0390, -0.0975,  ..., -0.0877, -0.3752,  0.2810],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.1602, -5.4297,  1.4609,  ..., -3.8281, -0.0957, -2.4180],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0405, -0.0069,  0.0172,  ..., -0.0120,  0.0085,  0.0152],
        [ 0.0084,  0.0102,  0.0069,  ..., -0.0155,  0.0049,  0.0083],
        [-0.0342,  0.0257,  0.0027,  ...,  0.0109, -0.0035, -0.0216],
        ...,
        [-0.0384,  0.0115, -0.0119,  ...,  0.0319,  0.0092, -0.0180],
        [ 0.0309, -0.0143,  0.0219,  ..., -0.0139,  0.0105,  0.0111],
        [ 0.0188, -0.0115,  0.0176,  ...,  0.0027, -0.0058,  0.0475]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.0703, -4.6523,  1.2861,  ..., -4.1328, -0.0176, -2.3672]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 22:24:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of cyprus primarily speaks the language of greek
The country of venezuela primarily speaks the language of spanish
The country of colombia primarily speaks the language of spanish
The country of jordan primarily speaks the language of arabic
The country of bahamas primarily speaks the language of english
The country of guyana primarily speaks the language of english
The country of kosovo primarily speaks the language of albanian
The country of israel primarily speaks the language of
2024-07-26 22:24:26 root INFO     [order_1_approx] starting weight calculation for The country of jordan primarily speaks the language of arabic
The country of guyana primarily speaks the language of english
The country of israel primarily speaks the language of hebrew
The country of colombia primarily speaks the language of spanish
The country of bahamas primarily speaks the language of english
The country of venezuela primarily speaks the language of spanish
The country of cyprus primarily speaks the language of greek
The country of kosovo primarily speaks the language of
2024-07-26 22:24:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 22:27:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3804, -0.1236, -0.2637,  ...,  0.2039, -0.3320,  0.0791],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0801, -4.8906,  1.7637,  ..., -1.5059, -0.0190, -0.8315],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0152,  0.0006, -0.0018,  ...,  0.0095,  0.0145,  0.0063],
        [-0.0019,  0.0260,  0.0049,  ...,  0.0010,  0.0026,  0.0145],
        [-0.0076,  0.0212,  0.0315,  ...,  0.0006, -0.0093, -0.0385],
        ...,
        [-0.0026,  0.0116, -0.0190,  ...,  0.0189,  0.0039, -0.0215],
        [ 0.0035,  0.0122,  0.0167,  ..., -0.0073,  0.0156,  0.0286],
        [ 0.0113,  0.0011,  0.0050,  ...,  0.0085, -0.0049,  0.0113]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8955, -4.4844,  1.1426,  ..., -1.7100,  0.4790, -0.7080]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 22:27:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of jordan primarily speaks the language of arabic
The country of guyana primarily speaks the language of english
The country of israel primarily speaks the language of hebrew
The country of colombia primarily speaks the language of spanish
The country of bahamas primarily speaks the language of english
The country of venezuela primarily speaks the language of spanish
The country of cyprus primarily speaks the language of greek
The country of kosovo primarily speaks the language of
2024-07-26 22:27:05 root INFO     [order_1_approx] starting weight calculation for The country of jordan primarily speaks the language of arabic
The country of colombia primarily speaks the language of spanish
The country of guyana primarily speaks the language of english
The country of kosovo primarily speaks the language of albanian
The country of bahamas primarily speaks the language of english
The country of israel primarily speaks the language of hebrew
The country of venezuela primarily speaks the language of spanish
The country of cyprus primarily speaks the language of
2024-07-26 22:27:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 22:29:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0090, -0.2930, -0.2805,  ..., -0.0260, -0.4189, -0.1744],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7461, -4.5195, -0.8740,  ..., -1.6328, -1.6777, -1.2676],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0219, -0.0149,  0.0093,  ..., -0.0099,  0.0178,  0.0277],
        [ 0.0104,  0.0120,  0.0172,  ..., -0.0095,  0.0035,  0.0302],
        [-0.0198,  0.0115,  0.0032,  ...,  0.0059,  0.0034, -0.0324],
        ...,
        [ 0.0055,  0.0109, -0.0120,  ...,  0.0256,  0.0131, -0.0207],
        [ 0.0109, -0.0108,  0.0295,  ..., -0.0076,  0.0274,  0.0488],
        [ 0.0102, -0.0167, -0.0012,  ..., -0.0003, -0.0032,  0.0215]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2251, -4.1836, -1.2070,  ..., -2.0527, -1.1523, -0.9375]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 22:29:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of jordan primarily speaks the language of arabic
The country of colombia primarily speaks the language of spanish
The country of guyana primarily speaks the language of english
The country of kosovo primarily speaks the language of albanian
The country of bahamas primarily speaks the language of english
The country of israel primarily speaks the language of hebrew
The country of venezuela primarily speaks the language of spanish
The country of cyprus primarily speaks the language of
2024-07-26 22:29:49 root INFO     [order_1_approx] starting weight calculation for The country of jordan primarily speaks the language of arabic
The country of cyprus primarily speaks the language of greek
The country of colombia primarily speaks the language of spanish
The country of guyana primarily speaks the language of english
The country of kosovo primarily speaks the language of albanian
The country of israel primarily speaks the language of hebrew
The country of venezuela primarily speaks the language of spanish
The country of bahamas primarily speaks the language of
2024-07-26 22:29:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 22:32:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2260,  0.0861, -0.0925,  ..., -0.1169, -0.4204, -0.1807],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9824, -0.4644,  1.7773,  ...,  0.9746,  1.6348, -2.3125],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0193,  0.0058,  0.0169,  ..., -0.0090, -0.0086,  0.0013],
        [ 0.0065,  0.0098,  0.0096,  ..., -0.0111,  0.0052, -0.0021],
        [-0.0669,  0.0113, -0.0241,  ...,  0.0132,  0.0219, -0.0047],
        ...,
        [-0.0440,  0.0073, -0.0336,  ...,  0.0179,  0.0206, -0.0133],
        [ 0.0069,  0.0073,  0.0194,  ...,  0.0110,  0.0163,  0.0111],
        [ 0.0502, -0.0080,  0.0560,  ..., -0.0151, -0.0222,  0.0164]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2090, -0.2769,  1.0947,  ...,  0.4067,  1.7520, -1.4922]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 22:32:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of jordan primarily speaks the language of arabic
The country of cyprus primarily speaks the language of greek
The country of colombia primarily speaks the language of spanish
The country of guyana primarily speaks the language of english
The country of kosovo primarily speaks the language of albanian
The country of israel primarily speaks the language of hebrew
The country of venezuela primarily speaks the language of spanish
The country of bahamas primarily speaks the language of
2024-07-26 22:32:35 root INFO     [order_1_approx] starting weight calculation for The country of jordan primarily speaks the language of arabic
The country of cyprus primarily speaks the language of greek
The country of venezuela primarily speaks the language of spanish
The country of israel primarily speaks the language of hebrew
The country of bahamas primarily speaks the language of english
The country of kosovo primarily speaks the language of albanian
The country of guyana primarily speaks the language of english
The country of colombia primarily speaks the language of
2024-07-26 22:32:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 22:35:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0148, -0.0320, -0.3694,  ...,  0.1126, -0.4009, -0.0894],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0361, -2.3008,  1.2051,  ...,  0.4829,  0.3926, -2.1719],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0248, -0.0106,  0.0108,  ..., -0.0062,  0.0057,  0.0103],
        [ 0.0098,  0.0069,  0.0169,  ..., -0.0052, -0.0200,  0.0203],
        [-0.0562,  0.0307, -0.0159,  ..., -0.0063,  0.0070, -0.0462],
        ...,
        [-0.0293,  0.0198, -0.0153,  ...,  0.0188,  0.0073, -0.0326],
        [ 0.0092, -0.0172,  0.0176,  ...,  0.0059,  0.0071,  0.0160],
        [ 0.0173, -0.0208,  0.0198,  ...,  0.0032, -0.0023,  0.0330]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5840, -1.7949, -0.2432,  ..., -0.3901,  0.8223, -1.2861]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 22:35:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of jordan primarily speaks the language of arabic
The country of cyprus primarily speaks the language of greek
The country of venezuela primarily speaks the language of spanish
The country of israel primarily speaks the language of hebrew
The country of bahamas primarily speaks the language of english
The country of kosovo primarily speaks the language of albanian
The country of guyana primarily speaks the language of english
The country of colombia primarily speaks the language of
2024-07-26 22:35:23 root INFO     total operator prediction time: 1315.612110376358 seconds
2024-07-26 22:35:23 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - shelter
2024-07-26 22:35:23 root INFO     building operator animal - shelter
2024-07-26 22:35:23 root INFO     [order_1_approx] starting weight calculation for The place hornet lives in is called nest
The place scorpion lives in is called nest
The place fish lives in is called sea
The place herring lives in is called sea
The place tiger lives in is called den
The place mouse lives in is called nest
The place gorilla lives in is called grove
The place bat lives in is called
2024-07-26 22:35:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 22:38:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4719, -0.1636,  0.2734,  ..., -0.1207, -0.3386, -0.0840],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4331, -4.8828,  0.7207,  ..., -3.6348,  0.5508, -2.4707],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0453, -0.0418,  0.0104,  ..., -0.0123,  0.0149, -0.0093],
        [-0.0196,  0.0744,  0.0091,  ...,  0.0213,  0.0300, -0.0027],
        [-0.0180, -0.0103,  0.0377,  ..., -0.0048,  0.0124, -0.0090],
        ...,
        [-0.0184, -0.0093,  0.0187,  ...,  0.0169,  0.0104,  0.0013],
        [ 0.0012,  0.0342, -0.0018,  ...,  0.0209,  0.0348,  0.0089],
        [ 0.0014, -0.0184, -0.0224,  ..., -0.0017, -0.0151,  0.0583]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5190, -5.0742,  0.3640,  ..., -3.8848,  0.2559, -2.5938]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 22:38:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place hornet lives in is called nest
The place scorpion lives in is called nest
The place fish lives in is called sea
The place herring lives in is called sea
The place tiger lives in is called den
The place mouse lives in is called nest
The place gorilla lives in is called grove
The place bat lives in is called
2024-07-26 22:38:09 root INFO     [order_1_approx] starting weight calculation for The place herring lives in is called sea
The place bat lives in is called cave
The place tiger lives in is called den
The place fish lives in is called sea
The place hornet lives in is called nest
The place gorilla lives in is called grove
The place mouse lives in is called nest
The place scorpion lives in is called
2024-07-26 22:38:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 22:40:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0289,  0.0388, -0.2974,  ..., -0.4019, -0.0213,  0.1128],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1777, -4.9922,  0.9404,  ..., -2.6875,  0.5474, -1.5898],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0298, -0.0058,  0.0090,  ..., -0.0031, -0.0065,  0.0150],
        [-0.0149,  0.0045, -0.0143,  ..., -0.0022, -0.0136,  0.0013],
        [-0.0079,  0.0148,  0.0077,  ..., -0.0005,  0.0018, -0.0123],
        ...,
        [-0.0175, -0.0029,  0.0037,  ..., -0.0022, -0.0020, -0.0038],
        [-0.0021,  0.0100, -0.0086,  ...,  0.0242,  0.0064, -0.0251],
        [-0.0054, -0.0071,  0.0067,  ..., -0.0118, -0.0018,  0.0211]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3066, -4.9141,  0.6567,  ..., -2.7715,  0.2319, -1.5322]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 22:40:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place herring lives in is called sea
The place bat lives in is called cave
The place tiger lives in is called den
The place fish lives in is called sea
The place hornet lives in is called nest
The place gorilla lives in is called grove
The place mouse lives in is called nest
The place scorpion lives in is called
2024-07-26 22:40:54 root INFO     [order_1_approx] starting weight calculation for The place herring lives in is called sea
The place gorilla lives in is called grove
The place fish lives in is called sea
The place scorpion lives in is called nest
The place tiger lives in is called den
The place bat lives in is called cave
The place mouse lives in is called nest
The place hornet lives in is called
2024-07-26 22:40:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 22:43:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1699,  0.1375,  0.0553,  ...,  0.1141,  0.0198, -0.0101],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9570, -7.0391,  1.2715,  ..., -3.5156,  0.5542, -1.6182],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0599, -0.0037,  0.0152,  ..., -0.0122,  0.0081, -0.0021],
        [-0.0100,  0.0513, -0.0091,  ...,  0.0642,  0.0002, -0.0020],
        [-0.0274,  0.0266,  0.0504,  ...,  0.0004,  0.0046,  0.0201],
        ...,
        [-0.0180, -0.0172,  0.0094,  ...,  0.0532,  0.0027,  0.0055],
        [-0.0031,  0.0144, -0.0105,  ...,  0.0050,  0.0145,  0.0103],
        [-0.0298,  0.0003, -0.0046,  ...,  0.0012, -0.0239,  0.0356]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8438, -6.5938,  0.8877,  ..., -3.2188,  0.3027, -1.5361]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 22:43:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place herring lives in is called sea
The place gorilla lives in is called grove
The place fish lives in is called sea
The place scorpion lives in is called nest
The place tiger lives in is called den
The place bat lives in is called cave
The place mouse lives in is called nest
The place hornet lives in is called
2024-07-26 22:43:40 root INFO     [order_1_approx] starting weight calculation for The place hornet lives in is called nest
The place herring lives in is called sea
The place bat lives in is called cave
The place mouse lives in is called nest
The place scorpion lives in is called nest
The place fish lives in is called sea
The place gorilla lives in is called grove
The place tiger lives in is called
2024-07-26 22:43:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 22:46:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0805,  0.2229, -0.1960,  ...,  0.1019, -0.0042,  0.0067],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([  4.5547, -11.6641,   1.9131,  ...,  -2.8906,   0.5195,  -3.7559],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0367, -0.0041, -0.0089,  ...,  0.0190, -0.0051, -0.0289],
        [-0.0127,  0.0029, -0.0095,  ..., -0.0265, -0.0062, -0.0156],
        [-0.0136,  0.0060,  0.0472,  ...,  0.0128, -0.0086, -0.0141],
        ...,
        [-0.0134,  0.0003, -0.0056,  ...,  0.0306,  0.0124,  0.0080],
        [ 0.0082,  0.0051,  0.0024,  ...,  0.0558,  0.0169,  0.0021],
        [-0.0295, -0.0199,  0.0066,  ..., -0.0073, -0.0130,  0.0287]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[  4.4258, -11.0547,   1.6123,  ...,  -2.5293,   0.4712,  -3.5137]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 22:46:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place hornet lives in is called nest
The place herring lives in is called sea
The place bat lives in is called cave
The place mouse lives in is called nest
The place scorpion lives in is called nest
The place fish lives in is called sea
The place gorilla lives in is called grove
The place tiger lives in is called
2024-07-26 22:46:25 root INFO     [order_1_approx] starting weight calculation for The place bat lives in is called cave
The place tiger lives in is called den
The place fish lives in is called sea
The place herring lives in is called sea
The place mouse lives in is called nest
The place hornet lives in is called nest
The place scorpion lives in is called nest
The place gorilla lives in is called
2024-07-26 22:46:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 22:49:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2234, -0.1713, -0.2405,  ..., -0.2065, -0.3301,  0.1387],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.6211, -8.9531,  0.8584,  ..., -1.9678, -0.1396,  0.3916],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0330, -0.0193, -0.0094,  ...,  0.0079,  0.0173,  0.0184],
        [-0.0040,  0.0255,  0.0159,  ..., -0.0008, -0.0122, -0.0023],
        [-0.0030,  0.0148, -0.0166,  ..., -0.0177,  0.0248, -0.0017],
        ...,
        [-0.0082,  0.0121, -0.0039,  ...,  0.0151, -0.0049,  0.0064],
        [ 0.0044, -0.0075,  0.0049,  ..., -0.0016,  0.0143, -0.0057],
        [-0.0082, -0.0089,  0.0127,  ...,  0.0021,  0.0030,  0.0357]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.7891, -8.9219,  0.7500,  ..., -1.7539, -0.4331,  0.5273]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 22:49:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place bat lives in is called cave
The place tiger lives in is called den
The place fish lives in is called sea
The place herring lives in is called sea
The place mouse lives in is called nest
The place hornet lives in is called nest
The place scorpion lives in is called nest
The place gorilla lives in is called
2024-07-26 22:49:12 root INFO     [order_1_approx] starting weight calculation for The place mouse lives in is called nest
The place herring lives in is called sea
The place bat lives in is called cave
The place hornet lives in is called nest
The place gorilla lives in is called grove
The place tiger lives in is called den
The place scorpion lives in is called nest
The place fish lives in is called
2024-07-26 22:49:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 22:51:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0421,  0.1362, -0.0939,  ..., -0.1998, -0.2153, -0.0132],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5645, -5.8672,  0.2705,  ..., -3.1133, -0.1172, -2.6562],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0320, -0.0408,  0.0271,  ...,  0.0174, -0.0129,  0.0109],
        [ 0.0000, -0.0244,  0.0087,  ...,  0.0176, -0.0240,  0.0205],
        [-0.0199,  0.0311,  0.0219,  ...,  0.0045,  0.0132,  0.0082],
        ...,
        [-0.0081,  0.0053,  0.0071,  ...,  0.0159, -0.0046, -0.0047],
        [-0.0228,  0.0409,  0.0048,  ...,  0.0014,  0.0283,  0.0005],
        [ 0.0153, -0.0390,  0.0068,  ..., -0.0204, -0.0185,  0.0554]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7715, -5.2852,  0.0573,  ..., -3.0215, -0.8638, -1.7617]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 22:51:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place mouse lives in is called nest
The place herring lives in is called sea
The place bat lives in is called cave
The place hornet lives in is called nest
The place gorilla lives in is called grove
The place tiger lives in is called den
The place scorpion lives in is called nest
The place fish lives in is called
2024-07-26 22:51:57 root INFO     [order_1_approx] starting weight calculation for The place hornet lives in is called nest
The place scorpion lives in is called nest
The place herring lives in is called sea
The place tiger lives in is called den
The place bat lives in is called cave
The place fish lives in is called sea
The place gorilla lives in is called grove
The place mouse lives in is called
2024-07-26 22:51:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 22:54:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2466, -0.1237,  0.0385,  ...,  0.0222, -0.1870, -0.1978],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0684, -6.0234,  1.1719,  ..., -1.1357, -0.9790,  0.2871],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0441, -0.0218,  0.0487,  ...,  0.0117, -0.0223, -0.0061],
        [-0.0153,  0.0353, -0.0168,  ...,  0.0064,  0.0021, -0.0208],
        [-0.0061,  0.0310,  0.0263,  ..., -0.0539,  0.0119,  0.0182],
        ...,
        [ 0.0044, -0.0217,  0.0107,  ...,  0.0253,  0.0419,  0.0157],
        [ 0.0206,  0.0204, -0.0050,  ...,  0.0271,  0.0181, -0.0059],
        [-0.0166,  0.0097,  0.0152,  ..., -0.0109, -0.0128,  0.0233]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1055, -5.4844,  0.6548,  ..., -1.3623, -0.7466,  0.0227]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 22:54:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place hornet lives in is called nest
The place scorpion lives in is called nest
The place herring lives in is called sea
The place tiger lives in is called den
The place bat lives in is called cave
The place fish lives in is called sea
The place gorilla lives in is called grove
The place mouse lives in is called
2024-07-26 22:54:43 root INFO     [order_1_approx] starting weight calculation for The place fish lives in is called sea
The place tiger lives in is called den
The place bat lives in is called cave
The place gorilla lives in is called grove
The place hornet lives in is called nest
The place mouse lives in is called nest
The place scorpion lives in is called nest
The place herring lives in is called
2024-07-26 22:54:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 22:57:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1472, -0.0565, -0.2778,  ..., -0.0964, -0.1604, -0.1892],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.9219, -6.0625, -0.0527,  ..., -3.2734, -1.1348, -2.4453],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0552,  0.0156,  0.0153,  ...,  0.0078, -0.0013, -0.0071],
        [-0.0032,  0.0417, -0.0033,  ...,  0.0292,  0.0043, -0.0256],
        [-0.0055,  0.0204,  0.0401,  ..., -0.0223, -0.0012,  0.0287],
        ...,
        [ 0.0061,  0.0089,  0.0347,  ...,  0.0527, -0.0085, -0.0069],
        [ 0.0004,  0.0005, -0.0229,  ...,  0.0382,  0.0220, -0.0017],
        [-0.0209,  0.0058,  0.0026,  ...,  0.0004,  0.0180,  0.0261]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.0000, -6.0430, -0.2201,  ..., -3.3516, -0.9746, -2.2695]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 22:57:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place fish lives in is called sea
The place tiger lives in is called den
The place bat lives in is called cave
The place gorilla lives in is called grove
The place hornet lives in is called nest
The place mouse lives in is called nest
The place scorpion lives in is called nest
The place herring lives in is called
2024-07-26 22:57:27 root INFO     total operator prediction time: 1323.996817111969 seconds
2024-07-26 22:57:27 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on male - female
2024-07-26 22:57:27 root INFO     building operator male - female
2024-07-26 22:57:27 root INFO     [order_1_approx] starting weight calculation for A female lion is known as a lioness
A female prince is known as a princess
A female boy is known as a girl
A female daddy is known as a mommy
A female father is known as a mother
A female husband is known as a wife
A female stepfather is known as a stepmother
A female tiger is known as a
2024-07-26 22:57:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 23:00:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 1.0840e-01,  1.0620e-02, -1.1780e-01,  ..., -6.1035e-05,
        -1.2854e-01,  7.3364e-02], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9443, -5.9688, -1.4434,  ..., -0.8306, -1.9336,  0.5762],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.3438e-02, -1.6815e-02, -1.9730e-02,  ...,  5.8174e-05,
         -3.9856e-02, -4.7760e-03],
        [-2.7786e-02,  3.0426e-02, -2.1515e-02,  ...,  2.4475e-02,
          2.2984e-03,  6.6071e-03],
        [ 4.8431e-02, -8.1329e-03,  6.0852e-02,  ..., -2.6970e-03,
          5.8075e-02, -3.2578e-03],
        ...,
        [-1.7059e-02, -2.3361e-02,  1.0483e-02,  ...,  3.6743e-02,
          1.9455e-02, -5.2528e-03],
        [ 2.1835e-02,  1.4740e-02,  5.2834e-03,  ...,  2.5665e-02,
         -2.2018e-02,  3.2120e-03],
        [ 3.6564e-03, -6.9008e-03, -2.8610e-02,  ..., -2.2873e-02,
         -3.0045e-02,  1.6144e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9736, -6.0352, -1.5879,  ..., -1.0088, -1.9648,  0.3433]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 23:00:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female lion is known as a lioness
A female prince is known as a princess
A female boy is known as a girl
A female daddy is known as a mommy
A female father is known as a mother
A female husband is known as a wife
A female stepfather is known as a stepmother
A female tiger is known as a
2024-07-26 23:00:13 root INFO     [order_1_approx] starting weight calculation for A female tiger is known as a tigress
A female stepfather is known as a stepmother
A female lion is known as a lioness
A female husband is known as a wife
A female boy is known as a girl
A female daddy is known as a mommy
A female father is known as a mother
A female prince is known as a
2024-07-26 23:00:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 23:02:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2147,  0.0894, -0.1333,  ..., -0.1785, -0.2556,  0.2769],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6680, -4.4688, -1.5918,  ..., -1.7217, -0.3984,  1.2061],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0455,  0.0173,  0.0095,  ..., -0.0066,  0.0171,  0.0121],
        [-0.0409,  0.0111, -0.0455,  ...,  0.0418,  0.0308,  0.0086],
        [ 0.0464, -0.0118,  0.0601,  ..., -0.0159,  0.0277,  0.0113],
        ...,
        [-0.0549, -0.0021, -0.0082,  ...,  0.0649, -0.0284, -0.0227],
        [-0.0099, -0.0137,  0.0295,  ..., -0.0401,  0.0083,  0.0029],
        [ 0.0027, -0.0290, -0.0001,  ..., -0.0310, -0.0150,  0.0299]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4688, -4.1289, -1.8887,  ..., -1.8125, -1.0078,  0.5630]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 23:02:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female tiger is known as a tigress
A female stepfather is known as a stepmother
A female lion is known as a lioness
A female husband is known as a wife
A female boy is known as a girl
A female daddy is known as a mommy
A female father is known as a mother
A female prince is known as a
2024-07-26 23:02:59 root INFO     [order_1_approx] starting weight calculation for A female stepfather is known as a stepmother
A female prince is known as a princess
A female husband is known as a wife
A female boy is known as a girl
A female tiger is known as a tigress
A female daddy is known as a mommy
A female lion is known as a lioness
A female father is known as a
2024-07-26 23:02:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 23:05:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2698,  0.0313, -0.1521,  ..., -0.2954, -0.2499,  0.0775],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.7656, -2.6016, -1.8008,  ...,  1.2480, -2.4316, -1.4961],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0147,  0.0053,  0.0415,  ..., -0.0126, -0.0061,  0.0180],
        [-0.0225,  0.0169, -0.0240,  ...,  0.0397,  0.0586, -0.0157],
        [-0.0211, -0.0133,  0.0499,  ..., -0.0304, -0.0001, -0.0008],
        ...,
        [-0.0028,  0.0026, -0.0214,  ...,  0.0243,  0.0247,  0.0030],
        [ 0.0086, -0.0270,  0.0199,  ..., -0.0113, -0.0247, -0.0178],
        [ 0.0168, -0.0150, -0.0011,  ..., -0.0048, -0.0127,  0.0226]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.9297, -3.6133, -2.3672,  ...,  1.1924, -2.3926, -0.2891]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 23:05:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female stepfather is known as a stepmother
A female prince is known as a princess
A female husband is known as a wife
A female boy is known as a girl
A female tiger is known as a tigress
A female daddy is known as a mommy
A female lion is known as a lioness
A female father is known as a
2024-07-26 23:05:41 root INFO     [order_1_approx] starting weight calculation for A female tiger is known as a tigress
A female prince is known as a princess
A female father is known as a mother
A female husband is known as a wife
A female stepfather is known as a stepmother
A female daddy is known as a mommy
A female boy is known as a girl
A female lion is known as a
2024-07-26 23:05:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 23:08:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4727, -0.0157, -0.0883,  ...,  0.0868, -0.0999,  0.1497],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4238, -6.1758, -0.7070,  ...,  0.8848, -1.7842,  1.1758],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0153, -0.0085,  0.0137,  ..., -0.0089, -0.0412,  0.0089],
        [-0.0300,  0.0219, -0.0122,  ...,  0.0158,  0.0298,  0.0087],
        [ 0.0158, -0.0151,  0.0409,  ..., -0.0110,  0.0222,  0.0011],
        ...,
        [ 0.0008,  0.0033,  0.0053,  ...,  0.0277,  0.0276, -0.0096],
        [ 0.0039,  0.0187,  0.0181,  ...,  0.0216,  0.0140, -0.0020],
        [-0.0208, -0.0157, -0.0374,  ..., -0.0385, -0.0259,  0.0104]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3633, -6.0234, -0.6582,  ...,  0.7437, -1.8867,  0.9434]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 23:08:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female tiger is known as a tigress
A female prince is known as a princess
A female father is known as a mother
A female husband is known as a wife
A female stepfather is known as a stepmother
A female daddy is known as a mommy
A female boy is known as a girl
A female lion is known as a
2024-07-26 23:08:24 root INFO     [order_1_approx] starting weight calculation for A female daddy is known as a mommy
A female tiger is known as a tigress
A female father is known as a mother
A female lion is known as a lioness
A female husband is known as a wife
A female prince is known as a princess
A female boy is known as a girl
A female stepfather is known as a
2024-07-26 23:08:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 23:11:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2866, -0.0274,  0.2422,  ..., -0.0664, -0.2477,  0.3247],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.9922, -1.6191, -1.9863,  ...,  1.4971, -2.7051,  0.5273],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0109, -0.0013, -0.0105,  ...,  0.0089, -0.0127,  0.0305],
        [ 0.0149,  0.0207,  0.0040,  ...,  0.0093,  0.0153,  0.0037],
        [ 0.0010,  0.0075,  0.0516,  ..., -0.0081,  0.0068,  0.0120],
        ...,
        [-0.0026, -0.0054, -0.0016,  ..., -0.0003,  0.0095, -0.0200],
        [ 0.0093, -0.0052,  0.0252,  ..., -0.0212,  0.0031, -0.0020],
        [ 0.0210, -0.0105,  0.0170,  ..., -0.0023,  0.0095,  0.0257]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.2344, -1.7148, -2.1797,  ...,  1.3125, -2.7227,  0.8457]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 23:11:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female daddy is known as a mommy
A female tiger is known as a tigress
A female father is known as a mother
A female lion is known as a lioness
A female husband is known as a wife
A female prince is known as a princess
A female boy is known as a girl
A female stepfather is known as a
2024-07-26 23:11:09 root INFO     [order_1_approx] starting weight calculation for A female father is known as a mother
A female daddy is known as a mommy
A female boy is known as a girl
A female prince is known as a princess
A female stepfather is known as a stepmother
A female lion is known as a lioness
A female tiger is known as a tigress
A female husband is known as a
2024-07-26 23:11:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 23:13:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2568,  0.2175,  0.0948,  ...,  0.0842, -0.0920,  0.0929],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2285, -2.5859, -2.4863,  ...,  0.8496, -1.5312,  2.7031],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0079,  0.0081,  0.0149,  ...,  0.0013,  0.0055,  0.0391],
        [-0.0298,  0.0529, -0.0070,  ...,  0.0254,  0.0163, -0.0373],
        [ 0.0176, -0.0030,  0.0291,  ..., -0.0030,  0.0023,  0.0118],
        ...,
        [ 0.0046,  0.0207, -0.0005,  ...,  0.0336,  0.0172, -0.0102],
        [ 0.0338, -0.0056,  0.0093,  ..., -0.0196,  0.0012, -0.0170],
        [ 0.0054, -0.0179,  0.0015,  ...,  0.0072,  0.0105,  0.0018]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0352, -2.8945, -2.5898,  ...,  0.6763, -2.1172,  2.9160]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 23:13:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female father is known as a mother
A female daddy is known as a mommy
A female boy is known as a girl
A female prince is known as a princess
A female stepfather is known as a stepmother
A female lion is known as a lioness
A female tiger is known as a tigress
A female husband is known as a
2024-07-26 23:13:52 root INFO     [order_1_approx] starting weight calculation for A female husband is known as a wife
A female prince is known as a princess
A female tiger is known as a tigress
A female father is known as a mother
A female lion is known as a lioness
A female boy is known as a girl
A female stepfather is known as a stepmother
A female daddy is known as a
2024-07-26 23:13:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 23:16:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0235,  0.0829, -0.1210,  ..., -0.3345, -0.4980, -0.0159],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1445, -2.3047, -2.9922,  ...,  1.5957, -3.8164, -1.1328],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0581, -0.0410, -0.0347,  ..., -0.0015, -0.0080,  0.0193],
        [ 0.0027,  0.0667,  0.0031,  ...,  0.0395,  0.0024,  0.0015],
        [ 0.0060, -0.0359,  0.0356,  ...,  0.0170,  0.0012,  0.0044],
        ...,
        [ 0.0316, -0.0108,  0.0002,  ...,  0.0298, -0.0098, -0.0068],
        [-0.0044, -0.0442,  0.0099,  ..., -0.0145,  0.0058, -0.0041],
        [-0.0105, -0.0097,  0.0270,  ..., -0.0011,  0.0228,  0.0014]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0781, -2.2383, -2.7910,  ...,  1.5410, -4.0117, -1.0732]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 23:16:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female husband is known as a wife
A female prince is known as a princess
A female tiger is known as a tigress
A female father is known as a mother
A female lion is known as a lioness
A female boy is known as a girl
A female stepfather is known as a stepmother
A female daddy is known as a
2024-07-26 23:16:36 root INFO     [order_1_approx] starting weight calculation for A female stepfather is known as a stepmother
A female father is known as a mother
A female husband is known as a wife
A female lion is known as a lioness
A female prince is known as a princess
A female tiger is known as a tigress
A female daddy is known as a mommy
A female boy is known as a
2024-07-26 23:16:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 23:19:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3018,  0.1775, -0.1621,  ..., -0.0880, -0.4102, -0.1134],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1953, -2.7227, -3.7812,  ...,  3.4883, -1.0869,  1.3320],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0086, -0.0269, -0.0121,  ...,  0.0502,  0.0034,  0.0197],
        [-0.0061,  0.0395,  0.0106,  ...,  0.0189,  0.0334, -0.0181],
        [ 0.0151, -0.0274,  0.0316,  ..., -0.0401, -0.0356,  0.0350],
        ...,
        [-0.0281,  0.0144,  0.0262,  ...,  0.0274,  0.0280, -0.0192],
        [-0.0238,  0.0297,  0.0167,  ..., -0.0059, -0.0134,  0.0107],
        [ 0.0019, -0.0084, -0.0114,  ...,  0.0018,  0.0210, -0.0098]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.1367, -3.0020, -4.1289,  ...,  3.0977, -1.4473,  1.6514]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 23:19:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female stepfather is known as a stepmother
A female father is known as a mother
A female husband is known as a wife
A female lion is known as a lioness
A female prince is known as a princess
A female tiger is known as a tigress
A female daddy is known as a mommy
A female boy is known as a
2024-07-26 23:19:21 root INFO     total operator prediction time: 1313.863042831421 seconds
2024-07-26 23:19:21 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on name - occupation
2024-07-26 23:19:21 root INFO     building operator name - occupation
2024-07-26 23:19:21 root INFO     [order_1_approx] starting weight calculation for marx was known for their work as a  philosopher
aristotle was known for their work as a  philosopher
pascal was known for their work as a  mathematician
jolie was known for their work as a  actress
beethoven was known for their work as a  composer
hume was known for their work as a  philosopher
euler was known for their work as a  mathematician
haydn was known for their work as a 
2024-07-26 23:19:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 23:22:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0427,  0.1219, -0.2244,  ..., -0.0604, -0.1057,  0.0342],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7227, -4.7031,  2.0586,  ..., -2.7012,  0.9707, -2.2070],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.6266e-02,  1.8829e-02,  3.7231e-03,  ..., -4.8752e-03,
         -2.5772e-02,  3.0121e-02],
        [ 4.5776e-05,  2.6245e-02,  9.3079e-04,  ..., -2.0981e-04,
          6.7177e-03, -2.2888e-04],
        [-6.4850e-04,  4.0054e-03,  6.3782e-02,  ..., -1.1719e-02,
          1.0262e-03,  2.9312e-02],
        ...,
        [ 1.2970e-04,  5.6000e-03,  2.0920e-02,  ...,  5.5939e-02,
          2.9202e-03, -1.9958e-02],
        [ 1.0605e-02,  1.8646e-02,  1.6403e-02,  ...,  8.6060e-03,
          1.6296e-02,  1.3046e-02],
        [-6.6376e-03, -2.4414e-03, -1.0986e-02,  ..., -1.2878e-02,
         -2.2644e-02,  2.6230e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3555, -4.2578,  1.7188,  ..., -2.9570,  0.7139, -1.5020]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 23:22:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for marx was known for their work as a  philosopher
aristotle was known for their work as a  philosopher
pascal was known for their work as a  mathematician
jolie was known for their work as a  actress
beethoven was known for their work as a  composer
hume was known for their work as a  philosopher
euler was known for their work as a  mathematician
haydn was known for their work as a 
2024-07-26 23:22:10 root INFO     [order_1_approx] starting weight calculation for jolie was known for their work as a  actress
haydn was known for their work as a  composer
marx was known for their work as a  philosopher
aristotle was known for their work as a  philosopher
beethoven was known for their work as a  composer
pascal was known for their work as a  mathematician
euler was known for their work as a  mathematician
hume was known for their work as a 
2024-07-26 23:22:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 23:24:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2188,  0.2415, -0.1757,  ..., -0.1567,  0.3330,  0.0864],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8149, -3.0156,  2.6641,  ..., -4.5742, -0.0459, -1.9600],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0648,  0.0184, -0.0003,  ...,  0.0043, -0.0136, -0.0148],
        [ 0.0066,  0.0603,  0.0238,  ..., -0.0237, -0.0270, -0.0088],
        [ 0.0032, -0.0042,  0.0652,  ...,  0.0101, -0.0005, -0.0153],
        ...,
        [-0.0043,  0.0130,  0.0128,  ...,  0.0494, -0.0080, -0.0258],
        [ 0.0215,  0.0159,  0.0261,  ...,  0.0327,  0.0308,  0.0066],
        [-0.0253,  0.0361,  0.0075,  ..., -0.0475, -0.0310,  0.0645]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9614, -3.2715,  3.1543,  ..., -4.7500, -0.6982, -1.9277]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 23:24:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for jolie was known for their work as a  actress
haydn was known for their work as a  composer
marx was known for their work as a  philosopher
aristotle was known for their work as a  philosopher
beethoven was known for their work as a  composer
pascal was known for their work as a  mathematician
euler was known for their work as a  mathematician
hume was known for their work as a 
2024-07-26 23:24:57 root INFO     [order_1_approx] starting weight calculation for euler was known for their work as a  mathematician
jolie was known for their work as a  actress
marx was known for their work as a  philosopher
pascal was known for their work as a  mathematician
hume was known for their work as a  philosopher
haydn was known for their work as a  composer
aristotle was known for their work as a  philosopher
beethoven was known for their work as a 
2024-07-26 23:24:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 23:27:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1234,  0.1844, -0.3542,  ..., -0.0978,  0.0094, -0.1825],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7012, -5.5234,  1.6865,  ..., -2.7715,  1.1592, -2.0566],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0244,  0.0007, -0.0075,  ...,  0.0052,  0.0077, -0.0119],
        [ 0.0391,  0.0067,  0.0067,  ..., -0.0292, -0.0187,  0.0034],
        [-0.0139, -0.0015,  0.0193,  ...,  0.0020,  0.0112, -0.0025],
        ...,
        [-0.0204,  0.0267, -0.0256,  ...,  0.0303,  0.0102, -0.0092],
        [ 0.0156,  0.0079,  0.0021,  ...,  0.0050,  0.0072, -0.0033],
        [ 0.0088, -0.0166,  0.0154,  ..., -0.0201, -0.0149,  0.0174]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6250, -5.0391,  1.3867,  ..., -3.0020,  1.2031, -1.8145]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 23:27:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for euler was known for their work as a  mathematician
jolie was known for their work as a  actress
marx was known for their work as a  philosopher
pascal was known for their work as a  mathematician
hume was known for their work as a  philosopher
haydn was known for their work as a  composer
aristotle was known for their work as a  philosopher
beethoven was known for their work as a 
2024-07-26 23:27:43 root INFO     [order_1_approx] starting weight calculation for euler was known for their work as a  mathematician
jolie was known for their work as a  actress
hume was known for their work as a  philosopher
aristotle was known for their work as a  philosopher
beethoven was known for their work as a  composer
haydn was known for their work as a  composer
marx was known for their work as a  philosopher
pascal was known for their work as a 
2024-07-26 23:27:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 23:30:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0229,  0.0939, -0.1665,  ..., -0.3433, -0.0402,  0.3960],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1514, -1.2070,  2.4219,  ..., -5.7930,  0.6870,  0.8262],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0831,  0.0124,  0.0054,  ...,  0.0260, -0.0286, -0.0247],
        [ 0.0423,  0.0577, -0.0213,  ...,  0.0542, -0.0067, -0.0018],
        [ 0.0411,  0.0325,  0.0617,  ...,  0.0154,  0.0087,  0.0060],
        ...,
        [-0.0268,  0.0339,  0.0087,  ...,  0.0918,  0.0117, -0.0049],
        [ 0.0100, -0.0123,  0.0552,  ...,  0.0128,  0.0369, -0.0037],
        [-0.0047,  0.0392, -0.0029,  ..., -0.0152, -0.0259,  0.0422]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8623, -1.4766,  1.6973,  ..., -5.0117,  0.7744,  0.6963]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 23:30:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for euler was known for their work as a  mathematician
jolie was known for their work as a  actress
hume was known for their work as a  philosopher
aristotle was known for their work as a  philosopher
beethoven was known for their work as a  composer
haydn was known for their work as a  composer
marx was known for their work as a  philosopher
pascal was known for their work as a 
2024-07-26 23:30:30 root INFO     [order_1_approx] starting weight calculation for beethoven was known for their work as a  composer
aristotle was known for their work as a  philosopher
marx was known for their work as a  philosopher
hume was known for their work as a  philosopher
euler was known for their work as a  mathematician
pascal was known for their work as a  mathematician
haydn was known for their work as a  composer
jolie was known for their work as a 
2024-07-26 23:30:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 23:33:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2477,  0.1387, -0.4229,  ...,  0.2134, -0.1851,  0.0745],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8906, -4.4766,  2.5703,  ..., -4.4219, -1.5000,  1.4355],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0462,  0.0061, -0.0115,  ...,  0.0023, -0.0341,  0.0022],
        [ 0.0006,  0.0363,  0.0114,  ..., -0.0004,  0.0022, -0.0124],
        [ 0.0178,  0.0189,  0.0318,  ...,  0.0099,  0.0191,  0.0215],
        ...,
        [ 0.0092,  0.0055,  0.0124,  ...,  0.0645, -0.0214,  0.0063],
        [ 0.0026,  0.0101, -0.0253,  ...,  0.0012, -0.0012,  0.0014],
        [ 0.0166,  0.0020,  0.0079,  ...,  0.0190,  0.0386,  0.0408]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4824, -4.3320,  2.4160,  ..., -3.9375, -1.8398,  1.4062]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 23:33:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for beethoven was known for their work as a  composer
aristotle was known for their work as a  philosopher
marx was known for their work as a  philosopher
hume was known for their work as a  philosopher
euler was known for their work as a  mathematician
pascal was known for their work as a  mathematician
haydn was known for their work as a  composer
jolie was known for their work as a 
2024-07-26 23:33:18 root INFO     [order_1_approx] starting weight calculation for haydn was known for their work as a  composer
marx was known for their work as a  philosopher
jolie was known for their work as a  actress
beethoven was known for their work as a  composer
pascal was known for their work as a  mathematician
hume was known for their work as a  philosopher
euler was known for their work as a  mathematician
aristotle was known for their work as a 
2024-07-26 23:33:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 23:36:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3098, -0.0988, -0.6538,  ..., -0.4236, -0.1516,  0.2573],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6074, -5.2422,  2.3262,  ..., -6.6992, -1.2764, -1.7305],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.5583e-02, -6.1302e-03,  8.4686e-04,  ..., -1.3985e-02,
         -1.1055e-02,  9.4833e-03],
        [ 1.8921e-02, -2.1973e-03,  5.5695e-03,  ..., -1.7990e-02,
         -8.5526e-03,  1.8921e-02],
        [-7.9803e-03,  9.5367e-04,  1.5144e-02,  ...,  1.8188e-02,
          5.0125e-03, -3.8147e-03],
        ...,
        [ 3.2684e-02, -1.0796e-02,  3.0899e-04,  ...,  1.2840e-02,
         -7.8735e-03,  7.6256e-03],
        [ 4.0054e-05,  7.1220e-03,  9.0332e-03,  ..., -2.0733e-03,
         -4.8523e-03,  4.8447e-03],
        [-1.9531e-02,  5.6229e-03, -2.9335e-03,  ..., -1.2627e-03,
          7.7820e-03,  2.2110e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7783, -4.7188,  2.1250,  ..., -6.1016, -1.3887, -1.7207]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 23:36:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for haydn was known for their work as a  composer
marx was known for their work as a  philosopher
jolie was known for their work as a  actress
beethoven was known for their work as a  composer
pascal was known for their work as a  mathematician
hume was known for their work as a  philosopher
euler was known for their work as a  mathematician
aristotle was known for their work as a 
2024-07-26 23:36:03 root INFO     [order_1_approx] starting weight calculation for jolie was known for their work as a  actress
hume was known for their work as a  philosopher
euler was known for their work as a  mathematician
haydn was known for their work as a  composer
aristotle was known for their work as a  philosopher
beethoven was known for their work as a  composer
pascal was known for their work as a  mathematician
marx was known for their work as a 
2024-07-26 23:36:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 23:38:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0299,  0.0137, -0.0044,  ...,  0.1403,  0.1591,  0.2517],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5825, -7.2461,  3.2109,  ..., -4.9531,  0.9355, -2.8750],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.8228e-02, -9.1553e-03,  7.9956e-03,  ..., -2.2552e-02,
         -1.4961e-02,  8.6365e-03],
        [ 1.9165e-02,  3.5583e-02, -3.4237e-03,  ...,  8.0719e-03,
         -3.0228e-02, -1.7868e-02],
        [ 1.6907e-02, -1.3168e-02,  4.9835e-02,  ..., -6.1569e-03,
         -4.0054e-04,  3.6895e-05],
        ...,
        [-1.5411e-03,  4.5242e-03,  1.1955e-02,  ...,  6.3416e-02,
         -1.2932e-02,  1.6159e-02],
        [ 1.8339e-03,  8.1177e-03,  1.6813e-03,  ...,  2.2903e-02,
          1.4145e-02,  3.8738e-03],
        [-2.8381e-03,  1.9409e-02,  2.2110e-02,  ...,  1.3535e-02,
          1.1208e-02,  2.5589e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3984, -6.8164,  3.3125,  ..., -4.7852,  0.8086, -2.4961]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 23:38:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for jolie was known for their work as a  actress
hume was known for their work as a  philosopher
euler was known for their work as a  mathematician
haydn was known for their work as a  composer
aristotle was known for their work as a  philosopher
beethoven was known for their work as a  composer
pascal was known for their work as a  mathematician
marx was known for their work as a 
2024-07-26 23:38:47 root INFO     [order_1_approx] starting weight calculation for beethoven was known for their work as a  composer
jolie was known for their work as a  actress
marx was known for their work as a  philosopher
pascal was known for their work as a  mathematician
haydn was known for their work as a  composer
hume was known for their work as a  philosopher
aristotle was known for their work as a  philosopher
euler was known for their work as a 
2024-07-26 23:38:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 23:41:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2729,  0.1726, -0.2798,  ..., -0.3406, -0.1992, -0.0054],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4229, -1.6133, -0.6748,  ..., -4.5820, -0.8047, -0.2324],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.8359e-02, -1.5106e-03,  2.3743e-02,  ..., -4.2847e-02,
         -1.1505e-02, -2.7222e-02],
        [ 9.2697e-04,  5.5664e-02, -6.8817e-03,  ...,  1.9913e-02,
         -1.4259e-02, -1.8585e-02],
        [ 3.5919e-02,  6.5155e-03,  8.3374e-02,  ...,  1.6937e-02,
         -3.0518e-05,  8.1253e-03],
        ...,
        [-5.9280e-03,  2.5177e-02, -7.5226e-03,  ...,  1.0272e-01,
         -2.7237e-03,  2.6703e-05],
        [ 1.0742e-02,  2.5238e-02,  2.5345e-02,  ...,  3.6774e-03,
          5.4596e-02, -3.1219e-02],
        [-1.8463e-03,  8.4229e-03, -1.1963e-02,  ...,  1.1658e-02,
         -3.1647e-02,  8.7769e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4390, -1.5430, -0.7275,  ..., -3.8770, -1.5957,  0.4697]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 23:41:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for beethoven was known for their work as a  composer
jolie was known for their work as a  actress
marx was known for their work as a  philosopher
pascal was known for their work as a  mathematician
haydn was known for their work as a  composer
hume was known for their work as a  philosopher
aristotle was known for their work as a  philosopher
euler was known for their work as a 
2024-07-26 23:41:26 root INFO     total operator prediction time: 1325.7234210968018 seconds
2024-07-26 23:41:26 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on country - capital
2024-07-26 23:41:26 root INFO     building operator country - capital
2024-07-26 23:41:27 root INFO     [order_1_approx] starting weight calculation for The country with bangkok as its capital is known as thailand
The country with london as its capital is known as england
The country with dublin as its capital is known as ireland
The country with brussels as its capital is known as belgium
The country with damascus as its capital is known as syria
The country with vienna as its capital is known as austria
The country with paris as its capital is known as france
The country with jakarta as its capital is known as
2024-07-26 23:41:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 23:44:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2168, -0.0025, -0.5928,  ...,  0.2271, -0.4641,  0.0121],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8594, -5.8281, -0.8438,  ..., -1.5527, -1.3594, -3.8281],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.1656e-02,  1.6327e-02, -3.7403e-03,  ...,  1.0139e-02,
         -6.9275e-03, -6.1722e-03],
        [-3.9577e-05,  1.7303e-02, -7.1793e-03,  ..., -1.8250e-02,
         -2.6836e-03, -2.1606e-02],
        [ 1.5860e-03,  1.6769e-02,  4.5410e-02,  ...,  6.4697e-03,
          1.4832e-02,  3.8223e-03],
        ...,
        [ 1.1833e-02,  2.2583e-02,  1.8063e-03,  ...,  1.8723e-02,
          4.6921e-03, -1.9958e-02],
        [ 1.2054e-02, -3.5667e-03, -1.2238e-02,  ...,  8.2245e-03,
          1.5152e-02,  3.5992e-03],
        [ 1.2680e-02, -2.2781e-02, -9.8572e-03,  ..., -1.0376e-02,
         -1.1566e-02,  1.8295e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6855, -5.6133, -0.9619,  ..., -1.1348, -1.4629, -3.5898]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 23:44:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with bangkok as its capital is known as thailand
The country with london as its capital is known as england
The country with dublin as its capital is known as ireland
The country with brussels as its capital is known as belgium
The country with damascus as its capital is known as syria
The country with vienna as its capital is known as austria
The country with paris as its capital is known as france
The country with jakarta as its capital is known as
2024-07-26 23:44:09 root INFO     [order_1_approx] starting weight calculation for The country with jakarta as its capital is known as indonesia
The country with bangkok as its capital is known as thailand
The country with london as its capital is known as england
The country with dublin as its capital is known as ireland
The country with damascus as its capital is known as syria
The country with brussels as its capital is known as belgium
The country with paris as its capital is known as france
The country with vienna as its capital is known as
2024-07-26 23:44:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 23:46:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2473, -0.1808, -0.2944,  ...,  0.0737, -0.1625, -0.1088],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4463, -5.9727, -0.3320,  ..., -0.0616,  1.0449, -2.4785],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0022, -0.0039, -0.0116,  ...,  0.0058,  0.0040,  0.0046],
        [ 0.0025,  0.0180,  0.0134,  ..., -0.0210, -0.0051, -0.0149],
        [-0.0139,  0.0077,  0.0285,  ...,  0.0013, -0.0003, -0.0029],
        ...,
        [ 0.0051,  0.0374, -0.0024,  ...,  0.0561, -0.0106, -0.0158],
        [ 0.0167, -0.0047, -0.0086,  ...,  0.0098,  0.0043,  0.0076],
        [-0.0289,  0.0144,  0.0156,  ...,  0.0110,  0.0004, -0.0055]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4092, -5.4414, -0.3320,  ..., -0.4534,  0.9048, -2.3965]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 23:46:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with jakarta as its capital is known as indonesia
The country with bangkok as its capital is known as thailand
The country with london as its capital is known as england
The country with dublin as its capital is known as ireland
The country with damascus as its capital is known as syria
The country with brussels as its capital is known as belgium
The country with paris as its capital is known as france
The country with vienna as its capital is known as
2024-07-26 23:46:53 root INFO     [order_1_approx] starting weight calculation for The country with london as its capital is known as england
The country with bangkok as its capital is known as thailand
The country with brussels as its capital is known as belgium
The country with paris as its capital is known as france
The country with vienna as its capital is known as austria
The country with jakarta as its capital is known as indonesia
The country with dublin as its capital is known as ireland
The country with damascus as its capital is known as
2024-07-26 23:46:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 23:49:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0146, -0.1772, -0.5713,  ..., -0.0510, -0.1281, -0.1329],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9629, -5.5859, -1.5703,  ..., -0.2397,  1.8301, -4.5391],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0126, -0.0091, -0.0086,  ..., -0.0026, -0.0046, -0.0080],
        [ 0.0022, -0.0068,  0.0090,  ...,  0.0032,  0.0020, -0.0017],
        [-0.0263,  0.0113, -0.0036,  ..., -0.0157,  0.0037, -0.0126],
        ...,
        [ 0.0026,  0.0128, -0.0127,  ...,  0.0082, -0.0051, -0.0091],
        [ 0.0126, -0.0038,  0.0063,  ...,  0.0040,  0.0107,  0.0005],
        [-0.0033, -0.0084,  0.0031,  ...,  0.0015, -0.0015,  0.0004]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0762, -5.6289, -1.6318,  ..., -0.0490,  1.9512, -4.5977]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 23:49:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with london as its capital is known as england
The country with bangkok as its capital is known as thailand
The country with brussels as its capital is known as belgium
The country with paris as its capital is known as france
The country with vienna as its capital is known as austria
The country with jakarta as its capital is known as indonesia
The country with dublin as its capital is known as ireland
The country with damascus as its capital is known as
2024-07-26 23:49:41 root INFO     [order_1_approx] starting weight calculation for The country with paris as its capital is known as france
The country with bangkok as its capital is known as thailand
The country with london as its capital is known as england
The country with damascus as its capital is known as syria
The country with dublin as its capital is known as ireland
The country with jakarta as its capital is known as indonesia
The country with vienna as its capital is known as austria
The country with brussels as its capital is known as
2024-07-26 23:49:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 23:52:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.5112, -0.0214, -0.3879,  ...,  0.1981, -0.1934,  0.1312],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2773, -6.2188, -1.7344,  ..., -0.6699,  0.6328, -3.9219],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.9427e-03,  5.2872e-03, -1.2856e-03,  ...,  9.3460e-03,
         -5.6419e-03, -4.9019e-03],
        [ 1.0319e-03,  5.7259e-03,  1.3687e-02,  ..., -1.2619e-02,
         -3.8223e-03, -1.5783e-03],
        [ 5.8365e-04,  3.8261e-03,  9.9564e-03,  ..., -1.7738e-04,
          1.1314e-02, -2.1973e-03],
        ...,
        [-1.6449e-02, -5.8899e-03, -3.5133e-03,  ...,  1.8448e-02,
          8.6365e-03, -2.3453e-02],
        [ 1.3031e-02, -9.1553e-05, -2.3403e-03,  ..., -4.6577e-03,
          2.7771e-03,  8.5678e-03],
        [-7.5150e-03, -1.3931e-02, -1.9165e-02,  ...,  1.0262e-03,
         -8.0414e-03, -1.9989e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1191, -5.9180, -1.7539,  ..., -0.6113,  0.6470, -3.8555]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 23:52:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with paris as its capital is known as france
The country with bangkok as its capital is known as thailand
The country with london as its capital is known as england
The country with damascus as its capital is known as syria
The country with dublin as its capital is known as ireland
The country with jakarta as its capital is known as indonesia
The country with vienna as its capital is known as austria
The country with brussels as its capital is known as
2024-07-26 23:52:27 root INFO     [order_1_approx] starting weight calculation for The country with bangkok as its capital is known as thailand
The country with london as its capital is known as england
The country with jakarta as its capital is known as indonesia
The country with brussels as its capital is known as belgium
The country with paris as its capital is known as france
The country with damascus as its capital is known as syria
The country with vienna as its capital is known as austria
The country with dublin as its capital is known as
2024-07-26 23:52:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 23:55:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2206,  0.0137, -0.5781,  ...,  0.3352, -0.1133, -0.1125],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9023, -5.5195, -1.1445,  ...,  1.8711, -1.0850, -6.6406],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0330, -0.0096,  0.0024,  ...,  0.0190, -0.0089,  0.0190],
        [-0.0106,  0.0286, -0.0140,  ..., -0.0213, -0.0245, -0.0292],
        [-0.0120,  0.0057,  0.0275,  ...,  0.0181,  0.0259, -0.0147],
        ...,
        [ 0.0145,  0.0216,  0.0019,  ...,  0.0347,  0.0092, -0.0400],
        [-0.0092,  0.0071, -0.0161,  ..., -0.0119,  0.0104, -0.0161],
        [-0.0042, -0.0221,  0.0108,  ..., -0.0118,  0.0011,  0.0165]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8301, -5.3594, -1.1816,  ...,  1.8936, -1.3027, -6.4961]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 23:55:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with bangkok as its capital is known as thailand
The country with london as its capital is known as england
The country with jakarta as its capital is known as indonesia
The country with brussels as its capital is known as belgium
The country with paris as its capital is known as france
The country with damascus as its capital is known as syria
The country with vienna as its capital is known as austria
The country with dublin as its capital is known as
2024-07-26 23:55:15 root INFO     [order_1_approx] starting weight calculation for The country with vienna as its capital is known as austria
The country with jakarta as its capital is known as indonesia
The country with paris as its capital is known as france
The country with damascus as its capital is known as syria
The country with brussels as its capital is known as belgium
The country with bangkok as its capital is known as thailand
The country with dublin as its capital is known as ireland
The country with london as its capital is known as
2024-07-26 23:55:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-26 23:57:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0391, -0.0650, -0.1246,  ...,  0.1285,  0.1927,  0.0972],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9727, -5.3672, -1.0059,  ..., -3.4844,  0.8159, -5.7930],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0195, -0.0166, -0.0069,  ...,  0.0192,  0.0087,  0.0029],
        [-0.0007,  0.0193, -0.0107,  ..., -0.0057, -0.0049, -0.0104],
        [-0.0027, -0.0132,  0.0258,  ...,  0.0064,  0.0329,  0.0166],
        ...,
        [-0.0211,  0.0025, -0.0049,  ...,  0.0111, -0.0069, -0.0370],
        [ 0.0062, -0.0056,  0.0155,  ..., -0.0111,  0.0002,  0.0057],
        [-0.0020, -0.0097,  0.0021,  ..., -0.0082, -0.0157, -0.0028]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8975, -5.2070, -1.1777,  ..., -3.4863,  0.7510, -5.3945]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-26 23:57:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with vienna as its capital is known as austria
The country with jakarta as its capital is known as indonesia
The country with paris as its capital is known as france
The country with damascus as its capital is known as syria
The country with brussels as its capital is known as belgium
The country with bangkok as its capital is known as thailand
The country with dublin as its capital is known as ireland
The country with london as its capital is known as
2024-07-26 23:57:57 root INFO     [order_1_approx] starting weight calculation for The country with jakarta as its capital is known as indonesia
The country with london as its capital is known as england
The country with vienna as its capital is known as austria
The country with damascus as its capital is known as syria
The country with dublin as its capital is known as ireland
The country with brussels as its capital is known as belgium
The country with bangkok as its capital is known as thailand
The country with paris as its capital is known as
2024-07-26 23:57:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 00:00:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0381, -0.1438, -0.4700,  ...,  0.1318,  0.0826,  0.0484],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9688, -5.1250,  0.8154,  ..., -2.0039,  1.1445, -3.0488],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.3209e-02, -1.6449e-02, -1.2627e-02,  ..., -5.8670e-03,
          2.0981e-03,  9.0637e-03],
        [ 1.0460e-02,  2.4628e-02,  5.6267e-05,  ..., -1.3206e-02,
         -2.4643e-02, -2.4231e-02],
        [-4.2648e-03, -1.0620e-02,  4.2236e-02,  ...,  1.7944e-02,
          3.1616e-02, -6.3171e-03],
        ...,
        [ 2.3300e-02, -7.1220e-03,  2.7809e-03,  ...,  3.2349e-02,
         -1.5495e-02, -2.9694e-02],
        [-1.8396e-03, -2.4338e-03,  8.0261e-03,  ..., -4.0359e-03,
          8.5678e-03, -1.5907e-03],
        [-1.2314e-02,  9.1553e-04,  2.8763e-03,  ...,  1.4999e-02,
         -8.1177e-03,  9.0790e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7383, -4.3945,  0.8438,  ..., -1.7861,  0.9243, -2.4297]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 00:00:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with jakarta as its capital is known as indonesia
The country with london as its capital is known as england
The country with vienna as its capital is known as austria
The country with damascus as its capital is known as syria
The country with dublin as its capital is known as ireland
The country with brussels as its capital is known as belgium
The country with bangkok as its capital is known as thailand
The country with paris as its capital is known as
2024-07-27 00:00:41 root INFO     [order_1_approx] starting weight calculation for The country with jakarta as its capital is known as indonesia
The country with vienna as its capital is known as austria
The country with damascus as its capital is known as syria
The country with brussels as its capital is known as belgium
The country with dublin as its capital is known as ireland
The country with london as its capital is known as england
The country with paris as its capital is known as france
The country with bangkok as its capital is known as
2024-07-27 00:00:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 00:03:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0522,  0.1199, -0.3945,  ...,  0.1458, -0.3223, -0.0061],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2812, -5.6406,  1.0996,  ..., -0.4795, -1.8613, -3.6680],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0222, -0.0049,  0.0077,  ...,  0.0052, -0.0038, -0.0011],
        [ 0.0082, -0.0060,  0.0082,  ..., -0.0173,  0.0030, -0.0326],
        [ 0.0012,  0.0041,  0.0273,  ...,  0.0010,  0.0193, -0.0006],
        ...,
        [ 0.0106,  0.0007,  0.0193,  ...,  0.0110,  0.0039, -0.0305],
        [-0.0026, -0.0032, -0.0220,  ..., -0.0036,  0.0053,  0.0080],
        [-0.0010, -0.0180,  0.0104,  ..., -0.0097,  0.0218,  0.0004]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2988, -5.1641,  1.3145,  ..., -0.1416, -1.8662, -3.5020]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 00:03:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with jakarta as its capital is known as indonesia
The country with vienna as its capital is known as austria
The country with damascus as its capital is known as syria
The country with brussels as its capital is known as belgium
The country with dublin as its capital is known as ireland
The country with london as its capital is known as england
The country with paris as its capital is known as france
The country with bangkok as its capital is known as
2024-07-27 00:03:19 root INFO     total operator prediction time: 1312.4110860824585 seconds
2024-07-27 00:03:19 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on things - color
2024-07-27 00:03:19 root INFO     building operator things - color
2024-07-27 00:03:19 root INFO     [order_1_approx] starting weight calculation for The grass is colored green
The leaves is colored green
The toothpaste is colored white
The cauliflower is colored white
The coffee is colored black
The fridge is colored white
The yoghurt is colored white
The cream is colored
2024-07-27 00:03:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 00:06:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2290, -0.3284,  0.0453,  ..., -0.1538, -0.2876, -0.0462],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1123, -5.5234,  2.5645,  ..., -3.1777, -0.3252, -0.9531],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0345,  0.0004,  0.0113,  ..., -0.0099, -0.0196,  0.0186],
        [ 0.0298,  0.0164,  0.0042,  ..., -0.0161, -0.0201,  0.0077],
        [-0.0001,  0.0098,  0.0061,  ...,  0.0193,  0.0187, -0.0071],
        ...,
        [ 0.0136,  0.0050,  0.0123,  ...,  0.0260,  0.0041, -0.0034],
        [ 0.0163,  0.0036, -0.0110,  ...,  0.0263,  0.0106,  0.0005],
        [-0.0045, -0.0047, -0.0082,  ..., -0.0011,  0.0080,  0.0286]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1555, -5.7266,  2.2852,  ..., -3.3008, -0.8179, -0.9399]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 00:06:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The grass is colored green
The leaves is colored green
The toothpaste is colored white
The cauliflower is colored white
The coffee is colored black
The fridge is colored white
The yoghurt is colored white
The cream is colored
2024-07-27 00:06:04 root INFO     [order_1_approx] starting weight calculation for The cauliflower is colored white
The toothpaste is colored white
The fridge is colored white
The coffee is colored black
The leaves is colored green
The yoghurt is colored white
The cream is colored white
The grass is colored
2024-07-27 00:06:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 00:08:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0099,  0.1877, -0.2268,  ..., -0.2153, -0.0535, -0.1815],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3594, -5.4688, -1.8428,  ..., -1.6982,  0.8120, -2.6738],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0657,  0.0300,  0.0098,  ..., -0.0084,  0.0092, -0.0011],
        [-0.0037, -0.0033, -0.0196,  ..., -0.0017, -0.0081, -0.0280],
        [ 0.0103,  0.0108,  0.0383,  ..., -0.0278, -0.0063,  0.0324],
        ...,
        [-0.0090, -0.0191, -0.0014,  ...,  0.0316,  0.0093,  0.0062],
        [ 0.0163, -0.0105,  0.0117,  ...,  0.0082,  0.0233, -0.0339],
        [-0.0268, -0.0190,  0.0082,  ..., -0.0026, -0.0088,  0.0312]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5977, -5.3906, -1.7217,  ..., -1.5771,  0.5103, -2.8340]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 00:08:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The cauliflower is colored white
The toothpaste is colored white
The fridge is colored white
The coffee is colored black
The leaves is colored green
The yoghurt is colored white
The cream is colored white
The grass is colored
2024-07-27 00:08:49 root INFO     [order_1_approx] starting weight calculation for The cream is colored white
The yoghurt is colored white
The leaves is colored green
The coffee is colored black
The cauliflower is colored white
The fridge is colored white
The grass is colored green
The toothpaste is colored
2024-07-27 00:08:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 00:11:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0336, -0.3081, -0.0917,  ..., -0.2656, -0.4546, -0.0961],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.8848, -2.5215,  1.1484,  ..., -1.1299, -2.8398, -0.7168],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0496,  0.0292,  0.0323,  ..., -0.0265, -0.0375,  0.0267],
        [-0.0084,  0.0585, -0.0227,  ...,  0.0013,  0.0052, -0.0233],
        [-0.0036,  0.0064,  0.0244,  ...,  0.0137, -0.0084,  0.0094],
        ...,
        [-0.0129, -0.0098,  0.0282,  ...,  0.0156,  0.0081, -0.0140],
        [ 0.0146, -0.0029, -0.0172,  ...,  0.0396,  0.0056, -0.0357],
        [-0.0025, -0.0183,  0.0145,  ..., -0.0030,  0.0135,  0.0396]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.7363, -3.1211,  0.4102,  ..., -1.2979, -2.4707, -0.8071]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 00:11:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The cream is colored white
The yoghurt is colored white
The leaves is colored green
The coffee is colored black
The cauliflower is colored white
The fridge is colored white
The grass is colored green
The toothpaste is colored
2024-07-27 00:11:33 root INFO     [order_1_approx] starting weight calculation for The fridge is colored white
The toothpaste is colored white
The yoghurt is colored white
The grass is colored green
The cream is colored white
The cauliflower is colored white
The leaves is colored green
The coffee is colored
2024-07-27 00:11:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 00:14:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0870, -0.2345, -0.0470,  ..., -0.1375, -0.3613, -0.2312],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1836, -3.7598, -0.2134,  ..., -3.1016, -1.7363, -2.5469],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0291,  0.0269,  0.0125,  ..., -0.0419, -0.0027,  0.0210],
        [ 0.0047,  0.0185,  0.0026,  ..., -0.0048, -0.0259, -0.0275],
        [ 0.0014, -0.0132,  0.0275,  ...,  0.0135, -0.0060, -0.0081],
        ...,
        [ 0.0107, -0.0077, -0.0158,  ...,  0.0431, -0.0186, -0.0187],
        [ 0.0117, -0.0218, -0.0244,  ...,  0.0306,  0.0412, -0.0280],
        [-0.0300, -0.0319, -0.0005,  ..., -0.0047, -0.0170,  0.0665]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1060, -3.7441, -0.2261,  ..., -3.1406, -1.6826, -2.8457]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 00:14:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The fridge is colored white
The toothpaste is colored white
The yoghurt is colored white
The grass is colored green
The cream is colored white
The cauliflower is colored white
The leaves is colored green
The coffee is colored
2024-07-27 00:14:18 root INFO     [order_1_approx] starting weight calculation for The coffee is colored black
The fridge is colored white
The cauliflower is colored white
The cream is colored white
The grass is colored green
The leaves is colored green
The toothpaste is colored white
The yoghurt is colored
2024-07-27 00:14:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 00:17:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0461, -0.1514,  0.0276,  ...,  0.0767, -0.4058, -0.0184],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2510, -5.2539,  0.8384,  ..., -2.8281, -1.7754, -1.8496],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0159,  0.0055,  0.0294,  ..., -0.0132,  0.0011,  0.0039],
        [ 0.0055,  0.0240,  0.0035,  ..., -0.0237, -0.0013,  0.0253],
        [-0.0130, -0.0050,  0.0142,  ...,  0.0115,  0.0063, -0.0008],
        ...,
        [ 0.0149,  0.0025,  0.0006,  ...,  0.0094,  0.0018,  0.0076],
        [ 0.0033, -0.0017, -0.0059,  ...,  0.0263,  0.0191, -0.0290],
        [-0.0078, -0.0316, -0.0009,  ..., -0.0197,  0.0065,  0.0498]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3379, -5.4531,  0.7866,  ..., -2.8613, -1.6748, -1.7324]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 00:17:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The coffee is colored black
The fridge is colored white
The cauliflower is colored white
The cream is colored white
The grass is colored green
The leaves is colored green
The toothpaste is colored white
The yoghurt is colored
2024-07-27 00:17:02 root INFO     [order_1_approx] starting weight calculation for The coffee is colored black
The fridge is colored white
The yoghurt is colored white
The toothpaste is colored white
The grass is colored green
The cream is colored white
The cauliflower is colored white
The leaves is colored
2024-07-27 00:17:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 00:19:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0759,  0.0093, -0.1019,  ..., -0.1809,  0.2350, -0.2349],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3921, -6.3203,  0.2156,  ..., -0.5957, -0.8481, -2.7773],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0379,  0.0204, -0.0143,  ..., -0.0063, -0.0083, -0.0032],
        [ 0.0204,  0.0305,  0.0044,  ..., -0.0259, -0.0099, -0.0013],
        [ 0.0075, -0.0026,  0.0239,  ..., -0.0031, -0.0281,  0.0157],
        ...,
        [ 0.0282, -0.0032,  0.0015,  ..., -0.0118,  0.0046,  0.0106],
        [ 0.0049,  0.0009,  0.0090,  ...,  0.0087,  0.0152,  0.0033],
        [-0.0160,  0.0094,  0.0062,  ..., -0.0211,  0.0033,  0.0163]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0115, -6.4180,  0.2566,  ..., -0.5713, -1.1494, -3.0625]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 00:19:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The coffee is colored black
The fridge is colored white
The yoghurt is colored white
The toothpaste is colored white
The grass is colored green
The cream is colored white
The cauliflower is colored white
The leaves is colored
2024-07-27 00:19:46 root INFO     [order_1_approx] starting weight calculation for The toothpaste is colored white
The grass is colored green
The cauliflower is colored white
The cream is colored white
The coffee is colored black
The leaves is colored green
The yoghurt is colored white
The fridge is colored
2024-07-27 00:19:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 00:22:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0265, -0.0074, -0.0278,  ...,  0.0236, -0.4019,  0.0557],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1926, -9.0000,  0.1790,  ..., -0.5757, -3.2930, -1.2070],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.2561e-02,  8.8501e-03,  7.0343e-03,  ..., -5.7526e-03,
         -3.8528e-03,  3.8696e-02],
        [ 1.0040e-02,  1.4153e-02, -4.2572e-03,  ..., -8.8348e-03,
         -4.0588e-03, -6.5384e-03],
        [ 9.8724e-03,  1.2863e-02,  8.5678e-03,  ...,  1.7281e-03,
         -3.1769e-02, -9.7733e-03],
        ...,
        [-1.6727e-03, -9.2850e-03, -4.6310e-03,  ...,  2.4841e-02,
          2.2469e-03, -6.9847e-03],
        [ 1.0689e-02, -5.8823e-03,  2.1149e-02,  ...,  3.1471e-03,
          2.7161e-02, -1.2589e-02],
        [-1.0170e-02, -1.6312e-02, -7.0810e-05,  ..., -1.1017e-02,
          1.5610e-02,  2.0096e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2405, -9.2422,  0.3391,  ..., -0.9766, -3.1621, -1.2109]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 00:22:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The toothpaste is colored white
The grass is colored green
The cauliflower is colored white
The cream is colored white
The coffee is colored black
The leaves is colored green
The yoghurt is colored white
The fridge is colored
2024-07-27 00:22:28 root INFO     [order_1_approx] starting weight calculation for The yoghurt is colored white
The fridge is colored white
The cream is colored white
The grass is colored green
The leaves is colored green
The coffee is colored black
The toothpaste is colored white
The cauliflower is colored
2024-07-27 00:22:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 00:25:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1183, -0.2207, -0.3086,  ..., -0.0549, -0.4355,  0.1240],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0264e+00, -6.1016e+00,  1.4531e+00,  ..., -2.3789e+00,
         1.2207e-03,  3.2715e-01], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0461,  0.0009,  0.0106,  ..., -0.0331, -0.0039,  0.0451],
        [ 0.0373,  0.0008, -0.0094,  ..., -0.0237, -0.0153,  0.0222],
        [-0.0486,  0.0051,  0.0194,  ...,  0.0092, -0.0111, -0.0101],
        ...,
        [ 0.0117, -0.0313, -0.0101,  ...,  0.0432, -0.0144,  0.0451],
        [-0.0275,  0.0050,  0.0055,  ...,  0.0254,  0.0168, -0.0206],
        [-0.0248, -0.0043,  0.0128,  ...,  0.0026,  0.0012,  0.0310]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5112, -6.0547,  1.2939,  ..., -2.3066, -0.1766,  0.1758]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 00:25:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The yoghurt is colored white
The fridge is colored white
The cream is colored white
The grass is colored green
The leaves is colored green
The coffee is colored black
The toothpaste is colored white
The cauliflower is colored
2024-07-27 00:25:11 root INFO     total operator prediction time: 1312.2502558231354 seconds
2024-07-27 00:25:11 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - sound
2024-07-27 00:25:11 root INFO     building operator animal - sound
2024-07-27 00:25:11 root INFO     [order_1_approx] starting weight calculation for The sound that a mouse makes is called a squeak
The sound that a duck makes is called a quack
The sound that a goat makes is called a bleat
The sound that a gorilla makes is called a grunt
The sound that a monkey makes is called a chatter
The sound that a hornet makes is called a buzz
The sound that a rat makes is called a squeak
The sound that a chimpanzee makes is called a
2024-07-27 00:25:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 00:27:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1635, -0.1218, -0.0112,  ..., -0.1541, -0.3591,  0.2903],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9805, -1.9062,  1.7939,  ..., -0.1875, -1.9609,  1.3398],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0016,  0.0023,  0.0023,  ..., -0.0023, -0.0110,  0.0031],
        [-0.0049,  0.0082,  0.0079,  ...,  0.0088,  0.0015, -0.0084],
        [-0.0001, -0.0018,  0.0011,  ..., -0.0104,  0.0033, -0.0132],
        ...,
        [-0.0004,  0.0085,  0.0045,  ...,  0.0131,  0.0046,  0.0013],
        [ 0.0018, -0.0118, -0.0046,  ...,  0.0032,  0.0074,  0.0156],
        [-0.0031, -0.0014, -0.0011,  ..., -0.0020,  0.0008, -0.0004]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9766, -2.0156,  1.6357,  ..., -0.1862, -1.8760,  1.2754]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 00:27:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a mouse makes is called a squeak
The sound that a duck makes is called a quack
The sound that a goat makes is called a bleat
The sound that a gorilla makes is called a grunt
The sound that a monkey makes is called a chatter
The sound that a hornet makes is called a buzz
The sound that a rat makes is called a squeak
The sound that a chimpanzee makes is called a
2024-07-27 00:27:52 root INFO     [order_1_approx] starting weight calculation for The sound that a rat makes is called a squeak
The sound that a monkey makes is called a chatter
The sound that a mouse makes is called a squeak
The sound that a gorilla makes is called a grunt
The sound that a chimpanzee makes is called a scream
The sound that a duck makes is called a quack
The sound that a hornet makes is called a buzz
The sound that a goat makes is called a
2024-07-27 00:27:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 00:30:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0509, -0.2666, -0.0361,  ..., -0.2484, -0.1648,  0.2539],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7979, -3.0547,  3.8457,  ..., -0.8418, -0.5396,  0.9121],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0523,  0.0208, -0.0140,  ...,  0.0042, -0.0249,  0.0082],
        [-0.0129,  0.0496, -0.0035,  ..., -0.0268, -0.0227,  0.0089],
        [-0.0055, -0.0153,  0.0294,  ..., -0.0139,  0.0236,  0.0283],
        ...,
        [-0.0224,  0.0311, -0.0142,  ...,  0.0325, -0.0158, -0.0117],
        [-0.0115,  0.0093, -0.0180,  ...,  0.0006,  0.0126, -0.0260],
        [ 0.0178, -0.0247,  0.0142,  ..., -0.0115,  0.0147,  0.0078]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6230, -2.9941,  3.6289,  ..., -0.5708, -0.6494,  0.6387]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 00:30:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a rat makes is called a squeak
The sound that a monkey makes is called a chatter
The sound that a mouse makes is called a squeak
The sound that a gorilla makes is called a grunt
The sound that a chimpanzee makes is called a scream
The sound that a duck makes is called a quack
The sound that a hornet makes is called a buzz
The sound that a goat makes is called a
2024-07-27 00:30:35 root INFO     [order_1_approx] starting weight calculation for The sound that a chimpanzee makes is called a scream
The sound that a hornet makes is called a buzz
The sound that a gorilla makes is called a grunt
The sound that a mouse makes is called a squeak
The sound that a goat makes is called a bleat
The sound that a monkey makes is called a chatter
The sound that a rat makes is called a squeak
The sound that a duck makes is called a
2024-07-27 00:30:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 00:33:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0738,  0.1189,  0.2405,  ..., -0.1088, -0.1042,  0.0233],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1680, -3.2852,  3.7266,  ...,  0.5654, -3.4766,  3.1875],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0485,  0.0013, -0.0122,  ...,  0.0191, -0.0162, -0.0026],
        [ 0.0119,  0.0356,  0.0056,  ..., -0.0141, -0.0352, -0.0168],
        [ 0.0062, -0.0203,  0.0430,  ..., -0.0191, -0.0019,  0.0104],
        ...,
        [-0.0160,  0.0331, -0.0457,  ...,  0.0485, -0.0308,  0.0007],
        [-0.0018,  0.0010,  0.0151,  ..., -0.0002,  0.0234, -0.0194],
        [ 0.0063,  0.0062,  0.0149,  ..., -0.0372,  0.0077, -0.0013]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0518, -3.0625,  3.6211,  ...,  0.9570, -3.6094,  2.9004]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 00:33:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a chimpanzee makes is called a scream
The sound that a hornet makes is called a buzz
The sound that a gorilla makes is called a grunt
The sound that a mouse makes is called a squeak
The sound that a goat makes is called a bleat
The sound that a monkey makes is called a chatter
The sound that a rat makes is called a squeak
The sound that a duck makes is called a
2024-07-27 00:33:21 root INFO     [order_1_approx] starting weight calculation for The sound that a rat makes is called a squeak
The sound that a monkey makes is called a chatter
The sound that a gorilla makes is called a grunt
The sound that a goat makes is called a bleat
The sound that a duck makes is called a quack
The sound that a chimpanzee makes is called a scream
The sound that a mouse makes is called a squeak
The sound that a hornet makes is called a
2024-07-27 00:33:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 00:36:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0848,  0.0441,  0.1394,  ...,  0.0859, -0.0490,  0.1523],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9980, -1.4229,  3.1055,  ..., -0.5059, -1.0977,  2.7812],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0718, -0.0010,  0.0031,  ..., -0.0282, -0.0238,  0.0108],
        [-0.0252,  0.0254, -0.0289,  ...,  0.0183, -0.0296, -0.0260],
        [ 0.0050,  0.0423,  0.0431,  ..., -0.0056, -0.0101, -0.0038],
        ...,
        [-0.0276,  0.0258,  0.0126,  ...,  0.0381, -0.0354, -0.0358],
        [ 0.0128,  0.0061, -0.0022,  ..., -0.0136,  0.0035, -0.0133],
        [-0.0041,  0.0104, -0.0064,  ..., -0.0244, -0.0172,  0.0306]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6035, -1.0938,  2.8594,  ..., -0.8711, -1.4209,  2.9336]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 00:36:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a rat makes is called a squeak
The sound that a monkey makes is called a chatter
The sound that a gorilla makes is called a grunt
The sound that a goat makes is called a bleat
The sound that a duck makes is called a quack
The sound that a chimpanzee makes is called a scream
The sound that a mouse makes is called a squeak
The sound that a hornet makes is called a
2024-07-27 00:36:03 root INFO     [order_1_approx] starting weight calculation for The sound that a monkey makes is called a chatter
The sound that a chimpanzee makes is called a scream
The sound that a goat makes is called a bleat
The sound that a gorilla makes is called a grunt
The sound that a hornet makes is called a buzz
The sound that a duck makes is called a quack
The sound that a mouse makes is called a squeak
The sound that a rat makes is called a
2024-07-27 00:36:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 00:38:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2021, -0.0645, -0.0082,  ..., -0.3845, -0.1670,  0.1448],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8965, -0.4905,  1.6387,  ..., -1.6641, -0.2393,  2.6211],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0437,  0.0014, -0.0089,  ..., -0.0015, -0.0348, -0.0191],
        [ 0.0210,  0.0392,  0.0194,  ...,  0.0068, -0.0237, -0.0370],
        [-0.0087, -0.0110,  0.0517,  ..., -0.0578,  0.0125, -0.0243],
        ...,
        [-0.0070,  0.0052,  0.0021,  ...,  0.0312, -0.0252,  0.0016],
        [ 0.0080, -0.0120,  0.0118,  ...,  0.0260,  0.0202,  0.0160],
        [-0.0007, -0.0017, -0.0238,  ..., -0.0281, -0.0089,  0.0227]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8145, -0.8569,  1.7881,  ..., -2.3633, -0.0829,  2.6777]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 00:38:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a monkey makes is called a chatter
The sound that a chimpanzee makes is called a scream
The sound that a goat makes is called a bleat
The sound that a gorilla makes is called a grunt
The sound that a hornet makes is called a buzz
The sound that a duck makes is called a quack
The sound that a mouse makes is called a squeak
The sound that a rat makes is called a
2024-07-27 00:38:45 root INFO     [order_1_approx] starting weight calculation for The sound that a duck makes is called a quack
The sound that a gorilla makes is called a grunt
The sound that a goat makes is called a bleat
The sound that a hornet makes is called a buzz
The sound that a rat makes is called a squeak
The sound that a chimpanzee makes is called a scream
The sound that a monkey makes is called a chatter
The sound that a mouse makes is called a
2024-07-27 00:38:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 00:41:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4014, -0.0535,  0.0805,  ..., -0.0698, -0.2212, -0.1259],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6201,  0.2223,  2.2891,  ..., -1.6865, -1.1338,  2.6211],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0174,  0.0153,  0.0328,  ..., -0.0062, -0.0512,  0.0063],
        [ 0.0226,  0.0474,  0.0066,  ...,  0.0210,  0.0223, -0.0369],
        [-0.0025, -0.0110,  0.0543,  ..., -0.0326,  0.0108, -0.0184],
        ...,
        [ 0.0065,  0.0068, -0.0130,  ...,  0.0630,  0.0070, -0.0204],
        [ 0.0285, -0.0029,  0.0011,  ..., -0.0120,  0.0037,  0.0051],
        [-0.0071,  0.0155, -0.0242,  ..., -0.0083, -0.0124,  0.0075]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4619, -0.2015,  1.9805,  ..., -1.8789, -1.1494,  2.5098]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 00:41:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a duck makes is called a quack
The sound that a gorilla makes is called a grunt
The sound that a goat makes is called a bleat
The sound that a hornet makes is called a buzz
The sound that a rat makes is called a squeak
The sound that a chimpanzee makes is called a scream
The sound that a monkey makes is called a chatter
The sound that a mouse makes is called a
2024-07-27 00:41:32 root INFO     [order_1_approx] starting weight calculation for The sound that a chimpanzee makes is called a scream
The sound that a gorilla makes is called a grunt
The sound that a rat makes is called a squeak
The sound that a duck makes is called a quack
The sound that a goat makes is called a bleat
The sound that a mouse makes is called a squeak
The sound that a hornet makes is called a buzz
The sound that a monkey makes is called a
2024-07-27 00:41:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 00:44:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0575, -0.1743,  0.0388,  ..., -0.0247, -0.4299,  0.2097],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8711, -2.9570,  2.6016,  ..., -1.2529, -2.3477,  1.5449],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0363,  0.0103,  0.0124,  ...,  0.0025, -0.0231,  0.0206],
        [ 0.0213,  0.0487, -0.0414,  ...,  0.0037, -0.0243, -0.0116],
        [-0.0274,  0.0219,  0.0139,  ..., -0.0330,  0.0037, -0.0076],
        ...,
        [-0.0077,  0.0198, -0.0094,  ...,  0.0348, -0.0005,  0.0055],
        [ 0.0117, -0.0253,  0.0160,  ...,  0.0054,  0.0124,  0.0004],
        [-0.0342, -0.0030, -0.0134,  ..., -0.0213, -0.0103,  0.0176]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5059, -2.6992,  2.2520,  ..., -1.4463, -2.2168,  1.5410]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 00:44:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a chimpanzee makes is called a scream
The sound that a gorilla makes is called a grunt
The sound that a rat makes is called a squeak
The sound that a duck makes is called a quack
The sound that a goat makes is called a bleat
The sound that a mouse makes is called a squeak
The sound that a hornet makes is called a buzz
The sound that a monkey makes is called a
2024-07-27 00:44:16 root INFO     [order_1_approx] starting weight calculation for The sound that a chimpanzee makes is called a scream
The sound that a rat makes is called a squeak
The sound that a monkey makes is called a chatter
The sound that a goat makes is called a bleat
The sound that a mouse makes is called a squeak
The sound that a duck makes is called a quack
The sound that a hornet makes is called a buzz
The sound that a gorilla makes is called a
2024-07-27 00:44:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 00:47:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0875, -0.2419, -0.0549,  ..., -0.2262, -0.4019,  0.2605],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.7695, -5.2969,  1.5586,  ...,  0.0273, -0.4917,  0.6406],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0165,  0.0147, -0.0010,  ...,  0.0018, -0.0241,  0.0066],
        [ 0.0160,  0.0246,  0.0025,  ...,  0.0062, -0.0105,  0.0012],
        [ 0.0048,  0.0063,  0.0113,  ..., -0.0228,  0.0185, -0.0273],
        ...,
        [-0.0003,  0.0400, -0.0232,  ...,  0.0254, -0.0213,  0.0051],
        [-0.0045, -0.0248, -0.0067,  ...,  0.0205,  0.0201, -0.0142],
        [-0.0042, -0.0119, -0.0106,  ..., -0.0159, -0.0009,  0.0100]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.5859, -5.0625,  1.3906,  ...,  0.1404, -0.6787,  0.2781]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 00:47:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a chimpanzee makes is called a scream
The sound that a rat makes is called a squeak
The sound that a monkey makes is called a chatter
The sound that a goat makes is called a bleat
The sound that a mouse makes is called a squeak
The sound that a duck makes is called a quack
The sound that a hornet makes is called a buzz
The sound that a gorilla makes is called a
2024-07-27 00:47:02 root INFO     total operator prediction time: 1310.9247558116913 seconds
2024-07-27 00:47:02 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - youth
2024-07-27 00:47:02 root INFO     building operator animal - youth
2024-07-27 00:47:02 root INFO     [order_1_approx] starting weight calculation for The offspring of a wolf is referred to as a cub
The offspring of a fox is referred to as a cub
The offspring of a trout is referred to as a fingerling
The offspring of a cicada is referred to as a nymph
The offspring of a fish is referred to as a fingerling
The offspring of a camel is referred to as a calf
The offspring of a tiger is referred to as a cub
The offspring of a goldfish is referred to as a
2024-07-27 00:47:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 00:49:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1611,  0.1070, -0.2561,  ..., -0.0427, -0.1515,  0.2488],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6660, -2.6680, -4.6172,  ..., -0.0713, -5.0000,  0.4600],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0632,  0.0004, -0.0262,  ..., -0.0074, -0.0591,  0.0062],
        [ 0.0091,  0.0643, -0.0215,  ..., -0.0090,  0.0267, -0.0144],
        [ 0.0255,  0.0079,  0.0497,  ...,  0.0018,  0.0186, -0.0019],
        ...,
        [-0.0031,  0.0116, -0.0324,  ..., -0.0018,  0.0158, -0.0032],
        [ 0.0061,  0.0283, -0.0006,  ..., -0.0059,  0.0197, -0.0165],
        [-0.0043,  0.0146, -0.0036,  ...,  0.0142, -0.0061,  0.0299]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5137, -2.6660, -4.2539,  ...,  0.8081, -4.3281, -0.2441]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 00:49:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a wolf is referred to as a cub
The offspring of a fox is referred to as a cub
The offspring of a trout is referred to as a fingerling
The offspring of a cicada is referred to as a nymph
The offspring of a fish is referred to as a fingerling
The offspring of a camel is referred to as a calf
The offspring of a tiger is referred to as a cub
The offspring of a goldfish is referred to as a
2024-07-27 00:49:45 root INFO     [order_1_approx] starting weight calculation for The offspring of a fox is referred to as a cub
The offspring of a wolf is referred to as a cub
The offspring of a trout is referred to as a fingerling
The offspring of a goldfish is referred to as a fingerling
The offspring of a fish is referred to as a fingerling
The offspring of a cicada is referred to as a nymph
The offspring of a camel is referred to as a calf
The offspring of a tiger is referred to as a
2024-07-27 00:49:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 00:52:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0617,  0.1719, -0.2256,  ..., -0.0212, -0.0350, -0.0074],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3809, -4.8477, -1.9512,  ...,  0.3999, -1.7852,  1.1309],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0303, -0.0250, -0.0065,  ..., -0.0003, -0.0297, -0.0146],
        [-0.0172,  0.0230, -0.0316,  ...,  0.0181, -0.0349, -0.0257],
        [ 0.0133, -0.0123,  0.0420,  ..., -0.0047,  0.0281,  0.0258],
        ...,
        [ 0.0042,  0.0065,  0.0052,  ...,  0.0143,  0.0118, -0.0041],
        [ 0.0155, -0.0185,  0.0154,  ...,  0.0397, -0.0121,  0.0210],
        [ 0.0130,  0.0138, -0.0047,  ..., -0.0053,  0.0046,  0.0164]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1289, -4.0391, -1.4805,  ...,  0.7539, -1.4326,  0.8506]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 00:52:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a fox is referred to as a cub
The offspring of a wolf is referred to as a cub
The offspring of a trout is referred to as a fingerling
The offspring of a goldfish is referred to as a fingerling
The offspring of a fish is referred to as a fingerling
The offspring of a cicada is referred to as a nymph
The offspring of a camel is referred to as a calf
The offspring of a tiger is referred to as a
2024-07-27 00:52:28 root INFO     [order_1_approx] starting weight calculation for The offspring of a fish is referred to as a fingerling
The offspring of a fox is referred to as a cub
The offspring of a camel is referred to as a calf
The offspring of a wolf is referred to as a cub
The offspring of a tiger is referred to as a cub
The offspring of a trout is referred to as a fingerling
The offspring of a goldfish is referred to as a fingerling
The offspring of a cicada is referred to as a
2024-07-27 00:52:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 00:55:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1481,  0.1416, -0.2000,  ..., -0.2529, -0.1105, -0.0078],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2627, -2.5508, -0.5171,  ..., -1.2285, -2.6562,  2.2676],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0531, -0.0297,  0.0161,  ..., -0.0079, -0.0101,  0.0170],
        [-0.0045,  0.0262, -0.0075,  ...,  0.0153,  0.0075, -0.0205],
        [-0.0184,  0.0174,  0.0605,  ...,  0.0301, -0.0025,  0.0124],
        ...,
        [-0.0050, -0.0017, -0.0013,  ...,  0.0211,  0.0211, -0.0111],
        [-0.0483,  0.0096, -0.0311,  ...,  0.0234,  0.0344, -0.0145],
        [ 0.0221,  0.0002, -0.0059,  ..., -0.0057, -0.0056,  0.0263]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2133, -2.6719, -0.8154,  ..., -0.7202, -2.5098,  2.4434]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 00:55:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a fish is referred to as a fingerling
The offspring of a fox is referred to as a cub
The offspring of a camel is referred to as a calf
The offspring of a wolf is referred to as a cub
The offspring of a tiger is referred to as a cub
The offspring of a trout is referred to as a fingerling
The offspring of a goldfish is referred to as a fingerling
The offspring of a cicada is referred to as a
2024-07-27 00:55:15 root INFO     [order_1_approx] starting weight calculation for The offspring of a cicada is referred to as a nymph
The offspring of a camel is referred to as a calf
The offspring of a goldfish is referred to as a fingerling
The offspring of a fox is referred to as a cub
The offspring of a tiger is referred to as a cub
The offspring of a fish is referred to as a fingerling
The offspring of a trout is referred to as a fingerling
The offspring of a wolf is referred to as a
2024-07-27 00:55:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 00:58:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1331,  0.0887, -0.1302,  ..., -0.0459, -0.0573, -0.0402],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0469, -5.5508, -2.3047,  ..., -0.0566, -3.5879,  2.5156],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0250, -0.0263, -0.0221,  ...,  0.0078, -0.0245,  0.0003],
        [-0.0165,  0.0398, -0.0128,  ..., -0.0038, -0.0110,  0.0128],
        [ 0.0249, -0.0236,  0.0334,  ..., -0.0109, -0.0030, -0.0134],
        ...,
        [-0.0076,  0.0209, -0.0123,  ...,  0.0099,  0.0177, -0.0132],
        [-0.0027, -0.0228,  0.0376,  ...,  0.0279, -0.0143,  0.0112],
        [-0.0060,  0.0014,  0.0045,  ...,  0.0146, -0.0223, -0.0007]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0586, -4.4102, -1.7285,  ...,  0.2917, -3.1914,  2.0938]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 00:58:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a cicada is referred to as a nymph
The offspring of a camel is referred to as a calf
The offspring of a goldfish is referred to as a fingerling
The offspring of a fox is referred to as a cub
The offspring of a tiger is referred to as a cub
The offspring of a fish is referred to as a fingerling
The offspring of a trout is referred to as a fingerling
The offspring of a wolf is referred to as a
2024-07-27 00:58:02 root INFO     [order_1_approx] starting weight calculation for The offspring of a tiger is referred to as a cub
The offspring of a wolf is referred to as a cub
The offspring of a fox is referred to as a cub
The offspring of a cicada is referred to as a nymph
The offspring of a goldfish is referred to as a fingerling
The offspring of a trout is referred to as a fingerling
The offspring of a fish is referred to as a fingerling
The offspring of a camel is referred to as a
2024-07-27 00:58:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 01:00:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0244, -0.0774, -0.2847,  ..., -0.3037, -0.0899,  0.4360],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5469, -1.9512, -0.4268,  ...,  0.7734, -3.9688,  0.7573],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0545, -0.0096, -0.0048,  ..., -0.0077, -0.0224,  0.0010],
        [-0.0155,  0.0120,  0.0185,  ...,  0.0025, -0.0168, -0.0447],
        [ 0.0251,  0.0175,  0.0360,  ..., -0.0173, -0.0135, -0.0089],
        ...,
        [ 0.0071,  0.0204, -0.0024,  ...,  0.0385,  0.0055, -0.0156],
        [ 0.0298, -0.0060,  0.0003,  ..., -0.0053, -0.0127,  0.0186],
        [ 0.0107,  0.0072, -0.0146,  ..., -0.0262,  0.0528,  0.0460]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0664, -1.0488, -0.5596,  ...,  0.9473, -3.8340,  0.6284]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 01:00:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a tiger is referred to as a cub
The offspring of a wolf is referred to as a cub
The offspring of a fox is referred to as a cub
The offspring of a cicada is referred to as a nymph
The offspring of a goldfish is referred to as a fingerling
The offspring of a trout is referred to as a fingerling
The offspring of a fish is referred to as a fingerling
The offspring of a camel is referred to as a
2024-07-27 01:00:46 root INFO     [order_1_approx] starting weight calculation for The offspring of a wolf is referred to as a cub
The offspring of a trout is referred to as a fingerling
The offspring of a goldfish is referred to as a fingerling
The offspring of a tiger is referred to as a cub
The offspring of a camel is referred to as a calf
The offspring of a cicada is referred to as a nymph
The offspring of a fox is referred to as a cub
The offspring of a fish is referred to as a
2024-07-27 01:00:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 01:03:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1774,  0.2356, -0.1709,  ..., -0.2468, -0.1545, -0.0800],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7402, -2.2988, -2.8320,  ..., -0.6953, -5.2031,  0.2188],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0335, -0.0031,  0.0178,  ...,  0.0120, -0.0232, -0.0042],
        [ 0.0039,  0.0398, -0.0149,  ..., -0.0117,  0.0063, -0.0112],
        [ 0.0219,  0.0005,  0.0248,  ..., -0.0059, -0.0096,  0.0068],
        ...,
        [-0.0129,  0.0058,  0.0033,  ...,  0.0163,  0.0127,  0.0084],
        [ 0.0014,  0.0236, -0.0133,  ..., -0.0282,  0.0049, -0.0204],
        [-0.0003, -0.0145, -0.0090,  ..., -0.0031,  0.0063,  0.0177]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4502, -2.4121, -2.8945,  ..., -0.6431, -4.8750,  0.8223]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 01:03:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a wolf is referred to as a cub
The offspring of a trout is referred to as a fingerling
The offspring of a goldfish is referred to as a fingerling
The offspring of a tiger is referred to as a cub
The offspring of a camel is referred to as a calf
The offspring of a cicada is referred to as a nymph
The offspring of a fox is referred to as a cub
The offspring of a fish is referred to as a
2024-07-27 01:03:27 root INFO     [order_1_approx] starting weight calculation for The offspring of a trout is referred to as a fingerling
The offspring of a goldfish is referred to as a fingerling
The offspring of a camel is referred to as a calf
The offspring of a wolf is referred to as a cub
The offspring of a fish is referred to as a fingerling
The offspring of a cicada is referred to as a nymph
The offspring of a tiger is referred to as a cub
The offspring of a fox is referred to as a
2024-07-27 01:03:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 01:06:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2413,  0.1428, -0.1490,  ..., -0.0797,  0.0873, -0.1434],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4512, -2.9961, -2.5547,  ...,  1.0771, -2.7637,  3.2559],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0320, -0.0136, -0.0108,  ...,  0.0133, -0.0151,  0.0003],
        [-0.0343,  0.0396, -0.0029,  ...,  0.0117, -0.0235, -0.0215],
        [ 0.0305, -0.0151,  0.0079,  ..., -0.0127, -0.0089, -0.0072],
        ...,
        [-0.0045,  0.0062,  0.0092,  ...,  0.0063,  0.0406, -0.0273],
        [ 0.0051, -0.0029,  0.0314,  ...,  0.0195, -0.0006,  0.0035],
        [-0.0091, -0.0162,  0.0100,  ..., -0.0130,  0.0028,  0.0022]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9805, -2.7480, -2.3789,  ...,  1.5381, -2.7520,  2.9199]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 01:06:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a trout is referred to as a fingerling
The offspring of a goldfish is referred to as a fingerling
The offspring of a camel is referred to as a calf
The offspring of a wolf is referred to as a cub
The offspring of a fish is referred to as a fingerling
The offspring of a cicada is referred to as a nymph
The offspring of a tiger is referred to as a cub
The offspring of a fox is referred to as a
2024-07-27 01:06:14 root INFO     [order_1_approx] starting weight calculation for The offspring of a tiger is referred to as a cub
The offspring of a cicada is referred to as a nymph
The offspring of a fish is referred to as a fingerling
The offspring of a wolf is referred to as a cub
The offspring of a fox is referred to as a cub
The offspring of a camel is referred to as a calf
The offspring of a goldfish is referred to as a fingerling
The offspring of a trout is referred to as a
2024-07-27 01:06:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 01:08:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3010,  0.2766, -0.2456,  ...,  0.0829, -0.2109, -0.0613],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2148, -1.7217, -5.2695,  ...,  2.2090, -3.1016, -1.0938],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0479, -0.0205,  0.0058,  ...,  0.0117, -0.0327, -0.0121],
        [ 0.0399,  0.0677,  0.0060,  ...,  0.0107, -0.0158, -0.0143],
        [ 0.0420, -0.0236,  0.0283,  ..., -0.0015,  0.0222, -0.0047],
        ...,
        [-0.0069,  0.0004, -0.0083,  ...,  0.0457,  0.0076,  0.0164],
        [ 0.0184,  0.0191,  0.0101,  ...,  0.0389,  0.0361, -0.0231],
        [-0.0234,  0.0122, -0.0090,  ..., -0.0071, -0.0122, -0.0021]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6997, -1.1484, -5.1094,  ...,  2.3438, -2.2988, -0.9790]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 01:08:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a tiger is referred to as a cub
The offspring of a cicada is referred to as a nymph
The offspring of a fish is referred to as a fingerling
The offspring of a wolf is referred to as a cub
The offspring of a fox is referred to as a cub
The offspring of a camel is referred to as a calf
The offspring of a goldfish is referred to as a fingerling
The offspring of a trout is referred to as a
2024-07-27 01:08:56 root INFO     total operator prediction time: 1314.2556397914886 seconds
2024-07-27 01:08:56 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on synonyms - exact
2024-07-27 01:08:56 root INFO     building operator synonyms - exact
2024-07-27 01:08:56 root INFO     [order_1_approx] starting weight calculation for Another word for child is kid
Another word for reasonable is sensible
Another word for help is aid
Another word for snake is serpent
Another word for intelligent is clever
Another word for honest is sincere
Another word for airplane is aeroplane
Another word for mend is
2024-07-27 01:08:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 01:11:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2559,  0.2393, -0.1222,  ..., -0.1031, -0.2981,  0.2256],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6836, -6.4141,  1.4033,  ...,  2.9688, -5.7812,  0.3516],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0190, -0.0697,  0.0469,  ..., -0.0046, -0.0097, -0.0202],
        [ 0.0003,  0.0688,  0.0025,  ...,  0.0117,  0.0070,  0.0164],
        [-0.0210, -0.0334,  0.0153,  ..., -0.0129, -0.0084,  0.0030],
        ...,
        [ 0.0614,  0.0266,  0.0519,  ...,  0.0637,  0.0283, -0.0336],
        [ 0.0094,  0.0133,  0.0090,  ...,  0.0248,  0.0367, -0.0228],
        [ 0.0193, -0.0211, -0.0208,  ...,  0.0094, -0.0098,  0.0325]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9551e+00, -5.6797e+00,  1.4746e+00,  ...,  2.2930e+00,
         -5.2930e+00, -4.8828e-03]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SubBackward0>) 

                    
2024-07-27 01:11:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for child is kid
Another word for reasonable is sensible
Another word for help is aid
Another word for snake is serpent
Another word for intelligent is clever
Another word for honest is sincere
Another word for airplane is aeroplane
Another word for mend is
2024-07-27 01:11:41 root INFO     [order_1_approx] starting weight calculation for Another word for reasonable is sensible
Another word for child is kid
Another word for honest is sincere
Another word for intelligent is clever
Another word for mend is repair
Another word for snake is serpent
Another word for airplane is aeroplane
Another word for help is
2024-07-27 01:11:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 01:14:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0208, -0.1079,  0.0770,  ...,  0.1002, -0.1550,  0.1628],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.2656, -6.2305,  1.3877,  ...,  2.1855, -3.2734, -1.2227],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0454, -0.0116,  0.0193,  ...,  0.0034,  0.0182, -0.0105],
        [-0.0417,  0.0307,  0.0126,  ..., -0.0258,  0.0228, -0.0098],
        [-0.0062, -0.0037,  0.0030,  ...,  0.0209, -0.0173,  0.0130],
        ...,
        [ 0.0098,  0.0136, -0.0119,  ...,  0.0065,  0.0180,  0.0117],
        [ 0.0099,  0.0100, -0.0571,  ...,  0.0319,  0.0443, -0.0027],
        [-0.0042,  0.0055, -0.0190,  ..., -0.0366, -0.0091,  0.0358]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 6.0156, -5.5625,  1.5889,  ...,  2.1699, -3.9766, -1.8223]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 01:14:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for reasonable is sensible
Another word for child is kid
Another word for honest is sincere
Another word for intelligent is clever
Another word for mend is repair
Another word for snake is serpent
Another word for airplane is aeroplane
Another word for help is
2024-07-27 01:14:27 root INFO     [order_1_approx] starting weight calculation for Another word for airplane is aeroplane
Another word for intelligent is clever
Another word for snake is serpent
Another word for help is aid
Another word for reasonable is sensible
Another word for mend is repair
Another word for honest is sincere
Another word for child is
2024-07-27 01:14:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 01:17:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0583, -0.0853,  0.0367,  ..., -0.0786, -0.5229,  0.0472],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3828, -4.1016, -2.9531,  ...,  1.1211, -1.7988, -0.1787],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0488, -0.0342,  0.0238,  ...,  0.0253,  0.0099,  0.0174],
        [ 0.0056,  0.0382,  0.0131,  ..., -0.0144,  0.0234, -0.0072],
        [-0.0042, -0.0195,  0.0328,  ..., -0.0032,  0.0047, -0.0123],
        ...,
        [-0.0261,  0.0005,  0.0109,  ..., -0.0353, -0.0136,  0.0108],
        [-0.0005,  0.0279,  0.0024,  ...,  0.0028,  0.0488, -0.0496],
        [ 0.0015, -0.0191, -0.0017,  ..., -0.0357, -0.0288,  0.0455]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9922, -3.5215, -2.6914,  ...,  1.0869, -1.7803,  0.1987]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 01:17:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for airplane is aeroplane
Another word for intelligent is clever
Another word for snake is serpent
Another word for help is aid
Another word for reasonable is sensible
Another word for mend is repair
Another word for honest is sincere
Another word for child is
2024-07-27 01:17:13 root INFO     [order_1_approx] starting weight calculation for Another word for intelligent is clever
Another word for honest is sincere
Another word for child is kid
Another word for airplane is aeroplane
Another word for mend is repair
Another word for snake is serpent
Another word for help is aid
Another word for reasonable is
2024-07-27 01:17:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 01:19:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1017,  0.1914, -0.1321,  ..., -0.3145, -0.2722,  0.1837],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3086,  1.6875, -1.9521,  ..., -3.1055, -8.6406, -1.1914],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.2317e-02, -2.7222e-02,  1.8524e-02,  ..., -1.0567e-02,
         -1.5640e-03,  3.0807e-02],
        [-1.8250e-02,  2.6672e-02,  2.2308e-02,  ..., -1.3985e-02,
          3.6438e-02,  3.8574e-02],
        [ 2.6291e-02, -1.8753e-02,  5.4077e-02,  ...,  1.1307e-02,
         -2.4734e-02,  2.4521e-02],
        ...,
        [ 3.9886e-02,  3.2257e-02,  4.8492e-02,  ...,  6.0089e-02,
          2.8137e-02,  4.0932e-03],
        [ 2.5650e-02, -4.4937e-03,  6.8665e-05,  ..., -1.4694e-02,
          3.7575e-03, -4.7424e-02],
        [-5.5199e-03, -3.6526e-03,  3.7781e-02,  ..., -1.1505e-02,
         -2.2125e-02,  3.8788e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1582,  1.8789, -2.2695,  ..., -2.0176, -8.5312, -0.7178]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 01:20:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for intelligent is clever
Another word for honest is sincere
Another word for child is kid
Another word for airplane is aeroplane
Another word for mend is repair
Another word for snake is serpent
Another word for help is aid
Another word for reasonable is
2024-07-27 01:20:00 root INFO     [order_1_approx] starting weight calculation for Another word for child is kid
Another word for help is aid
Another word for snake is serpent
Another word for airplane is aeroplane
Another word for reasonable is sensible
Another word for mend is repair
Another word for honest is sincere
Another word for intelligent is
2024-07-27 01:20:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 01:22:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0665,  0.0917, -0.1331,  ..., -0.1584,  0.0159, -0.0526],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5967, -0.6084,  0.2236,  ...,  1.5850, -4.1094,  0.1792],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0367,  0.0004,  0.0037,  ..., -0.0094,  0.0235,  0.0045],
        [-0.0413,  0.0145,  0.0147,  ..., -0.0009,  0.0258,  0.0080],
        [ 0.0073, -0.0169,  0.0387,  ...,  0.0079,  0.0152, -0.0043],
        ...,
        [ 0.0049,  0.0188, -0.0185,  ...,  0.0184, -0.0086, -0.0247],
        [ 0.0053, -0.0034,  0.0233,  ..., -0.0055,  0.0029, -0.0076],
        [ 0.0008,  0.0022,  0.0203,  ..., -0.0109,  0.0095, -0.0035]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6689, -0.2996, -0.1174,  ...,  1.9121, -4.4023,  0.2837]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 01:22:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for child is kid
Another word for help is aid
Another word for snake is serpent
Another word for airplane is aeroplane
Another word for reasonable is sensible
Another word for mend is repair
Another word for honest is sincere
Another word for intelligent is
2024-07-27 01:22:46 root INFO     [order_1_approx] starting weight calculation for Another word for reasonable is sensible
Another word for help is aid
Another word for airplane is aeroplane
Another word for snake is serpent
Another word for mend is repair
Another word for intelligent is clever
Another word for child is kid
Another word for honest is
2024-07-27 01:22:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 01:25:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1475,  0.1648, -0.1589,  ...,  0.0840,  0.1115,  0.1467],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0938, -3.3203, -1.1865,  ...,  0.0742, -8.6328,  2.7520],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0395, -0.0167,  0.0253,  ..., -0.0430,  0.0182,  0.0146],
        [-0.0132,  0.0648,  0.0047,  ..., -0.0433,  0.0791, -0.0045],
        [-0.0165, -0.0320,  0.0552,  ..., -0.0018, -0.0424, -0.0067],
        ...,
        [ 0.0032, -0.0266,  0.0237,  ...,  0.0591, -0.0105, -0.0098],
        [-0.0172,  0.0036, -0.0118,  ..., -0.0015,  0.0382, -0.0289],
        [ 0.0237, -0.0356,  0.0196,  ..., -0.0244, -0.0110,  0.0508]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8555, -2.6387, -1.1963,  ...,  0.3257, -8.7969,  1.9121]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 01:25:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for reasonable is sensible
Another word for help is aid
Another word for airplane is aeroplane
Another word for snake is serpent
Another word for mend is repair
Another word for intelligent is clever
Another word for child is kid
Another word for honest is
2024-07-27 01:25:32 root INFO     [order_1_approx] starting weight calculation for Another word for honest is sincere
Another word for child is kid
Another word for reasonable is sensible
Another word for intelligent is clever
Another word for airplane is aeroplane
Another word for mend is repair
Another word for help is aid
Another word for snake is
2024-07-27 01:25:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 01:28:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1279,  0.2242, -0.0417,  ..., -0.1467, -0.0322,  0.1300],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.9160, -5.8750,  1.9238,  ..., -0.8125, -1.0762,  0.0645],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0276,  0.0055,  0.0340,  ...,  0.0088,  0.0473, -0.0007],
        [-0.0193,  0.0330,  0.0112,  ..., -0.0251, -0.0237, -0.0018],
        [-0.0144, -0.0048,  0.0986,  ..., -0.0344,  0.0017,  0.0178],
        ...,
        [ 0.0210,  0.0369, -0.0272,  ...,  0.0554,  0.0132, -0.0311],
        [ 0.0071,  0.0095,  0.0073,  ..., -0.0095,  0.0168, -0.0027],
        [ 0.0077,  0.0076, -0.0139,  ..., -0.0143, -0.0161,  0.0118]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7124, -5.6406,  1.4434,  ..., -0.6934, -1.2891, -0.0513]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 01:28:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for honest is sincere
Another word for child is kid
Another word for reasonable is sensible
Another word for intelligent is clever
Another word for airplane is aeroplane
Another word for mend is repair
Another word for help is aid
Another word for snake is
2024-07-27 01:28:17 root INFO     [order_1_approx] starting weight calculation for Another word for mend is repair
Another word for child is kid
Another word for snake is serpent
Another word for honest is sincere
Another word for help is aid
Another word for reasonable is sensible
Another word for intelligent is clever
Another word for airplane is
2024-07-27 01:28:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 01:31:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0756,  0.0228, -0.2371,  ...,  0.2137, -0.1704,  0.0743],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1216, -3.4414,  3.3047,  ..., -1.2930, -2.3008,  1.2744],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.0731e-02, -6.3629e-03,  8.2092e-03,  ...,  2.0615e-02,
          2.7252e-02,  4.1542e-03],
        [ 1.3504e-02,  5.5939e-02, -1.6159e-02,  ...,  1.1749e-02,
          6.4621e-03, -2.1400e-03],
        [-1.4236e-02, -4.1962e-04,  5.4718e-02,  ..., -2.0008e-03,
         -8.5144e-03,  2.5299e-02],
        ...,
        [ 7.2479e-05,  1.1139e-02, -9.6359e-03,  ...,  3.8757e-02,
         -9.3155e-03, -1.2024e-02],
        [-8.7585e-03, -2.1133e-02,  4.0932e-03,  ..., -1.0071e-02,
          2.7283e-02,  5.3253e-03],
        [ 1.6079e-03,  1.7471e-02,  1.2932e-02,  ..., -1.7548e-02,
          1.1574e-02,  2.0508e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0874, -3.3398,  3.1016,  ..., -1.4844, -2.5234,  1.2773]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 01:31:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for mend is repair
Another word for child is kid
Another word for snake is serpent
Another word for honest is sincere
Another word for help is aid
Another word for reasonable is sensible
Another word for intelligent is clever
Another word for airplane is
2024-07-27 01:31:02 root INFO     total operator prediction time: 1326.2315881252289 seconds
2024-07-27 01:31:02 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hypernyms - misc
2024-07-27 01:31:02 root INFO     building operator hypernyms - misc
2024-07-27 01:31:03 root INFO     [order_1_approx] starting weight calculation for The sunscreen falls into the category of cream
The peach falls into the category of fruit
The hairpin falls into the category of pin
The jeans falls into the category of trousers
The computer falls into the category of device
The juicer falls into the category of utensil
The toaster falls into the category of appliance
The diary falls into the category of
2024-07-27 01:31:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 01:33:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1586, -0.0480, -0.0959,  ..., -0.0740, -0.3389,  0.1780],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4734, -4.2266,  2.3008,  ..., -2.6016, -3.5938, -0.0801],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0217, -0.0137,  0.0131,  ...,  0.0044,  0.0260,  0.0128],
        [-0.0077,  0.0218, -0.0130,  ..., -0.0226, -0.0225,  0.0287],
        [-0.0113, -0.0407,  0.0119,  ...,  0.0367, -0.0154,  0.0111],
        ...,
        [-0.0011,  0.0196, -0.0115,  ...,  0.0555,  0.0059,  0.0118],
        [ 0.0009, -0.0104,  0.0174,  ...,  0.0165,  0.0340, -0.0016],
        [ 0.0038,  0.0025,  0.0128,  ..., -0.0474, -0.0078,  0.0500]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8892, -4.6602,  2.2207,  ..., -2.3633, -3.6797, -0.0486]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 01:33:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sunscreen falls into the category of cream
The peach falls into the category of fruit
The hairpin falls into the category of pin
The jeans falls into the category of trousers
The computer falls into the category of device
The juicer falls into the category of utensil
The toaster falls into the category of appliance
The diary falls into the category of
2024-07-27 01:33:46 root INFO     [order_1_approx] starting weight calculation for The hairpin falls into the category of pin
The toaster falls into the category of appliance
The computer falls into the category of device
The diary falls into the category of journal
The peach falls into the category of fruit
The jeans falls into the category of trousers
The juicer falls into the category of utensil
The sunscreen falls into the category of
2024-07-27 01:33:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 01:36:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4080, -0.3340, -0.1265,  ..., -0.0527,  0.1116, -0.2610],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5884, -0.4746,  2.2500,  ..., -1.6992, -1.5059,  1.2080],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0220, -0.0218, -0.0134,  ..., -0.0261,  0.0100,  0.0215],
        [ 0.0134,  0.0518, -0.0259,  ...,  0.0129, -0.0231, -0.0053],
        [ 0.0036,  0.0253,  0.0124,  ..., -0.0143, -0.0253,  0.0159],
        ...,
        [ 0.0247, -0.0091,  0.0102,  ...,  0.0645, -0.0226,  0.0140],
        [-0.0045,  0.0044,  0.0074,  ..., -0.0052,  0.0467, -0.0141],
        [-0.0083, -0.0285,  0.0066,  ...,  0.0161, -0.0127,  0.0538]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6890, -0.6138,  2.3867,  ..., -1.9883, -1.2324,  0.9492]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 01:36:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The hairpin falls into the category of pin
The toaster falls into the category of appliance
The computer falls into the category of device
The diary falls into the category of journal
The peach falls into the category of fruit
The jeans falls into the category of trousers
The juicer falls into the category of utensil
The sunscreen falls into the category of
2024-07-27 01:36:32 root INFO     [order_1_approx] starting weight calculation for The computer falls into the category of device
The sunscreen falls into the category of cream
The diary falls into the category of journal
The toaster falls into the category of appliance
The hairpin falls into the category of pin
The juicer falls into the category of utensil
The jeans falls into the category of trousers
The peach falls into the category of
2024-07-27 01:36:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 01:39:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2413, -0.0204, -0.3179,  ...,  0.2275, -0.0989, -0.1558],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1562, -6.5938,  0.5864,  ..., -1.8516, -1.0850, -3.0195],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0432,  0.0002, -0.0031,  ...,  0.0091,  0.0016, -0.0037],
        [ 0.0144,  0.0039,  0.0228,  ..., -0.0035, -0.0028,  0.0347],
        [-0.0237,  0.0391,  0.0249,  ...,  0.0007, -0.0436,  0.0047],
        ...,
        [ 0.0227, -0.0033,  0.0052,  ...,  0.0532,  0.0032,  0.0145],
        [-0.0056, -0.0053,  0.0005,  ...,  0.0167,  0.0240, -0.0269],
        [ 0.0066, -0.0475,  0.0195,  ..., -0.0314,  0.0134,  0.0537]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2637, -6.1875,  0.3433,  ..., -1.1963, -1.0859, -2.6250]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 01:39:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The computer falls into the category of device
The sunscreen falls into the category of cream
The diary falls into the category of journal
The toaster falls into the category of appliance
The hairpin falls into the category of pin
The juicer falls into the category of utensil
The jeans falls into the category of trousers
The peach falls into the category of
2024-07-27 01:39:13 root INFO     [order_1_approx] starting weight calculation for The peach falls into the category of fruit
The juicer falls into the category of utensil
The sunscreen falls into the category of cream
The diary falls into the category of journal
The toaster falls into the category of appliance
The jeans falls into the category of trousers
The computer falls into the category of device
The hairpin falls into the category of
2024-07-27 01:39:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 01:41:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0571, -0.2186, -0.2422,  ...,  0.0893,  0.0931, -0.2397],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2012, -3.8203, -2.2500,  ..., -1.0566, -4.8867,  1.9629],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0756,  0.0082, -0.0069,  ...,  0.0117, -0.0060,  0.0234],
        [-0.0224,  0.0167,  0.0056,  ..., -0.0316, -0.0156,  0.0143],
        [ 0.0142, -0.0034, -0.0043,  ...,  0.0171, -0.0077, -0.0080],
        ...,
        [-0.0085,  0.0021,  0.0346,  ...,  0.0243, -0.0169, -0.0160],
        [-0.0241,  0.0025, -0.0075,  ...,  0.0153,  0.0359,  0.0328],
        [-0.0193, -0.0090,  0.0191,  ..., -0.0446,  0.0205,  0.0498]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1406, -4.1172, -2.3613,  ..., -0.5029, -4.7500,  1.6211]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 01:41:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The peach falls into the category of fruit
The juicer falls into the category of utensil
The sunscreen falls into the category of cream
The diary falls into the category of journal
The toaster falls into the category of appliance
The jeans falls into the category of trousers
The computer falls into the category of device
The hairpin falls into the category of
2024-07-27 01:41:56 root INFO     [order_1_approx] starting weight calculation for The sunscreen falls into the category of cream
The diary falls into the category of journal
The toaster falls into the category of appliance
The hairpin falls into the category of pin
The computer falls into the category of device
The peach falls into the category of fruit
The juicer falls into the category of utensil
The jeans falls into the category of
2024-07-27 01:41:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 01:44:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2216, -0.2010, -0.2356,  ...,  0.4009, -0.2336, -0.0667],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1953, -7.2812, -0.8193,  ...,  1.3809, -3.2031, -0.1143],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0200,  0.0130, -0.0079,  ...,  0.0258,  0.0075, -0.0032],
        [ 0.0164, -0.0214, -0.0015,  ..., -0.0358, -0.0032,  0.0284],
        [ 0.0008, -0.0122, -0.0008,  ...,  0.0046, -0.0186, -0.0096],
        ...,
        [ 0.0111, -0.0191,  0.0086,  ...,  0.0336, -0.0063, -0.0010],
        [-0.0130, -0.0152,  0.0070,  ..., -0.0082,  0.0378, -0.0100],
        [ 0.0106, -0.0346,  0.0220,  ..., -0.0334, -0.0005,  0.0298]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7617, -6.8398, -0.8208,  ...,  1.3525, -2.9473,  0.7363]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 01:44:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sunscreen falls into the category of cream
The diary falls into the category of journal
The toaster falls into the category of appliance
The hairpin falls into the category of pin
The computer falls into the category of device
The peach falls into the category of fruit
The juicer falls into the category of utensil
The jeans falls into the category of
2024-07-27 01:44:35 root INFO     [order_1_approx] starting weight calculation for The sunscreen falls into the category of cream
The diary falls into the category of journal
The computer falls into the category of device
The hairpin falls into the category of pin
The toaster falls into the category of appliance
The jeans falls into the category of trousers
The peach falls into the category of fruit
The juicer falls into the category of
2024-07-27 01:44:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 01:47:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0627, -0.2445, -0.0960,  ..., -0.0271, -0.2014, -0.1812],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5576, -5.3008, -0.2073,  ..., -1.7783, -2.3438,  0.2969],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0181, -0.0059, -0.0159,  ...,  0.0056,  0.0021,  0.0283],
        [-0.0086,  0.0480,  0.0325,  ...,  0.0068, -0.0246, -0.0377],
        [ 0.0009, -0.0060,  0.0155,  ..., -0.0121, -0.0145, -0.0012],
        ...,
        [ 0.0150,  0.0012, -0.0012,  ...,  0.0260, -0.0190,  0.0117],
        [-0.0026, -0.0084,  0.0047,  ...,  0.0148,  0.0248, -0.0172],
        [-0.0047,  0.0049,  0.0129,  ..., -0.0111, -0.0009, -0.0093]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7559e+00, -5.3164e+00, -3.6621e-03,  ..., -1.9453e+00,
         -2.5254e+00,  3.7500e-01]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SubBackward0>) 

                    
2024-07-27 01:47:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sunscreen falls into the category of cream
The diary falls into the category of journal
The computer falls into the category of device
The hairpin falls into the category of pin
The toaster falls into the category of appliance
The jeans falls into the category of trousers
The peach falls into the category of fruit
The juicer falls into the category of
2024-07-27 01:47:17 root INFO     [order_1_approx] starting weight calculation for The computer falls into the category of device
The hairpin falls into the category of pin
The sunscreen falls into the category of cream
The peach falls into the category of fruit
The diary falls into the category of journal
The jeans falls into the category of trousers
The juicer falls into the category of utensil
The toaster falls into the category of
2024-07-27 01:47:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 01:50:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3984, -0.1105, -0.0511,  ..., -0.0878, -0.2355, -0.0437],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3809, -2.4902,  0.2847,  ...,  0.3408, -3.2617,  2.0605],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0717, -0.0030, -0.0286,  ..., -0.0278, -0.0244,  0.0129],
        [ 0.0132,  0.0682,  0.0342,  ...,  0.0058, -0.0013, -0.0028],
        [ 0.0443,  0.0022,  0.0085,  ..., -0.0360, -0.0311,  0.0055],
        ...,
        [-0.0088,  0.0058, -0.0030,  ...,  0.0530,  0.0005, -0.0201],
        [-0.0346, -0.0112,  0.0126,  ...,  0.0464,  0.0627, -0.0162],
        [ 0.0215, -0.0167,  0.0201,  ..., -0.0086, -0.0086,  0.0462]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4209, -2.8164,  0.8618,  ...,  0.3501, -3.0254,  1.7832]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 01:50:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The computer falls into the category of device
The hairpin falls into the category of pin
The sunscreen falls into the category of cream
The peach falls into the category of fruit
The diary falls into the category of journal
The jeans falls into the category of trousers
The juicer falls into the category of utensil
The toaster falls into the category of
2024-07-27 01:50:01 root INFO     [order_1_approx] starting weight calculation for The juicer falls into the category of utensil
The diary falls into the category of journal
The toaster falls into the category of appliance
The hairpin falls into the category of pin
The sunscreen falls into the category of cream
The peach falls into the category of fruit
The jeans falls into the category of trousers
The computer falls into the category of
2024-07-27 01:50:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 01:52:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1412, -0.1766,  0.1401,  ...,  0.1584, -0.2207, -0.0039],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6924, -4.8516, -0.5713,  ..., -1.9297, -2.3418, -2.0898],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.4800e-02, -2.1835e-02, -1.4328e-02,  ...,  4.1122e-03,
          9.4376e-03,  3.1525e-02],
        [ 2.0676e-02,  3.0548e-02,  7.0419e-03,  ..., -5.9967e-03,
         -2.7332e-03,  2.1805e-02],
        [ 1.5259e-05, -4.6539e-03,  3.4546e-02,  ..., -1.2924e-02,
         -9.7580e-03,  1.3283e-02],
        ...,
        [-1.8158e-03,  1.1551e-02, -9.0361e-05,  ...,  2.8595e-02,
          6.7863e-03, -8.1062e-04],
        [ 4.0550e-03, -3.0479e-03,  1.1032e-02,  ...,  1.5656e-02,
          3.6041e-02, -8.3923e-05],
        [ 1.4847e-02, -8.1024e-03, -1.2985e-02,  ..., -1.9760e-02,
          1.7151e-02,  5.0354e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2551, -4.5234, -0.8408,  ..., -1.9785, -1.5244, -1.6660]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 01:52:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The juicer falls into the category of utensil
The diary falls into the category of journal
The toaster falls into the category of appliance
The hairpin falls into the category of pin
The sunscreen falls into the category of cream
The peach falls into the category of fruit
The jeans falls into the category of trousers
The computer falls into the category of
2024-07-27 01:52:45 root INFO     total operator prediction time: 1302.0829465389252 seconds
2024-07-27 01:52:45 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - substance
2024-07-27 01:52:45 root INFO     building operator meronyms - substance
2024-07-27 01:52:45 root INFO     [order_1_approx] starting weight calculation for A money is made up of paper
A mirror is made up of glass
A desk is made up of wood
A ice is made up of water
A ocean is made up of water
A candy is made up of sugar
A concrete is made up of silicon
A wall is made up of
2024-07-27 01:52:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 01:55:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1692, -0.0038,  0.0663,  ...,  0.3892, -0.2690, -0.0668],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8086, -6.3672,  1.3809,  ..., -1.8994, -1.2061,  1.4531],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0011,  0.0161,  0.0210,  ..., -0.0111,  0.0026, -0.0538],
        [ 0.0238,  0.0177,  0.0022,  ..., -0.0295, -0.0106, -0.0007],
        [-0.0166,  0.0200,  0.0151,  ...,  0.0227,  0.0123, -0.0421],
        ...,
        [ 0.0098, -0.0231,  0.0212,  ...,  0.0304, -0.0143, -0.0557],
        [-0.0088,  0.0208, -0.0219,  ...,  0.0025,  0.0158, -0.0023],
        [ 0.0027, -0.0152,  0.0176,  ...,  0.0011,  0.0201,  0.0303]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9727, -6.1719,  1.4229,  ..., -1.5615, -1.5928,  1.5078]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 01:55:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A money is made up of paper
A mirror is made up of glass
A desk is made up of wood
A ice is made up of water
A ocean is made up of water
A candy is made up of sugar
A concrete is made up of silicon
A wall is made up of
2024-07-27 01:55:28 root INFO     [order_1_approx] starting weight calculation for A mirror is made up of glass
A candy is made up of sugar
A desk is made up of wood
A ocean is made up of water
A concrete is made up of silicon
A wall is made up of cement
A money is made up of paper
A ice is made up of
2024-07-27 01:55:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 01:58:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1188,  0.2396, -0.0359,  ..., -0.0122, -0.2279, -0.1175],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6406, -4.3047,  0.4849,  ..., -6.7969,  1.6914, -0.7075],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0389, -0.0306, -0.0078,  ..., -0.0071,  0.0067, -0.0179],
        [-0.0003,  0.0016, -0.0392,  ...,  0.0009, -0.0087, -0.0255],
        [ 0.0215, -0.0160,  0.0254,  ..., -0.0080,  0.0143, -0.0139],
        ...,
        [ 0.0193, -0.0230,  0.0171,  ...,  0.0470,  0.0038, -0.0166],
        [ 0.0001,  0.0008,  0.0067,  ...,  0.0119,  0.0002,  0.0101],
        [ 0.0180,  0.0013, -0.0072,  ...,  0.0008, -0.0207,  0.0414]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8516, -4.9531,  0.4714,  ..., -6.4336,  0.9810, -0.5640]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 01:58:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A mirror is made up of glass
A candy is made up of sugar
A desk is made up of wood
A ocean is made up of water
A concrete is made up of silicon
A wall is made up of cement
A money is made up of paper
A ice is made up of
2024-07-27 01:58:11 root INFO     [order_1_approx] starting weight calculation for A candy is made up of sugar
A ice is made up of water
A wall is made up of cement
A money is made up of paper
A ocean is made up of water
A concrete is made up of silicon
A mirror is made up of glass
A desk is made up of
2024-07-27 01:58:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 02:00:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2878, -0.0036, -0.3149,  ...,  0.2432, -0.5176, -0.0352],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.3164, -6.8008,  2.9297,  ..., -4.3750,  0.2798, -2.4102],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0031,  0.0041, -0.0167,  ...,  0.0252, -0.0184, -0.0337],
        [ 0.0052,  0.0377, -0.0075,  ..., -0.0037, -0.0087, -0.0025],
        [-0.0190,  0.0368,  0.0131,  ..., -0.0023, -0.0218, -0.0188],
        ...,
        [ 0.0190, -0.0299,  0.0310,  ...,  0.0018, -0.0169,  0.0254],
        [-0.0197,  0.0262, -0.0193,  ...,  0.0251,  0.0146, -0.0449],
        [ 0.0233, -0.0148,  0.0096,  ..., -0.0057,  0.0113,  0.0288]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0625, -6.7266,  2.5352,  ..., -4.3828,  0.0815, -2.3047]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 02:00:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A candy is made up of sugar
A ice is made up of water
A wall is made up of cement
A money is made up of paper
A ocean is made up of water
A concrete is made up of silicon
A mirror is made up of glass
A desk is made up of
2024-07-27 02:00:55 root INFO     [order_1_approx] starting weight calculation for A ocean is made up of water
A candy is made up of sugar
A mirror is made up of glass
A wall is made up of cement
A desk is made up of wood
A ice is made up of water
A money is made up of paper
A concrete is made up of
2024-07-27 02:00:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 02:03:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1229, -0.0206, -0.2346,  ...,  0.0167, -0.3223, -0.0126],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.0195, -6.9531, -1.3672,  ..., -2.7109,  1.5586,  0.0547],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0035, -0.0056, -0.0067,  ..., -0.0274, -0.0254, -0.0343],
        [ 0.0068,  0.0148,  0.0296,  ...,  0.0174, -0.0205,  0.0109],
        [-0.0140, -0.0028,  0.0079,  ..., -0.0091, -0.0031, -0.0039],
        ...,
        [-0.0132, -0.0266,  0.0216,  ...,  0.0353,  0.0298, -0.0355],
        [-0.0472, -0.0079, -0.0306,  ...,  0.0603,  0.0051, -0.0139],
        [-0.0354, -0.0072, -0.0054,  ..., -0.0238,  0.0083,  0.0164]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.1914, -7.2422, -0.6284,  ..., -2.4355,  0.2949, -0.0381]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 02:03:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A ocean is made up of water
A candy is made up of sugar
A mirror is made up of glass
A wall is made up of cement
A desk is made up of wood
A ice is made up of water
A money is made up of paper
A concrete is made up of
2024-07-27 02:03:36 root INFO     [order_1_approx] starting weight calculation for A ice is made up of water
A mirror is made up of glass
A ocean is made up of water
A wall is made up of cement
A concrete is made up of silicon
A money is made up of paper
A desk is made up of wood
A candy is made up of
2024-07-27 02:03:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 02:06:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2404,  0.1897, -0.2063,  ..., -0.1866, -0.1339, -0.1508],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5000, -6.2969, -0.0410,  ..., -2.4492, -1.4121,  4.1562],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0375, -0.0301,  0.0097,  ...,  0.0166, -0.0150,  0.0008],
        [-0.0251,  0.0409,  0.0073,  ..., -0.0167,  0.0155, -0.0029],
        [-0.0242,  0.0038,  0.0041,  ...,  0.0046, -0.0212, -0.0247],
        ...,
        [ 0.0170, -0.0220,  0.0195,  ...,  0.0422, -0.0265, -0.0007],
        [-0.0277, -0.0067, -0.0257,  ...,  0.0533, -0.0006, -0.0500],
        [ 0.0220,  0.0101,  0.0202,  ..., -0.0356,  0.0109,  0.0451]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4805, -6.0156, -0.0588,  ..., -2.4258, -1.8809,  4.8047]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 02:06:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A ice is made up of water
A mirror is made up of glass
A ocean is made up of water
A wall is made up of cement
A concrete is made up of silicon
A money is made up of paper
A desk is made up of wood
A candy is made up of
2024-07-27 02:06:22 root INFO     [order_1_approx] starting weight calculation for A ice is made up of water
A mirror is made up of glass
A desk is made up of wood
A concrete is made up of silicon
A money is made up of paper
A candy is made up of sugar
A wall is made up of cement
A ocean is made up of
2024-07-27 02:06:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 02:09:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0303,  0.3330,  0.0738,  ...,  0.0052, -0.0342, -0.2084],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2812, -4.2500,  1.6172,  ..., -5.1797,  2.5469, -1.3281],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-1.9211e-02,  6.7062e-03, -5.4260e-02,  ...,  8.3466e-03,
         -7.6904e-03, -2.3514e-02],
        [ 3.9185e-02, -9.5367e-05,  7.2708e-03,  ..., -6.0699e-02,
         -4.1199e-04, -2.0477e-02],
        [-2.9755e-04,  6.5536e-03,  3.4149e-02,  ...,  1.1932e-02,
          5.2338e-03,  1.1024e-02],
        ...,
        [ 5.7190e-02,  5.5313e-03,  4.8950e-02,  ..., -1.2886e-02,
          1.5549e-02, -1.7426e-02],
        [-6.6406e-02,  9.7198e-03, -3.5126e-02,  ...,  4.3213e-02,
          8.2855e-03, -7.7896e-03],
        [ 1.3229e-02, -1.6098e-02,  2.5406e-03,  ..., -2.0172e-02,
         -1.6479e-02,  5.2734e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8984, -4.1914,  1.4473,  ..., -5.3711,  2.2754, -0.7495]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 02:09:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A ice is made up of water
A mirror is made up of glass
A desk is made up of wood
A concrete is made up of silicon
A money is made up of paper
A candy is made up of sugar
A wall is made up of cement
A ocean is made up of
2024-07-27 02:09:06 root INFO     [order_1_approx] starting weight calculation for A concrete is made up of silicon
A desk is made up of wood
A ice is made up of water
A ocean is made up of water
A wall is made up of cement
A candy is made up of sugar
A mirror is made up of glass
A money is made up of
2024-07-27 02:09:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 02:11:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2822,  0.0249, -0.2842,  ...,  0.0961, -0.0507, -0.0454],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3672, -3.7305, -2.0195,  ..., -4.2422,  0.2100,  2.0898],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.1726e-02, -6.2622e-02, -8.1253e-04,  ...,  1.1063e-02,
         -1.0498e-02, -3.1372e-02],
        [-2.7878e-02,  2.1332e-02, -2.9678e-02,  ..., -1.8280e-02,
         -1.5259e-05, -1.8753e-02],
        [ 1.1627e-02,  1.5793e-02,  6.2256e-03,  ..., -6.2408e-03,
         -4.4250e-03, -8.9874e-03],
        ...,
        [ 1.6022e-02,  1.8295e-02,  1.8616e-03,  ...,  4.1595e-02,
          1.5045e-02, -2.6825e-02],
        [-2.5848e-02, -2.0050e-02, -1.2161e-02,  ...,  2.5879e-02,
          3.6713e-02, -1.6159e-02],
        [ 6.7520e-04, -2.3148e-02, -7.2327e-03,  ..., -3.6812e-03,
          2.7466e-04,  2.2766e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4629, -4.1797, -1.7734,  ..., -4.0664, -0.0322,  2.4492]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 02:11:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A concrete is made up of silicon
A desk is made up of wood
A ice is made up of water
A ocean is made up of water
A wall is made up of cement
A candy is made up of sugar
A mirror is made up of glass
A money is made up of
2024-07-27 02:11:54 root INFO     [order_1_approx] starting weight calculation for A ice is made up of water
A ocean is made up of water
A money is made up of paper
A concrete is made up of silicon
A wall is made up of cement
A candy is made up of sugar
A desk is made up of wood
A mirror is made up of
2024-07-27 02:11:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 02:14:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-2.7173e-01, -2.5940e-04, -1.7419e-01,  ...,  1.2195e-01,
         6.8909e-02, -2.0447e-01], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2109, -4.8242, -0.0302,  ..., -3.4512, -2.2207,  1.2539],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0352, -0.0219,  0.0316,  ...,  0.0196,  0.0018, -0.0033],
        [-0.0056,  0.0501, -0.0064,  ...,  0.0120, -0.0056, -0.0110],
        [ 0.0183,  0.0051,  0.0251,  ...,  0.0105, -0.0316,  0.0040],
        ...,
        [ 0.0150,  0.0113,  0.0117,  ...,  0.0256, -0.0106,  0.0049],
        [-0.0108,  0.0043, -0.0408,  ..., -0.0136,  0.0123, -0.0184],
        [ 0.0126, -0.0052,  0.0003,  ..., -0.0084,  0.0190,  0.0545]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6230, -5.1484, -0.3989,  ..., -3.6328, -2.8691,  1.8945]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 02:14:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A ice is made up of water
A ocean is made up of water
A money is made up of paper
A concrete is made up of silicon
A wall is made up of cement
A candy is made up of sugar
A desk is made up of wood
A mirror is made up of
2024-07-27 02:14:40 root INFO     total operator prediction time: 1315.8773348331451 seconds
2024-07-27 02:14:40 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on synonyms - intensity
2024-07-27 02:14:40 root INFO     building operator synonyms - intensity
2024-07-27 02:14:41 root INFO     [order_1_approx] starting weight calculation for A more intense word for snack is meal
A more intense word for opposed is averse
A more intense word for pain is torment
A more intense word for boring is tedious
A more intense word for tired is exhausted
A more intense word for guilty is remorseful
A more intense word for irritate is enrage
A more intense word for well is
2024-07-27 02:14:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 02:17:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0528,  0.0134,  0.0028,  ..., -0.1332, -0.3413,  0.1038],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3184,  0.0444,  1.3359,  ..., -0.3210, -7.6367, -1.0977],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0696,  0.0112,  0.0023,  ...,  0.0305, -0.0024,  0.0254],
        [-0.0555,  0.0557, -0.0216,  ...,  0.0292, -0.0322, -0.0550],
        [ 0.0318, -0.0450, -0.0058,  ...,  0.0528, -0.0222,  0.0260],
        ...,
        [-0.0714,  0.0044,  0.0211,  ...,  0.0784, -0.0053, -0.0108],
        [ 0.0453, -0.1016, -0.0490,  ..., -0.0146,  0.1206,  0.0086],
        [-0.0185, -0.0060, -0.0132,  ...,  0.0217, -0.0579,  0.0517]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1484, -0.0372,  1.2676,  ..., -0.4919, -7.4922, -1.4385]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 02:17:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for snack is meal
A more intense word for opposed is averse
A more intense word for pain is torment
A more intense word for boring is tedious
A more intense word for tired is exhausted
A more intense word for guilty is remorseful
A more intense word for irritate is enrage
A more intense word for well is
2024-07-27 02:17:25 root INFO     [order_1_approx] starting weight calculation for A more intense word for tired is exhausted
A more intense word for opposed is averse
A more intense word for irritate is enrage
A more intense word for guilty is remorseful
A more intense word for well is flourishing
A more intense word for snack is meal
A more intense word for pain is torment
A more intense word for boring is
2024-07-27 02:17:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 02:20:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0938,  0.0260,  0.1824,  ...,  0.0206, -0.4749,  0.1367],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3691, -1.6094,  4.0781,  ..., -1.6328, -6.0156, -0.6387],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0382, -0.0090,  0.0342,  ...,  0.0128, -0.0148,  0.0243],
        [-0.0036,  0.0133,  0.0109,  ...,  0.0029,  0.0266, -0.0384],
        [-0.0015, -0.0236,  0.0182,  ...,  0.0301,  0.0127,  0.0216],
        ...,
        [ 0.0507,  0.0128,  0.0277,  ...,  0.0058, -0.0193, -0.0435],
        [ 0.0207, -0.0101,  0.0563,  ...,  0.0133, -0.0332, -0.0350],
        [ 0.0446, -0.0001, -0.0056,  ...,  0.0189, -0.0113,  0.0051]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2500, -1.4766,  3.3984,  ..., -1.3994, -6.1719, -0.8413]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 02:20:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for tired is exhausted
A more intense word for opposed is averse
A more intense word for irritate is enrage
A more intense word for guilty is remorseful
A more intense word for well is flourishing
A more intense word for snack is meal
A more intense word for pain is torment
A more intense word for boring is
2024-07-27 02:20:08 root INFO     [order_1_approx] starting weight calculation for A more intense word for tired is exhausted
A more intense word for irritate is enrage
A more intense word for well is flourishing
A more intense word for guilty is remorseful
A more intense word for boring is tedious
A more intense word for opposed is averse
A more intense word for pain is torment
A more intense word for snack is
2024-07-27 02:20:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 02:22:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1926, -0.1323, -0.1149,  ...,  0.1146, -0.4314, -0.0936],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8730, -1.9629, -0.7324,  ...,  1.5596, -6.4023,  0.2432],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0083, -0.0219,  0.0184,  ...,  0.0215,  0.0217,  0.0484],
        [ 0.0180,  0.0287,  0.0174,  ..., -0.0290, -0.0262, -0.0401],
        [-0.0183, -0.0360,  0.0099,  ...,  0.0023, -0.0031,  0.0080],
        ...,
        [ 0.0352,  0.0113,  0.0607,  ...,  0.0039, -0.0330, -0.0175],
        [ 0.0038,  0.0009,  0.0327,  ...,  0.0005,  0.0134,  0.0153],
        [-0.0416,  0.0056, -0.0057,  ...,  0.0294,  0.0313,  0.0477]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2773, -1.3545, -0.4028,  ...,  1.1885, -7.0117,  0.3892]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 02:22:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for tired is exhausted
A more intense word for irritate is enrage
A more intense word for well is flourishing
A more intense word for guilty is remorseful
A more intense word for boring is tedious
A more intense word for opposed is averse
A more intense word for pain is torment
A more intense word for snack is
2024-07-27 02:22:52 root INFO     [order_1_approx] starting weight calculation for A more intense word for irritate is enrage
A more intense word for boring is tedious
A more intense word for tired is exhausted
A more intense word for well is flourishing
A more intense word for opposed is averse
A more intense word for snack is meal
A more intense word for guilty is remorseful
A more intense word for pain is
2024-07-27 02:22:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 02:25:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0102, -0.1992,  0.0146,  ..., -0.2166, -0.4534,  0.3069],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.3125, -4.9141,  0.7280,  ..., -1.3193, -1.7344, -3.0059],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0508, -0.0355, -0.0012,  ..., -0.0163,  0.0102,  0.0097],
        [-0.0095,  0.0279,  0.0141,  ...,  0.0014, -0.0156, -0.0030],
        [ 0.0120, -0.0361,  0.0295,  ..., -0.0049, -0.0133,  0.0068],
        ...,
        [-0.0024, -0.0069, -0.0059,  ...,  0.0229, -0.0151, -0.0235],
        [ 0.0253,  0.0021,  0.0119,  ...,  0.0065,  0.0050, -0.0127],
        [-0.0144, -0.0004, -0.0163,  ...,  0.0034, -0.0142,  0.0257]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.9531, -4.4609,  0.7598,  ..., -1.0059, -2.0312, -2.9531]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 02:25:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for irritate is enrage
A more intense word for boring is tedious
A more intense word for tired is exhausted
A more intense word for well is flourishing
A more intense word for opposed is averse
A more intense word for snack is meal
A more intense word for guilty is remorseful
A more intense word for pain is
2024-07-27 02:25:37 root INFO     [order_1_approx] starting weight calculation for A more intense word for tired is exhausted
A more intense word for irritate is enrage
A more intense word for boring is tedious
A more intense word for well is flourishing
A more intense word for snack is meal
A more intense word for opposed is averse
A more intense word for pain is torment
A more intense word for guilty is
2024-07-27 02:25:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 02:28:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0466, -0.2144, -0.2094,  ...,  0.0863, -0.1025,  0.5161],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2246, -3.6523,  0.8091,  ..., -1.2822, -3.5469, -0.2666],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0154, -0.0120,  0.0317,  ..., -0.0139, -0.0230,  0.0259],
        [-0.0095,  0.0215,  0.0263,  ..., -0.0052, -0.0142,  0.0033],
        [-0.0029, -0.0150,  0.0200,  ...,  0.0172, -0.0138, -0.0018],
        ...,
        [-0.0010,  0.0043, -0.0026,  ...,  0.0383, -0.0055, -0.0131],
        [-0.0075, -0.0077, -0.0070,  ..., -0.0040,  0.0278, -0.0275],
        [-0.0076, -0.0279, -0.0295,  ...,  0.0036, -0.0282,  0.0300]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2471, -3.3711,  0.9258,  ..., -1.1689, -3.4473, -0.7822]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 02:28:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for tired is exhausted
A more intense word for irritate is enrage
A more intense word for boring is tedious
A more intense word for well is flourishing
A more intense word for snack is meal
A more intense word for opposed is averse
A more intense word for pain is torment
A more intense word for guilty is
2024-07-27 02:28:21 root INFO     [order_1_approx] starting weight calculation for A more intense word for guilty is remorseful
A more intense word for pain is torment
A more intense word for boring is tedious
A more intense word for well is flourishing
A more intense word for snack is meal
A more intense word for opposed is averse
A more intense word for irritate is enrage
A more intense word for tired is
2024-07-27 02:28:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 02:31:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0237, -0.3188, -0.1428,  ...,  0.0670, -0.1764,  0.4966],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1875, -6.7539,  3.5566,  ..., -2.2402, -1.5234,  0.1035],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0286,  0.0091,  0.0309,  ...,  0.0012,  0.0266,  0.0052],
        [-0.0051,  0.0227,  0.0001,  ..., -0.0174, -0.0012,  0.0261],
        [-0.0309,  0.0034,  0.0428,  ...,  0.0257, -0.0214,  0.0170],
        ...,
        [ 0.0236,  0.0088, -0.0014,  ...,  0.0531, -0.0212,  0.0014],
        [-0.0073,  0.0245,  0.0130,  ..., -0.0090,  0.0414, -0.0223],
        [-0.0150,  0.0137, -0.0136,  ...,  0.0151,  0.0088,  0.0027]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0566, -6.1758,  3.4492,  ..., -2.2812, -1.5859, -0.1271]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 02:31:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for guilty is remorseful
A more intense word for pain is torment
A more intense word for boring is tedious
A more intense word for well is flourishing
A more intense word for snack is meal
A more intense word for opposed is averse
A more intense word for irritate is enrage
A more intense word for tired is
2024-07-27 02:31:05 root INFO     [order_1_approx] starting weight calculation for A more intense word for opposed is averse
A more intense word for well is flourishing
A more intense word for snack is meal
A more intense word for guilty is remorseful
A more intense word for boring is tedious
A more intense word for pain is torment
A more intense word for tired is exhausted
A more intense word for irritate is
2024-07-27 02:31:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 02:33:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0917, -0.0668, -0.2878,  ..., -0.1068, -0.5107,  0.6787],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0410, -4.1094,  0.1250,  ..., -1.3057,  0.6348,  1.9219],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0169,  0.0111, -0.0123,  ...,  0.0199,  0.0086, -0.0006],
        [ 0.0049,  0.0163,  0.0238,  ..., -0.0056, -0.0020,  0.0086],
        [ 0.0137, -0.0097,  0.0147,  ...,  0.0034,  0.0041,  0.0179],
        ...,
        [-0.0027,  0.0133,  0.0172,  ...,  0.0233, -0.0013, -0.0017],
        [ 0.0160, -0.0073,  0.0046,  ..., -0.0119,  0.0060, -0.0131],
        [-0.0082, -0.0002, -0.0151,  ...,  0.0019, -0.0195,  0.0121]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6738, -4.3828, -0.0493,  ..., -1.3164,  0.3079,  2.2402]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 02:33:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for opposed is averse
A more intense word for well is flourishing
A more intense word for snack is meal
A more intense word for guilty is remorseful
A more intense word for boring is tedious
A more intense word for pain is torment
A more intense word for tired is exhausted
A more intense word for irritate is
2024-07-27 02:33:52 root INFO     [order_1_approx] starting weight calculation for A more intense word for tired is exhausted
A more intense word for snack is meal
A more intense word for well is flourishing
A more intense word for guilty is remorseful
A more intense word for irritate is enrage
A more intense word for boring is tedious
A more intense word for pain is torment
A more intense word for opposed is
2024-07-27 02:33:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 02:36:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1652, -0.0645, -0.2217,  ..., -0.0506, -0.2007,  0.2747],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6602, -4.4766,  2.2852,  ..., -0.0514, -5.2500, -1.9971],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0192,  0.0248,  0.0148,  ...,  0.0032,  0.0048, -0.0164],
        [ 0.0386,  0.0160,  0.0624,  ..., -0.0236, -0.0035, -0.0009],
        [-0.0203,  0.0113, -0.0083,  ...,  0.0070,  0.0065, -0.0192],
        ...,
        [ 0.0114,  0.0187, -0.0053,  ...,  0.0361, -0.0294, -0.0558],
        [ 0.0084, -0.0334,  0.0260,  ...,  0.0267,  0.0185,  0.0018],
        [-0.0081, -0.0129, -0.0048,  ..., -0.0083, -0.0067,  0.0140]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4707, -4.1289,  2.4336,  ...,  0.1018, -5.3633, -2.0625]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 02:36:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for tired is exhausted
A more intense word for snack is meal
A more intense word for well is flourishing
A more intense word for guilty is remorseful
A more intense word for irritate is enrage
A more intense word for boring is tedious
A more intense word for pain is torment
A more intense word for opposed is
2024-07-27 02:36:40 root INFO     total operator prediction time: 1319.2116782665253 seconds
2024-07-27 02:36:40 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hypernyms - animals
2024-07-27 02:36:40 root INFO     building operator hypernyms - animals
2024-07-27 02:36:40 root INFO     [order_1_approx] starting weight calculation for The pony falls into the category of bovid
The jackal falls into the category of canine
The chicken falls into the category of fowl
The dog falls into the category of canine
The fox falls into the category of canine
The ant falls into the category of insect
The chinchilla falls into the category of rodent
The human falls into the category of
2024-07-27 02:36:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 02:39:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0782, -0.1163,  0.1792,  ...,  0.1365,  0.0711,  0.0312],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.0332, -5.8594,  1.9004,  ..., -0.9438, -8.7109, -0.8252],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0196,  0.0047, -0.0112,  ...,  0.0072,  0.0104,  0.0063],
        [ 0.0359, -0.0551,  0.0042,  ..., -0.0097,  0.0225, -0.0027],
        [-0.0155,  0.0278, -0.0044,  ...,  0.0086, -0.0226, -0.0016],
        ...,
        [ 0.0004,  0.0238,  0.0021,  ...,  0.0113, -0.0093, -0.0023],
        [ 0.0125, -0.0054,  0.0034,  ..., -0.0126,  0.0180, -0.0090],
        [ 0.0367, -0.0369,  0.0012,  ...,  0.0021,  0.0079,  0.0252]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.1230, -5.5156,  1.7383,  ..., -1.6621, -8.5156, -0.1553]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 02:39:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The pony falls into the category of bovid
The jackal falls into the category of canine
The chicken falls into the category of fowl
The dog falls into the category of canine
The fox falls into the category of canine
The ant falls into the category of insect
The chinchilla falls into the category of rodent
The human falls into the category of
2024-07-27 02:39:23 root INFO     [order_1_approx] starting weight calculation for The human falls into the category of primate
The fox falls into the category of canine
The dog falls into the category of canine
The pony falls into the category of bovid
The jackal falls into the category of canine
The ant falls into the category of insect
The chinchilla falls into the category of rodent
The chicken falls into the category of
2024-07-27 02:39:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 02:42:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0910, -0.1000, -0.1785,  ...,  0.0123, -0.0109, -0.0566],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6167, -6.2266,  4.3945,  ..., -2.9707, -9.6875,  1.1934],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0464,  0.0116, -0.0108,  ..., -0.0053,  0.0004,  0.0062],
        [ 0.0117,  0.0259,  0.0134,  ..., -0.0219,  0.0160, -0.0181],
        [-0.0041, -0.0053,  0.0479,  ...,  0.0150, -0.0076, -0.0186],
        ...,
        [ 0.0170,  0.0021, -0.0078,  ...,  0.0179, -0.0093,  0.0008],
        [ 0.0236, -0.0016, -0.0024,  ..., -0.0088,  0.0257, -0.0024],
        [ 0.0172, -0.0161, -0.0014,  ..., -0.0089,  0.0102,  0.0278]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2539, -6.2773,  4.5156,  ..., -3.2129, -9.9375,  1.4150]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 02:42:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The human falls into the category of primate
The fox falls into the category of canine
The dog falls into the category of canine
The pony falls into the category of bovid
The jackal falls into the category of canine
The ant falls into the category of insect
The chinchilla falls into the category of rodent
The chicken falls into the category of
2024-07-27 02:42:09 root INFO     [order_1_approx] starting weight calculation for The chinchilla falls into the category of rodent
The dog falls into the category of canine
The ant falls into the category of insect
The human falls into the category of primate
The chicken falls into the category of fowl
The fox falls into the category of canine
The pony falls into the category of bovid
The jackal falls into the category of
2024-07-27 02:42:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 02:44:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2139,  0.1802, -0.2065,  ..., -0.0023, -0.3062,  0.1100],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8965, -6.1719,  1.8008,  ..., -3.9746, -7.4492,  2.1055],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0581,  0.0117,  0.0034,  ..., -0.0320, -0.0488,  0.0117],
        [ 0.0400,  0.0013,  0.0302,  ..., -0.0145, -0.0217,  0.0363],
        [-0.0057, -0.0206,  0.0398,  ..., -0.0098, -0.0128,  0.0112],
        ...,
        [ 0.0061, -0.0118,  0.0070,  ...,  0.0253, -0.0090,  0.0297],
        [-0.0011, -0.0078,  0.0002,  ...,  0.0264,  0.0458,  0.0002],
        [ 0.0183,  0.0060,  0.0350,  ..., -0.0040, -0.0175,  0.0349]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7988, -6.6484,  1.5635,  ..., -3.2090, -8.2188,  1.6748]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 02:44:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The chinchilla falls into the category of rodent
The dog falls into the category of canine
The ant falls into the category of insect
The human falls into the category of primate
The chicken falls into the category of fowl
The fox falls into the category of canine
The pony falls into the category of bovid
The jackal falls into the category of
2024-07-27 02:44:54 root INFO     [order_1_approx] starting weight calculation for The chicken falls into the category of fowl
The dog falls into the category of canine
The pony falls into the category of bovid
The jackal falls into the category of canine
The human falls into the category of primate
The fox falls into the category of canine
The ant falls into the category of insect
The chinchilla falls into the category of
2024-07-27 02:44:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 02:47:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0545, -0.4216, -0.2827,  ..., -0.1447, -0.1298,  0.0397],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3027, -4.6992,  1.7422,  ..., -1.8379, -6.7266, -2.6934],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0223, -0.0147, -0.0129,  ...,  0.0087, -0.0493, -0.0116],
        [-0.0013,  0.0266,  0.0223,  ...,  0.0057,  0.0135, -0.0135],
        [ 0.0033, -0.0041,  0.0382,  ..., -0.0174, -0.0099, -0.0133],
        ...,
        [ 0.0262,  0.0277,  0.0056,  ...,  0.0207,  0.0284,  0.0216],
        [ 0.0075, -0.0213,  0.0141,  ..., -0.0024,  0.0302, -0.0101],
        [ 0.0017, -0.0044,  0.0013,  ..., -0.0086,  0.0424,  0.0493]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8320, -4.8750,  2.0918,  ..., -2.0293, -6.6602, -2.7539]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 02:47:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The chicken falls into the category of fowl
The dog falls into the category of canine
The pony falls into the category of bovid
The jackal falls into the category of canine
The human falls into the category of primate
The fox falls into the category of canine
The ant falls into the category of insect
The chinchilla falls into the category of
2024-07-27 02:47:37 root INFO     [order_1_approx] starting weight calculation for The jackal falls into the category of canine
The ant falls into the category of insect
The chinchilla falls into the category of rodent
The chicken falls into the category of fowl
The dog falls into the category of canine
The pony falls into the category of bovid
The human falls into the category of primate
The fox falls into the category of
2024-07-27 02:47:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 02:50:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2041,  0.0101, -0.2092,  ..., -0.1666,  0.0406, -0.2009],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1338, -5.2930,  2.5273,  ..., -3.5078, -6.9531,  0.7832],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0402, -0.0137,  0.0085,  ..., -0.0150, -0.0179,  0.0214],
        [ 0.0064,  0.0262,  0.0174,  ...,  0.0260, -0.0256, -0.0175],
        [ 0.0075, -0.0216,  0.0233,  ..., -0.0450, -0.0103, -0.0259],
        ...,
        [ 0.0096,  0.0101,  0.0119,  ...,  0.0183,  0.0266,  0.0106],
        [-0.0223,  0.0215,  0.0084,  ...,  0.0523,  0.0323, -0.0128],
        [ 0.0351, -0.0194,  0.0256,  ..., -0.0368,  0.0295,  0.0137]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3147, -5.2852,  2.3613,  ..., -3.2109, -7.1914,  0.6084]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 02:50:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The jackal falls into the category of canine
The ant falls into the category of insect
The chinchilla falls into the category of rodent
The chicken falls into the category of fowl
The dog falls into the category of canine
The pony falls into the category of bovid
The human falls into the category of primate
The fox falls into the category of
2024-07-27 02:50:24 root INFO     [order_1_approx] starting weight calculation for The chicken falls into the category of fowl
The fox falls into the category of canine
The dog falls into the category of canine
The jackal falls into the category of canine
The pony falls into the category of bovid
The human falls into the category of primate
The chinchilla falls into the category of rodent
The ant falls into the category of
2024-07-27 02:50:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 02:53:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1609, -0.1072,  0.0185,  ..., -0.0703, -0.2297, -0.2749],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.9199, -4.0977,  2.1016,  ..., -2.5273, -5.7031, -1.7871],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0462,  0.0114, -0.0094,  ..., -0.0163,  0.0026, -0.0012],
        [ 0.0205,  0.0207,  0.0179,  ...,  0.0078, -0.0239, -0.0302],
        [-0.0374,  0.0057,  0.0155,  ..., -0.0246, -0.0072,  0.0225],
        ...,
        [ 0.0765,  0.0509,  0.0068,  ...,  0.0349, -0.1142, -0.0679],
        [ 0.0034,  0.0402,  0.0190,  ...,  0.0025,  0.0429, -0.0061],
        [-0.0108, -0.0313,  0.0075,  ..., -0.0177,  0.0221,  0.0145]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.8516, -4.5820,  2.2656,  ..., -2.4531, -6.8711, -1.3516]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 02:53:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The chicken falls into the category of fowl
The fox falls into the category of canine
The dog falls into the category of canine
The jackal falls into the category of canine
The pony falls into the category of bovid
The human falls into the category of primate
The chinchilla falls into the category of rodent
The ant falls into the category of
2024-07-27 02:53:09 root INFO     [order_1_approx] starting weight calculation for The pony falls into the category of bovid
The fox falls into the category of canine
The human falls into the category of primate
The chinchilla falls into the category of rodent
The jackal falls into the category of canine
The chicken falls into the category of fowl
The ant falls into the category of insect
The dog falls into the category of
2024-07-27 02:53:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 02:55:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1791, -0.0192, -0.0464,  ...,  0.1672, -0.2494, -0.0693],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5879, -4.8477,  2.0977,  ..., -3.1738, -6.1328,  0.0972],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0345, -0.0018, -0.0215,  ..., -0.0278, -0.0269,  0.0103],
        [ 0.0091, -0.0284, -0.0513,  ..., -0.0327, -0.0099,  0.0210],
        [ 0.0073,  0.0143,  0.0749,  ...,  0.0124,  0.0034,  0.0043],
        ...,
        [ 0.0016, -0.0194, -0.0107,  ...,  0.0164, -0.0096,  0.0009],
        [-0.0055, -0.0041,  0.0228,  ...,  0.0111,  0.0562,  0.0112],
        [ 0.0266, -0.0377, -0.0386,  ..., -0.0198,  0.0258,  0.0667]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8389, -4.3906,  1.5625,  ..., -2.3711, -6.3438, -0.0215]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 02:55:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The pony falls into the category of bovid
The fox falls into the category of canine
The human falls into the category of primate
The chinchilla falls into the category of rodent
The jackal falls into the category of canine
The chicken falls into the category of fowl
The ant falls into the category of insect
The dog falls into the category of
2024-07-27 02:55:54 root INFO     [order_1_approx] starting weight calculation for The chinchilla falls into the category of rodent
The jackal falls into the category of canine
The fox falls into the category of canine
The dog falls into the category of canine
The chicken falls into the category of fowl
The ant falls into the category of insect
The human falls into the category of primate
The pony falls into the category of
2024-07-27 02:55:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 02:58:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0430,  0.0898, -0.3677,  ..., -0.0189, -0.0574,  0.2081],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4829, -5.6641,  2.1270,  ...,  0.6226, -6.7383, -1.0498],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0526, -0.0650,  0.0075,  ..., -0.0285,  0.0297,  0.0364],
        [-0.0077,  0.0131,  0.0055,  ...,  0.0254,  0.0346,  0.0372],
        [-0.0036,  0.0065,  0.0412,  ..., -0.0087, -0.0499, -0.0270],
        ...,
        [ 0.0172,  0.0154, -0.0055,  ...,  0.0592, -0.0372, -0.0150],
        [ 0.0014,  0.0170,  0.0072,  ..., -0.0066,  0.0354, -0.0178],
        [ 0.0519, -0.0750,  0.0416,  ..., -0.0781,  0.0587,  0.0768]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4272, -5.3320,  2.1602,  ...,  0.8398, -6.6406, -1.4336]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 02:58:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The chinchilla falls into the category of rodent
The jackal falls into the category of canine
The fox falls into the category of canine
The dog falls into the category of canine
The chicken falls into the category of fowl
The ant falls into the category of insect
The human falls into the category of primate
The pony falls into the category of
2024-07-27 02:58:35 root INFO     total operator prediction time: 1315.6890587806702 seconds
2024-07-27 02:58:35 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hyponyms - misc
2024-07-27 02:58:35 root INFO     building operator hyponyms - misc
2024-07-27 02:58:36 root INFO     [order_1_approx] starting weight calculation for A more specific term for a song is lullaby
A more specific term for a brush is toothbrush
A more specific term for a burger is hamburger
A more specific term for a oven is broiler
A more specific term for a seat is chair
A more specific term for a spice is pepper
A more specific term for a cutlery is knife
A more specific term for a shirt is
2024-07-27 02:58:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 03:01:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1531, -0.1359, -0.2739,  ...,  0.1831, -0.3105,  0.0731],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0312, -3.3496, -0.1653,  ...,  1.7578, -0.4402, -1.1426],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.1738e-02, -6.0081e-03,  5.5046e-03,  ..., -7.0076e-03,
          2.0844e-02, -3.3607e-03],
        [-4.2725e-03,  3.6499e-02, -1.0529e-02,  ...,  8.6517e-03,
         -2.5360e-02, -3.2139e-03],
        [ 2.2079e-02, -3.5187e-02,  3.8239e-02,  ...,  9.6130e-03,
         -3.3997e-02,  7.5226e-03],
        ...,
        [ 3.7994e-02,  1.5457e-02, -1.2302e-03,  ...,  2.5604e-02,
          1.8250e-02, -9.8038e-03],
        [-1.0986e-02,  2.8229e-04,  4.5776e-05,  ...,  6.5842e-03,
          3.5400e-02, -2.1088e-02],
        [-2.2507e-02,  1.1269e-02,  3.3722e-03,  ..., -2.1576e-02,
          3.4424e-02,  1.1963e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4863, -3.1484,  0.0457,  ...,  1.4697, -0.3403, -0.9277]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 03:01:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a song is lullaby
A more specific term for a brush is toothbrush
A more specific term for a burger is hamburger
A more specific term for a oven is broiler
A more specific term for a seat is chair
A more specific term for a spice is pepper
A more specific term for a cutlery is knife
A more specific term for a shirt is
2024-07-27 03:01:26 root INFO     [order_1_approx] starting weight calculation for A more specific term for a shirt is polo
A more specific term for a seat is chair
A more specific term for a oven is broiler
A more specific term for a brush is toothbrush
A more specific term for a cutlery is knife
A more specific term for a spice is pepper
A more specific term for a song is lullaby
A more specific term for a burger is
2024-07-27 03:01:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 03:04:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1174,  0.1953, -0.0998,  ...,  0.0737, -0.1445, -0.2458],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6777, -5.1836,  1.3389,  ..., -1.2314, -4.3945, -2.6289],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0240, -0.0103,  0.0082,  ..., -0.0379,  0.0026,  0.0025],
        [ 0.0034,  0.0301,  0.0010,  ..., -0.0300,  0.0099,  0.0417],
        [ 0.0074, -0.0126,  0.0693,  ...,  0.0011,  0.0103, -0.0309],
        ...,
        [ 0.0240,  0.0149, -0.0070,  ...,  0.0616, -0.0029,  0.0046],
        [ 0.0168, -0.0171,  0.0184,  ...,  0.0191,  0.0329, -0.0190],
        [ 0.0235, -0.0039,  0.0036,  ..., -0.0242, -0.0149,  0.0831]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8218, -5.4023,  1.4336,  ..., -1.3770, -3.8770, -2.9668]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 03:04:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a shirt is polo
A more specific term for a seat is chair
A more specific term for a oven is broiler
A more specific term for a brush is toothbrush
A more specific term for a cutlery is knife
A more specific term for a spice is pepper
A more specific term for a song is lullaby
A more specific term for a burger is
2024-07-27 03:04:12 root INFO     [order_1_approx] starting weight calculation for A more specific term for a cutlery is knife
A more specific term for a burger is hamburger
A more specific term for a spice is pepper
A more specific term for a brush is toothbrush
A more specific term for a oven is broiler
A more specific term for a shirt is polo
A more specific term for a song is lullaby
A more specific term for a seat is
2024-07-27 03:04:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 03:06:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0438, -0.0262, -0.2695,  ...,  0.0598, -0.0298, -0.0015],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8174, -4.8359,  4.0898,  ...,  2.5273, -2.1719,  2.0000],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0398, -0.0410,  0.0084,  ...,  0.0114, -0.0323, -0.0190],
        [-0.0106,  0.0681,  0.0115,  ..., -0.0012,  0.0277,  0.0292],
        [ 0.0133, -0.0040,  0.0408,  ..., -0.0102, -0.0479,  0.0099],
        ...,
        [ 0.0131,  0.0219,  0.0051,  ...,  0.0381,  0.0227,  0.0147],
        [ 0.0091, -0.0288, -0.0178,  ...,  0.0173, -0.0245, -0.0366],
        [ 0.0007, -0.0169,  0.0104,  ..., -0.0080, -0.0009,  0.0442]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1602, -5.2383,  4.0273,  ...,  2.0664, -1.9375,  1.9893]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 03:07:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a cutlery is knife
A more specific term for a burger is hamburger
A more specific term for a spice is pepper
A more specific term for a brush is toothbrush
A more specific term for a oven is broiler
A more specific term for a shirt is polo
A more specific term for a song is lullaby
A more specific term for a seat is
2024-07-27 03:07:00 root INFO     [order_1_approx] starting weight calculation for A more specific term for a shirt is polo
A more specific term for a oven is broiler
A more specific term for a spice is pepper
A more specific term for a song is lullaby
A more specific term for a burger is hamburger
A more specific term for a seat is chair
A more specific term for a cutlery is knife
A more specific term for a brush is
2024-07-27 03:07:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 03:09:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1940,  0.1859, -0.1960,  ...,  0.0088,  0.0508, -0.0917],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.3789, -4.4727, -2.2305,  ...,  2.5605, -2.9805, -1.1973],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0462,  0.0021, -0.0031,  ...,  0.0417, -0.0699, -0.0075],
        [-0.0018, -0.0080,  0.0081,  ..., -0.0195,  0.0117,  0.0104],
        [-0.0110, -0.0033,  0.0321,  ...,  0.0064, -0.0117, -0.0108],
        ...,
        [ 0.0235,  0.0085, -0.0049,  ...,  0.0392,  0.0169,  0.0138],
        [-0.0147, -0.0263, -0.0196,  ..., -0.0173,  0.0479, -0.0162],
        [-0.0320, -0.0058,  0.0096,  ...,  0.0160,  0.0177,  0.0404]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.1055, -4.3672, -2.1777,  ...,  3.0391, -2.8477, -1.0127]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 03:09:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a shirt is polo
A more specific term for a oven is broiler
A more specific term for a spice is pepper
A more specific term for a song is lullaby
A more specific term for a burger is hamburger
A more specific term for a seat is chair
A more specific term for a cutlery is knife
A more specific term for a brush is
2024-07-27 03:09:41 root INFO     [order_1_approx] starting weight calculation for A more specific term for a spice is pepper
A more specific term for a brush is toothbrush
A more specific term for a oven is broiler
A more specific term for a shirt is polo
A more specific term for a seat is chair
A more specific term for a burger is hamburger
A more specific term for a cutlery is knife
A more specific term for a song is
2024-07-27 03:09:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 03:12:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1422,  0.2358, -0.0609,  ..., -0.0003, -0.2900, -0.2556],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3623, -9.0938,  2.4609,  ..., -0.2500, -1.4463, -0.8652],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0203, -0.0315, -0.0100,  ...,  0.0012,  0.0108,  0.0716],
        [-0.0121,  0.0206, -0.0427,  ..., -0.0060,  0.0410,  0.0449],
        [ 0.0060,  0.0047,  0.0703,  ...,  0.0046, -0.0444, -0.0109],
        ...,
        [ 0.0274, -0.0045,  0.0134,  ...,  0.0551, -0.0111, -0.0167],
        [-0.0085, -0.0081,  0.0049,  ..., -0.0045,  0.0132,  0.0277],
        [-0.0066,  0.0202, -0.0445,  ..., -0.0384,  0.0510,  0.0902]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6279, -9.4297,  2.8848,  ..., -0.2340, -1.8799, -1.3652]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 03:12:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a spice is pepper
A more specific term for a brush is toothbrush
A more specific term for a oven is broiler
A more specific term for a shirt is polo
A more specific term for a seat is chair
A more specific term for a burger is hamburger
A more specific term for a cutlery is knife
A more specific term for a song is
2024-07-27 03:12:25 root INFO     [order_1_approx] starting weight calculation for A more specific term for a song is lullaby
A more specific term for a burger is hamburger
A more specific term for a brush is toothbrush
A more specific term for a oven is broiler
A more specific term for a seat is chair
A more specific term for a spice is pepper
A more specific term for a shirt is polo
A more specific term for a cutlery is
2024-07-27 03:12:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 03:15:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1765, -0.2864, -0.4619,  ..., -0.0527, -0.0543, -0.1604],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6777, -3.7344, -3.0605,  ..., -0.3301, -0.7451, -0.3638],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0439, -0.0249, -0.0159,  ...,  0.0014,  0.0224,  0.0086],
        [ 0.0096,  0.0247,  0.0345,  ..., -0.0327,  0.0603, -0.0103],
        [-0.0240, -0.0121,  0.0489,  ...,  0.0016, -0.0418, -0.0352],
        ...,
        [ 0.0197, -0.0049, -0.0301,  ...,  0.0399,  0.0076,  0.0236],
        [ 0.0277,  0.0218, -0.0338,  ..., -0.0264,  0.0697,  0.0022],
        [ 0.0124,  0.0137, -0.0290,  ..., -0.0079,  0.0410,  0.0406]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9067, -3.3945, -3.1172,  ..., -0.0605, -0.5942, -0.5972]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 03:15:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a song is lullaby
A more specific term for a burger is hamburger
A more specific term for a brush is toothbrush
A more specific term for a oven is broiler
A more specific term for a seat is chair
A more specific term for a spice is pepper
A more specific term for a shirt is polo
A more specific term for a cutlery is
2024-07-27 03:15:08 root INFO     [order_1_approx] starting weight calculation for A more specific term for a seat is chair
A more specific term for a burger is hamburger
A more specific term for a song is lullaby
A more specific term for a brush is toothbrush
A more specific term for a spice is pepper
A more specific term for a cutlery is knife
A more specific term for a shirt is polo
A more specific term for a oven is
2024-07-27 03:15:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 03:17:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0130, -0.0731, -0.0734,  ..., -0.1396, -0.2686,  0.0317],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8926, -5.0391,  3.5137,  ..., -2.7148, -2.6387,  1.2871],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0184, -0.0084, -0.0039,  ...,  0.0055, -0.0036,  0.0359],
        [-0.0060,  0.0357, -0.0024,  ...,  0.0122,  0.0288, -0.0151],
        [-0.0535, -0.0138,  0.0331,  ..., -0.0085,  0.0106,  0.0020],
        ...,
        [-0.0105,  0.0160, -0.0009,  ...,  0.0334, -0.0092, -0.0073],
        [-0.0199,  0.0018, -0.0021,  ..., -0.0043,  0.0580, -0.0364],
        [-0.0276, -0.0085, -0.0155,  ..., -0.0061, -0.0204,  0.0400]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4922, -4.3477,  3.7148,  ..., -2.5703, -2.4238,  1.3535]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 03:17:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a seat is chair
A more specific term for a burger is hamburger
A more specific term for a song is lullaby
A more specific term for a brush is toothbrush
A more specific term for a spice is pepper
A more specific term for a cutlery is knife
A more specific term for a shirt is polo
A more specific term for a oven is
2024-07-27 03:17:49 root INFO     [order_1_approx] starting weight calculation for A more specific term for a brush is toothbrush
A more specific term for a shirt is polo
A more specific term for a seat is chair
A more specific term for a burger is hamburger
A more specific term for a song is lullaby
A more specific term for a cutlery is knife
A more specific term for a oven is broiler
A more specific term for a spice is
2024-07-27 03:17:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 03:20:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0215,  0.2429, -0.1530,  ...,  0.0537, -0.1229, -0.2837],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7695, -4.8711, -1.0312,  ...,  0.0381, -2.2363, -3.2227],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0422, -0.0072, -0.0130,  ...,  0.0003, -0.0010,  0.0091],
        [ 0.0031,  0.0453,  0.0149,  ..., -0.0003,  0.0160,  0.0069],
        [ 0.0013, -0.0085,  0.0399,  ...,  0.0141, -0.0112,  0.0043],
        ...,
        [ 0.0160,  0.0246,  0.0134,  ...,  0.0411,  0.0109,  0.0081],
        [-0.0050, -0.0141, -0.0038,  ..., -0.0132,  0.0375, -0.0175],
        [ 0.0261, -0.0171,  0.0076,  ..., -0.0076,  0.0231,  0.0184]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7559, -4.9609, -0.7803,  ..., -0.1460, -2.2754, -2.8008]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 03:20:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a brush is toothbrush
A more specific term for a shirt is polo
A more specific term for a seat is chair
A more specific term for a burger is hamburger
A more specific term for a song is lullaby
A more specific term for a cutlery is knife
A more specific term for a oven is broiler
A more specific term for a spice is
2024-07-27 03:20:32 root INFO     total operator prediction time: 1316.6221659183502 seconds
2024-07-27 03:20:32 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on antonyms - binary
2024-07-27 03:20:32 root INFO     building operator antonyms - binary
2024-07-27 03:20:32 root INFO     [order_1_approx] starting weight calculation for The opposite of occupied is vacant
The opposite of decrement is increment
The opposite of employ is dismiss
The opposite of rise is sink
The opposite of dynamic is static
The opposite of internal is external
The opposite of downslope is upslope
The opposite of submerge is
2024-07-27 03:20:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 03:23:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2939,  0.3757,  0.0382,  ..., -0.1709, -0.7129,  0.2803],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7754, -0.9883,  0.1177,  ...,  3.8809, -2.0059,  0.1738],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0219, -0.0046, -0.0266,  ..., -0.0309,  0.0379, -0.0153],
        [ 0.0120,  0.0102,  0.0057,  ...,  0.0649,  0.0124,  0.0024],
        [-0.0593,  0.0440,  0.0073,  ..., -0.0086, -0.0479, -0.0610],
        ...,
        [-0.0075,  0.0488, -0.0073,  ...,  0.0296,  0.0523, -0.0331],
        [ 0.0283, -0.0331,  0.0326,  ..., -0.0158,  0.0010, -0.0020],
        [-0.0046, -0.0186, -0.0208,  ...,  0.0123,  0.0071,  0.0041]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1914, -1.1094,  0.5898,  ...,  2.8887, -1.7266,  0.2866]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 03:23:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of occupied is vacant
The opposite of decrement is increment
The opposite of employ is dismiss
The opposite of rise is sink
The opposite of dynamic is static
The opposite of internal is external
The opposite of downslope is upslope
The opposite of submerge is
2024-07-27 03:23:17 root INFO     [order_1_approx] starting weight calculation for The opposite of internal is external
The opposite of occupied is vacant
The opposite of dynamic is static
The opposite of downslope is upslope
The opposite of rise is sink
The opposite of submerge is emerge
The opposite of employ is dismiss
The opposite of decrement is
2024-07-27 03:23:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 03:26:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3562,  0.0964, -0.1853,  ..., -0.0332, -0.2117,  0.1067],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1846, -0.9502, -0.2104,  ..., -0.0944, -2.6250, -0.5205],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0229, -0.0009,  0.0007,  ...,  0.0327, -0.0294,  0.0433],
        [-0.0228,  0.0342,  0.0110,  ...,  0.0161, -0.0058,  0.0064],
        [ 0.0057, -0.0129, -0.0108,  ..., -0.0393, -0.0191, -0.0054],
        ...,
        [ 0.0133,  0.0377,  0.0038,  ...,  0.0219,  0.0374, -0.0254],
        [-0.0083, -0.0010, -0.0156,  ..., -0.0386,  0.0601, -0.0186],
        [ 0.0222,  0.0011, -0.0106,  ..., -0.0328, -0.0287,  0.0176]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0781, -1.2988, -0.8237,  ..., -0.5396, -2.7988, -0.1780]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 03:26:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of internal is external
The opposite of occupied is vacant
The opposite of dynamic is static
The opposite of downslope is upslope
The opposite of rise is sink
The opposite of submerge is emerge
The opposite of employ is dismiss
The opposite of decrement is
2024-07-27 03:26:01 root INFO     [order_1_approx] starting weight calculation for The opposite of submerge is emerge
The opposite of dynamic is static
The opposite of internal is external
The opposite of decrement is increment
The opposite of rise is sink
The opposite of occupied is vacant
The opposite of employ is dismiss
The opposite of downslope is
2024-07-27 03:26:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 03:28:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-1.6907e-01,  2.4414e-01, -1.9495e-01,  ..., -1.7041e-01,
        -5.6689e-01, -1.2207e-04], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7485, -1.2539, -3.9570,  ..., -1.0703, -1.8711, -2.4199],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0365,  0.0443, -0.0127,  ..., -0.0032,  0.0477,  0.0656],
        [ 0.0125,  0.0554, -0.0211,  ...,  0.0286,  0.0035, -0.0158],
        [ 0.0195, -0.0044,  0.0040,  ...,  0.0027, -0.0523,  0.0245],
        ...,
        [ 0.0097,  0.0016,  0.0460,  ...,  0.0196, -0.0264,  0.0097],
        [-0.0090, -0.0040,  0.0171,  ...,  0.0114,  0.0673, -0.0170],
        [-0.0021, -0.0003,  0.0191,  ...,  0.0041, -0.0058,  0.0448]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1777, -1.5664, -3.4375,  ..., -0.5537, -2.0957, -2.8633]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 03:28:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of submerge is emerge
The opposite of dynamic is static
The opposite of internal is external
The opposite of decrement is increment
The opposite of rise is sink
The opposite of occupied is vacant
The opposite of employ is dismiss
The opposite of downslope is
2024-07-27 03:28:45 root INFO     [order_1_approx] starting weight calculation for The opposite of rise is sink
The opposite of employ is dismiss
The opposite of internal is external
The opposite of submerge is emerge
The opposite of dynamic is static
The opposite of downslope is upslope
The opposite of decrement is increment
The opposite of occupied is
2024-07-27 03:28:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 03:31:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1370, -0.1567, -0.1621,  ..., -0.0914, -0.3652,  0.3245],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6162, -0.9365,  0.7119,  ...,  0.2183, -2.4629, -0.9312],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0643,  0.0301, -0.0305,  ...,  0.0239, -0.0294,  0.0248],
        [ 0.0462,  0.0086,  0.0243,  ..., -0.0135,  0.0482,  0.0513],
        [-0.0098, -0.0032, -0.0028,  ..., -0.0457,  0.0142, -0.0164],
        ...,
        [ 0.0201, -0.0022,  0.0547,  ..., -0.0063,  0.0039, -0.0004],
        [-0.0373, -0.0558,  0.0660,  ..., -0.0233,  0.0500, -0.0241],
        [-0.0231,  0.0260, -0.0025,  ..., -0.0089,  0.0067,  0.0014]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4507, -0.9180,  0.6128,  ...,  0.1030, -2.9863, -0.9556]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 03:31:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of rise is sink
The opposite of employ is dismiss
The opposite of internal is external
The opposite of submerge is emerge
The opposite of dynamic is static
The opposite of downslope is upslope
The opposite of decrement is increment
The opposite of occupied is
2024-07-27 03:31:29 root INFO     [order_1_approx] starting weight calculation for The opposite of decrement is increment
The opposite of downslope is upslope
The opposite of internal is external
The opposite of submerge is emerge
The opposite of rise is sink
The opposite of occupied is vacant
The opposite of employ is dismiss
The opposite of dynamic is
2024-07-27 03:31:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 03:34:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2239,  0.1971, -0.1533,  ...,  0.0366, -0.0641,  0.2224],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4111,  1.8213,  2.1328,  ..., -0.9580, -3.2773, -3.1855],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0326,  0.0175, -0.0027,  ...,  0.0424, -0.0010,  0.0057],
        [ 0.0332,  0.0309,  0.0168,  ...,  0.0175,  0.0042, -0.0089],
        [-0.0435,  0.0070,  0.0068,  ..., -0.0074, -0.0529, -0.0117],
        ...,
        [ 0.0401, -0.0069, -0.0138,  ...,  0.0106,  0.0271, -0.0134],
        [-0.0252, -0.0162, -0.0006,  ..., -0.0676,  0.0474, -0.0456],
        [ 0.0819, -0.0049, -0.0556,  ...,  0.0368,  0.0392,  0.0427]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3132,  1.9785,  1.9473,  ..., -0.6865, -3.7461, -2.2344]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 03:34:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of decrement is increment
The opposite of downslope is upslope
The opposite of internal is external
The opposite of submerge is emerge
The opposite of rise is sink
The opposite of occupied is vacant
The opposite of employ is dismiss
The opposite of dynamic is
2024-07-27 03:34:13 root INFO     [order_1_approx] starting weight calculation for The opposite of rise is sink
The opposite of submerge is emerge
The opposite of occupied is vacant
The opposite of decrement is increment
The opposite of downslope is upslope
The opposite of employ is dismiss
The opposite of dynamic is static
The opposite of internal is
2024-07-27 03:34:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 03:36:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1703, -0.3198,  0.1006,  ...,  0.0333, -0.0291,  0.2363],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1572,  0.2910,  2.4180,  ..., -1.8242, -1.3926, -4.6953],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0327,  0.0086, -0.0346,  ...,  0.0113, -0.0158,  0.0346],
        [-0.0218,  0.0111,  0.0077,  ..., -0.0108,  0.0303,  0.0038],
        [-0.0134,  0.0050,  0.0200,  ...,  0.0292, -0.0488,  0.0160],
        ...,
        [ 0.0308,  0.0022,  0.0124,  ..., -0.0162,  0.0388, -0.0289],
        [ 0.0056, -0.0064, -0.0117,  ..., -0.0197,  0.0534, -0.0050],
        [ 0.0338, -0.0048, -0.0115,  ...,  0.0368, -0.0246,  0.0502]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9785,  0.5386,  2.0410,  ..., -2.2480, -1.5400, -4.4492]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 03:36:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of rise is sink
The opposite of submerge is emerge
The opposite of occupied is vacant
The opposite of decrement is increment
The opposite of downslope is upslope
The opposite of employ is dismiss
The opposite of dynamic is static
The opposite of internal is
2024-07-27 03:36:57 root INFO     [order_1_approx] starting weight calculation for The opposite of decrement is increment
The opposite of dynamic is static
The opposite of employ is dismiss
The opposite of submerge is emerge
The opposite of occupied is vacant
The opposite of downslope is upslope
The opposite of internal is external
The opposite of rise is
2024-07-27 03:36:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 03:39:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2542,  0.0636, -0.2059,  ...,  0.0162, -0.3123, -0.0051],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4375, -0.5488,  1.4199,  ..., -1.4004, -3.7539, -2.2168],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0300, -0.0160, -0.0189,  ...,  0.0172,  0.0149,  0.0097],
        [-0.0005,  0.0228,  0.0039,  ...,  0.0228,  0.0215, -0.0024],
        [-0.0302, -0.0043,  0.0006,  ..., -0.0158, -0.0066, -0.0082],
        ...,
        [ 0.0205, -0.0253,  0.0112,  ...,  0.0190, -0.0022, -0.0126],
        [-0.0176,  0.0001, -0.0053,  ..., -0.0056,  0.0347, -0.0420],
        [ 0.0122, -0.0113,  0.0077,  ...,  0.0067,  0.0137, -0.0083]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0527, -0.6318,  1.4336,  ..., -1.7227, -4.2422, -2.5605]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 03:39:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of decrement is increment
The opposite of dynamic is static
The opposite of employ is dismiss
The opposite of submerge is emerge
The opposite of occupied is vacant
The opposite of downslope is upslope
The opposite of internal is external
The opposite of rise is
2024-07-27 03:39:40 root INFO     [order_1_approx] starting weight calculation for The opposite of dynamic is static
The opposite of occupied is vacant
The opposite of decrement is increment
The opposite of downslope is upslope
The opposite of rise is sink
The opposite of internal is external
The opposite of submerge is emerge
The opposite of employ is
2024-07-27 03:39:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 03:42:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1484,  0.1508,  0.1504,  ..., -0.0304, -0.3303,  0.1787],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0000, -2.0449,  0.6416,  ...,  1.5781, -3.4590, -0.7646],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0479,  0.0276, -0.0149,  ...,  0.0208, -0.0066, -0.0029],
        [-0.0066,  0.0136,  0.0111,  ...,  0.0226, -0.0086,  0.0255],
        [ 0.0211, -0.0114,  0.0301,  ..., -0.0178,  0.0143, -0.0200],
        ...,
        [-0.0035, -0.0019,  0.0198,  ...,  0.0132,  0.0091, -0.0024],
        [-0.0060,  0.0192,  0.0313,  ...,  0.0059,  0.0341,  0.0241],
        [-0.0059, -0.0160,  0.0096,  ...,  0.0027, -0.0051,  0.0152]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9429, -2.1719,  0.6514,  ...,  1.4365, -3.6836, -1.0088]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 03:42:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of dynamic is static
The opposite of occupied is vacant
The opposite of decrement is increment
The opposite of downslope is upslope
The opposite of rise is sink
The opposite of internal is external
The opposite of submerge is emerge
The opposite of employ is
2024-07-27 03:42:24 root INFO     total operator prediction time: 1312.1998119354248 seconds
2024-07-27 03:42:24 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - member
2024-07-27 03:42:24 root INFO     building operator meronyms - member
2024-07-27 03:42:24 root INFO     [order_1_approx] starting weight calculation for A person is a member of a society
A member is a member of a club
A car is a member of a train
A goose is a member of a gaggle
A secretary is a member of a staff
A bird is a member of a flock
A senator is a member of a senate
A star is a member of a
2024-07-27 03:42:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 03:45:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0103,  0.2039, -0.1301,  ..., -0.0303, -0.0037, -0.1523],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.2871, -2.8398,  7.2109,  ..., -0.1094, -1.0713,  1.3740],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0875, -0.0543,  0.0036,  ..., -0.0440,  0.0337,  0.0462],
        [-0.0235,  0.0052, -0.0173,  ...,  0.0022, -0.0112, -0.0114],
        [-0.0056,  0.0117,  0.0558,  ...,  0.0002, -0.0068, -0.0434],
        ...,
        [-0.0109,  0.0387, -0.0024,  ...,  0.0748, -0.0464, -0.0414],
        [ 0.0122, -0.0055, -0.0216,  ..., -0.0188,  0.0335, -0.0281],
        [ 0.0265, -0.0392, -0.0209,  ..., -0.0446,  0.0348,  0.0739]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7485, -2.3379,  6.5000,  ..., -0.2340, -0.5752,  1.8545]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 03:45:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A person is a member of a society
A member is a member of a club
A car is a member of a train
A goose is a member of a gaggle
A secretary is a member of a staff
A bird is a member of a flock
A senator is a member of a senate
A star is a member of a
2024-07-27 03:45:11 root INFO     [order_1_approx] starting weight calculation for A member is a member of a club
A senator is a member of a senate
A star is a member of a constellation
A bird is a member of a flock
A person is a member of a society
A car is a member of a train
A secretary is a member of a staff
A goose is a member of a
2024-07-27 03:45:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 03:47:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0977,  0.0320, -0.0745,  ...,  0.0717, -0.0300,  0.0321],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.3945, -2.6992,  3.4844,  ...,  0.4404, -4.9141,  2.6699],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0348,  0.0150,  0.0098,  ..., -0.0020, -0.0293,  0.0332],
        [-0.0384,  0.0137,  0.0435,  ...,  0.0168, -0.0127, -0.0057],
        [ 0.0350,  0.0112,  0.0256,  ...,  0.0316,  0.0062,  0.0007],
        ...,
        [ 0.0369,  0.0387,  0.0190,  ...,  0.0544, -0.0003, -0.0517],
        [ 0.0735,  0.0389,  0.0122,  ...,  0.0113,  0.0520,  0.0145],
        [-0.0150, -0.0015, -0.0024,  ..., -0.0395, -0.0121,  0.0303]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.1367, -2.0879,  3.1016,  ...,  0.0786, -5.9453,  3.3496]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 03:47:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A member is a member of a club
A senator is a member of a senate
A star is a member of a constellation
A bird is a member of a flock
A person is a member of a society
A car is a member of a train
A secretary is a member of a staff
A goose is a member of a
2024-07-27 03:47:55 root INFO     [order_1_approx] starting weight calculation for A star is a member of a constellation
A senator is a member of a senate
A member is a member of a club
A bird is a member of a flock
A car is a member of a train
A goose is a member of a gaggle
A secretary is a member of a staff
A person is a member of a
2024-07-27 03:47:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 03:50:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0063, -0.0050, -0.0294,  ..., -0.0489, -0.1204, -0.3091],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2969, -2.6035,  3.5039,  ..., -1.9131, -2.4219, -1.2842],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0081,  0.0027,  0.0175,  ...,  0.0029,  0.0023, -0.0245],
        [ 0.0018,  0.0027, -0.0023,  ...,  0.0206, -0.0118,  0.0335],
        [ 0.0119,  0.0079,  0.0383,  ...,  0.0159,  0.0180,  0.0058],
        ...,
        [ 0.0016, -0.0017, -0.0115,  ...,  0.0191, -0.0231,  0.0065],
        [ 0.0002, -0.0105, -0.0215,  ...,  0.0144,  0.0138,  0.0099],
        [ 0.0017,  0.0052,  0.0007,  ...,  0.0158, -0.0185,  0.0265]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2148, -2.7656,  3.3223,  ..., -1.6631, -2.5410, -1.4658]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 03:50:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A star is a member of a constellation
A senator is a member of a senate
A member is a member of a club
A bird is a member of a flock
A car is a member of a train
A goose is a member of a gaggle
A secretary is a member of a staff
A person is a member of a
2024-07-27 03:50:37 root INFO     [order_1_approx] starting weight calculation for A secretary is a member of a staff
A member is a member of a club
A star is a member of a constellation
A car is a member of a train
A person is a member of a society
A bird is a member of a flock
A goose is a member of a gaggle
A senator is a member of a
2024-07-27 03:50:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 03:53:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0310,  0.2957, -0.2844,  ...,  0.0602, -0.0676,  0.2744],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8799, -4.6562,  4.2539,  ..., -1.6465,  1.2109, -0.3311],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0421, -0.0154,  0.0060,  ...,  0.0067, -0.0113,  0.0274],
        [ 0.0025,  0.0159,  0.0166,  ...,  0.0036,  0.0136,  0.0186],
        [-0.0170,  0.0021,  0.0180,  ..., -0.0053, -0.0140, -0.0153],
        ...,
        [ 0.0260,  0.0107,  0.0140,  ...,  0.0220,  0.0071, -0.0116],
        [-0.0029,  0.0066, -0.0209,  ...,  0.0029,  0.0035, -0.0146],
        [ 0.0089, -0.0148, -0.0002,  ..., -0.0170,  0.0179,  0.0499]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0332, -4.0312,  4.1641,  ..., -1.6074,  0.8174,  0.0754]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 03:53:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A secretary is a member of a staff
A member is a member of a club
A star is a member of a constellation
A car is a member of a train
A person is a member of a society
A bird is a member of a flock
A goose is a member of a gaggle
A senator is a member of a
2024-07-27 03:53:19 root INFO     [order_1_approx] starting weight calculation for A senator is a member of a senate
A goose is a member of a gaggle
A bird is a member of a flock
A star is a member of a constellation
A secretary is a member of a staff
A car is a member of a train
A person is a member of a society
A member is a member of a
2024-07-27 03:53:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 03:56:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([0.1953, 0.0126, 0.0234,  ..., 0.0085, 0.0982, 0.0317], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0410, -2.0781,  3.3438,  ..., -2.8496,  1.2285, -0.2930],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0110, -0.0015, -0.0030,  ..., -0.0090, -0.0030, -0.0011],
        [-0.0018,  0.0032,  0.0116,  ..., -0.0046, -0.0033,  0.0038],
        [-0.0085,  0.0104,  0.0023,  ...,  0.0014, -0.0097, -0.0015],
        ...,
        [ 0.0059, -0.0034,  0.0125,  ...,  0.0072,  0.0072,  0.0096],
        [-0.0039,  0.0047, -0.0090,  ...,  0.0059,  0.0104, -0.0059],
        [ 0.0080, -0.0069,  0.0015,  ..., -0.0015,  0.0032,  0.0114]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9990, -2.1270,  3.2480,  ..., -2.7695,  1.1152, -0.3623]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 03:56:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A senator is a member of a senate
A goose is a member of a gaggle
A bird is a member of a flock
A star is a member of a constellation
A secretary is a member of a staff
A car is a member of a train
A person is a member of a society
A member is a member of a
2024-07-27 03:56:03 root INFO     [order_1_approx] starting weight calculation for A car is a member of a train
A goose is a member of a gaggle
A star is a member of a constellation
A member is a member of a club
A person is a member of a society
A secretary is a member of a staff
A senator is a member of a senate
A bird is a member of a
2024-07-27 03:56:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 03:58:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0765,  0.0303,  0.1890,  ..., -0.0239, -0.1000, -0.2463],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.4336, -3.7969,  2.5664,  ..., -0.6421, -3.5059,  0.6162],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0206, -0.0025,  0.0579,  ..., -0.0010, -0.0154,  0.0450],
        [-0.0168,  0.0515,  0.0268,  ...,  0.0255,  0.0084, -0.0084],
        [ 0.0121, -0.0328,  0.0282,  ..., -0.0240,  0.0013,  0.0120],
        ...,
        [ 0.0138,  0.0148,  0.0203,  ...,  0.0451,  0.0244,  0.0062],
        [ 0.0276,  0.0056, -0.0064,  ...,  0.0407,  0.0518, -0.0416],
        [-0.0161, -0.0139,  0.0186,  ..., -0.0214, -0.0214,  0.0522]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.3086, -3.7168,  2.5039,  ..., -0.5669, -3.8203,  1.0049]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 03:58:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A car is a member of a train
A goose is a member of a gaggle
A star is a member of a constellation
A member is a member of a club
A person is a member of a society
A secretary is a member of a staff
A senator is a member of a senate
A bird is a member of a
2024-07-27 03:58:49 root INFO     [order_1_approx] starting weight calculation for A goose is a member of a gaggle
A secretary is a member of a staff
A person is a member of a society
A senator is a member of a senate
A bird is a member of a flock
A member is a member of a club
A star is a member of a constellation
A car is a member of a
2024-07-27 03:58:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 04:01:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2080,  0.0774, -0.0948,  ..., -0.0030, -0.0102, -0.0768],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8770, -4.4141,  3.6484,  ..., -1.0430, -0.8599, -0.1484],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0143, -0.0220, -0.0219,  ..., -0.0270, -0.0136,  0.0257],
        [-0.0269,  0.0601,  0.0070,  ...,  0.0206, -0.0081, -0.0288],
        [ 0.0271,  0.0195,  0.0223,  ...,  0.0024,  0.0007, -0.0099],
        ...,
        [ 0.0208,  0.0071, -0.0204,  ...,  0.0387, -0.0034, -0.0079],
        [ 0.0303, -0.0142, -0.0094,  ...,  0.0041,  0.0193, -0.0014],
        [-0.0049, -0.0254, -0.0027,  ..., -0.0077, -0.0020,  0.0336]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9590, -4.2812,  4.0508,  ..., -0.8516, -1.1533,  0.2512]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 04:01:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A goose is a member of a gaggle
A secretary is a member of a staff
A person is a member of a society
A senator is a member of a senate
A bird is a member of a flock
A member is a member of a club
A star is a member of a constellation
A car is a member of a
2024-07-27 04:01:35 root INFO     [order_1_approx] starting weight calculation for A bird is a member of a flock
A car is a member of a train
A member is a member of a club
A senator is a member of a senate
A goose is a member of a gaggle
A person is a member of a society
A star is a member of a constellation
A secretary is a member of a
2024-07-27 04:01:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 04:04:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1157,  0.0055, -0.3118,  ..., -0.0784, -0.1420,  0.0192],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6133, -3.1523,  3.2676,  ..., -0.7090, -0.9170, -1.8125],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0124, -0.0091,  0.0235,  ...,  0.0139,  0.0052,  0.0245],
        [ 0.0015,  0.0317, -0.0126,  ...,  0.0155,  0.0081, -0.0382],
        [-0.0022,  0.0108,  0.0383,  ..., -0.0072, -0.0229,  0.0222],
        ...,
        [ 0.0096,  0.0495,  0.0523,  ...,  0.0304,  0.0501, -0.0374],
        [ 0.0431,  0.0396, -0.0338,  ...,  0.0304,  0.0028, -0.0183],
        [ 0.0210, -0.0253, -0.0258,  ..., -0.0285,  0.0370,  0.0258]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8389, -2.5156,  3.2617,  ..., -0.8081, -0.7031, -1.4053]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 04:04:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A bird is a member of a flock
A car is a member of a train
A member is a member of a club
A senator is a member of a senate
A goose is a member of a gaggle
A person is a member of a society
A star is a member of a constellation
A secretary is a member of a
2024-07-27 04:04:19 root INFO     total operator prediction time: 1315.159157037735 seconds
2024-07-27 04:04:19 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun - plural_irreg
2024-07-27 04:04:19 root INFO     building operator noun - plural_irreg
2024-07-27 04:04:20 root INFO     [order_1_approx] starting weight calculation for The plural form of opportunity is opportunities
The plural form of child is children
The plural form of story is stories
The plural form of woman is women
The plural form of activity is activities
The plural form of majority is majorities
The plural form of safety is safeties
The plural form of energy is
2024-07-27 04:04:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 04:07:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0635,  0.0653, -0.0054,  ...,  0.0660, -0.0685,  0.0468],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5322,  1.0508,  1.1309,  ..., -2.4727, -3.1777, -3.6738],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0439, -0.0087, -0.0218,  ...,  0.0368, -0.0022,  0.0044],
        [-0.0168,  0.0307,  0.0171,  ...,  0.0014, -0.0258,  0.0013],
        [-0.0322, -0.0055,  0.0091,  ..., -0.0170, -0.0147,  0.0122],
        ...,
        [ 0.0083, -0.0070, -0.0020,  ...,  0.0258, -0.0002,  0.0050],
        [-0.0055, -0.0080, -0.0130,  ..., -0.0066,  0.0015, -0.0032],
        [ 0.0069, -0.0119, -0.0122,  ...,  0.0332, -0.0008,  0.0163]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2656,  0.8379,  0.9668,  ..., -2.5645, -3.8789, -3.1738]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 04:07:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of opportunity is opportunities
The plural form of child is children
The plural form of story is stories
The plural form of woman is women
The plural form of activity is activities
The plural form of majority is majorities
The plural form of safety is safeties
The plural form of energy is
2024-07-27 04:07:03 root INFO     [order_1_approx] starting weight calculation for The plural form of safety is safeties
The plural form of woman is women
The plural form of opportunity is opportunities
The plural form of majority is majorities
The plural form of story is stories
The plural form of energy is energies
The plural form of child is children
The plural form of activity is
2024-07-27 04:07:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 04:09:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0184, -0.0116, -0.0623,  ...,  0.0195, -0.3640, -0.0638],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0654, -1.1523,  1.6162,  ..., -0.0107,  0.0591, -2.5098],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0351,  0.0296, -0.0075,  ...,  0.0464,  0.0225,  0.0531],
        [-0.0329,  0.0350,  0.0145,  ...,  0.0149, -0.0330, -0.0129],
        [-0.0035, -0.0109, -0.0046,  ...,  0.0028,  0.0088,  0.0292],
        ...,
        [ 0.0014,  0.0143, -0.0249,  ...,  0.0296, -0.0071, -0.0285],
        [ 0.0211,  0.0050, -0.0370,  ..., -0.0120, -0.0118, -0.0569],
        [ 0.0363, -0.0030, -0.0198,  ...,  0.0217, -0.0030,  0.0253]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2026, -1.4570,  1.7666,  ..., -0.0363, -0.4229, -2.3945]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 04:09:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of safety is safeties
The plural form of woman is women
The plural form of opportunity is opportunities
The plural form of majority is majorities
The plural form of story is stories
The plural form of energy is energies
The plural form of child is children
The plural form of activity is
2024-07-27 04:09:43 root INFO     [order_1_approx] starting weight calculation for The plural form of energy is energies
The plural form of majority is majorities
The plural form of safety is safeties
The plural form of child is children
The plural form of activity is activities
The plural form of story is stories
The plural form of opportunity is opportunities
The plural form of woman is
2024-07-27 04:09:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 04:12:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0468, -0.0154,  0.0146,  ...,  0.0369, -0.1561,  0.0088],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7461, -4.8828,  2.3262,  ..., -0.7642, -1.3770, -0.3550],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.9509e-03, -1.8463e-02,  3.0060e-03,  ...,  6.3629e-03,
         -9.0561e-03,  1.4755e-02],
        [ 1.4214e-02,  2.8046e-02, -8.2779e-04,  ...,  1.8250e-02,
          2.2888e-05, -2.9545e-03],
        [ 1.3206e-02,  2.4307e-02, -1.7258e-02,  ...,  4.4159e-02,
         -1.2123e-02,  5.5725e-02],
        ...,
        [-1.8829e-02,  5.5313e-04,  6.0349e-03,  ...,  2.2522e-02,
         -3.1036e-02, -9.1476e-03],
        [ 1.3702e-02,  2.2552e-02, -2.7969e-02,  ...,  3.0212e-03,
          1.8387e-02,  1.9318e-02],
        [-1.9043e-02, -8.8272e-03, -9.1171e-03,  ...,  1.8921e-02,
         -3.3989e-03,  2.2232e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3535, -4.9336,  2.3770,  ..., -0.8789, -1.0244, -0.5098]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 04:12:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of energy is energies
The plural form of majority is majorities
The plural form of safety is safeties
The plural form of child is children
The plural form of activity is activities
The plural form of story is stories
The plural form of opportunity is opportunities
The plural form of woman is
2024-07-27 04:12:24 root INFO     [order_1_approx] starting weight calculation for The plural form of energy is energies
The plural form of woman is women
The plural form of activity is activities
The plural form of safety is safeties
The plural form of opportunity is opportunities
The plural form of majority is majorities
The plural form of child is children
The plural form of story is
2024-07-27 04:12:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 04:15:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3589, -0.0086,  0.0677,  ..., -0.0913, -0.2852,  0.2078],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3516, -2.2188,  1.0107,  ..., -0.6597, -1.7051, -2.7617],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.0171e-02, -1.0605e-02, -5.3177e-03,  ...,  1.3306e-02,
          7.2479e-03,  1.9409e-02],
        [ 2.7618e-02,  2.1591e-02, -1.8143e-02,  ...,  5.8594e-03,
         -2.4246e-02, -2.4872e-03],
        [-2.0752e-03,  4.6692e-03,  7.6370e-03,  ..., -9.3317e-04,
         -3.0624e-02,  6.7062e-03],
        ...,
        [ 2.6596e-02,  1.2688e-02, -2.1839e-04,  ...,  9.4910e-03,
          1.2749e-02,  6.3286e-03],
        [-1.3245e-02, -4.1771e-04, -3.1204e-03,  ..., -6.5956e-03,
          7.4959e-04, -1.9073e-02],
        [ 3.0182e-02, -7.3242e-03,  5.3406e-05,  ...,  8.3771e-03,
          3.6793e-03,  2.6123e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6855, -2.4258,  1.0840,  ..., -0.4004, -1.8730, -2.6816]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 04:15:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of energy is energies
The plural form of woman is women
The plural form of activity is activities
The plural form of safety is safeties
The plural form of opportunity is opportunities
The plural form of majority is majorities
The plural form of child is children
The plural form of story is
2024-07-27 04:15:09 root INFO     [order_1_approx] starting weight calculation for The plural form of activity is activities
The plural form of energy is energies
The plural form of woman is women
The plural form of majority is majorities
The plural form of story is stories
The plural form of opportunity is opportunities
The plural form of child is children
The plural form of safety is
2024-07-27 04:15:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 04:17:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0527, -0.1272, -0.0858,  ...,  0.0168, -0.0072,  0.1523],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4023, -0.7559, -0.0319,  ..., -0.1777, -3.3594, -2.6328],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.7206e-02, -3.1799e-02, -1.3016e-02,  ...,  1.9592e-02,
         -1.5762e-02, -7.3624e-03],
        [-1.8433e-02,  4.1138e-02,  1.9211e-02,  ..., -1.6174e-02,
         -3.4088e-02,  1.8448e-02],
        [-9.8114e-03,  1.9012e-02,  1.4565e-02,  ...,  1.2741e-02,
         -2.0096e-02, -8.5373e-03],
        ...,
        [ 1.2825e-02, -5.1918e-03, -1.2360e-02,  ...,  3.4302e-02,
          1.5091e-02,  6.2828e-03],
        [ 4.0092e-03,  4.1122e-03,  8.4991e-03,  ...,  9.5215e-03,
         -4.4823e-03, -1.5717e-02],
        [ 1.1932e-02, -1.2848e-02,  4.9896e-03,  ...,  5.9509e-02,
         -4.3869e-05,  1.5121e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6387, -1.5791,  0.0844,  ..., -0.5098, -4.1719, -2.4336]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 04:17:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of activity is activities
The plural form of energy is energies
The plural form of woman is women
The plural form of majority is majorities
The plural form of story is stories
The plural form of opportunity is opportunities
The plural form of child is children
The plural form of safety is
2024-07-27 04:17:56 root INFO     [order_1_approx] starting weight calculation for The plural form of safety is safeties
The plural form of woman is women
The plural form of energy is energies
The plural form of story is stories
The plural form of majority is majorities
The plural form of opportunity is opportunities
The plural form of activity is activities
The plural form of child is
2024-07-27 04:17:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 04:20:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1282, -0.1357,  0.0552,  ..., -0.0713, -0.5039,  0.1118],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1719, -2.3750,  1.6006,  ..., -1.3955, -0.6431, -2.0410],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0565, -0.0565, -0.0719,  ..., -0.0071, -0.0507,  0.0183],
        [-0.0047,  0.0299,  0.0105,  ...,  0.0065, -0.0304, -0.0135],
        [-0.0019,  0.0084, -0.0055,  ...,  0.0254, -0.0163,  0.0083],
        ...,
        [-0.0026, -0.0034, -0.0252,  ...,  0.0026, -0.0197,  0.0178],
        [-0.0623,  0.0445,  0.0237,  ...,  0.0339,  0.0579, -0.0220],
        [ 0.0141, -0.0623, -0.0436,  ..., -0.0068, -0.0774,  0.0328]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9082, -2.1758,  1.5928,  ..., -1.6895, -0.5132, -2.1816]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 04:20:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of safety is safeties
The plural form of woman is women
The plural form of energy is energies
The plural form of story is stories
The plural form of majority is majorities
The plural form of opportunity is opportunities
The plural form of activity is activities
The plural form of child is
2024-07-27 04:20:40 root INFO     [order_1_approx] starting weight calculation for The plural form of safety is safeties
The plural form of child is children
The plural form of majority is majorities
The plural form of activity is activities
The plural form of woman is women
The plural form of energy is energies
The plural form of story is stories
The plural form of opportunity is
2024-07-27 04:20:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 04:23:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0762,  0.0089, -0.0113,  ...,  0.1113, -0.1921,  0.1304],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1104,  0.0679, -0.5938,  ..., -0.2546, -1.0527, -0.1416],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0174,  0.0054,  0.0108,  ...,  0.0029,  0.0182,  0.0171],
        [ 0.0063,  0.0312, -0.0041,  ...,  0.0044, -0.0253,  0.0413],
        [ 0.0137,  0.0072, -0.0097,  ..., -0.0033, -0.0057,  0.0096],
        ...,
        [-0.0105,  0.0129, -0.0055,  ...,  0.0411, -0.0159,  0.0133],
        [-0.0001, -0.0297, -0.0147,  ..., -0.0062,  0.0234, -0.0462],
        [ 0.0038, -0.0149,  0.0035,  ...,  0.0341, -0.0098,  0.0047]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2295,  0.0500, -0.7031,  ..., -0.6377, -1.9346, -0.2517]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 04:23:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of safety is safeties
The plural form of child is children
The plural form of majority is majorities
The plural form of activity is activities
The plural form of woman is women
The plural form of energy is energies
The plural form of story is stories
The plural form of opportunity is
2024-07-27 04:23:24 root INFO     [order_1_approx] starting weight calculation for The plural form of opportunity is opportunities
The plural form of energy is energies
The plural form of child is children
The plural form of activity is activities
The plural form of story is stories
The plural form of safety is safeties
The plural form of woman is women
The plural form of majority is
2024-07-27 04:23:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 04:26:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1376,  0.0995, -0.0746,  ..., -0.0074, -0.2522,  0.2739],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1250, -0.3599, -1.3359,  ..., -5.6719, -1.0615, -2.7031],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0087,  0.0323, -0.0162,  ...,  0.0141, -0.0329, -0.0156],
        [ 0.0161,  0.0457,  0.0073,  ...,  0.0257, -0.0461,  0.0168],
        [ 0.0019, -0.0237,  0.0408,  ..., -0.0349, -0.0315,  0.0333],
        ...,
        [ 0.0316, -0.0145, -0.0075,  ...,  0.0211, -0.0550,  0.0355],
        [ 0.0008,  0.0149, -0.0606,  ...,  0.0027, -0.0176, -0.0309],
        [ 0.0220, -0.0157, -0.0397,  ...,  0.0184,  0.0218,  0.0431]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6855, -0.5498, -1.6826,  ..., -5.0938, -0.8193, -2.5723]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 04:26:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of opportunity is opportunities
The plural form of energy is energies
The plural form of child is children
The plural form of activity is activities
The plural form of story is stories
The plural form of safety is safeties
The plural form of woman is women
The plural form of majority is
2024-07-27 04:26:07 root INFO     total operator prediction time: 1307.696563243866 seconds
2024-07-27 04:26:07 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on Ving - verb_inf
2024-07-27 04:26:07 root INFO     building operator Ving - verb_inf
2024-07-27 04:26:07 root INFO     [order_1_approx] starting weight calculation for avoiding is the active form of avoid
seeming is the active form of seem
existing is the active form of exist
improving is the active form of improve
understanding is the active form of understand
becoming is the active form of become
teaching is the active form of teach
appearing is the active form of
2024-07-27 04:26:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 04:28:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0505,  0.0592, -0.1222,  ...,  0.1193, -0.0290, -0.2588],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9258, -4.0469, -0.2004,  ...,  3.8535, -1.6240, -1.9492],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.8173e-02,  2.0790e-04,  2.4796e-05,  ..., -4.9171e-03,
          6.9656e-03,  1.8005e-02],
        [-7.5150e-04,  4.9164e-02, -9.3689e-03,  ..., -3.2997e-03,
         -1.5656e-02,  7.8354e-03],
        [ 1.0056e-02,  2.4414e-04,  3.2845e-03,  ...,  3.4332e-04,
         -1.5076e-02,  7.1955e-04],
        ...,
        [ 4.5586e-03,  1.4587e-02, -1.9970e-03,  ...,  2.0081e-02,
         -2.6489e-02,  2.2850e-03],
        [-1.0529e-02,  6.0883e-03,  1.3075e-03,  ...,  4.6883e-03,
          5.1453e-02,  1.5549e-02],
        [ 7.4005e-03,  5.1880e-03,  6.5575e-03,  ...,  1.3428e-02,
         -2.6550e-03,  1.2489e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6821, -3.9141, -0.2302,  ...,  4.2344, -1.6914, -2.1523]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 04:28:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for avoiding is the active form of avoid
seeming is the active form of seem
existing is the active form of exist
improving is the active form of improve
understanding is the active form of understand
becoming is the active form of become
teaching is the active form of teach
appearing is the active form of
2024-07-27 04:28:53 root INFO     [order_1_approx] starting weight calculation for understanding is the active form of understand
improving is the active form of improve
avoiding is the active form of avoid
seeming is the active form of seem
existing is the active form of exist
becoming is the active form of become
appearing is the active form of appear
teaching is the active form of
2024-07-27 04:28:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 04:31:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0293,  0.3130,  0.1320,  ...,  0.1609, -0.2220,  0.0327],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9570, -3.2910,  1.4570,  ...,  3.8809, -2.8555, -4.4297],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0100,  0.0188,  0.0044,  ...,  0.0041, -0.0058, -0.0016],
        [-0.0003,  0.0156, -0.0026,  ..., -0.0211, -0.0157, -0.0121],
        [-0.0135,  0.0005,  0.0033,  ..., -0.0121, -0.0025, -0.0156],
        ...,
        [ 0.0101,  0.0057, -0.0103,  ...,  0.0148, -0.0035, -0.0088],
        [-0.0019, -0.0200,  0.0098,  ...,  0.0093,  0.0260,  0.0287],
        [ 0.0050,  0.0135,  0.0067,  ...,  0.0111,  0.0191,  0.0256]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9824, -3.4492,  1.7881,  ...,  3.6973, -2.9590, -4.5039]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 04:31:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for understanding is the active form of understand
improving is the active form of improve
avoiding is the active form of avoid
seeming is the active form of seem
existing is the active form of exist
becoming is the active form of become
appearing is the active form of appear
teaching is the active form of
2024-07-27 04:31:38 root INFO     [order_1_approx] starting weight calculation for appearing is the active form of appear
existing is the active form of exist
teaching is the active form of teach
seeming is the active form of seem
improving is the active form of improve
becoming is the active form of become
avoiding is the active form of avoid
understanding is the active form of
2024-07-27 04:31:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 04:34:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2126,  0.3508,  0.1479,  ...,  0.2191, -0.1428,  0.0215],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6484, -2.1562,  0.7764,  ...,  0.1934, -1.3281,  0.0322],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0525,  0.0034,  0.0138,  ..., -0.0011, -0.0071,  0.0335],
        [-0.0103,  0.0186, -0.0010,  ..., -0.0367, -0.0134,  0.0054],
        [ 0.0290,  0.0043,  0.0059,  ..., -0.0209,  0.0198,  0.0128],
        ...,
        [-0.0031,  0.0033, -0.0095,  ...,  0.0404,  0.0127, -0.0009],
        [ 0.0437,  0.0203, -0.0068,  ..., -0.0152,  0.0472, -0.0055],
        [ 0.0081,  0.0143, -0.0101,  ..., -0.0204,  0.0138,  0.0016]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7031, -2.3945,  1.0322,  ...,  0.1470, -1.2539, -0.3335]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 04:34:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for appearing is the active form of appear
existing is the active form of exist
teaching is the active form of teach
seeming is the active form of seem
improving is the active form of improve
becoming is the active form of become
avoiding is the active form of avoid
understanding is the active form of
2024-07-27 04:34:22 root INFO     [order_1_approx] starting weight calculation for appearing is the active form of appear
avoiding is the active form of avoid
seeming is the active form of seem
understanding is the active form of understand
improving is the active form of improve
becoming is the active form of become
teaching is the active form of teach
existing is the active form of
2024-07-27 04:34:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 04:37:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1232,  0.1853, -0.2053,  ..., -0.1840, -0.2338, -0.2437],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9980, -2.9062,  0.2866,  ...,  0.9810, -1.6689, -0.7212],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0416, -0.0322,  0.0160,  ...,  0.0152,  0.0048,  0.0163],
        [ 0.0002,  0.0502, -0.0008,  ..., -0.0253, -0.0041, -0.0064],
        [ 0.0019, -0.0199, -0.0189,  ..., -0.0155,  0.0126, -0.0123],
        ...,
        [-0.0013,  0.0356, -0.0320,  ...,  0.0482, -0.0055, -0.0220],
        [ 0.0264, -0.0039, -0.0133,  ..., -0.0384,  0.0340,  0.0228],
        [-0.0012,  0.0258,  0.0079,  ..., -0.0284,  0.0015,  0.0172]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9004, -3.3281,  0.1602,  ...,  0.9819, -1.9043, -1.1416]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 04:37:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for appearing is the active form of appear
avoiding is the active form of avoid
seeming is the active form of seem
understanding is the active form of understand
improving is the active form of improve
becoming is the active form of become
teaching is the active form of teach
existing is the active form of
2024-07-27 04:37:07 root INFO     [order_1_approx] starting weight calculation for becoming is the active form of become
teaching is the active form of teach
appearing is the active form of appear
avoiding is the active form of avoid
understanding is the active form of understand
existing is the active form of exist
improving is the active form of improve
seeming is the active form of
2024-07-27 04:37:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 04:39:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0105,  0.1780,  0.2830,  ...,  0.1061, -0.3215, -0.0634],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7617, -3.8887, -1.3066,  ...,  2.5898, -0.3232, -3.5352],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0178, -0.0093,  0.0072,  ...,  0.0037, -0.0174,  0.0047],
        [ 0.0056,  0.0352,  0.0010,  ..., -0.0107, -0.0021,  0.0108],
        [ 0.0016, -0.0019,  0.0078,  ..., -0.0046, -0.0142, -0.0105],
        ...,
        [ 0.0040,  0.0182,  0.0069,  ...,  0.0178,  0.0086, -0.0063],
        [-0.0040, -0.0153,  0.0009,  ..., -0.0297,  0.0609,  0.0166],
        [-0.0015,  0.0098,  0.0006,  ..., -0.0023,  0.0159,  0.0163]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8496, -4.0781, -1.3398,  ...,  2.8359, -0.0298, -3.2324]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 04:39:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for becoming is the active form of become
teaching is the active form of teach
appearing is the active form of appear
avoiding is the active form of avoid
understanding is the active form of understand
existing is the active form of exist
improving is the active form of improve
seeming is the active form of
2024-07-27 04:39:48 root INFO     [order_1_approx] starting weight calculation for teaching is the active form of teach
appearing is the active form of appear
understanding is the active form of understand
avoiding is the active form of avoid
existing is the active form of exist
improving is the active form of improve
seeming is the active form of seem
becoming is the active form of
2024-07-27 04:39:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 04:42:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0614,  0.3621,  0.2007,  ...,  0.0229, -0.0446, -0.0136],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3682, -3.7383, -0.4341,  ...,  3.3633,  0.9692, -2.6758],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.7740e-02,  1.4969e-02, -3.4332e-04,  ...,  2.2919e-02,
         -4.1008e-03,  3.0518e-02],
        [-5.4092e-03,  7.0763e-03, -3.3951e-04,  ..., -1.0757e-02,
         -1.8921e-02, -1.0185e-02],
        [ 2.0256e-03, -1.0284e-02,  1.7639e-02,  ..., -1.1444e-04,
          2.4033e-03, -7.3471e-03],
        ...,
        [-4.4746e-03,  8.5907e-03,  1.0872e-02,  ...,  3.6743e-02,
         -1.5602e-03,  7.4501e-03],
        [-5.0354e-03, -3.6316e-02,  2.9343e-02,  ...,  1.0796e-02,
          3.1433e-02, -9.7961e-03],
        [ 4.5929e-03,  3.3752e-02, -2.3163e-02,  ...,  2.8320e-02,
         -5.5313e-05,  4.8676e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2861, -3.8652, -0.2510,  ...,  3.4551,  0.9512, -2.8945]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 04:42:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for teaching is the active form of teach
appearing is the active form of appear
understanding is the active form of understand
avoiding is the active form of avoid
existing is the active form of exist
improving is the active form of improve
seeming is the active form of seem
becoming is the active form of
2024-07-27 04:42:34 root INFO     [order_1_approx] starting weight calculation for becoming is the active form of become
avoiding is the active form of avoid
understanding is the active form of understand
seeming is the active form of seem
existing is the active form of exist
appearing is the active form of appear
teaching is the active form of teach
improving is the active form of
2024-07-27 04:42:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 04:45:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1039,  0.2078,  0.0859,  ..., -0.0543, -0.1398,  0.0263],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2539, -4.5938, -1.0938,  ...,  3.3242, -0.1753, -2.8555],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.6312e-02,  5.0125e-03,  7.8888e-03,  ..., -7.3128e-03,
         -1.2321e-02,  7.9155e-05],
        [-1.3294e-03,  2.4643e-02, -1.4505e-03,  ...,  5.4588e-03,
         -1.4191e-02,  9.4223e-03],
        [ 3.0556e-03,  1.1826e-03,  1.2779e-02,  ..., -5.8556e-04,
         -6.4850e-04, -1.6212e-04],
        ...,
        [-3.3798e-03,  9.4910e-03, -7.4692e-03,  ...,  3.3142e-02,
          5.8174e-03, -5.5771e-03],
        [-3.5591e-03,  1.8692e-03,  7.2479e-04,  ..., -3.5210e-03,
          2.8488e-02,  2.5902e-03],
        [ 5.8517e-03, -8.3466e-03, -2.1553e-03,  ...,  6.3171e-03,
         -5.4092e-03,  2.0691e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3613, -4.6367, -1.1914,  ...,  3.3301, -0.4194, -3.0234]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 04:45:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for becoming is the active form of become
avoiding is the active form of avoid
understanding is the active form of understand
seeming is the active form of seem
existing is the active form of exist
appearing is the active form of appear
teaching is the active form of teach
improving is the active form of
2024-07-27 04:45:21 root INFO     [order_1_approx] starting weight calculation for teaching is the active form of teach
existing is the active form of exist
improving is the active form of improve
understanding is the active form of understand
seeming is the active form of seem
becoming is the active form of become
appearing is the active form of appear
avoiding is the active form of
2024-07-27 04:45:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 04:48:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2078,  0.1642, -0.0945,  ..., -0.0633,  0.0628,  0.0826],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2461, -3.5098, -2.4375,  ...,  3.1582, -0.6113, -1.8496],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0072,  0.0108,  0.0022,  ..., -0.0001, -0.0139,  0.0068],
        [-0.0122,  0.0369,  0.0013,  ..., -0.0050, -0.0107, -0.0081],
        [ 0.0237,  0.0011, -0.0117,  ..., -0.0169, -0.0100,  0.0090],
        ...,
        [ 0.0019,  0.0258, -0.0069,  ...,  0.0094, -0.0085,  0.0039],
        [ 0.0155, -0.0253,  0.0319,  ..., -0.0115,  0.0313,  0.0005],
        [ 0.0035,  0.0065,  0.0084,  ...,  0.0088,  0.0053,  0.0175]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3789, -3.7461, -2.3789,  ...,  3.0430, -0.9800, -1.8936]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 04:48:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for teaching is the active form of teach
existing is the active form of exist
improving is the active form of improve
understanding is the active form of understand
seeming is the active form of seem
becoming is the active form of become
appearing is the active form of appear
avoiding is the active form of
2024-07-27 04:48:07 root INFO     total operator prediction time: 1320.1164844036102 seconds
2024-07-27 04:48:07 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_Ving - Ved
2024-07-27 04:48:07 root INFO     building operator verb_Ving - Ved
2024-07-27 04:48:07 root INFO     [order_1_approx] starting weight calculation for After something is applying, it has applied
After something is sending, it has sent
After something is suffering, it has suffered
After something is performing, it has performed
After something is developing, it has developed
After something is creating, it has created
After something is announcing, it has announced
After something is relating, it has
2024-07-27 04:48:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 04:50:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1531,  0.1294, -0.0482,  ...,  0.1646, -0.4314, -0.1200],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0044,  0.5830,  1.4961,  ...,  0.3198, -3.3145, -0.8281],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0108,  0.0174,  0.0077,  ...,  0.0380,  0.0114,  0.0334],
        [-0.0356,  0.0079,  0.0498,  ...,  0.0281, -0.0247, -0.0182],
        [ 0.0020, -0.0166, -0.0220,  ...,  0.0179,  0.0066, -0.0130],
        ...,
        [ 0.0021,  0.0378, -0.0036,  ..., -0.0067,  0.0259,  0.0395],
        [ 0.0269, -0.0171, -0.0124,  ..., -0.0057,  0.0130, -0.0356],
        [ 0.0088,  0.0120, -0.0065,  ...,  0.0315, -0.0170,  0.0124]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2029,  0.5513,  1.8193,  ...,  0.0386, -2.6914, -0.9658]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 04:50:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is applying, it has applied
After something is sending, it has sent
After something is suffering, it has suffered
After something is performing, it has performed
After something is developing, it has developed
After something is creating, it has created
After something is announcing, it has announced
After something is relating, it has
2024-07-27 04:50:54 root INFO     [order_1_approx] starting weight calculation for After something is relating, it has related
After something is sending, it has sent
After something is applying, it has applied
After something is suffering, it has suffered
After something is performing, it has performed
After something is announcing, it has announced
After something is creating, it has created
After something is developing, it has
2024-07-27 04:50:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 04:53:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1364, -0.0247,  0.1964,  ...,  0.0758,  0.0867,  0.0107],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2168, -0.8989,  2.8789,  ..., -2.5645, -1.3555, -2.1465],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0160,  0.0127, -0.0276,  ..., -0.0058,  0.0019, -0.0075],
        [-0.0673,  0.0363, -0.0110,  ...,  0.0302,  0.0135, -0.0005],
        [ 0.0295, -0.0141, -0.0046,  ..., -0.0471, -0.0298, -0.0402],
        ...,
        [ 0.0413,  0.0224,  0.0290,  ...,  0.0261,  0.0065,  0.0276],
        [ 0.0069, -0.0318,  0.0092,  ..., -0.0276,  0.0176,  0.0129],
        [-0.0063, -0.0150, -0.0001,  ..., -0.0114, -0.0293, -0.0032]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1738, -0.5996,  2.3477,  ..., -2.1953, -2.2148, -2.7305]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 04:53:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is relating, it has related
After something is sending, it has sent
After something is applying, it has applied
After something is suffering, it has suffered
After something is performing, it has performed
After something is announcing, it has announced
After something is creating, it has created
After something is developing, it has
2024-07-27 04:53:37 root INFO     [order_1_approx] starting weight calculation for After something is suffering, it has suffered
After something is performing, it has performed
After something is developing, it has developed
After something is creating, it has created
After something is sending, it has sent
After something is announcing, it has announced
After something is relating, it has related
After something is applying, it has
2024-07-27 04:53:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 04:56:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0330, -0.0304,  0.2144,  ...,  0.1655, -0.2874, -0.0772],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2568,  0.6255, -0.1821,  ..., -1.0391, -2.0488, -0.4395],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0228,  0.0114,  0.0117,  ...,  0.0379,  0.0227,  0.0093],
        [-0.0393,  0.0313,  0.0350,  ..., -0.0065, -0.0034, -0.0104],
        [-0.0095, -0.0024, -0.0082,  ..., -0.0036,  0.0091, -0.0025],
        ...,
        [ 0.0190,  0.0138, -0.0076,  ...,  0.0177, -0.0045,  0.0187],
        [-0.0134, -0.0087,  0.0107,  ..., -0.0117,  0.0214, -0.0197],
        [ 0.0033, -0.0059, -0.0011,  ..., -0.0235, -0.0575,  0.0009]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1152,  0.3364,  0.0728,  ..., -0.7495, -1.8262, -0.4287]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 04:56:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is suffering, it has suffered
After something is performing, it has performed
After something is developing, it has developed
After something is creating, it has created
After something is sending, it has sent
After something is announcing, it has announced
After something is relating, it has related
After something is applying, it has
2024-07-27 04:56:23 root INFO     [order_1_approx] starting weight calculation for After something is relating, it has related
After something is creating, it has created
After something is announcing, it has announced
After something is performing, it has performed
After something is sending, it has sent
After something is applying, it has applied
After something is developing, it has developed
After something is suffering, it has
2024-07-27 04:56:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 04:59:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2042,  0.1100,  0.0757,  ..., -0.1974, -0.0710,  0.1683],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6836, -2.1348,  0.8232,  ..., -2.9512,  2.5586,  1.3320],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0165, -0.0240,  0.0059,  ...,  0.0081,  0.0228,  0.0287],
        [-0.0222,  0.0254,  0.0351,  ..., -0.0028,  0.0045, -0.0035],
        [-0.0021, -0.0122, -0.0083,  ...,  0.0072,  0.0250, -0.0085],
        ...,
        [ 0.0058, -0.0116,  0.0121,  ..., -0.0024,  0.0152, -0.0056],
        [ 0.0010,  0.0173, -0.0032,  ..., -0.0317,  0.0222, -0.0014],
        [-0.0055,  0.0063,  0.0198,  ...,  0.0010, -0.0173,  0.0051]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8281, -2.0723,  0.9146,  ..., -2.6738,  2.3086,  1.0791]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 04:59:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is relating, it has related
After something is creating, it has created
After something is announcing, it has announced
After something is performing, it has performed
After something is sending, it has sent
After something is applying, it has applied
After something is developing, it has developed
After something is suffering, it has
2024-07-27 04:59:09 root INFO     [order_1_approx] starting weight calculation for After something is performing, it has performed
After something is suffering, it has suffered
After something is developing, it has developed
After something is applying, it has applied
After something is announcing, it has announced
After something is creating, it has created
After something is relating, it has related
After something is sending, it has
2024-07-27 04:59:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 05:01:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1268,  0.1929,  0.2703,  ...,  0.0514, -0.0847, -0.0438],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2041, -0.4697, -0.9858,  ..., -2.6992, -0.5459, -1.1357],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0435, -0.0133, -0.0027,  ...,  0.0115,  0.0098, -0.0330],
        [-0.0222,  0.0373,  0.0394,  ..., -0.0271, -0.0178, -0.0088],
        [ 0.0092, -0.0062,  0.0284,  ...,  0.0131, -0.0055, -0.0188],
        ...,
        [ 0.0053,  0.0039, -0.0118,  ...,  0.0388,  0.0131,  0.0042],
        [ 0.0005, -0.0023,  0.0036,  ..., -0.0054,  0.0349,  0.0156],
        [ 0.0005,  0.0123,  0.0133,  ..., -0.0175, -0.0330,  0.0174]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7793, -0.1260, -0.1689,  ..., -2.5820, -0.9893, -1.7637]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 05:01:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is performing, it has performed
After something is suffering, it has suffered
After something is developing, it has developed
After something is applying, it has applied
After something is announcing, it has announced
After something is creating, it has created
After something is relating, it has related
After something is sending, it has
2024-07-27 05:01:54 root INFO     [order_1_approx] starting weight calculation for After something is sending, it has sent
After something is announcing, it has announced
After something is performing, it has performed
After something is applying, it has applied
After something is developing, it has developed
After something is relating, it has related
After something is suffering, it has suffered
After something is creating, it has
2024-07-27 05:01:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 05:04:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0277,  0.0616,  0.0129,  ...,  0.1318, -0.1357, -0.1537],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0342, -0.1914,  1.7822,  ..., -1.1230, -2.1562, -0.4082],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0153,  0.0050, -0.0226,  ...,  0.0319,  0.0147,  0.0087],
        [-0.0291,  0.0081,  0.0202,  ..., -0.0021, -0.0494, -0.0284],
        [-0.0009, -0.0212,  0.0051,  ...,  0.0002,  0.0041,  0.0035],
        ...,
        [ 0.0249,  0.0452,  0.0410,  ...,  0.0165,  0.0334, -0.0169],
        [-0.0028, -0.0114, -0.0399,  ..., -0.0200, -0.0078, -0.0040],
        [-0.0141, -0.0014, -0.0064,  ..., -0.0199, -0.0346, -0.0042]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7012, -0.7124,  1.6611,  ..., -0.5122, -2.3027, -0.7944]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 05:04:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is sending, it has sent
After something is announcing, it has announced
After something is performing, it has performed
After something is applying, it has applied
After something is developing, it has developed
After something is relating, it has related
After something is suffering, it has suffered
After something is creating, it has
2024-07-27 05:04:37 root INFO     [order_1_approx] starting weight calculation for After something is relating, it has related
After something is developing, it has developed
After something is performing, it has performed
After something is suffering, it has suffered
After something is creating, it has created
After something is applying, it has applied
After something is sending, it has sent
After something is announcing, it has
2024-07-27 05:04:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 05:07:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0223,  0.4080, -0.0334,  ...,  0.0492, -0.1927, -0.1764],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5400, -1.0566,  2.4453,  ..., -0.1860, -1.8008,  0.5898],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0239,  0.0047, -0.0106,  ...,  0.0131, -0.0019,  0.0006],
        [-0.0177,  0.0013,  0.0048,  ..., -0.0063,  0.0022,  0.0045],
        [ 0.0114, -0.0124, -0.0254,  ..., -0.0105, -0.0067,  0.0016],
        ...,
        [-0.0002,  0.0187, -0.0242,  ...,  0.0059,  0.0136,  0.0030],
        [ 0.0073,  0.0037,  0.0072,  ..., -0.0072, -0.0030, -0.0026],
        [-0.0020,  0.0062,  0.0241,  ..., -0.0044, -0.0132, -0.0013]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1855, -1.2930,  2.9297,  ...,  0.3413, -2.0273,  0.3640]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 05:07:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is relating, it has related
After something is developing, it has developed
After something is performing, it has performed
After something is suffering, it has suffered
After something is creating, it has created
After something is applying, it has applied
After something is sending, it has sent
After something is announcing, it has
2024-07-27 05:07:23 root INFO     [order_1_approx] starting weight calculation for After something is developing, it has developed
After something is applying, it has applied
After something is sending, it has sent
After something is relating, it has related
After something is announcing, it has announced
After something is suffering, it has suffered
After something is creating, it has created
After something is performing, it has
2024-07-27 05:07:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 05:10:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0432,  0.2529, -0.0676,  ...,  0.0121, -0.2164, -0.0966],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6650, -0.4487,  4.0039,  ..., -2.3594, -2.8555, -0.3594],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0271,  0.0028, -0.0070,  ..., -0.0163,  0.0043, -0.0035],
        [-0.0097,  0.0806,  0.0356,  ...,  0.0382,  0.0516, -0.0388],
        [-0.0302, -0.0090, -0.0277,  ...,  0.0099, -0.0096,  0.0383],
        ...,
        [ 0.0092,  0.0001,  0.0039,  ...,  0.0365,  0.0278, -0.0133],
        [-0.0238, -0.0126,  0.0271,  ..., -0.0586,  0.0105,  0.0161],
        [-0.0046,  0.0023, -0.0020,  ...,  0.0134, -0.0448,  0.0087]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6328,  0.0581,  4.1641,  ..., -2.2168, -2.5137, -0.4312]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 05:10:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is developing, it has developed
After something is applying, it has applied
After something is sending, it has sent
After something is relating, it has related
After something is announcing, it has announced
After something is suffering, it has suffered
After something is creating, it has created
After something is performing, it has
2024-07-27 05:10:09 root INFO     total operator prediction time: 1321.61350607872 seconds
2024-07-27 05:10:09 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_inf - Ved
2024-07-27 05:10:09 root INFO     building operator verb_inf - Ved
2024-07-27 05:10:09 root INFO     [order_1_approx] starting weight calculation for If the present form is apply, the past form is applied
If the present form is involve, the past form is involved
If the present form is develop, the past form is developed
If the present form is seem, the past form is seemed
If the present form is include, the past form is included
If the present form is tell, the past form is told
If the present form is consider, the past form is considered
If the present form is become, the past form is
2024-07-27 05:10:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 05:12:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0421,  0.2012,  0.3728,  ..., -0.0571, -0.4004,  0.1681],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7759, -0.2700,  1.0557,  ...,  0.2412,  1.1748, -1.3545],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0223, -0.0091,  0.0318,  ...,  0.0559,  0.0016, -0.0199],
        [-0.0036,  0.0058,  0.0218,  ..., -0.0035, -0.0254, -0.0201],
        [-0.0019, -0.0029,  0.0159,  ..., -0.0323,  0.0075, -0.0099],
        ...,
        [-0.0005,  0.0091, -0.0266,  ...,  0.0397,  0.0197, -0.0245],
        [ 0.0047,  0.0304, -0.0208,  ..., -0.0135,  0.0374,  0.0020],
        [-0.0071,  0.0089,  0.0298,  ..., -0.0190, -0.0228, -0.0003]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9106, -0.4683,  0.2803,  ...,  0.3279,  0.7188, -1.4385]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 05:12:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is apply, the past form is applied
If the present form is involve, the past form is involved
If the present form is develop, the past form is developed
If the present form is seem, the past form is seemed
If the present form is include, the past form is included
If the present form is tell, the past form is told
If the present form is consider, the past form is considered
If the present form is become, the past form is
2024-07-27 05:12:56 root INFO     [order_1_approx] starting weight calculation for If the present form is seem, the past form is seemed
If the present form is involve, the past form is involved
If the present form is apply, the past form is applied
If the present form is include, the past form is included
If the present form is become, the past form is became
If the present form is develop, the past form is developed
If the present form is consider, the past form is considered
If the present form is tell, the past form is
2024-07-27 05:12:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 05:15:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1355, -0.0070,  0.1753,  ...,  0.0864, -0.2915,  0.1997],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5977, -0.1138,  1.4404,  ...,  3.5195, -4.6250, -2.8750],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0069, -0.0176, -0.0027,  ...,  0.0032, -0.0036,  0.0112],
        [-0.0005,  0.0446,  0.0058,  ...,  0.0038, -0.0225, -0.0172],
        [-0.0108, -0.0216,  0.0119,  ..., -0.0082, -0.0200,  0.0129],
        ...,
        [-0.0138,  0.0181, -0.0128,  ...,  0.0195, -0.0083, -0.0052],
        [-0.0023, -0.0078,  0.0012,  ..., -0.0198,  0.0341,  0.0089],
        [ 0.0164,  0.0579,  0.0045,  ...,  0.0125,  0.0086,  0.0237]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0293,  0.1755,  1.7168,  ...,  3.6973, -4.5000, -3.5059]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 05:15:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is seem, the past form is seemed
If the present form is involve, the past form is involved
If the present form is apply, the past form is applied
If the present form is include, the past form is included
If the present form is become, the past form is became
If the present form is develop, the past form is developed
If the present form is consider, the past form is considered
If the present form is tell, the past form is
2024-07-27 05:15:44 root INFO     [order_1_approx] starting weight calculation for If the present form is include, the past form is included
If the present form is consider, the past form is considered
If the present form is become, the past form is became
If the present form is develop, the past form is developed
If the present form is involve, the past form is involved
If the present form is tell, the past form is told
If the present form is apply, the past form is applied
If the present form is seem, the past form is
2024-07-27 05:15:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 05:18:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1904,  0.0873,  0.2568,  ...,  0.2195, -0.4836,  0.2515],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2080,  0.2646, -0.3425,  ...,  0.3726, -2.0664, -1.7158],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.0283e-02, -4.2725e-02,  3.1708e-02,  ..., -1.9913e-02,
          8.1329e-03, -2.6520e-02],
        [ 5.3864e-03,  5.3711e-02,  1.5442e-02,  ..., -2.2888e-05,
         -8.8120e-03, -2.7420e-02],
        [-1.4053e-02, -5.8823e-03,  3.0106e-02,  ..., -1.0666e-02,
         -2.6672e-02, -1.6678e-02],
        ...,
        [-8.4076e-03,  2.3727e-02, -2.6512e-03,  ...,  5.0751e-02,
          4.4250e-03,  3.1185e-03],
        [ 3.6957e-02, -2.4765e-02, -1.4801e-02,  ..., -1.0849e-02,
          2.1973e-02, -1.4664e-02],
        [ 9.7275e-03, -7.3776e-03, -7.9422e-03,  ...,  2.3361e-02,
          1.0681e-03, -1.1284e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4033,  0.4263, -0.7510,  ...,  0.2686, -1.7139, -1.7725]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 05:18:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is include, the past form is included
If the present form is consider, the past form is considered
If the present form is become, the past form is became
If the present form is develop, the past form is developed
If the present form is involve, the past form is involved
If the present form is tell, the past form is told
If the present form is apply, the past form is applied
If the present form is seem, the past form is
2024-07-27 05:18:29 root INFO     [order_1_approx] starting weight calculation for If the present form is develop, the past form is developed
If the present form is involve, the past form is involved
If the present form is seem, the past form is seemed
If the present form is consider, the past form is considered
If the present form is tell, the past form is told
If the present form is become, the past form is became
If the present form is include, the past form is included
If the present form is apply, the past form is
2024-07-27 05:18:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 05:21:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1527, -0.0103,  0.2391,  ...,  0.0285, -0.4668,  0.0205],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0918, -0.7339, -0.7642,  ...,  0.1226, -2.5000, -1.3574],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0244, -0.0042,  0.0171,  ..., -0.0126,  0.0071, -0.0111],
        [-0.0144,  0.0107,  0.0031,  ...,  0.0186, -0.0324, -0.0265],
        [ 0.0124, -0.0123, -0.0112,  ..., -0.0117, -0.0357, -0.0210],
        ...,
        [-0.0012,  0.0274,  0.0064,  ...,  0.0274,  0.0093, -0.0088],
        [-0.0027, -0.0153,  0.0254,  ...,  0.0069,  0.0202, -0.0215],
        [ 0.0207, -0.0246, -0.0156,  ...,  0.0065, -0.0428, -0.0012]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0198, -1.1621, -0.8740,  ...,  0.2407, -2.5527, -1.3760]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 05:21:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is develop, the past form is developed
If the present form is involve, the past form is involved
If the present form is seem, the past form is seemed
If the present form is consider, the past form is considered
If the present form is tell, the past form is told
If the present form is become, the past form is became
If the present form is include, the past form is included
If the present form is apply, the past form is
2024-07-27 05:21:11 root INFO     [order_1_approx] starting weight calculation for If the present form is apply, the past form is applied
If the present form is seem, the past form is seemed
If the present form is include, the past form is included
If the present form is develop, the past form is developed
If the present form is tell, the past form is told
If the present form is become, the past form is became
If the present form is consider, the past form is considered
If the present form is involve, the past form is
2024-07-27 05:21:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 05:23:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0611, -0.1163,  0.1122,  ...,  0.1111, -0.2971,  0.0594],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2197,  0.3840,  2.0312,  ..., -0.9316,  0.3286, -2.4570],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0025,  0.0065, -0.0081,  ..., -0.0134, -0.0169, -0.0183],
        [-0.0385,  0.0567,  0.0177,  ...,  0.0366, -0.0058, -0.0081],
        [ 0.0031, -0.0037, -0.0025,  ..., -0.0333, -0.0332, -0.0168],
        ...,
        [ 0.0125,  0.0211, -0.0039,  ...,  0.0453,  0.0275,  0.0122],
        [ 0.0270,  0.0094, -0.0168,  ..., -0.0084,  0.0437, -0.0069],
        [ 0.0752, -0.0039,  0.0227,  ...,  0.0263, -0.0366,  0.0115]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1511,  0.4880,  1.8066,  ..., -1.1875,  0.5288, -2.4082]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 05:23:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is apply, the past form is applied
If the present form is seem, the past form is seemed
If the present form is include, the past form is included
If the present form is develop, the past form is developed
If the present form is tell, the past form is told
If the present form is become, the past form is became
If the present form is consider, the past form is considered
If the present form is involve, the past form is
2024-07-27 05:23:57 root INFO     [order_1_approx] starting weight calculation for If the present form is become, the past form is became
If the present form is seem, the past form is seemed
If the present form is consider, the past form is considered
If the present form is tell, the past form is told
If the present form is apply, the past form is applied
If the present form is involve, the past form is involved
If the present form is include, the past form is included
If the present form is develop, the past form is
2024-07-27 05:23:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 05:26:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2129,  0.1086,  0.2573,  ..., -0.0325, -0.3701,  0.1407],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5908, -1.3066,  3.3906,  ..., -0.9839, -1.5146, -1.9414],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0105, -0.0045,  0.0042,  ..., -0.0055, -0.0200, -0.0020],
        [-0.0096,  0.0401, -0.0131,  ...,  0.0377, -0.0097, -0.0206],
        [-0.0137,  0.0104, -0.0181,  ..., -0.0175, -0.0285, -0.0044],
        ...,
        [ 0.0185,  0.0112, -0.0049,  ...,  0.0312,  0.0120,  0.0109],
        [ 0.0159, -0.0077,  0.0004,  ..., -0.0121,  0.0178, -0.0112],
        [-0.0066, -0.0205,  0.0210,  ...,  0.0091, -0.0090, -0.0034]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1465, -1.5977,  3.2500,  ..., -1.3984, -1.1934, -1.8701]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 05:26:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is become, the past form is became
If the present form is seem, the past form is seemed
If the present form is consider, the past form is considered
If the present form is tell, the past form is told
If the present form is apply, the past form is applied
If the present form is involve, the past form is involved
If the present form is include, the past form is included
If the present form is develop, the past form is
2024-07-27 05:26:43 root INFO     [order_1_approx] starting weight calculation for If the present form is apply, the past form is applied
If the present form is involve, the past form is involved
If the present form is develop, the past form is developed
If the present form is become, the past form is became
If the present form is tell, the past form is told
If the present form is seem, the past form is seemed
If the present form is consider, the past form is considered
If the present form is include, the past form is
2024-07-27 05:26:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 05:29:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0032, -0.1313,  0.2664,  ...,  0.0115, -0.1141,  0.0671],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6562,  0.0938,  0.1206,  ..., -1.2217, -0.4727, -1.5039],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0240, -0.0030, -0.0083,  ..., -0.0235,  0.0019, -0.0173],
        [-0.0171,  0.0394,  0.0270,  ...,  0.0273,  0.0001, -0.0214],
        [ 0.0041,  0.0066,  0.0140,  ..., -0.0400, -0.0493, -0.0176],
        ...,
        [-0.0046,  0.0029,  0.0110,  ...,  0.0316,  0.0110,  0.0101],
        [ 0.0135,  0.0145, -0.0011,  ..., -0.0101,  0.0390, -0.0031],
        [ 0.0225,  0.0052,  0.0162,  ..., -0.0104, -0.0147,  0.0186]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7778, -0.3696, -0.0400,  ..., -1.5742,  0.2603, -0.4902]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 05:29:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is apply, the past form is applied
If the present form is involve, the past form is involved
If the present form is develop, the past form is developed
If the present form is become, the past form is became
If the present form is tell, the past form is told
If the present form is seem, the past form is seemed
If the present form is consider, the past form is considered
If the present form is include, the past form is
2024-07-27 05:29:27 root INFO     [order_1_approx] starting weight calculation for If the present form is seem, the past form is seemed
If the present form is involve, the past form is involved
If the present form is become, the past form is became
If the present form is include, the past form is included
If the present form is develop, the past form is developed
If the present form is tell, the past form is told
If the present form is apply, the past form is applied
If the present form is consider, the past form is
2024-07-27 05:29:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 05:32:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0578,  0.1416,  0.0184,  ...,  0.1262, -0.2812,  0.1292],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6523, -0.2351,  1.8438,  ..., -2.0703, -0.5664, -0.2891],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0019, -0.0075,  0.0021,  ..., -0.0276, -0.0085,  0.0044],
        [ 0.0163,  0.0014,  0.0081,  ...,  0.0202, -0.0158, -0.0047],
        [-0.0075,  0.0101,  0.0428,  ..., -0.0394, -0.0110, -0.0043],
        ...,
        [ 0.0154,  0.0168,  0.0218,  ...,  0.0180,  0.0112, -0.0193],
        [ 0.0334,  0.0206,  0.0038,  ...,  0.0172,  0.0276, -0.0322],
        [ 0.0305,  0.0084,  0.0219,  ...,  0.0089, -0.0011,  0.0014]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9805, -0.5938,  1.3506,  ..., -2.0781, -0.4775, -0.3518]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 05:32:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is seem, the past form is seemed
If the present form is involve, the past form is involved
If the present form is become, the past form is became
If the present form is include, the past form is included
If the present form is develop, the past form is developed
If the present form is tell, the past form is told
If the present form is apply, the past form is applied
If the present form is consider, the past form is
2024-07-27 05:32:13 root INFO     total operator prediction time: 1323.9608302116394 seconds
2024-07-27 05:32:13 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_inf - 3pSg
2024-07-27 05:32:13 root INFO     building operator verb_inf - 3pSg
2024-07-27 05:32:13 root INFO     [order_1_approx] starting weight calculation for I receive, he receives
I seem, he seems
I hear, he hears
I represent, he represents
I ensure, he ensures
I exist, he exists
I develop, he develops
I enjoy, he
2024-07-27 05:32:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 05:34:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0739,  0.2520,  0.0695,  ..., -0.0193, -0.2468, -0.0884],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5156, -3.1406, -1.1504,  ..., -1.2900, -6.3750, -0.6494],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0087,  0.0056,  0.0191,  ...,  0.0231, -0.0062,  0.0308],
        [-0.0151,  0.0285, -0.0072,  ..., -0.0048,  0.0234, -0.0080],
        [ 0.0135, -0.0134,  0.0049,  ..., -0.0052, -0.0617,  0.0114],
        ...,
        [ 0.0138, -0.0007,  0.0043,  ...,  0.0122, -0.0042, -0.0151],
        [-0.0025,  0.0227, -0.0149,  ..., -0.0033, -0.0134, -0.0431],
        [ 0.0004,  0.0040, -0.0032,  ...,  0.0054, -0.0190, -0.0256]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0664, -3.3145, -1.1436,  ..., -0.6836, -6.6133, -1.2676]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 05:34:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I receive, he receives
I seem, he seems
I hear, he hears
I represent, he represents
I ensure, he ensures
I exist, he exists
I develop, he develops
I enjoy, he
2024-07-27 05:34:58 root INFO     [order_1_approx] starting weight calculation for I enjoy, he enjoys
I exist, he exists
I develop, he develops
I receive, he receives
I seem, he seems
I ensure, he ensures
I represent, he represents
I hear, he
2024-07-27 05:34:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 05:37:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2230,  0.2126,  0.0083,  ..., -0.0322, -0.1558, -0.0569],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2715, -4.5859, -2.3574,  ..., -1.8105, -7.3125, -2.7910],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0464,  0.0351, -0.0174,  ..., -0.0254, -0.0346,  0.0103],
        [-0.0043,  0.0066, -0.0005,  ...,  0.0063,  0.0244, -0.0121],
        [ 0.0272,  0.0013,  0.0061,  ..., -0.0168, -0.0253,  0.0171],
        ...,
        [ 0.0420, -0.0194,  0.0077,  ...,  0.0030,  0.0162,  0.0041],
        [-0.0012, -0.0129, -0.0100,  ..., -0.0175,  0.0297,  0.0059],
        [ 0.0207, -0.0021,  0.0098,  ..., -0.0142,  0.0147,  0.0115]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7305, -4.4570, -2.1191,  ..., -1.1270, -7.5156, -3.1582]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 05:37:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I enjoy, he enjoys
I exist, he exists
I develop, he develops
I receive, he receives
I seem, he seems
I ensure, he ensures
I represent, he represents
I hear, he
2024-07-27 05:37:43 root INFO     [order_1_approx] starting weight calculation for I develop, he develops
I hear, he hears
I seem, he seems
I receive, he receives
I represent, he represents
I ensure, he ensures
I enjoy, he enjoys
I exist, he
2024-07-27 05:37:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 05:40:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0903,  0.0903, -0.2200,  ..., -0.0989, -0.1818, -0.3245],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9551, -2.9219, -1.7041,  ..., -1.0176, -3.7734,  0.7383],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0043,  0.0144,  0.0069,  ...,  0.0149, -0.0106, -0.0018],
        [-0.0058,  0.0258, -0.0079,  ..., -0.0120,  0.0234, -0.0021],
        [ 0.0046,  0.0036, -0.0059,  ..., -0.0139,  0.0022, -0.0051],
        ...,
        [-0.0017, -0.0199, -0.0140,  ...,  0.0034, -0.0141, -0.0173],
        [-0.0210, -0.0213,  0.0225,  ...,  0.0009,  0.0353, -0.0325],
        [ 0.0014,  0.0221, -0.0029,  ...,  0.0018, -0.0078,  0.0008]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9375, -2.7461, -1.7920,  ..., -0.3374, -4.4297,  0.2261]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 05:40:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I develop, he develops
I hear, he hears
I seem, he seems
I receive, he receives
I represent, he represents
I ensure, he ensures
I enjoy, he enjoys
I exist, he
2024-07-27 05:40:30 root INFO     [order_1_approx] starting weight calculation for I hear, he hears
I develop, he develops
I exist, he exists
I represent, he represents
I ensure, he ensures
I enjoy, he enjoys
I receive, he receives
I seem, he
2024-07-27 05:40:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 05:43:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4580,  0.2930, -0.1219,  ...,  0.0351, -0.3982,  0.0334],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1641, -2.1543, -2.9688,  ...,  0.9688, -5.4766, -1.4746],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0110,  0.0392, -0.0084,  ..., -0.0074,  0.0135, -0.0007],
        [-0.0080, -0.0056, -0.0104,  ..., -0.0163,  0.0194, -0.0183],
        [ 0.0174,  0.0307,  0.0129,  ...,  0.0027, -0.0429, -0.0039],
        ...,
        [-0.0046,  0.0453, -0.0185,  ...,  0.0168, -0.0145, -0.0101],
        [-0.0133, -0.0257, -0.0518,  ..., -0.0457,  0.0434, -0.0511],
        [ 0.0893,  0.0271, -0.0048,  ...,  0.0487, -0.0980, -0.0294]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3789, -2.7969, -3.3555,  ...,  1.1660, -6.3125, -1.2402]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 05:43:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I hear, he hears
I develop, he develops
I exist, he exists
I represent, he represents
I ensure, he ensures
I enjoy, he enjoys
I receive, he receives
I seem, he
2024-07-27 05:43:14 root INFO     [order_1_approx] starting weight calculation for I seem, he seems
I receive, he receives
I ensure, he ensures
I represent, he represents
I hear, he hears
I enjoy, he enjoys
I exist, he exists
I develop, he
2024-07-27 05:43:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 05:45:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0888,  0.2883,  0.0555,  ..., -0.1111, -0.2725,  0.0630],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6445e+00, -4.6094e+00,  1.9531e-03,  ..., -9.0820e-02,
        -6.6562e+00,  8.7891e-02], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0127,  0.0049,  0.0009,  ...,  0.0259, -0.0033,  0.0230],
        [-0.0253,  0.0245, -0.0142,  ..., -0.0057,  0.0126, -0.0005],
        [ 0.0016, -0.0110, -0.0053,  ...,  0.0047, -0.0276,  0.0102],
        ...,
        [ 0.0110, -0.0024,  0.0179,  ...,  0.0205,  0.0082,  0.0094],
        [ 0.0121, -0.0247,  0.0093,  ..., -0.0266, -0.0217, -0.0205],
        [ 0.0068, -0.0056, -0.0025,  ..., -0.0053, -0.0062, -0.0034]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5371, -4.4492, -0.0674,  ...,  0.5298, -6.9180, -0.3865]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 05:45:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I seem, he seems
I receive, he receives
I ensure, he ensures
I represent, he represents
I hear, he hears
I enjoy, he enjoys
I exist, he exists
I develop, he
2024-07-27 05:45:58 root INFO     [order_1_approx] starting weight calculation for I hear, he hears
I exist, he exists
I represent, he represents
I seem, he seems
I receive, he receives
I enjoy, he enjoys
I develop, he develops
I ensure, he
2024-07-27 05:45:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 05:48:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0931,  0.3955, -0.1753,  ..., -0.0135, -0.2261, -0.1282],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7656, -3.3047, -0.9941,  ...,  0.0303, -7.5820, -0.9941],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0123, -0.0017,  0.0346,  ...,  0.0374, -0.0280,  0.0153],
        [-0.0176,  0.0039,  0.0133,  ..., -0.0179,  0.0160,  0.0055],
        [-0.0095,  0.0205,  0.0063,  ..., -0.0079, -0.0446,  0.0012],
        ...,
        [ 0.0054, -0.0012,  0.0200,  ..., -0.0118, -0.0013,  0.0224],
        [ 0.0084, -0.0015,  0.0396,  ..., -0.0299, -0.0034,  0.0131],
        [ 0.0232,  0.0282,  0.0235,  ..., -0.0142, -0.0243,  0.0004]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.2461, -3.5352, -1.4160,  ..., -0.1396, -7.9062, -1.1152]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 05:48:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I hear, he hears
I exist, he exists
I represent, he represents
I seem, he seems
I receive, he receives
I enjoy, he enjoys
I develop, he develops
I ensure, he
2024-07-27 05:48:44 root INFO     [order_1_approx] starting weight calculation for I seem, he seems
I ensure, he ensures
I develop, he develops
I exist, he exists
I represent, he represents
I enjoy, he enjoys
I hear, he hears
I receive, he
2024-07-27 05:48:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 05:51:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1326,  0.1862, -0.1387,  ..., -0.3760, -0.2128, -0.1605],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7881, -2.1621, -3.1250,  ..., -2.4219, -6.4531, -2.2988],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0087,  0.0076,  0.0096,  ..., -0.0126, -0.0210,  0.0179],
        [-0.0293,  0.0506,  0.0001,  ...,  0.0006,  0.0201, -0.0111],
        [ 0.0111,  0.0081,  0.0036,  ..., -0.0061, -0.0027, -0.0278],
        ...,
        [ 0.0218,  0.0343,  0.0026,  ...,  0.0254,  0.0081, -0.0099],
        [ 0.0273,  0.0095,  0.0338,  ..., -0.0129,  0.0311, -0.0477],
        [ 0.0079, -0.0011, -0.0027,  ..., -0.0255,  0.0051, -0.0116]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9917, -2.2695, -2.7383,  ..., -1.5195, -6.5117, -2.5410]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 05:51:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I seem, he seems
I ensure, he ensures
I develop, he develops
I exist, he exists
I represent, he represents
I enjoy, he enjoys
I hear, he hears
I receive, he
2024-07-27 05:51:29 root INFO     [order_1_approx] starting weight calculation for I hear, he hears
I develop, he develops
I receive, he receives
I exist, he exists
I ensure, he ensures
I seem, he seems
I enjoy, he enjoys
I represent, he
2024-07-27 05:51:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 05:54:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0741,  0.4717, -0.2014,  ...,  0.0287, -0.1149, -0.2625],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2500, -2.9570,  0.6582,  ..., -0.9639, -7.1250,  0.3926],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0344,  0.0142,  0.0119,  ...,  0.0184, -0.0248,  0.0164],
        [-0.0391, -0.0020, -0.0070,  ..., -0.0159,  0.0381, -0.0042],
        [ 0.0083,  0.0226,  0.0331,  ..., -0.0199, -0.0311,  0.0064],
        ...,
        [-0.0072,  0.0058,  0.0021,  ..., -0.0075, -0.0155, -0.0167],
        [ 0.0062, -0.0370, -0.0185,  ..., -0.0254,  0.0298, -0.0187],
        [ 0.0018, -0.0224, -0.0057,  ..., -0.0047, -0.0080,  0.0031]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4912, -3.3086,  0.5586,  ..., -0.7881, -8.3203,  0.0693]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 05:54:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I hear, he hears
I develop, he develops
I receive, he receives
I exist, he exists
I ensure, he ensures
I seem, he seems
I enjoy, he enjoys
I represent, he
2024-07-27 05:54:14 root INFO     total operator prediction time: 1320.966959953308 seconds
2024-07-27 05:54:14 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_Ving - 3pSg
2024-07-27 05:54:14 root INFO     building operator verb_Ving - 3pSg
2024-07-27 05:54:14 root INFO     [order_1_approx] starting weight calculation for When something is telling, it tells
When something is occurring, it occurs
When something is involving, it involves
When something is sitting, it sits
When something is publishing, it publishes
When something is existing, it exists
When something is discovering, it discovers
When something is hearing, it
2024-07-27 05:54:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 05:56:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1831,  0.2286, -0.0249,  ...,  0.0717,  0.0928, -0.0375],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4590, -3.2656, -0.3086,  ..., -1.8223, -5.4922, -3.3789],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0351,  0.0162,  0.0164,  ..., -0.0120,  0.0194, -0.0314],
        [-0.0150,  0.0474,  0.0131,  ..., -0.0140, -0.0129, -0.0060],
        [ 0.0062, -0.0086,  0.0341,  ..., -0.0080, -0.0095,  0.0086],
        ...,
        [ 0.0306,  0.0036,  0.0170,  ...,  0.0270,  0.0146,  0.0081],
        [ 0.0423, -0.0240, -0.0211,  ..., -0.0179,  0.0467, -0.0171],
        [-0.0061,  0.0079,  0.0079,  ..., -0.0065,  0.0057,  0.0086]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2546, -3.9609, -0.3677,  ..., -1.8867, -5.0859, -3.6309]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 05:57:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is telling, it tells
When something is occurring, it occurs
When something is involving, it involves
When something is sitting, it sits
When something is publishing, it publishes
When something is existing, it exists
When something is discovering, it discovers
When something is hearing, it
2024-07-27 05:57:01 root INFO     [order_1_approx] starting weight calculation for When something is discovering, it discovers
When something is involving, it involves
When something is telling, it tells
When something is occurring, it occurs
When something is sitting, it sits
When something is publishing, it publishes
When something is hearing, it hears
When something is existing, it
2024-07-27 05:57:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 05:59:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0776,  0.2932, -0.0426,  ..., -0.1721, -0.1938, -0.3601],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1426, -2.9961, -0.6992,  ..., -0.5498, -4.7031,  0.1377],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0209, -0.0058, -0.0050,  ...,  0.0129,  0.0559, -0.0043],
        [-0.0266,  0.0292, -0.0024,  ...,  0.0113, -0.0034, -0.0286],
        [-0.0093, -0.0168,  0.0105,  ..., -0.0061, -0.0172, -0.0023],
        ...,
        [ 0.0112,  0.0386, -0.0388,  ...,  0.0613,  0.0148, -0.0018],
        [-0.0049, -0.0262,  0.0090,  ..., -0.0297,  0.0220,  0.0012],
        [-0.0275,  0.0219,  0.0212,  ...,  0.0301, -0.0245, -0.0098]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6035, -3.1797, -0.9668,  ...,  0.4238, -4.8555, -0.1167]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 05:59:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is discovering, it discovers
When something is involving, it involves
When something is telling, it tells
When something is occurring, it occurs
When something is sitting, it sits
When something is publishing, it publishes
When something is hearing, it hears
When something is existing, it
2024-07-27 05:59:47 root INFO     [order_1_approx] starting weight calculation for When something is occurring, it occurs
When something is sitting, it sits
When something is telling, it tells
When something is hearing, it hears
When something is publishing, it publishes
When something is existing, it exists
When something is discovering, it discovers
When something is involving, it
2024-07-27 05:59:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 06:02:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0657,  0.1438,  0.0710,  ...,  0.0345, -0.4160, -0.1296],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8926, -0.9204,  2.4375,  ..., -0.3057, -3.3926, -3.1992],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0153,  0.0263, -0.0089,  ...,  0.0204, -0.0141, -0.0053],
        [-0.0130,  0.0259,  0.0249,  ..., -0.0255, -0.0330,  0.0147],
        [-0.0151, -0.0012,  0.0130,  ..., -0.0105, -0.0053, -0.0146],
        ...,
        [ 0.0339,  0.0361, -0.0280,  ...,  0.0191, -0.0150, -0.0132],
        [-0.0441, -0.0292, -0.0064,  ..., -0.0313, -0.0068, -0.0408],
        [-0.0018,  0.0181,  0.0244,  ..., -0.0100, -0.0502, -0.0051]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7803, -2.1133,  2.2559,  ..., -0.3940, -3.8496, -3.3730]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 06:02:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is occurring, it occurs
When something is sitting, it sits
When something is telling, it tells
When something is hearing, it hears
When something is publishing, it publishes
When something is existing, it exists
When something is discovering, it discovers
When something is involving, it
2024-07-27 06:02:35 root INFO     [order_1_approx] starting weight calculation for When something is involving, it involves
When something is existing, it exists
When something is hearing, it hears
When something is discovering, it discovers
When something is sitting, it sits
When something is telling, it tells
When something is publishing, it publishes
When something is occurring, it
2024-07-27 06:02:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 06:05:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1587,  0.0795,  0.0674,  ..., -0.0771, -0.0222, -0.3740],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1748, -4.3008, -0.8340,  ..., -1.4814, -3.4102,  1.2793],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0197,  0.0299,  0.0071,  ...,  0.0127,  0.0443,  0.0267],
        [ 0.0081,  0.0321,  0.0115,  ...,  0.0213, -0.0056,  0.0079],
        [-0.0086, -0.0145, -0.0115,  ..., -0.0082, -0.0284, -0.0305],
        ...,
        [ 0.0228, -0.0069, -0.0019,  ...,  0.0128, -0.0269,  0.0165],
        [ 0.0211, -0.0112, -0.0079,  ..., -0.0349, -0.0291, -0.0265],
        [-0.0398,  0.0385,  0.0201,  ...,  0.0142,  0.0132,  0.0027]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1826, -4.1172, -1.2744,  ..., -1.2949, -3.9316,  0.7012]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 06:05:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is involving, it involves
When something is existing, it exists
When something is hearing, it hears
When something is discovering, it discovers
When something is sitting, it sits
When something is telling, it tells
When something is publishing, it publishes
When something is occurring, it
2024-07-27 06:05:20 root INFO     [order_1_approx] starting weight calculation for When something is sitting, it sits
When something is occurring, it occurs
When something is hearing, it hears
When something is existing, it exists
When something is publishing, it publishes
When something is involving, it involves
When something is discovering, it discovers
When something is telling, it
2024-07-27 06:05:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 06:08:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2817,  0.0399,  0.1600,  ...,  0.1284, -0.0858, -0.1388],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1484, -1.5176,  1.2324,  ...,  1.5645, -8.3125, -0.5117],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0232, -0.0042, -0.0021,  ..., -0.0021, -0.0093,  0.0251],
        [-0.0185,  0.0242,  0.0160,  ..., -0.0304, -0.0165, -0.0146],
        [ 0.0037, -0.0157,  0.0021,  ..., -0.0020,  0.0026,  0.0193],
        ...,
        [ 0.0210,  0.0084,  0.0079,  ...,  0.0377,  0.0095,  0.0014],
        [ 0.0021,  0.0104, -0.0112,  ..., -0.0158,  0.0415, -0.0217],
        [ 0.0007,  0.0202,  0.0020,  ...,  0.0176, -0.0007,  0.0091]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2969, -1.7520,  1.2207,  ...,  1.4043, -8.9297, -0.8877]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 06:08:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is sitting, it sits
When something is occurring, it occurs
When something is hearing, it hears
When something is existing, it exists
When something is publishing, it publishes
When something is involving, it involves
When something is discovering, it discovers
When something is telling, it
2024-07-27 06:08:03 root INFO     [order_1_approx] starting weight calculation for When something is involving, it involves
When something is discovering, it discovers
When something is hearing, it hears
When something is sitting, it sits
When something is occurring, it occurs
When something is existing, it exists
When something is telling, it tells
When something is publishing, it
2024-07-27 06:08:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 06:10:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0779,  0.1180,  0.1425,  ...,  0.0192,  0.0388,  0.0881],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2852, -3.4199, -0.5244,  ...,  0.2358, -8.3125,  0.2949],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0242,  0.0049,  0.0084,  ...,  0.0486,  0.0183, -0.0151],
        [-0.0448,  0.0779,  0.0324,  ...,  0.0332,  0.0776, -0.0297],
        [ 0.0018,  0.0241,  0.0433,  ...,  0.0510,  0.0299, -0.0233],
        ...,
        [ 0.0125,  0.0378,  0.0293,  ...,  0.0820,  0.0289, -0.0396],
        [ 0.0264, -0.0345, -0.0166,  ..., -0.0835, -0.0122,  0.0022],
        [ 0.0406,  0.0437,  0.0087,  ...,  0.0239, -0.0346, -0.0235]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8047, -2.9590,  0.6016,  ...,  0.8325, -9.4219,  0.3359]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 06:10:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is involving, it involves
When something is discovering, it discovers
When something is hearing, it hears
When something is sitting, it sits
When something is occurring, it occurs
When something is existing, it exists
When something is telling, it tells
When something is publishing, it
2024-07-27 06:10:49 root INFO     [order_1_approx] starting weight calculation for When something is existing, it exists
When something is publishing, it publishes
When something is involving, it involves
When something is hearing, it hears
When something is sitting, it sits
When something is occurring, it occurs
When something is telling, it tells
When something is discovering, it
2024-07-27 06:10:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 06:13:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1826,  0.1926, -0.0851,  ..., -0.1240, -0.2493, -0.1555],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6426, -3.8652,  1.7188,  ..., -0.4912, -5.3047,  1.3203],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0069, -0.0012, -0.0033,  ...,  0.0094,  0.0207, -0.0015],
        [ 0.0212,  0.0262, -0.0043,  ...,  0.0166, -0.0035,  0.0120],
        [-0.0105, -0.0113, -0.0132,  ..., -0.0012,  0.0002, -0.0237],
        ...,
        [ 0.0428,  0.0198, -0.0041,  ...,  0.0320, -0.0011,  0.0113],
        [-0.0011, -0.0243, -0.0075,  ..., -0.0371, -0.0128, -0.0314],
        [-0.0097,  0.0091,  0.0532,  ..., -0.0118, -0.0292, -0.0042]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8281, -4.0312,  1.7471,  ..., -0.4756, -5.6406,  1.2549]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 06:13:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is existing, it exists
When something is publishing, it publishes
When something is involving, it involves
When something is hearing, it hears
When something is sitting, it sits
When something is occurring, it occurs
When something is telling, it tells
When something is discovering, it
2024-07-27 06:13:35 root INFO     [order_1_approx] starting weight calculation for When something is publishing, it publishes
When something is occurring, it occurs
When something is involving, it involves
When something is existing, it exists
When something is hearing, it hears
When something is discovering, it discovers
When something is telling, it tells
When something is sitting, it
2024-07-27 06:13:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 06:16:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0410,  0.1295, -0.0660,  ...,  0.0888, -0.1464, -0.0599],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9062, -3.5391, -1.0312,  ..., -3.8359, -2.8438, -1.5215],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0187, -0.0315, -0.0060,  ...,  0.0101,  0.0185, -0.0085],
        [-0.0005,  0.0222,  0.0144,  ..., -0.0249,  0.0147, -0.0140],
        [-0.0043,  0.0031,  0.0582,  ...,  0.0061, -0.0360,  0.0122],
        ...,
        [-0.0158,  0.0158, -0.0161,  ...,  0.0632,  0.0322,  0.0026],
        [-0.0082, -0.0193, -0.0113,  ..., -0.0073,  0.0380, -0.0161],
        [ 0.0026,  0.0275,  0.0176,  ..., -0.0269, -0.0206,  0.0001]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9980, -4.1914, -1.5889,  ..., -2.7578, -2.9531, -1.8545]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 06:16:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is publishing, it publishes
When something is occurring, it occurs
When something is involving, it involves
When something is existing, it exists
When something is hearing, it hears
When something is discovering, it discovers
When something is telling, it tells
When something is sitting, it
2024-07-27 06:16:19 root INFO     total operator prediction time: 1325.2128479480743 seconds
2024-07-27 06:16:19 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun - plural_reg
2024-07-27 06:16:19 root INFO     building operator noun - plural_reg
2024-07-27 06:16:19 root INFO     [order_1_approx] starting weight calculation for The plural form of student is students
The plural form of population is populations
The plural form of street is streets
The plural form of department is departments
The plural form of problem is problems
The plural form of period is periods
The plural form of hour is hours
The plural form of role is
2024-07-27 06:16:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 06:19:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1560, -0.1442,  0.1249,  ..., -0.1193, -0.1907,  0.0615],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.6865, -2.4961,  0.0684,  ..., -2.9668,  0.3213, -4.2148],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0864, -0.0304, -0.0201,  ..., -0.0078, -0.0391, -0.0321],
        [ 0.0084,  0.0384, -0.0096,  ..., -0.0089, -0.0255, -0.0341],
        [ 0.0020, -0.0189, -0.0150,  ...,  0.0145, -0.0111, -0.0002],
        ...,
        [ 0.0138, -0.0060, -0.0311,  ...,  0.0650, -0.0195, -0.0122],
        [-0.0183, -0.0124, -0.0600,  ...,  0.0056,  0.0548, -0.0063],
        [ 0.0516,  0.0110, -0.0101,  ..., -0.0165, -0.0102,  0.0275]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.7041, -2.8867,  0.0258,  ..., -2.9512,  0.8047, -4.3398]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 06:19:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of student is students
The plural form of population is populations
The plural form of street is streets
The plural form of department is departments
The plural form of problem is problems
The plural form of period is periods
The plural form of hour is hours
The plural form of role is
2024-07-27 06:19:02 root INFO     [order_1_approx] starting weight calculation for The plural form of street is streets
The plural form of department is departments
The plural form of student is students
The plural form of hour is hours
The plural form of problem is problems
The plural form of role is roles
The plural form of period is periods
The plural form of population is
2024-07-27 06:19:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 06:21:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2070, -0.0836,  0.2090,  ..., -0.1512,  0.0481,  0.1904],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1484, -3.4082,  0.8281,  ..., -1.4561, -2.4609, -1.9004],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0349,  0.0102, -0.0343,  ...,  0.0132, -0.0406, -0.0099],
        [ 0.0381,  0.0107, -0.0146,  ...,  0.0366, -0.0181,  0.0166],
        [-0.0050,  0.0264, -0.0067,  ..., -0.0268, -0.0343,  0.0018],
        ...,
        [ 0.0303, -0.0249, -0.0138,  ...,  0.0313,  0.0045, -0.0022],
        [ 0.0013,  0.0145, -0.0201,  ...,  0.0021,  0.0165, -0.0245],
        [ 0.0042,  0.0078, -0.0185,  ...,  0.0145, -0.0211,  0.0220]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7754, -3.9434,  0.5410,  ..., -1.7402, -2.2266, -1.9141]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 06:21:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of street is streets
The plural form of department is departments
The plural form of student is students
The plural form of hour is hours
The plural form of problem is problems
The plural form of role is roles
The plural form of period is periods
The plural form of population is
2024-07-27 06:21:46 root INFO     [order_1_approx] starting weight calculation for The plural form of hour is hours
The plural form of street is streets
The plural form of problem is problems
The plural form of period is periods
The plural form of student is students
The plural form of population is populations
The plural form of role is roles
The plural form of department is
2024-07-27 06:21:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 06:24:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0190,  0.0283,  0.1322,  ..., -0.0140, -0.0797,  0.0040],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0449, -3.0859,  2.8867,  ..., -1.4502,  1.3330, -2.7227],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.3824e-02, -3.8147e-05, -3.5400e-02,  ..., -2.1484e-02,
         -7.1106e-03,  1.1971e-02],
        [ 1.0078e-02, -3.8948e-03, -6.0616e-03,  ..., -1.0956e-02,
         -9.3231e-03,  4.2877e-03],
        [-2.0035e-02,  2.2049e-02, -3.4332e-04,  ...,  1.1040e-02,
         -2.6581e-02,  8.3847e-03],
        ...,
        [ 1.5259e-04,  1.8356e-02, -2.4872e-03,  ...,  2.4536e-02,
          1.3733e-02,  4.1656e-03],
        [ 2.0638e-03, -7.8735e-03,  5.2643e-03,  ...,  3.1433e-02,
          4.7150e-03, -9.8724e-03],
        [ 1.7807e-02, -1.0345e-02,  6.2752e-03,  ..., -9.5901e-03,
         -1.9547e-02,  5.1422e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9570, -2.9434,  3.0293,  ..., -1.5869,  1.4834, -2.7793]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 06:24:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of hour is hours
The plural form of street is streets
The plural form of problem is problems
The plural form of period is periods
The plural form of student is students
The plural form of population is populations
The plural form of role is roles
The plural form of department is
2024-07-27 06:24:30 root INFO     [order_1_approx] starting weight calculation for The plural form of population is populations
The plural form of street is streets
The plural form of period is periods
The plural form of role is roles
The plural form of student is students
The plural form of problem is problems
The plural form of department is departments
The plural form of hour is
2024-07-27 06:24:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 06:27:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1103, -0.2227,  0.3267,  ...,  0.1982,  0.1285,  0.0078],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2505, -2.6230,  1.2500,  ..., -1.7393,  0.5190, -2.7441],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0335,  0.0002, -0.0287,  ...,  0.0030, -0.0026,  0.0122],
        [-0.0051,  0.0024, -0.0205,  ...,  0.0007, -0.0127, -0.0236],
        [ 0.0002, -0.0094,  0.0086,  ...,  0.0022, -0.0005,  0.0404],
        ...,
        [-0.0208,  0.0160,  0.0071,  ...,  0.0283,  0.0032, -0.0043],
        [-0.0082,  0.0357, -0.0034,  ...,  0.0261,  0.0184, -0.0703],
        [ 0.0062, -0.0195, -0.0065,  ...,  0.0115, -0.0169,  0.0321]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4043, -2.4805,  1.3467,  ..., -2.0586,  0.1836, -2.4453]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 06:27:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of population is populations
The plural form of street is streets
The plural form of period is periods
The plural form of role is roles
The plural form of student is students
The plural form of problem is problems
The plural form of department is departments
The plural form of hour is
2024-07-27 06:27:15 root INFO     [order_1_approx] starting weight calculation for The plural form of department is departments
The plural form of street is streets
The plural form of hour is hours
The plural form of role is roles
The plural form of student is students
The plural form of problem is problems
The plural form of population is populations
The plural form of period is
2024-07-27 06:27:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 06:29:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1278,  0.0305,  0.2296,  ..., -0.0709, -0.2325, -0.0061],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3123, -3.1152,  1.7441,  ..., -0.6377, -0.2944, -1.0312],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0329, -0.0175,  0.0046,  ..., -0.0016,  0.0091,  0.0171],
        [-0.0071,  0.0612,  0.0047,  ..., -0.0030, -0.0097,  0.0237],
        [-0.0243, -0.0103,  0.0343,  ...,  0.0055, -0.0134, -0.0025],
        ...,
        [ 0.0224,  0.0580,  0.0125,  ...,  0.0697, -0.0154,  0.0194],
        [-0.0125, -0.0208, -0.0093,  ...,  0.0235,  0.0106, -0.0107],
        [ 0.0064,  0.0150, -0.0178,  ...,  0.0244, -0.0069,  0.0131]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6440, -3.3223,  1.2090,  ..., -0.7319, -0.0585, -1.1982]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 06:29:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of department is departments
The plural form of street is streets
The plural form of hour is hours
The plural form of role is roles
The plural form of student is students
The plural form of problem is problems
The plural form of population is populations
The plural form of period is
2024-07-27 06:30:00 root INFO     [order_1_approx] starting weight calculation for The plural form of role is roles
The plural form of department is departments
The plural form of problem is problems
The plural form of student is students
The plural form of population is populations
The plural form of hour is hours
The plural form of period is periods
The plural form of street is
2024-07-27 06:30:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 06:32:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1453,  0.0157,  0.1741,  ..., -0.0151, -0.0234,  0.2166],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7041, -3.8477, -0.7666,  ...,  0.8252,  0.0437, -2.5508],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.7231e-02,  3.8147e-06, -3.3905e-02,  ...,  1.6510e-02,
         -1.5358e-02,  2.2003e-02],
        [ 1.9257e-02,  2.5177e-02, -1.9257e-02,  ...,  8.1482e-03,
         -2.6382e-02, -4.6921e-03],
        [-1.3298e-02, -6.5613e-03,  1.3557e-02,  ...,  1.3428e-02,
          5.6801e-03,  2.2278e-02],
        ...,
        [-1.5190e-02, -1.5717e-03,  1.2436e-02,  ...,  1.3115e-02,
         -1.0513e-02,  8.9264e-03],
        [-2.7924e-02, -1.9363e-02, -5.5756e-02,  ...,  3.8544e-02,
          4.1565e-02, -3.0792e-02],
        [-4.3716e-03, -1.0864e-02, -1.1078e-02,  ...,  1.7380e-02,
         -2.4506e-02, -6.7215e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4893, -4.7734, -0.1548,  ...,  0.8169,  0.1115, -2.4590]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 06:32:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of role is roles
The plural form of department is departments
The plural form of problem is problems
The plural form of student is students
The plural form of population is populations
The plural form of hour is hours
The plural form of period is periods
The plural form of street is
2024-07-27 06:32:44 root INFO     [order_1_approx] starting weight calculation for The plural form of street is streets
The plural form of hour is hours
The plural form of problem is problems
The plural form of role is roles
The plural form of department is departments
The plural form of period is periods
The plural form of population is populations
The plural form of student is
2024-07-27 06:32:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 06:35:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3059, -0.2329, -0.1152,  ...,  0.0795, -0.2515,  0.2988],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6025, -1.3369,  2.7598,  ..., -0.3623,  0.5449, -1.5000],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0044, -0.0047, -0.0162,  ...,  0.0142,  0.0041, -0.0192],
        [ 0.0132,  0.0108,  0.0015,  ..., -0.0082, -0.0278, -0.0146],
        [ 0.0009, -0.0105, -0.0095,  ...,  0.0063, -0.0180,  0.0131],
        ...,
        [-0.0133,  0.0165, -0.0106,  ..., -0.0041,  0.0028,  0.0052],
        [-0.0062,  0.0187,  0.0066,  ...,  0.0241,  0.0068, -0.0203],
        [-0.0056, -0.0182, -0.0264,  ...,  0.0272, -0.0080, -0.0242]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5869, -1.7559,  2.6641,  ..., -0.8369,  0.5366, -1.3320]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 06:35:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of street is streets
The plural form of hour is hours
The plural form of problem is problems
The plural form of role is roles
The plural form of department is departments
The plural form of period is periods
The plural form of population is populations
The plural form of student is
2024-07-27 06:35:30 root INFO     [order_1_approx] starting weight calculation for The plural form of student is students
The plural form of department is departments
The plural form of period is periods
The plural form of hour is hours
The plural form of street is streets
The plural form of population is populations
The plural form of role is roles
The plural form of problem is
2024-07-27 06:35:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 06:38:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1954, -0.0869,  0.2229,  ..., -0.1333, -0.5439,  0.4795],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4629, -2.6758,  0.8789,  ..., -0.2017,  0.0459, -0.5215],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.6230e-02, -4.2458e-03,  1.2581e-02,  ...,  5.4359e-03,
          7.6752e-03,  9.5520e-03],
        [-1.4427e-02,  5.8022e-03, -5.8632e-03,  ...,  1.4633e-02,
         -3.0396e-02,  9.7504e-03],
        [ 7.6294e-06,  5.8594e-03, -3.7518e-03,  ..., -1.5327e-02,
         -8.9111e-03,  9.3994e-03],
        ...,
        [ 7.6294e-05,  1.4481e-02,  1.1002e-02,  ...,  2.3621e-02,
         -1.0101e-02, -1.5381e-02],
        [ 3.3016e-03, -4.6883e-03, -1.5305e-02,  ...,  1.2085e-02,
          1.4038e-02, -1.7456e-02],
        [ 8.3618e-03, -1.2909e-02,  1.0002e-02,  ...,  2.2537e-02,
         -1.3535e-02, -3.4981e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3076, -2.9648,  0.8096,  ...,  0.1484, -0.2380, -0.5654]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 06:38:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of student is students
The plural form of department is departments
The plural form of period is periods
The plural form of hour is hours
The plural form of street is streets
The plural form of population is populations
The plural form of role is roles
The plural form of problem is
2024-07-27 06:38:15 root INFO     total operator prediction time: 1316.037237405777 seconds
2024-07-27 06:38:15 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_3pSg - Ved
2024-07-27 06:38:15 root INFO     building operator verb_3pSg - Ved
2024-07-27 06:38:15 root INFO     [order_1_approx] starting weight calculation for When he develops something, something has been developed
When he relates something, something has been related
When he receives something, something has been received
When he provides something, something has been provided
When he suggests something, something has been suggested
When he becomes something, something has been became
When he performs something, something has been performed
When he establishes something, something has been
2024-07-27 06:38:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 06:40:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1733,  0.2073, -0.0754,  ...,  0.2529, -0.2991,  0.0831],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2168, -0.4341,  1.2090,  ..., -0.3633, -0.7051, -1.7695],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0009, -0.0103, -0.0052,  ..., -0.0051,  0.0022,  0.0107],
        [-0.0112,  0.0236, -0.0021,  ..., -0.0040,  0.0026,  0.0061],
        [ 0.0173,  0.0097,  0.0039,  ..., -0.0084,  0.0050,  0.0020],
        ...,
        [ 0.0025, -0.0016,  0.0019,  ..., -0.0061,  0.0151,  0.0078],
        [-0.0081,  0.0071, -0.0028,  ...,  0.0072, -0.0031, -0.0050],
        [-0.0071,  0.0009,  0.0091,  ...,  0.0159, -0.0111, -0.0092]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3428e-03, -3.8232e-01,  1.5186e+00,  ..., -1.0107e-01,
         -7.7881e-01, -1.9199e+00]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SubBackward0>) 

                    
2024-07-27 06:40:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he develops something, something has been developed
When he relates something, something has been related
When he receives something, something has been received
When he provides something, something has been provided
When he suggests something, something has been suggested
When he becomes something, something has been became
When he performs something, something has been performed
When he establishes something, something has been
2024-07-27 06:41:00 root INFO     [order_1_approx] starting weight calculation for When he establishes something, something has been established
When he receives something, something has been received
When he relates something, something has been related
When he suggests something, something has been suggested
When he performs something, something has been performed
When he provides something, something has been provided
When he becomes something, something has been became
When he develops something, something has been
2024-07-27 06:41:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 06:43:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0058, -0.1174, -0.0446,  ...,  0.0388, -0.0906, -0.0120],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3301, -1.4648,  3.9746,  ..., -1.4043, -1.4629, -1.5107],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-8.3008e-03, -6.5689e-03,  5.4741e-04,  ..., -1.0315e-02,
          5.4131e-03, -2.7275e-04],
        [-1.3489e-02,  1.7044e-02, -6.7635e-03,  ...,  7.5035e-03,
          3.6964e-03,  2.6073e-03],
        [-9.9945e-04, -3.0823e-03, -3.9482e-03,  ..., -2.6665e-03,
          3.3875e-03, -1.7197e-02],
        ...,
        [-8.4534e-03,  2.5864e-03,  2.1576e-02,  ..., -1.9836e-03,
          8.5754e-03,  8.3466e-03],
        [ 4.6539e-04, -2.9850e-03, -7.4463e-03,  ..., -3.0899e-04,
         -2.2888e-05, -2.5654e-04],
        [ 1.9417e-03,  7.9584e-04, -1.6823e-03,  ...,  1.7731e-02,
         -9.3994e-03, -8.1482e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2285, -1.4746,  3.9727,  ..., -1.5820, -1.4521, -1.6885]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 06:43:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he establishes something, something has been established
When he receives something, something has been received
When he relates something, something has been related
When he suggests something, something has been suggested
When he performs something, something has been performed
When he provides something, something has been provided
When he becomes something, something has been became
When he develops something, something has been
2024-07-27 06:43:46 root INFO     [order_1_approx] starting weight calculation for When he performs something, something has been performed
When he provides something, something has been provided
When he develops something, something has been developed
When he relates something, something has been related
When he receives something, something has been received
When he establishes something, something has been established
When he suggests something, something has been suggested
When he becomes something, something has been
2024-07-27 06:43:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 06:46:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0723,  0.1479,  0.1655,  ...,  0.1490, -0.2971, -0.0709],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8516,  2.4375,  4.4531,  ..., -0.8896,  1.0459, -1.2773],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0010,  0.0124,  0.0207,  ...,  0.0223,  0.0255,  0.0202],
        [-0.0184, -0.0108, -0.0068,  ..., -0.0316, -0.0282,  0.0029],
        [ 0.0061, -0.0131,  0.0109,  ...,  0.0175, -0.0035,  0.0167],
        ...,
        [-0.0137,  0.0185, -0.0039,  ..., -0.0115,  0.0206,  0.0039],
        [ 0.0092, -0.0027, -0.0058,  ..., -0.0441,  0.0128, -0.0143],
        [-0.0102, -0.0140, -0.0084,  ..., -0.0037, -0.0140, -0.0063]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2305,  1.7979,  4.5117,  ..., -1.1123,  0.8770, -1.5830]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 06:46:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he performs something, something has been performed
When he provides something, something has been provided
When he develops something, something has been developed
When he relates something, something has been related
When he receives something, something has been received
When he establishes something, something has been established
When he suggests something, something has been suggested
When he becomes something, something has been
2024-07-27 06:46:31 root INFO     [order_1_approx] starting weight calculation for When he relates something, something has been related
When he provides something, something has been provided
When he becomes something, something has been became
When he establishes something, something has been established
When he performs something, something has been performed
When he suggests something, something has been suggested
When he develops something, something has been developed
When he receives something, something has been
2024-07-27 06:46:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 06:49:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2693,  0.1014, -0.1312,  ..., -0.0452, -0.0921, -0.1451],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0596,  0.8203,  0.7197,  ..., -2.5039, -1.8359, -1.0723],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0162, -0.0121,  0.0193,  ..., -0.0187, -0.0027,  0.0501],
        [-0.0304,  0.0157, -0.0072,  ...,  0.0023, -0.0089, -0.0086],
        [ 0.0045,  0.0114, -0.0092,  ..., -0.0031,  0.0057, -0.0294],
        ...,
        [ 0.0171,  0.0333,  0.0167,  ...,  0.0206,  0.0100,  0.0113],
        [ 0.0015,  0.0191,  0.0045,  ..., -0.0091,  0.0374, -0.0339],
        [-0.0381,  0.0125,  0.0015,  ...,  0.0134,  0.0260,  0.0167]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.2217,  0.6924,  0.9199,  ..., -2.4453, -1.6543, -1.6514]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 06:49:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he relates something, something has been related
When he provides something, something has been provided
When he becomes something, something has been became
When he establishes something, something has been established
When he performs something, something has been performed
When he suggests something, something has been suggested
When he develops something, something has been developed
When he receives something, something has been
2024-07-27 06:49:14 root INFO     [order_1_approx] starting weight calculation for When he establishes something, something has been established
When he performs something, something has been performed
When he becomes something, something has been became
When he provides something, something has been provided
When he relates something, something has been related
When he develops something, something has been developed
When he receives something, something has been received
When he suggests something, something has been
2024-07-27 06:49:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 06:51:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0983,  0.3152,  0.1519,  ...,  0.2412, -0.2642, -0.0747],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.4922, -0.1599,  0.0604,  ...,  1.3926,  0.2488,  0.9180],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0216, -0.0093,  0.0210,  ..., -0.0352,  0.0015, -0.0030],
        [-0.0129,  0.0335, -0.0064,  ...,  0.0058,  0.0057,  0.0040],
        [ 0.0036, -0.0025, -0.0208,  ...,  0.0143,  0.0157,  0.0103],
        ...,
        [-0.0146,  0.0085,  0.0029,  ...,  0.0151,  0.0333,  0.0091],
        [ 0.0041,  0.0151,  0.0042,  ..., -0.0405, -0.0131, -0.0532],
        [ 0.0096,  0.0266,  0.0270,  ...,  0.0026, -0.0210, -0.0120]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.8477, -0.6240,  0.0983,  ...,  1.4189, -0.3899,  0.2842]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 06:51:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he establishes something, something has been established
When he performs something, something has been performed
When he becomes something, something has been became
When he provides something, something has been provided
When he relates something, something has been related
When he develops something, something has been developed
When he receives something, something has been received
When he suggests something, something has been
2024-07-27 06:52:00 root INFO     [order_1_approx] starting weight calculation for When he develops something, something has been developed
When he becomes something, something has been became
When he receives something, something has been received
When he suggests something, something has been suggested
When he provides something, something has been provided
When he performs something, something has been performed
When he establishes something, something has been established
When he relates something, something has been
2024-07-27 06:52:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 06:54:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2030,  0.2729, -0.0269,  ...,  0.1267, -0.2029, -0.0801],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.9492,  1.4219,  2.5898,  ...,  0.9336, -1.5410, -0.1641],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0052, -0.0187, -0.0157,  ..., -0.0153, -0.0118,  0.0305],
        [-0.0183,  0.0114,  0.0107,  ...,  0.0005,  0.0177, -0.0224],
        [ 0.0067, -0.0097, -0.0174,  ..., -0.0029,  0.0019, -0.0146],
        ...,
        [-0.0019, -0.0065, -0.0014,  ..., -0.0145,  0.0123,  0.0244],
        [ 0.0032,  0.0019, -0.0191,  ...,  0.0126, -0.0100, -0.0211],
        [-0.0058, -0.0118, -0.0018,  ...,  0.0175, -0.0022,  0.0094]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.5273,  1.4697,  2.7383,  ...,  0.6382, -1.7676, -0.4338]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 06:54:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he develops something, something has been developed
When he becomes something, something has been became
When he receives something, something has been received
When he suggests something, something has been suggested
When he provides something, something has been provided
When he performs something, something has been performed
When he establishes something, something has been established
When he relates something, something has been
2024-07-27 06:54:45 root INFO     [order_1_approx] starting weight calculation for When he develops something, something has been developed
When he establishes something, something has been established
When he receives something, something has been received
When he becomes something, something has been became
When he suggests something, something has been suggested
When he relates something, something has been related
When he performs something, something has been performed
When he provides something, something has been
2024-07-27 06:54:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 06:57:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1244,  0.0315, -0.0673,  ...,  0.0956, -0.1028, -0.0707],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6055, -3.3262,  1.7754,  ..., -1.1299, -2.8242, -0.5156],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0011, -0.0050,  0.0020,  ..., -0.0182,  0.0113,  0.0167],
        [-0.0070,  0.0106,  0.0248,  ...,  0.0197, -0.0053,  0.0123],
        [-0.0003, -0.0108,  0.0033,  ...,  0.0051, -0.0163, -0.0035],
        ...,
        [ 0.0047,  0.0184,  0.0106,  ...,  0.0290,  0.0171,  0.0046],
        [ 0.0313, -0.0069,  0.0026,  ..., -0.0114,  0.0014, -0.0182],
        [ 0.0015,  0.0130,  0.0005,  ...,  0.0049, -0.0284, -0.0060]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7715, -2.8867,  1.7266,  ..., -1.1406, -2.7285, -0.8633]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 06:57:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he develops something, something has been developed
When he establishes something, something has been established
When he receives something, something has been received
When he becomes something, something has been became
When he suggests something, something has been suggested
When he relates something, something has been related
When he performs something, something has been performed
When he provides something, something has been
2024-07-27 06:57:30 root INFO     [order_1_approx] starting weight calculation for When he receives something, something has been received
When he suggests something, something has been suggested
When he establishes something, something has been established
When he develops something, something has been developed
When he relates something, something has been related
When he provides something, something has been provided
When he becomes something, something has been became
When he performs something, something has been
2024-07-27 06:57:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 07:00:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1394,  0.3352, -0.0987,  ..., -0.0438, -0.1880, -0.0671],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5078, -0.8867,  5.2070,  ..., -1.6738, -2.1543, -1.3984],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.0354e-04, -1.0300e-03, -1.2627e-03,  ..., -2.1118e-02,
          2.1790e-02,  7.0801e-03],
        [-8.5449e-03,  4.0009e-02,  8.8577e-03,  ...,  1.5060e-02,
         -3.8471e-03, -3.2196e-03],
        [ 1.6174e-02,  5.7373e-03, -4.9744e-03,  ...,  1.2884e-03,
          4.1199e-04, -9.1553e-05],
        ...,
        [-1.5259e-02,  3.7918e-03, -2.2964e-02,  ..., -7.0763e-03,
          2.3666e-02, -3.4668e-02],
        [ 3.3951e-04, -2.7714e-03, -2.1839e-04,  ...,  5.5809e-03,
          1.7242e-02, -1.4633e-02],
        [-1.6556e-03,  5.6419e-03, -7.1335e-03,  ...,  7.3128e-03,
          1.0452e-02, -1.2505e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4473, -0.9292,  5.3320,  ..., -1.8037, -1.8652, -1.7363]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 07:00:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he receives something, something has been received
When he suggests something, something has been suggested
When he establishes something, something has been established
When he develops something, something has been developed
When he relates something, something has been related
When he provides something, something has been provided
When he becomes something, something has been became
When he performs something, something has been
2024-07-27 07:00:15 root INFO     total operator prediction time: 1320.3020777702332 seconds
2024-07-27 07:00:15 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj - superlative
2024-07-27 07:00:15 root INFO     building operator adj - superlative
2024-07-27 07:00:16 root INFO     [order_1_approx] starting weight calculation for If something is the most mild, it is mildest
If something is the most happy, it is happiest
If something is the most able, it is ablest
If something is the most wealthy, it is wealthiest
If something is the most sad, it is saddest
If something is the most tasty, it is tastiest
If something is the most huge, it is hugest
If something is the most sexy, it is
2024-07-27 07:00:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 07:03:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2192,  0.1263,  0.0549,  ...,  0.1093, -0.1823, -0.0495],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.8203, -3.1602, -2.7793,  ..., -0.5112, -2.5430, -3.3691],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0038, -0.0231,  0.0213,  ...,  0.0412,  0.0226,  0.0437],
        [-0.0086,  0.0201,  0.0122,  ..., -0.0412, -0.0066,  0.0035],
        [ 0.0185, -0.0184,  0.0175,  ...,  0.0176, -0.0148,  0.0135],
        ...,
        [-0.0068,  0.0236,  0.0077,  ...,  0.0138,  0.0059, -0.0459],
        [-0.0201, -0.0181, -0.0173,  ..., -0.0363,  0.0030, -0.0154],
        [ 0.0067,  0.0213,  0.0129,  ...,  0.0187, -0.0095, -0.0053]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.1680, -2.8750, -2.8398,  ..., -0.5962, -2.6934, -3.3340]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 07:03:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most mild, it is mildest
If something is the most happy, it is happiest
If something is the most able, it is ablest
If something is the most wealthy, it is wealthiest
If something is the most sad, it is saddest
If something is the most tasty, it is tastiest
If something is the most huge, it is hugest
If something is the most sexy, it is
2024-07-27 07:03:02 root INFO     [order_1_approx] starting weight calculation for If something is the most able, it is ablest
If something is the most sexy, it is sexiest
If something is the most huge, it is hugest
If something is the most wealthy, it is wealthiest
If something is the most mild, it is mildest
If something is the most tasty, it is tastiest
If something is the most sad, it is saddest
If something is the most happy, it is
2024-07-27 07:03:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 07:05:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1159,  0.0359, -0.1241,  ..., -0.2445, -0.2861, -0.1282],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5986, -3.8516, -0.9043,  ...,  1.1162, -1.8174, -0.5127],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0040, -0.0187,  0.0224,  ...,  0.0111,  0.0405, -0.0135],
        [-0.0068,  0.0032, -0.0066,  ..., -0.0101,  0.0156,  0.0048],
        [ 0.0122, -0.0335,  0.0173,  ...,  0.0168, -0.0190,  0.0028],
        ...,
        [ 0.0065, -0.0048,  0.0149,  ...,  0.0190,  0.0108, -0.0138],
        [ 0.0053, -0.0029,  0.0111,  ..., -0.0013, -0.0090,  0.0086],
        [-0.0115, -0.0154,  0.0041,  ...,  0.0205, -0.0129,  0.0043]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7124, -4.0312, -0.6919,  ...,  1.2793, -1.9795, -0.5161]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 07:05:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most able, it is ablest
If something is the most sexy, it is sexiest
If something is the most huge, it is hugest
If something is the most wealthy, it is wealthiest
If something is the most mild, it is mildest
If something is the most tasty, it is tastiest
If something is the most sad, it is saddest
If something is the most happy, it is
2024-07-27 07:05:45 root INFO     [order_1_approx] starting weight calculation for If something is the most tasty, it is tastiest
If something is the most sexy, it is sexiest
If something is the most able, it is ablest
If something is the most wealthy, it is wealthiest
If something is the most mild, it is mildest
If something is the most happy, it is happiest
If something is the most sad, it is saddest
If something is the most huge, it is
2024-07-27 07:05:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 07:08:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0112,  0.0088,  0.1659,  ...,  0.0925, -0.1443, -0.3901],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2910, -3.0137, -1.1699,  ..., -1.1855, -5.3672,  0.1387],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0022, -0.0281, -0.0138,  ...,  0.0024,  0.0137,  0.0010],
        [-0.0099, -0.0012,  0.0306,  ..., -0.0345, -0.0434,  0.0223],
        [ 0.0213, -0.0096,  0.0345,  ..., -0.0172, -0.0223,  0.0418],
        ...,
        [ 0.0142,  0.0162,  0.0357,  ...,  0.0288, -0.0197,  0.0017],
        [ 0.0432, -0.0055, -0.0141,  ...,  0.0264,  0.0362, -0.0372],
        [ 0.0141, -0.0093, -0.0150,  ...,  0.0118, -0.0136, -0.0206]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7383, -3.1465, -1.0059,  ..., -0.7344, -5.2070,  0.5186]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 07:08:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most tasty, it is tastiest
If something is the most sexy, it is sexiest
If something is the most able, it is ablest
If something is the most wealthy, it is wealthiest
If something is the most mild, it is mildest
If something is the most happy, it is happiest
If something is the most sad, it is saddest
If something is the most huge, it is
2024-07-27 07:08:27 root INFO     [order_1_approx] starting weight calculation for If something is the most happy, it is happiest
If something is the most sexy, it is sexiest
If something is the most tasty, it is tastiest
If something is the most mild, it is mildest
If something is the most huge, it is hugest
If something is the most sad, it is saddest
If something is the most wealthy, it is wealthiest
If something is the most able, it is
2024-07-27 07:08:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 07:11:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1530,  0.1541, -0.0600,  ...,  0.0350, -0.1661, -0.1788],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2656, -5.5117, -1.6143,  ...,  0.7334, -5.1641, -1.4766],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0006, -0.0080,  0.0058,  ...,  0.0034, -0.0075,  0.0040],
        [-0.0046,  0.0185, -0.0058,  ..., -0.0098, -0.0207,  0.0017],
        [-0.0056, -0.0399,  0.0269,  ..., -0.0089, -0.0137,  0.0002],
        ...,
        [-0.0123,  0.0094,  0.0223,  ...,  0.0051, -0.0040,  0.0102],
        [ 0.0030,  0.0110,  0.0184,  ..., -0.0177,  0.0228, -0.0270],
        [ 0.0064,  0.0002, -0.0123,  ...,  0.0149,  0.0230, -0.0155]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4873, -5.4258, -1.6113,  ...,  0.9434, -5.2969, -1.4014]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 07:11:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most happy, it is happiest
If something is the most sexy, it is sexiest
If something is the most tasty, it is tastiest
If something is the most mild, it is mildest
If something is the most huge, it is hugest
If something is the most sad, it is saddest
If something is the most wealthy, it is wealthiest
If something is the most able, it is
2024-07-27 07:11:05 root INFO     [order_1_approx] starting weight calculation for If something is the most mild, it is mildest
If something is the most sad, it is saddest
If something is the most happy, it is happiest
If something is the most huge, it is hugest
If something is the most wealthy, it is wealthiest
If something is the most able, it is ablest
If something is the most sexy, it is sexiest
If something is the most tasty, it is
2024-07-27 07:11:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 07:13:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0791,  0.1514, -0.0330,  ..., -0.1476, -0.3701, -0.3359],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9580, -4.8750, -3.7070,  ...,  0.4565, -6.8672, -1.4746],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0045, -0.0110,  0.0066,  ...,  0.0007,  0.0023,  0.0125],
        [-0.0014,  0.0202,  0.0040,  ..., -0.0124, -0.0072,  0.0109],
        [ 0.0045, -0.0234,  0.0011,  ...,  0.0083, -0.0185, -0.0204],
        ...,
        [ 0.0152,  0.0290,  0.0045,  ...,  0.0261, -0.0045, -0.0160],
        [ 0.0059, -0.0196,  0.0048,  ..., -0.0174, -0.0055,  0.0042],
        [-0.0015,  0.0289, -0.0043,  ...,  0.0075, -0.0071, -0.0075]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9692, -4.9531, -3.9805,  ...,  0.5688, -6.7539, -1.2773]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 07:13:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most mild, it is mildest
If something is the most sad, it is saddest
If something is the most happy, it is happiest
If something is the most huge, it is hugest
If something is the most wealthy, it is wealthiest
If something is the most able, it is ablest
If something is the most sexy, it is sexiest
If something is the most tasty, it is
2024-07-27 07:13:52 root INFO     [order_1_approx] starting weight calculation for If something is the most able, it is ablest
If something is the most happy, it is happiest
If something is the most mild, it is mildest
If something is the most sexy, it is sexiest
If something is the most tasty, it is tastiest
If something is the most wealthy, it is wealthiest
If something is the most huge, it is hugest
If something is the most sad, it is
2024-07-27 07:13:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 07:16:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1848,  0.0299, -0.1923,  ..., -0.0006, -0.2969,  0.0271],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5898, -5.9062, -2.7109,  ..., -5.0742, -0.3828, -2.3672],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0073, -0.0128,  0.0232,  ..., -0.0020, -0.0105, -0.0095],
        [ 0.0162, -0.0032,  0.0245,  ..., -0.0095,  0.0135,  0.0157],
        [ 0.0070, -0.0025,  0.0106,  ..., -0.0054, -0.0149, -0.0137],
        ...,
        [-0.0173, -0.0149,  0.0139,  ...,  0.0301, -0.0125,  0.0031],
        [-0.0249,  0.0025,  0.0147,  ..., -0.0083,  0.0319, -0.0249],
        [ 0.0119, -0.0051, -0.0169,  ..., -0.0098, -0.0201, -0.0104]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2041, -6.0742, -2.2188,  ..., -4.3750,  0.0679, -2.2852]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 07:16:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most able, it is ablest
If something is the most happy, it is happiest
If something is the most mild, it is mildest
If something is the most sexy, it is sexiest
If something is the most tasty, it is tastiest
If something is the most wealthy, it is wealthiest
If something is the most huge, it is hugest
If something is the most sad, it is
2024-07-27 07:16:39 root INFO     [order_1_approx] starting weight calculation for If something is the most sexy, it is sexiest
If something is the most sad, it is saddest
If something is the most able, it is ablest
If something is the most happy, it is happiest
If something is the most huge, it is hugest
If something is the most mild, it is mildest
If something is the most tasty, it is tastiest
If something is the most wealthy, it is
2024-07-27 07:16:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 07:19:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1847,  0.1985, -0.1561,  ...,  0.1044, -0.0312, -0.0947],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6582, -4.8867, -2.9414,  ..., -1.8174, -2.5039, -0.3223],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0049, -0.0150,  0.0044,  ...,  0.0137, -0.0014,  0.0168],
        [ 0.0058,  0.0200,  0.0049,  ..., -0.0018,  0.0066, -0.0060],
        [ 0.0095, -0.0083, -0.0014,  ...,  0.0098, -0.0060, -0.0027],
        ...,
        [ 0.0062, -0.0047,  0.0111,  ...,  0.0089, -0.0221,  0.0147],
        [ 0.0038,  0.0040, -0.0026,  ...,  0.0050,  0.0120,  0.0036],
        [-0.0045, -0.0008,  0.0088,  ...,  0.0207,  0.0061, -0.0002]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5420, -4.8164, -3.0703,  ..., -1.5703, -2.6797, -0.0740]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 07:19:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most sexy, it is sexiest
If something is the most sad, it is saddest
If something is the most able, it is ablest
If something is the most happy, it is happiest
If something is the most huge, it is hugest
If something is the most mild, it is mildest
If something is the most tasty, it is tastiest
If something is the most wealthy, it is
2024-07-27 07:19:19 root INFO     [order_1_approx] starting weight calculation for If something is the most tasty, it is tastiest
If something is the most sad, it is saddest
If something is the most sexy, it is sexiest
If something is the most huge, it is hugest
If something is the most happy, it is happiest
If something is the most wealthy, it is wealthiest
If something is the most able, it is ablest
If something is the most mild, it is
2024-07-27 07:19:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 07:22:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0983,  0.1376,  0.0187,  ..., -0.1337, -0.0343, -0.1514],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0537, -2.2051, -1.0977,  ..., -1.3867, -2.8672, -1.7012],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0166, -0.0086, -0.0039,  ...,  0.0044, -0.0151, -0.0164],
        [-0.0037,  0.0129,  0.0074,  ...,  0.0188, -0.0026,  0.0109],
        [ 0.0273, -0.0226,  0.0290,  ...,  0.0286, -0.0159,  0.0153],
        ...,
        [ 0.0157,  0.0231, -0.0012,  ...,  0.0561,  0.0253, -0.0289],
        [-0.0104, -0.0128,  0.0089,  ..., -0.0053,  0.0402, -0.0270],
        [ 0.0267,  0.0027,  0.0202,  ...,  0.0129, -0.0041, -0.0086]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8774, -2.7246, -0.7002,  ..., -0.8789, -2.4551, -1.8359]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 07:22:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most tasty, it is tastiest
If something is the most sad, it is saddest
If something is the most sexy, it is sexiest
If something is the most huge, it is hugest
If something is the most happy, it is happiest
If something is the most wealthy, it is wealthiest
If something is the most able, it is ablest
If something is the most mild, it is
2024-07-27 07:22:03 root INFO     total operator prediction time: 1307.2753472328186 seconds
2024-07-27 07:22:03 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+er_irreg
2024-07-27 07:22:03 root INFO     building operator verb+er_irreg
2024-07-27 07:22:03 root INFO     [order_1_approx] starting weight calculation for If you preach something, you are a preacher
If you entertain something, you are a entertainer
If you lose something, you are a loser
If you listen something, you are a listener
If you announce something, you are a announcer
If you perform something, you are a performer
If you receive something, you are a receiver
If you choreograph something, you are a
2024-07-27 07:22:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 07:24:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0400,  0.3213, -0.0475,  ...,  0.0807, -0.3320, -0.1021],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9565, -3.1309,  2.7754,  ..., -1.8604, -2.9316, -1.2158],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0275, -0.0146,  0.0073,  ..., -0.0027,  0.0255, -0.0055],
        [-0.0146,  0.0403, -0.0149,  ...,  0.0206,  0.0141, -0.0016],
        [-0.0107, -0.0096,  0.0145,  ..., -0.0134,  0.0019, -0.0046],
        ...,
        [ 0.0196,  0.0073, -0.0009,  ...,  0.0203,  0.0026, -0.0131],
        [ 0.0022,  0.0139, -0.0209,  ..., -0.0286,  0.0037,  0.0013],
        [-0.0021,  0.0061,  0.0232,  ..., -0.0128, -0.0048,  0.0322]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4866, -3.3789,  2.9512,  ..., -1.8594, -2.8867, -1.1221]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 07:24:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you preach something, you are a preacher
If you entertain something, you are a entertainer
If you lose something, you are a loser
If you listen something, you are a listener
If you announce something, you are a announcer
If you perform something, you are a performer
If you receive something, you are a receiver
If you choreograph something, you are a
2024-07-27 07:24:45 root INFO     [order_1_approx] starting weight calculation for If you choreograph something, you are a choreographer
If you entertain something, you are a entertainer
If you listen something, you are a listener
If you perform something, you are a performer
If you lose something, you are a loser
If you announce something, you are a announcer
If you receive something, you are a receiver
If you preach something, you are a
2024-07-27 07:24:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 07:27:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0006,  0.1833,  0.1206,  ..., -0.1329, -0.2390,  0.0982],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.5977, -5.2188,  4.2578,  ...,  0.5186, -2.0508, -1.1914],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0380, -0.0026,  0.0195,  ...,  0.0018,  0.0143, -0.0057],
        [-0.0076,  0.0511,  0.0095,  ...,  0.0087,  0.0321,  0.0039],
        [-0.0206,  0.0096,  0.0319,  ...,  0.0213, -0.0030,  0.0198],
        ...,
        [ 0.0044,  0.0091, -0.0007,  ...,  0.0611,  0.0237, -0.0077],
        [ 0.0094, -0.0129, -0.0056,  ...,  0.0037, -0.0064, -0.0087],
        [ 0.0065,  0.0207, -0.0027,  ..., -0.0061, -0.0065,  0.0261]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.4375, -5.4141,  4.1680,  ...,  0.5654, -2.0195, -1.2520]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 07:27:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you choreograph something, you are a choreographer
If you entertain something, you are a entertainer
If you listen something, you are a listener
If you perform something, you are a performer
If you lose something, you are a loser
If you announce something, you are a announcer
If you receive something, you are a receiver
If you preach something, you are a
2024-07-27 07:27:27 root INFO     [order_1_approx] starting weight calculation for If you lose something, you are a loser
If you preach something, you are a preacher
If you announce something, you are a announcer
If you choreograph something, you are a choreographer
If you perform something, you are a performer
If you listen something, you are a listener
If you entertain something, you are a entertainer
If you receive something, you are a
2024-07-27 07:27:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 07:30:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1205,  0.1434, -0.1647,  ..., -0.1453, -0.0650, -0.1177],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6426,  0.4980, -1.4297,  ..., -2.0879, -3.2148, -2.8398],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0021,  0.0084,  0.0146,  ...,  0.0008,  0.0057, -0.0086],
        [-0.0467,  0.0332,  0.0176,  ...,  0.0105, -0.0014,  0.0078],
        [-0.0008,  0.0057, -0.0009,  ..., -0.0058,  0.0208,  0.0056],
        ...,
        [ 0.0387,  0.0116, -0.0101,  ...,  0.0224, -0.0144,  0.0039],
        [ 0.0004,  0.0143, -0.0042,  ..., -0.0152,  0.0408,  0.0093],
        [ 0.0010,  0.0265, -0.0059,  ..., -0.0034,  0.0127, -0.0043]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7617,  0.4570, -1.4043,  ..., -1.4922, -3.3320, -2.7910]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 07:30:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you lose something, you are a loser
If you preach something, you are a preacher
If you announce something, you are a announcer
If you choreograph something, you are a choreographer
If you perform something, you are a performer
If you listen something, you are a listener
If you entertain something, you are a entertainer
If you receive something, you are a
2024-07-27 07:30:10 root INFO     [order_1_approx] starting weight calculation for If you preach something, you are a preacher
If you receive something, you are a receiver
If you entertain something, you are a entertainer
If you listen something, you are a listener
If you lose something, you are a loser
If you choreograph something, you are a choreographer
If you announce something, you are a announcer
If you perform something, you are a
2024-07-27 07:30:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 07:32:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0182,  0.4062, -0.0961,  ..., -0.0215, -0.3062, -0.2220],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0859, -2.2988,  2.9629,  ..., -0.8516, -3.1992, -2.9902],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0045, -0.0139,  0.0159,  ..., -0.0003, -0.0067, -0.0228],
        [-0.0128,  0.0316,  0.0046,  ...,  0.0087,  0.0078,  0.0085],
        [-0.0023, -0.0107,  0.0135,  ...,  0.0006, -0.0058,  0.0141],
        ...,
        [ 0.0059,  0.0240,  0.0049,  ...,  0.0015,  0.0179, -0.0072],
        [-0.0072,  0.0120,  0.0028,  ..., -0.0074,  0.0006, -0.0079],
        [ 0.0052, -0.0019, -0.0024,  ...,  0.0055,  0.0064, -0.0091]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.2969, -2.5176,  2.9473,  ..., -0.6987, -2.8066, -3.3750]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 07:32:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you preach something, you are a preacher
If you receive something, you are a receiver
If you entertain something, you are a entertainer
If you listen something, you are a listener
If you lose something, you are a loser
If you choreograph something, you are a choreographer
If you announce something, you are a announcer
If you perform something, you are a
2024-07-27 07:32:55 root INFO     [order_1_approx] starting weight calculation for If you choreograph something, you are a choreographer
If you preach something, you are a preacher
If you entertain something, you are a entertainer
If you announce something, you are a announcer
If you lose something, you are a loser
If you perform something, you are a performer
If you receive something, you are a receiver
If you listen something, you are a
2024-07-27 07:32:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 07:35:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3159,  0.0419, -0.0738,  ...,  0.2123,  0.1034, -0.1057],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5566, -2.2891,  1.4600,  ...,  0.0283, -2.0234, -3.8203],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.6388e-02, -9.1476e-03,  6.8665e-05,  ...,  7.8278e-03,
          1.2756e-02, -5.6000e-03],
        [-1.5961e-02,  4.5441e-02,  6.1493e-03,  ...,  2.2736e-03,
          1.0162e-02,  1.7414e-03],
        [ 3.0861e-03, -3.4729e-02,  2.2034e-02,  ...,  4.9744e-03,
          4.1275e-03,  1.3550e-02],
        ...,
        [ 2.1637e-02, -1.6800e-02,  3.0231e-03,  ...,  7.1182e-03,
          2.0325e-02,  2.8248e-03],
        [-1.3866e-03, -2.2873e-02, -1.0201e-02,  ..., -1.1917e-02,
         -1.4229e-03,  9.1934e-04],
        [ 1.4740e-02,  5.2490e-03,  1.1841e-02,  ..., -3.4790e-02,
         -2.1935e-03, -1.4328e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9551, -2.6367,  1.8682,  ..., -0.3445, -1.5439, -4.1094]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 07:35:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you choreograph something, you are a choreographer
If you preach something, you are a preacher
If you entertain something, you are a entertainer
If you announce something, you are a announcer
If you lose something, you are a loser
If you perform something, you are a performer
If you receive something, you are a receiver
If you listen something, you are a
2024-07-27 07:35:39 root INFO     [order_1_approx] starting weight calculation for If you receive something, you are a receiver
If you choreograph something, you are a choreographer
If you preach something, you are a preacher
If you announce something, you are a announcer
If you entertain something, you are a entertainer
If you listen something, you are a listener
If you perform something, you are a performer
If you lose something, you are a
2024-07-27 07:35:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 07:38:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1763,  0.1425,  0.0545,  ..., -0.0849,  0.0278,  0.0194],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6914, -0.9785,  0.9268,  ..., -1.0703, -2.0566,  0.2188],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0087, -0.0211,  0.0089,  ...,  0.0336,  0.0070,  0.0182],
        [-0.0311,  0.0298,  0.0080,  ...,  0.0029,  0.0125, -0.0051],
        [ 0.0132,  0.0087,  0.0288,  ..., -0.0075, -0.0014, -0.0052],
        ...,
        [ 0.0122,  0.0125, -0.0187,  ..., -0.0073, -0.0027,  0.0002],
        [-0.0180,  0.0310, -0.0077,  ..., -0.0250,  0.0125, -0.0101],
        [-0.0033,  0.0312,  0.0138,  ..., -0.0527, -0.0030, -0.0406]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6953, -1.0068,  0.3774,  ..., -0.9312, -2.3125,  0.3843]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 07:38:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you receive something, you are a receiver
If you choreograph something, you are a choreographer
If you preach something, you are a preacher
If you announce something, you are a announcer
If you entertain something, you are a entertainer
If you listen something, you are a listener
If you perform something, you are a performer
If you lose something, you are a
2024-07-27 07:38:25 root INFO     [order_1_approx] starting weight calculation for If you lose something, you are a loser
If you preach something, you are a preacher
If you perform something, you are a performer
If you choreograph something, you are a choreographer
If you receive something, you are a receiver
If you entertain something, you are a entertainer
If you listen something, you are a listener
If you announce something, you are a
2024-07-27 07:38:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 07:41:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0710,  0.3518,  0.0260,  ..., -0.0822, -0.2448, -0.1958],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7266, -4.5312,  2.3438,  ...,  3.8789, -2.1738, -2.4180],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.0248e-02, -5.4703e-03, -4.0436e-03,  ...,  4.0283e-03,
          8.7547e-04,  2.5120e-03],
        [-1.9897e-02,  2.6016e-02, -3.4332e-05,  ..., -1.3199e-02,
          2.2980e-02, -3.3836e-03],
        [ 1.0849e-02, -1.6663e-02,  1.8173e-02,  ..., -2.9621e-03,
         -3.3875e-03,  2.2827e-02],
        ...,
        [-9.5673e-03,  6.4621e-03,  1.9760e-03,  ...,  3.8147e-02,
          8.6746e-03, -2.4586e-03],
        [-4.5433e-03,  6.3095e-03, -9.5558e-04,  ...,  7.5378e-03,
          7.2784e-03,  2.1667e-02],
        [ 1.7128e-03,  4.2877e-03,  2.1332e-02,  ..., -1.5388e-02,
         -1.9882e-02,  1.8951e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.1484, -4.8438,  2.2969,  ...,  4.0273, -2.0098, -2.5508]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 07:41:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you lose something, you are a loser
If you preach something, you are a preacher
If you perform something, you are a performer
If you choreograph something, you are a choreographer
If you receive something, you are a receiver
If you entertain something, you are a entertainer
If you listen something, you are a listener
If you announce something, you are a
2024-07-27 07:41:06 root INFO     [order_1_approx] starting weight calculation for If you receive something, you are a receiver
If you choreograph something, you are a choreographer
If you announce something, you are a announcer
If you listen something, you are a listener
If you perform something, you are a performer
If you preach something, you are a preacher
If you lose something, you are a loser
If you entertain something, you are a
2024-07-27 07:41:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 07:43:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1986,  0.2786, -0.0845,  ..., -0.1331, -0.2373, -0.1653],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9258, -1.9512,  0.2524,  ..., -1.1387, -1.0781, -4.3359],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0083, -0.0116,  0.0173,  ..., -0.0035, -0.0020, -0.0107],
        [-0.0159,  0.0337, -0.0141,  ...,  0.0106,  0.0121,  0.0054],
        [ 0.0212, -0.0072,  0.0201,  ..., -0.0033,  0.0087, -0.0005],
        ...,
        [ 0.0466,  0.0169,  0.0079,  ...,  0.0450, -0.0409,  0.0218],
        [-0.0022,  0.0161,  0.0052,  ..., -0.0364,  0.0097, -0.0049],
        [ 0.0075,  0.0314, -0.0155,  ...,  0.0118, -0.0142, -0.0056]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1094, -2.4082,  0.4844,  ..., -1.0459, -0.2393, -4.2695]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 07:43:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you receive something, you are a receiver
If you choreograph something, you are a choreographer
If you announce something, you are a announcer
If you listen something, you are a listener
If you perform something, you are a performer
If you preach something, you are a preacher
If you lose something, you are a loser
If you entertain something, you are a
2024-07-27 07:43:50 root INFO     total operator prediction time: 1307.7822091579437 seconds
2024-07-27 07:43:50 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on over+adj_reg
2024-07-27 07:43:50 root INFO     building operator over+adj_reg
2024-07-27 07:43:51 root INFO     [order_1_approx] starting weight calculation for If something is too simplified, it is oversimplified
If something is too laid, it is overlaid
If something is too grown, it is overgrown
If something is too done, it is overdone
If something is too compensated, it is overcompensated
If something is too charged, it is overcharged
If something is too paid, it is overpaid
If something is too thrown, it is
2024-07-27 07:43:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 07:46:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2534, -0.1307, -0.0817,  ...,  0.0774, -0.3557,  0.1099],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1172, -4.2422,  0.5918,  ...,  0.6313, -1.9688, -2.0020],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0663,  0.0402, -0.0032,  ..., -0.0108, -0.0132,  0.0069],
        [-0.0176,  0.0645,  0.0026,  ...,  0.0025, -0.0291, -0.0223],
        [ 0.0049, -0.0017,  0.0227,  ..., -0.0053,  0.0008,  0.0036],
        ...,
        [-0.0075,  0.0136, -0.0219,  ...,  0.0186, -0.0002, -0.0241],
        [-0.0082, -0.0129,  0.0001,  ..., -0.0122,  0.0397, -0.0025],
        [-0.0164, -0.0011, -0.0024,  ...,  0.0023, -0.0168, -0.0099]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1582, -3.8887,  0.3242,  ...,  0.2659, -1.9434, -1.9121]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 07:46:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too simplified, it is oversimplified
If something is too laid, it is overlaid
If something is too grown, it is overgrown
If something is too done, it is overdone
If something is too compensated, it is overcompensated
If something is too charged, it is overcharged
If something is too paid, it is overpaid
If something is too thrown, it is
2024-07-27 07:46:37 root INFO     [order_1_approx] starting weight calculation for If something is too simplified, it is oversimplified
If something is too done, it is overdone
If something is too charged, it is overcharged
If something is too grown, it is overgrown
If something is too compensated, it is overcompensated
If something is too thrown, it is overthrown
If something is too laid, it is overlaid
If something is too paid, it is
2024-07-27 07:46:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 07:49:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 2.2449e-01, -2.9907e-01, -1.6492e-01,  ..., -4.8828e-04,
        -5.3662e-01, -1.3428e-01], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9473, -3.8438, -0.1504,  ..., -0.4814, -2.7266, -2.9629],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0089,  0.0023, -0.0010,  ...,  0.0107,  0.0065,  0.0114],
        [-0.0034, -0.0085,  0.0023,  ...,  0.0394, -0.0214,  0.0126],
        [ 0.0334, -0.0040,  0.0258,  ...,  0.0022,  0.0050,  0.0148],
        ...,
        [-0.0026,  0.0234, -0.0239,  ...,  0.0405,  0.0135, -0.0045],
        [-0.0039, -0.0327, -0.0246,  ..., -0.0110,  0.0036, -0.0114],
        [-0.0027, -0.0121, -0.0033,  ...,  0.0189, -0.0121,  0.0384]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2598, -3.5918, -0.1826,  ...,  0.0161, -2.9121, -3.4688]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 07:49:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too simplified, it is oversimplified
If something is too done, it is overdone
If something is too charged, it is overcharged
If something is too grown, it is overgrown
If something is too compensated, it is overcompensated
If something is too thrown, it is overthrown
If something is too laid, it is overlaid
If something is too paid, it is
2024-07-27 07:49:24 root INFO     [order_1_approx] starting weight calculation for If something is too simplified, it is oversimplified
If something is too grown, it is overgrown
If something is too thrown, it is overthrown
If something is too laid, it is overlaid
If something is too charged, it is overcharged
If something is too paid, it is overpaid
If something is too done, it is overdone
If something is too compensated, it is
2024-07-27 07:49:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 07:52:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3877, -0.2964, -0.2969,  ..., -0.1810, -0.4060, -0.1520],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6777, -4.3633,  1.1348,  ..., -1.3467, -1.2559, -2.2617],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.3081e-02,  7.7477e-03, -1.4534e-03,  ...,  1.6174e-02,
         -8.7280e-03,  1.3489e-02],
        [-1.1032e-02,  1.0666e-02,  1.8585e-02,  ...,  1.3557e-02,
         -2.9007e-02, -6.5956e-03],
        [ 1.0559e-02,  3.3302e-03,  1.3397e-02,  ..., -1.0559e-02,
          2.6131e-04, -7.2937e-03],
        ...,
        [ 2.0844e-02, -3.2291e-03, -9.9030e-03,  ...,  4.6814e-02,
          2.5597e-03, -4.1504e-03],
        [-1.0651e-02, -2.9861e-02,  7.9441e-04,  ..., -2.6428e-02,
          2.5330e-02,  5.7297e-03],
        [-9.1553e-05,  8.9951e-03, -9.0790e-03,  ...,  9.7351e-03,
         -3.6652e-02,  2.2171e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1465, -4.2344,  1.1113,  ..., -1.2471, -1.4844, -2.2871]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 07:52:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too simplified, it is oversimplified
If something is too grown, it is overgrown
If something is too thrown, it is overthrown
If something is too laid, it is overlaid
If something is too charged, it is overcharged
If something is too paid, it is overpaid
If something is too done, it is overdone
If something is too compensated, it is
2024-07-27 07:52:11 root INFO     [order_1_approx] starting weight calculation for If something is too done, it is overdone
If something is too thrown, it is overthrown
If something is too compensated, it is overcompensated
If something is too grown, it is overgrown
If something is too paid, it is overpaid
If something is too laid, it is overlaid
If something is too simplified, it is oversimplified
If something is too charged, it is
2024-07-27 07:52:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 07:54:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0652, -0.3301,  0.0428,  ...,  0.1181, -0.4001, -0.0613],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0652, -2.8789, -0.1084,  ...,  0.1538, -0.2168, -2.1426],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.2532e-02, -2.3666e-02, -1.1765e-02,  ...,  3.1174e-02,
          9.7046e-03,  1.4755e-02],
        [-1.3535e-02,  5.7434e-02,  2.2598e-02,  ..., -2.8381e-02,
          7.2479e-05, -3.1281e-04],
        [ 1.7258e-02,  1.0872e-02,  4.1443e-02,  ..., -7.7133e-03,
          8.6136e-03,  2.3834e-02],
        ...,
        [ 3.1921e-02, -4.7531e-03, -2.8534e-02,  ...,  4.1718e-02,
          1.4343e-03, -2.6016e-02],
        [ 2.2202e-03,  8.9722e-03,  4.4136e-03,  ..., -3.2410e-02,
         -6.9160e-03, -1.4877e-03],
        [-1.5610e-02, -1.0109e-04, -2.7451e-02,  ..., -6.1264e-03,
         -1.1864e-02,  3.5431e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1051, -2.6953, -0.3831,  ...,  0.0243,  0.0284, -2.4609]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 07:54:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too done, it is overdone
If something is too thrown, it is overthrown
If something is too compensated, it is overcompensated
If something is too grown, it is overgrown
If something is too paid, it is overpaid
If something is too laid, it is overlaid
If something is too simplified, it is oversimplified
If something is too charged, it is
2024-07-27 07:55:00 root INFO     [order_1_approx] starting weight calculation for If something is too charged, it is overcharged
If something is too thrown, it is overthrown
If something is too done, it is overdone
If something is too laid, it is overlaid
If something is too grown, it is overgrown
If something is too compensated, it is overcompensated
If something is too paid, it is overpaid
If something is too simplified, it is
2024-07-27 07:55:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 07:57:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1571,  0.1365, -0.4036,  ..., -0.0767, -0.3359,  0.1440],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7637, -2.7910,  1.0000,  ..., -0.8687, -2.8594, -0.8105],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.1525e-02,  3.1036e-02, -1.7166e-03,  ..., -1.3893e-02,
         -2.4567e-02,  2.5452e-02],
        [ 3.0945e-02,  3.5858e-02,  4.3335e-02,  ..., -1.1368e-02,
         -3.2257e-02, -2.9663e-02],
        [ 1.0025e-02,  8.8348e-03,  1.4763e-02,  ...,  4.3396e-02,
         -3.7445e-02,  9.2506e-05],
        ...,
        [ 2.5436e-02,  4.4739e-02,  2.2736e-02,  ...,  6.0303e-02,
         -1.6144e-02,  8.0252e-04],
        [ 7.9803e-03, -1.2970e-02,  2.5848e-02,  ..., -9.0408e-03,
         -4.3793e-03, -2.6031e-02],
        [-1.9501e-02,  1.9257e-02, -4.7302e-03,  ..., -3.5583e-02,
         -1.8585e-02, -2.8133e-04]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5527, -2.7539,  1.4521,  ..., -0.5947, -2.9512, -0.5815]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 07:57:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too charged, it is overcharged
If something is too thrown, it is overthrown
If something is too done, it is overdone
If something is too laid, it is overlaid
If something is too grown, it is overgrown
If something is too compensated, it is overcompensated
If something is too paid, it is overpaid
If something is too simplified, it is
2024-07-27 07:57:40 root INFO     [order_1_approx] starting weight calculation for If something is too charged, it is overcharged
If something is too compensated, it is overcompensated
If something is too simplified, it is oversimplified
If something is too thrown, it is overthrown
If something is too grown, it is overgrown
If something is too paid, it is overpaid
If something is too laid, it is overlaid
If something is too done, it is
2024-07-27 07:57:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 08:00:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0273,  0.1271, -0.1997,  ..., -0.0685, -0.4583, -0.0087],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2314, -3.6133, -0.8423,  ...,  0.8677, -3.0605, -2.0957],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0263, -0.0058,  0.0182,  ...,  0.0165, -0.0034,  0.0354],
        [ 0.0105,  0.0079,  0.0099,  ...,  0.0035,  0.0010, -0.0073],
        [ 0.0136,  0.0028,  0.0362,  ...,  0.0056, -0.0287,  0.0263],
        ...,
        [-0.0021,  0.0095, -0.0066,  ...,  0.0497,  0.0008,  0.0008],
        [ 0.0245, -0.0138,  0.0070,  ..., -0.0122,  0.0259,  0.0138],
        [-0.0139,  0.0102,  0.0108,  ..., -0.0072,  0.0007, -0.0124]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5459, -3.5723, -0.2197,  ...,  0.3647, -2.9902, -2.3438]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 08:00:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too charged, it is overcharged
If something is too compensated, it is overcompensated
If something is too simplified, it is oversimplified
If something is too thrown, it is overthrown
If something is too grown, it is overgrown
If something is too paid, it is overpaid
If something is too laid, it is overlaid
If something is too done, it is
2024-07-27 08:00:25 root INFO     [order_1_approx] starting weight calculation for If something is too thrown, it is overthrown
If something is too done, it is overdone
If something is too simplified, it is oversimplified
If something is too paid, it is overpaid
If something is too compensated, it is overcompensated
If something is too charged, it is overcharged
If something is too grown, it is overgrown
If something is too laid, it is
2024-07-27 08:00:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 08:03:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0844,  0.1779, -0.0840,  ..., -0.1335, -0.4121,  0.0298],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9004, -2.7461,  0.1475,  ...,  1.3076, -1.6680, -2.2285],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0758, -0.0241,  0.0065,  ..., -0.0133, -0.0275, -0.0041],
        [-0.0190,  0.0461,  0.0194,  ...,  0.0029, -0.0143, -0.0027],
        [ 0.0132, -0.0046,  0.0500,  ..., -0.0092, -0.0349, -0.0092],
        ...,
        [ 0.0055,  0.0244,  0.0099,  ...,  0.0287,  0.0030,  0.0013],
        [-0.0373, -0.0412,  0.0144,  ..., -0.0418,  0.0595, -0.0045],
        [-0.0077,  0.0067, -0.0025,  ...,  0.0196, -0.0043,  0.0254]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2959, -3.0098,  0.1636,  ...,  1.4014, -1.9287, -2.2812]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 08:03:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too thrown, it is overthrown
If something is too done, it is overdone
If something is too simplified, it is oversimplified
If something is too paid, it is overpaid
If something is too compensated, it is overcompensated
If something is too charged, it is overcharged
If something is too grown, it is overgrown
If something is too laid, it is
2024-07-27 08:03:12 root INFO     [order_1_approx] starting weight calculation for If something is too done, it is overdone
If something is too compensated, it is overcompensated
If something is too paid, it is overpaid
If something is too charged, it is overcharged
If something is too thrown, it is overthrown
If something is too laid, it is overlaid
If something is too simplified, it is oversimplified
If something is too grown, it is
2024-07-27 08:03:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 08:05:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0013,  0.0581, -0.0092,  ..., -0.3503, -0.4648, -0.2271],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9829, -4.3594,  1.0273,  ..., -0.6523, -1.1484, -2.1035],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0101, -0.0015,  0.0015,  ...,  0.0261,  0.0254,  0.0049],
        [ 0.0371,  0.0293,  0.0142,  ...,  0.0034, -0.0200, -0.0186],
        [ 0.0078,  0.0126,  0.0512,  ...,  0.0220, -0.0007,  0.0262],
        ...,
        [ 0.0053,  0.0167,  0.0041,  ...,  0.0545,  0.0155, -0.0025],
        [ 0.0029, -0.0014,  0.0019,  ...,  0.0068,  0.0226, -0.0073],
        [-0.0076, -0.0143,  0.0136,  ..., -0.0003, -0.0288,  0.0132]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7344, -4.0625,  2.3320,  ..., -1.1055, -1.5547, -2.0273]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 08:05:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too done, it is overdone
If something is too compensated, it is overcompensated
If something is too paid, it is overpaid
If something is too charged, it is overcharged
If something is too thrown, it is overthrown
If something is too laid, it is overlaid
If something is too simplified, it is oversimplified
If something is too grown, it is
2024-07-27 08:05:55 root INFO     total operator prediction time: 1324.1093909740448 seconds
2024-07-27 08:05:55 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj+ly_reg
2024-07-27 08:05:55 root INFO     building operator adj+ly_reg
2024-07-27 08:05:55 root INFO     [order_1_approx] starting weight calculation for The adjective form of federal is federally
The adjective form of similar is similarly
The adjective form of regional is regionally
The adjective form of interesting is interestingly
The adjective form of effective is effectively
The adjective form of political is politically
The adjective form of visual is visually
The adjective form of mental is
2024-07-27 08:05:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 08:08:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0162, -0.2233,  0.1907,  ..., -0.0895, -0.3975, -0.0352],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6113,  0.2112,  2.2500,  ..., -2.9668, -1.7715, -1.3789],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0495,  0.0045, -0.0223,  ..., -0.0076,  0.0189,  0.0764],
        [ 0.0033,  0.0507,  0.0348,  ..., -0.0570,  0.0087, -0.0251],
        [ 0.0051,  0.0003,  0.0309,  ..., -0.0219, -0.0412,  0.0040],
        ...,
        [ 0.0298, -0.0057, -0.0162,  ...,  0.0645,  0.0122, -0.0376],
        [ 0.0245, -0.0277, -0.0171,  ...,  0.0308,  0.0198, -0.0154],
        [ 0.0129,  0.0128,  0.0257,  ...,  0.0117,  0.0079,  0.0172]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2773,  0.4817,  2.0820,  ..., -3.1211, -1.9141, -1.5166]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 08:08:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of federal is federally
The adjective form of similar is similarly
The adjective form of regional is regionally
The adjective form of interesting is interestingly
The adjective form of effective is effectively
The adjective form of political is politically
The adjective form of visual is visually
The adjective form of mental is
2024-07-27 08:08:40 root INFO     [order_1_approx] starting weight calculation for The adjective form of political is politically
The adjective form of visual is visually
The adjective form of interesting is interestingly
The adjective form of mental is mentally
The adjective form of regional is regionally
The adjective form of effective is effectively
The adjective form of similar is similarly
The adjective form of federal is
2024-07-27 08:08:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 08:11:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1627,  0.1309, -0.1053,  ..., -0.2871, -0.3523, -0.0657],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0195, -1.6475,  3.6152,  ..., -1.4922, -0.5112, -0.3955],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0435, -0.0585, -0.0222,  ...,  0.0174,  0.0089,  0.0072],
        [ 0.0227,  0.0359, -0.0067,  ...,  0.0096, -0.0125, -0.0462],
        [ 0.0327,  0.0034,  0.0067,  ..., -0.0486, -0.0002, -0.0327],
        ...,
        [ 0.0265,  0.0460, -0.0469,  ...,  0.0509, -0.0362, -0.0516],
        [-0.0043, -0.0222, -0.0423,  ...,  0.0437,  0.0083, -0.0099],
        [-0.0263, -0.0080,  0.0195,  ...,  0.0192, -0.0101,  0.0097]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5190, -1.2998,  3.6973,  ..., -1.1445, -0.5259, -0.6895]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 08:11:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of political is politically
The adjective form of visual is visually
The adjective form of interesting is interestingly
The adjective form of mental is mentally
The adjective form of regional is regionally
The adjective form of effective is effectively
The adjective form of similar is similarly
The adjective form of federal is
2024-07-27 08:11:24 root INFO     [order_1_approx] starting weight calculation for The adjective form of political is politically
The adjective form of interesting is interestingly
The adjective form of similar is similarly
The adjective form of mental is mentally
The adjective form of regional is regionally
The adjective form of federal is federally
The adjective form of visual is visually
The adjective form of effective is
2024-07-27 08:11:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 08:14:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2299,  0.0738,  0.0511,  ..., -0.0820, -0.4197,  0.0319],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5205, -2.1934,  0.4812,  ...,  0.0762, -1.6133, -4.4531],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0209, -0.0237,  0.0116,  ..., -0.0284,  0.0100,  0.0175],
        [-0.0104,  0.0299,  0.0173,  ...,  0.0081,  0.0251, -0.0243],
        [ 0.0342, -0.0226, -0.0146,  ..., -0.0389, -0.0212,  0.0066],
        ...,
        [ 0.0398,  0.0187, -0.0007,  ...,  0.0307,  0.0131, -0.0209],
        [ 0.0028,  0.0098, -0.0002,  ...,  0.0217,  0.0287, -0.0060],
        [ 0.0035, -0.0136,  0.0134,  ...,  0.0169,  0.0044, -0.0068]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3098, -1.7559,  0.2234,  ...,  1.0391, -2.5781, -4.4336]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 08:14:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of political is politically
The adjective form of interesting is interestingly
The adjective form of similar is similarly
The adjective form of mental is mentally
The adjective form of regional is regionally
The adjective form of federal is federally
The adjective form of visual is visually
The adjective form of effective is
2024-07-27 08:14:10 root INFO     [order_1_approx] starting weight calculation for The adjective form of political is politically
The adjective form of similar is similarly
The adjective form of effective is effectively
The adjective form of mental is mentally
The adjective form of interesting is interestingly
The adjective form of federal is federally
The adjective form of visual is visually
The adjective form of regional is
2024-07-27 08:14:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 08:16:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1256,  0.0725, -0.0251,  ..., -0.1339, -0.1936, -0.0384],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.3887, -2.3418,  1.1387,  ..., -3.8496, -0.9551, -2.0645],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0316, -0.0570, -0.0062,  ...,  0.0162,  0.0081,  0.0129],
        [-0.0088,  0.0772,  0.0398,  ...,  0.0259, -0.0112, -0.0106],
        [ 0.0199, -0.0343, -0.0141,  ..., -0.0038, -0.0389,  0.0364],
        ...,
        [ 0.0054,  0.0334, -0.0337,  ...,  0.0941,  0.0263,  0.0266],
        [-0.0034, -0.0101, -0.0217,  ...,  0.0331, -0.0040, -0.0208],
        [-0.0107,  0.0019,  0.0159,  ...,  0.0357, -0.0439, -0.0009]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.8184, -2.3438,  1.5771,  ..., -3.3945, -0.7100, -2.6895]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 08:16:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of political is politically
The adjective form of similar is similarly
The adjective form of effective is effectively
The adjective form of mental is mentally
The adjective form of interesting is interestingly
The adjective form of federal is federally
The adjective form of visual is visually
The adjective form of regional is
2024-07-27 08:16:55 root INFO     [order_1_approx] starting weight calculation for The adjective form of regional is regionally
The adjective form of interesting is interestingly
The adjective form of visual is visually
The adjective form of mental is mentally
The adjective form of effective is effectively
The adjective form of political is politically
The adjective form of federal is federally
The adjective form of similar is
2024-07-27 08:16:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 08:19:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0068, -0.3787,  0.0207,  ...,  0.1047, -0.1401,  0.1812],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5742, -1.0205,  1.5234,  ..., -2.2500,  0.0054, -0.9141],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0485, -0.0406, -0.0241,  ...,  0.0309,  0.0525,  0.0008],
        [-0.0383,  0.0594,  0.0554,  ..., -0.0296,  0.0158, -0.0092],
        [ 0.0240, -0.0203, -0.0180,  ..., -0.0218, -0.0108,  0.0141],
        ...,
        [-0.0177,  0.0411,  0.0184,  ...,  0.0550, -0.0235, -0.0043],
        [ 0.0548,  0.0177,  0.0324,  ...,  0.0112, -0.0173, -0.0267],
        [ 0.0080,  0.0040,  0.0031,  ...,  0.0161, -0.0289,  0.0088]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2788, -0.6240,  1.3613,  ..., -2.1172,  0.0828, -1.1758]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 08:19:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of regional is regionally
The adjective form of interesting is interestingly
The adjective form of visual is visually
The adjective form of mental is mentally
The adjective form of effective is effectively
The adjective form of political is politically
The adjective form of federal is federally
The adjective form of similar is
2024-07-27 08:19:41 root INFO     [order_1_approx] starting weight calculation for The adjective form of mental is mentally
The adjective form of regional is regionally
The adjective form of similar is similarly
The adjective form of federal is federally
The adjective form of interesting is interestingly
The adjective form of political is politically
The adjective form of effective is effectively
The adjective form of visual is
2024-07-27 08:19:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 08:22:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0789, -0.0446,  0.0981,  ...,  0.0446, -0.1328, -0.0450],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9648, -3.3145,  1.3965,  ..., -2.1406, -1.0908, -1.0625],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0632, -0.0545,  0.0221,  ..., -0.0215,  0.0034,  0.0385],
        [ 0.0114,  0.0627,  0.0264,  ..., -0.0004, -0.0239, -0.0189],
        [ 0.0345, -0.0376,  0.0233,  ..., -0.0045, -0.0216,  0.0352],
        ...,
        [ 0.0066,  0.0171, -0.0393,  ...,  0.0423,  0.0097, -0.0262],
        [ 0.0168,  0.0189, -0.0459,  ...,  0.0009,  0.0226, -0.0107],
        [-0.0195,  0.0288,  0.0032,  ...,  0.0271, -0.0300,  0.0062]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8936, -3.1836,  1.1953,  ..., -2.1016, -1.5010, -1.3086]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 08:22:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of mental is mentally
The adjective form of regional is regionally
The adjective form of similar is similarly
The adjective form of federal is federally
The adjective form of interesting is interestingly
The adjective form of political is politically
The adjective form of effective is effectively
The adjective form of visual is
2024-07-27 08:22:26 root INFO     [order_1_approx] starting weight calculation for The adjective form of visual is visually
The adjective form of similar is similarly
The adjective form of mental is mentally
The adjective form of federal is federally
The adjective form of effective is effectively
The adjective form of regional is regionally
The adjective form of interesting is interestingly
The adjective form of political is
2024-07-27 08:22:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 08:25:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0528,  0.1726,  0.0212,  ...,  0.0321, -0.2520,  0.1209],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9497, -2.9883,  1.1104,  ..., -2.0938, -0.3250,  0.3193],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0150, -0.0061, -0.0080,  ..., -0.0054,  0.0032,  0.0323],
        [-0.0209,  0.0254,  0.0237,  ..., -0.0045,  0.0093, -0.0426],
        [ 0.0297, -0.0385, -0.0163,  ..., -0.0107, -0.0432,  0.0008],
        ...,
        [ 0.0071, -0.0080, -0.0172,  ...,  0.0467, -0.0010, -0.0196],
        [ 0.0121,  0.0030, -0.0168,  ...,  0.0096,  0.0247, -0.0407],
        [-0.0208,  0.0276,  0.0020,  ...,  0.0144,  0.0098, -0.0256]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0303, -2.9570,  0.7510,  ..., -1.9355, -0.0522,  0.4272]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 08:25:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of visual is visually
The adjective form of similar is similarly
The adjective form of mental is mentally
The adjective form of federal is federally
The adjective form of effective is effectively
The adjective form of regional is regionally
The adjective form of interesting is interestingly
The adjective form of political is
2024-07-27 08:25:11 root INFO     [order_1_approx] starting weight calculation for The adjective form of mental is mentally
The adjective form of visual is visually
The adjective form of federal is federally
The adjective form of regional is regionally
The adjective form of effective is effectively
The adjective form of political is politically
The adjective form of similar is similarly
The adjective form of interesting is
2024-07-27 08:25:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 08:27:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0379,  0.0758,  0.0119,  ...,  0.1365, -0.4058,  0.2130],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9688, -1.8018,  1.5703,  ..., -1.5312, -2.0098, -1.6904],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0236, -0.0330,  0.0099,  ..., -0.0215,  0.0154,  0.0247],
        [-0.0177,  0.0160,  0.0246,  ..., -0.0317,  0.0271, -0.0278],
        [ 0.0282, -0.0101, -0.0177,  ...,  0.0005, -0.0141,  0.0071],
        ...,
        [ 0.0220, -0.0184, -0.0044,  ...,  0.0536, -0.0062, -0.0196],
        [ 0.0654,  0.0091,  0.0034,  ...,  0.0538, -0.0047, -0.0175],
        [-0.0014,  0.0103,  0.0287,  ...,  0.0170,  0.0020, -0.0173]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1738, -1.0986,  1.6465,  ..., -1.5000, -2.1406, -1.7471]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 08:27:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of mental is mentally
The adjective form of visual is visually
The adjective form of federal is federally
The adjective form of regional is regionally
The adjective form of effective is effectively
The adjective form of political is politically
The adjective form of similar is similarly
The adjective form of interesting is
2024-07-27 08:27:54 root INFO     total operator prediction time: 1319.047589302063 seconds
2024-07-27 08:27:54 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+tion_irreg
2024-07-27 08:27:54 root INFO     building operator verb+tion_irreg
2024-07-27 08:27:54 root INFO     [order_1_approx] starting weight calculation for To minimize results in minimization
To visualize results in visualization
To allege results in allegation
To observe results in observation
To modernize results in modernization
To expire results in expiration
To perspire results in perspiration
To starve results in
2024-07-27 08:27:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 08:30:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0730, -0.0770, -0.3118,  ..., -0.0780,  0.0051,  0.0060],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6758, -3.1406,  3.5781,  ..., -0.0913, -2.1250, -1.3242],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0211,  0.0081, -0.0005,  ..., -0.0003, -0.0050, -0.0125],
        [-0.0226,  0.0176, -0.0030,  ...,  0.0186,  0.0045,  0.0141],
        [ 0.0048, -0.0048,  0.0066,  ...,  0.0233, -0.0055, -0.0043],
        ...,
        [ 0.0374,  0.0031,  0.0203,  ...,  0.0059,  0.0024, -0.0147],
        [-0.0088, -0.0160,  0.0055,  ...,  0.0125,  0.0213,  0.0075],
        [ 0.0014, -0.0128,  0.0044,  ..., -0.0045, -0.0166,  0.0388]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7500, -2.6152,  3.5957,  ...,  0.2122, -2.1875, -0.4932]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 08:30:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To minimize results in minimization
To visualize results in visualization
To allege results in allegation
To observe results in observation
To modernize results in modernization
To expire results in expiration
To perspire results in perspiration
To starve results in
2024-07-27 08:30:39 root INFO     [order_1_approx] starting weight calculation for To expire results in expiration
To perspire results in perspiration
To visualize results in visualization
To allege results in allegation
To minimize results in minimization
To modernize results in modernization
To starve results in starvation
To observe results in
2024-07-27 08:30:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 08:33:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0226,  0.4753,  0.0610,  ..., -0.0044, -0.3801, -0.1797],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.7236, -3.3125,  3.1504,  ...,  0.6709, -1.6875, -1.1602],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0193,  0.0097,  0.0017,  ..., -0.0623, -0.0137,  0.0396],
        [ 0.0306,  0.0468, -0.0182,  ...,  0.0662, -0.0033, -0.0486],
        [-0.0107, -0.0102,  0.0212,  ..., -0.0187, -0.0072,  0.0175],
        ...,
        [ 0.0211,  0.0135,  0.0223,  ...,  0.0913,  0.0061, -0.0497],
        [-0.0026, -0.0211,  0.0207,  ...,  0.0384,  0.0491, -0.0011],
        [ 0.0431,  0.0115,  0.0033,  ...,  0.0953,  0.0060, -0.0158]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.4688, -1.9795,  2.9824,  ...,  0.9629, -2.5078, -0.4717]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 08:33:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To expire results in expiration
To perspire results in perspiration
To visualize results in visualization
To allege results in allegation
To minimize results in minimization
To modernize results in modernization
To starve results in starvation
To observe results in
2024-07-27 08:33:21 root INFO     [order_1_approx] starting weight calculation for To observe results in observation
To starve results in starvation
To allege results in allegation
To perspire results in perspiration
To visualize results in visualization
To minimize results in minimization
To modernize results in modernization
To expire results in
2024-07-27 08:33:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 08:36:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1088,  0.0721, -0.4307,  ..., -0.2646, -0.0446,  0.0238],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2305, -3.0684,  1.2588,  ..., -0.5371, -0.8428, -1.6992],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0154, -0.0094,  0.0044,  ..., -0.0107,  0.0022,  0.0454],
        [-0.0261,  0.0271,  0.0035,  ...,  0.0052,  0.0039,  0.0030],
        [-0.0148,  0.0124,  0.0042,  ..., -0.0166, -0.0136,  0.0019],
        ...,
        [ 0.0344,  0.0341,  0.0381,  ...,  0.0384, -0.0204, -0.0102],
        [ 0.0100, -0.0236, -0.0188,  ...,  0.0326,  0.0283, -0.0024],
        [ 0.0147, -0.0019,  0.0027,  ...,  0.0405, -0.0100,  0.0660]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8379, -2.7266,  1.5068,  ..., -0.6377, -1.0645, -1.3770]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 08:36:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To observe results in observation
To starve results in starvation
To allege results in allegation
To perspire results in perspiration
To visualize results in visualization
To minimize results in minimization
To modernize results in modernization
To expire results in
2024-07-27 08:36:06 root INFO     [order_1_approx] starting weight calculation for To observe results in observation
To starve results in starvation
To perspire results in perspiration
To visualize results in visualization
To expire results in expiration
To modernize results in modernization
To minimize results in minimization
To allege results in
2024-07-27 08:36:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 08:38:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0170,  0.3638, -0.0634,  ...,  0.0614, -0.4746,  0.1619],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1240, -6.1250,  0.5439,  ...,  3.0195, -1.6230,  0.4131],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0304,  0.0033,  0.0144,  ..., -0.0441, -0.0697,  0.0220],
        [ 0.0054,  0.0411, -0.0105,  ...,  0.0297,  0.0457, -0.0152],
        [-0.0084, -0.0238,  0.0246,  ..., -0.0052, -0.0020, -0.0149],
        ...,
        [-0.0048,  0.0018,  0.0276,  ...,  0.0575,  0.0057,  0.0049],
        [ 0.0201, -0.0176, -0.0364,  ..., -0.0070,  0.0280, -0.0147],
        [ 0.0110,  0.0210,  0.0167,  ...,  0.0181, -0.0154,  0.0566]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1533, -3.8926, -0.1279,  ...,  3.2031, -1.6143,  1.2812]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 08:38:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To observe results in observation
To starve results in starvation
To perspire results in perspiration
To visualize results in visualization
To expire results in expiration
To modernize results in modernization
To minimize results in minimization
To allege results in
2024-07-27 08:38:50 root INFO     [order_1_approx] starting weight calculation for To starve results in starvation
To perspire results in perspiration
To allege results in allegation
To modernize results in modernization
To minimize results in minimization
To expire results in expiration
To observe results in observation
To visualize results in
2024-07-27 08:38:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 08:41:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0422,  0.1110,  0.0544,  ..., -0.0728, -0.1578,  0.0765],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0967, -3.0020,  4.1641,  ...,  1.7910, -1.9170,  0.2168],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.7130e-02, -9.2468e-03, -3.1494e-02,  ..., -9.1431e-02,
         -4.3915e-02, -1.4679e-02],
        [ 7.8888e-03,  3.9398e-02,  1.7807e-02,  ...,  7.1167e-02,
          2.7206e-02, -2.4872e-03],
        [-2.9053e-02, -1.1383e-02,  2.1088e-02,  ..., -1.1894e-02,
         -2.5970e-02,  1.2794e-02],
        ...,
        [ 1.8799e-02,  1.4282e-02,  2.6260e-02,  ...,  1.0229e-01,
          3.4698e-02,  1.4755e-02],
        [-3.8185e-03,  2.0981e-03, -1.1688e-02,  ...,  2.9236e-02,
          4.8157e-02,  6.8665e-05],
        [-2.2827e-02,  8.6060e-03,  1.6693e-02,  ...,  6.3416e-02,
         -1.1765e-02,  5.4932e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.0312, -0.9766,  3.3320,  ...,  3.0215, -1.5781,  1.1348]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 08:41:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To starve results in starvation
To perspire results in perspiration
To allege results in allegation
To modernize results in modernization
To minimize results in minimization
To expire results in expiration
To observe results in observation
To visualize results in
2024-07-27 08:41:34 root INFO     [order_1_approx] starting weight calculation for To modernize results in modernization
To expire results in expiration
To allege results in allegation
To observe results in observation
To starve results in starvation
To perspire results in perspiration
To visualize results in visualization
To minimize results in
2024-07-27 08:41:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 08:44:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0481, -0.0533, -0.2925,  ..., -0.0972,  0.0099, -0.1467],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0312, -1.3652,  1.8535,  ..., -1.4609, -3.6328, -2.8711],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0324, -0.0036, -0.0269,  ..., -0.0188, -0.0321,  0.0115],
        [-0.0101,  0.0278,  0.0031,  ...,  0.0210,  0.0115, -0.0098],
        [-0.0079,  0.0004,  0.0013,  ..., -0.0097, -0.0034, -0.0006],
        ...,
        [ 0.0022, -0.0141,  0.0104,  ...,  0.0410,  0.0116,  0.0224],
        [-0.0042, -0.0116,  0.0017,  ...,  0.0031,  0.0294, -0.0012],
        [ 0.0059, -0.0044,  0.0216,  ...,  0.0103, -0.0140,  0.0240]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2052, -0.3931,  1.8330,  ..., -1.3789, -3.8418, -1.9707]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 08:44:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To modernize results in modernization
To expire results in expiration
To allege results in allegation
To observe results in observation
To starve results in starvation
To perspire results in perspiration
To visualize results in visualization
To minimize results in
2024-07-27 08:44:19 root INFO     [order_1_approx] starting weight calculation for To observe results in observation
To expire results in expiration
To visualize results in visualization
To minimize results in minimization
To allege results in allegation
To starve results in starvation
To perspire results in perspiration
To modernize results in
2024-07-27 08:44:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 08:47:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0208,  0.4751, -0.3411,  ..., -0.2512, -0.2017, -0.1489],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.3428, -3.4648,  0.3232,  ..., -0.2688, -3.5957, -1.5273],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0282, -0.0033,  0.0072,  ...,  0.0057, -0.0107,  0.0066],
        [-0.0150,  0.0171,  0.0144,  ...,  0.0331,  0.0075,  0.0095],
        [ 0.0022,  0.0059, -0.0058,  ...,  0.0101,  0.0019,  0.0185],
        ...,
        [ 0.0031, -0.0078,  0.0259,  ...,  0.0517, -0.0130,  0.0057],
        [ 0.0066, -0.0121, -0.0088,  ...,  0.0008,  0.0568, -0.0172],
        [ 0.0024, -0.0116,  0.0093,  ...,  0.0206,  0.0003,  0.0150]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.3066, -3.4746,  0.6523,  ..., -0.6084, -3.6973, -1.6572]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 08:47:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To observe results in observation
To expire results in expiration
To visualize results in visualization
To minimize results in minimization
To allege results in allegation
To starve results in starvation
To perspire results in perspiration
To modernize results in
2024-07-27 08:47:04 root INFO     [order_1_approx] starting weight calculation for To starve results in starvation
To visualize results in visualization
To modernize results in modernization
To expire results in expiration
To allege results in allegation
To observe results in observation
To minimize results in minimization
To perspire results in
2024-07-27 08:47:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 08:49:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0522,  0.0339, -0.5308,  ..., -0.0792, -0.0111, -0.1146],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9141, -3.6055,  1.3281,  ..., -2.0957, -0.7515, -0.4316],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0252, -0.0037, -0.0175,  ..., -0.0229, -0.0082,  0.0186],
        [-0.0391,  0.0731, -0.0061,  ...,  0.0462, -0.0378,  0.0124],
        [-0.0316, -0.0168,  0.0147,  ...,  0.0273, -0.0164,  0.0169],
        ...,
        [ 0.0337,  0.0073,  0.0292,  ...,  0.0280,  0.0049, -0.0091],
        [-0.0370,  0.0208,  0.0017,  ..., -0.0058,  0.0210, -0.0053],
        [ 0.0064, -0.0121, -0.0115,  ...,  0.0440, -0.0220,  0.0691]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0859, -3.0410,  1.6523,  ..., -2.6699, -0.7939,  0.0586]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 08:49:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To starve results in starvation
To visualize results in visualization
To modernize results in modernization
To expire results in expiration
To allege results in allegation
To observe results in observation
To minimize results in minimization
To perspire results in
2024-07-27 08:49:49 root INFO     total operator prediction time: 1315.3774676322937 seconds
2024-07-27 08:49:49 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+able_reg
2024-07-27 08:49:49 root INFO     building operator verb+able_reg
2024-07-27 08:49:49 root INFO     [order_1_approx] starting weight calculation for If you can achieve something, that thing is achieveable
If you can represent something, that thing is representable
If you can dispose something, that thing is disposable
If you can accept something, that thing is acceptable
If you can believe something, that thing is believeable
If you can adjust something, that thing is adjustable
If you can expand something, that thing is expandable
If you can sustain something, that thing is
2024-07-27 08:49:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 08:52:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1644,  0.2864,  0.1664,  ...,  0.1371, -0.1266, -0.0729],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5938, -1.8340, -1.9766,  ..., -3.6465, -5.8984, -2.8633],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0089,  0.0050, -0.0186,  ..., -0.0041,  0.0267, -0.0020],
        [-0.0087,  0.0135,  0.0049,  ..., -0.0109, -0.0032, -0.0057],
        [ 0.0196, -0.0112,  0.0036,  ..., -0.0113, -0.0016, -0.0053],
        ...,
        [ 0.0109, -0.0011,  0.0135,  ...,  0.0009, -0.0072, -0.0081],
        [ 0.0108,  0.0033, -0.0034,  ..., -0.0146, -0.0015, -0.0030],
        [-0.0132,  0.0052,  0.0134,  ..., -0.0044, -0.0194, -0.0157]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5273, -2.0352, -1.9209,  ..., -3.7168, -5.6875, -2.8301]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 08:52:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can achieve something, that thing is achieveable
If you can represent something, that thing is representable
If you can dispose something, that thing is disposable
If you can accept something, that thing is acceptable
If you can believe something, that thing is believeable
If you can adjust something, that thing is adjustable
If you can expand something, that thing is expandable
If you can sustain something, that thing is
2024-07-27 08:52:32 root INFO     [order_1_approx] starting weight calculation for If you can dispose something, that thing is disposable
If you can believe something, that thing is believeable
If you can represent something, that thing is representable
If you can accept something, that thing is acceptable
If you can expand something, that thing is expandable
If you can achieve something, that thing is achieveable
If you can sustain something, that thing is sustainable
If you can adjust something, that thing is
2024-07-27 08:52:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 08:55:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2620,  0.1571, -0.1227,  ..., -0.1121, -0.0913, -0.1448],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1680, -1.3057, -2.7734,  ..., -1.6387, -7.3477, -1.2656],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0336,  0.0159, -0.0214,  ...,  0.0208,  0.0036,  0.0010],
        [ 0.0013,  0.0508, -0.0003,  ..., -0.0153, -0.0201, -0.0056],
        [ 0.0190, -0.0356,  0.0169,  ...,  0.0040,  0.0005,  0.0111],
        ...,
        [ 0.0177,  0.0212, -0.0020,  ...,  0.0369,  0.0111, -0.0104],
        [-0.0062, -0.0284, -0.0089,  ..., -0.0245,  0.0284, -0.0064],
        [ 0.0028, -0.0032,  0.0320,  ..., -0.0074, -0.0267,  0.0107]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4883, -1.3809, -2.9141,  ..., -1.8516, -6.7656, -1.3350]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 08:55:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can dispose something, that thing is disposable
If you can believe something, that thing is believeable
If you can represent something, that thing is representable
If you can accept something, that thing is acceptable
If you can expand something, that thing is expandable
If you can achieve something, that thing is achieveable
If you can sustain something, that thing is sustainable
If you can adjust something, that thing is
2024-07-27 08:55:13 root INFO     [order_1_approx] starting weight calculation for If you can adjust something, that thing is adjustable
If you can expand something, that thing is expandable
If you can believe something, that thing is believeable
If you can represent something, that thing is representable
If you can sustain something, that thing is sustainable
If you can achieve something, that thing is achieveable
If you can dispose something, that thing is disposable
If you can accept something, that thing is
2024-07-27 08:55:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 08:57:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0075,  0.3882,  0.1621,  ...,  0.1897, -0.2002,  0.0734],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8574,  0.1758, -2.3145,  ..., -1.1338, -8.0781, -1.7959],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.2444e-02, -1.4496e-02, -2.8488e-02,  ...,  2.4078e-02,
          1.9318e-02,  1.9241e-02],
        [-5.5695e-03,  3.2898e-02, -6.7368e-03,  ..., -1.6953e-02,
         -3.7018e-02, -2.8717e-02],
        [ 2.8900e-02, -2.0782e-02,  1.6724e-02,  ..., -2.5192e-02,
         -2.6337e-02,  2.3499e-03],
        ...,
        [ 2.9907e-02,  2.5208e-02,  1.8723e-02,  ...,  9.1248e-03,
          5.0354e-04, -4.1382e-02],
        [ 1.5259e-05,  2.6001e-02, -6.9656e-03,  ..., -3.3997e-02,
          2.1469e-02,  3.7903e-02],
        [-5.7983e-03, -6.3210e-03, -1.4977e-02,  ...,  5.0621e-03,
         -1.6907e-02, -3.1189e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8813, -0.1538, -2.3203,  ..., -1.0693, -7.7305, -1.9043]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 08:57:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can adjust something, that thing is adjustable
If you can expand something, that thing is expandable
If you can believe something, that thing is believeable
If you can represent something, that thing is representable
If you can sustain something, that thing is sustainable
If you can achieve something, that thing is achieveable
If you can dispose something, that thing is disposable
If you can accept something, that thing is
2024-07-27 08:57:54 root INFO     [order_1_approx] starting weight calculation for If you can accept something, that thing is acceptable
If you can expand something, that thing is expandable
If you can represent something, that thing is representable
If you can sustain something, that thing is sustainable
If you can believe something, that thing is believeable
If you can dispose something, that thing is disposable
If you can adjust something, that thing is adjustable
If you can achieve something, that thing is
2024-07-27 08:57:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 09:00:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0313,  0.3145,  0.1053,  ...,  0.0226, -0.3604, -0.0311],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3672,  0.5054, -2.1738,  ..., -3.9883, -8.7500, -4.4102],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0139,  0.0031, -0.0171,  ...,  0.0536,  0.0287,  0.0040],
        [-0.0153,  0.0145, -0.0038,  ..., -0.0268, -0.0334, -0.0047],
        [ 0.0159, -0.0253, -0.0067,  ...,  0.0050, -0.0222,  0.0130],
        ...,
        [-0.0058,  0.0114,  0.0100,  ..., -0.0027,  0.0312, -0.0281],
        [ 0.0295, -0.0030, -0.0060,  ..., -0.0198,  0.0259,  0.0268],
        [ 0.0025,  0.0059, -0.0153,  ...,  0.0101,  0.0076, -0.0104]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8203,  0.1047, -2.1465,  ..., -4.0625, -8.5000, -4.3555]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 09:00:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can accept something, that thing is acceptable
If you can expand something, that thing is expandable
If you can represent something, that thing is representable
If you can sustain something, that thing is sustainable
If you can believe something, that thing is believeable
If you can dispose something, that thing is disposable
If you can adjust something, that thing is adjustable
If you can achieve something, that thing is
2024-07-27 09:00:35 root INFO     [order_1_approx] starting weight calculation for If you can dispose something, that thing is disposable
If you can believe something, that thing is believeable
If you can adjust something, that thing is adjustable
If you can achieve something, that thing is achieveable
If you can accept something, that thing is acceptable
If you can expand something, that thing is expandable
If you can sustain something, that thing is sustainable
If you can represent something, that thing is
2024-07-27 09:00:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 09:03:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0082,  0.2742,  0.0598,  ...,  0.0237, -0.1392, -0.3164],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0381,  0.7803,  1.4629,  ..., -2.1523, -7.0312, -3.5859],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0307,  0.0105,  0.0054,  ...,  0.0011,  0.0076,  0.0131],
        [-0.0148,  0.0418,  0.0292,  ..., -0.0240, -0.0049, -0.0129],
        [ 0.0075,  0.0023,  0.0118,  ..., -0.0087, -0.0178, -0.0119],
        ...,
        [ 0.0188,  0.0350, -0.0210,  ...,  0.0295, -0.0249, -0.0112],
        [-0.0056, -0.0080, -0.0215,  ..., -0.0175,  0.0270,  0.0235],
        [-0.0361, -0.0115, -0.0103,  ...,  0.0004, -0.0190,  0.0183]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1504,  0.9092,  1.4775,  ..., -2.1621, -7.0391, -3.8359]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 09:03:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can dispose something, that thing is disposable
If you can believe something, that thing is believeable
If you can adjust something, that thing is adjustable
If you can achieve something, that thing is achieveable
If you can accept something, that thing is acceptable
If you can expand something, that thing is expandable
If you can sustain something, that thing is sustainable
If you can represent something, that thing is
2024-07-27 09:03:17 root INFO     [order_1_approx] starting weight calculation for If you can expand something, that thing is expandable
If you can achieve something, that thing is achieveable
If you can adjust something, that thing is adjustable
If you can sustain something, that thing is sustainable
If you can believe something, that thing is believeable
If you can accept something, that thing is acceptable
If you can represent something, that thing is representable
If you can dispose something, that thing is
2024-07-27 09:03:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 09:06:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0731,  0.1016, -0.1230,  ...,  0.0750, -0.1462,  0.2095],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7256, -2.1348, -1.2139,  ..., -3.6367, -5.3320, -2.0449],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0223,  0.0157,  0.0006,  ...,  0.0363,  0.0240, -0.0020],
        [-0.0080,  0.0251,  0.0188,  ..., -0.0308, -0.0218,  0.0022],
        [ 0.0220,  0.0019,  0.0118,  ..., -0.0251, -0.0107, -0.0091],
        ...,
        [-0.0030, -0.0063, -0.0093,  ...,  0.0131,  0.0025, -0.0250],
        [-0.0060, -0.0113, -0.0359,  ..., -0.0117,  0.0175, -0.0060],
        [-0.0050, -0.0074,  0.0221,  ..., -0.0190, -0.0209,  0.0145]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8369, -1.7676, -1.2539,  ..., -3.9199, -5.2852, -2.3145]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 09:06:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can expand something, that thing is expandable
If you can achieve something, that thing is achieveable
If you can adjust something, that thing is adjustable
If you can sustain something, that thing is sustainable
If you can believe something, that thing is believeable
If you can accept something, that thing is acceptable
If you can represent something, that thing is representable
If you can dispose something, that thing is
2024-07-27 09:06:02 root INFO     [order_1_approx] starting weight calculation for If you can represent something, that thing is representable
If you can accept something, that thing is acceptable
If you can achieve something, that thing is achieveable
If you can dispose something, that thing is disposable
If you can expand something, that thing is expandable
If you can sustain something, that thing is sustainable
If you can adjust something, that thing is adjustable
If you can believe something, that thing is
2024-07-27 09:06:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 09:08:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0450,  0.2152,  0.2871,  ..., -0.0338, -0.3691,  0.1313],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4688, -0.9219,  0.3223,  ..., -3.4141, -6.5469, -3.7070],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0183, -0.0173, -0.0137,  ...,  0.0261, -0.0002,  0.0192],
        [-0.0101,  0.0170,  0.0105,  ..., -0.0042, -0.0009,  0.0073],
        [ 0.0025, -0.0127,  0.0042,  ...,  0.0122, -0.0242,  0.0088],
        ...,
        [ 0.0082,  0.0066,  0.0143,  ...,  0.0088, -0.0140, -0.0147],
        [-0.0059, -0.0066, -0.0242,  ..., -0.0121,  0.0288, -0.0008],
        [ 0.0214,  0.0006,  0.0041,  ..., -0.0159, -0.0047, -0.0046]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8320, -0.9307,  0.7812,  ..., -3.2324, -6.7109, -3.8516]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 09:08:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can represent something, that thing is representable
If you can accept something, that thing is acceptable
If you can achieve something, that thing is achieveable
If you can dispose something, that thing is disposable
If you can expand something, that thing is expandable
If you can sustain something, that thing is sustainable
If you can adjust something, that thing is adjustable
If you can believe something, that thing is
2024-07-27 09:08:47 root INFO     [order_1_approx] starting weight calculation for If you can accept something, that thing is acceptable
If you can represent something, that thing is representable
If you can achieve something, that thing is achieveable
If you can sustain something, that thing is sustainable
If you can believe something, that thing is believeable
If you can dispose something, that thing is disposable
If you can adjust something, that thing is adjustable
If you can expand something, that thing is
2024-07-27 09:08:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 09:11:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1035,  0.0948, -0.1036,  ...,  0.0970, -0.1736,  0.0262],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2402, -0.8325, -0.3320,  ..., -2.3516, -6.8828, -4.3906],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0200,  0.0163, -0.0346,  ...,  0.0255,  0.0053,  0.0081],
        [-0.0087,  0.0471,  0.0205,  ..., -0.0003, -0.0368, -0.0082],
        [ 0.0414, -0.0163,  0.0306,  ...,  0.0045, -0.0007, -0.0088],
        ...,
        [-0.0031,  0.0198, -0.0005,  ...,  0.0298, -0.0055,  0.0018],
        [ 0.0047, -0.0107, -0.0230,  ..., -0.0413,  0.0439,  0.0122],
        [-0.0240, -0.0119, -0.0074,  ..., -0.0023, -0.0155,  0.0151]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0388, -0.9780, -0.3188,  ..., -3.2227, -6.7578, -4.6289]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 09:11:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can accept something, that thing is acceptable
If you can represent something, that thing is representable
If you can achieve something, that thing is achieveable
If you can sustain something, that thing is sustainable
If you can believe something, that thing is believeable
If you can dispose something, that thing is disposable
If you can adjust something, that thing is adjustable
If you can expand something, that thing is
2024-07-27 09:11:30 root INFO     total operator prediction time: 1301.2196407318115 seconds
2024-07-27 09:11:30 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on un+adj_reg
2024-07-27 09:11:30 root INFO     building operator un+adj_reg
2024-07-27 09:11:30 root INFO     [order_1_approx] starting weight calculation for The opposite of wanted is unwanted
The opposite of happy is unhappy
The opposite of desirable is undesirable
The opposite of believable is unbelievable
The opposite of able is unable
The opposite of used is unused
The opposite of noticed is unnoticed
The opposite of intended is
2024-07-27 09:11:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 09:14:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0660,  0.2109, -0.1228,  ..., -0.1060, -0.0196,  0.0238],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4663, -0.5352, -0.5781,  ...,  0.2542,  0.4668, -4.5898],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-4.5586e-04,  2.2369e-02, -1.0071e-02,  ..., -3.5324e-03,
         -2.6489e-02,  3.9246e-02],
        [-1.4618e-02,  3.2196e-02,  1.3992e-02,  ...,  1.1932e-02,
          1.6663e-02, -6.3721e-02],
        [ 1.4511e-02,  6.7978e-03,  6.3843e-02,  ...,  1.1757e-02,
          2.9663e-02, -2.0935e-02],
        ...,
        [-3.7842e-02, -5.8899e-03,  1.0490e-04,  ...,  1.4610e-02,
         -3.0945e-02, -8.6365e-03],
        [-2.5604e-02, -7.3204e-03,  2.7649e-02,  ..., -6.8665e-05,
          7.9773e-02, -6.1951e-02],
        [ 5.0278e-03,  1.7303e-02, -9.3842e-04,  ...,  7.9651e-03,
         -2.5040e-02,  2.2793e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8838,  0.1382, -0.8022,  ...,  0.0197,  0.2971, -4.3672]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 09:14:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of wanted is unwanted
The opposite of happy is unhappy
The opposite of desirable is undesirable
The opposite of believable is unbelievable
The opposite of able is unable
The opposite of used is unused
The opposite of noticed is unnoticed
The opposite of intended is
2024-07-27 09:14:17 root INFO     [order_1_approx] starting weight calculation for The opposite of able is unable
The opposite of noticed is unnoticed
The opposite of used is unused
The opposite of happy is unhappy
The opposite of believable is unbelievable
The opposite of intended is unintended
The opposite of wanted is unwanted
The opposite of desirable is
2024-07-27 09:14:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 09:17:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0089,  0.1901, -0.0054,  ..., -0.0194, -0.1165,  0.0348],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3335, -4.6055, -0.0508,  ..., -0.4929, -3.7461, -3.1758],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.1240e-02, -1.6663e-02, -3.1616e-02,  ...,  3.4546e-02,
         -1.6052e-02,  3.1860e-02],
        [-5.4810e-02,  3.3879e-04, -2.3834e-02,  ...,  1.4030e-02,
          1.2299e-02, -7.4768e-04],
        [ 5.0964e-03,  1.9699e-02,  2.8961e-02,  ..., -4.1016e-02,
          1.7242e-02, -3.2440e-02],
        ...,
        [-4.1151e-04,  3.2623e-02,  4.5547e-03,  ..., -1.9806e-02,
          2.0630e-02, -4.7302e-02],
        [-7.6294e-05, -1.1368e-02,  4.6356e-02,  ..., -1.7944e-02,
          1.6357e-02, -3.6011e-02],
        [ 1.8511e-03,  2.2156e-02, -1.6693e-02,  ..., -7.2708e-03,
         -2.4109e-02,  1.6281e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1667, -4.4062,  0.0846,  ..., -0.4370, -3.6465, -2.9551]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 09:17:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of able is unable
The opposite of noticed is unnoticed
The opposite of used is unused
The opposite of happy is unhappy
The opposite of believable is unbelievable
The opposite of intended is unintended
The opposite of wanted is unwanted
The opposite of desirable is
2024-07-27 09:17:01 root INFO     [order_1_approx] starting weight calculation for The opposite of noticed is unnoticed
The opposite of able is unable
The opposite of intended is unintended
The opposite of desirable is undesirable
The opposite of used is unused
The opposite of believable is unbelievable
The opposite of happy is unhappy
The opposite of wanted is
2024-07-27 09:17:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 09:19:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2017, -0.0197, -0.2705,  ..., -0.0198, -0.0610,  0.1829],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0723, -2.1270, -0.8818,  ..., -0.1058, -1.5859, -2.1465],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0361, -0.0361,  0.0241,  ..., -0.0208, -0.0300,  0.0351],
        [-0.0446,  0.0511, -0.0226,  ...,  0.0024, -0.0391,  0.0235],
        [ 0.0210,  0.0234,  0.0228,  ...,  0.0134,  0.0033, -0.0153],
        ...,
        [-0.0296,  0.0268, -0.0126,  ..., -0.0040,  0.0555,  0.0073],
        [ 0.0499, -0.0158,  0.0092,  ...,  0.0313,  0.0361, -0.0561],
        [-0.0030,  0.0334, -0.0172,  ...,  0.0387,  0.0522,  0.0486]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3906, -2.7051, -0.6782,  ..., -0.3425, -2.5254, -1.8115]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 09:19:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of noticed is unnoticed
The opposite of able is unable
The opposite of intended is unintended
The opposite of desirable is undesirable
The opposite of used is unused
The opposite of believable is unbelievable
The opposite of happy is unhappy
The opposite of wanted is
2024-07-27 09:19:46 root INFO     [order_1_approx] starting weight calculation for The opposite of able is unable
The opposite of intended is unintended
The opposite of desirable is undesirable
The opposite of noticed is unnoticed
The opposite of happy is unhappy
The opposite of used is unused
The opposite of wanted is unwanted
The opposite of believable is
2024-07-27 09:19:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 09:22:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2515, -0.1184,  0.0148,  ..., -0.2378, -0.3335,  0.1943],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2490, -3.8359,  0.3140,  ..., -1.6465, -1.4082, -3.3672],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.0131e-02, -1.7532e-02, -4.6143e-02,  ...,  2.6001e-02,
          3.8376e-03,  5.1514e-02],
        [-2.5299e-02, -1.9913e-03,  3.8208e-02,  ...,  9.7198e-03,
          1.9608e-02, -4.3106e-03],
        [-2.5299e-02, -1.1978e-02, -4.0779e-03,  ..., -1.5259e-05,
         -1.8982e-02, -2.1057e-02],
        ...,
        [-2.7832e-02,  1.8417e-02, -4.4983e-02,  ..., -1.9646e-03,
          6.5765e-03, -1.0193e-02],
        [-3.3844e-02,  3.4851e-02,  3.4393e-02,  ..., -7.3547e-03,
         -4.1885e-03, -4.0314e-02],
        [-2.6535e-02,  1.7151e-02, -2.8366e-02,  ..., -1.3565e-02,
          2.2621e-03,  2.1332e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6504, -4.2344,  0.4644,  ..., -1.4336, -1.7812, -3.3906]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 09:22:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of able is unable
The opposite of intended is unintended
The opposite of desirable is undesirable
The opposite of noticed is unnoticed
The opposite of happy is unhappy
The opposite of used is unused
The opposite of wanted is unwanted
The opposite of believable is
2024-07-27 09:22:29 root INFO     [order_1_approx] starting weight calculation for The opposite of wanted is unwanted
The opposite of able is unable
The opposite of desirable is undesirable
The opposite of happy is unhappy
The opposite of intended is unintended
The opposite of noticed is unnoticed
The opposite of believable is unbelievable
The opposite of used is
2024-07-27 09:22:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 09:25:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1377, -0.1340,  0.0181,  ...,  0.1125, -0.5986,  0.1571],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0918, -2.6758, -0.1943,  ..., -1.9512, -2.6328, -1.5205],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0047, -0.0131,  0.0018,  ...,  0.0493, -0.0212,  0.0235],
        [-0.0531,  0.1103,  0.0427,  ...,  0.0074, -0.0138,  0.0113],
        [-0.0129, -0.0217,  0.0475,  ...,  0.0450, -0.0089, -0.0032],
        ...,
        [-0.0023, -0.0161,  0.0001,  ..., -0.0111,  0.0057, -0.0059],
        [ 0.0217, -0.0178,  0.0342,  ...,  0.0156,  0.0454,  0.0287],
        [-0.0104,  0.0183, -0.0748,  ...,  0.0416,  0.0234,  0.0189]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4717, -2.7461,  0.4473,  ..., -1.7500, -3.9590, -1.5938]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 09:25:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of wanted is unwanted
The opposite of able is unable
The opposite of desirable is undesirable
The opposite of happy is unhappy
The opposite of intended is unintended
The opposite of noticed is unnoticed
The opposite of believable is unbelievable
The opposite of used is
2024-07-27 09:25:12 root INFO     [order_1_approx] starting weight calculation for The opposite of wanted is unwanted
The opposite of believable is unbelievable
The opposite of noticed is unnoticed
The opposite of desirable is undesirable
The opposite of intended is unintended
The opposite of used is unused
The opposite of able is unable
The opposite of happy is
2024-07-27 09:25:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 09:27:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1018, -0.1997, -0.0530,  ...,  0.0288, -0.0887,  0.1467],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8398, -1.8691,  1.1201,  ..., -2.7031, -1.5566, -1.1719],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0318, -0.0060,  0.0166,  ..., -0.0162,  0.0004,  0.0381],
        [-0.0295,  0.0350,  0.0344,  ..., -0.0024,  0.0058,  0.0275],
        [ 0.0141, -0.0074,  0.0065,  ...,  0.0282, -0.0127, -0.0032],
        ...,
        [ 0.0022,  0.0216,  0.0265,  ...,  0.0196,  0.0264, -0.0116],
        [-0.0141,  0.0002, -0.0134,  ..., -0.0057,  0.0230, -0.0435],
        [ 0.0179, -0.0159, -0.0381,  ...,  0.0531, -0.0227,  0.0294]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2910, -2.5215,  0.9751,  ..., -2.6641, -1.5918, -1.5225]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 09:27:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of wanted is unwanted
The opposite of believable is unbelievable
The opposite of noticed is unnoticed
The opposite of desirable is undesirable
The opposite of intended is unintended
The opposite of used is unused
The opposite of able is unable
The opposite of happy is
2024-07-27 09:27:59 root INFO     [order_1_approx] starting weight calculation for The opposite of used is unused
The opposite of wanted is unwanted
The opposite of intended is unintended
The opposite of noticed is unnoticed
The opposite of happy is unhappy
The opposite of desirable is undesirable
The opposite of believable is unbelievable
The opposite of able is
2024-07-27 09:27:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 09:30:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1295, -0.0388, -0.0743,  ..., -0.2507, -0.1354,  0.1202],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0830, -5.8984,  1.9102,  ...,  0.5708, -0.7256, -1.4102],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0357, -0.0376,  0.0073,  ...,  0.0312, -0.0180,  0.0231],
        [-0.0122,  0.0466, -0.0371,  ...,  0.0137,  0.0399,  0.0093],
        [ 0.0235,  0.0428, -0.0005,  ..., -0.0119,  0.0203, -0.0308],
        ...,
        [-0.0280,  0.0003, -0.0307,  ..., -0.0140,  0.0195, -0.0389],
        [ 0.0016,  0.0149,  0.0163,  ...,  0.0025,  0.0423, -0.0163],
        [-0.0011,  0.0062, -0.0287,  ...,  0.0003,  0.0405, -0.0195]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8770, -6.1680,  2.8281,  ...,  0.5791, -1.2266, -1.4766]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 09:30:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of used is unused
The opposite of wanted is unwanted
The opposite of intended is unintended
The opposite of noticed is unnoticed
The opposite of happy is unhappy
The opposite of desirable is undesirable
The opposite of believable is unbelievable
The opposite of able is
2024-07-27 09:30:42 root INFO     [order_1_approx] starting weight calculation for The opposite of wanted is unwanted
The opposite of happy is unhappy
The opposite of used is unused
The opposite of believable is unbelievable
The opposite of intended is unintended
The opposite of desirable is undesirable
The opposite of able is unable
The opposite of noticed is
2024-07-27 09:30:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 09:33:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2159, -0.0191, -0.0424,  ..., -0.0050, -0.4900,  0.2781],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.1172,  0.7832, -1.4512,  ..., -3.6250, -2.0684, -1.3574],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0361,  0.0073,  0.0067,  ...,  0.0338,  0.0026,  0.0360],
        [-0.0211,  0.0361,  0.0438,  ..., -0.0260, -0.0317, -0.0121],
        [-0.0202,  0.0196,  0.0144,  ...,  0.0125,  0.0110,  0.0069],
        ...,
        [-0.0033,  0.0462,  0.0068,  ...,  0.0286,  0.0211,  0.0015],
        [ 0.0071,  0.0155, -0.0074,  ...,  0.0019,  0.0484, -0.0450],
        [ 0.0128,  0.0118,  0.0049,  ...,  0.0318, -0.0132,  0.0527]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8623,  0.2866, -1.8115,  ..., -3.2246, -2.5098, -0.7100]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 09:33:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of wanted is unwanted
The opposite of happy is unhappy
The opposite of used is unused
The opposite of believable is unbelievable
The opposite of intended is unintended
The opposite of desirable is undesirable
The opposite of able is unable
The opposite of noticed is
2024-07-27 09:33:26 root INFO     total operator prediction time: 1315.468974351883 seconds
2024-07-27 09:33:26 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on re+verb_reg
2024-07-27 09:33:26 root INFO     building operator re+verb_reg
2024-07-27 09:33:26 root INFO     [order_1_approx] starting weight calculation for To connect again is to reconnect
To appear again is to reappear
To locate again is to relocate
To send again is to resend
To decorate again is to redecorate
To adjust again is to readjust
To acquire again is to reacquire
To assure again is to
2024-07-27 09:33:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 09:36:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0428,  0.3950, -0.1440,  ..., -0.0037, -0.0833, -0.1198],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4343, -2.7207, -0.3826,  ...,  1.8574, -5.6680, -4.4961],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0440, -0.0158,  0.0176,  ..., -0.0314, -0.0164,  0.0251],
        [-0.0181,  0.0220, -0.0018,  ...,  0.0052,  0.0077,  0.0262],
        [ 0.0001, -0.0013, -0.0040,  ...,  0.0282,  0.0122, -0.0040],
        ...,
        [ 0.0194, -0.0105, -0.0247,  ...,  0.0443,  0.0222,  0.0215],
        [-0.0128, -0.0232,  0.0131,  ..., -0.0028,  0.0246, -0.0208],
        [ 0.0067, -0.0235, -0.0034,  ..., -0.0159, -0.0371,  0.0441]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7236, -2.5605, -0.3115,  ...,  2.3164, -5.7773, -4.3633]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 09:36:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To connect again is to reconnect
To appear again is to reappear
To locate again is to relocate
To send again is to resend
To decorate again is to redecorate
To adjust again is to readjust
To acquire again is to reacquire
To assure again is to
2024-07-27 09:36:08 root INFO     [order_1_approx] starting weight calculation for To acquire again is to reacquire
To send again is to resend
To decorate again is to redecorate
To appear again is to reappear
To adjust again is to readjust
To locate again is to relocate
To assure again is to reassure
To connect again is to
2024-07-27 09:36:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 09:38:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0645,  0.1611, -0.1688,  ...,  0.1686, -0.3328,  0.0637],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.3789, -2.9316,  1.3457,  ...,  3.4961, -3.8223, -3.4297],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0060, -0.0268,  0.0433,  ...,  0.0443,  0.0574,  0.0335],
        [ 0.0158,  0.0258,  0.0281,  ...,  0.0086, -0.0209,  0.0061],
        [ 0.0028, -0.0086,  0.0222,  ..., -0.0062,  0.0198, -0.0042],
        ...,
        [ 0.0028, -0.0128,  0.0238,  ...,  0.0083,  0.0222,  0.0159],
        [ 0.0026, -0.0156, -0.0175,  ..., -0.0166, -0.0019, -0.0008],
        [-0.0446, -0.0293, -0.0015,  ...,  0.0111,  0.0220,  0.0186]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.6738, -3.3340,  1.6221,  ...,  2.7969, -3.8770, -3.3867]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 09:38:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To acquire again is to reacquire
To send again is to resend
To decorate again is to redecorate
To appear again is to reappear
To adjust again is to readjust
To locate again is to relocate
To assure again is to reassure
To connect again is to
2024-07-27 09:38:52 root INFO     [order_1_approx] starting weight calculation for To assure again is to reassure
To connect again is to reconnect
To send again is to resend
To acquire again is to reacquire
To decorate again is to redecorate
To adjust again is to readjust
To appear again is to reappear
To locate again is to
2024-07-27 09:38:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 09:41:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0413,  0.4204, -0.4253,  ..., -0.0187, -0.2856,  0.0391],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.5020, -2.6133, -0.2803,  ...,  0.8657, -3.4941, -3.6953],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0151, -0.0366,  0.0157,  ...,  0.0023,  0.0573,  0.0042],
        [ 0.0011,  0.0259,  0.0025,  ..., -0.0030, -0.0130, -0.0019],
        [ 0.0052,  0.0141,  0.0314,  ...,  0.0179,  0.0157, -0.0150],
        ...,
        [ 0.0225, -0.0038, -0.0160,  ...,  0.0199,  0.0112,  0.0198],
        [ 0.0247,  0.0065, -0.0073,  ...,  0.0081,  0.0028,  0.0146],
        [-0.0100,  0.0214, -0.0353,  ..., -0.0038,  0.0259,  0.0192]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.3291, -2.8359, -0.2192,  ...,  0.5557, -3.1816, -3.7500]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 09:41:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To assure again is to reassure
To connect again is to reconnect
To send again is to resend
To acquire again is to reacquire
To decorate again is to redecorate
To adjust again is to readjust
To appear again is to reappear
To locate again is to
2024-07-27 09:41:38 root INFO     [order_1_approx] starting weight calculation for To acquire again is to reacquire
To locate again is to relocate
To connect again is to reconnect
To send again is to resend
To appear again is to reappear
To adjust again is to readjust
To assure again is to reassure
To decorate again is to
2024-07-27 09:41:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 09:44:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0261,  0.1759, -0.2255,  ...,  0.0747, -0.2208,  0.0730],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.5117, -3.5391,  0.3794,  ...,  1.2354, -5.2227, -2.9844],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0311, -0.0161,  0.0113,  ..., -0.0067,  0.0028,  0.0120],
        [-0.0099,  0.0132,  0.0162,  ..., -0.0075, -0.0050, -0.0137],
        [ 0.0149,  0.0119, -0.0042,  ...,  0.0010, -0.0107, -0.0107],
        ...,
        [ 0.0116, -0.0107,  0.0221,  ...,  0.0225, -0.0002, -0.0087],
        [ 0.0060, -0.0096, -0.0243,  ..., -0.0062,  0.0029, -0.0077],
        [-0.0039,  0.0152, -0.0072,  ..., -0.0133, -0.0184,  0.0180]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.4619, -3.2207,  0.4875,  ...,  1.1572, -5.1250, -2.8340]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 09:44:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To acquire again is to reacquire
To locate again is to relocate
To connect again is to reconnect
To send again is to resend
To appear again is to reappear
To adjust again is to readjust
To assure again is to reassure
To decorate again is to
2024-07-27 09:44:22 root INFO     [order_1_approx] starting weight calculation for To adjust again is to readjust
To connect again is to reconnect
To send again is to resend
To locate again is to relocate
To decorate again is to redecorate
To acquire again is to reacquire
To assure again is to reassure
To appear again is to
2024-07-27 09:44:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 09:47:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2329,  0.3396, -0.2181,  ..., -0.1694, -0.0786,  0.0787],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-3.4180e-03, -1.6348e+00, -1.2959e+00,  ...,  4.1562e+00,
        -4.6406e+00, -2.8906e+00], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0414, -0.0184,  0.0104,  ..., -0.0145, -0.0210,  0.0157],
        [-0.0202,  0.0060, -0.0403,  ...,  0.0367,  0.0144, -0.0022],
        [-0.0022,  0.0284,  0.0238,  ..., -0.0024,  0.0096, -0.0338],
        ...,
        [-0.0065, -0.0058,  0.0217,  ...,  0.0438, -0.0058,  0.0204],
        [-0.0232, -0.0179, -0.0202,  ..., -0.0624, -0.0008, -0.0199],
        [-0.0301, -0.0191, -0.0341,  ...,  0.0117, -0.0193,  0.0243]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1639, -1.2520, -1.3662,  ...,  3.6348, -4.4219, -2.4785]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 09:47:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To adjust again is to readjust
To connect again is to reconnect
To send again is to resend
To locate again is to relocate
To decorate again is to redecorate
To acquire again is to reacquire
To assure again is to reassure
To appear again is to
2024-07-27 09:47:06 root INFO     [order_1_approx] starting weight calculation for To locate again is to relocate
To send again is to resend
To adjust again is to readjust
To connect again is to reconnect
To decorate again is to redecorate
To assure again is to reassure
To appear again is to reappear
To acquire again is to
2024-07-27 09:47:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 09:49:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1848,  0.4727, -0.1370,  ..., -0.1256, -0.3003, -0.1199],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2744, -2.9180, -1.6934,  ...,  0.8965, -4.1172, -2.9688],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0375, -0.0216,  0.0248,  ...,  0.0368, -0.0178,  0.0403],
        [-0.0193,  0.0240, -0.0132,  ...,  0.0168,  0.0042,  0.0182],
        [ 0.0086, -0.0036,  0.0178,  ...,  0.0060,  0.0166, -0.0076],
        ...,
        [ 0.0425, -0.0124,  0.0121,  ...,  0.0242, -0.0007,  0.0184],
        [ 0.0030,  0.0162,  0.0015,  ..., -0.0134,  0.0040, -0.0261],
        [ 0.0222, -0.0303,  0.0125,  ...,  0.0023, -0.0109,  0.0298]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0726, -3.2363, -1.5156,  ...,  0.8481, -4.1055, -2.4609]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 09:49:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To locate again is to relocate
To send again is to resend
To adjust again is to readjust
To connect again is to reconnect
To decorate again is to redecorate
To assure again is to reassure
To appear again is to reappear
To acquire again is to
2024-07-27 09:49:53 root INFO     [order_1_approx] starting weight calculation for To connect again is to reconnect
To acquire again is to reacquire
To decorate again is to redecorate
To appear again is to reappear
To locate again is to relocate
To assure again is to reassure
To send again is to resend
To adjust again is to
2024-07-27 09:49:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 09:52:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0914,  0.1759, -0.4387,  ..., -0.1040, -0.2981, -0.0598],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5371, -2.0371, -1.7715,  ...,  1.9336, -4.4453, -4.3281],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0374, -0.0081,  0.0023,  ...,  0.0126,  0.0212,  0.0204],
        [ 0.0173,  0.0194,  0.0154,  ...,  0.0265, -0.0023, -0.0110],
        [ 0.0014,  0.0164,  0.0231,  ..., -0.0095,  0.0189,  0.0168],
        ...,
        [ 0.0035, -0.0241, -0.0173,  ...,  0.0441,  0.0235, -0.0105],
        [-0.0220, -0.0185, -0.0176,  ..., -0.0173,  0.0344,  0.0066],
        [ 0.0044, -0.0029, -0.0032,  ..., -0.0455, -0.0388,  0.0389]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4451, -1.9990, -1.3691,  ...,  1.3867, -4.1562, -4.1328]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 09:52:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To connect again is to reconnect
To acquire again is to reacquire
To decorate again is to redecorate
To appear again is to reappear
To locate again is to relocate
To assure again is to reassure
To send again is to resend
To adjust again is to
2024-07-27 09:52:38 root INFO     [order_1_approx] starting weight calculation for To assure again is to reassure
To acquire again is to reacquire
To connect again is to reconnect
To appear again is to reappear
To decorate again is to redecorate
To locate again is to relocate
To adjust again is to readjust
To send again is to
2024-07-27 09:52:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 09:55:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2113,  0.2773,  0.1497,  ...,  0.1191, -0.2593, -0.0165],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.5537, -3.2871, -2.1328,  ...,  0.7705, -3.2891, -4.1406],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0369, -0.0372,  0.0409,  ...,  0.0225, -0.0294,  0.0177],
        [-0.0024,  0.0263, -0.0132,  ...,  0.0004, -0.0086, -0.0204],
        [ 0.0276, -0.0018,  0.0327,  ..., -0.0037,  0.0108, -0.0022],
        ...,
        [ 0.0131, -0.0221,  0.0447,  ...,  0.0327,  0.0054,  0.0267],
        [-0.0235,  0.0041, -0.0010,  ..., -0.0388,  0.0182, -0.0081],
        [-0.0113, -0.0088, -0.0048,  ..., -0.0110, -0.0220,  0.0261]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.3301, -3.4551, -1.6367,  ...,  0.0142, -3.3164, -4.1914]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 09:55:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To assure again is to reassure
To acquire again is to reacquire
To connect again is to reconnect
To appear again is to reappear
To decorate again is to redecorate
To locate again is to relocate
To adjust again is to readjust
To send again is to
2024-07-27 09:55:21 root INFO     total operator prediction time: 1315.3831901550293 seconds
2024-07-27 09:55:21 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj+ness_reg
2024-07-27 09:55:21 root INFO     building operator adj+ness_reg
2024-07-27 09:55:21 root INFO     [order_1_approx] starting weight calculation for The state of being innovative is innovativeness
The state of being distinctive is distinctiveness
The state of being attractive is attractiveness
The state of being broken is brokenness
The state of being directed is directedness
The state of being strange is strangeness
The state of being vast is vastness
The state of being hot is
2024-07-27 09:55:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 09:58:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1682,  0.0075,  0.0885,  ...,  0.0195, -0.3096, -0.0736],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0293, -2.5938, -0.2764,  ..., -3.7109, -5.9141, -0.6787],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0292, -0.0139,  0.0054,  ..., -0.0359, -0.0153,  0.0166],
        [-0.0065,  0.0029, -0.0065,  ..., -0.0162, -0.0134,  0.0148],
        [-0.0034, -0.0072,  0.0215,  ...,  0.0163, -0.0020,  0.0018],
        ...,
        [ 0.0058, -0.0199,  0.0110,  ...,  0.0167,  0.0097, -0.0191],
        [ 0.0074, -0.0128, -0.0088,  ..., -0.0098,  0.0344,  0.0080],
        [ 0.0052, -0.0100, -0.0285,  ...,  0.0285,  0.0015,  0.0292]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8838, -2.2891, -0.6387,  ..., -3.9785, -6.1758, -0.6768]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 09:58:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being innovative is innovativeness
The state of being distinctive is distinctiveness
The state of being attractive is attractiveness
The state of being broken is brokenness
The state of being directed is directedness
The state of being strange is strangeness
The state of being vast is vastness
The state of being hot is
2024-07-27 09:58:03 root INFO     [order_1_approx] starting weight calculation for The state of being directed is directedness
The state of being strange is strangeness
The state of being hot is hotness
The state of being innovative is innovativeness
The state of being distinctive is distinctiveness
The state of being attractive is attractiveness
The state of being vast is vastness
The state of being broken is
2024-07-27 09:58:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 10:00:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2783,  0.2104, -0.0620,  ..., -0.0762, -0.2429,  0.0422],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7002, -4.8281, -0.6895,  ..., -1.6846,  0.6006, -0.5518],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0177,  0.0096, -0.0122,  ...,  0.0009,  0.0203,  0.0253],
        [ 0.0216, -0.0030,  0.0062,  ...,  0.0270, -0.0109,  0.0203],
        [-0.0008, -0.0265,  0.0059,  ...,  0.0199,  0.0022,  0.0196],
        ...,
        [ 0.0367, -0.0051,  0.0220,  ...,  0.0190, -0.0226, -0.0099],
        [-0.0268,  0.0005, -0.0125,  ..., -0.0457,  0.0535, -0.0568],
        [ 0.0003,  0.0055,  0.0015,  ...,  0.0073, -0.0055,  0.0156]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0723, -5.0703, -0.4307,  ..., -1.8105,  0.7583, -0.7314]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 10:00:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being directed is directedness
The state of being strange is strangeness
The state of being hot is hotness
The state of being innovative is innovativeness
The state of being distinctive is distinctiveness
The state of being attractive is attractiveness
The state of being vast is vastness
The state of being broken is
2024-07-27 10:00:50 root INFO     [order_1_approx] starting weight calculation for The state of being hot is hotness
The state of being innovative is innovativeness
The state of being vast is vastness
The state of being strange is strangeness
The state of being distinctive is distinctiveness
The state of being attractive is attractiveness
The state of being broken is brokenness
The state of being directed is
2024-07-27 10:00:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 10:03:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3171,  0.1062, -0.1807,  ..., -0.0179, -0.2974,  0.1597],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8945, -3.6836, -0.6934,  ...,  0.4797, -3.3555, -5.0781],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0068,  0.0111, -0.0097,  ...,  0.0231,  0.0130,  0.0277],
        [-0.0089,  0.0302,  0.0156,  ..., -0.0245, -0.0147, -0.0048],
        [ 0.0121,  0.0024, -0.0204,  ..., -0.0084,  0.0008, -0.0018],
        ...,
        [ 0.0238,  0.0120,  0.0136,  ..., -0.0019,  0.0129,  0.0045],
        [-0.0017, -0.0135,  0.0094,  ..., -0.0063,  0.0640, -0.0135],
        [-0.0134, -0.0146, -0.0343,  ...,  0.0089, -0.0428,  0.0539]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5215, -4.0469, -0.0386,  ...,  0.3457, -3.0938, -5.3750]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 10:03:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being hot is hotness
The state of being innovative is innovativeness
The state of being vast is vastness
The state of being strange is strangeness
The state of being distinctive is distinctiveness
The state of being attractive is attractiveness
The state of being broken is brokenness
The state of being directed is
2024-07-27 10:03:35 root INFO     [order_1_approx] starting weight calculation for The state of being strange is strangeness
The state of being attractive is attractiveness
The state of being hot is hotness
The state of being directed is directedness
The state of being broken is brokenness
The state of being distinctive is distinctiveness
The state of being vast is vastness
The state of being innovative is
2024-07-27 10:03:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 10:06:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0732,  0.1582, -0.0499,  ...,  0.0469, -0.1831, -0.1069],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3516, -3.2715, -0.6484,  ...,  1.4160, -1.2617, -1.9385],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.7487e-02, -6.9199e-03,  3.9215e-03,  ..., -3.0041e-03,
         -1.6022e-04,  1.4809e-02],
        [-7.5455e-03,  8.3237e-03,  7.1487e-03,  ..., -1.6994e-03,
         -1.7715e-02,  7.8049e-03],
        [-5.7526e-03, -2.8778e-02,  1.5976e-02,  ..., -3.2997e-04,
          4.6577e-03, -1.5236e-02],
        ...,
        [ 2.9678e-03,  1.6861e-02,  1.1162e-02,  ...,  1.6251e-02,
         -5.3482e-03,  1.4908e-02],
        [ 3.9291e-03,  1.5381e-02, -4.1428e-03,  ..., -4.7684e-06,
          2.7771e-02, -1.5030e-02],
        [ 3.9902e-03, -1.8127e-02, -4.3793e-03,  ..., -3.8147e-06,
         -2.2049e-02,  3.0640e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5273, -2.8438, -0.6899,  ...,  1.4561, -1.3105, -2.0820]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 10:06:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being strange is strangeness
The state of being attractive is attractiveness
The state of being hot is hotness
The state of being directed is directedness
The state of being broken is brokenness
The state of being distinctive is distinctiveness
The state of being vast is vastness
The state of being innovative is
2024-07-27 10:06:21 root INFO     [order_1_approx] starting weight calculation for The state of being directed is directedness
The state of being strange is strangeness
The state of being broken is brokenness
The state of being vast is vastness
The state of being innovative is innovativeness
The state of being attractive is attractiveness
The state of being hot is hotness
The state of being distinctive is
2024-07-27 10:06:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 10:09:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1677, -0.0662, -0.2593,  ...,  0.1041, -0.1816,  0.0463],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1826, -1.7891, -0.9307,  ..., -1.7529, -4.0312, -0.5439],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0290, -0.0066, -0.0010,  ..., -0.0095, -0.0061,  0.0242],
        [-0.0139,  0.0140,  0.0157,  ..., -0.0058,  0.0100, -0.0065],
        [ 0.0154, -0.0183,  0.0043,  ...,  0.0061,  0.0002, -0.0140],
        ...,
        [-0.0069,  0.0196, -0.0013,  ...,  0.0141,  0.0027, -0.0103],
        [ 0.0180, -0.0042, -0.0127,  ..., -0.0026,  0.0080,  0.0221],
        [ 0.0035,  0.0065, -0.0057,  ...,  0.0010,  0.0074,  0.0057]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1262, -1.5811, -0.8906,  ..., -1.8145, -4.3516, -0.5942]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 10:09:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being directed is directedness
The state of being strange is strangeness
The state of being broken is brokenness
The state of being vast is vastness
The state of being innovative is innovativeness
The state of being attractive is attractiveness
The state of being hot is hotness
The state of being distinctive is
2024-07-27 10:09:07 root INFO     [order_1_approx] starting weight calculation for The state of being strange is strangeness
The state of being hot is hotness
The state of being directed is directedness
The state of being broken is brokenness
The state of being distinctive is distinctiveness
The state of being innovative is innovativeness
The state of being vast is vastness
The state of being attractive is
2024-07-27 10:09:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 10:11:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0401,  0.1594, -0.1117,  ...,  0.2263, -0.0148, -0.1934],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4043, -0.8555, -3.2148,  ..., -0.0884, -4.6172, -2.8789],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.0737e-02, -1.2070e-02, -4.2877e-03,  ..., -8.4839e-03,
          1.0414e-03,  5.9624e-03],
        [-9.9869e-03,  1.1726e-02, -4.2152e-04,  ...,  4.3335e-03,
          1.7517e-02,  4.5738e-03],
        [ 1.0475e-02, -1.7227e-02,  9.7961e-03,  ..., -5.6267e-03,
         -7.2289e-03, -1.0330e-02],
        ...,
        [ 1.6449e-02,  1.5251e-02,  9.2468e-03,  ...,  1.8188e-02,
          3.9024e-03,  3.3035e-03],
        [ 8.9264e-03, -2.6059e-04,  1.1826e-04,  ..., -1.4877e-02,
          2.1896e-03, -4.4708e-03],
        [-4.7684e-07,  9.9564e-03, -1.8082e-03,  ...,  1.7914e-02,
         -1.2764e-02,  2.4063e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5015, -0.6064, -3.3340,  ..., -0.3281, -4.8594, -3.0273]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 10:11:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being strange is strangeness
The state of being hot is hotness
The state of being directed is directedness
The state of being broken is brokenness
The state of being distinctive is distinctiveness
The state of being innovative is innovativeness
The state of being vast is vastness
The state of being attractive is
2024-07-27 10:11:54 root INFO     [order_1_approx] starting weight calculation for The state of being vast is vastness
The state of being distinctive is distinctiveness
The state of being attractive is attractiveness
The state of being innovative is innovativeness
The state of being hot is hotness
The state of being broken is brokenness
The state of being directed is directedness
The state of being strange is
2024-07-27 10:11:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 10:14:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2979,  0.0119,  0.0277,  ...,  0.0158, -0.1796,  0.1270],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5317, -2.2070, -2.7676,  ..., -2.7285, -4.7812, -1.7852],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0026, -0.0015, -0.0354,  ..., -0.0078,  0.0012,  0.0203],
        [-0.0018,  0.0116,  0.0037,  ...,  0.0108, -0.0110,  0.0049],
        [-0.0063, -0.0037,  0.0132,  ..., -0.0057, -0.0080,  0.0152],
        ...,
        [-0.0113,  0.0289,  0.0154,  ...,  0.0095, -0.0026,  0.0107],
        [-0.0022,  0.0187, -0.0069,  ..., -0.0095,  0.0263, -0.0310],
        [ 0.0094,  0.0026, -0.0032,  ...,  0.0135, -0.0247,  0.0065]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8438, -1.7637, -2.5508,  ..., -2.5957, -5.0195, -1.6797]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 10:14:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being vast is vastness
The state of being distinctive is distinctiveness
The state of being attractive is attractiveness
The state of being innovative is innovativeness
The state of being hot is hotness
The state of being broken is brokenness
The state of being directed is directedness
The state of being strange is
2024-07-27 10:14:42 root INFO     [order_1_approx] starting weight calculation for The state of being strange is strangeness
The state of being distinctive is distinctiveness
The state of being directed is directedness
The state of being attractive is attractiveness
The state of being innovative is innovativeness
The state of being hot is hotness
The state of being broken is brokenness
The state of being vast is
2024-07-27 10:14:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 10:17:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1714,  0.1190,  0.0790,  ...,  0.0970, -0.1858, -0.0472],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6924, -2.4980, -2.4922,  ..., -4.7500, -6.1289, -1.7090],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0268,  0.0062, -0.0058,  ..., -0.0190,  0.0051, -0.0075],
        [ 0.0015,  0.0079,  0.0021,  ...,  0.0184, -0.0100,  0.0233],
        [-0.0281, -0.0154,  0.0284,  ...,  0.0052, -0.0012,  0.0142],
        ...,
        [-0.0090, -0.0034,  0.0071,  ...,  0.0285, -0.0085,  0.0007],
        [ 0.0297, -0.0198, -0.0152,  ...,  0.0183,  0.0374, -0.0069],
        [-0.0164,  0.0325, -0.0039,  ...,  0.0107, -0.0088,  0.0042]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1816, -2.1797, -2.5410,  ..., -4.5078, -7.0234, -1.6357]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 10:17:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being strange is strangeness
The state of being distinctive is distinctiveness
The state of being directed is directedness
The state of being attractive is attractiveness
The state of being innovative is innovativeness
The state of being hot is hotness
The state of being broken is brokenness
The state of being vast is
2024-07-27 10:17:27 root INFO     total operator prediction time: 1326.306492805481 seconds
2024-07-27 10:17:27 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun+less_reg
2024-07-27 10:17:27 root INFO     building operator noun+less_reg
2024-07-27 10:17:28 root INFO     [order_1_approx] starting weight calculation for Something without meat is meatless
Something without heart is heartless
Something without window is windowless
Something without money is moneyless
Something without sensor is sensorless
Something without child is childless
Something without defence is defenceless
Something without penny is
2024-07-27 10:17:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 10:20:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0720, -0.3174, -0.2273,  ..., -0.2207, -0.1768, -0.0595],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4917, -3.2852, -0.7646,  ..., -5.0547, -4.9883, -2.0527],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0113, -0.0428,  0.0257,  ..., -0.0351, -0.0148,  0.0185],
        [ 0.0091,  0.0007,  0.0227,  ...,  0.0298, -0.0080,  0.0156],
        [ 0.0139, -0.0332,  0.0019,  ..., -0.0009,  0.0004,  0.0215],
        ...,
        [ 0.0036, -0.0208,  0.0280,  ..., -0.0304, -0.0193,  0.0214],
        [-0.0362, -0.0026,  0.0381,  ...,  0.0002, -0.0218, -0.0290],
        [ 0.0098,  0.0099, -0.0277,  ..., -0.0130, -0.0182,  0.0099]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6909, -3.6992, -0.9038,  ..., -4.7383, -4.3203, -1.9072]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 10:20:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without meat is meatless
Something without heart is heartless
Something without window is windowless
Something without money is moneyless
Something without sensor is sensorless
Something without child is childless
Something without defence is defenceless
Something without penny is
2024-07-27 10:20:12 root INFO     [order_1_approx] starting weight calculation for Something without heart is heartless
Something without money is moneyless
Something without meat is meatless
Something without child is childless
Something without sensor is sensorless
Something without window is windowless
Something without penny is penniless
Something without defence is
2024-07-27 10:20:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 10:22:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3374, -0.0548,  0.0923,  ..., -0.0447,  0.0012, -0.0908],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1133, -5.0703,  1.3457,  ..., -3.0957, -1.7920, -2.0566],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0093, -0.0083,  0.0179,  ...,  0.0350, -0.0203, -0.0022],
        [-0.0146, -0.0037, -0.0100,  ..., -0.0466, -0.0052,  0.0171],
        [ 0.0060, -0.0092,  0.0423,  ...,  0.0178, -0.0260, -0.0097],
        ...,
        [ 0.0026,  0.0083,  0.0117,  ..., -0.0100,  0.0204, -0.0180],
        [-0.0016, -0.0261, -0.0208,  ..., -0.0150,  0.0261, -0.0510],
        [ 0.0136, -0.0063, -0.0116,  ..., -0.0281, -0.0135,  0.0031]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9824, -4.9688,  0.8701,  ..., -3.3203, -1.8545, -2.2246]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 10:22:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without heart is heartless
Something without money is moneyless
Something without meat is meatless
Something without child is childless
Something without sensor is sensorless
Something without window is windowless
Something without penny is penniless
Something without defence is
2024-07-27 10:22:57 root INFO     [order_1_approx] starting weight calculation for Something without sensor is sensorless
Something without money is moneyless
Something without child is childless
Something without heart is heartless
Something without defence is defenceless
Something without window is windowless
Something without penny is penniless
Something without meat is
2024-07-27 10:22:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 10:25:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0970, -0.3469,  0.1475,  ..., -0.1597, -0.2593,  0.1573],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2422, -3.7832, -0.9941,  ..., -4.2109, -5.1016, -2.7461],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 9.5062e-03, -1.9867e-02, -2.0142e-02,  ...,  2.3010e-02,
         -1.7990e-02, -9.2163e-03],
        [ 2.0294e-02,  3.2654e-03,  2.0004e-02,  ..., -1.6403e-02,
         -1.7059e-02,  2.4307e-02],
        [-3.4210e-02, -2.5146e-02,  3.0716e-02,  ...,  2.9572e-02,
         -4.9973e-03,  7.0457e-03],
        ...,
        [ 1.9073e-05,  1.1093e-02,  4.8767e-02,  ..., -2.7252e-02,
          1.7761e-02,  8.0338e-03],
        [ 1.1597e-03,  2.1484e-02, -1.7654e-02,  ...,  5.1346e-03,
          3.8818e-02,  1.4677e-03],
        [-8.1635e-04,  2.4460e-02,  1.9638e-02,  ..., -7.5226e-03,
          1.2264e-03, -1.5167e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7617, -3.6953, -1.8496,  ..., -4.2734, -4.9219, -3.2832]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 10:25:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without sensor is sensorless
Something without money is moneyless
Something without child is childless
Something without heart is heartless
Something without defence is defenceless
Something without window is windowless
Something without penny is penniless
Something without meat is
2024-07-27 10:25:43 root INFO     [order_1_approx] starting weight calculation for Something without meat is meatless
Something without money is moneyless
Something without heart is heartless
Something without window is windowless
Something without sensor is sensorless
Something without penny is penniless
Something without defence is defenceless
Something without child is
2024-07-27 10:25:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 10:28:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0729, -0.3330,  0.0037,  ..., -0.3918, -0.4854,  0.0572],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.1318, -1.3691,  1.0645,  ..., -2.2480, -2.4922, -0.0332],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0469,  0.0156,  0.0447,  ..., -0.0163, -0.0306,  0.0771],
        [-0.0150, -0.0077, -0.0031,  ..., -0.0016,  0.0341,  0.0166],
        [ 0.0149, -0.0053,  0.0187,  ..., -0.0071, -0.0051, -0.0181],
        ...,
        [ 0.0249,  0.0147,  0.0324,  ..., -0.0264, -0.0025,  0.0201],
        [-0.0264, -0.0279, -0.0318,  ...,  0.0105,  0.0218, -0.0700],
        [-0.0015, -0.0023,  0.0019,  ..., -0.0342, -0.0396, -0.0111]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.9922, -1.4463,  0.8574,  ..., -2.1016, -2.3223, -0.9873]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 10:28:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without meat is meatless
Something without money is moneyless
Something without heart is heartless
Something without window is windowless
Something without sensor is sensorless
Something without penny is penniless
Something without defence is defenceless
Something without child is
2024-07-27 10:28:30 root INFO     [order_1_approx] starting weight calculation for Something without money is moneyless
Something without penny is penniless
Something without defence is defenceless
Something without sensor is sensorless
Something without heart is heartless
Something without child is childless
Something without meat is meatless
Something without window is
2024-07-27 10:28:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 10:31:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2695, -0.4556, -0.1729,  ...,  0.0490,  0.0677,  0.0617],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5176, -4.9375,  0.1650,  ..., -2.2188, -3.8457,  1.5195],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0253, -0.0388,  0.0062,  ...,  0.0137,  0.0083,  0.0291],
        [ 0.0236,  0.0052,  0.0087,  ..., -0.0306, -0.0212,  0.0256],
        [ 0.0294, -0.0009,  0.0064,  ..., -0.0029,  0.0039, -0.0074],
        ...,
        [ 0.0140,  0.0081,  0.0226,  ..., -0.0321,  0.0129, -0.0356],
        [-0.0452, -0.0143, -0.0294,  ..., -0.0026,  0.0075, -0.0316],
        [-0.0072,  0.0295, -0.0013,  ...,  0.0034,  0.0176, -0.0174]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8115, -5.7031, -0.2935,  ..., -2.4512, -4.1797,  1.9023]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 10:31:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without money is moneyless
Something without penny is penniless
Something without defence is defenceless
Something without sensor is sensorless
Something without heart is heartless
Something without child is childless
Something without meat is meatless
Something without window is
2024-07-27 10:31:15 root INFO     [order_1_approx] starting weight calculation for Something without money is moneyless
Something without meat is meatless
Something without window is windowless
Something without defence is defenceless
Something without penny is penniless
Something without child is childless
Something without sensor is sensorless
Something without heart is
2024-07-27 10:31:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 10:33:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0977, -0.3179, -0.0800,  ..., -0.2063, -0.1472,  0.1576],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1963, -3.8711, -0.9302,  ..., -3.4727, -2.1016, -2.6562],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0558,  0.0098,  0.0501,  ...,  0.0028, -0.0334,  0.0356],
        [-0.0231,  0.0386, -0.0065,  ...,  0.0017, -0.0117,  0.0128],
        [ 0.0103, -0.0055,  0.0307,  ...,  0.0131, -0.0103,  0.0045],
        ...,
        [-0.0059,  0.0278,  0.0022,  ...,  0.0086,  0.0013, -0.0045],
        [-0.0347,  0.0106, -0.0308,  ..., -0.0073,  0.0028, -0.0257],
        [ 0.0080, -0.0004, -0.0341,  ...,  0.0083, -0.0083,  0.0031]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0225, -4.5625, -2.1504,  ..., -3.3867, -1.4668, -2.6719]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 10:33:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without money is moneyless
Something without meat is meatless
Something without window is windowless
Something without defence is defenceless
Something without penny is penniless
Something without child is childless
Something without sensor is sensorless
Something without heart is
2024-07-27 10:33:59 root INFO     [order_1_approx] starting weight calculation for Something without heart is heartless
Something without meat is meatless
Something without window is windowless
Something without sensor is sensorless
Something without child is childless
Something without penny is penniless
Something without defence is defenceless
Something without money is
2024-07-27 10:33:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 10:36:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0482, -0.3589,  0.0989,  ..., -0.0548,  0.0274,  0.0332],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1646, -3.1328, -1.6221,  ..., -4.3125, -3.4219,  0.2119],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0341, -0.0300,  0.0109,  ..., -0.0323, -0.0023,  0.0539],
        [ 0.0078,  0.0316,  0.0231,  ...,  0.0088, -0.0240, -0.0098],
        [ 0.0267, -0.0258,  0.0331,  ..., -0.0497,  0.0103,  0.0238],
        ...,
        [ 0.0363, -0.0035,  0.0067,  ..., -0.0153, -0.0001, -0.0207],
        [-0.0422, -0.0085,  0.0091,  ...,  0.0110,  0.0448, -0.0238],
        [ 0.0258,  0.0142, -0.0074,  ...,  0.0231,  0.0045, -0.0221]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4753, -2.9414, -3.0957,  ..., -4.4219, -2.9688, -0.1992]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 10:36:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without heart is heartless
Something without meat is meatless
Something without window is windowless
Something without sensor is sensorless
Something without child is childless
Something without penny is penniless
Something without defence is defenceless
Something without money is
2024-07-27 10:36:43 root INFO     [order_1_approx] starting weight calculation for Something without defence is defenceless
Something without window is windowless
Something without money is moneyless
Something without heart is heartless
Something without penny is penniless
Something without meat is meatless
Something without child is childless
Something without sensor is
2024-07-27 10:36:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 10:39:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0540, -0.1019, -0.1547,  ..., -0.0911, -0.1414, -0.2949],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0879, -1.3779, -1.1650,  ..., -5.3203, -4.0117, -1.5352],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.5166e-02, -1.5991e-02, -9.5978e-03,  ..., -1.5879e-03,
          1.4801e-02, -1.1169e-02],
        [ 3.9825e-03,  4.3579e-02,  2.3346e-03,  ..., -2.3239e-02,
          1.2222e-02,  4.9164e-02],
        [ 3.1891e-02, -2.2308e-02,  1.2711e-02,  ..., -1.1223e-02,
         -2.5757e-02, -6.0310e-03],
        ...,
        [ 5.9906e-02,  9.5367e-06,  5.9998e-02,  ...,  3.2166e-02,
          8.6670e-03, -1.6663e-02],
        [-1.3428e-02, -1.4214e-02, -1.9531e-02,  ..., -2.9221e-02,
          6.5918e-03, -4.2389e-02],
        [ 2.7634e-02,  3.3997e-02,  1.8127e-02,  ...,  2.4872e-02,
         -5.8746e-03, -4.6158e-04]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4648, -2.3281, -1.2256,  ..., -5.2227, -3.5352, -1.6641]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 10:39:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without defence is defenceless
Something without window is windowless
Something without money is moneyless
Something without heart is heartless
Something without penny is penniless
Something without meat is meatless
Something without child is childless
Something without sensor is
2024-07-27 10:39:28 root INFO     total operator prediction time: 1320.322859287262 seconds
2024-07-27 10:39:28 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+ment_irreg
2024-07-27 10:39:28 root INFO     building operator verb+ment_irreg
2024-07-27 10:39:28 root INFO     [order_1_approx] starting weight calculation for To redevelop results in a redevelopment
To reimburse results in a reimbursement
To announce results in a announcement
To enlighten results in a enlightenment
To engage results in a engagement
To excite results in a excitement
To establish results in a establishment
To infringe results in a
2024-07-27 10:39:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 10:42:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0194,  0.5127, -0.2493,  ...,  0.0529, -0.2742, -0.1160],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4551, -6.0625,  1.1953,  ...,  0.8496, -1.4814, -0.2646],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.7695e-02, -5.8365e-04,  1.8097e-02,  ..., -1.6602e-02,
          5.7983e-04,  8.3618e-03],
        [-2.0046e-03,  2.3026e-02, -3.0785e-03,  ...,  3.1555e-02,
          5.2917e-02,  7.0953e-03],
        [-6.7596e-03, -3.1433e-02,  3.5095e-03,  ...,  2.2202e-03,
          2.9205e-02, -3.2104e-02],
        ...,
        [ 9.7809e-03, -1.8616e-03,  7.3395e-03,  ...,  5.8563e-02,
          1.7824e-03,  1.9653e-02],
        [ 2.3270e-03,  8.3923e-05,  1.5083e-02,  ...,  1.1429e-02,
          4.8004e-02, -1.5961e-02],
        [ 1.9058e-02, -6.1951e-03, -2.0935e-02,  ...,  2.1484e-02,
         -4.2480e-02,  1.3962e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4082, -5.1875,  1.2783,  ...,  1.0674, -2.1797, -0.1924]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 10:42:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To redevelop results in a redevelopment
To reimburse results in a reimbursement
To announce results in a announcement
To enlighten results in a enlightenment
To engage results in a engagement
To excite results in a excitement
To establish results in a establishment
To infringe results in a
2024-07-27 10:42:09 root INFO     [order_1_approx] starting weight calculation for To redevelop results in a redevelopment
To establish results in a establishment
To reimburse results in a reimbursement
To engage results in a engagement
To announce results in a announcement
To infringe results in a infringement
To enlighten results in a enlightenment
To excite results in a
2024-07-27 10:42:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 10:44:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1350,  0.3218, -0.1616,  ...,  0.1237, -0.3601,  0.0890],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8037, -2.4336,  0.6201,  ...,  3.1719, -0.6758, -2.4258],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0373,  0.0246,  0.0144,  ..., -0.0050,  0.0192,  0.0056],
        [-0.0274,  0.0522,  0.0054,  ...,  0.0108, -0.0193,  0.0077],
        [ 0.0031, -0.0096, -0.0068,  ..., -0.0045,  0.0085, -0.0193],
        ...,
        [ 0.0377,  0.0246, -0.0059,  ...,  0.0496,  0.0049, -0.0176],
        [ 0.0289, -0.0267,  0.0316,  ...,  0.0041,  0.0235, -0.0245],
        [-0.0247,  0.0118, -0.0099,  ...,  0.0341, -0.0279,  0.0384]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6592, -2.2520,  0.8208,  ...,  2.8633, -0.7949, -2.4883]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 10:44:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To redevelop results in a redevelopment
To establish results in a establishment
To reimburse results in a reimbursement
To engage results in a engagement
To announce results in a announcement
To infringe results in a infringement
To enlighten results in a enlightenment
To excite results in a
2024-07-27 10:44:54 root INFO     [order_1_approx] starting weight calculation for To redevelop results in a redevelopment
To announce results in a announcement
To infringe results in a infringement
To enlighten results in a enlightenment
To reimburse results in a reimbursement
To engage results in a engagement
To excite results in a excitement
To establish results in a
2024-07-27 10:44:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 10:47:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1951,  0.3081, -0.0685,  ..., -0.0836, -0.2211,  0.2196],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3604, -4.0391, -0.2646,  ...,  2.6348, -1.7900, -0.0986],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0421, -0.0079,  0.0007,  ...,  0.0152, -0.0328,  0.0047],
        [ 0.0128,  0.0535,  0.0146,  ...,  0.0247,  0.0186,  0.0081],
        [ 0.0417, -0.0076,  0.0216,  ..., -0.0098,  0.0277, -0.0043],
        ...,
        [-0.0034, -0.0060, -0.0103,  ...,  0.0190, -0.0168,  0.0203],
        [-0.0322,  0.0143,  0.0266,  ...,  0.0206,  0.0443,  0.0074],
        [ 0.0094, -0.0132,  0.0097,  ...,  0.0359, -0.0278,  0.0324]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7510, -3.8574, -0.1062,  ...,  2.6309, -1.7969, -0.4543]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 10:47:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To redevelop results in a redevelopment
To announce results in a announcement
To infringe results in a infringement
To enlighten results in a enlightenment
To reimburse results in a reimbursement
To engage results in a engagement
To excite results in a excitement
To establish results in a
2024-07-27 10:47:41 root INFO     [order_1_approx] starting weight calculation for To excite results in a excitement
To announce results in a announcement
To establish results in a establishment
To redevelop results in a redevelopment
To infringe results in a infringement
To reimburse results in a reimbursement
To engage results in a engagement
To enlighten results in a
2024-07-27 10:47:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 10:50:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1825,  0.5430, -0.0828,  ..., -0.1447, -0.5186,  0.1835],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0742, -0.8750,  2.1055,  ...,  5.1211, -1.6611, -2.3770],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-1.7929e-02,  9.5978e-03, -1.4252e-02,  ..., -3.5217e-02,
         -3.6449e-03, -1.3390e-02],
        [ 8.1253e-03,  3.4332e-03,  6.1035e-05,  ...,  3.2684e-02,
         -6.2065e-03,  1.5457e-02],
        [ 5.0201e-03, -8.7585e-03,  1.4862e-02,  ..., -4.0741e-03,
          5.5847e-03, -8.1253e-03],
        ...,
        [ 1.9043e-02, -3.2158e-03,  3.8338e-03,  ...,  5.4077e-02,
          6.2637e-03,  8.3313e-03],
        [ 1.9836e-02, -1.5518e-02, -3.7231e-03,  ...,  8.6689e-04,
          1.6129e-02, -3.8338e-03],
        [ 9.7513e-04, -2.6760e-03, -2.6665e-03,  ...,  2.3132e-02,
         -2.0752e-02,  3.0609e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3740, -0.9697,  1.9912,  ...,  4.8555, -1.7314, -2.4121]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 10:50:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To excite results in a excitement
To announce results in a announcement
To establish results in a establishment
To redevelop results in a redevelopment
To infringe results in a infringement
To reimburse results in a reimbursement
To engage results in a engagement
To enlighten results in a
2024-07-27 10:50:24 root INFO     [order_1_approx] starting weight calculation for To infringe results in a infringement
To excite results in a excitement
To establish results in a establishment
To engage results in a engagement
To reimburse results in a reimbursement
To announce results in a announcement
To enlighten results in a enlightenment
To redevelop results in a
2024-07-27 10:50:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 10:53:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1511,  0.3069, -0.3608,  ..., -0.0693, -0.0749, -0.1313],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0137, -4.8945,  0.7412,  ...,  1.8584, -1.3359, -2.8828],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.2583e-02,  1.5106e-02,  9.3651e-04,  ...,  2.1683e-02,
          2.8229e-03,  4.3640e-03],
        [-2.2583e-02,  4.5471e-02,  1.6800e-02,  ...,  3.9711e-03,
          4.3457e-02, -1.6953e-02],
        [-3.0243e-02, -3.9825e-03,  1.0452e-02,  ...,  2.7451e-02,
          2.6642e-02, -3.2921e-03],
        ...,
        [ 2.5848e-02,  6.5804e-05,  8.0338e-03,  ...,  4.8065e-02,
         -4.5471e-02,  6.2141e-03],
        [ 2.4826e-02, -5.9242e-03,  3.4607e-02,  ..., -1.9424e-02,
          3.7720e-02, -1.6708e-02],
        [-2.4597e-02, -2.9888e-03, -1.3939e-02,  ...,  7.7248e-03,
          1.6846e-02,  3.6102e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1292e-03, -4.5234e+00,  7.5635e-01,  ...,  1.8896e+00,
         -1.5840e+00, -2.9473e+00]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SubBackward0>) 

                    
2024-07-27 10:53:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To infringe results in a infringement
To excite results in a excitement
To establish results in a establishment
To engage results in a engagement
To reimburse results in a reimbursement
To announce results in a announcement
To enlighten results in a enlightenment
To redevelop results in a
2024-07-27 10:53:07 root INFO     [order_1_approx] starting weight calculation for To reimburse results in a reimbursement
To excite results in a excitement
To establish results in a establishment
To redevelop results in a redevelopment
To enlighten results in a enlightenment
To announce results in a announcement
To infringe results in a infringement
To engage results in a
2024-07-27 10:53:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 10:55:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0573,  0.4890, -0.0272,  ...,  0.1271, -0.2949, -0.0966],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4961, -3.9922, -0.3643,  ...,  2.0586, -0.9434, -4.0156],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.9882e-02,  1.5518e-02,  4.9591e-02,  ..., -1.9974e-02,
         -3.9581e-02, -1.2131e-03],
        [-1.6678e-02,  5.1270e-02, -9.5520e-03,  ...,  1.8616e-02,
          3.4912e-02,  2.4948e-02],
        [-2.6199e-02, -1.8326e-02,  5.0201e-03,  ...,  1.1871e-02,
          2.0416e-02, -7.9803e-03],
        ...,
        [ 3.2227e-02,  1.9821e-02,  1.4175e-02,  ...,  3.8086e-02,
          2.7908e-02,  1.6388e-02],
        [ 1.3893e-02,  4.6997e-03, -1.2070e-02,  ..., -1.8585e-02,
          3.4424e-02, -6.2943e-03],
        [-3.7918e-03,  9.1553e-05, -6.7940e-03,  ...,  3.6591e-02,
         -2.0081e-02,  6.7810e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5234, -3.5039, -0.2798,  ...,  1.7402, -0.7256, -3.9043]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 10:55:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To reimburse results in a reimbursement
To excite results in a excitement
To establish results in a establishment
To redevelop results in a redevelopment
To enlighten results in a enlightenment
To announce results in a announcement
To infringe results in a infringement
To engage results in a
2024-07-27 10:55:45 root INFO     [order_1_approx] starting weight calculation for To redevelop results in a redevelopment
To establish results in a establishment
To excite results in a excitement
To engage results in a engagement
To announce results in a announcement
To infringe results in a infringement
To enlighten results in a enlightenment
To reimburse results in a
2024-07-27 10:55:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 10:58:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0518,  0.3521, -0.3425,  ...,  0.0685, -0.1184, -0.2389],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0059, -3.3691, -0.6538,  ..., -1.1943, -1.4941, -2.0039],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0331,  0.0086,  0.0340,  ..., -0.0138, -0.0293,  0.0290],
        [-0.0047,  0.0435,  0.0287,  ...,  0.0085,  0.0278,  0.0023],
        [-0.0190, -0.0074,  0.0434,  ..., -0.0444,  0.0080, -0.0176],
        ...,
        [ 0.0248,  0.0043, -0.0076,  ...,  0.0288,  0.0181, -0.0181],
        [ 0.0192, -0.0110, -0.0006,  ..., -0.0182,  0.0519, -0.0215],
        [ 0.0406, -0.0040, -0.0176,  ...,  0.0127, -0.0257,  0.0745]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2168, -3.4297, -1.0078,  ..., -1.7158, -1.7178, -1.5889]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 10:58:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To redevelop results in a redevelopment
To establish results in a establishment
To excite results in a excitement
To engage results in a engagement
To announce results in a announcement
To infringe results in a infringement
To enlighten results in a enlightenment
To reimburse results in a
2024-07-27 10:58:31 root INFO     [order_1_approx] starting weight calculation for To infringe results in a infringement
To redevelop results in a redevelopment
To excite results in a excitement
To reimburse results in a reimbursement
To establish results in a establishment
To enlighten results in a enlightenment
To engage results in a engagement
To announce results in a
2024-07-27 10:58:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 11:01:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1627,  0.6865,  0.0016,  ...,  0.0687, -0.3066, -0.1106],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6836, -4.9609,  1.4473,  ...,  3.7285, -2.4531,  0.0801],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.7140e-02, -1.2909e-02, -1.9073e-05,  ...,  6.0234e-03,
         -3.5187e-02,  1.6205e-02],
        [ 1.9623e-02,  4.6539e-03, -1.8402e-02,  ...,  1.7578e-02,
          2.6550e-02,  2.9236e-02],
        [ 7.9651e-03, -2.9755e-02,  9.3536e-03,  ..., -2.7374e-02,
         -2.7908e-02, -1.3161e-02],
        ...,
        [ 8.5602e-03,  8.7814e-03, -2.1210e-02,  ...,  2.3285e-02,
         -2.7145e-02, -1.3313e-03],
        [-5.6686e-03, -4.8065e-03,  7.7972e-03,  ..., -6.0272e-03,
          4.3488e-02,  3.3226e-03],
        [-7.8430e-03, -1.1368e-02, -1.9196e-02,  ...,  8.5907e-03,
         -3.6530e-02,  1.5427e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6484, -4.5547,  1.3623,  ...,  3.4688, -2.3066, -0.2478]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 11:01:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To infringe results in a infringement
To redevelop results in a redevelopment
To excite results in a excitement
To reimburse results in a reimbursement
To establish results in a establishment
To enlighten results in a enlightenment
To engage results in a engagement
To announce results in a
2024-07-27 11:01:16 root INFO     total operator prediction time: 1308.3619029521942 seconds
2024-07-27 11:01:16 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on UK_city - county
2024-07-27 11:01:16 root INFO     building operator UK_city - county
2024-07-27 11:01:16 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of winchester is in the county of hampshire
In the United Kingdom, the city of reading is in the county of berkshire
In the United Kingdom, the city of bath is in the county of somerset
In the United Kingdom, the city of gloucester is in the county of gloucestershire
In the United Kingdom, the city of dundee is in the county of lowlands
In the United Kingdom, the city of newport is in the county of gwent
In the United Kingdom, the city of liverpool is in the county of lancashire
In the United Kingdom, the city of inverness is in the county of
2024-07-27 11:01:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 11:04:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0516,  0.1730, -0.1335,  ..., -0.0629,  0.0209,  0.0460],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0142, -6.1797,  1.8516,  ..., -6.8125, -1.3877, -3.8027],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0058, -0.0010,  0.0078,  ...,  0.0001, -0.0063,  0.0078],
        [ 0.0030,  0.0175,  0.0006,  ...,  0.0119, -0.0022, -0.0226],
        [-0.0323, -0.0015,  0.0037,  ...,  0.0111,  0.0036, -0.0066],
        ...,
        [ 0.0002,  0.0175, -0.0088,  ...,  0.0377, -0.0083, -0.0058],
        [ 0.0119,  0.0010,  0.0107,  ..., -0.0074, -0.0072,  0.0165],
        [ 0.0028, -0.0142, -0.0042,  ..., -0.0116, -0.0062,  0.0324]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0643, -6.1094,  1.6475,  ..., -6.1562, -1.5029, -3.7129]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 11:04:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of winchester is in the county of hampshire
In the United Kingdom, the city of reading is in the county of berkshire
In the United Kingdom, the city of bath is in the county of somerset
In the United Kingdom, the city of gloucester is in the county of gloucestershire
In the United Kingdom, the city of dundee is in the county of lowlands
In the United Kingdom, the city of newport is in the county of gwent
In the United Kingdom, the city of liverpool is in the county of lancashire
In the United Kingdom, the city of inverness is in the county of
2024-07-27 11:04:51 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of newport is in the county of gwent
In the United Kingdom, the city of bath is in the county of somerset
In the United Kingdom, the city of winchester is in the county of hampshire
In the United Kingdom, the city of gloucester is in the county of gloucestershire
In the United Kingdom, the city of liverpool is in the county of lancashire
In the United Kingdom, the city of inverness is in the county of highlands
In the United Kingdom, the city of dundee is in the county of lowlands
In the United Kingdom, the city of reading is in the county of
2024-07-27 11:04:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 11:08:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0551, -0.2118, -0.4529,  ...,  0.3757, -0.1672, -0.1074],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.4688, -8.0234,  2.4414,  ..., -3.3242,  1.9912, -3.9727],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0033, -0.0051, -0.0007,  ...,  0.0126,  0.0043, -0.0349],
        [-0.0121,  0.0042,  0.0225,  ...,  0.0072, -0.0225,  0.0247],
        [-0.0161,  0.0179,  0.0228,  ...,  0.0109, -0.0095, -0.0110],
        ...,
        [-0.0084,  0.0175, -0.0107,  ...,  0.0381, -0.0040, -0.0286],
        [-0.0156,  0.0051,  0.0450,  ..., -0.0036,  0.0258, -0.0154],
        [-0.0109,  0.0050,  0.0122,  ..., -0.0039, -0.0134, -0.0015]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.6016, -7.9141,  2.1230,  ..., -3.0840,  2.1094, -3.9668]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 11:08:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of newport is in the county of gwent
In the United Kingdom, the city of bath is in the county of somerset
In the United Kingdom, the city of winchester is in the county of hampshire
In the United Kingdom, the city of gloucester is in the county of gloucestershire
In the United Kingdom, the city of liverpool is in the county of lancashire
In the United Kingdom, the city of inverness is in the county of highlands
In the United Kingdom, the city of dundee is in the county of lowlands
In the United Kingdom, the city of reading is in the county of
2024-07-27 11:08:04 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of gloucester is in the county of gloucestershire
In the United Kingdom, the city of reading is in the county of berkshire
In the United Kingdom, the city of winchester is in the county of hampshire
In the United Kingdom, the city of inverness is in the county of highlands
In the United Kingdom, the city of newport is in the county of gwent
In the United Kingdom, the city of bath is in the county of somerset
In the United Kingdom, the city of dundee is in the county of lowlands
In the United Kingdom, the city of liverpool is in the county of
2024-07-27 11:08:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 11:11:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1663,  0.0360, -0.1373,  ...,  0.2128, -0.1034,  0.1730],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9727, -7.5078,  1.2549,  ..., -6.0312, -0.1328, -3.5195],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0121,  0.0217,  0.0204,  ...,  0.0218, -0.0023, -0.0488],
        [ 0.0030, -0.0110, -0.0071,  ..., -0.0029, -0.0169,  0.0054],
        [-0.0348,  0.0192, -0.0052,  ...,  0.0285,  0.0083, -0.0112],
        ...,
        [ 0.0118, -0.0056, -0.0082,  ...,  0.0246, -0.0024, -0.0263],
        [ 0.0138, -0.0207,  0.0211,  ..., -0.0068,  0.0047,  0.0044],
        [ 0.0206, -0.0161, -0.0210,  ..., -0.0156, -0.0307,  0.0122]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0195, -7.1328,  1.0557,  ..., -5.9141, -0.0260, -3.2988]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 11:11:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of gloucester is in the county of gloucestershire
In the United Kingdom, the city of reading is in the county of berkshire
In the United Kingdom, the city of winchester is in the county of hampshire
In the United Kingdom, the city of inverness is in the county of highlands
In the United Kingdom, the city of newport is in the county of gwent
In the United Kingdom, the city of bath is in the county of somerset
In the United Kingdom, the city of dundee is in the county of lowlands
In the United Kingdom, the city of liverpool is in the county of
2024-07-27 11:11:23 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of bath is in the county of somerset
In the United Kingdom, the city of liverpool is in the county of lancashire
In the United Kingdom, the city of reading is in the county of berkshire
In the United Kingdom, the city of gloucester is in the county of gloucestershire
In the United Kingdom, the city of inverness is in the county of highlands
In the United Kingdom, the city of dundee is in the county of lowlands
In the United Kingdom, the city of winchester is in the county of hampshire
In the United Kingdom, the city of newport is in the county of
2024-07-27 11:11:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 11:14:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2532,  0.0109, -0.1052,  ...,  0.1113, -0.0732,  0.0569],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.8164, -5.7266,  2.3633,  ..., -2.9453,  0.8843,  0.3730],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0118,  0.0004,  0.0231,  ...,  0.0070, -0.0208, -0.0393],
        [ 0.0184, -0.0172,  0.0469,  ...,  0.0482,  0.0168,  0.0095],
        [-0.0077,  0.0042,  0.0005,  ...,  0.0257,  0.0218, -0.0072],
        ...,
        [ 0.0107, -0.0031,  0.0009,  ...,  0.0460,  0.0046, -0.0183],
        [ 0.0215,  0.0085,  0.0055,  ...,  0.0186,  0.0012,  0.0112],
        [ 0.0260, -0.0156,  0.0221,  ..., -0.0250,  0.0102, -0.0161]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.8945, -5.8828,  2.1680,  ..., -3.0410,  0.8452, -0.0889]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 11:14:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of bath is in the county of somerset
In the United Kingdom, the city of liverpool is in the county of lancashire
In the United Kingdom, the city of reading is in the county of berkshire
In the United Kingdom, the city of gloucester is in the county of gloucestershire
In the United Kingdom, the city of inverness is in the county of highlands
In the United Kingdom, the city of dundee is in the county of lowlands
In the United Kingdom, the city of winchester is in the county of hampshire
In the United Kingdom, the city of newport is in the county of
2024-07-27 11:14:38 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of gloucester is in the county of gloucestershire
In the United Kingdom, the city of reading is in the county of berkshire
In the United Kingdom, the city of winchester is in the county of hampshire
In the United Kingdom, the city of dundee is in the county of lowlands
In the United Kingdom, the city of liverpool is in the county of lancashire
In the United Kingdom, the city of inverness is in the county of highlands
In the United Kingdom, the city of newport is in the county of gwent
In the United Kingdom, the city of bath is in the county of
2024-07-27 11:14:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 11:17:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3525,  0.0231,  0.1350,  ...,  0.2006, -0.4785, -0.0242],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9297, -3.9277, -0.2266,  ..., -1.4053, -0.6113, -1.2998],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0337,  0.0054, -0.0173,  ...,  0.0227,  0.0165, -0.0100],
        [ 0.0059,  0.0285,  0.0291,  ...,  0.0215, -0.0284, -0.0356],
        [-0.0636,  0.0138, -0.0226,  ...,  0.0360,  0.0206, -0.0435],
        ...,
        [-0.0339,  0.0247,  0.0031,  ...,  0.0136,  0.0169, -0.0898],
        [ 0.0510, -0.0461,  0.0152,  ..., -0.0180, -0.0078,  0.0464],
        [ 0.0216,  0.0008,  0.0137,  ..., -0.0016, -0.0093, -0.0094]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9199, -4.1797, -0.5166,  ..., -1.5039,  0.0825, -1.3174]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 11:17:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of gloucester is in the county of gloucestershire
In the United Kingdom, the city of reading is in the county of berkshire
In the United Kingdom, the city of winchester is in the county of hampshire
In the United Kingdom, the city of dundee is in the county of lowlands
In the United Kingdom, the city of liverpool is in the county of lancashire
In the United Kingdom, the city of inverness is in the county of highlands
In the United Kingdom, the city of newport is in the county of gwent
In the United Kingdom, the city of bath is in the county of
2024-07-27 11:17:56 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of inverness is in the county of highlands
In the United Kingdom, the city of reading is in the county of berkshire
In the United Kingdom, the city of newport is in the county of gwent
In the United Kingdom, the city of bath is in the county of somerset
In the United Kingdom, the city of dundee is in the county of lowlands
In the United Kingdom, the city of winchester is in the county of hampshire
In the United Kingdom, the city of liverpool is in the county of lancashire
In the United Kingdom, the city of gloucester is in the county of
2024-07-27 11:17:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 11:21:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1858, -0.1555, -0.1015,  ...,  0.0291, -0.3123,  0.1979],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1680, -5.1953,  2.5840,  ..., -4.3750,  2.5039, -2.2773],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0068,  0.0016,  0.0057,  ...,  0.0015,  0.0038, -0.0087],
        [-0.0130,  0.0026,  0.0034,  ...,  0.0105,  0.0049, -0.0238],
        [-0.0435,  0.0062,  0.0078,  ...,  0.0236,  0.0338, -0.0490],
        ...,
        [-0.0097, -0.0053, -0.0077,  ...,  0.0164,  0.0311, -0.0202],
        [-0.0025, -0.0066, -0.0017,  ...,  0.0068, -0.0145,  0.0046],
        [ 0.0011, -0.0190,  0.0044,  ..., -0.0025,  0.0095, -0.0167]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1660, -5.3125,  2.4180,  ..., -4.2070,  2.7285, -2.4922]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 11:21:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of inverness is in the county of highlands
In the United Kingdom, the city of reading is in the county of berkshire
In the United Kingdom, the city of newport is in the county of gwent
In the United Kingdom, the city of bath is in the county of somerset
In the United Kingdom, the city of dundee is in the county of lowlands
In the United Kingdom, the city of winchester is in the county of hampshire
In the United Kingdom, the city of liverpool is in the county of lancashire
In the United Kingdom, the city of gloucester is in the county of
2024-07-27 11:21:13 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of winchester is in the county of hampshire
In the United Kingdom, the city of reading is in the county of berkshire
In the United Kingdom, the city of bath is in the county of somerset
In the United Kingdom, the city of gloucester is in the county of gloucestershire
In the United Kingdom, the city of inverness is in the county of highlands
In the United Kingdom, the city of newport is in the county of gwent
In the United Kingdom, the city of liverpool is in the county of lancashire
In the United Kingdom, the city of dundee is in the county of
2024-07-27 11:21:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 11:24:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0470, -0.0112, -0.0381,  ...,  0.3296, -0.1218, -0.0715],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4727, -0.9097,  0.7671,  ..., -2.7715, -4.2539, -0.5938],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0017, -0.0019,  0.0230,  ...,  0.0065, -0.0040, -0.0250],
        [-0.0127,  0.0081,  0.0162,  ...,  0.0242, -0.0005, -0.0223],
        [-0.0213,  0.0105,  0.0302,  ...,  0.0182,  0.0090, -0.0302],
        ...,
        [-0.0104,  0.0153, -0.0007,  ...,  0.0245,  0.0057, -0.0271],
        [ 0.0201, -0.0093,  0.0024,  ..., -0.0191, -0.0058,  0.0131],
        [-0.0033, -0.0161, -0.0044,  ...,  0.0027, -0.0080,  0.0208]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2402, -1.1172,  0.1475,  ..., -2.6992, -3.8594, -0.6353]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 11:24:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of winchester is in the county of hampshire
In the United Kingdom, the city of reading is in the county of berkshire
In the United Kingdom, the city of bath is in the county of somerset
In the United Kingdom, the city of gloucester is in the county of gloucestershire
In the United Kingdom, the city of inverness is in the county of highlands
In the United Kingdom, the city of newport is in the county of gwent
In the United Kingdom, the city of liverpool is in the county of lancashire
In the United Kingdom, the city of dundee is in the county of
2024-07-27 11:24:35 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of liverpool is in the county of lancashire
In the United Kingdom, the city of reading is in the county of berkshire
In the United Kingdom, the city of gloucester is in the county of gloucestershire
In the United Kingdom, the city of dundee is in the county of lowlands
In the United Kingdom, the city of bath is in the county of somerset
In the United Kingdom, the city of newport is in the county of gwent
In the United Kingdom, the city of inverness is in the county of highlands
In the United Kingdom, the city of winchester is in the county of
2024-07-27 11:24:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 11:27:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0460,  0.1294, -0.2482,  ...,  0.0894, -0.3184,  0.0336],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9414, -6.9648,  1.9824,  ..., -5.1719,  0.0479, -0.3267],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0033,  0.0174, -0.0106,  ...,  0.0197, -0.0207, -0.0432],
        [-0.0383,  0.0257,  0.0302,  ...,  0.0221, -0.0698,  0.0011],
        [-0.0315,  0.0020, -0.0534,  ...,  0.0554,  0.0436, -0.0307],
        ...,
        [ 0.0063,  0.0197, -0.0166,  ...,  0.0031,  0.0049, -0.0028],
        [ 0.0301, -0.0348,  0.0241,  ..., -0.0017,  0.0226, -0.0117],
        [-0.0178,  0.0124, -0.0041,  ...,  0.0224, -0.0061, -0.0311]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6953, -6.1055,  1.6055,  ..., -4.7578,  0.4585, -0.3689]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 11:27:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of liverpool is in the county of lancashire
In the United Kingdom, the city of reading is in the county of berkshire
In the United Kingdom, the city of gloucester is in the county of gloucestershire
In the United Kingdom, the city of dundee is in the county of lowlands
In the United Kingdom, the city of bath is in the county of somerset
In the United Kingdom, the city of newport is in the county of gwent
In the United Kingdom, the city of inverness is in the county of highlands
In the United Kingdom, the city of winchester is in the county of
2024-07-27 11:27:49 root INFO     total operator prediction time: 1593.3206100463867 seconds
2024-07-27 11:27:49 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on name - nationality
2024-07-27 11:27:49 root INFO     building operator name - nationality
2024-07-27 11:27:50 root INFO     [order_1_approx] starting weight calculation for aristotle was greek
machiavelli was italian
balzac was french
wagner was german
lennon was english
newton was english
einstein was jewish
beethoven was
2024-07-27 11:27:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 11:30:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0377,  0.1188, -0.3931,  ..., -0.1901,  0.0300,  0.0035],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5684, -5.5469,  0.5469,  ..., -2.4336, -0.1445, -2.2559],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.2583e-03,  7.2479e-05, -3.0197e-02,  ..., -2.0676e-02,
         -1.5182e-03, -4.9561e-02],
        [ 6.7383e-02,  1.6266e-02,  4.9835e-02,  ..., -3.4729e-02,
         -6.4575e-02,  4.3152e-02],
        [-2.4658e-02, -1.6754e-02,  2.7435e-02,  ...,  2.9907e-02,
          7.6752e-03, -2.3895e-02],
        ...,
        [ 4.6021e-02,  1.0529e-02,  3.0136e-04,  ...,  5.1117e-03,
         -2.3621e-02,  1.1940e-02],
        [ 5.0201e-03, -2.3155e-03,  1.3916e-02,  ...,  7.8888e-03,
          5.7945e-03,  5.3024e-03],
        [ 5.6610e-03, -3.4637e-03,  9.5215e-03,  ..., -1.2360e-02,
         -3.1006e-02,  6.8848e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1406, -4.3945, -0.0098,  ..., -1.5459, -0.1049, -1.8496]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 11:30:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for aristotle was greek
machiavelli was italian
balzac was french
wagner was german
lennon was english
newton was english
einstein was jewish
beethoven was
2024-07-27 11:30:35 root INFO     [order_1_approx] starting weight calculation for wagner was german
aristotle was greek
balzac was french
machiavelli was italian
beethoven was german
lennon was english
newton was english
einstein was
2024-07-27 11:30:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 11:33:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1158, -0.3203, -0.4126,  ..., -0.2085, -0.1796,  0.3857],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3071, -4.4922,  0.7817,  ..., -2.6660, -2.2383, -0.0166],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.5735e-02,  1.5564e-02, -2.8519e-02,  ..., -2.0340e-02,
         -3.6835e-02,  2.0615e-02],
        [-3.7231e-02,  1.1871e-02,  1.3779e-02,  ...,  2.3315e-02,
         -5.0240e-03, -1.7532e-02],
        [-3.3020e-02, -7.2746e-03,  7.1655e-02,  ...,  6.1035e-05,
          3.0136e-04,  1.5335e-02],
        ...,
        [ 2.7710e-02,  2.8015e-02,  1.9257e-02,  ...,  7.7881e-02,
         -1.7303e-02,  3.9215e-02],
        [ 1.2970e-02, -5.9433e-03,  1.1322e-02,  ...,  2.6016e-03,
          3.0289e-02, -2.9449e-03],
        [ 2.3193e-03,  2.9144e-02,  2.1973e-02,  ..., -1.2802e-02,
          2.9068e-03,  7.0068e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0461, -4.2031,  0.6064,  ..., -2.1582, -2.0664,  0.4814]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 11:33:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for wagner was german
aristotle was greek
balzac was french
machiavelli was italian
beethoven was german
lennon was english
newton was english
einstein was
2024-07-27 11:33:20 root INFO     [order_1_approx] starting weight calculation for machiavelli was italian
einstein was jewish
aristotle was greek
beethoven was german
newton was english
wagner was german
balzac was french
lennon was
2024-07-27 11:33:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 11:36:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1415,  0.0563,  0.0059,  ...,  0.1166, -0.0908,  0.3269],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5215, -2.7852,  0.9751,  ..., -2.5117, -0.6724, -1.4629],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0136,  0.0124, -0.0066,  ...,  0.0177, -0.0147, -0.0008],
        [ 0.0523,  0.0238,  0.0158,  ..., -0.0216, -0.0011, -0.0093],
        [-0.0347, -0.0217,  0.0349,  ..., -0.0030,  0.0123, -0.0080],
        ...,
        [ 0.0074, -0.0116,  0.0214,  ...,  0.0490,  0.0108,  0.0081],
        [-0.0123, -0.0100,  0.0077,  ...,  0.0022, -0.0033,  0.0001],
        [-0.0021, -0.0286,  0.0053,  ..., -0.0183, -0.0067,  0.0444]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9473, -2.1855,  0.5215,  ..., -2.2930, -0.5171, -0.9004]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 11:36:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for machiavelli was italian
einstein was jewish
aristotle was greek
beethoven was german
newton was english
wagner was german
balzac was french
lennon was
2024-07-27 11:36:06 root INFO     [order_1_approx] starting weight calculation for balzac was french
wagner was german
lennon was english
beethoven was german
machiavelli was italian
newton was english
einstein was jewish
aristotle was
2024-07-27 11:36:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 11:38:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2671,  0.0378, -0.5361,  ..., -0.3062, -0.2659,  0.1887],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5352, -5.3320, -0.4927,  ..., -4.3359, -1.0420, -0.2112],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0645, -0.0157, -0.0093,  ..., -0.0100, -0.0491,  0.0173],
        [ 0.0277, -0.0017,  0.0147,  ...,  0.0010, -0.0113,  0.0356],
        [-0.0134, -0.0032,  0.0200,  ...,  0.0053, -0.0098, -0.0030],
        ...,
        [ 0.0794, -0.0269,  0.0054,  ...,  0.0258, -0.0260,  0.0352],
        [-0.0180,  0.0025,  0.0039,  ..., -0.0081,  0.0335, -0.0574],
        [-0.0066, -0.0074,  0.0033,  ..., -0.0149, -0.0247,  0.1049]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8184, -4.9531, -0.5288,  ..., -3.8203, -1.4482,  0.3992]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 11:38:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for balzac was french
wagner was german
lennon was english
beethoven was german
machiavelli was italian
newton was english
einstein was jewish
aristotle was
2024-07-27 11:38:52 root INFO     [order_1_approx] starting weight calculation for newton was english
aristotle was greek
balzac was french
beethoven was german
wagner was german
lennon was english
einstein was jewish
machiavelli was
2024-07-27 11:38:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 11:41:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0800, -0.0343, -0.4385,  ..., -0.3647, -0.1067,  0.0714],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.4414, -3.4902,  1.1064,  ..., -1.9697, -1.6191,  1.5859],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0311,  0.0135, -0.0183,  ..., -0.0031, -0.0111, -0.0164],
        [ 0.0161,  0.0273,  0.0241,  ...,  0.0074, -0.0340,  0.0022],
        [-0.0235, -0.0110,  0.0400,  ...,  0.0018, -0.0146, -0.0080],
        ...,
        [ 0.0274,  0.0230, -0.0034,  ...,  0.0468, -0.0079,  0.0178],
        [ 0.0179,  0.0030, -0.0145,  ...,  0.0165,  0.0293,  0.0088],
        [-0.0083, -0.0081,  0.0046,  ..., -0.0177, -0.0218,  0.0414]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.4570, -3.1582,  0.8477,  ..., -1.9580, -1.3027,  1.7275]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 11:41:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for newton was english
aristotle was greek
balzac was french
beethoven was german
wagner was german
lennon was english
einstein was jewish
machiavelli was
2024-07-27 11:41:38 root INFO     [order_1_approx] starting weight calculation for beethoven was german
lennon was english
newton was english
einstein was jewish
machiavelli was italian
aristotle was greek
wagner was german
balzac was
2024-07-27 11:41:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 11:44:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1774,  0.0891, -0.5107,  ..., -0.2500, -0.1125, -0.0504],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.2383, -3.0391,  1.8838,  ..., -3.9023,  0.0273,  1.0000],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0822,  0.0101, -0.0203,  ...,  0.0124, -0.0364, -0.0284],
        [-0.0033,  0.0392,  0.0411,  ...,  0.0180, -0.0002,  0.0068],
        [-0.0065, -0.0056,  0.0795,  ...,  0.0218,  0.0159,  0.0057],
        ...,
        [ 0.0121, -0.0114, -0.0104,  ...,  0.0468, -0.0202,  0.0405],
        [ 0.0222, -0.0153, -0.0161,  ...,  0.0371,  0.0508, -0.0035],
        [-0.0692,  0.0126,  0.0421,  ...,  0.0206, -0.0264,  0.0668]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.3086, -3.1328,  1.7324,  ..., -3.3184, -0.1583,  1.4395]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 11:44:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for beethoven was german
lennon was english
newton was english
einstein was jewish
machiavelli was italian
aristotle was greek
wagner was german
balzac was
2024-07-27 11:44:22 root INFO     [order_1_approx] starting weight calculation for einstein was jewish
wagner was german
beethoven was german
balzac was french
machiavelli was italian
lennon was english
aristotle was greek
newton was
2024-07-27 11:44:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 11:47:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2335,  0.0728, -0.1462,  ..., -0.2969, -0.0053,  0.2434],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.5508, -1.5449, -0.3066,  ..., -4.5859, -1.5059, -1.8848],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0609,  0.0019, -0.0131,  ..., -0.0038, -0.0418, -0.0109],
        [-0.0105,  0.0630,  0.0487,  ..., -0.0394, -0.0073, -0.0163],
        [ 0.0025, -0.0156,  0.0370,  ...,  0.0276,  0.0007,  0.0155],
        ...,
        [ 0.0250,  0.0020,  0.0538,  ..., -0.0196, -0.0102,  0.0152],
        [ 0.0042, -0.0282,  0.0029,  ...,  0.0558,  0.0179, -0.0166],
        [-0.0376,  0.0156,  0.0513,  ..., -0.0460, -0.0018,  0.0727]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2949, -1.3311, -0.4883,  ..., -3.9043, -1.4756, -1.2578]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 11:47:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for einstein was jewish
wagner was german
beethoven was german
balzac was french
machiavelli was italian
lennon was english
aristotle was greek
newton was
2024-07-27 11:47:08 root INFO     [order_1_approx] starting weight calculation for lennon was english
balzac was french
beethoven was german
einstein was jewish
newton was english
machiavelli was italian
aristotle was greek
wagner was
2024-07-27 11:47:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 11:49:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2786,  0.4487,  0.0513,  ...,  0.1378, -0.0229,  0.0887],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2422, -5.7969,  0.8071,  ..., -3.0586, -1.3379, -0.6680],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0092, -0.0365, -0.0334,  ..., -0.0532, -0.0458, -0.0662],
        [ 0.0406,  0.0681,  0.0403,  ...,  0.0179, -0.0023,  0.0112],
        [-0.0440,  0.0346,  0.0451,  ...,  0.0402,  0.0216, -0.0436],
        ...,
        [ 0.0403,  0.0111,  0.0445,  ...,  0.0509, -0.0292,  0.0573],
        [ 0.0304,  0.0037,  0.0274,  ...,  0.0026,  0.0144,  0.0174],
        [ 0.0032,  0.0285,  0.0157,  ...,  0.0134,  0.0018,  0.0938]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4746, -5.1562,  0.7080,  ..., -2.5742, -1.4824,  0.3438]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 11:49:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for lennon was english
balzac was french
beethoven was german
einstein was jewish
newton was english
machiavelli was italian
aristotle was greek
wagner was
2024-07-27 11:49:54 root INFO     total operator prediction time: 1324.1491780281067 seconds
2024-07-27 11:49:54 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on country - language
2024-07-27 11:49:54 root INFO     building operator country - language
2024-07-27 11:49:54 root INFO     [order_1_approx] starting weight calculation for The country of guyana primarily speaks the language of english
The country of iran primarily speaks the language of persian
The country of australia primarily speaks the language of english
The country of philippines primarily speaks the language of tagalog
The country of fiji primarily speaks the language of english
The country of barbados primarily speaks the language of english
The country of ireland primarily speaks the language of english
The country of egypt primarily speaks the language of
2024-07-27 11:49:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 11:52:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1256, -0.0571, -0.1565,  ..., -0.0461, -0.4707,  0.0555],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.3320, -4.8281,  2.8125,  ..., -1.3223,  0.1816, -0.0654],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0122,  0.0047,  0.0233,  ..., -0.0435,  0.0049,  0.0154],
        [-0.0047,  0.0084,  0.0121,  ...,  0.0003, -0.0112,  0.0076],
        [-0.0286,  0.0027,  0.0269,  ...,  0.0411, -0.0177, -0.0282],
        ...,
        [-0.0210,  0.0083, -0.0260,  ...,  0.0837, -0.0002, -0.0079],
        [ 0.0130, -0.0097,  0.0190,  ..., -0.0025,  0.0184, -0.0078],
        [-0.0019, -0.0141, -0.0065,  ...,  0.0313, -0.0144,  0.0010]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4995, -4.5000,  2.1230,  ..., -1.9062,  0.3862, -0.3813]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 11:52:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of guyana primarily speaks the language of english
The country of iran primarily speaks the language of persian
The country of australia primarily speaks the language of english
The country of philippines primarily speaks the language of tagalog
The country of fiji primarily speaks the language of english
The country of barbados primarily speaks the language of english
The country of ireland primarily speaks the language of english
The country of egypt primarily speaks the language of
2024-07-27 11:52:39 root INFO     [order_1_approx] starting weight calculation for The country of guyana primarily speaks the language of english
The country of egypt primarily speaks the language of arabic
The country of iran primarily speaks the language of persian
The country of barbados primarily speaks the language of english
The country of fiji primarily speaks the language of english
The country of ireland primarily speaks the language of english
The country of philippines primarily speaks the language of tagalog
The country of australia primarily speaks the language of
2024-07-27 11:52:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 11:55:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0828, -0.0060, -0.0573,  ...,  0.1897, -0.4006,  0.1022],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3125, -1.9980,  1.7158,  ..., -0.5605, -1.4043, -2.1055],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0202, -0.0193,  0.0056,  ..., -0.0109, -0.0039,  0.0129],
        [ 0.0097,  0.0061,  0.0090,  ..., -0.0045, -0.0030,  0.0054],
        [-0.0310,  0.0163,  0.0035,  ...,  0.0116, -0.0105, -0.0109],
        ...,
        [-0.0316,  0.0194, -0.0070,  ...,  0.0085,  0.0028, -0.0199],
        [ 0.0129, -0.0048,  0.0261,  ...,  0.0143,  0.0202,  0.0055],
        [ 0.0033, -0.0229, -0.0095,  ...,  0.0018, -0.0100,  0.0225]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4434, -1.7676,  1.3613,  ..., -0.9834, -1.4248, -1.9336]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 11:55:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of guyana primarily speaks the language of english
The country of egypt primarily speaks the language of arabic
The country of iran primarily speaks the language of persian
The country of barbados primarily speaks the language of english
The country of fiji primarily speaks the language of english
The country of ireland primarily speaks the language of english
The country of philippines primarily speaks the language of tagalog
The country of australia primarily speaks the language of
2024-07-27 11:55:24 root INFO     [order_1_approx] starting weight calculation for The country of barbados primarily speaks the language of english
The country of philippines primarily speaks the language of tagalog
The country of guyana primarily speaks the language of english
The country of ireland primarily speaks the language of english
The country of fiji primarily speaks the language of english
The country of egypt primarily speaks the language of arabic
The country of australia primarily speaks the language of english
The country of iran primarily speaks the language of
2024-07-27 11:55:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 11:58:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0578,  0.0308, -0.2334,  ..., -0.2517, -0.2949,  0.1659],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4622, -4.5898, -0.3071,  ..., -0.0400, -1.3125, -2.7266],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0132,  0.0328,  0.0041,  ..., -0.0611,  0.0214,  0.0257],
        [-0.0098,  0.0069,  0.0155,  ..., -0.0017, -0.0136,  0.0041],
        [ 0.0005, -0.0049,  0.0472,  ..., -0.0213,  0.0055, -0.0208],
        ...,
        [-0.0087,  0.0002,  0.0085,  ...,  0.0363, -0.0014, -0.0228],
        [-0.0038,  0.0404,  0.0160,  ..., -0.0611,  0.0376,  0.0246],
        [-0.0024, -0.0172, -0.0005,  ...,  0.0242, -0.0080,  0.0185]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6074, -4.0039, -0.2832,  ...,  0.2429, -1.2510, -2.5410]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 11:58:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of barbados primarily speaks the language of english
The country of philippines primarily speaks the language of tagalog
The country of guyana primarily speaks the language of english
The country of ireland primarily speaks the language of english
The country of fiji primarily speaks the language of english
The country of egypt primarily speaks the language of arabic
The country of australia primarily speaks the language of english
The country of iran primarily speaks the language of
2024-07-27 11:58:05 root INFO     [order_1_approx] starting weight calculation for The country of fiji primarily speaks the language of english
The country of ireland primarily speaks the language of english
The country of barbados primarily speaks the language of english
The country of guyana primarily speaks the language of english
The country of iran primarily speaks the language of persian
The country of australia primarily speaks the language of english
The country of egypt primarily speaks the language of arabic
The country of philippines primarily speaks the language of
2024-07-27 11:58:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 12:00:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1013, -0.1149, -0.4868,  ...,  0.2744, -0.4907,  0.0336],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.5039, -1.4004,  1.2246,  ..., -1.3281, -1.6641, -1.7812],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0157, -0.0087,  0.0009,  ..., -0.0009, -0.0027,  0.0068],
        [ 0.0056,  0.0120,  0.0150,  ..., -0.0043, -0.0152,  0.0052],
        [-0.0140,  0.0176,  0.0080,  ..., -0.0105,  0.0066, -0.0062],
        ...,
        [ 0.0013, -0.0025, -0.0111,  ...,  0.0260,  0.0137, -0.0118],
        [ 0.0076, -0.0080,  0.0201,  ...,  0.0123,  0.0068,  0.0045],
        [-0.0086, -0.0027, -0.0064,  ...,  0.0017, -0.0082,  0.0020]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.5898, -1.2666,  1.2822,  ..., -1.2842, -1.6406, -1.7090]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 12:00:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of fiji primarily speaks the language of english
The country of ireland primarily speaks the language of english
The country of barbados primarily speaks the language of english
The country of guyana primarily speaks the language of english
The country of iran primarily speaks the language of persian
The country of australia primarily speaks the language of english
The country of egypt primarily speaks the language of arabic
The country of philippines primarily speaks the language of
2024-07-27 12:00:48 root INFO     [order_1_approx] starting weight calculation for The country of ireland primarily speaks the language of english
The country of guyana primarily speaks the language of english
The country of australia primarily speaks the language of english
The country of egypt primarily speaks the language of arabic
The country of philippines primarily speaks the language of tagalog
The country of barbados primarily speaks the language of english
The country of iran primarily speaks the language of persian
The country of fiji primarily speaks the language of
2024-07-27 12:00:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 12:03:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1777, -0.1846, -0.2262,  ...,  0.1146, -0.3867, -0.2969],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0796,  0.5977,  3.0449,  ...,  0.8770, -3.3633, -0.5713],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0282, -0.0054,  0.0410,  ...,  0.0070, -0.0089,  0.0171],
        [-0.0119, -0.0001,  0.0011,  ..., -0.0133, -0.0319, -0.0114],
        [-0.0222, -0.0072,  0.0530,  ..., -0.0276,  0.0076, -0.0045],
        ...,
        [-0.0080, -0.0013,  0.0228,  ...,  0.0356,  0.0190, -0.0217],
        [ 0.0118,  0.0229,  0.0278,  ...,  0.0080,  0.0466,  0.0364],
        [ 0.0020, -0.0167,  0.0172,  ...,  0.0117, -0.0062,  0.0412]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1965,  0.9673,  3.3496,  ...,  1.0615, -3.3633, -0.3411]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 12:03:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of ireland primarily speaks the language of english
The country of guyana primarily speaks the language of english
The country of australia primarily speaks the language of english
The country of egypt primarily speaks the language of arabic
The country of philippines primarily speaks the language of tagalog
The country of barbados primarily speaks the language of english
The country of iran primarily speaks the language of persian
The country of fiji primarily speaks the language of
2024-07-27 12:03:34 root INFO     [order_1_approx] starting weight calculation for The country of philippines primarily speaks the language of tagalog
The country of barbados primarily speaks the language of english
The country of australia primarily speaks the language of english
The country of iran primarily speaks the language of persian
The country of guyana primarily speaks the language of english
The country of fiji primarily speaks the language of english
The country of egypt primarily speaks the language of arabic
The country of ireland primarily speaks the language of
2024-07-27 12:03:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 12:06:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1392,  0.0708, -0.3728,  ...,  0.1636,  0.0274,  0.0999],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8599, -2.5371,  0.1533,  ...,  0.1162,  0.2559, -2.9629],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 8.3618e-03, -6.3896e-03,  5.2986e-03,  ..., -1.2161e-02,
          2.9106e-03,  1.3130e-02],
        [ 1.2207e-03,  3.3661e-02,  1.3290e-02,  ..., -1.4801e-02,
         -1.9989e-02, -5.3406e-05],
        [-1.2884e-03,  1.5640e-02,  2.0035e-02,  ..., -1.6068e-02,
          2.5177e-04, -1.2169e-02],
        ...,
        [-1.3214e-02,  1.5945e-02,  4.0359e-03,  ...,  4.0314e-02,
         -1.8280e-02, -5.4550e-03],
        [-6.0997e-03,  1.2703e-02,  1.3062e-02,  ...,  7.1335e-03,
          1.0872e-02,  8.3237e-03],
        [ 1.5411e-02, -2.4521e-02,  1.9485e-02,  ...,  1.2703e-02,
         -1.1406e-02,  2.4170e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7065, -2.3574, -0.1736,  ..., -0.0123, -0.0032, -2.6602]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 12:06:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of philippines primarily speaks the language of tagalog
The country of barbados primarily speaks the language of english
The country of australia primarily speaks the language of english
The country of iran primarily speaks the language of persian
The country of guyana primarily speaks the language of english
The country of fiji primarily speaks the language of english
The country of egypt primarily speaks the language of arabic
The country of ireland primarily speaks the language of
2024-07-27 12:06:21 root INFO     [order_1_approx] starting weight calculation for The country of ireland primarily speaks the language of english
The country of philippines primarily speaks the language of tagalog
The country of australia primarily speaks the language of english
The country of fiji primarily speaks the language of english
The country of egypt primarily speaks the language of arabic
The country of iran primarily speaks the language of persian
The country of barbados primarily speaks the language of english
The country of guyana primarily speaks the language of
2024-07-27 12:06:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 12:09:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2460, -0.0997,  0.0750,  ...,  0.0493, -0.4873, -0.2162],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9873, -0.0078,  1.8125,  ...,  0.4441,  0.7871, -3.6016],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0005,  0.0080,  0.0049,  ...,  0.0012,  0.0122, -0.0049],
        [ 0.0012,  0.0242, -0.0128,  ...,  0.0141, -0.0235, -0.0144],
        [-0.0105,  0.0128,  0.0401,  ..., -0.0324,  0.0025, -0.0192],
        ...,
        [ 0.0002, -0.0019, -0.0062,  ...,  0.0358, -0.0074, -0.0294],
        [-0.0157,  0.0340, -0.0164,  ..., -0.0005,  0.0232,  0.0046],
        [ 0.0191, -0.0083, -0.0042,  ..., -0.0105,  0.0050,  0.0302]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8232,  0.1173,  2.1367,  ...,  0.3989,  0.4697, -3.1230]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 12:09:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of ireland primarily speaks the language of english
The country of philippines primarily speaks the language of tagalog
The country of australia primarily speaks the language of english
The country of fiji primarily speaks the language of english
The country of egypt primarily speaks the language of arabic
The country of iran primarily speaks the language of persian
The country of barbados primarily speaks the language of english
The country of guyana primarily speaks the language of
2024-07-27 12:09:05 root INFO     [order_1_approx] starting weight calculation for The country of australia primarily speaks the language of english
The country of fiji primarily speaks the language of english
The country of philippines primarily speaks the language of tagalog
The country of iran primarily speaks the language of persian
The country of egypt primarily speaks the language of arabic
The country of ireland primarily speaks the language of english
The country of guyana primarily speaks the language of english
The country of barbados primarily speaks the language of
2024-07-27 12:09:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 12:11:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0421,  0.0048, -0.3000,  ...,  0.2600, -0.3804, -0.2000],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6719, -0.2620,  1.2871,  ...,  0.4177,  1.4004, -3.2188],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.4687e-02,  9.6054e-03,  2.0767e-02,  ..., -1.3687e-02,
         -1.1642e-02,  8.0338e-03],
        [-5.6648e-03,  9.2468e-03, -1.0986e-03,  ..., -3.1033e-03,
          1.0319e-03, -5.4359e-05],
        [-2.1027e-02,  9.3079e-03,  3.3295e-02,  ..., -2.8275e-02,
         -4.7989e-03, -1.0963e-02],
        ...,
        [-1.5533e-02,  1.1337e-02,  2.0737e-02,  ..., -4.7035e-03,
         -1.2245e-02, -1.3374e-02],
        [-1.8530e-03,  9.6512e-03,  2.4395e-03,  ...,  5.6686e-03,
          1.3535e-02,  1.4565e-02],
        [ 5.6076e-03, -9.2545e-03,  8.7128e-03,  ..., -1.1604e-02,
         -2.9640e-03,  2.1500e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9326, -0.3030,  1.3252,  ...,  0.1372,  1.2012, -3.0137]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 12:11:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of australia primarily speaks the language of english
The country of fiji primarily speaks the language of english
The country of philippines primarily speaks the language of tagalog
The country of iran primarily speaks the language of persian
The country of egypt primarily speaks the language of arabic
The country of ireland primarily speaks the language of english
The country of guyana primarily speaks the language of english
The country of barbados primarily speaks the language of
2024-07-27 12:11:54 root INFO     total operator prediction time: 1320.2724590301514 seconds
2024-07-27 12:11:54 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - shelter
2024-07-27 12:11:54 root INFO     building operator animal - shelter
2024-07-27 12:11:54 root INFO     [order_1_approx] starting weight calculation for The place dolphin lives in is called sea
The place crocodile lives in is called river
The place duck lives in is called pond
The place beaver lives in is called dam
The place cattle lives in is called barn
The place wolf lives in is called den
The place goldfish lives in is called pond
The place rabbit lives in is called
2024-07-27 12:11:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 12:14:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1091, -0.0306, -0.1142,  ..., -0.0781, -0.2708, -0.1464],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9395, -6.2344,  2.7148,  ...,  0.1792,  0.3481, -0.5703],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0294, -0.0082,  0.0178,  ...,  0.0182, -0.0070,  0.0002],
        [-0.0209,  0.0306, -0.0114,  ...,  0.0090, -0.0309,  0.0207],
        [-0.0153, -0.0005,  0.0180,  ..., -0.0093,  0.0118,  0.0188],
        ...,
        [-0.0015,  0.0042, -0.0035,  ...,  0.0190,  0.0130,  0.0104],
        [-0.0015,  0.0082,  0.0123,  ...,  0.0017,  0.0258,  0.0194],
        [-0.0137,  0.0081,  0.0033,  ..., -0.0087,  0.0027,  0.0084]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9473, -6.2773,  2.7695,  ..., -0.0896,  0.4771, -0.8789]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 12:14:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place dolphin lives in is called sea
The place crocodile lives in is called river
The place duck lives in is called pond
The place beaver lives in is called dam
The place cattle lives in is called barn
The place wolf lives in is called den
The place goldfish lives in is called pond
The place rabbit lives in is called
2024-07-27 12:14:37 root INFO     [order_1_approx] starting weight calculation for The place beaver lives in is called dam
The place goldfish lives in is called pond
The place rabbit lives in is called burrow
The place duck lives in is called pond
The place cattle lives in is called barn
The place wolf lives in is called den
The place dolphin lives in is called sea
The place crocodile lives in is called
2024-07-27 12:14:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 12:17:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2214, -0.0101, -0.2017,  ..., -0.2334, -0.2158,  0.1700],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3086, -6.3516,  1.7148,  ..., -2.2090,  1.0762,  0.1387],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0016, -0.0061,  0.0071,  ...,  0.0111,  0.0069, -0.0004],
        [ 0.0006, -0.0095, -0.0054,  ..., -0.0181, -0.0127,  0.0058],
        [-0.0008,  0.0048,  0.0099,  ...,  0.0023, -0.0037,  0.0041],
        ...,
        [ 0.0003,  0.0057, -0.0057,  ...,  0.0058,  0.0018, -0.0059],
        [-0.0007, -0.0051,  0.0007,  ...,  0.0059,  0.0068,  0.0056],
        [-0.0087, -0.0014, -0.0029,  ..., -0.0040, -0.0026,  0.0087]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4316, -6.2891,  1.6865,  ..., -2.2930,  0.9653,  0.1859]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 12:17:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place beaver lives in is called dam
The place goldfish lives in is called pond
The place rabbit lives in is called burrow
The place duck lives in is called pond
The place cattle lives in is called barn
The place wolf lives in is called den
The place dolphin lives in is called sea
The place crocodile lives in is called
2024-07-27 12:17:21 root INFO     [order_1_approx] starting weight calculation for The place beaver lives in is called dam
The place goldfish lives in is called pond
The place crocodile lives in is called river
The place cattle lives in is called barn
The place duck lives in is called pond
The place rabbit lives in is called burrow
The place dolphin lives in is called sea
The place wolf lives in is called
2024-07-27 12:17:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 12:20:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0900,  0.0637, -0.1396,  ..., -0.1295, -0.1014,  0.0703],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([  4.2891, -11.1562,   1.1123,  ...,  -3.6328,   0.0770,   0.6875],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0446, -0.0434, -0.0025,  ...,  0.0103,  0.0049,  0.0205],
        [-0.0142,  0.0057, -0.0175,  ..., -0.0161, -0.0087,  0.0229],
        [ 0.0115, -0.0223,  0.0447,  ...,  0.0102,  0.0110, -0.0192],
        ...,
        [-0.0255, -0.0035, -0.0121,  ...,  0.0420, -0.0054, -0.0080],
        [ 0.0091, -0.0123,  0.0004,  ..., -0.0025,  0.0479, -0.0219],
        [-0.0170, -0.0237, -0.0161,  ...,  0.0093, -0.0193,  0.0186]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[  4.1641, -10.6641,   1.0869,  ...,  -3.3516,  -0.1385,   0.8926]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 12:20:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place beaver lives in is called dam
The place goldfish lives in is called pond
The place crocodile lives in is called river
The place cattle lives in is called barn
The place duck lives in is called pond
The place rabbit lives in is called burrow
The place dolphin lives in is called sea
The place wolf lives in is called
2024-07-27 12:20:03 root INFO     [order_1_approx] starting weight calculation for The place crocodile lives in is called river
The place goldfish lives in is called pond
The place beaver lives in is called dam
The place rabbit lives in is called burrow
The place wolf lives in is called den
The place cattle lives in is called barn
The place duck lives in is called pond
The place dolphin lives in is called
2024-07-27 12:20:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 12:22:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1747, -0.1292, -0.2651,  ..., -0.4006, -0.2158,  0.1058],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7358, -5.8672,  0.3987,  ..., -2.2090,  0.2593,  1.1758],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.8950e-03, -1.3702e-02,  9.7961e-03,  ...,  3.0079e-03,
          7.1716e-04, -1.8120e-03],
        [-2.5215e-03, -3.8681e-03, -7.5302e-03,  ..., -1.3313e-02,
         -1.1871e-02,  1.3176e-02],
        [-4.4975e-03,  2.0676e-03,  1.1642e-02,  ...,  3.0766e-03,
         -1.6327e-03,  1.2903e-03],
        ...,
        [-1.3590e-05,  7.3395e-03, -4.8089e-04,  ...,  5.7564e-03,
         -2.5368e-04, -3.6087e-03],
        [ 1.3208e-04, -3.3607e-03,  8.1711e-03,  ..., -1.4734e-03,
         -7.5874e-03,  1.0239e-02],
        [-7.8278e-03, -4.4212e-03,  1.3905e-03,  ..., -2.3708e-03,
         -4.5357e-03,  1.8272e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9385, -5.7383,  0.4558,  ..., -2.2227,  0.0874,  1.1973]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 12:22:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place crocodile lives in is called river
The place goldfish lives in is called pond
The place beaver lives in is called dam
The place rabbit lives in is called burrow
The place wolf lives in is called den
The place cattle lives in is called barn
The place duck lives in is called pond
The place dolphin lives in is called
2024-07-27 12:22:39 root INFO     [order_1_approx] starting weight calculation for The place duck lives in is called pond
The place rabbit lives in is called burrow
The place wolf lives in is called den
The place goldfish lives in is called pond
The place crocodile lives in is called river
The place dolphin lives in is called sea
The place cattle lives in is called barn
The place beaver lives in is called
2024-07-27 12:22:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 12:25:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0463,  0.1958, -0.0618,  ..., -0.1912, -0.2074,  0.0704],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7002, -6.0156, -0.0723,  ..., -2.5547,  0.3232, -0.6377],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0461, -0.0018, -0.0152,  ...,  0.0292, -0.0262, -0.0333],
        [ 0.0070,  0.0470,  0.0103,  ...,  0.0606,  0.0083, -0.0307],
        [ 0.0131, -0.0048,  0.0318,  ..., -0.0242, -0.0314,  0.0046],
        ...,
        [-0.0309,  0.0359, -0.0119,  ...,  0.0615,  0.0027, -0.0077],
        [ 0.0320,  0.0287,  0.0153,  ...,  0.0294,  0.0399, -0.0091],
        [-0.0349,  0.0033, -0.0208,  ..., -0.0276, -0.0306,  0.0412]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 7.0752e-01, -5.7070e+00, -2.5635e-03,  ..., -2.4688e+00,
          1.4551e-01, -1.3975e+00]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SubBackward0>) 

                    
2024-07-27 12:25:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place duck lives in is called pond
The place rabbit lives in is called burrow
The place wolf lives in is called den
The place goldfish lives in is called pond
The place crocodile lives in is called river
The place dolphin lives in is called sea
The place cattle lives in is called barn
The place beaver lives in is called
2024-07-27 12:25:23 root INFO     [order_1_approx] starting weight calculation for The place crocodile lives in is called river
The place dolphin lives in is called sea
The place wolf lives in is called den
The place beaver lives in is called dam
The place duck lives in is called pond
The place goldfish lives in is called pond
The place rabbit lives in is called burrow
The place cattle lives in is called
2024-07-27 12:25:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 12:28:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1031, -0.0291, -0.0482,  ..., -0.1392,  0.0796,  0.1260],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4082, -7.0898,  3.3691,  ..., -1.7314,  2.1914, -1.3633],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0497, -0.0149,  0.0125,  ..., -0.0385, -0.0230,  0.0069],
        [-0.0190, -0.0024, -0.0434,  ...,  0.0201, -0.0129,  0.0213],
        [ 0.0130, -0.0129,  0.0557,  ..., -0.0206, -0.0087, -0.0042],
        ...,
        [-0.0237,  0.0287, -0.0134,  ...,  0.0516,  0.0076,  0.0092],
        [ 0.0250,  0.0307,  0.0125,  ...,  0.0185,  0.0563, -0.0016],
        [-0.0004, -0.0193, -0.0043,  ..., -0.0112, -0.0073,  0.0247]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6523, -6.8633,  3.0449,  ..., -1.9180,  1.4004, -0.9648]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 12:28:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place crocodile lives in is called river
The place dolphin lives in is called sea
The place wolf lives in is called den
The place beaver lives in is called dam
The place duck lives in is called pond
The place goldfish lives in is called pond
The place rabbit lives in is called burrow
The place cattle lives in is called
2024-07-27 12:28:06 root INFO     [order_1_approx] starting weight calculation for The place dolphin lives in is called sea
The place rabbit lives in is called burrow
The place crocodile lives in is called river
The place beaver lives in is called dam
The place wolf lives in is called den
The place goldfish lives in is called pond
The place cattle lives in is called barn
The place duck lives in is called
2024-07-27 12:28:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 12:30:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1888,  0.0637, -0.0715,  ..., -0.1208, -0.1212, -0.0958],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3086, -6.1445,  1.5576,  ...,  0.1128, -0.7837,  1.8877],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0234, -0.0025,  0.0049,  ...,  0.0039, -0.0117, -0.0159],
        [-0.0201,  0.0448,  0.0093,  ..., -0.0164, -0.0233, -0.0106],
        [-0.0123, -0.0167,  0.0332,  ...,  0.0216, -0.0109, -0.0133],
        ...,
        [ 0.0209,  0.0170, -0.0015,  ...,  0.0557,  0.0015,  0.0237],
        [ 0.0142, -0.0290,  0.0078,  ..., -0.0178,  0.0339,  0.0141],
        [-0.0171,  0.0198,  0.0027,  ...,  0.0096, -0.0071,  0.0479]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4395, -5.7969,  1.1611,  ...,  0.0396, -1.0547,  2.0137]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 12:30:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place dolphin lives in is called sea
The place rabbit lives in is called burrow
The place crocodile lives in is called river
The place beaver lives in is called dam
The place wolf lives in is called den
The place goldfish lives in is called pond
The place cattle lives in is called barn
The place duck lives in is called
2024-07-27 12:30:48 root INFO     [order_1_approx] starting weight calculation for The place duck lives in is called pond
The place crocodile lives in is called river
The place wolf lives in is called den
The place cattle lives in is called barn
The place dolphin lives in is called sea
The place beaver lives in is called dam
The place rabbit lives in is called burrow
The place goldfish lives in is called
2024-07-27 12:30:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 12:33:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1772,  0.1256, -0.1422,  ..., -0.0709, -0.4209,  0.2910],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0398, -2.9238, -0.1807,  ..., -2.6113, -0.0084, -0.1797],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0535, -0.0073, -0.0213,  ..., -0.0031, -0.0337,  0.0174],
        [ 0.0280,  0.0371, -0.0102,  ..., -0.0114,  0.0140,  0.0029],
        [ 0.0155, -0.0281,  0.0221,  ...,  0.0057, -0.0297, -0.0091],
        ...,
        [-0.0295, -0.0016, -0.0377,  ...,  0.0411,  0.0314,  0.0202],
        [-0.0153, -0.0111,  0.0022,  ...,  0.0281,  0.0375,  0.0215],
        [-0.0591, -0.0282,  0.0162,  ..., -0.0130,  0.0066,  0.0355]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1482, -2.9355,  0.2654,  ..., -2.1895, -0.4004, -0.5381]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 12:33:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place duck lives in is called pond
The place crocodile lives in is called river
The place wolf lives in is called den
The place cattle lives in is called barn
The place dolphin lives in is called sea
The place beaver lives in is called dam
The place rabbit lives in is called burrow
The place goldfish lives in is called
2024-07-27 12:33:31 root INFO     total operator prediction time: 1297.5694952011108 seconds
2024-07-27 12:33:31 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on male - female
2024-07-27 12:33:31 root INFO     building operator male - female
2024-07-27 12:33:32 root INFO     [order_1_approx] starting weight calculation for A female grandfather is known as a grandmother
A female brother is known as a sister
A female buck is known as a doe
A female webmaster is known as a webmistress
A female poet is known as a poetess
A female fisherman is known as a fisherwoman
A female ram is known as a ewe
A female waiter is known as a
2024-07-27 12:33:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 12:36:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1901,  0.0460, -0.1873,  ..., -0.1454, -0.1019,  0.0467],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3848e+00,  1.9531e-03,  9.4678e-01,  ...,  1.6396e+00,
        -1.7520e+00, -4.4922e-02], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0009, -0.0213,  0.0045,  ..., -0.0163,  0.0048, -0.0021],
        [-0.0124,  0.0457, -0.0088,  ...,  0.0157,  0.0021,  0.0129],
        [-0.0025,  0.0054,  0.0126,  ..., -0.0083,  0.0001,  0.0048],
        ...,
        [ 0.0037,  0.0272,  0.0066,  ...,  0.0135,  0.0082,  0.0065],
        [ 0.0183,  0.0330, -0.0145,  ...,  0.0080,  0.0074, -0.0128],
        [-0.0120,  0.0228, -0.0168,  ...,  0.0017, -0.0091,  0.0064]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4863, -0.0831,  0.9624,  ...,  1.2734, -1.8301, -0.2686]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 12:36:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female grandfather is known as a grandmother
A female brother is known as a sister
A female buck is known as a doe
A female webmaster is known as a webmistress
A female poet is known as a poetess
A female fisherman is known as a fisherwoman
A female ram is known as a ewe
A female waiter is known as a
2024-07-27 12:36:16 root INFO     [order_1_approx] starting weight calculation for A female buck is known as a doe
A female ram is known as a ewe
A female brother is known as a sister
A female waiter is known as a waitress
A female webmaster is known as a webmistress
A female grandfather is known as a grandmother
A female fisherman is known as a fisherwoman
A female poet is known as a
2024-07-27 12:36:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 12:38:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0354, -0.0132, -0.1046,  ..., -0.1675, -0.2622,  0.1465],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5957, -4.7500,  0.3567,  ..., -1.2158, -3.7578, -0.7886],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0389, -0.0158,  0.0311,  ..., -0.0067,  0.0037,  0.0302],
        [-0.0012,  0.0355, -0.0213,  ...,  0.0280, -0.0154, -0.0428],
        [ 0.0124,  0.0086,  0.0421,  ...,  0.0261, -0.0279,  0.0170],
        ...,
        [ 0.0042, -0.0071,  0.0088,  ...,  0.0449, -0.0174, -0.0218],
        [-0.0144, -0.0120,  0.0180,  ...,  0.0012, -0.0064,  0.0150],
        [ 0.0055,  0.0164,  0.0039,  ...,  0.0077,  0.0084,  0.0138]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4102, -4.7695,  0.1240,  ..., -0.7832, -3.6504, -0.5024]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 12:38:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female buck is known as a doe
A female ram is known as a ewe
A female brother is known as a sister
A female waiter is known as a waitress
A female webmaster is known as a webmistress
A female grandfather is known as a grandmother
A female fisherman is known as a fisherwoman
A female poet is known as a
2024-07-27 12:38:57 root INFO     [order_1_approx] starting weight calculation for A female waiter is known as a waitress
A female webmaster is known as a webmistress
A female fisherman is known as a fisherwoman
A female poet is known as a poetess
A female ram is known as a ewe
A female brother is known as a sister
A female buck is known as a doe
A female grandfather is known as a
2024-07-27 12:38:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 12:41:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3030, -0.0160,  0.0530,  ..., -0.2073, -0.1354,  0.1995],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2168, -1.0996, -0.1719,  ...,  1.2324, -4.5156, -2.9688],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0148, -0.0471,  0.0523,  ...,  0.0432, -0.0557,  0.0629],
        [-0.0059,  0.0419, -0.0184,  ...,  0.0184, -0.0158, -0.0083],
        [-0.0140, -0.0043,  0.0154,  ...,  0.0459, -0.0046,  0.0004],
        ...,
        [ 0.0003,  0.0296, -0.0409,  ...,  0.0153,  0.0310,  0.0160],
        [-0.0111, -0.0171,  0.0309,  ..., -0.0103, -0.0214,  0.0021],
        [ 0.0114, -0.0174,  0.0164,  ...,  0.0102, -0.0024,  0.0253]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8740, -1.0000, -0.5674,  ...,  1.0430, -5.1016, -3.1836]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 12:41:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female waiter is known as a waitress
A female webmaster is known as a webmistress
A female fisherman is known as a fisherwoman
A female poet is known as a poetess
A female ram is known as a ewe
A female brother is known as a sister
A female buck is known as a doe
A female grandfather is known as a
2024-07-27 12:41:40 root INFO     [order_1_approx] starting weight calculation for A female brother is known as a sister
A female waiter is known as a waitress
A female webmaster is known as a webmistress
A female grandfather is known as a grandmother
A female ram is known as a ewe
A female poet is known as a poetess
A female fisherman is known as a fisherwoman
A female buck is known as a
2024-07-27 12:41:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 12:44:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3755,  0.2039,  0.0592,  ..., -0.0781, -0.2217,  0.2517],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4727, -2.0352, -1.1289,  ...,  1.5879, -5.5664,  0.8809],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0087,  0.0264,  0.0296,  ...,  0.0008,  0.0061, -0.0129],
        [-0.0078,  0.0651, -0.0191,  ...,  0.0483,  0.0308,  0.0181],
        [ 0.0123, -0.0164,  0.0087,  ...,  0.0028,  0.0145, -0.0416],
        ...,
        [-0.0256, -0.0176,  0.0138,  ...,  0.0470,  0.0422, -0.0075],
        [-0.0232,  0.0124,  0.0305,  ..., -0.0547,  0.0062, -0.0088],
        [ 0.0030, -0.0226, -0.0639,  ..., -0.0047,  0.0104, -0.0345]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8555, -1.7656, -0.2983,  ...,  1.6348, -5.0508,  2.5059]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 12:44:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female brother is known as a sister
A female waiter is known as a waitress
A female webmaster is known as a webmistress
A female grandfather is known as a grandmother
A female ram is known as a ewe
A female poet is known as a poetess
A female fisherman is known as a fisherwoman
A female buck is known as a
2024-07-27 12:44:24 root INFO     [order_1_approx] starting weight calculation for A female waiter is known as a waitress
A female grandfather is known as a grandmother
A female webmaster is known as a webmistress
A female brother is known as a sister
A female poet is known as a poetess
A female fisherman is known as a fisherwoman
A female buck is known as a doe
A female ram is known as a
2024-07-27 12:44:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 12:47:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2839,  0.0745,  0.0450,  ..., -0.0233, -0.0444,  0.1771],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1719, -1.3125,  1.1221,  ...,  1.9004, -2.0703, -1.8242],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0258,  0.0265, -0.0327,  ...,  0.0144, -0.0038, -0.0193],
        [-0.0031,  0.0090,  0.0008,  ...,  0.0181,  0.0184, -0.0112],
        [-0.0022,  0.0139,  0.0274,  ...,  0.0166, -0.0058, -0.0165],
        ...,
        [-0.0133,  0.0011, -0.0491,  ...,  0.0464,  0.0348, -0.0105],
        [ 0.0212,  0.0501,  0.0073,  ..., -0.0359,  0.0053,  0.0067],
        [ 0.0209, -0.0375, -0.0151,  ..., -0.0019,  0.0258,  0.0126]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8516, -1.0498,  1.2783,  ...,  2.1582, -2.6270, -1.8369]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 12:47:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female waiter is known as a waitress
A female grandfather is known as a grandmother
A female webmaster is known as a webmistress
A female brother is known as a sister
A female poet is known as a poetess
A female fisherman is known as a fisherwoman
A female buck is known as a doe
A female ram is known as a
2024-07-27 12:47:06 root INFO     [order_1_approx] starting weight calculation for A female waiter is known as a waitress
A female brother is known as a sister
A female fisherman is known as a fisherwoman
A female poet is known as a poetess
A female ram is known as a ewe
A female grandfather is known as a grandmother
A female buck is known as a doe
A female webmaster is known as a
2024-07-27 12:47:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 12:49:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2206, -0.0463, -0.0578,  ...,  0.0009, -0.3267,  0.1887],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1211, -4.3281, -0.3188,  ...,  0.0718, -2.0254,  0.4775],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0447,  0.0109, -0.0156,  ...,  0.0098, -0.0031,  0.0248],
        [-0.0287,  0.0488, -0.0069,  ..., -0.0191, -0.0126, -0.0057],
        [-0.0288, -0.0124,  0.0335,  ..., -0.0225, -0.0084,  0.0027],
        ...,
        [ 0.0075,  0.0197,  0.0117,  ...,  0.0209, -0.0085, -0.0140],
        [-0.0173,  0.0209, -0.0045,  ..., -0.0319, -0.0070, -0.0268],
        [ 0.0101, -0.0164, -0.0033,  ..., -0.0006,  0.0073,  0.0256]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.2344, -4.4766,  0.0369,  ..., -0.0110, -2.1484,  0.4856]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 12:49:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female waiter is known as a waitress
A female brother is known as a sister
A female fisherman is known as a fisherwoman
A female poet is known as a poetess
A female ram is known as a ewe
A female grandfather is known as a grandmother
A female buck is known as a doe
A female webmaster is known as a
2024-07-27 12:49:51 root INFO     [order_1_approx] starting weight calculation for A female ram is known as a ewe
A female buck is known as a doe
A female brother is known as a sister
A female grandfather is known as a grandmother
A female poet is known as a poetess
A female webmaster is known as a webmistress
A female waiter is known as a waitress
A female fisherman is known as a
2024-07-27 12:49:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 12:52:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2274, -0.0905, -0.3101,  ..., -0.3516, -0.1732,  0.2112],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.7383, -3.5625, -0.3591,  ...,  0.8394, -4.9297,  0.4248],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0137, -0.0081,  0.0062,  ...,  0.0171,  0.0115, -0.0026],
        [ 0.0075,  0.0199, -0.0158,  ..., -0.0093,  0.0031, -0.0290],
        [-0.0014, -0.0086,  0.0054,  ...,  0.0099, -0.0036, -0.0025],
        ...,
        [-0.0354,  0.0045, -0.0264,  ...,  0.0032,  0.0082, -0.0220],
        [ 0.0168,  0.0166,  0.0111,  ..., -0.0152, -0.0114, -0.0052],
        [-0.0026,  0.0185, -0.0078,  ...,  0.0042,  0.0142, -0.0033]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.9570, -3.3047, -0.3672,  ...,  0.9805, -5.0898,  0.6079]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 12:52:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female ram is known as a ewe
A female buck is known as a doe
A female brother is known as a sister
A female grandfather is known as a grandmother
A female poet is known as a poetess
A female webmaster is known as a webmistress
A female waiter is known as a waitress
A female fisherman is known as a
2024-07-27 12:52:35 root INFO     [order_1_approx] starting weight calculation for A female buck is known as a doe
A female poet is known as a poetess
A female waiter is known as a waitress
A female grandfather is known as a grandmother
A female webmaster is known as a webmistress
A female fisherman is known as a fisherwoman
A female ram is known as a ewe
A female brother is known as a
2024-07-27 12:52:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 12:55:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2549,  0.1621,  0.1705,  ..., -0.0919, -0.2303,  0.1229],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6680, -1.0225, -2.0352,  ...,  0.7412, -2.4258, -0.4026],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0425, -0.0158,  0.0278,  ...,  0.0064, -0.0454,  0.0380],
        [ 0.0477,  0.0165, -0.0144,  ...,  0.0314,  0.0602, -0.0533],
        [ 0.0197, -0.0510,  0.0236,  ..., -0.0186,  0.0121,  0.0010],
        ...,
        [-0.0542,  0.0276, -0.0159,  ...,  0.0475, -0.0096, -0.0042],
        [-0.0635,  0.0202,  0.0394,  ..., -0.0144, -0.0790,  0.0102],
        [ 0.0709, -0.0340, -0.0258,  ..., -0.0057,  0.0791, -0.0226]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8398, -0.1475, -1.8604,  ..., -0.3340, -4.6406,  0.4983]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 12:55:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female buck is known as a doe
A female poet is known as a poetess
A female waiter is known as a waitress
A female grandfather is known as a grandmother
A female webmaster is known as a webmistress
A female fisherman is known as a fisherwoman
A female ram is known as a ewe
A female brother is known as a
2024-07-27 12:55:21 root INFO     total operator prediction time: 1309.8996489048004 seconds
2024-07-27 12:55:21 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on name - occupation
2024-07-27 12:55:21 root INFO     building operator name - occupation
2024-07-27 12:55:22 root INFO     [order_1_approx] starting weight calculation for stalin was known for their work as a  dictator
hegel was known for their work as a  philosopher
einstein was known for their work as a  physicist
caesar was known for their work as a  emperor
napoleon was known for their work as a  emperor
dante was known for their work as a  poet
marx was known for their work as a  philosopher
hume was known for their work as a 
2024-07-27 12:55:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 12:58:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2031,  0.2900, -0.2280,  ..., -0.1427,  0.2649,  0.0723],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9893, -3.4688,  2.5352,  ..., -6.6914,  0.3223, -2.5352],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0522,  0.0116,  0.0209,  ..., -0.0110,  0.0056,  0.0069],
        [-0.0157,  0.0628,  0.0109,  ...,  0.0005, -0.0284, -0.0157],
        [ 0.0196, -0.0117,  0.0572,  ..., -0.0121,  0.0299, -0.0024],
        ...,
        [-0.0272,  0.0316,  0.0079,  ...,  0.1004,  0.0010,  0.0049],
        [ 0.0220,  0.0104,  0.0117,  ...,  0.0109,  0.0176,  0.0017],
        [-0.0515,  0.0243, -0.0187,  ...,  0.0232, -0.0126,  0.0755]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6016, -2.8184,  2.3965,  ..., -5.6797, -0.7432, -1.9922]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 12:58:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for stalin was known for their work as a  dictator
hegel was known for their work as a  philosopher
einstein was known for their work as a  physicist
caesar was known for their work as a  emperor
napoleon was known for their work as a  emperor
dante was known for their work as a  poet
marx was known for their work as a  philosopher
hume was known for their work as a 
2024-07-27 12:58:07 root INFO     [order_1_approx] starting weight calculation for stalin was known for their work as a  dictator
marx was known for their work as a  philosopher
hume was known for their work as a  philosopher
dante was known for their work as a  poet
einstein was known for their work as a  physicist
hegel was known for their work as a  philosopher
napoleon was known for their work as a  emperor
caesar was known for their work as a 
2024-07-27 12:58:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 13:00:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1302,  0.0997, -0.2974,  ...,  0.1228, -0.4424,  0.1968],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5850, -5.8047,  2.0527,  ..., -2.1250,  0.8652, -0.4902],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0486,  0.0173, -0.0083,  ...,  0.0006, -0.0080, -0.0060],
        [ 0.0059,  0.0557, -0.0150,  ..., -0.0124, -0.0045,  0.0040],
        [ 0.0170, -0.0466,  0.0424,  ..., -0.0079, -0.0037, -0.0096],
        ...,
        [ 0.0077,  0.0361,  0.0048,  ...,  0.0858,  0.0383, -0.0161],
        [ 0.0170,  0.0237,  0.0125,  ..., -0.0237, -0.0103,  0.0093],
        [-0.0078, -0.0016, -0.0042,  ..., -0.0261,  0.0241,  0.0115]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3584, -5.1875,  2.0410,  ..., -2.2715,  1.0996, -0.2964]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 13:00:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for stalin was known for their work as a  dictator
marx was known for their work as a  philosopher
hume was known for their work as a  philosopher
dante was known for their work as a  poet
einstein was known for their work as a  physicist
hegel was known for their work as a  philosopher
napoleon was known for their work as a  emperor
caesar was known for their work as a 
2024-07-27 13:00:52 root INFO     [order_1_approx] starting weight calculation for hume was known for their work as a  philosopher
einstein was known for their work as a  physicist
dante was known for their work as a  poet
hegel was known for their work as a  philosopher
napoleon was known for their work as a  emperor
marx was known for their work as a  philosopher
caesar was known for their work as a  emperor
stalin was known for their work as a 
2024-07-27 13:00:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 13:03:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0263, -0.0189, -0.2576,  ...,  0.0729, -0.1984,  0.1729],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.8281, -4.5820,  3.1582,  ..., -2.6094,  0.4487, -2.5938],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0200,  0.0696,  0.0065,  ...,  0.0004, -0.0592, -0.0134],
        [-0.0232,  0.0033,  0.0193,  ..., -0.0087,  0.0227, -0.0065],
        [-0.0212,  0.0015,  0.0529,  ..., -0.0011, -0.0154, -0.0034],
        ...,
        [-0.0140, -0.0006,  0.0013,  ...,  0.0980, -0.0231, -0.0063],
        [ 0.0102,  0.0304, -0.0040,  ..., -0.0003,  0.0007,  0.0157],
        [-0.0337, -0.0218,  0.0150,  ...,  0.0128,  0.0326,  0.0543]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.4922, -4.0859,  3.4277,  ..., -2.7207,  0.1350, -1.7090]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 13:03:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for hume was known for their work as a  philosopher
einstein was known for their work as a  physicist
dante was known for their work as a  poet
hegel was known for their work as a  philosopher
napoleon was known for their work as a  emperor
marx was known for their work as a  philosopher
caesar was known for their work as a  emperor
stalin was known for their work as a 
2024-07-27 13:03:36 root INFO     [order_1_approx] starting weight calculation for napoleon was known for their work as a  emperor
caesar was known for their work as a  emperor
dante was known for their work as a  poet
hegel was known for their work as a  philosopher
marx was known for their work as a  philosopher
stalin was known for their work as a  dictator
hume was known for their work as a  philosopher
einstein was known for their work as a 
2024-07-27 13:03:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 13:06:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0609, -0.2301, -0.3616,  ..., -0.1702, -0.2817,  0.2629],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5908e+00, -5.0312e+00,  1.9824e+00,  ..., -6.4375e+00,
         2.9297e-03, -1.7891e+00], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0359, -0.0037,  0.0161,  ..., -0.0048, -0.0200,  0.0179],
        [-0.0169,  0.0072, -0.0153,  ..., -0.0022,  0.0125, -0.0149],
        [ 0.0047, -0.0141,  0.0361,  ..., -0.0094, -0.0112,  0.0173],
        ...,
        [ 0.0077,  0.0032,  0.0176,  ...,  0.0332,  0.0074,  0.0111],
        [ 0.0239,  0.0115,  0.0055,  ...,  0.0057, -0.0117,  0.0037],
        [ 0.0048,  0.0035,  0.0084,  ...,  0.0036,  0.0163,  0.0061]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7402, -5.0664,  2.0898,  ..., -6.1680,  0.1405, -1.4990]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 13:06:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for napoleon was known for their work as a  emperor
caesar was known for their work as a  emperor
dante was known for their work as a  poet
hegel was known for their work as a  philosopher
marx was known for their work as a  philosopher
stalin was known for their work as a  dictator
hume was known for their work as a  philosopher
einstein was known for their work as a 
2024-07-27 13:06:21 root INFO     [order_1_approx] starting weight calculation for hegel was known for their work as a  philosopher
marx was known for their work as a  philosopher
einstein was known for their work as a  physicist
caesar was known for their work as a  emperor
stalin was known for their work as a  dictator
napoleon was known for their work as a  emperor
hume was known for their work as a  philosopher
dante was known for their work as a 
2024-07-27 13:06:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 13:09:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0488,  0.1460, -0.3958,  ...,  0.0808, -0.2037,  0.0333],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7852, -8.1406,  2.1562,  ..., -5.1055, -0.2374,  0.3789],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0932,  0.0436,  0.0383,  ..., -0.0214, -0.0115,  0.0190],
        [-0.0295,  0.0366,  0.0009,  ..., -0.0297,  0.0016,  0.0246],
        [ 0.0087,  0.0054,  0.0351,  ..., -0.0180, -0.0050,  0.0120],
        ...,
        [-0.0205,  0.0447,  0.0074,  ...,  0.0670,  0.0247, -0.0168],
        [ 0.0182, -0.0312, -0.0533,  ..., -0.0089,  0.0265, -0.0078],
        [-0.0092,  0.0072,  0.0135,  ...,  0.0022,  0.0121,  0.0684]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5645, -7.0938,  2.7207,  ..., -3.9258, -0.7529,  0.5996]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 13:09:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for hegel was known for their work as a  philosopher
marx was known for their work as a  philosopher
einstein was known for their work as a  physicist
caesar was known for their work as a  emperor
stalin was known for their work as a  dictator
napoleon was known for their work as a  emperor
hume was known for their work as a  philosopher
dante was known for their work as a 
2024-07-27 13:09:06 root INFO     [order_1_approx] starting weight calculation for caesar was known for their work as a  emperor
einstein was known for their work as a  physicist
hegel was known for their work as a  philosopher
stalin was known for their work as a  dictator
dante was known for their work as a  poet
marx was known for their work as a  philosopher
hume was known for their work as a  philosopher
napoleon was known for their work as a 
2024-07-27 13:09:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 13:11:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1854, -0.1000, -0.1274,  ..., -0.0945,  0.0193,  0.2406],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0654, -4.8203,  0.3057,  ..., -1.2402,  2.1934, -0.4932],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0319,  0.0061,  0.0028,  ...,  0.0086, -0.0125,  0.0180],
        [ 0.0190,  0.0132,  0.0289,  ..., -0.0072, -0.0273, -0.0087],
        [ 0.0108, -0.0248,  0.0247,  ..., -0.0178,  0.0087,  0.0253],
        ...,
        [-0.0211,  0.0132, -0.0002,  ...,  0.0457,  0.0369, -0.0123],
        [-0.0076,  0.0081, -0.0125,  ...,  0.0064,  0.0087, -0.0007],
        [ 0.0064, -0.0058, -0.0092,  ..., -0.0116, -0.0052,  0.0284]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0945, -4.9297,  0.6289,  ..., -1.7070,  2.0000, -0.2435]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 13:11:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for caesar was known for their work as a  emperor
einstein was known for their work as a  physicist
hegel was known for their work as a  philosopher
stalin was known for their work as a  dictator
dante was known for their work as a  poet
marx was known for their work as a  philosopher
hume was known for their work as a  philosopher
napoleon was known for their work as a 
2024-07-27 13:11:50 root INFO     [order_1_approx] starting weight calculation for stalin was known for their work as a  dictator
hume was known for their work as a  philosopher
napoleon was known for their work as a  emperor
dante was known for their work as a  poet
einstein was known for their work as a  physicist
hegel was known for their work as a  philosopher
caesar was known for their work as a  emperor
marx was known for their work as a 
2024-07-27 13:11:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 13:14:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([0.0754, 0.1059, 0.0536,  ..., 0.1385, 0.1587, 0.1218], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0225, -7.8594,  3.2285,  ..., -5.5820,  1.6855, -3.5508],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0997, -0.0081,  0.0348,  ..., -0.0472,  0.0098,  0.0212],
        [ 0.0424,  0.0251,  0.0026,  ..., -0.0380, -0.0226, -0.0022],
        [ 0.0197, -0.0145,  0.0484,  ..., -0.0008, -0.0103,  0.0021],
        ...,
        [-0.0192,  0.0265,  0.0119,  ...,  0.0953, -0.0043,  0.0272],
        [-0.0046,  0.0299,  0.0159,  ...,  0.0170,  0.0019, -0.0133],
        [-0.0300,  0.0005, -0.0085,  ...,  0.0033,  0.0127,  0.0216]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1479, -7.7344,  3.6328,  ..., -4.9727,  1.1797, -2.8828]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 13:14:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for stalin was known for their work as a  dictator
hume was known for their work as a  philosopher
napoleon was known for their work as a  emperor
dante was known for their work as a  poet
einstein was known for their work as a  physicist
hegel was known for their work as a  philosopher
caesar was known for their work as a  emperor
marx was known for their work as a 
2024-07-27 13:14:32 root INFO     [order_1_approx] starting weight calculation for einstein was known for their work as a  physicist
caesar was known for their work as a  emperor
marx was known for their work as a  philosopher
napoleon was known for their work as a  emperor
hume was known for their work as a  philosopher
dante was known for their work as a  poet
stalin was known for their work as a  dictator
hegel was known for their work as a 
2024-07-27 13:14:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 13:17:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2266,  0.2800, -0.0518,  ..., -0.0939,  0.2112,  0.3252],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5259, -6.4453,  3.7891,  ..., -5.3047, -0.3240, -2.0977],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0559, -0.0226, -0.0067,  ..., -0.0193, -0.0055,  0.0055],
        [-0.0125,  0.0215,  0.0280,  ...,  0.0111, -0.0164, -0.0089],
        [ 0.0127,  0.0235,  0.0447,  ..., -0.0440, -0.0031, -0.0139],
        ...,
        [ 0.0010,  0.0150,  0.0215,  ...,  0.0828,  0.0160,  0.0197],
        [-0.0162,  0.0081, -0.0244,  ..., -0.0208, -0.0102, -0.0063],
        [-0.0032, -0.0076,  0.0045,  ...,  0.0216,  0.0141,  0.0519]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2375, -6.4258,  3.3438,  ..., -4.9727, -1.2412, -2.1055]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 13:17:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for einstein was known for their work as a  physicist
caesar was known for their work as a  emperor
marx was known for their work as a  philosopher
napoleon was known for their work as a  emperor
hume was known for their work as a  philosopher
dante was known for their work as a  poet
stalin was known for their work as a  dictator
hegel was known for their work as a 
2024-07-27 13:17:18 root INFO     total operator prediction time: 1317.027913093567 seconds
2024-07-27 13:17:18 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on country - capital
2024-07-27 13:17:18 root INFO     building operator country - capital
2024-07-27 13:17:19 root INFO     [order_1_approx] starting weight calculation for The country with bucharest as its capital is known as romania
The country with london as its capital is known as england
The country with lima as its capital is known as peru
The country with taipei as its capital is known as taiwan
The country with baghdad as its capital is known as iraq
The country with oslo as its capital is known as norway
The country with berlin as its capital is known as germany
The country with santiago as its capital is known as
2024-07-27 13:17:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 13:20:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1097, -0.1187, -0.5347,  ...,  0.1227, -0.0388, -0.0069],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7793, -0.7090, -0.0348,  ...,  0.3882, -0.4219, -3.0078],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0357,  0.0119, -0.0059,  ...,  0.0245, -0.0572, -0.0179],
        [ 0.0258,  0.0004,  0.0031,  ...,  0.0005, -0.0291, -0.0180],
        [-0.0261,  0.0542,  0.0354,  ..., -0.0262,  0.0164,  0.0022],
        ...,
        [-0.0068,  0.0033, -0.0181,  ...,  0.0341,  0.0141, -0.0387],
        [ 0.0336, -0.0143, -0.0186,  ..., -0.0025,  0.0228, -0.0063],
        [-0.0084,  0.0007, -0.0065,  ..., -0.0171, -0.0037, -0.0124]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6445, -0.3518, -0.2876,  ...,  0.6602, -0.4792, -2.6953]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 13:20:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with bucharest as its capital is known as romania
The country with london as its capital is known as england
The country with lima as its capital is known as peru
The country with taipei as its capital is known as taiwan
The country with baghdad as its capital is known as iraq
The country with oslo as its capital is known as norway
The country with berlin as its capital is known as germany
The country with santiago as its capital is known as
2024-07-27 13:20:04 root INFO     [order_1_approx] starting weight calculation for The country with berlin as its capital is known as germany
The country with santiago as its capital is known as chile
The country with taipei as its capital is known as taiwan
The country with bucharest as its capital is known as romania
The country with baghdad as its capital is known as iraq
The country with london as its capital is known as england
The country with oslo as its capital is known as norway
The country with lima as its capital is known as
2024-07-27 13:20:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 13:22:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1019, -0.1462, -0.3457,  ...,  0.1589, -0.2803,  0.0939],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0469, -4.0859,  1.5000,  ..., -0.7563, -2.1406, -3.0410],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0061,  0.0073,  0.0080,  ..., -0.0058, -0.0053, -0.0028],
        [-0.0215,  0.0262, -0.0324,  ..., -0.0257, -0.0011, -0.0187],
        [-0.0010,  0.0172,  0.0198,  ...,  0.0309,  0.0075, -0.0505],
        ...,
        [ 0.0136,  0.0309, -0.0170,  ...,  0.0297,  0.0010, -0.0099],
        [ 0.0113, -0.0019, -0.0120,  ..., -0.0271,  0.0123,  0.0061],
        [-0.0030, -0.0171,  0.0248,  ...,  0.0041, -0.0016, -0.0040]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7441, -4.4180,  1.0391,  ..., -1.2314, -2.5156, -2.7500]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 13:22:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with berlin as its capital is known as germany
The country with santiago as its capital is known as chile
The country with taipei as its capital is known as taiwan
The country with bucharest as its capital is known as romania
The country with baghdad as its capital is known as iraq
The country with london as its capital is known as england
The country with oslo as its capital is known as norway
The country with lima as its capital is known as
2024-07-27 13:22:48 root INFO     [order_1_approx] starting weight calculation for The country with bucharest as its capital is known as romania
The country with london as its capital is known as england
The country with oslo as its capital is known as norway
The country with baghdad as its capital is known as iraq
The country with santiago as its capital is known as chile
The country with lima as its capital is known as peru
The country with berlin as its capital is known as germany
The country with taipei as its capital is known as
2024-07-27 13:22:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 13:25:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0757, -0.0886, -0.3066,  ...,  0.0621, -0.2278,  0.0312],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7715, -3.3164,  0.6382,  ..., -0.6689, -1.6836, -1.2715],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0208,  0.0125, -0.0037,  ...,  0.0098, -0.0107, -0.0061],
        [ 0.0027,  0.0012, -0.0033,  ..., -0.0039,  0.0100, -0.0157],
        [-0.0012,  0.0196,  0.0257,  ..., -0.0067,  0.0073, -0.0057],
        ...,
        [-0.0149,  0.0223, -0.0026,  ...,  0.0051,  0.0154, -0.0264],
        [ 0.0134, -0.0216, -0.0145,  ..., -0.0115,  0.0090,  0.0146],
        [-0.0128, -0.0112,  0.0046,  ..., -0.0025,  0.0087,  0.0040]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7041, -3.1094,  0.4651,  ..., -0.6025, -1.5088, -1.1982]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 13:25:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with bucharest as its capital is known as romania
The country with london as its capital is known as england
The country with oslo as its capital is known as norway
The country with baghdad as its capital is known as iraq
The country with santiago as its capital is known as chile
The country with lima as its capital is known as peru
The country with berlin as its capital is known as germany
The country with taipei as its capital is known as
2024-07-27 13:25:34 root INFO     [order_1_approx] starting weight calculation for The country with berlin as its capital is known as germany
The country with taipei as its capital is known as taiwan
The country with oslo as its capital is known as norway
The country with bucharest as its capital is known as romania
The country with santiago as its capital is known as chile
The country with lima as its capital is known as peru
The country with london as its capital is known as england
The country with baghdad as its capital is known as
2024-07-27 13:25:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 13:28:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1125, -0.1239, -0.6064,  ..., -0.0499, -0.2964, -0.0108],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3594, -2.2383, -0.7783,  ..., -0.7246, -0.2603, -4.4180],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0211, -0.0063, -0.0020,  ..., -0.0047, -0.0004,  0.0013],
        [-0.0001, -0.0017,  0.0155,  ...,  0.0034,  0.0024, -0.0119],
        [-0.0138,  0.0020,  0.0114,  ..., -0.0041,  0.0097, -0.0090],
        ...,
        [-0.0049,  0.0053, -0.0010,  ...,  0.0145,  0.0142, -0.0141],
        [ 0.0157, -0.0086,  0.0144,  ..., -0.0079,  0.0058, -0.0060],
        [ 0.0026, -0.0027,  0.0097,  ..., -0.0048,  0.0043,  0.0040]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5859, -2.1914, -0.8623,  ..., -0.6382, -0.0807, -4.2539]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 13:28:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with berlin as its capital is known as germany
The country with taipei as its capital is known as taiwan
The country with oslo as its capital is known as norway
The country with bucharest as its capital is known as romania
The country with santiago as its capital is known as chile
The country with lima as its capital is known as peru
The country with london as its capital is known as england
The country with baghdad as its capital is known as
2024-07-27 13:28:15 root INFO     [order_1_approx] starting weight calculation for The country with taipei as its capital is known as taiwan
The country with lima as its capital is known as peru
The country with santiago as its capital is known as chile
The country with oslo as its capital is known as norway
The country with london as its capital is known as england
The country with berlin as its capital is known as germany
The country with baghdad as its capital is known as iraq
The country with bucharest as its capital is known as
2024-07-27 13:28:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 13:31:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2229,  0.0018, -0.5239,  ...,  0.1747,  0.0007, -0.2441],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5869, -6.1016, -1.3984,  ..., -2.4082, -0.6279, -3.2422],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0258, -0.0303, -0.0098,  ...,  0.0093, -0.0139,  0.0027],
        [ 0.0092,  0.0105,  0.0443,  ..., -0.0098,  0.0017, -0.0106],
        [-0.0077,  0.0284,  0.0197,  ...,  0.0041, -0.0105, -0.0100],
        ...,
        [ 0.0037,  0.0303, -0.0141,  ...,  0.0274,  0.0200, -0.0222],
        [ 0.0093, -0.0195, -0.0235,  ..., -0.0204,  0.0325, -0.0048],
        [-0.0036,  0.0005,  0.0057,  ...,  0.0229,  0.0066,  0.0041]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5869, -5.1992, -1.5723,  ..., -2.5059, -0.7451, -2.8047]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 13:31:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with taipei as its capital is known as taiwan
The country with lima as its capital is known as peru
The country with santiago as its capital is known as chile
The country with oslo as its capital is known as norway
The country with london as its capital is known as england
The country with berlin as its capital is known as germany
The country with baghdad as its capital is known as iraq
The country with bucharest as its capital is known as
2024-07-27 13:31:04 root INFO     [order_1_approx] starting weight calculation for The country with bucharest as its capital is known as romania
The country with santiago as its capital is known as chile
The country with oslo as its capital is known as norway
The country with baghdad as its capital is known as iraq
The country with berlin as its capital is known as germany
The country with taipei as its capital is known as taiwan
The country with lima as its capital is known as peru
The country with london as its capital is known as
2024-07-27 13:31:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 13:33:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 1.8311e-04, -1.1450e-01, -1.9409e-01,  ...,  1.4502e-01,
         2.4878e-01,  5.3467e-02], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8242, -5.0469, -1.6660,  ..., -3.5020,  0.7158, -5.5977],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0222, -0.0247, -0.0007,  ...,  0.0233,  0.0118,  0.0054],
        [ 0.0035,  0.0202, -0.0063,  ..., -0.0014,  0.0024, -0.0114],
        [-0.0074, -0.0081,  0.0374,  ...,  0.0035,  0.0398,  0.0148],
        ...,
        [-0.0190,  0.0071, -0.0122,  ...,  0.0211, -0.0085, -0.0352],
        [ 0.0028,  0.0012,  0.0207,  ..., -0.0125, -0.0021, -0.0014],
        [-0.0077, -0.0137,  0.0017,  ..., -0.0087, -0.0211, -0.0013]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6807, -4.7344, -1.7344,  ..., -3.3672,  0.7900, -5.1406]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 13:33:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with bucharest as its capital is known as romania
The country with santiago as its capital is known as chile
The country with oslo as its capital is known as norway
The country with baghdad as its capital is known as iraq
The country with berlin as its capital is known as germany
The country with taipei as its capital is known as taiwan
The country with lima as its capital is known as peru
The country with london as its capital is known as
2024-07-27 13:33:45 root INFO     [order_1_approx] starting weight calculation for The country with bucharest as its capital is known as romania
The country with lima as its capital is known as peru
The country with london as its capital is known as england
The country with baghdad as its capital is known as iraq
The country with santiago as its capital is known as chile
The country with taipei as its capital is known as taiwan
The country with berlin as its capital is known as germany
The country with oslo as its capital is known as
2024-07-27 13:33:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 13:36:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1126,  0.0262, -0.4241,  ...,  0.1445,  0.1733,  0.0740],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1641, -3.7246, -3.1836,  ..., -1.4893, -0.9199, -4.3789],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0084, -0.0250, -0.0018,  ...,  0.0118,  0.0115,  0.0024],
        [ 0.0145,  0.0634,  0.0167,  ...,  0.0127, -0.0029, -0.0228],
        [-0.0289,  0.0213,  0.0436,  ...,  0.0033,  0.0295, -0.0056],
        ...,
        [ 0.0091,  0.0488,  0.0018,  ...,  0.0615, -0.0053, -0.0199],
        [ 0.0115,  0.0133, -0.0103,  ...,  0.0097,  0.0150,  0.0052],
        [-0.0072, -0.0358,  0.0081,  ..., -0.0151,  0.0014, -0.0014]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.2500, -3.7871, -3.3789,  ..., -1.3604, -0.6592, -3.8203]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 13:36:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with bucharest as its capital is known as romania
The country with lima as its capital is known as peru
The country with london as its capital is known as england
The country with baghdad as its capital is known as iraq
The country with santiago as its capital is known as chile
The country with taipei as its capital is known as taiwan
The country with berlin as its capital is known as germany
The country with oslo as its capital is known as
2024-07-27 13:36:28 root INFO     [order_1_approx] starting weight calculation for The country with london as its capital is known as england
The country with oslo as its capital is known as norway
The country with santiago as its capital is known as chile
The country with lima as its capital is known as peru
The country with baghdad as its capital is known as iraq
The country with taipei as its capital is known as taiwan
The country with bucharest as its capital is known as romania
The country with berlin as its capital is known as
2024-07-27 13:36:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 13:39:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1627,  0.0567, -0.3381,  ...,  0.3621, -0.1752,  0.0624],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4258, -5.4727, -1.1104,  ..., -0.0311,  0.4375, -4.5039],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0039,  0.0117, -0.0158,  ...,  0.0081,  0.0155,  0.0040],
        [ 0.0072,  0.0181,  0.0192,  ..., -0.0097, -0.0391, -0.0303],
        [-0.0096,  0.0018,  0.0407,  ...,  0.0267,  0.0155, -0.0094],
        ...,
        [-0.0013,  0.0029,  0.0009,  ...,  0.0409, -0.0295, -0.0144],
        [ 0.0149,  0.0131, -0.0039,  ...,  0.0126,  0.0175, -0.0127],
        [-0.0076, -0.0087,  0.0173,  ...,  0.0052, -0.0105,  0.0276]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6064, -4.9414, -1.4434,  ...,  0.7427,  0.0701, -4.0625]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 13:39:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with london as its capital is known as england
The country with oslo as its capital is known as norway
The country with santiago as its capital is known as chile
The country with lima as its capital is known as peru
The country with baghdad as its capital is known as iraq
The country with taipei as its capital is known as taiwan
The country with bucharest as its capital is known as romania
The country with berlin as its capital is known as
2024-07-27 13:39:11 root INFO     total operator prediction time: 1312.6584894657135 seconds
2024-07-27 13:39:11 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on things - color
2024-07-27 13:39:11 root INFO     building operator things - color
2024-07-27 13:39:11 root INFO     [order_1_approx] starting weight calculation for The coal is colored black
The carrot is colored orange
The frog is colored green
The blackboard is colored black
The celery is colored green
The tomato is colored red
The cranberry is colored red
The pepper is colored
2024-07-27 13:39:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 13:41:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2324, -0.0961, -0.2883,  ...,  0.1011, -0.3350,  0.1019],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.2773, -6.5938, -1.6172,  ..., -2.1719, -0.3174, -2.9316],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0403,  0.0078,  0.0281,  ..., -0.0357,  0.0234,  0.0016],
        [-0.0046,  0.0552,  0.0231,  ..., -0.0002,  0.0118,  0.0015],
        [-0.0195,  0.0182,  0.0199,  ...,  0.0395, -0.0154, -0.0219],
        ...,
        [ 0.0010, -0.0337,  0.0156,  ...,  0.0591, -0.0085, -0.0045],
        [ 0.0170, -0.0261, -0.0295,  ..., -0.0017,  0.0393, -0.0112],
        [ 0.0041, -0.0121,  0.0269,  ..., -0.0140,  0.0134,  0.0673]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.5820, -6.3359, -1.5088,  ..., -2.1465, -0.6729, -2.7637]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 13:41:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The coal is colored black
The carrot is colored orange
The frog is colored green
The blackboard is colored black
The celery is colored green
The tomato is colored red
The cranberry is colored red
The pepper is colored
2024-07-27 13:41:57 root INFO     [order_1_approx] starting weight calculation for The pepper is colored black
The celery is colored green
The carrot is colored orange
The frog is colored green
The coal is colored black
The cranberry is colored red
The tomato is colored red
The blackboard is colored
2024-07-27 13:41:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 13:44:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2639, -0.1133, -0.3530,  ...,  0.0816, -0.1929, -0.3472],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.8896, -4.3672,  1.2568,  ..., -0.7095, -0.7969, -2.2383],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0510,  0.0173,  0.0266,  ..., -0.0061, -0.0017,  0.0288],
        [-0.0119,  0.0608, -0.0330,  ..., -0.0071, -0.0248, -0.0249],
        [-0.0083,  0.0338, -0.0098,  ...,  0.0142, -0.0328, -0.0100],
        ...,
        [ 0.0142,  0.0233,  0.0242,  ...,  0.0432, -0.0016, -0.0164],
        [-0.0124, -0.0003, -0.0172,  ...,  0.0090,  0.0186, -0.0121],
        [ 0.0234, -0.0062,  0.0222,  ...,  0.0043,  0.0019,  0.0544]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.8994, -4.5195,  1.2773,  ..., -0.4143, -0.6963, -2.6289]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 13:44:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The pepper is colored black
The celery is colored green
The carrot is colored orange
The frog is colored green
The coal is colored black
The cranberry is colored red
The tomato is colored red
The blackboard is colored
2024-07-27 13:44:42 root INFO     [order_1_approx] starting weight calculation for The blackboard is colored black
The frog is colored green
The tomato is colored red
The coal is colored black
The pepper is colored black
The cranberry is colored red
The carrot is colored orange
The celery is colored
2024-07-27 13:44:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 13:47:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1307, -0.0243, -0.1616,  ..., -0.2415, -0.2815,  0.0657],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3677, -4.3164, -2.4023,  ..., -1.4805, -1.4082, -2.5859],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0190,  0.0090, -0.0084,  ..., -0.0014,  0.0121, -0.0004],
        [-0.0133,  0.0183, -0.0150,  ...,  0.0085,  0.0279, -0.0273],
        [-0.0373,  0.0122,  0.0296,  ...,  0.0364, -0.0145, -0.0047],
        ...,
        [ 0.0294, -0.0173, -0.0179,  ...,  0.0954, -0.0005, -0.0255],
        [ 0.0050,  0.0234, -0.0102,  ..., -0.0114,  0.0338, -0.0150],
        [-0.0123,  0.0179,  0.0346,  ..., -0.0110,  0.0117,  0.0452]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0752, -4.6914, -2.5762,  ..., -1.7520, -1.3975, -2.5156]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 13:47:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The blackboard is colored black
The frog is colored green
The tomato is colored red
The coal is colored black
The pepper is colored black
The cranberry is colored red
The carrot is colored orange
The celery is colored
2024-07-27 13:47:23 root INFO     [order_1_approx] starting weight calculation for The carrot is colored orange
The pepper is colored black
The tomato is colored red
The frog is colored green
The blackboard is colored black
The cranberry is colored red
The celery is colored green
The coal is colored
2024-07-27 13:47:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 13:50:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2223, -0.0891, -0.1243,  ..., -0.3416,  0.2263,  0.3120],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6099, -6.0156, -0.6035,  ..., -4.3672,  0.7598, -4.5312],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0648,  0.0074,  0.0106,  ...,  0.0081,  0.0405,  0.0203],
        [-0.0013,  0.0253,  0.0024,  ..., -0.0058, -0.0065, -0.0216],
        [-0.0036, -0.0201,  0.0016,  ...,  0.0245,  0.0002,  0.0100],
        ...,
        [ 0.0010, -0.0096,  0.0017,  ...,  0.0371,  0.0137, -0.0328],
        [-0.0083, -0.0091, -0.0243,  ...,  0.0374,  0.0447, -0.0392],
        [-0.0180, -0.0126, -0.0418,  ..., -0.0284,  0.0032,  0.0108]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1863, -6.3398, -0.6357,  ..., -4.2891,  1.1670, -4.3906]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 13:50:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The carrot is colored orange
The pepper is colored black
The tomato is colored red
The frog is colored green
The blackboard is colored black
The cranberry is colored red
The celery is colored green
The coal is colored
2024-07-27 13:50:07 root INFO     [order_1_approx] starting weight calculation for The pepper is colored black
The tomato is colored red
The coal is colored black
The frog is colored green
The blackboard is colored black
The celery is colored green
The cranberry is colored red
The carrot is colored
2024-07-27 13:50:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 13:52:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0486, -0.0889, -0.0133,  ..., -0.2861, -0.3401, -0.1544],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.4023, -6.1641,  0.3950,  ..., -4.9102, -1.1162, -2.8867],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0309,  0.0120,  0.0158,  ..., -0.0528, -0.0171,  0.0116],
        [ 0.0179,  0.0147,  0.0070,  ..., -0.0165, -0.0111, -0.0072],
        [-0.0157,  0.0293,  0.0308,  ...,  0.0352,  0.0202, -0.0291],
        ...,
        [-0.0116, -0.0591, -0.0127,  ...,  0.0504, -0.0356,  0.0022],
        [-0.0032, -0.0066, -0.0239,  ...,  0.0459,  0.0124, -0.0161],
        [-0.0126, -0.0115,  0.0358,  ..., -0.0095,  0.0176,  0.0569]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.2676, -5.5547, -0.0222,  ..., -4.2500, -1.0283, -2.9219]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 13:52:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The pepper is colored black
The tomato is colored red
The coal is colored black
The frog is colored green
The blackboard is colored black
The celery is colored green
The cranberry is colored red
The carrot is colored
2024-07-27 13:52:53 root INFO     [order_1_approx] starting weight calculation for The blackboard is colored black
The celery is colored green
The cranberry is colored red
The pepper is colored black
The coal is colored black
The carrot is colored orange
The tomato is colored red
The frog is colored
2024-07-27 13:52:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 13:55:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1804,  0.2217,  0.1720,  ..., -0.3564, -0.2000,  0.1287],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.9375, -3.5547,  0.5107,  ...,  0.2725, -0.8174,  1.0859],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0643,  0.0080,  0.0347,  ...,  0.0042,  0.0133, -0.0120],
        [-0.0219,  0.0472,  0.0064,  ...,  0.0024, -0.0208, -0.0473],
        [-0.0241,  0.0367,  0.0363,  ...,  0.0433, -0.0311,  0.0068],
        ...,
        [-0.0215,  0.0219, -0.0166,  ...,  0.0813, -0.0021, -0.0261],
        [-0.0234,  0.0125,  0.0190,  ...,  0.0289,  0.0097, -0.0327],
        [-0.0168, -0.0085,  0.0146,  ..., -0.0323,  0.0111,  0.0346]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6475, -3.8652,  0.6157,  ..., -0.0891, -1.2158,  0.5679]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 13:55:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The blackboard is colored black
The celery is colored green
The cranberry is colored red
The pepper is colored black
The coal is colored black
The carrot is colored orange
The tomato is colored red
The frog is colored
2024-07-27 13:55:38 root INFO     [order_1_approx] starting weight calculation for The carrot is colored orange
The coal is colored black
The frog is colored green
The blackboard is colored black
The pepper is colored black
The celery is colored green
The tomato is colored red
The cranberry is colored
2024-07-27 13:55:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 13:58:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4253, -0.3008, -0.5781,  ...,  0.1227, -0.4094, -0.0772],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-4.4062, -7.2109, -1.3369,  ..., -1.7432,  1.6055, -0.4995],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0524,  0.0008,  0.0106,  ..., -0.0084,  0.0049,  0.0056],
        [-0.0101,  0.0258,  0.0347,  ...,  0.0057,  0.0093, -0.0033],
        [-0.0022, -0.0090,  0.0261,  ...,  0.0185, -0.0186, -0.0045],
        ...,
        [-0.0020, -0.0136, -0.0027,  ...,  0.0731, -0.0185,  0.0012],
        [-0.0199, -0.0173, -0.0111,  ...,  0.0131,  0.0327, -0.0086],
        [-0.0072,  0.0021, -0.0020,  ..., -0.0136,  0.0042,  0.0258]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-4.1523, -7.1641, -1.3398,  ..., -1.9277,  1.4258, -0.6470]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 13:58:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The carrot is colored orange
The coal is colored black
The frog is colored green
The blackboard is colored black
The pepper is colored black
The celery is colored green
The tomato is colored red
The cranberry is colored
2024-07-27 13:58:23 root INFO     [order_1_approx] starting weight calculation for The carrot is colored orange
The coal is colored black
The blackboard is colored black
The frog is colored green
The pepper is colored black
The celery is colored green
The cranberry is colored red
The tomato is colored
2024-07-27 13:58:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 14:01:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0601, -0.0801, -0.0074,  ...,  0.0043, -0.3486, -0.0708],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.9453, -8.8672, -0.1824,  ..., -1.9492,  0.9375, -1.3955],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0239,  0.0175,  0.0174,  ..., -0.0501,  0.0043, -0.0094],
        [ 0.0335,  0.0211,  0.0169,  ...,  0.0068, -0.0002, -0.0223],
        [-0.0242,  0.0162,  0.0302,  ...,  0.0312,  0.0148,  0.0061],
        ...,
        [-0.0269, -0.0307, -0.0146,  ...,  0.0874, -0.0214, -0.0211],
        [ 0.0009,  0.0029, -0.0282,  ...,  0.0205,  0.0099, -0.0022],
        [-0.0118, -0.0268,  0.0014,  ...,  0.0065, -0.0136,  0.0501]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.6543, -8.7812, -0.1178,  ..., -2.3223,  0.3867, -1.6807]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 14:01:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The carrot is colored orange
The coal is colored black
The blackboard is colored black
The frog is colored green
The pepper is colored black
The celery is colored green
The cranberry is colored red
The tomato is colored
2024-07-27 14:01:09 root INFO     total operator prediction time: 1317.4230620861053 seconds
2024-07-27 14:01:09 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - sound
2024-07-27 14:01:09 root INFO     building operator animal - sound
2024-07-27 14:01:09 root INFO     [order_1_approx] starting weight calculation for The sound that a donkey makes is called a bray
The sound that a alpaca makes is called a bray
The sound that a duck makes is called a quack
The sound that a pigeon makes is called a coo
The sound that a bear makes is called a growl
The sound that a elk makes is called a bellow
The sound that a songbird makes is called a chirrup
The sound that a wolf makes is called a
2024-07-27 14:01:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 14:03:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0220,  0.1416, -0.1434,  ..., -0.0971, -0.0662,  0.1451],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4570, -6.5352, -1.7451,  ..., -2.7383,  0.6309,  2.8477],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0562,  0.0208, -0.0019,  ..., -0.0175, -0.0168,  0.0240],
        [-0.0139,  0.0304, -0.0259,  ...,  0.0058, -0.0331, -0.0118],
        [ 0.0352, -0.0076,  0.0461,  ..., -0.0480, -0.0210,  0.0016],
        ...,
        [-0.0291,  0.0155, -0.0115,  ...,  0.0545, -0.0406, -0.0189],
        [-0.0057, -0.0442, -0.0079,  ...,  0.0132,  0.0138, -0.0056],
        [-0.0045, -0.0064, -0.0142,  ..., -0.0326, -0.0231, -0.0046]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7598, -5.9023, -1.4639,  ..., -2.7070,  0.8574,  2.5469]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 14:03:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a donkey makes is called a bray
The sound that a alpaca makes is called a bray
The sound that a duck makes is called a quack
The sound that a pigeon makes is called a coo
The sound that a bear makes is called a growl
The sound that a elk makes is called a bellow
The sound that a songbird makes is called a chirrup
The sound that a wolf makes is called a
2024-07-27 14:03:55 root INFO     [order_1_approx] starting weight calculation for The sound that a duck makes is called a quack
The sound that a wolf makes is called a howl
The sound that a songbird makes is called a chirrup
The sound that a alpaca makes is called a bray
The sound that a pigeon makes is called a coo
The sound that a bear makes is called a growl
The sound that a donkey makes is called a bray
The sound that a elk makes is called a
2024-07-27 14:03:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 14:06:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0291,  0.0332, -0.2251,  ..., -0.1473, -0.1689,  0.1239],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2898, -3.1445,  0.3984,  ...,  1.9824, -0.9380,  0.6582],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.0964e-02, -2.4506e-02,  9.8228e-05,  ..., -3.0518e-02,
         -3.7079e-03,  3.0045e-02],
        [-4.7485e-02,  3.1433e-02,  1.3824e-02,  ...,  1.7822e-02,
         -5.8655e-02,  1.7662e-03],
        [-6.1188e-03, -1.8677e-02,  2.8397e-02,  ..., -2.0752e-02,
         -1.3336e-02,  1.8753e-02],
        ...,
        [-1.8021e-02,  4.1504e-02, -1.5823e-02,  ...,  4.9286e-02,
         -1.2833e-02,  3.0899e-03],
        [ 4.4373e-02,  7.6752e-03,  1.8415e-03,  ...,  2.8168e-02,
          2.8198e-02,  6.2943e-03],
        [-9.7198e-03, -3.4180e-02, -1.1070e-02,  ..., -1.7212e-02,
         -4.8187e-02,  2.2110e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0303, -3.5000,  0.1157,  ...,  1.5605, -0.6143,  0.6470]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 14:06:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a duck makes is called a quack
The sound that a wolf makes is called a howl
The sound that a songbird makes is called a chirrup
The sound that a alpaca makes is called a bray
The sound that a pigeon makes is called a coo
The sound that a bear makes is called a growl
The sound that a donkey makes is called a bray
The sound that a elk makes is called a
2024-07-27 14:06:36 root INFO     [order_1_approx] starting weight calculation for The sound that a donkey makes is called a bray
The sound that a wolf makes is called a howl
The sound that a elk makes is called a bellow
The sound that a songbird makes is called a chirrup
The sound that a bear makes is called a growl
The sound that a pigeon makes is called a coo
The sound that a alpaca makes is called a bray
The sound that a duck makes is called a
2024-07-27 14:06:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 14:09:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0016,  0.0865,  0.0741,  ..., -0.0545, -0.0533,  0.0306],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0312, -4.3281,  3.0781,  ...,  0.3408, -3.6914,  2.4453],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0410,  0.0049, -0.0098,  ...,  0.0176, -0.0204,  0.0037],
        [ 0.0175,  0.0340,  0.0085,  ..., -0.0133, -0.0331, -0.0257],
        [ 0.0011, -0.0132,  0.0330,  ..., -0.0040, -0.0012,  0.0034],
        ...,
        [-0.0121,  0.0276, -0.0326,  ...,  0.0388, -0.0272, -0.0053],
        [ 0.0104, -0.0064,  0.0217,  ..., -0.0066,  0.0118, -0.0115],
        [ 0.0117,  0.0024,  0.0058,  ..., -0.0270, -0.0043,  0.0007]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4041, -4.2148,  2.8164,  ...,  0.6758, -3.8477,  2.3262]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 14:09:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a donkey makes is called a bray
The sound that a wolf makes is called a howl
The sound that a elk makes is called a bellow
The sound that a songbird makes is called a chirrup
The sound that a bear makes is called a growl
The sound that a pigeon makes is called a coo
The sound that a alpaca makes is called a bray
The sound that a duck makes is called a
2024-07-27 14:09:21 root INFO     [order_1_approx] starting weight calculation for The sound that a songbird makes is called a chirrup
The sound that a duck makes is called a quack
The sound that a pigeon makes is called a coo
The sound that a elk makes is called a bellow
The sound that a bear makes is called a growl
The sound that a wolf makes is called a howl
The sound that a donkey makes is called a bray
The sound that a alpaca makes is called a
2024-07-27 14:09:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 14:12:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0751, -0.2676, -0.1234,  ..., -0.0811, -0.2034,  0.2559],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.9424, -3.0996,  2.9180,  ..., -0.4785, -0.4453,  1.0215],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0315,  0.0003,  0.0026,  ..., -0.0119, -0.0238,  0.0121],
        [-0.0198,  0.0527, -0.0210,  ..., -0.0048, -0.0317, -0.0044],
        [-0.0002, -0.0203,  0.0295,  ..., -0.0488,  0.0066, -0.0288],
        ...,
        [-0.0046,  0.0195,  0.0020,  ...,  0.0472, -0.0038,  0.0137],
        [-0.0211, -0.0055,  0.0153,  ..., -0.0165,  0.0032,  0.0151],
        [-0.0006, -0.0052,  0.0287,  ..., -0.0127, -0.0007,  0.0325]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.5293, -3.3359,  1.8145,  ...,  0.4019, -0.1833,  0.9780]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 14:12:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a songbird makes is called a chirrup
The sound that a duck makes is called a quack
The sound that a pigeon makes is called a coo
The sound that a elk makes is called a bellow
The sound that a bear makes is called a growl
The sound that a wolf makes is called a howl
The sound that a donkey makes is called a bray
The sound that a alpaca makes is called a
2024-07-27 14:12:08 root INFO     [order_1_approx] starting weight calculation for The sound that a bear makes is called a growl
The sound that a songbird makes is called a chirrup
The sound that a alpaca makes is called a bray
The sound that a pigeon makes is called a coo
The sound that a elk makes is called a bellow
The sound that a wolf makes is called a howl
The sound that a duck makes is called a quack
The sound that a donkey makes is called a
2024-07-27 14:12:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 14:14:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0745, -0.2573, -0.0414,  ..., -0.3269, -0.1169,  0.2900],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4971, -2.6641,  0.2148,  ..., -0.5586, -1.4590,  2.3164],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0403,  0.0285,  0.0023,  ..., -0.0493, -0.0035,  0.0163],
        [ 0.0054,  0.0535, -0.0025,  ..., -0.0158, -0.0357, -0.0218],
        [-0.0235,  0.0047,  0.0381,  ..., -0.0489, -0.0029,  0.0497],
        ...,
        [ 0.0161,  0.0360, -0.0246,  ...,  0.0623, -0.0325, -0.0239],
        [-0.0032,  0.0225, -0.0289,  ...,  0.0042,  0.0246, -0.0039],
        [ 0.0274, -0.0316,  0.0225,  ..., -0.0083, -0.0423,  0.0023]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8472, -2.1152, -0.4678,  ..., -0.6182, -1.0889,  2.0859]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 14:14:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a bear makes is called a growl
The sound that a songbird makes is called a chirrup
The sound that a alpaca makes is called a bray
The sound that a pigeon makes is called a coo
The sound that a elk makes is called a bellow
The sound that a wolf makes is called a howl
The sound that a duck makes is called a quack
The sound that a donkey makes is called a
2024-07-27 14:14:51 root INFO     [order_1_approx] starting weight calculation for The sound that a elk makes is called a bellow
The sound that a pigeon makes is called a coo
The sound that a alpaca makes is called a bray
The sound that a bear makes is called a growl
The sound that a duck makes is called a quack
The sound that a donkey makes is called a bray
The sound that a wolf makes is called a howl
The sound that a songbird makes is called a
2024-07-27 14:14:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 14:17:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1096,  0.0063,  0.0847,  ..., -0.0377,  0.1432, -0.2174],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2529, -3.5547,  3.0195,  ..., -0.1006, -1.0957, -0.9033],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0158,  0.0011,  0.0072,  ..., -0.0021, -0.0344,  0.0189],
        [-0.0262,  0.0382,  0.0034,  ...,  0.0081,  0.0230, -0.0054],
        [-0.0046, -0.0072,  0.0284,  ..., -0.0053, -0.0019,  0.0142],
        ...,
        [-0.0122,  0.0245, -0.0122,  ...,  0.0175,  0.0134, -0.0026],
        [-0.0161,  0.0152, -0.0020,  ...,  0.0102,  0.0107, -0.0110],
        [-0.0062, -0.0224, -0.0083,  ..., -0.0263,  0.0019,  0.0242]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3994, -3.7051,  3.3379,  ..., -0.4353, -1.4863, -0.7959]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 14:17:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a elk makes is called a bellow
The sound that a pigeon makes is called a coo
The sound that a alpaca makes is called a bray
The sound that a bear makes is called a growl
The sound that a duck makes is called a quack
The sound that a donkey makes is called a bray
The sound that a wolf makes is called a howl
The sound that a songbird makes is called a
2024-07-27 14:17:39 root INFO     [order_1_approx] starting weight calculation for The sound that a donkey makes is called a bray
The sound that a alpaca makes is called a bray
The sound that a elk makes is called a bellow
The sound that a songbird makes is called a chirrup
The sound that a wolf makes is called a howl
The sound that a pigeon makes is called a coo
The sound that a duck makes is called a quack
The sound that a bear makes is called a
2024-07-27 14:17:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 14:20:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1711, -0.0511,  0.1073,  ..., -0.2177, -0.2954,  0.1345],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6523, -3.2422,  0.0234,  ..., -2.1562,  0.6724,  1.0576],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0747, -0.0088,  0.0102,  ..., -0.0394, -0.0401, -0.0027],
        [-0.0563,  0.0644,  0.0041,  ...,  0.0166, -0.0346, -0.0134],
        [ 0.0433, -0.0055,  0.0421,  ..., -0.0316, -0.0216,  0.0032],
        ...,
        [-0.0030,  0.0136, -0.0100,  ...,  0.0386,  0.0093, -0.0166],
        [-0.0145,  0.0037, -0.0135,  ...,  0.0335,  0.0217,  0.0049],
        [-0.0168,  0.0077, -0.0148,  ..., -0.0120, -0.0255,  0.0243]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4160, -3.5410,  0.1399,  ..., -1.8652,  0.3337,  0.9937]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 14:20:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a donkey makes is called a bray
The sound that a alpaca makes is called a bray
The sound that a elk makes is called a bellow
The sound that a songbird makes is called a chirrup
The sound that a wolf makes is called a howl
The sound that a pigeon makes is called a coo
The sound that a duck makes is called a quack
The sound that a bear makes is called a
2024-07-27 14:20:21 root INFO     [order_1_approx] starting weight calculation for The sound that a duck makes is called a quack
The sound that a alpaca makes is called a bray
The sound that a elk makes is called a bellow
The sound that a wolf makes is called a howl
The sound that a bear makes is called a growl
The sound that a donkey makes is called a bray
The sound that a songbird makes is called a chirrup
The sound that a pigeon makes is called a
2024-07-27 14:20:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 14:23:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0016, -0.0475, -0.2861,  ..., -0.0447, -0.1521,  0.0453],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1172, -3.5898,  5.3203,  ..., -0.7188, -0.7979,  2.2031],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0090,  0.0067,  0.0056,  ...,  0.0093, -0.0026, -0.0154],
        [ 0.0052,  0.0114,  0.0084,  ...,  0.0057,  0.0101, -0.0068],
        [ 0.0019,  0.0020,  0.0157,  ..., -0.0080,  0.0090, -0.0029],
        ...,
        [ 0.0085,  0.0068,  0.0053,  ...,  0.0164,  0.0036, -0.0069],
        [-0.0105,  0.0065, -0.0014,  ...,  0.0043,  0.0054, -0.0072],
        [ 0.0102, -0.0034,  0.0078,  ..., -0.0149, -0.0061,  0.0062]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1445, -3.6914,  5.5078,  ..., -0.8301, -0.8960,  2.3262]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 14:23:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a duck makes is called a quack
The sound that a alpaca makes is called a bray
The sound that a elk makes is called a bellow
The sound that a wolf makes is called a howl
The sound that a bear makes is called a growl
The sound that a donkey makes is called a bray
The sound that a songbird makes is called a chirrup
The sound that a pigeon makes is called a
2024-07-27 14:23:03 root INFO     total operator prediction time: 1313.955822467804 seconds
2024-07-27 14:23:03 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - youth
2024-07-27 14:23:03 root INFO     building operator animal - youth
2024-07-27 14:23:03 root INFO     [order_1_approx] starting weight calculation for The offspring of a beaver is referred to as a kit
The offspring of a woodchuck is referred to as a kit
The offspring of a herring is referred to as a fingerling
The offspring of a bear is referred to as a cub
The offspring of a fish is referred to as a fingerling
The offspring of a fox is referred to as a cub
The offspring of a bee is referred to as a larva
The offspring of a rabbit is referred to as a
2024-07-27 14:23:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 14:25:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0083, -0.0999, -0.1941,  ..., -0.2047, -0.0567, -0.0098],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.0820, -1.9336, -1.0166,  ...,  2.1016, -2.7188,  0.2363],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0097, -0.0108,  0.0044,  ...,  0.0185, -0.0047,  0.0101],
        [-0.0020,  0.0002,  0.0133,  ...,  0.0040, -0.0015, -0.0103],
        [ 0.0028,  0.0013,  0.0055,  ..., -0.0085,  0.0036, -0.0015],
        ...,
        [ 0.0072,  0.0096, -0.0005,  ...,  0.0150,  0.0121, -0.0038],
        [ 0.0121,  0.0014,  0.0050,  ..., -0.0073,  0.0078,  0.0130],
        [-0.0043,  0.0123,  0.0010,  ..., -0.0056, -0.0018,  0.0050]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.9023, -1.8545, -1.1494,  ...,  2.1719, -2.5117,  0.2385]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 14:25:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a beaver is referred to as a kit
The offspring of a woodchuck is referred to as a kit
The offspring of a herring is referred to as a fingerling
The offspring of a bear is referred to as a cub
The offspring of a fish is referred to as a fingerling
The offspring of a fox is referred to as a cub
The offspring of a bee is referred to as a larva
The offspring of a rabbit is referred to as a
2024-07-27 14:25:52 root INFO     [order_1_approx] starting weight calculation for The offspring of a rabbit is referred to as a bunny
The offspring of a bee is referred to as a larva
The offspring of a woodchuck is referred to as a kit
The offspring of a bear is referred to as a cub
The offspring of a beaver is referred to as a kit
The offspring of a fish is referred to as a fingerling
The offspring of a fox is referred to as a cub
The offspring of a herring is referred to as a
2024-07-27 14:25:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 14:28:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2229,  0.1583, -0.2490,  ...,  0.0616, -0.1707, -0.2155],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0381, -1.7041, -3.7305,  ...,  0.4229, -3.7969, -0.8496],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0337, -0.0150,  0.0136,  ...,  0.0066, -0.0294,  0.0435],
        [-0.0008,  0.0336, -0.0079,  ...,  0.0039, -0.0006, -0.0207],
        [ 0.0581, -0.0047,  0.0399,  ..., -0.0063, -0.0037,  0.0292],
        ...,
        [-0.0135,  0.0043, -0.0163,  ...,  0.0146,  0.0004,  0.0016],
        [-0.0011,  0.0302,  0.0190,  ...,  0.0287,  0.0277,  0.0012],
        [-0.0137,  0.0035, -0.0179,  ...,  0.0003,  0.0334,  0.0422]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.5957, -1.4746, -3.9199,  ...,  0.6162, -3.6328, -1.4219]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 14:28:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a rabbit is referred to as a bunny
The offspring of a bee is referred to as a larva
The offspring of a woodchuck is referred to as a kit
The offspring of a bear is referred to as a cub
The offspring of a beaver is referred to as a kit
The offspring of a fish is referred to as a fingerling
The offspring of a fox is referred to as a cub
The offspring of a herring is referred to as a
2024-07-27 14:28:43 root INFO     [order_1_approx] starting weight calculation for The offspring of a herring is referred to as a fingerling
The offspring of a fish is referred to as a fingerling
The offspring of a woodchuck is referred to as a kit
The offspring of a fox is referred to as a cub
The offspring of a rabbit is referred to as a bunny
The offspring of a bear is referred to as a cub
The offspring of a beaver is referred to as a kit
The offspring of a bee is referred to as a
2024-07-27 14:28:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 14:31:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1718, -0.0203,  0.1388,  ..., -0.0905, -0.0925, -0.1577],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7969, -1.8105, -1.0508,  ..., -0.2168, -0.6362,  1.4736],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0492, -0.0078,  0.0355,  ...,  0.0114, -0.0067,  0.0214],
        [-0.0381,  0.0086, -0.0172,  ..., -0.0048, -0.0194, -0.0375],
        [ 0.0001,  0.0090,  0.0284,  ..., -0.0050, -0.0081,  0.0134],
        ...,
        [-0.0188,  0.0095, -0.0242,  ..., -0.0030,  0.0135, -0.0270],
        [-0.0032, -0.0082,  0.0027,  ...,  0.0029,  0.0206, -0.0186],
        [ 0.0081,  0.0040,  0.0146,  ...,  0.0058, -0.0068,  0.0444]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6875, -1.2168, -1.1387,  ...,  0.2058, -0.2087,  1.0469]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 14:31:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a herring is referred to as a fingerling
The offspring of a fish is referred to as a fingerling
The offspring of a woodchuck is referred to as a kit
The offspring of a fox is referred to as a cub
The offspring of a rabbit is referred to as a bunny
The offspring of a bear is referred to as a cub
The offspring of a beaver is referred to as a kit
The offspring of a bee is referred to as a
2024-07-27 14:31:25 root INFO     [order_1_approx] starting weight calculation for The offspring of a fish is referred to as a fingerling
The offspring of a bear is referred to as a cub
The offspring of a herring is referred to as a fingerling
The offspring of a woodchuck is referred to as a kit
The offspring of a bee is referred to as a larva
The offspring of a beaver is referred to as a kit
The offspring of a rabbit is referred to as a bunny
The offspring of a fox is referred to as a
2024-07-27 14:31:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 14:34:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3286,  0.0317, -0.0245,  ..., -0.1598,  0.0735, -0.0538],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3809, -3.5898, -2.5801,  ...,  1.7051, -2.8906,  3.0742],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0329, -0.0142, -0.0020,  ...,  0.0175, -0.0046,  0.0162],
        [-0.0329,  0.0334, -0.0069,  ..., -0.0043, -0.0255, -0.0189],
        [ 0.0307, -0.0075,  0.0158,  ..., -0.0266, -0.0124, -0.0132],
        ...,
        [-0.0027,  0.0085,  0.0114,  ...,  0.0003,  0.0353, -0.0148],
        [-0.0026, -0.0112,  0.0249,  ...,  0.0087,  0.0030,  0.0036],
        [-0.0079, -0.0074,  0.0093,  ..., -0.0052, -0.0033,  0.0025]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2148, -3.3145, -2.2578,  ...,  1.9805, -2.5781,  2.7070]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 14:34:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a fish is referred to as a fingerling
The offspring of a bear is referred to as a cub
The offspring of a herring is referred to as a fingerling
The offspring of a woodchuck is referred to as a kit
The offspring of a bee is referred to as a larva
The offspring of a beaver is referred to as a kit
The offspring of a rabbit is referred to as a bunny
The offspring of a fox is referred to as a
2024-07-27 14:34:07 root INFO     [order_1_approx] starting weight calculation for The offspring of a beaver is referred to as a kit
The offspring of a woodchuck is referred to as a kit
The offspring of a herring is referred to as a fingerling
The offspring of a rabbit is referred to as a bunny
The offspring of a bee is referred to as a larva
The offspring of a bear is referred to as a cub
The offspring of a fox is referred to as a cub
The offspring of a fish is referred to as a
2024-07-27 14:34:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 14:36:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1002,  0.2476, -0.0497,  ..., -0.2488, -0.1313,  0.0320],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5762, -2.3516, -3.2969,  ..., -0.0791, -4.7656,  0.4922],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0363, -0.0240,  0.0249,  ...,  0.0234, -0.0156, -0.0003],
        [ 0.0025,  0.0560, -0.0157,  ..., -0.0141,  0.0159, -0.0377],
        [ 0.0405, -0.0123,  0.0150,  ...,  0.0005,  0.0042,  0.0037],
        ...,
        [-0.0165,  0.0126, -0.0086,  ...,  0.0213, -0.0046, -0.0011],
        [-0.0066,  0.0338, -0.0080,  ..., -0.0215,  0.0187, -0.0138],
        [ 0.0019,  0.0050, -0.0016,  ...,  0.0005, -0.0100,  0.0214]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1797, -2.2480, -3.4863,  ..., -0.0132, -4.3789,  0.2939]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 14:36:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a beaver is referred to as a kit
The offspring of a woodchuck is referred to as a kit
The offspring of a herring is referred to as a fingerling
The offspring of a rabbit is referred to as a bunny
The offspring of a bee is referred to as a larva
The offspring of a bear is referred to as a cub
The offspring of a fox is referred to as a cub
The offspring of a fish is referred to as a
2024-07-27 14:36:56 root INFO     [order_1_approx] starting weight calculation for The offspring of a fish is referred to as a fingerling
The offspring of a bee is referred to as a larva
The offspring of a woodchuck is referred to as a kit
The offspring of a rabbit is referred to as a bunny
The offspring of a bear is referred to as a cub
The offspring of a fox is referred to as a cub
The offspring of a herring is referred to as a fingerling
The offspring of a beaver is referred to as a
2024-07-27 14:36:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 14:39:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0670,  0.1263, -0.0190,  ..., -0.2490, -0.2429,  0.0696],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.6562, -1.7969, -2.6504,  ...,  1.1152, -1.1445,  0.8496],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0493,  0.0049,  0.0239,  ...,  0.0342, -0.0041,  0.0238],
        [-0.0020,  0.0464, -0.0243,  ...,  0.0092, -0.0186,  0.0032],
        [ 0.0188,  0.0050,  0.0052,  ..., -0.0528,  0.0040,  0.0034],
        ...,
        [-0.0038,  0.0087, -0.0121,  ...,  0.0305, -0.0011, -0.0313],
        [-0.0025, -0.0043,  0.0230,  ...,  0.0034,  0.0200,  0.0066],
        [ 0.0133, -0.0041, -0.0153,  ..., -0.0017, -0.0064,  0.0241]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.4961, -1.5059, -2.2559,  ...,  1.0371, -1.0518,  0.6753]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 14:39:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a fish is referred to as a fingerling
The offspring of a bee is referred to as a larva
The offspring of a woodchuck is referred to as a kit
The offspring of a rabbit is referred to as a bunny
The offspring of a bear is referred to as a cub
The offspring of a fox is referred to as a cub
The offspring of a herring is referred to as a fingerling
The offspring of a beaver is referred to as a
2024-07-27 14:39:41 root INFO     [order_1_approx] starting weight calculation for The offspring of a bear is referred to as a cub
The offspring of a herring is referred to as a fingerling
The offspring of a fox is referred to as a cub
The offspring of a beaver is referred to as a kit
The offspring of a bee is referred to as a larva
The offspring of a fish is referred to as a fingerling
The offspring of a rabbit is referred to as a bunny
The offspring of a woodchuck is referred to as a
2024-07-27 14:39:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 14:42:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0979, -0.0693, -0.2620,  ..., -0.1903, -0.5674, -0.2025],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0430, -3.7188,  0.9688,  ..., -1.0391, -1.9688,  0.6685],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0255, -0.0296,  0.0164,  ...,  0.0459, -0.0262,  0.0384],
        [ 0.0089,  0.0099, -0.0198,  ..., -0.0079,  0.0527,  0.0053],
        [ 0.0140, -0.0044,  0.0364,  ..., -0.0162,  0.0015, -0.0028],
        ...,
        [ 0.0350,  0.0035, -0.0199,  ...,  0.0317,  0.0339,  0.0215],
        [-0.0002, -0.0107,  0.0199,  ..., -0.0037,  0.0163, -0.0218],
        [-0.0168,  0.0172, -0.0332,  ...,  0.0016, -0.0144,  0.0094]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8652, -3.3672,  0.8613,  ..., -0.9966, -1.7441,  0.7070]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 14:42:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a bear is referred to as a cub
The offspring of a herring is referred to as a fingerling
The offspring of a fox is referred to as a cub
The offspring of a beaver is referred to as a kit
The offspring of a bee is referred to as a larva
The offspring of a fish is referred to as a fingerling
The offspring of a rabbit is referred to as a bunny
The offspring of a woodchuck is referred to as a
2024-07-27 14:42:27 root INFO     [order_1_approx] starting weight calculation for The offspring of a bee is referred to as a larva
The offspring of a fox is referred to as a cub
The offspring of a herring is referred to as a fingerling
The offspring of a fish is referred to as a fingerling
The offspring of a woodchuck is referred to as a kit
The offspring of a rabbit is referred to as a bunny
The offspring of a beaver is referred to as a kit
The offspring of a bear is referred to as a
2024-07-27 14:42:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 14:45:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1135, -0.1022,  0.1154,  ..., -0.2559, -0.2134, -0.0066],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6133, -4.2188, -1.5410,  ...,  0.5972, -1.7588,  1.4248],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.6367e-02, -3.7598e-02,  9.2621e-03,  ...,  9.8877e-03,
         -1.1009e-02,  1.7929e-02],
        [-2.7054e-02,  2.3087e-02, -1.4923e-02,  ...,  3.3913e-03,
         -1.1406e-03, -2.7756e-02],
        [-5.5313e-05,  1.3790e-03,  1.6632e-02,  ...,  1.0048e-02,
          1.0445e-02, -2.8641e-02],
        ...,
        [-1.2634e-02,  1.2512e-02, -1.2985e-02,  ...,  3.1796e-03,
          1.9974e-02, -2.7199e-03],
        [ 1.7996e-03,  8.9569e-03,  1.5518e-02,  ...,  1.9073e-02,
          2.5528e-02, -8.6594e-03],
        [ 9.2316e-04, -1.5190e-02,  7.5417e-03,  ..., -3.8605e-03,
         -2.2095e-02,  2.4109e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4863, -3.5625, -0.9395,  ...,  0.9639, -1.1348,  0.9111]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 14:45:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a bee is referred to as a larva
The offspring of a fox is referred to as a cub
The offspring of a herring is referred to as a fingerling
The offspring of a fish is referred to as a fingerling
The offspring of a woodchuck is referred to as a kit
The offspring of a rabbit is referred to as a bunny
The offspring of a beaver is referred to as a kit
The offspring of a bear is referred to as a
2024-07-27 14:45:10 root INFO     total operator prediction time: 1327.2066900730133 seconds
2024-07-27 14:45:10 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on synonyms - exact
2024-07-27 14:45:10 root INFO     building operator synonyms - exact
2024-07-27 14:45:10 root INFO     [order_1_approx] starting weight calculation for Another word for reasonable is sensible
Another word for father is dad
Another word for sweets is confectionery
Another word for cloth is fabric
Another word for intelligent is clever
Another word for style is manner
Another word for vocabulary is lexicon
Another word for auto is
2024-07-27 14:45:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 14:47:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1443,  0.1740, -0.0219,  ..., -0.0668, -0.0977,  0.1182],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.6123, -6.5703,  1.9268,  ..., -1.1445,  0.0522,  1.3857],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0591,  0.0061,  0.0423,  ...,  0.0473,  0.0176,  0.0126],
        [-0.0388,  0.0385, -0.0119,  ...,  0.0120,  0.0225, -0.0386],
        [ 0.0309,  0.0030,  0.0553,  ..., -0.0116, -0.0194, -0.0025],
        ...,
        [-0.0154,  0.0067, -0.0064,  ...,  0.0535, -0.0032, -0.0273],
        [ 0.0395,  0.0089, -0.0052,  ...,  0.0525,  0.0262, -0.0245],
        [-0.0051, -0.0259, -0.0273,  ..., -0.0285, -0.0107,  0.0528]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.2168, -6.5859,  1.5664,  ..., -0.9336,  0.3281,  1.2646]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 14:47:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for reasonable is sensible
Another word for father is dad
Another word for sweets is confectionery
Another word for cloth is fabric
Another word for intelligent is clever
Another word for style is manner
Another word for vocabulary is lexicon
Another word for auto is
2024-07-27 14:47:57 root INFO     [order_1_approx] starting weight calculation for Another word for intelligent is clever
Another word for auto is car
Another word for style is manner
Another word for father is dad
Another word for vocabulary is lexicon
Another word for cloth is fabric
Another word for sweets is confectionery
Another word for reasonable is
2024-07-27 14:47:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 14:50:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1479,  0.1971, -0.0907,  ..., -0.2893, -0.2302,  0.1874],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9688,  1.9600, -2.0137,  ..., -2.9629, -8.6875, -0.7490],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0869, -0.0324,  0.0051,  ..., -0.0356,  0.0071,  0.0219],
        [-0.0521,  0.0415,  0.0225,  ..., -0.0128,  0.0119,  0.0362],
        [ 0.0164, -0.0215,  0.0681,  ..., -0.0099, -0.0159,  0.0154],
        ...,
        [ 0.0178,  0.0282,  0.0579,  ...,  0.0590,  0.0333, -0.0124],
        [ 0.0133, -0.0049, -0.0258,  ..., -0.0449,  0.0090, -0.0659],
        [-0.0223, -0.0057,  0.0436,  ...,  0.0031, -0.0277,  0.0432]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3047,  1.8018, -2.0566,  ..., -2.2500, -8.2812, -0.3708]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 14:50:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for intelligent is clever
Another word for auto is car
Another word for style is manner
Another word for father is dad
Another word for vocabulary is lexicon
Another word for cloth is fabric
Another word for sweets is confectionery
Another word for reasonable is
2024-07-27 14:50:46 root INFO     [order_1_approx] starting weight calculation for Another word for reasonable is sensible
Another word for sweets is confectionery
Another word for father is dad
Another word for auto is car
Another word for intelligent is clever
Another word for cloth is fabric
Another word for style is manner
Another word for vocabulary is
2024-07-27 14:50:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 14:53:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2399,  0.0994, -0.1470,  ...,  0.3696,  0.0584,  0.2229],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4980, -2.4043,  5.2812,  ..., -1.7656, -0.4980,  0.6875],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.9877e-02,  5.7526e-03, -9.0332e-03,  ..., -8.3923e-04,
         -1.8097e-02, -5.6534e-03],
        [-4.8637e-04,  2.3788e-02,  5.4077e-02,  ..., -2.0950e-02,
          2.7100e-02,  3.1967e-03],
        [-7.6256e-03, -4.6814e-02, -4.5013e-04,  ...,  1.5045e-02,
         -5.7602e-04,  1.1734e-02],
        ...,
        [ 1.4275e-02,  1.7166e-03, -1.2436e-02,  ...,  1.5579e-02,
          2.8610e-04,  6.8665e-05],
        [-8.8959e-03, -2.8534e-02, -2.2278e-03,  ...,  1.4496e-03,
          1.5129e-02, -9.3613e-03],
        [ 8.4610e-03,  1.1116e-02,  2.1057e-02,  ..., -1.6956e-03,
          4.5109e-04,  3.0365e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1445, -2.2949,  5.5820,  ..., -1.1250, -0.9111,  0.2583]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 14:53:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for reasonable is sensible
Another word for sweets is confectionery
Another word for father is dad
Another word for auto is car
Another word for intelligent is clever
Another word for cloth is fabric
Another word for style is manner
Another word for vocabulary is
2024-07-27 14:53:31 root INFO     [order_1_approx] starting weight calculation for Another word for reasonable is sensible
Another word for style is manner
Another word for father is dad
Another word for vocabulary is lexicon
Another word for intelligent is clever
Another word for auto is car
Another word for sweets is confectionery
Another word for cloth is
2024-07-27 14:53:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 14:56:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0695,  0.0129, -0.1693,  ...,  0.1981, -0.1566,  0.2185],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9297, -4.1875,  1.8662,  ..., -0.5552, -2.3770,  1.3145],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0658, -0.0134,  0.0283,  ...,  0.0020,  0.0200,  0.0086],
        [ 0.0131,  0.0359, -0.0117,  ..., -0.0184, -0.0032, -0.0212],
        [-0.0345, -0.0050,  0.0348,  ..., -0.0326, -0.0118, -0.0150],
        ...,
        [ 0.0327,  0.0167,  0.0175,  ...,  0.0188, -0.0282, -0.0031],
        [-0.0418, -0.0062, -0.0385,  ...,  0.0346,  0.0454, -0.0237],
        [-0.0074,  0.0286, -0.0021,  ..., -0.0316,  0.0215,  0.0480]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0430, -3.7832,  1.2266,  ..., -0.7188, -2.0098,  1.8379]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 14:56:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for reasonable is sensible
Another word for style is manner
Another word for father is dad
Another word for vocabulary is lexicon
Another word for intelligent is clever
Another word for auto is car
Another word for sweets is confectionery
Another word for cloth is
2024-07-27 14:56:17 root INFO     [order_1_approx] starting weight calculation for Another word for auto is car
Another word for sweets is confectionery
Another word for vocabulary is lexicon
Another word for cloth is fabric
Another word for father is dad
Another word for intelligent is clever
Another word for reasonable is sensible
Another word for style is
2024-07-27 14:56:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 14:59:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1301, -0.1641, -0.0099,  ...,  0.0676,  0.0357,  0.1686],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7656, -2.3320,  0.3552,  ...,  2.3105, -5.5625, -0.1943],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0513, -0.0281,  0.0244,  ...,  0.0071,  0.0032, -0.0222],
        [-0.0039,  0.0580,  0.0159,  ..., -0.0273,  0.0065,  0.0022],
        [ 0.0011, -0.0043,  0.0548,  ...,  0.0057,  0.0225, -0.0051],
        ...,
        [ 0.0060, -0.0096,  0.0309,  ...,  0.0398, -0.0269, -0.0175],
        [ 0.0038, -0.0298, -0.0064,  ...,  0.0025,  0.0567, -0.0052],
        [ 0.0103,  0.0460, -0.0044,  ...,  0.0053,  0.0044,  0.0098]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6772, -1.8311,  0.5840,  ...,  2.8398, -6.0664, -0.2502]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 14:59:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for auto is car
Another word for sweets is confectionery
Another word for vocabulary is lexicon
Another word for cloth is fabric
Another word for father is dad
Another word for intelligent is clever
Another word for reasonable is sensible
Another word for style is
2024-07-27 14:59:02 root INFO     [order_1_approx] starting weight calculation for Another word for intelligent is clever
Another word for cloth is fabric
Another word for reasonable is sensible
Another word for vocabulary is lexicon
Another word for auto is car
Another word for style is manner
Another word for sweets is confectionery
Another word for father is
2024-07-27 14:59:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 15:01:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0517,  0.0797, -0.1058,  ..., -0.0357, -0.1199,  0.1149],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4824, -1.9521, -0.2144,  ...,  0.7627, -2.5117, -1.9941],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0279, -0.0454,  0.0267,  ...,  0.0141,  0.0110,  0.0118],
        [-0.0101,  0.0061,  0.0020,  ..., -0.0163,  0.0215,  0.0036],
        [ 0.0142, -0.0182,  0.0339,  ...,  0.0272, -0.0089, -0.0074],
        ...,
        [-0.0274,  0.0124,  0.0019,  ...,  0.0200, -0.0100,  0.0041],
        [-0.0416,  0.0132, -0.0043,  ...,  0.0129, -0.0162, -0.0232],
        [ 0.0078, -0.0077, -0.0123,  ...,  0.0035, -0.0175,  0.0066]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7080, -1.4697,  0.6084,  ...,  0.5039, -2.4746, -1.9121]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 15:01:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for intelligent is clever
Another word for cloth is fabric
Another word for reasonable is sensible
Another word for vocabulary is lexicon
Another word for auto is car
Another word for style is manner
Another word for sweets is confectionery
Another word for father is
2024-07-27 15:01:46 root INFO     [order_1_approx] starting weight calculation for Another word for cloth is fabric
Another word for sweets is confectionery
Another word for style is manner
Another word for reasonable is sensible
Another word for father is dad
Another word for vocabulary is lexicon
Another word for auto is car
Another word for intelligent is
2024-07-27 15:01:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 15:04:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0610,  0.1599, -0.0554,  ..., -0.1935,  0.0190,  0.0390],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0469, -0.6128,  0.7627,  ...,  1.9238, -4.0195,  0.6113],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0349,  0.0077,  0.0139,  ..., -0.0147,  0.0181,  0.0156],
        [-0.0333,  0.0152,  0.0344,  ...,  0.0034,  0.0355,  0.0127],
        [ 0.0040, -0.0117,  0.0423,  ...,  0.0096,  0.0197,  0.0044],
        ...,
        [ 0.0037,  0.0140, -0.0225,  ...,  0.0336, -0.0076, -0.0324],
        [ 0.0123, -0.0132,  0.0114,  ..., -0.0149,  0.0094, -0.0231],
        [-0.0047,  0.0023,  0.0195,  ..., -0.0019,  0.0177,  0.0090]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0303, -0.6528,  0.7153,  ...,  2.1973, -4.2539,  0.6714]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 15:04:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for cloth is fabric
Another word for sweets is confectionery
Another word for style is manner
Another word for reasonable is sensible
Another word for father is dad
Another word for vocabulary is lexicon
Another word for auto is car
Another word for intelligent is
2024-07-27 15:04:32 root INFO     [order_1_approx] starting weight calculation for Another word for father is dad
Another word for auto is car
Another word for vocabulary is lexicon
Another word for reasonable is sensible
Another word for intelligent is clever
Another word for cloth is fabric
Another word for style is manner
Another word for sweets is
2024-07-27 15:04:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 15:07:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1293, -0.1490,  0.3052,  ..., -0.0265, -0.1747, -0.1400],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4336, -6.5547,  0.7188,  ..., -2.0156, -1.5029,  3.2773],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0214, -0.0012,  0.0197,  ..., -0.0263,  0.0120,  0.0139],
        [-0.0164,  0.0364,  0.0302,  ...,  0.0003, -0.0152, -0.0504],
        [-0.0028, -0.0078,  0.0092,  ...,  0.0123, -0.0124,  0.0089],
        ...,
        [ 0.0183, -0.0040, -0.0249,  ...,  0.0527,  0.0128, -0.0185],
        [-0.0104, -0.0201, -0.0187,  ...,  0.0041,  0.0368, -0.0213],
        [-0.0329,  0.0011, -0.0212,  ..., -0.0023,  0.0120,  0.0580]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8457, -6.7070,  0.4058,  ..., -1.5410, -1.8008,  3.3965]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 15:07:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for father is dad
Another word for auto is car
Another word for vocabulary is lexicon
Another word for reasonable is sensible
Another word for intelligent is clever
Another word for cloth is fabric
Another word for style is manner
Another word for sweets is
2024-07-27 15:07:17 root INFO     total operator prediction time: 1327.7485988140106 seconds
2024-07-27 15:07:17 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hypernyms - misc
2024-07-27 15:07:17 root INFO     building operator hypernyms - misc
2024-07-27 15:07:18 root INFO     [order_1_approx] starting weight calculation for The dishwasher falls into the category of appliance
The diary falls into the category of journal
The vase falls into the category of jar
The photo falls into the category of picture
The toaster falls into the category of appliance
The hairnet falls into the category of net
The denim falls into the category of fabric
The grapefruit falls into the category of
2024-07-27 15:07:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 15:10:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2437, -0.3850, -0.2301,  ..., -0.1448, -0.3799, -0.0471],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7168, -5.0938,  1.0273,  ..., -5.8672, -2.3555, -2.6348],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0237,  0.0178, -0.0128,  ...,  0.0154,  0.0004,  0.0007],
        [ 0.0069, -0.0012,  0.0179,  ..., -0.0051,  0.0045,  0.0429],
        [-0.0204,  0.0207,  0.0067,  ...,  0.0139, -0.0338, -0.0049],
        ...,
        [ 0.0135, -0.0279,  0.0007,  ...,  0.0233,  0.0021,  0.0303],
        [ 0.0025,  0.0042,  0.0089,  ...,  0.0330,  0.0094, -0.0117],
        [ 0.0076, -0.0363,  0.0264,  ..., -0.0562, -0.0030,  0.0621]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7227, -4.9570,  0.7256,  ..., -5.3398, -2.1387, -2.6133]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 15:10:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The dishwasher falls into the category of appliance
The diary falls into the category of journal
The vase falls into the category of jar
The photo falls into the category of picture
The toaster falls into the category of appliance
The hairnet falls into the category of net
The denim falls into the category of fabric
The grapefruit falls into the category of
2024-07-27 15:10:04 root INFO     [order_1_approx] starting weight calculation for The dishwasher falls into the category of appliance
The hairnet falls into the category of net
The grapefruit falls into the category of citrus
The toaster falls into the category of appliance
The vase falls into the category of jar
The diary falls into the category of journal
The photo falls into the category of picture
The denim falls into the category of
2024-07-27 15:10:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 15:12:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3496, -0.0758, -0.5259,  ...,  0.4058, -0.2290,  0.0980],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.2500, -7.4531,  1.3018,  ..., -0.0189, -4.5430,  1.9277],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0462,  0.0230,  0.0016,  ..., -0.0155,  0.0144,  0.0302],
        [ 0.0071,  0.0137, -0.0076,  ..., -0.0060, -0.0095,  0.0250],
        [ 0.0062, -0.0541,  0.0169,  ..., -0.0171, -0.0144, -0.0182],
        ...,
        [ 0.0236, -0.0247,  0.0026,  ...,  0.0735, -0.0110, -0.0097],
        [ 0.0107, -0.0002, -0.0005,  ...,  0.0143,  0.0384, -0.0218],
        [ 0.0259,  0.0137,  0.0230,  ..., -0.0121, -0.0236,  0.1020]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.1641, -7.2188,  1.7100,  ...,  0.1995, -4.5781,  2.4180]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 15:12:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The dishwasher falls into the category of appliance
The hairnet falls into the category of net
The grapefruit falls into the category of citrus
The toaster falls into the category of appliance
The vase falls into the category of jar
The diary falls into the category of journal
The photo falls into the category of picture
The denim falls into the category of
2024-07-27 15:12:51 root INFO     [order_1_approx] starting weight calculation for The grapefruit falls into the category of citrus
The denim falls into the category of fabric
The toaster falls into the category of appliance
The dishwasher falls into the category of appliance
The hairnet falls into the category of net
The photo falls into the category of picture
The diary falls into the category of journal
The vase falls into the category of
2024-07-27 15:12:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 15:15:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1898, -0.2474, -0.1282,  ...,  0.0706, -0.1375, -0.3445],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6289, -2.2402,  0.6162,  ..., -2.4531, -3.8555,  1.9678],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0641,  0.0161, -0.0167,  ..., -0.0110,  0.0057,  0.0342],
        [-0.0318,  0.0599,  0.0084,  ...,  0.0197, -0.0505, -0.0286],
        [ 0.0069, -0.0184,  0.0346,  ..., -0.0331, -0.0234, -0.0159],
        ...,
        [ 0.0006, -0.0292, -0.0037,  ...,  0.0193,  0.0046, -0.0405],
        [ 0.0038,  0.0010,  0.0113,  ...,  0.0164,  0.0425,  0.0098],
        [-0.0231, -0.0103,  0.0155,  ..., -0.0207,  0.0023,  0.0171]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7656, -2.0820,  1.2529,  ..., -1.8477, -3.4590,  1.6064]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 15:15:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The grapefruit falls into the category of citrus
The denim falls into the category of fabric
The toaster falls into the category of appliance
The dishwasher falls into the category of appliance
The hairnet falls into the category of net
The photo falls into the category of picture
The diary falls into the category of journal
The vase falls into the category of
2024-07-27 15:15:36 root INFO     [order_1_approx] starting weight calculation for The vase falls into the category of jar
The denim falls into the category of fabric
The grapefruit falls into the category of citrus
The diary falls into the category of journal
The hairnet falls into the category of net
The dishwasher falls into the category of appliance
The toaster falls into the category of appliance
The photo falls into the category of
2024-07-27 15:15:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 15:18:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1973, -0.0612, -0.1450,  ..., -0.1667, -0.2715, -0.0748],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1139, -3.0566,  0.4526,  ..., -1.4541, -0.9551,  0.0137],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.4922e-02, -1.8921e-02,  3.3875e-02,  ..., -1.7853e-02,
          1.1368e-02,  2.0401e-02],
        [-3.4882e-02,  1.9531e-02,  3.4973e-02,  ...,  3.5324e-03,
         -3.7292e-02,  2.6917e-02],
        [ 2.4811e-02, -5.4855e-03,  4.2847e-02,  ...,  5.8098e-03,
          8.7585e-03,  2.2461e-02],
        ...,
        [ 4.2191e-03,  3.1982e-02,  1.4191e-02,  ...,  2.6215e-02,
         -1.5961e-02,  1.9112e-03],
        [ 8.2474e-03,  1.6464e-02,  1.6724e-02,  ...,  8.7738e-05,
          6.0852e-02,  3.2440e-02],
        [-6.7139e-04,  3.8681e-03,  3.9520e-03,  ..., -1.3199e-02,
         -2.2522e-02,  3.7201e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3496, -3.2891,  0.6836,  ..., -1.4785, -1.0020,  0.1808]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 15:18:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The vase falls into the category of jar
The denim falls into the category of fabric
The grapefruit falls into the category of citrus
The diary falls into the category of journal
The hairnet falls into the category of net
The dishwasher falls into the category of appliance
The toaster falls into the category of appliance
The photo falls into the category of
2024-07-27 15:18:21 root INFO     [order_1_approx] starting weight calculation for The dishwasher falls into the category of appliance
The diary falls into the category of journal
The grapefruit falls into the category of citrus
The toaster falls into the category of appliance
The vase falls into the category of jar
The denim falls into the category of fabric
The photo falls into the category of picture
The hairnet falls into the category of
2024-07-27 15:18:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 15:21:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0137, -0.2668, -0.3804,  ..., -0.0359, -0.0887, -0.2086],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1875, -2.1152,  2.5410,  ..., -0.7666, -4.2656,  5.0703],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0380,  0.0157,  0.0096,  ..., -0.0025,  0.0069,  0.0128],
        [-0.0454,  0.0468, -0.0016,  ..., -0.0024,  0.0062, -0.0018],
        [ 0.0062,  0.0072,  0.0213,  ...,  0.0054, -0.0247,  0.0117],
        ...,
        [ 0.0059, -0.0349,  0.0220,  ...,  0.0324, -0.0067, -0.0053],
        [-0.0154, -0.0244, -0.0177,  ...,  0.0091,  0.0230, -0.0170],
        [-0.0464,  0.0020,  0.0261,  ..., -0.0126,  0.0069,  0.0214]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7480, -2.0625,  2.5723,  ..., -0.3079, -4.1289,  5.0195]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 15:21:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The dishwasher falls into the category of appliance
The diary falls into the category of journal
The grapefruit falls into the category of citrus
The toaster falls into the category of appliance
The vase falls into the category of jar
The denim falls into the category of fabric
The photo falls into the category of picture
The hairnet falls into the category of
2024-07-27 15:21:06 root INFO     [order_1_approx] starting weight calculation for The photo falls into the category of picture
The grapefruit falls into the category of citrus
The toaster falls into the category of appliance
The vase falls into the category of jar
The dishwasher falls into the category of appliance
The denim falls into the category of fabric
The hairnet falls into the category of net
The diary falls into the category of
2024-07-27 15:21:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 15:23:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1887, -0.1031, -0.1383,  ..., -0.0682, -0.3728,  0.0916],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6509, -4.8555,  2.8848,  ..., -2.6387, -3.1953, -0.8115],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1154, -0.0082,  0.0108,  ..., -0.0490,  0.0425,  0.0598],
        [ 0.0025,  0.0692,  0.0315,  ..., -0.0258,  0.0057,  0.0694],
        [-0.0090, -0.0461,  0.0220,  ...,  0.0278, -0.0236, -0.0141],
        ...,
        [ 0.0168,  0.0262, -0.0012,  ...,  0.0595,  0.0174,  0.0009],
        [-0.0088, -0.0179,  0.0172,  ...,  0.0276,  0.0254, -0.0235],
        [ 0.0422,  0.0121,  0.0074,  ..., -0.0524, -0.0022,  0.0988]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6182, -4.4219,  2.0332,  ..., -2.2852, -3.4473, -0.1416]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 15:23:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The photo falls into the category of picture
The grapefruit falls into the category of citrus
The toaster falls into the category of appliance
The vase falls into the category of jar
The dishwasher falls into the category of appliance
The denim falls into the category of fabric
The hairnet falls into the category of net
The diary falls into the category of
2024-07-27 15:23:53 root INFO     [order_1_approx] starting weight calculation for The dishwasher falls into the category of appliance
The denim falls into the category of fabric
The vase falls into the category of jar
The grapefruit falls into the category of citrus
The diary falls into the category of journal
The hairnet falls into the category of net
The photo falls into the category of picture
The toaster falls into the category of
2024-07-27 15:23:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 15:26:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.5005, -0.2529, -0.1682,  ..., -0.0685, -0.2115, -0.1133],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8008, -2.5059,  0.1261,  ..., -0.8442, -3.5020,  2.2812],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0840,  0.0182, -0.0312,  ..., -0.0090, -0.0297,  0.0154],
        [-0.0010,  0.0533,  0.0640,  ...,  0.0116, -0.0074,  0.0020],
        [ 0.0267, -0.0094,  0.0029,  ..., -0.0451, -0.0496,  0.0132],
        ...,
        [ 0.0079,  0.0012, -0.0051,  ...,  0.0494,  0.0027, -0.0265],
        [-0.0386, -0.0128,  0.0146,  ...,  0.0391,  0.0864, -0.0253],
        [ 0.0102, -0.0202,  0.0210,  ..., -0.0133,  0.0003,  0.0523]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4727, -2.8750,  0.6611,  ..., -0.7539, -3.2656,  2.1328]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 15:26:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The dishwasher falls into the category of appliance
The denim falls into the category of fabric
The vase falls into the category of jar
The grapefruit falls into the category of citrus
The diary falls into the category of journal
The hairnet falls into the category of net
The photo falls into the category of picture
The toaster falls into the category of
2024-07-27 15:26:33 root INFO     [order_1_approx] starting weight calculation for The photo falls into the category of picture
The diary falls into the category of journal
The grapefruit falls into the category of citrus
The vase falls into the category of jar
The hairnet falls into the category of net
The denim falls into the category of fabric
The toaster falls into the category of appliance
The dishwasher falls into the category of
2024-07-27 15:26:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 15:29:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1885,  0.0583, -0.3230,  ...,  0.1669, -0.3303, -0.3130],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3486, -2.8555,  2.0781,  ..., -0.8735, -4.0859,  1.7295],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0371,  0.0081,  0.0036,  ...,  0.0066,  0.0104,  0.0011],
        [-0.0109,  0.0054,  0.0055,  ..., -0.0031, -0.0149,  0.0113],
        [ 0.0098,  0.0018,  0.0054,  ..., -0.0066, -0.0041,  0.0053],
        ...,
        [ 0.0040, -0.0014,  0.0045,  ...,  0.0098, -0.0176,  0.0078],
        [-0.0062, -0.0141,  0.0026,  ..., -0.0007,  0.0128, -0.0137],
        [-0.0094, -0.0145,  0.0061,  ..., -0.0132,  0.0005,  0.0036]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0566, -2.2637,  2.1094,  ..., -0.6045, -3.7734,  2.2207]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 15:29:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The photo falls into the category of picture
The diary falls into the category of journal
The grapefruit falls into the category of citrus
The vase falls into the category of jar
The hairnet falls into the category of net
The denim falls into the category of fabric
The toaster falls into the category of appliance
The dishwasher falls into the category of
2024-07-27 15:29:17 root INFO     total operator prediction time: 1319.386690378189 seconds
2024-07-27 15:29:17 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - substance
2024-07-27 15:29:17 root INFO     building operator meronyms - substance
2024-07-27 15:29:17 root INFO     [order_1_approx] starting weight calculation for A omelette is made up of eggs
A cocktail is made up of alcohol
A money is made up of paper
A flag is made up of fabric
A snow is made up of water
A desk is made up of wood
A table is made up of wood
A diamond is made up of
2024-07-27 15:29:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 15:32:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1515,  0.0329, -0.2485,  ..., -0.0382,  0.2017,  0.0717],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7285, -4.1328,  0.0808,  ..., -5.3672,  1.7812,  0.0723],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0471, -0.0175, -0.0197,  ..., -0.0084, -0.0134, -0.0022],
        [-0.0143,  0.0180,  0.0123,  ...,  0.0202,  0.0154,  0.0085],
        [ 0.0150,  0.0059,  0.0296,  ..., -0.0054,  0.0032,  0.0101],
        ...,
        [ 0.0192,  0.0138,  0.0239,  ...,  0.0103, -0.0237, -0.0141],
        [-0.0354,  0.0082, -0.0274,  ...,  0.0333,  0.0208, -0.0450],
        [ 0.0006,  0.0055, -0.0011,  ..., -0.0136, -0.0077,  0.0006]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0859, -4.1875, -0.4602,  ..., -5.1992,  1.1914,  0.2488]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 15:32:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A omelette is made up of eggs
A cocktail is made up of alcohol
A money is made up of paper
A flag is made up of fabric
A snow is made up of water
A desk is made up of wood
A table is made up of wood
A diamond is made up of
2024-07-27 15:32:02 root INFO     [order_1_approx] starting weight calculation for A desk is made up of wood
A flag is made up of fabric
A table is made up of wood
A money is made up of paper
A snow is made up of water
A cocktail is made up of alcohol
A diamond is made up of carbon
A omelette is made up of
2024-07-27 15:32:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 15:34:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3372, -0.0361, -0.0925,  ..., -0.2128, -0.3721,  0.0607],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0664, -2.4844,  3.8809,  ..., -3.7695, -1.8330,  2.2324],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.7709e-02, -4.0405e-02,  2.0676e-02,  ..., -2.1912e-02,
         -4.6082e-02,  2.9945e-03],
        [-1.1292e-02,  3.9429e-02, -3.8147e-05,  ...,  6.9313e-03,
          3.1494e-02, -2.5177e-02],
        [-9.8343e-03, -2.3590e-02,  3.0518e-02,  ...,  2.2781e-02,
          1.4000e-02, -9.0714e-03],
        ...,
        [ 9.6512e-03,  3.6255e-02, -1.2177e-02,  ...,  2.4506e-02,
          2.4933e-02, -4.7417e-03],
        [-2.9846e-02, -9.4910e-03,  1.1871e-02,  ...,  7.3853e-02,
          5.2307e-02, -2.9022e-02],
        [ 1.2722e-03, -3.2158e-03,  2.8275e-02,  ..., -3.1567e-03,
          1.4671e-02,  5.3894e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5527, -2.6777,  3.2188,  ..., -3.8047, -1.5771,  2.5430]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 15:34:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A desk is made up of wood
A flag is made up of fabric
A table is made up of wood
A money is made up of paper
A snow is made up of water
A cocktail is made up of alcohol
A diamond is made up of carbon
A omelette is made up of
2024-07-27 15:34:47 root INFO     [order_1_approx] starting weight calculation for A omelette is made up of eggs
A diamond is made up of carbon
A flag is made up of fabric
A cocktail is made up of alcohol
A desk is made up of wood
A snow is made up of water
A table is made up of wood
A money is made up of
2024-07-27 15:34:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 15:37:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-2.5244e-01, -3.5034e-02, -1.3416e-01,  ...,  2.7710e-02,
         1.2207e-04, -1.1676e-01], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6523, -3.7227, -1.6748,  ..., -5.2695, -0.5225,  2.4492],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0316, -0.0307, -0.0082,  ..., -0.0149, -0.0120, -0.0102],
        [-0.0184,  0.0125, -0.0173,  ..., -0.0120, -0.0068, -0.0225],
        [ 0.0128,  0.0185,  0.0036,  ..., -0.0237, -0.0010,  0.0012],
        ...,
        [ 0.0058,  0.0071,  0.0102,  ...,  0.0271, -0.0161, -0.0125],
        [-0.0151, -0.0047, -0.0199,  ...,  0.0066,  0.0246, -0.0088],
        [-0.0139, -0.0414, -0.0026,  ...,  0.0098,  0.0001, -0.0010]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4062, -4.0000, -1.4854,  ..., -4.9219, -0.6846,  2.8203]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 15:37:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A omelette is made up of eggs
A diamond is made up of carbon
A flag is made up of fabric
A cocktail is made up of alcohol
A desk is made up of wood
A snow is made up of water
A table is made up of wood
A money is made up of
2024-07-27 15:37:32 root INFO     [order_1_approx] starting weight calculation for A flag is made up of fabric
A cocktail is made up of alcohol
A desk is made up of wood
A money is made up of paper
A diamond is made up of carbon
A snow is made up of water
A omelette is made up of eggs
A table is made up of
2024-07-27 15:37:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 15:40:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1704, -0.0198, -0.3291,  ...,  0.1151, -0.1885,  0.0015],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.9883, -5.2188,  2.9199,  ..., -4.9727, -0.5503, -0.0146],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0102, -0.0066,  0.0070,  ...,  0.0136, -0.0222, -0.0323],
        [ 0.0048,  0.0192,  0.0113,  ..., -0.0015, -0.0148,  0.0121],
        [-0.0056,  0.0501, -0.0045,  ...,  0.0178, -0.0060, -0.0161],
        ...,
        [ 0.0357, -0.0226,  0.0239,  ...,  0.0275,  0.0059,  0.0202],
        [-0.0149, -0.0079, -0.0153,  ...,  0.0055, -0.0031, -0.0180],
        [ 0.0076, -0.0217,  0.0032,  ..., -0.0020,  0.0124,  0.0131]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.0508, -5.2461,  2.7891,  ..., -5.0039, -0.4539,  0.5161]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 15:40:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A flag is made up of fabric
A cocktail is made up of alcohol
A desk is made up of wood
A money is made up of paper
A diamond is made up of carbon
A snow is made up of water
A omelette is made up of eggs
A table is made up of
2024-07-27 15:40:20 root INFO     [order_1_approx] starting weight calculation for A cocktail is made up of alcohol
A diamond is made up of carbon
A snow is made up of water
A money is made up of paper
A desk is made up of wood
A omelette is made up of eggs
A table is made up of wood
A flag is made up of
2024-07-27 15:40:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 15:43:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1045,  0.4526, -0.2959,  ...,  0.0901, -0.1345, -0.1289],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.8906, -7.5078,  2.3809,  ..., -3.2070,  0.4043, -0.0625],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.2074e-02, -1.1154e-02,  4.3640e-02,  ...,  1.1368e-02,
         -3.2257e-02, -2.0477e-02],
        [-1.7807e-02,  6.6101e-02, -3.5877e-03,  ..., -1.0231e-02,
         -8.3923e-05,  2.0432e-02],
        [-3.4760e-02, -6.3467e-04,  4.0512e-03,  ...,  6.1340e-03,
         -2.8488e-02, -2.0462e-02],
        ...,
        [ 2.1255e-02, -2.2297e-03,  1.9897e-02,  ...,  4.3335e-02,
         -6.2332e-03, -6.3721e-02],
        [-4.1351e-02, -1.0300e-02, -3.3112e-02,  ...,  1.4091e-02,
          5.9662e-03, -5.6458e-03],
        [ 2.7756e-02, -4.7760e-03, -1.9550e-04,  ..., -4.5288e-02,
         -7.6294e-05,  5.8411e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.1562, -8.0078,  2.3262,  ..., -3.5645, -0.1890,  0.1852]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 15:43:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A cocktail is made up of alcohol
A diamond is made up of carbon
A snow is made up of water
A money is made up of paper
A desk is made up of wood
A omelette is made up of eggs
A table is made up of wood
A flag is made up of
2024-07-27 15:43:01 root INFO     [order_1_approx] starting weight calculation for A diamond is made up of carbon
A omelette is made up of eggs
A money is made up of paper
A desk is made up of wood
A snow is made up of water
A flag is made up of fabric
A table is made up of wood
A cocktail is made up of
2024-07-27 15:43:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 15:45:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1685,  0.0836, -0.0487,  ...,  0.0729, -0.3977, -0.3291],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2930, -6.2031, -2.9980,  ..., -2.2480, -0.3828, -4.9922],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0336, -0.0068, -0.0256,  ...,  0.0513, -0.0145,  0.0166],
        [-0.0124,  0.0307,  0.0379,  ..., -0.0320,  0.0322,  0.0131],
        [ 0.0048,  0.0004,  0.0198,  ..., -0.0239, -0.0173, -0.0014],
        ...,
        [-0.0173,  0.0214,  0.0081,  ...,  0.0481, -0.0227, -0.0096],
        [-0.0020,  0.0034, -0.0238,  ...,  0.0370, -0.0127, -0.0014],
        [ 0.0342, -0.0245,  0.0115,  ..., -0.0495,  0.0245,  0.0140]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3320, -6.1562, -2.9355,  ..., -2.4805, -0.3406, -4.9766]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 15:45:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A diamond is made up of carbon
A omelette is made up of eggs
A money is made up of paper
A desk is made up of wood
A snow is made up of water
A flag is made up of fabric
A table is made up of wood
A cocktail is made up of
2024-07-27 15:45:46 root INFO     [order_1_approx] starting weight calculation for A flag is made up of fabric
A money is made up of paper
A diamond is made up of carbon
A desk is made up of wood
A cocktail is made up of alcohol
A table is made up of wood
A omelette is made up of eggs
A snow is made up of
2024-07-27 15:45:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 15:48:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4053,  0.2700, -0.0407,  ..., -0.1899,  0.0391, -0.0209],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7598, -2.7773, -0.1929,  ..., -5.6406,  1.0508, -0.5293],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0463, -0.0265, -0.0096,  ...,  0.0128, -0.0112, -0.0198],
        [-0.0047, -0.0094, -0.0155,  ...,  0.0091, -0.0103, -0.0052],
        [ 0.0106, -0.0170,  0.0127,  ...,  0.0127, -0.0044,  0.0371],
        ...,
        [ 0.0133,  0.0114, -0.0184,  ...,  0.0268, -0.0068, -0.0180],
        [-0.0064,  0.0066, -0.0049,  ...,  0.0215,  0.0119,  0.0072],
        [-0.0008, -0.0283, -0.0130,  ...,  0.0038, -0.0148, -0.0098]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0273, -3.1230, -0.3616,  ..., -5.6836,  1.0488, -0.3748]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 15:48:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A flag is made up of fabric
A money is made up of paper
A diamond is made up of carbon
A desk is made up of wood
A cocktail is made up of alcohol
A table is made up of wood
A omelette is made up of eggs
A snow is made up of
2024-07-27 15:48:32 root INFO     [order_1_approx] starting weight calculation for A flag is made up of fabric
A cocktail is made up of alcohol
A money is made up of paper
A snow is made up of water
A diamond is made up of carbon
A table is made up of wood
A omelette is made up of eggs
A desk is made up of
2024-07-27 15:48:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 15:51:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1910, -0.0492, -0.2478,  ...,  0.2408, -0.4189, -0.0634],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.2773, -5.5078,  1.7666,  ..., -4.7461, -1.1035, -1.0391],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0240, -0.0263, -0.0071,  ...,  0.0196, -0.0107,  0.0021],
        [-0.0062,  0.0286, -0.0128,  ...,  0.0014, -0.0048,  0.0090],
        [ 0.0057,  0.0205,  0.0263,  ...,  0.0128, -0.0252, -0.0186],
        ...,
        [ 0.0243, -0.0194, -0.0022,  ...,  0.0164, -0.0180, -0.0065],
        [-0.0187, -0.0006,  0.0003,  ...,  0.0071,  0.0063, -0.0254],
        [ 0.0262, -0.0149,  0.0035,  ..., -0.0176,  0.0306,  0.0475]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8926, -5.4414,  1.4619,  ..., -4.5586, -1.0283, -0.6719]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 15:51:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A flag is made up of fabric
A cocktail is made up of alcohol
A money is made up of paper
A snow is made up of water
A diamond is made up of carbon
A table is made up of wood
A omelette is made up of eggs
A desk is made up of
2024-07-27 15:51:17 root INFO     total operator prediction time: 1320.5730361938477 seconds
2024-07-27 15:51:17 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on synonyms - intensity
2024-07-27 15:51:17 root INFO     building operator synonyms - intensity
2024-07-27 15:51:18 root INFO     [order_1_approx] starting weight calculation for A more intense word for happy is ecstatic
A more intense word for interesting is exciting
A more intense word for drizzle is rain
A more intense word for creative is ingenious
A more intense word for pony is horse
A more intense word for bad is awful
A more intense word for chuckle is laugh
A more intense word for confused is
2024-07-27 15:51:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 15:53:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0173,  0.1671, -0.3579,  ...,  0.1021, -0.3721,  0.3896],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.2578, -2.8516,  4.8594,  ..., -0.9473, -0.4492, -0.8311],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0089,  0.0121, -0.0520,  ..., -0.0279,  0.0251,  0.0004],
        [ 0.0305,  0.0253,  0.0430,  ..., -0.0159, -0.0089,  0.0262],
        [-0.0063, -0.0480,  0.0632,  ...,  0.0145, -0.0242,  0.0349],
        ...,
        [ 0.0115,  0.0033,  0.0198,  ...,  0.0511, -0.0311, -0.0051],
        [ 0.0139, -0.0312, -0.0134,  ...,  0.0004,  0.0293, -0.0607],
        [ 0.0060, -0.0322,  0.0097,  ..., -0.0037, -0.0105,  0.0364]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.9648, -2.6992,  5.1992,  ..., -0.8242, -0.1633, -0.9868]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 15:54:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for happy is ecstatic
A more intense word for interesting is exciting
A more intense word for drizzle is rain
A more intense word for creative is ingenious
A more intense word for pony is horse
A more intense word for bad is awful
A more intense word for chuckle is laugh
A more intense word for confused is
2024-07-27 15:54:00 root INFO     [order_1_approx] starting weight calculation for A more intense word for chuckle is laugh
A more intense word for confused is lost
A more intense word for interesting is exciting
A more intense word for creative is ingenious
A more intense word for bad is awful
A more intense word for drizzle is rain
A more intense word for pony is horse
A more intense word for happy is
2024-07-27 15:54:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 15:56:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0684, -0.1993, -0.0162,  ...,  0.0215, -0.3020,  0.1054],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.2344, -0.5879,  3.9102,  ...,  0.9565, -6.5000, -0.2441],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0236,  0.0158,  0.0179,  ..., -0.0218,  0.0200,  0.0179],
        [-0.0015,  0.0154,  0.0177,  ..., -0.0156, -0.0021, -0.0036],
        [ 0.0008, -0.0028,  0.0144,  ...,  0.0305, -0.0400,  0.0026],
        ...,
        [ 0.0014, -0.0074, -0.0161,  ...,  0.0447, -0.0005, -0.0200],
        [ 0.0278, -0.0207,  0.0168,  ...,  0.0341, -0.0105, -0.0191],
        [-0.0100, -0.0138, -0.0130,  ...,  0.0090, -0.0134,  0.0296]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.2031, -0.4189,  3.7109,  ...,  1.3701, -6.7656, -0.6650]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 15:56:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for chuckle is laugh
A more intense word for confused is lost
A more intense word for interesting is exciting
A more intense word for creative is ingenious
A more intense word for bad is awful
A more intense word for drizzle is rain
A more intense word for pony is horse
A more intense word for happy is
2024-07-27 15:56:46 root INFO     [order_1_approx] starting weight calculation for A more intense word for interesting is exciting
A more intense word for bad is awful
A more intense word for happy is ecstatic
A more intense word for chuckle is laugh
A more intense word for pony is horse
A more intense word for confused is lost
A more intense word for drizzle is rain
A more intense word for creative is
2024-07-27 15:56:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 15:59:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0497,  0.0611,  0.0767,  ..., -0.0885, -0.2321,  0.1936],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7344, -1.4922,  2.1250,  ...,  0.6113, -4.8828,  0.8047],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.4719e-02, -3.4332e-05,  1.3474e-02,  ...,  1.0185e-02,
         -1.7273e-02,  1.6373e-02],
        [-2.8702e-02,  3.2959e-02,  1.4786e-02,  ..., -4.9744e-03,
         -4.1542e-03, -3.8757e-03],
        [-6.7329e-03, -3.8757e-02,  2.9602e-02,  ..., -3.8261e-03,
          2.1042e-02,  1.0849e-02],
        ...,
        [ 8.4457e-03,  7.4730e-03, -1.5053e-02,  ...,  2.2858e-02,
         -2.7206e-02, -2.6199e-02],
        [ 2.3422e-02,  8.4610e-03,  1.2245e-02,  ...,  1.8501e-03,
          2.2385e-02, -1.1887e-02],
        [ 1.3702e-02, -1.6129e-02,  7.9041e-03,  ...,  3.4218e-03,
         -1.1932e-02,  2.4338e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6230, -1.5254,  1.8018,  ...,  0.6421, -4.8867,  0.6436]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 15:59:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for interesting is exciting
A more intense word for bad is awful
A more intense word for happy is ecstatic
A more intense word for chuckle is laugh
A more intense word for pony is horse
A more intense word for confused is lost
A more intense word for drizzle is rain
A more intense word for creative is
2024-07-27 15:59:26 root INFO     [order_1_approx] starting weight calculation for A more intense word for happy is ecstatic
A more intense word for pony is horse
A more intense word for confused is lost
A more intense word for chuckle is laugh
A more intense word for bad is awful
A more intense word for drizzle is rain
A more intense word for creative is ingenious
A more intense word for interesting is
2024-07-27 15:59:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 16:02:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0381,  0.0490,  0.2128,  ...,  0.1819, -0.1934,  0.2400],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.4648,  1.4736,  1.1943,  ..., -0.2737, -6.0234, -2.1953],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0001, -0.0243,  0.0096,  ..., -0.0252,  0.0224,  0.0201],
        [-0.0169,  0.0023, -0.0157,  ..., -0.0066, -0.0635, -0.0271],
        [ 0.0423, -0.0310,  0.0245,  ..., -0.0262,  0.0216,  0.0213],
        ...,
        [ 0.0139, -0.0036, -0.0122,  ...,  0.0616, -0.0294, -0.0016],
        [ 0.0568, -0.0072,  0.0311,  ..., -0.0210,  0.0194, -0.0207],
        [ 0.0176, -0.0143, -0.0213,  ..., -0.0002,  0.0004,  0.0077]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.2500,  0.7954,  1.9141,  ..., -1.0352, -5.1602, -2.0430]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 16:02:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for happy is ecstatic
A more intense word for pony is horse
A more intense word for confused is lost
A more intense word for chuckle is laugh
A more intense word for bad is awful
A more intense word for drizzle is rain
A more intense word for creative is ingenious
A more intense word for interesting is
2024-07-27 16:02:08 root INFO     [order_1_approx] starting weight calculation for A more intense word for interesting is exciting
A more intense word for drizzle is rain
A more intense word for creative is ingenious
A more intense word for confused is lost
A more intense word for pony is horse
A more intense word for happy is ecstatic
A more intense word for bad is awful
A more intense word for chuckle is
2024-07-27 16:02:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 16:04:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0138, -0.1504, -0.0979,  ...,  0.0304, -0.6201,  0.2186],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0283, -2.6758,  5.1484,  ...,  3.2910, -0.3887, -0.2188],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.1941e-02, -1.4496e-04, -3.1509e-03,  ..., -1.6800e-02,
          2.8305e-03,  9.7275e-03],
        [-1.3641e-02,  4.2236e-02,  2.0325e-02,  ...,  3.4973e-02,
         -2.4033e-03,  2.2263e-02],
        [-3.3474e-03, -2.0996e-02, -5.7297e-03,  ..., -6.4850e-04,
         -6.4583e-03, -1.1765e-02],
        ...,
        [-6.3896e-04, -9.6741e-03, -1.3535e-02,  ...,  1.5678e-03,
          1.7090e-03, -1.5007e-02],
        [-7.0000e-04, -7.2098e-03, -9.9792e-03,  ..., -1.1730e-04,
          9.4070e-03,  2.5692e-03],
        [ 9.3937e-05,  7.0763e-03, -1.5121e-02,  ...,  1.0834e-03,
          8.4534e-03,  1.5114e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4023, -2.7812,  5.3281,  ...,  2.7812, -0.1221, -0.4624]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 16:04:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for interesting is exciting
A more intense word for drizzle is rain
A more intense word for creative is ingenious
A more intense word for confused is lost
A more intense word for pony is horse
A more intense word for happy is ecstatic
A more intense word for bad is awful
A more intense word for chuckle is
2024-07-27 16:04:54 root INFO     [order_1_approx] starting weight calculation for A more intense word for creative is ingenious
A more intense word for chuckle is laugh
A more intense word for interesting is exciting
A more intense word for bad is awful
A more intense word for pony is horse
A more intense word for confused is lost
A more intense word for happy is ecstatic
A more intense word for drizzle is
2024-07-27 16:04:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 16:07:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0660,  0.1231, -0.2781,  ..., -0.3914, -0.2411, -0.0211],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3633, -3.6035, -1.0420,  ...,  1.4980,  0.9233, -1.3867],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0218, -0.0124, -0.0088,  ..., -0.0073,  0.0062,  0.0148],
        [-0.0146,  0.0247,  0.0087,  ...,  0.0001, -0.0051,  0.0106],
        [ 0.0021, -0.0217,  0.0295,  ...,  0.0095, -0.0042,  0.0206],
        ...,
        [ 0.0050, -0.0102, -0.0075,  ...,  0.0089, -0.0332, -0.0231],
        [-0.0081,  0.0006, -0.0146,  ..., -0.0239, -0.0046, -0.0250],
        [ 0.0097, -0.0062, -0.0023,  ...,  0.0084, -0.0045,  0.0166]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6523, -3.4746, -0.8311,  ...,  1.5635,  0.8105, -1.3496]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 16:07:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for creative is ingenious
A more intense word for chuckle is laugh
A more intense word for interesting is exciting
A more intense word for bad is awful
A more intense word for pony is horse
A more intense word for confused is lost
A more intense word for happy is ecstatic
A more intense word for drizzle is
2024-07-27 16:07:38 root INFO     [order_1_approx] starting weight calculation for A more intense word for confused is lost
A more intense word for chuckle is laugh
A more intense word for creative is ingenious
A more intense word for bad is awful
A more intense word for drizzle is rain
A more intense word for interesting is exciting
A more intense word for happy is ecstatic
A more intense word for pony is
2024-07-27 16:07:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 16:10:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1041,  0.1384, -0.1500,  ..., -0.1803, -0.0499,  0.1855],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5820, -4.0156, -0.6543,  ...,  2.2070, -3.9883, -1.0684],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0819, -0.0138,  0.0144,  ...,  0.0024, -0.0217,  0.0486],
        [-0.0373,  0.0355, -0.0285,  ..., -0.0001,  0.0121,  0.0086],
        [ 0.0697, -0.0113,  0.0518,  ..., -0.0396, -0.0433, -0.0119],
        ...,
        [ 0.0094, -0.0195,  0.0063,  ...,  0.0679, -0.0158, -0.0261],
        [-0.0173, -0.0327,  0.0482,  ..., -0.0085, -0.0241, -0.0319],
        [-0.0370, -0.0334,  0.0173,  ..., -0.0025, -0.0109,  0.0445]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2070, -3.2559, -0.6567,  ...,  2.1270, -4.1523, -0.8462]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 16:10:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for confused is lost
A more intense word for chuckle is laugh
A more intense word for creative is ingenious
A more intense word for bad is awful
A more intense word for drizzle is rain
A more intense word for interesting is exciting
A more intense word for happy is ecstatic
A more intense word for pony is
2024-07-27 16:10:27 root INFO     [order_1_approx] starting weight calculation for A more intense word for confused is lost
A more intense word for pony is horse
A more intense word for chuckle is laugh
A more intense word for drizzle is rain
A more intense word for happy is ecstatic
A more intense word for interesting is exciting
A more intense word for creative is ingenious
A more intense word for bad is
2024-07-27 16:10:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 16:13:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0449,  0.1108,  0.1389,  ...,  0.1111, -0.1609, -0.0073],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1484, -0.9941,  0.6416,  ...,  0.2207, -3.8457, -0.1797],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0216, -0.0188,  0.0621,  ..., -0.0037, -0.0415,  0.1039],
        [-0.0806,  0.0119,  0.0165,  ..., -0.0031, -0.0115, -0.0472],
        [ 0.0236, -0.0458,  0.0586,  ...,  0.0319,  0.0035,  0.0447],
        ...,
        [ 0.0167, -0.0220, -0.0175,  ...,  0.0190, -0.0195, -0.0462],
        [-0.0025, -0.0141, -0.0662,  ..., -0.0012,  0.0169, -0.0706],
        [-0.0028, -0.0020, -0.0567,  ..., -0.0065,  0.0075, -0.0235]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0508, -0.5967,  0.7563,  ...,  0.2556, -4.0742, -0.2808]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 16:13:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for confused is lost
A more intense word for pony is horse
A more intense word for chuckle is laugh
A more intense word for drizzle is rain
A more intense word for happy is ecstatic
A more intense word for interesting is exciting
A more intense word for creative is ingenious
A more intense word for bad is
2024-07-27 16:13:12 root INFO     total operator prediction time: 1314.3330612182617 seconds
2024-07-27 16:13:12 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hypernyms - animals
2024-07-27 16:13:12 root INFO     building operator hypernyms - animals
2024-07-27 16:13:12 root INFO     [order_1_approx] starting weight calculation for The lion falls into the category of feline
The ant falls into the category of insect
The quail falls into the category of fowl
The coyote falls into the category of canine
The jaguar falls into the category of feline
The duck falls into the category of fowl
The chimpanzee falls into the category of primate
The turkey falls into the category of
2024-07-27 16:13:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 16:15:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0537, -0.1511, -0.1956,  ...,  0.0005, -0.0734,  0.2710],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5166, -4.5547,  3.2695,  ..., -1.3555, -6.2969, -0.1943],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0320,  0.0152, -0.0168,  ..., -0.0224, -0.0118, -0.0009],
        [-0.0107,  0.0663, -0.0082,  ..., -0.0107, -0.0208, -0.0284],
        [ 0.0106, -0.0400,  0.0417,  ...,  0.0102, -0.0101,  0.0112],
        ...,
        [ 0.0009, -0.0037,  0.0350,  ...,  0.0355, -0.0180,  0.0243],
        [-0.0053,  0.0359,  0.0352,  ...,  0.0108,  0.0352,  0.0198],
        [ 0.0043, -0.0262,  0.0076,  ..., -0.0256, -0.0025,  0.0166]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8281, -4.5312,  2.6797,  ..., -0.9893, -6.7734,  0.1399]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 16:15:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The lion falls into the category of feline
The ant falls into the category of insect
The quail falls into the category of fowl
The coyote falls into the category of canine
The jaguar falls into the category of feline
The duck falls into the category of fowl
The chimpanzee falls into the category of primate
The turkey falls into the category of
2024-07-27 16:15:58 root INFO     [order_1_approx] starting weight calculation for The duck falls into the category of fowl
The coyote falls into the category of canine
The turkey falls into the category of fowl
The quail falls into the category of fowl
The lion falls into the category of feline
The chimpanzee falls into the category of primate
The ant falls into the category of insect
The jaguar falls into the category of
2024-07-27 16:15:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 16:18:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1317, -0.0757, -0.2988,  ..., -0.0430, -0.0839, -0.1804],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7344, -5.9023, -0.3979,  ..., -3.6406, -6.1641, -2.0430],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.3102e-02, -7.7209e-03, -1.4404e-02,  ...,  8.0109e-04,
         -7.1411e-03,  2.6245e-02],
        [ 1.9714e-02,  1.3847e-03, -3.0823e-03,  ..., -1.2970e-04,
         -2.5978e-03,  1.2100e-02],
        [ 3.6011e-02, -1.9577e-02,  1.4587e-02,  ...,  7.4348e-03,
         -1.4435e-02,  2.5375e-02],
        ...,
        [ 2.9587e-02,  6.3477e-03,  1.8539e-03,  ...,  1.2123e-02,
         -2.1000e-03,  2.3239e-02],
        [-2.7809e-03, -8.8425e-03,  1.6083e-02,  ...,  7.0496e-03,
          2.6474e-02, -8.8425e-03],
        [ 2.0161e-03, -6.9656e-03, -8.7738e-05,  ..., -9.6054e-03,
         -2.9793e-03,  1.5839e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9126, -5.5352, -0.3074,  ..., -3.3164, -6.2930, -1.9570]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 16:18:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The duck falls into the category of fowl
The coyote falls into the category of canine
The turkey falls into the category of fowl
The quail falls into the category of fowl
The lion falls into the category of feline
The chimpanzee falls into the category of primate
The ant falls into the category of insect
The jaguar falls into the category of
2024-07-27 16:18:44 root INFO     [order_1_approx] starting weight calculation for The turkey falls into the category of fowl
The duck falls into the category of fowl
The chimpanzee falls into the category of primate
The ant falls into the category of insect
The coyote falls into the category of canine
The jaguar falls into the category of feline
The quail falls into the category of fowl
The lion falls into the category of
2024-07-27 16:18:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 16:21:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0794,  0.0617, -0.2646,  ...,  0.0188, -0.0179,  0.0012],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7754, -6.6445,  0.2478,  ..., -3.9980, -6.6562, -0.8413],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0276,  0.0014, -0.0026,  ..., -0.0140, -0.0011,  0.0595],
        [ 0.0027,  0.0106, -0.0071,  ..., -0.0008, -0.0063,  0.0062],
        [ 0.0237, -0.0389,  0.0457,  ..., -0.0364,  0.0037,  0.0125],
        ...,
        [ 0.0038,  0.0230,  0.0177,  ...,  0.0353, -0.0081,  0.0127],
        [ 0.0030, -0.0184,  0.0318,  ...,  0.0352,  0.0241,  0.0117],
        [ 0.0228, -0.0155, -0.0083,  ..., -0.0517,  0.0107,  0.0533]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6338, -6.0547,  0.2720,  ..., -3.3926, -6.4531, -1.1836]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 16:21:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The turkey falls into the category of fowl
The duck falls into the category of fowl
The chimpanzee falls into the category of primate
The ant falls into the category of insect
The coyote falls into the category of canine
The jaguar falls into the category of feline
The quail falls into the category of fowl
The lion falls into the category of
2024-07-27 16:21:27 root INFO     [order_1_approx] starting weight calculation for The jaguar falls into the category of feline
The coyote falls into the category of canine
The turkey falls into the category of fowl
The chimpanzee falls into the category of primate
The quail falls into the category of fowl
The duck falls into the category of fowl
The lion falls into the category of feline
The ant falls into the category of
2024-07-27 16:21:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 16:24:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1880, -0.0928,  0.0060,  ..., -0.1132, -0.1862, -0.2384],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0732, -4.4844,  2.8691,  ..., -2.6855, -4.6406, -2.5410],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0416,  0.0139,  0.0002,  ..., -0.0084,  0.0048,  0.0120],
        [ 0.0428, -0.0240,  0.0047,  ...,  0.0107,  0.0867,  0.0198],
        [-0.0196,  0.0481,  0.0331,  ..., -0.0167, -0.1008, -0.0098],
        ...,
        [ 0.0282,  0.0261,  0.0159,  ...,  0.0611, -0.0557, -0.0071],
        [-0.0184,  0.0323,  0.0339,  ..., -0.0051,  0.0054, -0.0167],
        [ 0.0146, -0.1042, -0.0021,  ..., -0.0447,  0.1584,  0.0492]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0723, -4.3242,  2.3574,  ..., -2.5488, -5.3047, -1.6230]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 16:24:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The jaguar falls into the category of feline
The coyote falls into the category of canine
The turkey falls into the category of fowl
The chimpanzee falls into the category of primate
The quail falls into the category of fowl
The duck falls into the category of fowl
The lion falls into the category of feline
The ant falls into the category of
2024-07-27 16:24:09 root INFO     [order_1_approx] starting weight calculation for The coyote falls into the category of canine
The duck falls into the category of fowl
The lion falls into the category of feline
The chimpanzee falls into the category of primate
The turkey falls into the category of fowl
The ant falls into the category of insect
The jaguar falls into the category of feline
The quail falls into the category of
2024-07-27 16:24:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 16:26:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1685, -0.2849, -0.1459,  ...,  0.0475, -0.0963, -0.2695],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8730, -3.2188,  2.3008,  ..., -1.5947, -3.2891, -0.4531],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0785,  0.0283, -0.0294,  ..., -0.0159, -0.0186, -0.0068],
        [ 0.0097,  0.0714,  0.0096,  ...,  0.0111, -0.0108,  0.0230],
        [-0.0050, -0.0228,  0.0781,  ...,  0.0034, -0.0689,  0.0012],
        ...,
        [ 0.0282,  0.0129,  0.0068,  ...,  0.0790, -0.0030,  0.0353],
        [ 0.0234, -0.0046,  0.0104,  ...,  0.0609,  0.0461, -0.0022],
        [-0.0197, -0.0197, -0.0105,  ..., -0.0330,  0.0039,  0.0570]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4775, -3.4570,  2.0820,  ..., -1.8877, -3.0781, -0.2610]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 16:26:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The coyote falls into the category of canine
The duck falls into the category of fowl
The lion falls into the category of feline
The chimpanzee falls into the category of primate
The turkey falls into the category of fowl
The ant falls into the category of insect
The jaguar falls into the category of feline
The quail falls into the category of
2024-07-27 16:26:53 root INFO     [order_1_approx] starting weight calculation for The duck falls into the category of fowl
The jaguar falls into the category of feline
The chimpanzee falls into the category of primate
The quail falls into the category of fowl
The turkey falls into the category of fowl
The ant falls into the category of insect
The lion falls into the category of feline
The coyote falls into the category of
2024-07-27 16:26:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 16:29:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2151,  0.1642, -0.4756,  ..., -0.0184, -0.0618, -0.0388],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.1973e-03, -5.8789e+00,  1.8350e+00,  ..., -3.7559e+00,
        -5.7031e+00,  9.7949e-01], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0423,  0.0261, -0.0087,  ..., -0.0223, -0.0096,  0.0318],
        [ 0.0181,  0.0089,  0.0209,  ...,  0.0112, -0.0024,  0.0236],
        [-0.0069, -0.0081,  0.0292,  ..., -0.0264, -0.0296, -0.0229],
        ...,
        [ 0.0043,  0.0231,  0.0014,  ..., -0.0009,  0.0158,  0.0112],
        [ 0.0052, -0.0045, -0.0029,  ...,  0.0188,  0.0262, -0.0130],
        [ 0.0161,  0.0042,  0.0215,  ..., -0.0163, -0.0054,  0.0203]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1523, -6.0781,  1.6436,  ..., -3.8516, -5.8125,  0.9512]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 16:29:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The duck falls into the category of fowl
The jaguar falls into the category of feline
The chimpanzee falls into the category of primate
The quail falls into the category of fowl
The turkey falls into the category of fowl
The ant falls into the category of insect
The lion falls into the category of feline
The coyote falls into the category of
2024-07-27 16:29:34 root INFO     [order_1_approx] starting weight calculation for The ant falls into the category of insect
The coyote falls into the category of canine
The jaguar falls into the category of feline
The quail falls into the category of fowl
The duck falls into the category of fowl
The lion falls into the category of feline
The turkey falls into the category of fowl
The chimpanzee falls into the category of
2024-07-27 16:29:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 16:32:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0150, -0.1600, -0.1641,  ...,  0.0605, -0.2107,  0.0756],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2798, -4.4609,  2.1836,  ..., -4.0469, -7.1719,  0.8389],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0173, -0.0029,  0.0053,  ...,  0.0015, -0.0058,  0.0244],
        [ 0.0303, -0.0064,  0.0076,  ...,  0.0011, -0.0037,  0.0435],
        [-0.0243,  0.0008,  0.0056,  ..., -0.0016,  0.0038, -0.0422],
        ...,
        [ 0.0075,  0.0019,  0.0017,  ..., -0.0047, -0.0046,  0.0194],
        [-0.0089, -0.0013,  0.0020,  ..., -0.0043,  0.0078, -0.0076],
        [ 0.0206, -0.0166,  0.0013,  ...,  0.0070, -0.0092,  0.0394]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0464, -3.8945,  1.8389,  ..., -3.9863, -7.2617,  1.3760]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 16:32:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The ant falls into the category of insect
The coyote falls into the category of canine
The jaguar falls into the category of feline
The quail falls into the category of fowl
The duck falls into the category of fowl
The lion falls into the category of feline
The turkey falls into the category of fowl
The chimpanzee falls into the category of
2024-07-27 16:32:17 root INFO     [order_1_approx] starting weight calculation for The quail falls into the category of fowl
The coyote falls into the category of canine
The ant falls into the category of insect
The chimpanzee falls into the category of primate
The lion falls into the category of feline
The turkey falls into the category of fowl
The jaguar falls into the category of feline
The duck falls into the category of
2024-07-27 16:32:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 16:35:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1600, -0.1508, -0.0129,  ..., -0.1316, -0.0560, -0.1020],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5791, -2.0977,  3.3516,  ..., -2.0859, -6.9961,  0.5195],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0468,  0.0030, -0.0257,  ..., -0.0040,  0.0042, -0.0010],
        [ 0.0261,  0.0287,  0.0126,  ...,  0.0087, -0.0022, -0.0120],
        [ 0.0112, -0.0358,  0.0479,  ..., -0.0212, -0.0084, -0.0234],
        ...,
        [ 0.0028,  0.0073, -0.0045,  ...,  0.0272, -0.0182,  0.0081],
        [-0.0119,  0.0051,  0.0193,  ...,  0.0178,  0.0343,  0.0228],
        [ 0.0142,  0.0023,  0.0245,  ..., -0.0255,  0.0225,  0.0309]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7725, -1.9678,  3.3613,  ..., -1.8096, -7.4922,  0.6416]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 16:35:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The quail falls into the category of fowl
The coyote falls into the category of canine
The ant falls into the category of insect
The chimpanzee falls into the category of primate
The lion falls into the category of feline
The turkey falls into the category of fowl
The jaguar falls into the category of feline
The duck falls into the category of
2024-07-27 16:35:04 root INFO     total operator prediction time: 1312.3720498085022 seconds
2024-07-27 16:35:04 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hyponyms - misc
2024-07-27 16:35:04 root INFO     building operator hyponyms - misc
2024-07-27 16:35:04 root INFO     [order_1_approx] starting weight calculation for A more specific term for a emotion is anger
A more specific term for a shirt is polo
A more specific term for a cloud is thundercloud
A more specific term for a boat is ferry
A more specific term for a poem is haiku
A more specific term for a container is bag
A more specific term for a tool is rake
A more specific term for a shoes is
2024-07-27 16:35:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 16:37:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1254, -0.2242,  0.0215,  ...,  0.2983, -0.1615, -0.2068],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.1016, -6.1094, -1.2734,  ...,  1.2773,  0.6484,  2.4727],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0010, -0.0103, -0.0038,  ...,  0.0106,  0.0017,  0.0139],
        [ 0.0037,  0.0179, -0.0012,  ..., -0.0025, -0.0120, -0.0251],
        [ 0.0007, -0.0104,  0.0490,  ..., -0.0088, -0.0468,  0.0220],
        ...,
        [ 0.0069, -0.0038,  0.0013,  ...,  0.0099,  0.0016,  0.0102],
        [-0.0216, -0.0090,  0.0149,  ..., -0.0152,  0.0066, -0.0032],
        [-0.0077, -0.0053,  0.0154,  ..., -0.0364,  0.0257,  0.0428]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 6.0508, -5.7930, -1.0449,  ...,  1.5938,  0.4087,  2.3691]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 16:37:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a emotion is anger
A more specific term for a shirt is polo
A more specific term for a cloud is thundercloud
A more specific term for a boat is ferry
A more specific term for a poem is haiku
A more specific term for a container is bag
A more specific term for a tool is rake
A more specific term for a shoes is
2024-07-27 16:37:48 root INFO     [order_1_approx] starting weight calculation for A more specific term for a shoes is sneakers
A more specific term for a tool is rake
A more specific term for a boat is ferry
A more specific term for a shirt is polo
A more specific term for a emotion is anger
A more specific term for a container is bag
A more specific term for a poem is haiku
A more specific term for a cloud is
2024-07-27 16:37:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 16:40:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0312, -0.0205,  0.1296,  ..., -0.1017, -0.0473, -0.0805],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3018, -3.8555,  4.0898,  ..., -0.0889, -0.8672,  1.4062],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0534,  0.0003, -0.0215,  ..., -0.0026, -0.0015,  0.0260],
        [-0.0083,  0.0443, -0.0020,  ...,  0.0036, -0.0018, -0.0119],
        [ 0.0479, -0.0173,  0.0685,  ..., -0.0091, -0.0030,  0.0019],
        ...,
        [-0.0086, -0.0254,  0.0213,  ...,  0.0374, -0.0170, -0.0239],
        [-0.0115, -0.0112, -0.0036,  ..., -0.0116,  0.0410, -0.0219],
        [-0.0018,  0.0024, -0.0093,  ..., -0.0120, -0.0164,  0.0355]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1185, -4.0156,  3.7539,  ...,  0.0090, -0.7363,  1.6689]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 16:40:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a shoes is sneakers
A more specific term for a tool is rake
A more specific term for a boat is ferry
A more specific term for a shirt is polo
A more specific term for a emotion is anger
A more specific term for a container is bag
A more specific term for a poem is haiku
A more specific term for a cloud is
2024-07-27 16:40:33 root INFO     [order_1_approx] starting weight calculation for A more specific term for a tool is rake
A more specific term for a shirt is polo
A more specific term for a poem is haiku
A more specific term for a shoes is sneakers
A more specific term for a container is bag
A more specific term for a cloud is thundercloud
A more specific term for a emotion is anger
A more specific term for a boat is
2024-07-27 16:40:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 16:43:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0083,  0.0085,  0.0665,  ..., -0.1132, -0.2949,  0.1122],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6338, -6.1836,  0.9346,  ...,  0.1367,  0.5044,  0.3516],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0646,  0.0168, -0.0042,  ...,  0.0106,  0.0516,  0.0295],
        [ 0.0104,  0.0470, -0.0301,  ...,  0.0082, -0.0053,  0.0138],
        [-0.0022, -0.0112,  0.0508,  ..., -0.0104, -0.0018,  0.0083],
        ...,
        [ 0.0114,  0.0083, -0.0141,  ...,  0.0408,  0.0246, -0.0103],
        [-0.0107, -0.0080,  0.0242,  ..., -0.0100,  0.0210, -0.0029],
        [-0.0108, -0.0201, -0.0068,  ..., -0.0070, -0.0195,  0.0464]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4683, -5.7188,  1.4609,  ...,  0.3413,  0.5698,  0.8071]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 16:43:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a tool is rake
A more specific term for a shirt is polo
A more specific term for a poem is haiku
A more specific term for a shoes is sneakers
A more specific term for a container is bag
A more specific term for a cloud is thundercloud
A more specific term for a emotion is anger
A more specific term for a boat is
2024-07-27 16:43:19 root INFO     [order_1_approx] starting weight calculation for A more specific term for a tool is rake
A more specific term for a poem is haiku
A more specific term for a cloud is thundercloud
A more specific term for a boat is ferry
A more specific term for a shoes is sneakers
A more specific term for a container is bag
A more specific term for a emotion is anger
A more specific term for a shirt is
2024-07-27 16:43:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 16:46:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1239, -0.2568, -0.1071,  ...,  0.2954, -0.4294, -0.0048],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4414, -3.3125, -0.3201,  ...,  3.0762, -0.9893,  0.9844],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0197,  0.0002,  0.0159,  ..., -0.0129,  0.0177,  0.0036],
        [-0.0004,  0.0408, -0.0203,  ..., -0.0192, -0.0320, -0.0116],
        [ 0.0379, -0.0464,  0.0540,  ..., -0.0021, -0.0374,  0.0118],
        ...,
        [ 0.0325,  0.0143,  0.0071,  ...,  0.0161, -0.0044, -0.0107],
        [-0.0128, -0.0111, -0.0026,  ...,  0.0115,  0.0173, -0.0212],
        [-0.0001,  0.0164,  0.0102,  ..., -0.0122,  0.0365,  0.0263]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9805, -2.8809, -0.1018,  ...,  2.5547, -1.0645,  0.9941]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 16:46:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a tool is rake
A more specific term for a poem is haiku
A more specific term for a cloud is thundercloud
A more specific term for a boat is ferry
A more specific term for a shoes is sneakers
A more specific term for a container is bag
A more specific term for a emotion is anger
A more specific term for a shirt is
2024-07-27 16:46:02 root INFO     [order_1_approx] starting weight calculation for A more specific term for a boat is ferry
A more specific term for a shoes is sneakers
A more specific term for a emotion is anger
A more specific term for a cloud is thundercloud
A more specific term for a poem is haiku
A more specific term for a tool is rake
A more specific term for a shirt is polo
A more specific term for a container is
2024-07-27 16:46:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 16:48:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3501, -0.1387,  0.0464,  ..., -0.0891, -0.0757, -0.1573],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.3828, -5.4219, -0.9697,  ...,  0.8770,  1.3330, -0.4365],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.8818e-02, -2.6352e-02, -4.8599e-03,  ...,  2.5070e-02,
         -2.7374e-02,  3.3051e-02],
        [-1.2159e-04,  1.5930e-02,  1.7517e-02,  ..., -4.8561e-03,
         -9.8495e-03,  1.4267e-02],
        [ 1.1120e-03,  1.8768e-03,  3.6926e-02,  ...,  9.2316e-03,
         -8.9874e-03,  1.6956e-03],
        ...,
        [ 3.1494e-02,  1.6602e-02,  7.8201e-05,  ...,  1.8219e-02,
          3.5167e-04,  1.8921e-03],
        [-5.2109e-03, -5.4893e-03, -2.2385e-02,  ..., -1.1475e-02,
          3.4546e-02,  1.5533e-02],
        [ 7.4081e-03,  6.4735e-03, -1.7776e-03,  ...,  3.2425e-04,
         -2.1858e-03,  4.3823e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9023, -5.4375, -0.5674,  ...,  1.1494,  1.3350, -0.1897]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 16:48:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a boat is ferry
A more specific term for a shoes is sneakers
A more specific term for a emotion is anger
A more specific term for a cloud is thundercloud
A more specific term for a poem is haiku
A more specific term for a tool is rake
A more specific term for a shirt is polo
A more specific term for a container is
2024-07-27 16:48:47 root INFO     [order_1_approx] starting weight calculation for A more specific term for a tool is rake
A more specific term for a cloud is thundercloud
A more specific term for a shoes is sneakers
A more specific term for a shirt is polo
A more specific term for a boat is ferry
A more specific term for a container is bag
A more specific term for a emotion is anger
A more specific term for a poem is
2024-07-27 16:48:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 16:51:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0021,  0.1479, -0.0727,  ..., -0.0999, -0.4641, -0.0425],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6328, -6.9141,  5.7031,  ...,  1.6074, -0.3389, -1.2852],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0268, -0.0343, -0.0111,  ...,  0.0072, -0.0405,  0.0445],
        [-0.0249,  0.0292, -0.0584,  ...,  0.0156, -0.0047,  0.0285],
        [ 0.0038,  0.0004,  0.0478,  ...,  0.0210, -0.0475, -0.0228],
        ...,
        [ 0.0157, -0.0070, -0.0100,  ...,  0.0468, -0.0072, -0.0079],
        [ 0.0008,  0.0235, -0.0023,  ...,  0.0052,  0.0451,  0.0038],
        [-0.0188,  0.0009, -0.0324,  ..., -0.0078,  0.0089,  0.0726]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1992, -7.0469,  5.5078,  ...,  1.2393, -0.6494, -1.8125]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 16:51:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a tool is rake
A more specific term for a cloud is thundercloud
A more specific term for a shoes is sneakers
A more specific term for a shirt is polo
A more specific term for a boat is ferry
A more specific term for a container is bag
A more specific term for a emotion is anger
A more specific term for a poem is
2024-07-27 16:51:31 root INFO     [order_1_approx] starting weight calculation for A more specific term for a emotion is anger
A more specific term for a shoes is sneakers
A more specific term for a shirt is polo
A more specific term for a boat is ferry
A more specific term for a cloud is thundercloud
A more specific term for a poem is haiku
A more specific term for a container is bag
A more specific term for a tool is
2024-07-27 16:51:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 16:54:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1616, -0.2649,  0.0428,  ...,  0.0769, -0.0297,  0.0981],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1069, -4.3359, -0.1172,  ...,  2.3281, -3.7031,  0.8721],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0563, -0.0291,  0.0036,  ...,  0.0098,  0.0012,  0.0324],
        [ 0.0110,  0.0134, -0.0184,  ...,  0.0022,  0.0348, -0.0193],
        [-0.0147, -0.0004,  0.0086,  ..., -0.0036, -0.0163,  0.0027],
        ...,
        [ 0.0003, -0.0119,  0.0018,  ...,  0.0209,  0.0121,  0.0076],
        [-0.0099, -0.0175, -0.0164,  ..., -0.0254,  0.0175,  0.0049],
        [-0.0104,  0.0086, -0.0044,  ..., -0.0297,  0.0380,  0.0358]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1987, -3.4336,  0.1262,  ...,  2.4121, -3.6875,  1.2041]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 16:54:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a emotion is anger
A more specific term for a shoes is sneakers
A more specific term for a shirt is polo
A more specific term for a boat is ferry
A more specific term for a cloud is thundercloud
A more specific term for a poem is haiku
A more specific term for a container is bag
A more specific term for a tool is
2024-07-27 16:54:15 root INFO     [order_1_approx] starting weight calculation for A more specific term for a shoes is sneakers
A more specific term for a cloud is thundercloud
A more specific term for a poem is haiku
A more specific term for a shirt is polo
A more specific term for a tool is rake
A more specific term for a container is bag
A more specific term for a boat is ferry
A more specific term for a emotion is
2024-07-27 16:54:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 16:56:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3970,  0.0239,  0.0991,  ...,  0.1025, -0.1392, -0.0098],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.7227, -3.3984,  1.4561,  ...,  1.4785, -0.9414, -1.4277],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0243,  0.0207, -0.0072,  ...,  0.0047, -0.0111, -0.0012],
        [-0.0223,  0.0165,  0.0048,  ...,  0.0136,  0.0035,  0.0131],
        [-0.0211, -0.0180,  0.0222,  ...,  0.0020, -0.0320, -0.0305],
        ...,
        [ 0.0031, -0.0111,  0.0038,  ...,  0.0176,  0.0039, -0.0141],
        [-0.0346, -0.0035, -0.0309,  ..., -0.0097,  0.0165,  0.0110],
        [ 0.0087, -0.0009,  0.0003,  ..., -0.0145, -0.0100, -0.0146]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0508, -3.6680,  1.4189,  ...,  1.7070, -1.2422, -1.2422]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 16:57:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a shoes is sneakers
A more specific term for a cloud is thundercloud
A more specific term for a poem is haiku
A more specific term for a shirt is polo
A more specific term for a tool is rake
A more specific term for a container is bag
A more specific term for a boat is ferry
A more specific term for a emotion is
2024-07-27 16:57:00 root INFO     total operator prediction time: 1315.7080194950104 seconds
2024-07-27 16:57:00 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on antonyms - binary
2024-07-27 16:57:00 root INFO     building operator antonyms - binary
2024-07-27 16:57:00 root INFO     [order_1_approx] starting weight calculation for The opposite of after is before
The opposite of forget is remember
The opposite of downslope is upslope
The opposite of true is false
The opposite of dynamic is static
The opposite of ahead is behind
The opposite of exit is entrance
The opposite of backward is
2024-07-27 16:57:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 16:59:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1582,  0.0035, -0.3359,  ..., -0.0455, -0.0747, -0.0367],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1680, -1.8818,  1.8633,  ..., -0.6162, -2.7500, -0.5889],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.6753e-02,  4.0558e-02, -2.4323e-02,  ..., -3.4515e-02,
         -1.3367e-02,  2.7466e-02],
        [ 1.2520e-02,  4.1962e-02,  1.5656e-02,  ...,  3.4393e-02,
         -1.4915e-02, -6.1035e-04],
        [ 4.2328e-02, -4.6265e-02,  1.6693e-02,  ...,  4.2938e-02,
         -1.2350e-03, -1.7441e-02],
        ...,
        [ 8.9569e-03,  1.6861e-02,  1.2589e-04,  ...,  6.8665e-05,
          1.0750e-02,  1.1292e-02],
        [-1.1551e-02, -4.2267e-02,  1.0262e-02,  ...,  2.1820e-02,
          4.2511e-02, -2.1881e-02],
        [ 8.0719e-03,  3.3493e-03, -1.4908e-02,  ..., -1.0651e-02,
         -4.6631e-02,  1.5961e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0957, -2.0742,  1.4385,  ...,  0.0293, -2.4902, -0.5015]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 16:59:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of after is before
The opposite of forget is remember
The opposite of downslope is upslope
The opposite of true is false
The opposite of dynamic is static
The opposite of ahead is behind
The opposite of exit is entrance
The opposite of backward is
2024-07-27 16:59:45 root INFO     [order_1_approx] starting weight calculation for The opposite of downslope is upslope
The opposite of forget is remember
The opposite of ahead is behind
The opposite of backward is forward
The opposite of true is false
The opposite of dynamic is static
The opposite of exit is entrance
The opposite of after is
2024-07-27 16:59:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 17:02:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0098, -0.0478, -0.1726,  ..., -0.2046, -0.2374,  0.1167],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4316, -2.4258, -0.5342,  ...,  1.5293, -1.0283, -4.7188],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.6824e-02, -1.6617e-02, -3.0304e-02,  ..., -6.3896e-05,
         -9.5444e-03,  3.0762e-02],
        [ 1.1444e-04,  6.7871e-02,  2.2232e-02,  ...,  5.4550e-04,
         -3.8643e-03, -2.2186e-02],
        [ 5.0163e-04, -3.6278e-03, -9.3079e-03,  ...,  1.8097e-02,
         -4.9133e-03,  2.4048e-02],
        ...,
        [ 1.3199e-03, -4.6844e-02,  4.4189e-02,  ...,  4.1580e-04,
          3.6804e-02, -1.8265e-02],
        [ 2.1179e-02, -9.3689e-03,  2.5970e-02,  ..., -3.6793e-03,
          2.2278e-02, -2.4460e-02],
        [ 3.7251e-03,  5.6953e-03,  4.3945e-03,  ...,  1.0445e-02,
          2.6169e-02,  3.1586e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5625, -2.2031, -0.2590,  ...,  1.6699, -1.1426, -4.2188]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 17:02:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of downslope is upslope
The opposite of forget is remember
The opposite of ahead is behind
The opposite of backward is forward
The opposite of true is false
The opposite of dynamic is static
The opposite of exit is entrance
The opposite of after is
2024-07-27 17:02:29 root INFO     [order_1_approx] starting weight calculation for The opposite of dynamic is static
The opposite of true is false
The opposite of backward is forward
The opposite of exit is entrance
The opposite of ahead is behind
The opposite of after is before
The opposite of downslope is upslope
The opposite of forget is
2024-07-27 17:02:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 17:05:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2954,  0.1498,  0.0267,  ..., -0.0756, -0.2720,  0.3252],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0215, -3.1406, -0.7373,  ..., -1.3730, -4.9414, -2.6758],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0093, -0.0228, -0.0093,  ...,  0.0141,  0.0800, -0.0025],
        [-0.0015,  0.0270, -0.0421,  ..., -0.0114, -0.0489,  0.0324],
        [-0.0495, -0.0506,  0.0142,  ...,  0.0385, -0.0364,  0.0012],
        ...,
        [ 0.0345, -0.0211,  0.0011,  ...,  0.0146,  0.0118,  0.0197],
        [ 0.0217, -0.0027,  0.0334,  ...,  0.0178, -0.0381,  0.0015],
        [ 0.0351,  0.0158, -0.0277,  ...,  0.0254, -0.0076,  0.0411]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2715, -3.3848, -1.2402,  ..., -1.7246, -4.5781, -2.7734]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 17:05:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of dynamic is static
The opposite of true is false
The opposite of backward is forward
The opposite of exit is entrance
The opposite of ahead is behind
The opposite of after is before
The opposite of downslope is upslope
The opposite of forget is
2024-07-27 17:05:13 root INFO     [order_1_approx] starting weight calculation for The opposite of backward is forward
The opposite of exit is entrance
The opposite of dynamic is static
The opposite of after is before
The opposite of true is false
The opposite of downslope is upslope
The opposite of forget is remember
The opposite of ahead is
2024-07-27 17:05:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 17:07:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1478, -0.0323, -0.1173,  ...,  0.0552, -0.1797,  0.1656],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6611, -2.8613,  0.7949,  ..., -4.5586, -1.4775, -3.1543],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0491, -0.0170, -0.0325,  ...,  0.0267, -0.0034,  0.0402],
        [-0.0385,  0.0476,  0.0364,  ...,  0.0221,  0.0041, -0.0273],
        [-0.0018,  0.0057, -0.0024,  ...,  0.0152, -0.0323,  0.0302],
        ...,
        [ 0.0171, -0.0044, -0.0211,  ..., -0.0075,  0.0637, -0.0134],
        [ 0.0045, -0.0237,  0.0346,  ...,  0.0286,  0.0849, -0.0462],
        [ 0.0052, -0.0332, -0.0127,  ...,  0.0069, -0.0068,  0.0153]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1289, -2.8828,  0.7666,  ..., -4.1523, -1.5166, -3.0820]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 17:07:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of backward is forward
The opposite of exit is entrance
The opposite of dynamic is static
The opposite of after is before
The opposite of true is false
The opposite of downslope is upslope
The opposite of forget is remember
The opposite of ahead is
2024-07-27 17:07:58 root INFO     [order_1_approx] starting weight calculation for The opposite of forget is remember
The opposite of backward is forward
The opposite of exit is entrance
The opposite of after is before
The opposite of true is false
The opposite of downslope is upslope
The opposite of ahead is behind
The opposite of dynamic is
2024-07-27 17:07:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 17:10:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1807,  0.2335, -0.1039,  ..., -0.0312, -0.0448,  0.2153],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0767,  1.0137,  1.8203,  ..., -1.2236, -2.9453, -2.7324],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-1.5167e-02,  3.0777e-02, -1.1169e-02,  ...,  1.6846e-02,
          2.1698e-02, -3.4576e-02],
        [ 3.8330e-02,  1.4648e-02,  6.3049e-02,  ...,  2.5208e-02,
          6.2561e-03,  3.3569e-02],
        [-3.7140e-02,  1.8326e-02,  2.9716e-03,  ...,  3.8929e-03,
         -3.7415e-02, -2.0599e-02],
        ...,
        [ 8.0017e-02, -2.1248e-03, -2.4109e-03,  ...,  1.9211e-02,
          1.3176e-02,  2.2308e-02],
        [-4.3976e-02, -5.9776e-03, -2.3407e-02,  ..., -6.6650e-02,
          4.8157e-02, -3.5645e-02],
        [ 9.2163e-02,  4.5776e-05, -1.8402e-02,  ...,  4.5013e-02,
          3.5950e-02,  8.4045e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2949,  1.4434,  1.7734,  ..., -0.8340, -3.4844, -1.3379]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 17:10:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of forget is remember
The opposite of backward is forward
The opposite of exit is entrance
The opposite of after is before
The opposite of true is false
The opposite of downslope is upslope
The opposite of ahead is behind
The opposite of dynamic is
2024-07-27 17:10:42 root INFO     [order_1_approx] starting weight calculation for The opposite of forget is remember
The opposite of downslope is upslope
The opposite of backward is forward
The opposite of dynamic is static
The opposite of after is before
The opposite of exit is entrance
The opposite of ahead is behind
The opposite of true is
2024-07-27 17:10:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 17:13:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0567, -0.2452,  0.0322,  ..., -0.2959, -0.1636,  0.3074],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.5664, -1.7676,  0.2544,  ...,  1.3691, -3.0449, -2.4414],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0262, -0.0154, -0.0170,  ..., -0.0021, -0.0019,  0.0250],
        [-0.0193,  0.0261,  0.0008,  ...,  0.0182, -0.0171, -0.0277],
        [ 0.0063, -0.0375,  0.0020,  ...,  0.0023, -0.0277,  0.0119],
        ...,
        [ 0.0173,  0.0029,  0.0277,  ...,  0.0225,  0.0288,  0.0086],
        [-0.0043, -0.0099,  0.0207,  ...,  0.0218,  0.0580, -0.0445],
        [ 0.0400, -0.0174, -0.0596,  ...,  0.0222, -0.0024,  0.0809]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.9414, -2.7422,  0.1969,  ...,  1.5859, -3.6250, -2.4805]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 17:13:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of forget is remember
The opposite of downslope is upslope
The opposite of backward is forward
The opposite of dynamic is static
The opposite of after is before
The opposite of exit is entrance
The opposite of ahead is behind
The opposite of true is
2024-07-27 17:13:23 root INFO     [order_1_approx] starting weight calculation for The opposite of after is before
The opposite of forget is remember
The opposite of true is false
The opposite of backward is forward
The opposite of ahead is behind
The opposite of dynamic is static
The opposite of downslope is upslope
The opposite of exit is
2024-07-27 17:13:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 17:16:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2576,  0.0010, -0.1715,  ..., -0.1416, -0.0770,  0.0592],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3750, -3.0234, -1.6348,  ...,  2.1309, -3.5508, -3.6875],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0002,  0.0010, -0.0036,  ...,  0.0181,  0.0752,  0.0204],
        [ 0.0176,  0.0333,  0.0035,  ..., -0.0124, -0.0340,  0.0144],
        [-0.0088,  0.0008,  0.0086,  ..., -0.0165, -0.0417, -0.0667],
        ...,
        [ 0.0063, -0.0155, -0.0191,  ...,  0.0184, -0.0059,  0.0059],
        [ 0.0391, -0.0039, -0.0687,  ..., -0.0229,  0.0029, -0.0180],
        [ 0.0033,  0.0367, -0.0623,  ..., -0.0190,  0.0400,  0.0328]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6826, -3.6289, -2.0508,  ...,  1.7393, -3.7500, -3.5586]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 17:16:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of after is before
The opposite of forget is remember
The opposite of true is false
The opposite of backward is forward
The opposite of ahead is behind
The opposite of dynamic is static
The opposite of downslope is upslope
The opposite of exit is
2024-07-27 17:16:07 root INFO     [order_1_approx] starting weight calculation for The opposite of ahead is behind
The opposite of backward is forward
The opposite of dynamic is static
The opposite of after is before
The opposite of forget is remember
The opposite of true is false
The opposite of exit is entrance
The opposite of downslope is
2024-07-27 17:16:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 17:18:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0431,  0.2197, -0.1542,  ..., -0.1700, -0.5366,  0.0257],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3203, -1.5215, -3.8613,  ..., -1.8896, -2.0664, -2.8359],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0410, -0.0100,  0.0131,  ..., -0.0139,  0.0724,  0.0550],
        [ 0.0166,  0.0583, -0.0034,  ...,  0.0052, -0.0040,  0.0015],
        [ 0.0307,  0.0022,  0.0126,  ..., -0.0062, -0.0762,  0.0343],
        ...,
        [ 0.0108,  0.0045,  0.0435,  ...,  0.0233, -0.0137, -0.0031],
        [-0.0146,  0.0019,  0.0100,  ..., -0.0001,  0.0462, -0.0269],
        [-0.0026, -0.0004,  0.0061,  ..., -0.0057, -0.0192,  0.0398]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0215, -2.0117, -3.3770,  ..., -1.6357, -2.5762, -3.2617]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 17:18:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of ahead is behind
The opposite of backward is forward
The opposite of dynamic is static
The opposite of after is before
The opposite of forget is remember
The opposite of true is false
The opposite of exit is entrance
The opposite of downslope is
2024-07-27 17:18:52 root INFO     total operator prediction time: 1312.2599380016327 seconds
2024-07-27 17:18:52 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - member
2024-07-27 17:18:52 root INFO     building operator meronyms - member
2024-07-27 17:18:52 root INFO     [order_1_approx] starting weight calculation for A listener is a member of a audience
A policeman is a member of a police
A player is a member of a team
A elephant is a member of a herd
A nomad is a member of a horde
A fish is a member of a school
A county is a member of a state
A page is a member of a
2024-07-27 17:18:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 17:21:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1594,  0.2158, -0.2983,  ...,  0.0247, -0.4048,  0.0354],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6875, -1.8125,  1.0566,  ..., -2.1680, -1.6279, -1.7871],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0605, -0.0157,  0.0243,  ..., -0.0065, -0.0028,  0.0081],
        [-0.0155,  0.1232,  0.0580,  ..., -0.0113, -0.0082, -0.0133],
        [ 0.0240, -0.0358,  0.0273,  ..., -0.0009, -0.0340, -0.0215],
        ...,
        [ 0.0273,  0.0232,  0.0337,  ...,  0.0422, -0.0002, -0.0271],
        [ 0.0134,  0.1042, -0.0310,  ...,  0.0312,  0.0374, -0.0205],
        [ 0.0196, -0.0276,  0.0265,  ..., -0.0219,  0.0323,  0.0361]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5566, -2.3750,  1.6465,  ..., -2.1289, -1.7500, -1.2227]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 17:21:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A listener is a member of a audience
A policeman is a member of a police
A player is a member of a team
A elephant is a member of a herd
A nomad is a member of a horde
A fish is a member of a school
A county is a member of a state
A page is a member of a
2024-07-27 17:21:38 root INFO     [order_1_approx] starting weight calculation for A elephant is a member of a herd
A page is a member of a book
A listener is a member of a audience
A player is a member of a team
A nomad is a member of a horde
A fish is a member of a school
A policeman is a member of a police
A county is a member of a
2024-07-27 17:21:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 17:24:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1582,  0.3594, -0.1096,  ..., -0.2058,  0.0936, -0.0147],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1182, -6.7344,  4.2969,  ..., -6.3672,  3.7715, -3.9844],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0444,  0.0129,  0.0150,  ..., -0.0044, -0.0134,  0.0028],
        [-0.0115, -0.0105, -0.0051,  ..., -0.0177, -0.0015,  0.0356],
        [-0.0089,  0.0344,  0.0359,  ...,  0.0075, -0.0076, -0.0148],
        ...,
        [ 0.0154, -0.0163, -0.0126,  ...,  0.0167,  0.0042, -0.0210],
        [ 0.0219,  0.0312, -0.0244,  ...,  0.0031,  0.0385, -0.0191],
        [-0.0273, -0.0822,  0.0247,  ..., -0.0072,  0.0003,  0.0465]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0557, -6.5898,  4.0859,  ..., -5.8711,  3.6348, -4.0977]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 17:24:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A elephant is a member of a herd
A page is a member of a book
A listener is a member of a audience
A player is a member of a team
A nomad is a member of a horde
A fish is a member of a school
A policeman is a member of a police
A county is a member of a
2024-07-27 17:24:23 root INFO     [order_1_approx] starting weight calculation for A policeman is a member of a police
A county is a member of a state
A page is a member of a book
A fish is a member of a school
A listener is a member of a audience
A elephant is a member of a herd
A player is a member of a team
A nomad is a member of a
2024-07-27 17:24:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 17:27:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0135,  0.0805, -0.2996,  ...,  0.1292, -0.1034,  0.1770],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5410, -3.0215,  1.5977,  ..., -2.0078, -1.7188, -0.5547],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0534, -0.0048,  0.0289,  ...,  0.0030, -0.0258, -0.0375],
        [ 0.0016,  0.0172, -0.0184,  ..., -0.0027,  0.0008, -0.0033],
        [ 0.0111, -0.0137,  0.0305,  ..., -0.0192, -0.0039,  0.0060],
        ...,
        [ 0.0129, -0.0094, -0.0047,  ...,  0.0536,  0.0089, -0.0028],
        [ 0.0114, -0.0008, -0.0238,  ..., -0.0148,  0.0147,  0.0006],
        [ 0.0084,  0.0033,  0.0059,  ...,  0.0206,  0.0105,  0.0649]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1523, -2.9121,  1.7051,  ..., -2.1016, -1.4932, -0.1248]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 17:27:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A policeman is a member of a police
A county is a member of a state
A page is a member of a book
A fish is a member of a school
A listener is a member of a audience
A elephant is a member of a herd
A player is a member of a team
A nomad is a member of a
2024-07-27 17:27:09 root INFO     [order_1_approx] starting weight calculation for A county is a member of a state
A fish is a member of a school
A listener is a member of a audience
A nomad is a member of a horde
A page is a member of a book
A policeman is a member of a police
A player is a member of a team
A elephant is a member of a
2024-07-27 17:27:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 17:29:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0887, -0.0100, -0.0148,  ..., -0.1295, -0.4177, -0.0577],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 8.2812, -4.6016,  3.2324,  ..., -3.0156, -3.2266, -2.1836],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0457,  0.0611, -0.0022,  ...,  0.0170,  0.0504, -0.0638],
        [ 0.0417, -0.0367,  0.0126,  ..., -0.0136, -0.0431,  0.0557],
        [-0.0403,  0.0119,  0.0106,  ...,  0.0064,  0.0167, -0.0305],
        ...,
        [ 0.0410, -0.0302,  0.0072,  ...,  0.0051, -0.0268,  0.0417],
        [ 0.0285, -0.0147, -0.0007,  ..., -0.0170,  0.0127,  0.0150],
        [ 0.0264, -0.0276,  0.0067,  ..., -0.0195, -0.0297,  0.0495]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 8.3984, -4.5703,  3.1934,  ..., -3.1953, -3.1426, -2.1914]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 17:29:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A county is a member of a state
A fish is a member of a school
A listener is a member of a audience
A nomad is a member of a horde
A page is a member of a book
A policeman is a member of a police
A player is a member of a team
A elephant is a member of a
2024-07-27 17:29:54 root INFO     [order_1_approx] starting weight calculation for A listener is a member of a audience
A page is a member of a book
A policeman is a member of a police
A county is a member of a state
A nomad is a member of a horde
A elephant is a member of a herd
A player is a member of a team
A fish is a member of a
2024-07-27 17:29:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 17:32:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1956,  0.3845, -0.0394,  ..., -0.1827, -0.1348, -0.0256],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.5977, -3.3867,  1.9346,  ..., -1.5186, -3.3398, -1.7324],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0477,  0.0039, -0.0058,  ...,  0.0227,  0.0090,  0.0071],
        [-0.0232,  0.0441, -0.0109,  ..., -0.0117,  0.0038, -0.0236],
        [ 0.0030,  0.0200,  0.0377,  ..., -0.0191, -0.0036, -0.0018],
        ...,
        [ 0.0268,  0.0375,  0.0152,  ...,  0.0429, -0.0185, -0.0164],
        [ 0.0058,  0.0061, -0.0070,  ..., -0.0035,  0.0220, -0.0051],
        [-0.0153, -0.0457,  0.0009,  ..., -0.0061,  0.0204,  0.0572]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.3867, -3.2148,  1.8213,  ..., -1.1699, -3.4629, -1.6094]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 17:32:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A listener is a member of a audience
A page is a member of a book
A policeman is a member of a police
A county is a member of a state
A nomad is a member of a horde
A elephant is a member of a herd
A player is a member of a team
A fish is a member of a
2024-07-27 17:32:38 root INFO     [order_1_approx] starting weight calculation for A nomad is a member of a horde
A fish is a member of a school
A county is a member of a state
A listener is a member of a audience
A page is a member of a book
A elephant is a member of a herd
A policeman is a member of a police
A player is a member of a
2024-07-27 17:32:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 17:35:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0620,  0.2559, -0.1184,  ...,  0.0872, -0.1967, -0.2448],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4336, -7.3047,  1.1357,  ..., -1.6621, -0.3159, -4.7266],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0536, -0.0424,  0.0146,  ...,  0.0071,  0.0378, -0.0014],
        [ 0.0095, -0.0159, -0.0214,  ..., -0.0179, -0.0175,  0.0688],
        [ 0.0349,  0.0051,  0.0299,  ..., -0.0311,  0.0081,  0.0011],
        ...,
        [ 0.0349, -0.0081, -0.0070,  ...,  0.0364,  0.0001,  0.0162],
        [ 0.0154,  0.0684,  0.0043,  ..., -0.0035,  0.0441, -0.0884],
        [ 0.0307, -0.0963, -0.0775,  ..., -0.0634, -0.0170,  0.1138]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5586, -6.9688,  1.0957,  ..., -1.4385, -0.4949, -4.0781]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 17:35:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A nomad is a member of a horde
A fish is a member of a school
A county is a member of a state
A listener is a member of a audience
A page is a member of a book
A elephant is a member of a herd
A policeman is a member of a police
A player is a member of a
2024-07-27 17:35:23 root INFO     [order_1_approx] starting weight calculation for A fish is a member of a school
A nomad is a member of a horde
A page is a member of a book
A player is a member of a team
A elephant is a member of a herd
A policeman is a member of a police
A county is a member of a state
A listener is a member of a
2024-07-27 17:35:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 17:38:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1212, -0.0988, -0.2317,  ...,  0.1447,  0.2737, -0.1095],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2217, -6.0547,  4.2422,  ...,  1.9277, -0.7500, -1.3809],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.0201e-02, -7.0068e-02,  8.9264e-04,  ...,  3.3325e-02,
          1.4557e-02,  5.2734e-02],
        [-5.7678e-03, -9.1553e-05,  3.5034e-02,  ..., -2.5043e-03,
         -5.3406e-03, -2.5616e-03],
        [-1.7410e-02, -1.3123e-03,  2.2217e-02,  ..., -1.7654e-02,
         -2.1179e-02,  4.9744e-03],
        ...,
        [ 2.3575e-03,  4.1931e-02,  6.0272e-03,  ...,  3.5065e-02,
          1.9592e-02, -2.1072e-02],
        [-2.9678e-03,  2.8046e-02, -2.7176e-02,  ..., -2.3056e-02,
          3.8147e-03, -1.4153e-02],
        [ 1.2863e-02,  2.3682e-02, -3.3661e-02,  ..., -1.3103e-03,
          2.4490e-02,  5.7129e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6533, -6.0273,  4.5820,  ...,  0.9277, -0.3101, -1.0293]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 17:38:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A fish is a member of a school
A nomad is a member of a horde
A page is a member of a book
A player is a member of a team
A elephant is a member of a herd
A policeman is a member of a police
A county is a member of a state
A listener is a member of a
2024-07-27 17:38:09 root INFO     [order_1_approx] starting weight calculation for A listener is a member of a audience
A page is a member of a book
A county is a member of a state
A nomad is a member of a horde
A player is a member of a team
A fish is a member of a school
A elephant is a member of a herd
A policeman is a member of a
2024-07-27 17:38:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 17:40:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1869,  0.1650, -0.2368,  ..., -0.0234, -0.0972, -0.1660],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3223, -7.0703,  3.9160,  ..., -2.0352,  1.5781, -8.0156],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0254, -0.0061,  0.0224,  ...,  0.0121,  0.0099, -0.0143],
        [ 0.0098,  0.0128,  0.0040,  ..., -0.0117, -0.0143,  0.0018],
        [ 0.0062, -0.0161,  0.0265,  ...,  0.0039,  0.0035,  0.0033],
        ...,
        [ 0.0097, -0.0060,  0.0178,  ...,  0.0230,  0.0107,  0.0048],
        [-0.0280,  0.0214, -0.0129,  ...,  0.0203, -0.0042, -0.0104],
        [ 0.0136, -0.0210, -0.0163,  ..., -0.0406, -0.0068,  0.0293]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7051, -7.1406,  4.0859,  ..., -2.1719,  1.4590, -7.9336]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 17:40:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A listener is a member of a audience
A page is a member of a book
A county is a member of a state
A nomad is a member of a horde
A player is a member of a team
A fish is a member of a school
A elephant is a member of a herd
A policeman is a member of a
2024-07-27 17:40:53 root INFO     total operator prediction time: 1320.5767467021942 seconds
2024-07-27 17:40:53 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun - plural_irreg
2024-07-27 17:40:53 root INFO     building operator noun - plural_irreg
2024-07-27 17:40:53 root INFO     [order_1_approx] starting weight calculation for The plural form of family is families
The plural form of university is universities
The plural form of agency is agencies
The plural form of ability is abilities
The plural form of basis is bases
The plural form of species is species
The plural form of county is counties
The plural form of country is
2024-07-27 17:40:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 17:43:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1302, -0.2898,  0.0661,  ..., -0.1826, -0.1088,  0.2771],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1743, -5.1172,  1.6777,  ..., -1.3984,  1.4277, -3.2305],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0158, -0.0404,  0.0157,  ...,  0.0100,  0.0018, -0.0250],
        [-0.0179,  0.0090,  0.0258,  ...,  0.0054, -0.0049, -0.0249],
        [-0.0403,  0.0355,  0.0158,  ...,  0.0101, -0.0268,  0.0226],
        ...,
        [ 0.0498,  0.0194, -0.0305,  ..., -0.0051,  0.0058, -0.0110],
        [-0.0204, -0.0110, -0.0106,  ...,  0.0038, -0.0022, -0.0123],
        [ 0.0261,  0.0019,  0.0037,  ...,  0.0214,  0.0029,  0.0199]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2937, -5.3047,  1.6465,  ..., -1.4785,  1.6680, -3.0293]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 17:43:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of family is families
The plural form of university is universities
The plural form of agency is agencies
The plural form of ability is abilities
The plural form of basis is bases
The plural form of species is species
The plural form of county is counties
The plural form of country is
2024-07-27 17:43:38 root INFO     [order_1_approx] starting weight calculation for The plural form of species is species
The plural form of university is universities
The plural form of country is countries
The plural form of ability is abilities
The plural form of county is counties
The plural form of family is families
The plural form of basis is bases
The plural form of agency is
2024-07-27 17:43:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 17:46:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1139,  0.3467, -0.1146,  ...,  0.0072, -0.0649, -0.2174],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0648, -0.6172,  2.5078,  ..., -1.2119,  0.2969, -3.2734],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0336,  0.0197, -0.0052,  ...,  0.0008,  0.0035, -0.0140],
        [-0.0212,  0.0208, -0.0057,  ..., -0.0003,  0.0132,  0.0252],
        [-0.0215,  0.0161,  0.0390,  ...,  0.0373, -0.0023,  0.0077],
        ...,
        [ 0.0224,  0.0518, -0.0024,  ...,  0.0305,  0.0071,  0.0173],
        [-0.0185,  0.0145,  0.0012,  ...,  0.0196,  0.0517, -0.0093],
        [ 0.0475, -0.0153,  0.0053,  ..., -0.0094, -0.0301,  0.0365]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2112, -0.6309,  2.1328,  ..., -1.5020, -0.3213, -3.1777]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 17:46:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of species is species
The plural form of university is universities
The plural form of country is countries
The plural form of ability is abilities
The plural form of county is counties
The plural form of family is families
The plural form of basis is bases
The plural form of agency is
2024-07-27 17:46:24 root INFO     [order_1_approx] starting weight calculation for The plural form of family is families
The plural form of basis is bases
The plural form of country is countries
The plural form of county is counties
The plural form of agency is agencies
The plural form of species is species
The plural form of university is universities
The plural form of ability is
2024-07-27 17:46:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 17:49:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1517, -0.1005,  0.1370,  ..., -0.0226, -0.1621,  0.2001],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1641, -1.9922,  1.0146,  ..., -0.5142, -2.5820, -1.7568],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0135, -0.0269,  0.0230,  ...,  0.0429,  0.0120,  0.0396],
        [-0.0072,  0.0831, -0.0021,  ..., -0.0198, -0.0163, -0.0355],
        [ 0.0139, -0.0476,  0.0243,  ...,  0.0218,  0.0025,  0.0541],
        ...,
        [ 0.0096,  0.0407, -0.0174,  ...,  0.0066, -0.0028,  0.0074],
        [ 0.0469, -0.0062, -0.0092,  ...,  0.0120, -0.0010, -0.0316],
        [ 0.0337, -0.0075,  0.0289,  ...,  0.0550, -0.0042,  0.0012]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3320, -1.9229,  0.5537,  ..., -0.6284, -2.8613, -1.8047]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 17:49:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of family is families
The plural form of basis is bases
The plural form of country is countries
The plural form of county is counties
The plural form of agency is agencies
The plural form of species is species
The plural form of university is universities
The plural form of ability is
2024-07-27 17:49:11 root INFO     [order_1_approx] starting weight calculation for The plural form of agency is agencies
The plural form of country is countries
The plural form of species is species
The plural form of basis is bases
The plural form of family is families
The plural form of ability is abilities
The plural form of university is universities
The plural form of county is
2024-07-27 17:49:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 17:51:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0491, -0.0619, -0.1737,  ..., -0.1544, -0.0027,  0.0595],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4802, -4.9453,  2.4746,  ..., -2.4844,  2.7617, -3.3535],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0212, -0.0085,  0.0121,  ..., -0.0012,  0.0049,  0.0106],
        [-0.0049,  0.0380, -0.0363,  ...,  0.0136, -0.0331,  0.0131],
        [-0.0156,  0.0030,  0.0378,  ...,  0.0319, -0.0109,  0.0649],
        ...,
        [ 0.0230,  0.0168, -0.0065,  ..., -0.0005,  0.0359, -0.0039],
        [-0.0028, -0.0088,  0.0125,  ...,  0.0179,  0.0024, -0.0274],
        [-0.0012, -0.0238, -0.0065,  ..., -0.0051,  0.0325,  0.0087]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5552, -4.1172,  2.4414,  ..., -2.0898,  2.6992, -2.9648]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 17:51:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of agency is agencies
The plural form of country is countries
The plural form of species is species
The plural form of basis is bases
The plural form of family is families
The plural form of ability is abilities
The plural form of university is universities
The plural form of county is
2024-07-27 17:51:58 root INFO     [order_1_approx] starting weight calculation for The plural form of agency is agencies
The plural form of family is families
The plural form of species is species
The plural form of country is countries
The plural form of ability is abilities
The plural form of county is counties
The plural form of university is universities
The plural form of basis is
2024-07-27 17:51:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 17:54:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1559, -0.3945, -0.3726,  ...,  0.1229, -0.4636,  0.2251],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1016, -2.3574,  1.6221,  ..., -2.1953, -2.3945, -2.4395],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0478, -0.0109,  0.0194,  ..., -0.0011, -0.0109, -0.0065],
        [ 0.0433,  0.0409,  0.0303,  ...,  0.0462, -0.0287,  0.0047],
        [-0.0021, -0.0044,  0.0316,  ...,  0.0344, -0.0014,  0.0338],
        ...,
        [-0.0149,  0.0215, -0.0156,  ...,  0.0021,  0.0046,  0.0067],
        [-0.0434,  0.0447, -0.0353,  ..., -0.0658,  0.0289, -0.0396],
        [ 0.0395, -0.0311,  0.0189,  ...,  0.0286, -0.0444,  0.0532]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0039, -2.4844,  1.5176,  ..., -1.8594, -1.9932, -1.8818]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 17:54:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of agency is agencies
The plural form of family is families
The plural form of species is species
The plural form of country is countries
The plural form of ability is abilities
The plural form of county is counties
The plural form of university is universities
The plural form of basis is
2024-07-27 17:54:44 root INFO     [order_1_approx] starting weight calculation for The plural form of agency is agencies
The plural form of basis is bases
The plural form of university is universities
The plural form of ability is abilities
The plural form of country is countries
The plural form of family is families
The plural form of county is counties
The plural form of species is
2024-07-27 17:54:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 17:57:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0154, -0.2769, -0.0700,  ..., -0.0536, -0.0093,  0.1639],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8984, -3.2148,  0.1104,  ..., -0.3418, -3.0938, -3.0352],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0357, -0.0293,  0.0098,  ...,  0.0163,  0.0136,  0.0199],
        [ 0.0211,  0.0500,  0.0355,  ..., -0.0123, -0.0074, -0.0061],
        [ 0.0031, -0.0090, -0.0172,  ...,  0.0136, -0.0207,  0.0444],
        ...,
        [-0.0254, -0.0023,  0.0392,  ...,  0.0176,  0.0590, -0.0009],
        [ 0.0102, -0.0089,  0.0029,  ...,  0.0289,  0.0012,  0.0028],
        [ 0.0335, -0.0052, -0.0235,  ...,  0.0136, -0.0158,  0.0341]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9570, -3.1777, -0.1602,  ..., -0.5415, -3.1797, -3.3359]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 17:57:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of agency is agencies
The plural form of basis is bases
The plural form of university is universities
The plural form of ability is abilities
The plural form of country is countries
The plural form of family is families
The plural form of county is counties
The plural form of species is
2024-07-27 17:57:28 root INFO     [order_1_approx] starting weight calculation for The plural form of university is universities
The plural form of basis is bases
The plural form of species is species
The plural form of county is counties
The plural form of country is countries
The plural form of ability is abilities
The plural form of agency is agencies
The plural form of family is
2024-07-27 17:57:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 18:00:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1869, -0.1168, -0.0439,  ...,  0.0132, -0.1033,  0.0015],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1367, -1.4453,  3.3789,  ..., -1.0889, -1.4375, -4.0273],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0408,  0.0004, -0.0047,  ..., -0.0068, -0.0148, -0.0016],
        [-0.0145,  0.0306,  0.0239,  ..., -0.0338, -0.0281, -0.0156],
        [-0.0157, -0.0234, -0.0144,  ...,  0.0302,  0.0104,  0.0310],
        ...,
        [-0.0005,  0.0327,  0.0094,  ..., -0.0140,  0.0064, -0.0134],
        [ 0.0131, -0.0251, -0.0258,  ...,  0.0394,  0.0040, -0.0184],
        [ 0.0526, -0.0298,  0.0317,  ..., -0.0082, -0.0285, -0.0081]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2559, -1.6035,  3.5723,  ..., -1.0684, -0.8110, -4.7500]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 18:00:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of university is universities
The plural form of basis is bases
The plural form of species is species
The plural form of county is counties
The plural form of country is countries
The plural form of ability is abilities
The plural form of agency is agencies
The plural form of family is
2024-07-27 18:00:13 root INFO     [order_1_approx] starting weight calculation for The plural form of county is counties
The plural form of agency is agencies
The plural form of species is species
The plural form of basis is bases
The plural form of country is countries
The plural form of family is families
The plural form of ability is abilities
The plural form of university is
2024-07-27 18:00:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 18:02:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3159, -0.0192, -0.0236,  ...,  0.1810, -0.2362,  0.0687],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0405, -2.6504,  1.5908,  ..., -0.5894,  0.0649, -1.3711],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0244,  0.0100, -0.0316,  ...,  0.0054, -0.0184, -0.0359],
        [ 0.0335,  0.0422, -0.0146,  ...,  0.0015,  0.0118, -0.0135],
        [ 0.0032, -0.0217,  0.0224,  ...,  0.0167, -0.0262,  0.0096],
        ...,
        [-0.0490,  0.0043,  0.0406,  ..., -0.0068,  0.0140,  0.0373],
        [ 0.0158, -0.0207,  0.0071,  ...,  0.0297,  0.0299,  0.0227],
        [-0.0066, -0.0230, -0.0152,  ...,  0.0359, -0.0284, -0.0101]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0968, -2.5215,  1.9648,  ..., -0.9922,  0.1610, -1.3486]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 18:02:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of county is counties
The plural form of agency is agencies
The plural form of species is species
The plural form of basis is bases
The plural form of country is countries
The plural form of family is families
The plural form of ability is abilities
The plural form of university is
2024-07-27 18:02:58 root INFO     total operator prediction time: 1325.6148929595947 seconds
2024-07-27 18:02:58 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on Ving - verb_inf
2024-07-27 18:02:58 root INFO     building operator Ving - verb_inf
2024-07-27 18:02:59 root INFO     [order_1_approx] starting weight calculation for reducing is the active form of reduce
remembering is the active form of remember
following is the active form of follow
encouraging is the active form of encourage
becoming is the active form of become
applying is the active form of apply
referring is the active form of refer
protecting is the active form of
2024-07-27 18:02:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 18:05:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2140, -0.0922, -0.1530,  ...,  0.0113, -0.0394, -0.0305],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5117, -5.1719, -1.1357,  ...,  2.1855, -1.2471, -2.4121],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0259, -0.0059, -0.0037,  ..., -0.0184, -0.0243,  0.0134],
        [-0.0102,  0.0197,  0.0077,  ...,  0.0062,  0.0132,  0.0130],
        [ 0.0155,  0.0099, -0.0106,  ..., -0.0068, -0.0051, -0.0069],
        ...,
        [ 0.0052,  0.0147,  0.0016,  ...,  0.0173,  0.0012, -0.0005],
        [-0.0054, -0.0062,  0.0077,  ...,  0.0079,  0.0252,  0.0051],
        [ 0.0002,  0.0090, -0.0050,  ...,  0.0105, -0.0082,  0.0141]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5854, -5.1836, -0.9956,  ...,  2.0977, -1.3594, -2.2676]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 18:05:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for reducing is the active form of reduce
remembering is the active form of remember
following is the active form of follow
encouraging is the active form of encourage
becoming is the active form of become
applying is the active form of apply
referring is the active form of refer
protecting is the active form of
2024-07-27 18:05:43 root INFO     [order_1_approx] starting weight calculation for becoming is the active form of become
remembering is the active form of remember
following is the active form of follow
reducing is the active form of reduce
referring is the active form of refer
applying is the active form of apply
protecting is the active form of protect
encouraging is the active form of
2024-07-27 18:05:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 18:08:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2795,  0.3420, -0.1261,  ...,  0.1826, -0.1923, -0.0290],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9824, -3.1211, -1.7998,  ...,  4.1836, -2.2090, -3.6270],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0152, -0.0104,  0.0164,  ..., -0.0006, -0.0261, -0.0092],
        [ 0.0087,  0.0208, -0.0064,  ...,  0.0084,  0.0080,  0.0186],
        [ 0.0032, -0.0013, -0.0169,  ..., -0.0206, -0.0049, -0.0060],
        ...,
        [-0.0057,  0.0249, -0.0003,  ...,  0.0339,  0.0178, -0.0025],
        [ 0.0191,  0.0060, -0.0281,  ..., -0.0029,  0.0154,  0.0053],
        [ 0.0154, -0.0093, -0.0081,  ...,  0.0104, -0.0041,  0.0218]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2559, -3.3691, -1.8916,  ...,  4.0000, -2.0742, -3.4844]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 18:08:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for becoming is the active form of become
remembering is the active form of remember
following is the active form of follow
reducing is the active form of reduce
referring is the active form of refer
applying is the active form of apply
protecting is the active form of protect
encouraging is the active form of
2024-07-27 18:08:29 root INFO     [order_1_approx] starting weight calculation for protecting is the active form of protect
becoming is the active form of become
applying is the active form of apply
referring is the active form of refer
following is the active form of follow
encouraging is the active form of encourage
reducing is the active form of reduce
remembering is the active form of
2024-07-27 18:08:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 18:11:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2891,  0.1118,  0.0071,  ..., -0.1824, -0.1368,  0.0335],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0430, -3.5859,  0.0278,  ...,  0.9619, -2.4004, -3.3203],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0225, -0.0105,  0.0020,  ..., -0.0049, -0.0056,  0.0108],
        [ 0.0044,  0.0251,  0.0012,  ..., -0.0111,  0.0012, -0.0007],
        [ 0.0026, -0.0081,  0.0018,  ..., -0.0058, -0.0059, -0.0145],
        ...,
        [-0.0017,  0.0074,  0.0024,  ...,  0.0088, -0.0154,  0.0093],
        [ 0.0118, -0.0081,  0.0105,  ...,  0.0039,  0.0149, -0.0015],
        [-0.0010,  0.0016, -0.0064,  ..., -0.0009, -0.0036,  0.0147]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-6.9922e-01, -3.5742e+00, -3.0518e-05,  ...,  1.0225e+00,
         -2.6797e+00, -3.3750e+00]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SubBackward0>) 

                    
2024-07-27 18:11:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for protecting is the active form of protect
becoming is the active form of become
applying is the active form of apply
referring is the active form of refer
following is the active form of follow
encouraging is the active form of encourage
reducing is the active form of reduce
remembering is the active form of
2024-07-27 18:11:13 root INFO     [order_1_approx] starting weight calculation for reducing is the active form of reduce
referring is the active form of refer
following is the active form of follow
remembering is the active form of remember
becoming is the active form of become
protecting is the active form of protect
encouraging is the active form of encourage
applying is the active form of
2024-07-27 18:11:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 18:13:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1036,  0.0724,  0.3225,  ...,  0.0570, -0.1362,  0.0670],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3926, -3.2539, -0.9961,  ...,  3.1875, -2.6680, -2.6953],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0528, -0.0132,  0.0168,  ...,  0.0009, -0.0199,  0.0003],
        [-0.0051,  0.0248,  0.0325,  ...,  0.0020, -0.0220,  0.0056],
        [-0.0018,  0.0211,  0.0088,  ...,  0.0068, -0.0124,  0.0090],
        ...,
        [ 0.0127,  0.0163, -0.0006,  ...,  0.0509, -0.0133,  0.0028],
        [-0.0110, -0.0028,  0.0043,  ...,  0.0002,  0.0422,  0.0124],
        [-0.0043,  0.0004,  0.0017,  ...,  0.0059, -0.0068,  0.0411]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0286, -3.9648, -0.7412,  ...,  3.0332, -2.7031, -2.8770]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 18:13:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for reducing is the active form of reduce
referring is the active form of refer
following is the active form of follow
remembering is the active form of remember
becoming is the active form of become
protecting is the active form of protect
encouraging is the active form of encourage
applying is the active form of
2024-07-27 18:13:59 root INFO     [order_1_approx] starting weight calculation for becoming is the active form of become
following is the active form of follow
encouraging is the active form of encourage
referring is the active form of refer
remembering is the active form of remember
protecting is the active form of protect
applying is the active form of apply
reducing is the active form of
2024-07-27 18:13:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 18:16:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0911, -0.0013, -0.0354,  ..., -0.0201,  0.0242, -0.1748],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8770, -3.1992, -1.4424,  ..., -0.7715, -0.7314, -4.3320],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0295,  0.0038,  0.0007,  ...,  0.0006,  0.0157,  0.0056],
        [-0.0008,  0.0245,  0.0027,  ...,  0.0152,  0.0020,  0.0118],
        [ 0.0112,  0.0071, -0.0027,  ..., -0.0202, -0.0007, -0.0041],
        ...,
        [ 0.0137,  0.0213, -0.0044,  ...,  0.0111, -0.0203,  0.0284],
        [ 0.0047, -0.0035,  0.0140,  ...,  0.0028,  0.0297,  0.0077],
        [-0.0088,  0.0095,  0.0044,  ..., -0.0141,  0.0032,  0.0297]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7075, -3.4395, -1.4980,  ..., -1.0508, -0.9414, -4.0664]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 18:16:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for becoming is the active form of become
following is the active form of follow
encouraging is the active form of encourage
referring is the active form of refer
remembering is the active form of remember
protecting is the active form of protect
applying is the active form of apply
reducing is the active form of
2024-07-27 18:16:46 root INFO     [order_1_approx] starting weight calculation for protecting is the active form of protect
following is the active form of follow
remembering is the active form of remember
reducing is the active form of reduce
encouraging is the active form of encourage
referring is the active form of refer
applying is the active form of apply
becoming is the active form of
2024-07-27 18:16:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 18:19:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1292,  0.3477,  0.1600,  ..., -0.0878, -0.0508,  0.0332],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2695, -2.9258, -0.4531,  ...,  3.3750,  1.0410, -3.1172],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.4526e-02, -1.0986e-02, -2.1648e-04,  ...,  1.5572e-02,
         -5.3520e-03,  4.1962e-05],
        [-2.0065e-03,  1.1749e-02, -1.4038e-02,  ...,  2.1042e-02,
         -1.0933e-02, -4.2343e-04],
        [ 7.5874e-03,  6.4278e-03,  2.4490e-03,  ..., -1.3763e-02,
          9.6512e-04, -6.6299e-03],
        ...,
        [ 1.6815e-02,  1.0231e-02, -8.5144e-03,  ...,  4.4189e-02,
          3.4714e-04,  1.2474e-02],
        [-1.6144e-02, -3.1555e-02,  1.8250e-02,  ..., -8.0566e-03,
          2.4765e-02,  1.7670e-02],
        [ 5.9967e-03, -1.7643e-03, -1.4626e-02,  ...,  1.5228e-02,
         -1.7014e-02,  1.5945e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9048, -3.2090, -0.4072,  ...,  3.3535,  1.3848, -3.4414]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 18:19:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for protecting is the active form of protect
following is the active form of follow
remembering is the active form of remember
reducing is the active form of reduce
encouraging is the active form of encourage
referring is the active form of refer
applying is the active form of apply
becoming is the active form of
2024-07-27 18:19:32 root INFO     [order_1_approx] starting weight calculation for reducing is the active form of reduce
becoming is the active form of become
following is the active form of follow
remembering is the active form of remember
protecting is the active form of protect
applying is the active form of apply
encouraging is the active form of encourage
referring is the active form of
2024-07-27 18:19:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 18:22:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0018, -0.1713,  0.0508,  ...,  0.1140, -0.3313,  0.0731],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8867, -5.1953,  0.2301,  ...,  4.0117, -0.7817, -3.4141],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0170,  0.0072, -0.0088,  ..., -0.0035,  0.0050,  0.0103],
        [-0.0086,  0.0459, -0.0012,  ..., -0.0064,  0.0007,  0.0146],
        [ 0.0050, -0.0126,  0.0017,  ..., -0.0117,  0.0023, -0.0095],
        ...,
        [ 0.0090,  0.0112, -0.0048,  ...,  0.0194,  0.0050,  0.0007],
        [ 0.0065, -0.0110, -0.0050,  ...,  0.0167,  0.0186, -0.0026],
        [ 0.0070,  0.0115, -0.0116,  ...,  0.0072, -0.0289,  0.0305]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8711, -5.1992,  0.2174,  ...,  3.9238, -0.7090, -3.7305]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 18:22:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for reducing is the active form of reduce
becoming is the active form of become
following is the active form of follow
remembering is the active form of remember
protecting is the active form of protect
applying is the active form of apply
encouraging is the active form of encourage
referring is the active form of
2024-07-27 18:22:18 root INFO     [order_1_approx] starting weight calculation for reducing is the active form of reduce
protecting is the active form of protect
encouraging is the active form of encourage
remembering is the active form of remember
applying is the active form of apply
becoming is the active form of become
referring is the active form of refer
following is the active form of
2024-07-27 18:22:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 18:25:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1343, -0.1545,  0.0070,  ..., -0.0734, -0.1476,  0.0363],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2412, -3.8574,  1.9688,  ...,  1.9453, -1.9141, -2.6309],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0256, -0.0106,  0.0089,  ..., -0.0028, -0.0040, -0.0074],
        [-0.0028,  0.0420,  0.0027,  ...,  0.0085, -0.0083, -0.0071],
        [ 0.0002,  0.0022, -0.0044,  ..., -0.0185, -0.0158, -0.0264],
        ...,
        [ 0.0094, -0.0005, -0.0030,  ...,  0.0330, -0.0188,  0.0168],
        [-0.0023, -0.0004, -0.0043,  ...,  0.0193,  0.0370,  0.0098],
        [ 0.0082, -0.0046, -0.0033,  ...,  0.0221, -0.0034,  0.0213]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0615, -4.0547,  1.7852,  ...,  2.0195, -1.6357, -2.8223]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 18:25:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for reducing is the active form of reduce
protecting is the active form of protect
encouraging is the active form of encourage
remembering is the active form of remember
applying is the active form of apply
becoming is the active form of become
referring is the active form of refer
following is the active form of
2024-07-27 18:25:03 root INFO     total operator prediction time: 1324.7292864322662 seconds
2024-07-27 18:25:03 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_Ving - Ved
2024-07-27 18:25:03 root INFO     building operator verb_Ving - Ved
2024-07-27 18:25:03 root INFO     [order_1_approx] starting weight calculation for After something is teaching, it has taught
After something is spending, it has spent
After something is performing, it has performed
After something is becoming, it has became
After something is introducing, it has introduced
After something is telling, it has told
After something is developing, it has developed
After something is appearing, it has
2024-07-27 18:25:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 18:27:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0979,  0.1064,  0.1396,  ...,  0.2056, -0.0997, -0.1472],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9512, -0.3599,  0.4443,  ...,  1.3555, -3.0312,  1.1133],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-8.3771e-03, -9.5215e-03, -2.6703e-02,  ...,  4.3716e-03,
          1.9608e-03,  8.5144e-03],
        [-1.4679e-02,  7.1899e-02, -2.1591e-03,  ...,  2.4963e-02,
         -2.3178e-02, -3.9978e-03],
        [-1.5808e-02, -1.1505e-02,  1.0727e-02,  ...,  1.1024e-03,
         -9.1553e-05, -1.6083e-02],
        ...,
        [-2.6283e-03,  3.8025e-02, -1.8188e-02,  ...,  2.5772e-02,
         -1.1765e-02,  6.6757e-04],
        [ 8.8272e-03, -1.0239e-02,  3.8635e-02,  ...,  7.8430e-03,
          3.3630e-02,  1.9226e-03],
        [-2.1194e-02, -1.3885e-03,  1.2688e-02,  ...,  1.2161e-02,
         -9.9335e-03,  1.2550e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1318, -0.8438, -0.0549,  ...,  1.4727, -3.1270,  1.0996]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 18:27:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is teaching, it has taught
After something is spending, it has spent
After something is performing, it has performed
After something is becoming, it has became
After something is introducing, it has introduced
After something is telling, it has told
After something is developing, it has developed
After something is appearing, it has
2024-07-27 18:27:50 root INFO     [order_1_approx] starting weight calculation for After something is performing, it has performed
After something is telling, it has told
After something is spending, it has spent
After something is developing, it has developed
After something is introducing, it has introduced
After something is appearing, it has appeared
After something is teaching, it has taught
After something is becoming, it has
2024-07-27 18:27:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 18:30:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1210,  0.1627,  0.3420,  ...,  0.0284, -0.2469, -0.0427],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9062,  0.1260,  2.5234,  ..., -0.5020,  0.9062, -0.8506],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0031,  0.0410,  0.0185,  ...,  0.0221,  0.0235,  0.0098],
        [-0.0235,  0.0474,  0.0003,  ...,  0.0020, -0.0010,  0.0137],
        [-0.0077, -0.0029,  0.0070,  ..., -0.0213, -0.0118, -0.0102],
        ...,
        [ 0.0028,  0.0202, -0.0386,  ...,  0.0410,  0.0054,  0.0142],
        [ 0.0235,  0.0042,  0.0094,  ..., -0.0348,  0.0180, -0.0163],
        [-0.0061, -0.0022,  0.0333,  ...,  0.0103, -0.0149, -0.0021]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3633, -0.4185,  2.7227,  ..., -0.2212,  0.9092, -1.5566]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 18:30:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is performing, it has performed
After something is telling, it has told
After something is spending, it has spent
After something is developing, it has developed
After something is introducing, it has introduced
After something is appearing, it has appeared
After something is teaching, it has taught
After something is becoming, it has
2024-07-27 18:30:36 root INFO     [order_1_approx] starting weight calculation for After something is appearing, it has appeared
After something is teaching, it has taught
After something is performing, it has performed
After something is developing, it has developed
After something is telling, it has told
After something is becoming, it has became
After something is spending, it has spent
After something is introducing, it has
2024-07-27 18:30:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 18:33:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1174,  0.0005,  0.1964,  ...,  0.0261, -0.1561,  0.0635],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1738, -1.4102,  2.0078,  ...,  0.5283, -4.2227, -1.9766],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0158,  0.0010, -0.0010,  ...,  0.0054,  0.0093, -0.0050],
        [-0.0398,  0.0172, -0.0075,  ...,  0.0120,  0.0191, -0.0078],
        [ 0.0230,  0.0101, -0.0179,  ..., -0.0174,  0.0085, -0.0349],
        ...,
        [ 0.0257,  0.0020, -0.0112,  ...,  0.0402, -0.0066,  0.0137],
        [ 0.0215,  0.0045,  0.0019,  ..., -0.0292,  0.0093, -0.0038],
        [-0.0051,  0.0208,  0.0189,  ..., -0.0091, -0.0226, -0.0026]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4121, -1.5400,  2.2266,  ...,  0.5181, -4.3516, -2.1289]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 18:33:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is appearing, it has appeared
After something is teaching, it has taught
After something is performing, it has performed
After something is developing, it has developed
After something is telling, it has told
After something is becoming, it has became
After something is spending, it has spent
After something is introducing, it has
2024-07-27 18:33:21 root INFO     [order_1_approx] starting weight calculation for After something is spending, it has spent
After something is telling, it has told
After something is introducing, it has introduced
After something is developing, it has developed
After something is becoming, it has became
After something is performing, it has performed
After something is appearing, it has appeared
After something is teaching, it has
2024-07-27 18:33:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 18:36:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2722,  0.2625,  0.0880,  ...,  0.0906, -0.2822,  0.0556],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.4062, -0.0890,  3.3809,  ...,  0.3940, -3.7246, -4.9453],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0138, -0.0057, -0.0079,  ...,  0.0074,  0.0042, -0.0049],
        [-0.0291,  0.0221, -0.0140,  ..., -0.0132, -0.0242, -0.0127],
        [-0.0099,  0.0086,  0.0011,  ..., -0.0113,  0.0347, -0.0199],
        ...,
        [ 0.0192,  0.0171, -0.0277,  ...,  0.0225,  0.0312, -0.0061],
        [ 0.0149,  0.0116,  0.0105,  ..., -0.0016,  0.0083, -0.0059],
        [ 0.0099, -0.0006,  0.0351,  ...,  0.0027, -0.0066, -0.0147]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.4844,  0.2549,  3.8984,  ...,  0.4414, -3.5234, -5.3828]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 18:36:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is spending, it has spent
After something is telling, it has told
After something is introducing, it has introduced
After something is developing, it has developed
After something is becoming, it has became
After something is performing, it has performed
After something is appearing, it has appeared
After something is teaching, it has
2024-07-27 18:36:02 root INFO     [order_1_approx] starting weight calculation for After something is teaching, it has taught
After something is telling, it has told
After something is becoming, it has became
After something is spending, it has spent
After something is appearing, it has appeared
After something is performing, it has performed
After something is introducing, it has introduced
After something is developing, it has
2024-07-27 18:36:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 18:38:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2107, -0.0573,  0.2104,  ..., -0.0261, -0.1576, -0.0119],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1367, -1.7441,  2.3535,  ..., -2.3242, -2.4922, -1.8477],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0098,  0.0106, -0.0022,  ...,  0.0008,  0.0041,  0.0046],
        [-0.0510,  0.0496,  0.0130,  ...,  0.0236,  0.0184, -0.0190],
        [-0.0040, -0.0040,  0.0109,  ..., -0.0363,  0.0093, -0.0115],
        ...,
        [ 0.0289,  0.0274,  0.0651,  ...,  0.0278,  0.0272,  0.0030],
        [-0.0075, -0.0088, -0.0127,  ..., -0.0153, -0.0089,  0.0244],
        [-0.0138, -0.0182, -0.0066,  ...,  0.0005, -0.0436, -0.0032]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7891, -1.1240,  1.7490,  ..., -2.6367, -2.4082, -1.8301]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 18:38:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is teaching, it has taught
After something is telling, it has told
After something is becoming, it has became
After something is spending, it has spent
After something is appearing, it has appeared
After something is performing, it has performed
After something is introducing, it has introduced
After something is developing, it has
2024-07-27 18:38:47 root INFO     [order_1_approx] starting weight calculation for After something is introducing, it has introduced
After something is teaching, it has taught
After something is performing, it has performed
After something is appearing, it has appeared
After something is developing, it has developed
After something is spending, it has spent
After something is becoming, it has became
After something is telling, it has
2024-07-27 18:38:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 18:41:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3269, -0.0282,  0.1462,  ...,  0.1281, -0.1802, -0.1002],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.5469, -0.6978,  3.0137,  ...,  1.5742, -4.9570, -2.2812],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0160, -0.0068,  0.0091,  ...,  0.0133,  0.0137,  0.0162],
        [-0.0421,  0.0497,  0.0216,  ..., -0.0296, -0.0240, -0.0061],
        [-0.0151, -0.0311,  0.0329,  ...,  0.0108,  0.0224,  0.0186],
        ...,
        [ 0.0353,  0.0164, -0.0186,  ...,  0.0298,  0.0035, -0.0002],
        [-0.0407,  0.0039,  0.0057,  ..., -0.0127,  0.0159,  0.0050],
        [-0.0161,  0.0255,  0.0142,  ...,  0.0162,  0.0037,  0.0115]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.6211, -1.1475,  3.3320,  ...,  1.7676, -4.8867, -2.4434]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 18:41:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is introducing, it has introduced
After something is teaching, it has taught
After something is performing, it has performed
After something is appearing, it has appeared
After something is developing, it has developed
After something is spending, it has spent
After something is becoming, it has became
After something is telling, it has
2024-07-27 18:41:33 root INFO     [order_1_approx] starting weight calculation for After something is introducing, it has introduced
After something is appearing, it has appeared
After something is becoming, it has became
After something is developing, it has developed
After something is spending, it has spent
After something is teaching, it has taught
After something is telling, it has told
After something is performing, it has
2024-07-27 18:41:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 18:44:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0437,  0.3381,  0.0112,  ..., -0.0770, -0.2781, -0.0822],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3906, -1.9736,  3.8691,  ..., -1.6162, -3.2871, -1.5312],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0311,  0.0245,  0.0304,  ...,  0.0281,  0.0405, -0.0011],
        [-0.0102,  0.0985,  0.0654,  ...,  0.0862,  0.0934, -0.0772],
        [-0.0294, -0.0202, -0.0233,  ..., -0.0144, -0.0408,  0.0526],
        ...,
        [-0.0102, -0.0148, -0.0201,  ...,  0.0214,  0.0188, -0.0134],
        [-0.0171, -0.0308,  0.0068,  ..., -0.0728, -0.0372,  0.0466],
        [-0.0006, -0.0173, -0.0388,  ..., -0.0212, -0.0520, -0.0043]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7754, -0.5029,  3.3691,  ..., -2.0859, -3.7383, -2.4453]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 18:44:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is introducing, it has introduced
After something is appearing, it has appeared
After something is becoming, it has became
After something is developing, it has developed
After something is spending, it has spent
After something is teaching, it has taught
After something is telling, it has told
After something is performing, it has
2024-07-27 18:44:19 root INFO     [order_1_approx] starting weight calculation for After something is introducing, it has introduced
After something is performing, it has performed
After something is developing, it has developed
After something is teaching, it has taught
After something is appearing, it has appeared
After something is becoming, it has became
After something is telling, it has told
After something is spending, it has
2024-07-27 18:44:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 18:46:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0625,  0.2810,  0.0995,  ...,  0.1213, -0.2239, -0.1852],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1680, -1.6641, -3.0859,  ..., -2.0293, -2.1465, -1.2051],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0199,  0.0089, -0.0152,  ..., -0.0076, -0.0080, -0.0152],
        [-0.0493,  0.0164,  0.0044,  ...,  0.0128,  0.0105,  0.0132],
        [-0.0029, -0.0370, -0.0070,  ..., -0.0103, -0.0041, -0.0127],
        ...,
        [ 0.0229, -0.0059,  0.0134,  ...,  0.0306,  0.0104,  0.0011],
        [ 0.0020,  0.0003, -0.0097,  ..., -0.0127,  0.0053,  0.0077],
        [-0.0221,  0.0031,  0.0143,  ..., -0.0109, -0.0161,  0.0311]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.4531, -2.1367, -2.5078,  ..., -1.7939, -2.8516, -1.5703]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 18:46:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is introducing, it has introduced
After something is performing, it has performed
After something is developing, it has developed
After something is teaching, it has taught
After something is appearing, it has appeared
After something is becoming, it has became
After something is telling, it has told
After something is spending, it has
2024-07-27 18:46:56 root INFO     total operator prediction time: 1312.7576241493225 seconds
2024-07-27 18:46:56 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_inf - Ved
2024-07-27 18:46:56 root INFO     building operator verb_inf - Ved
2024-07-27 18:46:56 root INFO     [order_1_approx] starting weight calculation for If the present form is replace, the past form is replaced
If the present form is lose, the past form is lost
If the present form is continue, the past form is continued
If the present form is establish, the past form is established
If the present form is describe, the past form is described
If the present form is relate, the past form is related
If the present form is consider, the past form is considered
If the present form is locate, the past form is
2024-07-27 18:46:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 18:49:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1179,  0.3201, -0.4573,  ...,  0.1123, -0.1772,  0.0951],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.5869, -0.7510, -1.3740,  ..., -2.2148, -1.1445, -1.8809],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0461, -0.0019, -0.0183,  ..., -0.0224,  0.0039,  0.0067],
        [ 0.0132,  0.0462,  0.0002,  ...,  0.0109, -0.0185,  0.0038],
        [ 0.0266, -0.0161,  0.0052,  ..., -0.0119, -0.0199,  0.0079],
        ...,
        [-0.0046, -0.0015,  0.0060,  ...,  0.0352,  0.0152,  0.0090],
        [ 0.0328, -0.0673, -0.0231,  ..., -0.0037, -0.0007, -0.0237],
        [ 0.0133,  0.0125, -0.0020,  ..., -0.0140, -0.0287,  0.0233]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.6699, -1.0146, -1.2314,  ..., -2.2324, -1.1973, -2.3516]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 18:49:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is replace, the past form is replaced
If the present form is lose, the past form is lost
If the present form is continue, the past form is continued
If the present form is establish, the past form is established
If the present form is describe, the past form is described
If the present form is relate, the past form is related
If the present form is consider, the past form is considered
If the present form is locate, the past form is
2024-07-27 18:49:40 root INFO     [order_1_approx] starting weight calculation for If the present form is continue, the past form is continued
If the present form is establish, the past form is established
If the present form is lose, the past form is lost
If the present form is describe, the past form is described
If the present form is locate, the past form is located
If the present form is consider, the past form is considered
If the present form is relate, the past form is related
If the present form is replace, the past form is
2024-07-27 18:49:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 18:52:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0236,  0.1003, -0.1550,  ..., -0.0150, -0.2109,  0.1459],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.9180, -0.0693, -0.1650,  ..., -2.2246,  0.5283,  0.4648],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0247,  0.0078,  0.0057,  ...,  0.0007,  0.0234,  0.0330],
        [ 0.0060,  0.0472,  0.0014,  ...,  0.0002, -0.0478, -0.0125],
        [ 0.0273, -0.0131, -0.0164,  ..., -0.0331, -0.0192, -0.0077],
        ...,
        [-0.0058, -0.0159, -0.0081,  ...,  0.0254,  0.0225,  0.0304],
        [ 0.0195, -0.0278,  0.0015,  ..., -0.0059,  0.0437, -0.0168],
        [ 0.0295, -0.0034, -0.0073,  ..., -0.0105, -0.0464, -0.0152]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.3086, -0.2969, -0.0244,  ..., -2.1914,  0.0586,  0.4385]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 18:52:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is continue, the past form is continued
If the present form is establish, the past form is established
If the present form is lose, the past form is lost
If the present form is describe, the past form is described
If the present form is locate, the past form is located
If the present form is consider, the past form is considered
If the present form is relate, the past form is related
If the present form is replace, the past form is
2024-07-27 18:52:22 root INFO     [order_1_approx] starting weight calculation for If the present form is continue, the past form is continued
If the present form is relate, the past form is related
If the present form is establish, the past form is established
If the present form is locate, the past form is located
If the present form is consider, the past form is considered
If the present form is describe, the past form is described
If the present form is replace, the past form is replaced
If the present form is lose, the past form is
2024-07-27 18:52:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 18:55:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0214,  0.2566,  0.2057,  ..., -0.0641, -0.2610,  0.1919],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6631, -0.8330,  0.0703,  ..., -1.0029, -0.3828, -1.2285],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0392,  0.0054,  0.0435,  ...,  0.0047, -0.0413, -0.0197],
        [-0.0125,  0.0387,  0.0211,  ..., -0.0146, -0.0162, -0.0189],
        [ 0.0065, -0.0067,  0.0220,  ..., -0.0331, -0.0029, -0.0153],
        ...,
        [ 0.0266, -0.0273, -0.0011,  ...,  0.0283,  0.0294,  0.0233],
        [ 0.0290, -0.0048,  0.0089,  ..., -0.0260,  0.0511, -0.0244],
        [ 0.0013,  0.0321,  0.0138,  ..., -0.0301,  0.0207, -0.0114]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5825, -0.8506, -0.1692,  ..., -0.7646, -0.4277, -0.8628]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 18:55:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is continue, the past form is continued
If the present form is relate, the past form is related
If the present form is establish, the past form is established
If the present form is locate, the past form is located
If the present form is consider, the past form is considered
If the present form is describe, the past form is described
If the present form is replace, the past form is replaced
If the present form is lose, the past form is
2024-07-27 18:55:12 root INFO     [order_1_approx] starting weight calculation for If the present form is establish, the past form is established
If the present form is replace, the past form is replaced
If the present form is describe, the past form is described
If the present form is lose, the past form is lost
If the present form is locate, the past form is located
If the present form is continue, the past form is continued
If the present form is relate, the past form is related
If the present form is consider, the past form is
2024-07-27 18:55:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 18:57:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1070,  0.1486,  0.1702,  ...,  0.0955, -0.2988,  0.2068],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6367,  0.0740,  2.1836,  ..., -2.6172, -0.2056, -0.1426],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0077, -0.0089,  0.0126,  ..., -0.0146,  0.0098,  0.0262],
        [-0.0019,  0.0115,  0.0165,  ...,  0.0079, -0.0474, -0.0076],
        [-0.0162, -0.0017,  0.0372,  ..., -0.0403, -0.0030, -0.0107],
        ...,
        [ 0.0098, -0.0036,  0.0121,  ...,  0.0320,  0.0193, -0.0159],
        [ 0.0326,  0.0302, -0.0118,  ...,  0.0196,  0.0206, -0.0293],
        [ 0.0195,  0.0052,  0.0226,  ...,  0.0225, -0.0130, -0.0074]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9922, -0.3684,  1.9902,  ..., -2.6504, -0.0073, -0.3623]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 18:57:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is establish, the past form is established
If the present form is replace, the past form is replaced
If the present form is describe, the past form is described
If the present form is lose, the past form is lost
If the present form is locate, the past form is located
If the present form is continue, the past form is continued
If the present form is relate, the past form is related
If the present form is consider, the past form is
2024-07-27 18:57:57 root INFO     [order_1_approx] starting weight calculation for If the present form is establish, the past form is established
If the present form is replace, the past form is replaced
If the present form is relate, the past form is related
If the present form is locate, the past form is located
If the present form is consider, the past form is considered
If the present form is lose, the past form is lost
If the present form is continue, the past form is continued
If the present form is describe, the past form is
2024-07-27 18:57:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 19:00:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0124,  0.1176,  0.1093,  ..., -0.0525, -0.2546,  0.0942],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1104,  0.7612,  4.5391,  ..., -0.9507, -0.5107, -2.5293],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0356, -0.0180, -0.0101,  ..., -0.0214, -0.0160,  0.0015],
        [-0.0571,  0.0212, -0.0245,  ..., -0.0194, -0.0312, -0.0180],
        [ 0.0109,  0.0197, -0.0103,  ..., -0.0239, -0.0063, -0.0010],
        ...,
        [ 0.0016,  0.0120,  0.0156,  ...,  0.0484,  0.0242, -0.0150],
        [ 0.0415,  0.0071, -0.0161,  ..., -0.0195,  0.0110, -0.0024],
        [ 0.0232, -0.0024,  0.0089,  ..., -0.0090, -0.0467,  0.0037]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0601,  1.2773,  4.2891,  ..., -1.0723, -0.6084, -2.2754]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 19:00:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is establish, the past form is established
If the present form is replace, the past form is replaced
If the present form is relate, the past form is related
If the present form is locate, the past form is located
If the present form is consider, the past form is considered
If the present form is lose, the past form is lost
If the present form is continue, the past form is continued
If the present form is describe, the past form is
2024-07-27 19:00:44 root INFO     [order_1_approx] starting weight calculation for If the present form is establish, the past form is established
If the present form is relate, the past form is related
If the present form is locate, the past form is located
If the present form is replace, the past form is replaced
If the present form is describe, the past form is described
If the present form is consider, the past form is considered
If the present form is lose, the past form is lost
If the present form is continue, the past form is
2024-07-27 19:00:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 19:03:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0696, -0.1355,  0.1743,  ..., -0.2671, -0.3315,  0.3164],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9463, -0.8521,  2.7910,  ..., -0.9897,  1.2969, -0.8623],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0113, -0.0010, -0.0043,  ..., -0.0105,  0.0231, -0.0039],
        [-0.0628,  0.0361, -0.0290,  ..., -0.0189, -0.0289, -0.0015],
        [ 0.0135,  0.0204, -0.0018,  ..., -0.0258, -0.0122, -0.0061],
        ...,
        [-0.0123,  0.0117,  0.0122,  ...,  0.0494,  0.0078, -0.0120],
        [ 0.0360,  0.0100,  0.0187,  ...,  0.0189,  0.0341, -0.0436],
        [-0.0037, -0.0184,  0.0208,  ..., -0.0095, -0.0314,  0.0045]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0820, -1.0059,  2.4336,  ..., -0.4092,  1.1084, -0.6250]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 19:03:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is establish, the past form is established
If the present form is relate, the past form is related
If the present form is locate, the past form is located
If the present form is replace, the past form is replaced
If the present form is describe, the past form is described
If the present form is consider, the past form is considered
If the present form is lose, the past form is lost
If the present form is continue, the past form is
2024-07-27 19:03:28 root INFO     [order_1_approx] starting weight calculation for If the present form is replace, the past form is replaced
If the present form is lose, the past form is lost
If the present form is relate, the past form is related
If the present form is locate, the past form is located
If the present form is consider, the past form is considered
If the present form is describe, the past form is described
If the present form is continue, the past form is continued
If the present form is establish, the past form is
2024-07-27 19:03:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 19:06:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0881,  0.1108, -0.0714,  ...,  0.0541, -0.3628,  0.2810],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3916,  0.3149,  0.3823,  ..., -0.2048, -0.6924, -1.9033],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0004, -0.0031, -0.0088,  ...,  0.0017, -0.0127,  0.0109],
        [-0.0145,  0.0303, -0.0033,  ...,  0.0028, -0.0240, -0.0230],
        [ 0.0176,  0.0067,  0.0098,  ..., -0.0135, -0.0128, -0.0070],
        ...,
        [ 0.0189,  0.0107, -0.0154,  ...,  0.0293,  0.0046,  0.0309],
        [-0.0079, -0.0281,  0.0017,  ...,  0.0053,  0.0213, -0.0268],
        [ 0.0107,  0.0056,  0.0057,  ...,  0.0007, -0.0284, -0.0071]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2120, -0.1738,  0.1399,  ..., -0.4600, -0.4241, -1.6211]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 19:06:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is replace, the past form is replaced
If the present form is lose, the past form is lost
If the present form is relate, the past form is related
If the present form is locate, the past form is located
If the present form is consider, the past form is considered
If the present form is describe, the past form is described
If the present form is continue, the past form is continued
If the present form is establish, the past form is
2024-07-27 19:06:09 root INFO     [order_1_approx] starting weight calculation for If the present form is locate, the past form is located
If the present form is replace, the past form is replaced
If the present form is lose, the past form is lost
If the present form is continue, the past form is continued
If the present form is describe, the past form is described
If the present form is establish, the past form is established
If the present form is consider, the past form is considered
If the present form is relate, the past form is
2024-07-27 19:06:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 19:08:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1887, -0.0225,  0.0067,  ..., -0.0383, -0.4146,  0.1724],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.3047,  0.3835,  1.5264,  ...,  0.0991, -0.9653, -1.4551],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0539, -0.0017, -0.0187,  ..., -0.0037, -0.0099,  0.0018],
        [-0.0273,  0.0367,  0.0039,  ...,  0.0162, -0.0272, -0.0157],
        [-0.0024,  0.0034,  0.0157,  ..., -0.0178, -0.0274, -0.0068],
        ...,
        [ 0.0223,  0.0168,  0.0071,  ...,  0.0507,  0.0050,  0.0103],
        [ 0.0131, -0.0202, -0.0182,  ..., -0.0098,  0.0333, -0.0206],
        [-0.0061, -0.0377, -0.0146,  ...,  0.0095, -0.0070,  0.0303]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.8574,  0.2700,  1.5273,  ..., -0.4927, -0.6240, -1.3486]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 19:08:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is locate, the past form is located
If the present form is replace, the past form is replaced
If the present form is lose, the past form is lost
If the present form is continue, the past form is continued
If the present form is describe, the past form is described
If the present form is establish, the past form is established
If the present form is consider, the past form is considered
If the present form is relate, the past form is
2024-07-27 19:08:50 root INFO     total operator prediction time: 1313.7274730205536 seconds
2024-07-27 19:08:50 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_inf - 3pSg
2024-07-27 19:08:50 root INFO     building operator verb_inf - 3pSg
2024-07-27 19:08:50 root INFO     [order_1_approx] starting weight calculation for I contain, he contains
I involve, he involves
I protect, he protects
I ensure, he ensures
I enable, he enables
I accept, he accepts
I happen, he happens
I send, he
2024-07-27 19:08:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 19:11:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2162,  0.2703,  0.2119,  ..., -0.0157, -0.1482, -0.0862],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4062, -2.3965, -5.0898,  ..., -2.7148, -6.5117, -2.8379],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0227, -0.0163,  0.0057,  ..., -0.0018, -0.0156, -0.0019],
        [-0.0469,  0.0063,  0.0043,  ..., -0.0067,  0.0435,  0.0193],
        [ 0.0195,  0.0157,  0.0174,  ...,  0.0086, -0.0167, -0.0090],
        ...,
        [ 0.0222, -0.0174,  0.0150,  ...,  0.0180,  0.0114, -0.0161],
        [-0.0219, -0.0020,  0.0137,  ..., -0.0361,  0.0244, -0.0157],
        [ 0.0762,  0.0183,  0.0015,  ...,  0.0206, -0.0657, -0.0194]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1406, -2.2578, -4.8711,  ..., -2.2383, -7.0000, -2.0781]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 19:11:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I contain, he contains
I involve, he involves
I protect, he protects
I ensure, he ensures
I enable, he enables
I accept, he accepts
I happen, he happens
I send, he
2024-07-27 19:11:33 root INFO     [order_1_approx] starting weight calculation for I accept, he accepts
I enable, he enables
I ensure, he ensures
I protect, he protects
I happen, he happens
I involve, he involves
I send, he sends
I contain, he
2024-07-27 19:11:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 19:14:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0338, -0.1948, -0.2188,  ..., -0.0123, -0.2935, -0.1143],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8242, -2.2109,  0.1328,  ..., -2.0332, -5.7930, -2.6465],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0002,  0.0435, -0.0083,  ...,  0.0177, -0.0298,  0.0186],
        [-0.0476,  0.0061,  0.0167,  ..., -0.0236,  0.0121,  0.0104],
        [ 0.0421,  0.0064,  0.0028,  ..., -0.0386,  0.0148, -0.0075],
        ...,
        [-0.0263, -0.0185,  0.0149,  ...,  0.0137,  0.0109, -0.0051],
        [ 0.0093, -0.0609, -0.0257,  ..., -0.0378,  0.0201,  0.0091],
        [ 0.0279,  0.0225, -0.0284,  ...,  0.0059, -0.0316, -0.0096]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9121, -2.9844, -0.0720,  ..., -1.6992, -5.9883, -3.1699]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 19:14:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I accept, he accepts
I enable, he enables
I ensure, he ensures
I protect, he protects
I happen, he happens
I involve, he involves
I send, he sends
I contain, he
2024-07-27 19:14:18 root INFO     [order_1_approx] starting weight calculation for I send, he sends
I protect, he protects
I enable, he enables
I happen, he happens
I contain, he contains
I ensure, he ensures
I accept, he accepts
I involve, he
2024-07-27 19:14:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 19:17:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1995,  0.2839, -0.0199,  ...,  0.2043, -0.4075,  0.0930],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3281, -0.2642,  1.8516,  ..., -0.2803, -4.5039, -1.8018],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0002, -0.0054,  0.0099,  ...,  0.0263, -0.0147,  0.0267],
        [-0.0073, -0.0096, -0.0041,  ..., -0.0032,  0.0061,  0.0406],
        [ 0.0204, -0.0259, -0.0051,  ..., -0.0142, -0.0632,  0.0263],
        ...,
        [ 0.0304,  0.0027, -0.0052,  ...,  0.0039, -0.0015,  0.0007],
        [-0.0071, -0.0190,  0.0004,  ..., -0.0168, -0.0005,  0.0152],
        [ 0.0038,  0.0251,  0.0320,  ..., -0.0146, -0.0443, -0.0190]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9023, -0.9399,  1.3877,  ..., -0.1270, -5.1172, -2.5273]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 19:17:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I send, he sends
I protect, he protects
I enable, he enables
I happen, he happens
I contain, he contains
I ensure, he ensures
I accept, he accepts
I involve, he
2024-07-27 19:17:03 root INFO     [order_1_approx] starting weight calculation for I enable, he enables
I contain, he contains
I accept, he accepts
I protect, he protects
I involve, he involves
I send, he sends
I happen, he happens
I ensure, he
2024-07-27 19:17:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 19:19:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1060,  0.2681, -0.2450,  ...,  0.0796, -0.2281, -0.2615],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.2852, -1.8359, -1.7168,  ..., -0.8115, -8.1953, -0.9854],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0244, -0.0084,  0.0275,  ..., -0.0024, -0.0176,  0.0183],
        [-0.0117, -0.0060, -0.0039,  ..., -0.0287,  0.0211,  0.0103],
        [-0.0117,  0.0107, -0.0061,  ..., -0.0013, -0.0036, -0.0028],
        ...,
        [-0.0046,  0.0026,  0.0137,  ..., -0.0020,  0.0071,  0.0013],
        [ 0.0153, -0.0163,  0.0196,  ..., -0.0165,  0.0121,  0.0211],
        [ 0.0073,  0.0244,  0.0343,  ..., -0.0085, -0.0508,  0.0181]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.5234, -1.6807, -1.6367,  ..., -0.8501, -8.0781, -0.9717]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 19:19:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I enable, he enables
I contain, he contains
I accept, he accepts
I protect, he protects
I involve, he involves
I send, he sends
I happen, he happens
I ensure, he
2024-07-27 19:19:47 root INFO     [order_1_approx] starting weight calculation for I send, he sends
I enable, he enables
I ensure, he ensures
I contain, he contains
I protect, he protects
I involve, he involves
I happen, he happens
I accept, he
2024-07-27 19:19:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 19:22:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1575,  0.4912, -0.0907,  ...,  0.0523, -0.2346,  0.0963],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.8203, -0.8232, -3.1992,  ..., -0.7856, -9.1406,  0.2070],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0199,  0.0183,  0.0168,  ...,  0.0026, -0.0306, -0.0026],
        [-0.0410, -0.0145, -0.0170,  ...,  0.0173,  0.0285,  0.0112],
        [-0.0151, -0.0129,  0.0069,  ..., -0.0213, -0.0026,  0.0013],
        ...,
        [-0.0004, -0.0038, -0.0041,  ...,  0.0201,  0.0020,  0.0003],
        [-0.0021, -0.0225, -0.0247,  ..., -0.0106,  0.0153,  0.0006],
        [-0.0043, -0.0082, -0.0045,  ..., -0.0015, -0.0220,  0.0006]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.8672, -0.7822, -3.4219,  ..., -0.5674, -9.2969,  0.2925]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 19:22:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I send, he sends
I enable, he enables
I ensure, he ensures
I contain, he contains
I protect, he protects
I involve, he involves
I happen, he happens
I accept, he
2024-07-27 19:22:33 root INFO     [order_1_approx] starting weight calculation for I involve, he involves
I send, he sends
I happen, he happens
I contain, he contains
I enable, he enables
I accept, he accepts
I ensure, he ensures
I protect, he
2024-07-27 19:22:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 19:25:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0013, -0.0491, -0.1313,  ..., -0.0306, -0.0739, -0.0066],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0078, -5.0703, -1.6719,  ..., -0.7021, -6.0898, -0.0361],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0122,  0.0062, -0.0128,  ...,  0.0080, -0.0161,  0.0261],
        [-0.0629,  0.0034, -0.0161,  ...,  0.0067,  0.0612, -0.0158],
        [-0.0137,  0.0157, -0.0066,  ...,  0.0043, -0.0078, -0.0121],
        ...,
        [ 0.0091,  0.0028,  0.0076,  ...,  0.0045,  0.0066, -0.0049],
        [ 0.0372, -0.0003,  0.0014,  ..., -0.0222,  0.0120, -0.0034],
        [-0.0044,  0.0177, -0.0025,  ...,  0.0035, -0.0071,  0.0155]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0469, -5.0039, -1.7578,  ..., -0.2964, -6.6250,  0.1506]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 19:25:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I involve, he involves
I send, he sends
I happen, he happens
I contain, he contains
I enable, he enables
I accept, he accepts
I ensure, he ensures
I protect, he
2024-07-27 19:25:18 root INFO     [order_1_approx] starting weight calculation for I accept, he accepts
I protect, he protects
I contain, he contains
I send, he sends
I ensure, he ensures
I happen, he happens
I involve, he involves
I enable, he
2024-07-27 19:25:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 19:28:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0507,  0.3694,  0.0266,  ..., -0.2009, -0.1719,  0.1343],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8770, -2.5801, -1.5430,  ..., -1.6211, -8.8516, -1.9746],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0087,  0.0154,  0.0066,  ...,  0.0234, -0.0012,  0.0138],
        [-0.0165,  0.0175,  0.0060,  ...,  0.0105,  0.0276,  0.0153],
        [-0.0064, -0.0471,  0.0115,  ..., -0.0368, -0.0099,  0.0110],
        ...,
        [-0.0043,  0.0012, -0.0010,  ...,  0.0045,  0.0183,  0.0066],
        [ 0.0294, -0.0058, -0.0081,  ..., -0.0054,  0.0370,  0.0318],
        [ 0.0171,  0.0477,  0.0322,  ..., -0.0216, -0.0114,  0.0092]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0820, -2.4844, -1.7275,  ..., -1.3691, -9.0547, -2.2891]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 19:28:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I accept, he accepts
I protect, he protects
I contain, he contains
I send, he sends
I ensure, he ensures
I happen, he happens
I involve, he involves
I enable, he
2024-07-27 19:28:01 root INFO     [order_1_approx] starting weight calculation for I ensure, he ensures
I enable, he enables
I send, he sends
I protect, he protects
I accept, he accepts
I involve, he involves
I contain, he contains
I happen, he
2024-07-27 19:28:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 19:30:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4041,  0.2108,  0.0657,  ..., -0.0739, -0.0200, -0.1425],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5449, -1.0898, -1.0371,  ..., -0.9316, -8.1875, -0.6270],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0228,  0.0089,  0.0066,  ..., -0.0045,  0.0148,  0.0077],
        [-0.0096,  0.0009, -0.0018,  ..., -0.0143,  0.0111,  0.0091],
        [-0.0017,  0.0080, -0.0080,  ..., -0.0056, -0.0084,  0.0096],
        ...,
        [ 0.0137, -0.0242, -0.0037,  ...,  0.0137, -0.0206, -0.0205],
        [ 0.0036, -0.0339,  0.0056,  ..., -0.0052, -0.0164, -0.0173],
        [ 0.0138, -0.0062,  0.0064,  ...,  0.0145, -0.0342, -0.0193]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7324, -1.6006, -1.4629,  ..., -0.5850, -8.6406, -1.1055]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 19:30:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I ensure, he ensures
I enable, he enables
I send, he sends
I protect, he protects
I accept, he accepts
I involve, he involves
I contain, he contains
I happen, he
2024-07-27 19:30:46 root INFO     total operator prediction time: 1316.8144969940186 seconds
2024-07-27 19:30:46 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_Ving - 3pSg
2024-07-27 19:30:46 root INFO     building operator verb_Ving - 3pSg
2024-07-27 19:30:47 root INFO     [order_1_approx] starting weight calculation for When something is improving, it improves
When something is enabling, it enables
When something is asking, it asks
When something is understanding, it understands
When something is providing, it provides
When something is representing, it represents
When something is considering, it considers
When something is receiving, it
2024-07-27 19:30:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 19:33:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1276,  0.1982,  0.0402,  ..., -0.3062, -0.1024, -0.1477],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7012, -2.1523, -2.1406,  ..., -1.3721, -6.1094, -2.6660],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0071,  0.0152,  0.0058,  ...,  0.0225, -0.0062,  0.0118],
        [-0.0279,  0.0316,  0.0025,  ...,  0.0133, -0.0113,  0.0140],
        [-0.0053,  0.0161,  0.0161,  ...,  0.0059,  0.0163, -0.0066],
        ...,
        [ 0.0291,  0.0170,  0.0143,  ...,  0.0215, -0.0003,  0.0195],
        [ 0.0080, -0.0005,  0.0144,  ..., -0.0867,  0.0461, -0.0170],
        [-0.0024,  0.0211, -0.0102,  ..., -0.0044,  0.0088,  0.0038]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3760, -2.6035, -1.5508,  ..., -1.2705, -6.7617, -3.0859]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 19:33:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is improving, it improves
When something is enabling, it enables
When something is asking, it asks
When something is understanding, it understands
When something is providing, it provides
When something is representing, it represents
When something is considering, it considers
When something is receiving, it
2024-07-27 19:33:30 root INFO     [order_1_approx] starting weight calculation for When something is providing, it provides
When something is asking, it asks
When something is understanding, it understands
When something is representing, it represents
When something is considering, it considers
When something is receiving, it receives
When something is improving, it improves
When something is enabling, it
2024-07-27 19:33:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 19:36:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1625,  0.2219,  0.0418,  ..., -0.0371, -0.3022,  0.1327],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0771, -3.9590,  0.0820,  ..., -0.6987, -8.3594, -1.0049],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0275,  0.0197,  0.0121,  ...,  0.0114, -0.0085,  0.0058],
        [ 0.0195,  0.0532,  0.0081,  ...,  0.0224,  0.0023, -0.0192],
        [-0.0368, -0.0141,  0.0007,  ..., -0.0274, -0.0127, -0.0227],
        ...,
        [ 0.0280,  0.0136, -0.0114,  ...,  0.0155,  0.0103, -0.0051],
        [ 0.0048, -0.0043,  0.0216,  ..., -0.0329, -0.0195, -0.0308],
        [-0.0158, -0.0157,  0.0195,  ..., -0.0211, -0.0280,  0.0281]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0396, -4.0117,  0.2842,  ..., -0.5786, -8.6641, -1.2217]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 19:36:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is providing, it provides
When something is asking, it asks
When something is understanding, it understands
When something is representing, it represents
When something is considering, it considers
When something is receiving, it receives
When something is improving, it improves
When something is enabling, it
2024-07-27 19:36:11 root INFO     [order_1_approx] starting weight calculation for When something is improving, it improves
When something is enabling, it enables
When something is representing, it represents
When something is considering, it considers
When something is providing, it provides
When something is understanding, it understands
When something is receiving, it receives
When something is asking, it
2024-07-27 19:36:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 19:38:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1030,  0.2054, -0.0439,  ...,  0.1078, -0.1501, -0.3491],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0840, -3.3711, -0.9336,  ...,  0.1196, -6.2969,  0.4570],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0196, -0.0084,  0.0150,  ...,  0.0105, -0.0045, -0.0021],
        [-0.0018,  0.0271,  0.0036,  ...,  0.0196, -0.0175,  0.0088],
        [ 0.0048,  0.0135,  0.0335,  ...,  0.0030, -0.0030, -0.0022],
        ...,
        [-0.0045,  0.0183,  0.0102,  ...,  0.0023, -0.0124,  0.0121],
        [-0.0361,  0.0334, -0.0481,  ..., -0.0720,  0.0347, -0.0102],
        [-0.0305,  0.0173,  0.0044,  ..., -0.0134, -0.0085, -0.0110]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3320, -3.4941, -0.9009,  ...,  0.2002, -6.4219,  0.4092]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 19:38:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is improving, it improves
When something is enabling, it enables
When something is representing, it represents
When something is considering, it considers
When something is providing, it provides
When something is understanding, it understands
When something is receiving, it receives
When something is asking, it
2024-07-27 19:38:54 root INFO     [order_1_approx] starting weight calculation for When something is considering, it considers
When something is receiving, it receives
When something is asking, it asks
When something is providing, it provides
When something is enabling, it enables
When something is representing, it represents
When something is understanding, it understands
When something is improving, it
2024-07-27 19:38:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 19:41:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0096,  0.1550,  0.2021,  ..., -0.1154,  0.0528,  0.1681],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.6250, -4.7578, -1.3438,  ..., -0.1143, -6.6172, -0.7363],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0120,  0.0032, -0.0190,  ...,  0.0249,  0.0038,  0.0160],
        [ 0.0080,  0.0432, -0.0099,  ...,  0.0018, -0.0058,  0.0172],
        [-0.0036,  0.0030, -0.0010,  ...,  0.0033,  0.0131, -0.0283],
        ...,
        [-0.0007,  0.0031,  0.0187,  ...,  0.0273,  0.0061,  0.0197],
        [-0.0041, -0.0255,  0.0024,  ..., -0.0209, -0.0178, -0.0800],
        [-0.0037, -0.0169,  0.0119,  ..., -0.0025, -0.0276,  0.0186]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.7148, -4.7891, -1.2363,  ..., -0.1703, -7.0234, -1.0381]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 19:41:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is considering, it considers
When something is receiving, it receives
When something is asking, it asks
When something is providing, it provides
When something is enabling, it enables
When something is representing, it represents
When something is understanding, it understands
When something is improving, it
2024-07-27 19:41:38 root INFO     [order_1_approx] starting weight calculation for When something is improving, it improves
When something is understanding, it understands
When something is asking, it asks
When something is representing, it represents
When something is providing, it provides
When something is receiving, it receives
When something is enabling, it enables
When something is considering, it
2024-07-27 19:41:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 19:44:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1200,  0.1543, -0.0623,  ...,  0.1093, -0.0183, -0.1218],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3789, -3.6621,  2.1660,  ..., -1.9531, -5.8398,  0.2656],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0389,  0.0217, -0.0462,  ...,  0.0068,  0.0123,  0.0093],
        [-0.0187,  0.0190,  0.0351,  ..., -0.0284, -0.0182,  0.0352],
        [-0.0031, -0.0199,  0.0239,  ..., -0.0303, -0.0195, -0.0109],
        ...,
        [ 0.0299,  0.0203,  0.0389,  ...,  0.0096, -0.0017, -0.0060],
        [-0.0175, -0.0173,  0.0075,  ..., -0.0688,  0.0067, -0.0580],
        [ 0.0213, -0.0172,  0.0425,  ..., -0.0028, -0.0340, -0.0208]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2930, -4.3164,  2.0645,  ..., -1.4805, -5.8359,  0.1816]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 19:44:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is improving, it improves
When something is understanding, it understands
When something is asking, it asks
When something is representing, it represents
When something is providing, it provides
When something is receiving, it receives
When something is enabling, it enables
When something is considering, it
2024-07-27 19:44:18 root INFO     [order_1_approx] starting weight calculation for When something is improving, it improves
When something is enabling, it enables
When something is receiving, it receives
When something is understanding, it understands
When something is providing, it provides
When something is considering, it considers
When something is asking, it asks
When something is representing, it
2024-07-27 19:44:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 19:46:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0242,  0.2532,  0.0702,  ...,  0.0598, -0.0310, -0.3374],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.1787, -3.7227,  1.0645,  ..., -0.8408, -7.1445,  0.1797],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.5563e-02,  1.4099e-02,  6.8359e-03,  ...,  9.9335e-03,
         -2.1820e-03,  8.2397e-03],
        [-6.7520e-03,  4.4403e-02,  1.1765e-02,  ..., -6.0730e-03,
         -4.8752e-03, -1.1154e-02],
        [-1.4359e-02, -7.7667e-03,  6.8893e-03,  ..., -4.6692e-03,
         -3.0060e-03, -1.1673e-03],
        ...,
        [ 7.6294e-05,  2.4353e-02, -1.2108e-02,  ...,  2.4811e-02,
         -2.8229e-02,  2.8503e-02],
        [-1.1215e-02, -5.6839e-03, -1.5907e-03,  ..., -3.4302e-02,
          3.4546e-02, -4.9072e-02],
        [ 2.0447e-03, -2.4887e-02, -1.0406e-02,  ..., -2.1484e-02,
         -6.1569e-03,  6.9542e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.0400, -3.9551,  1.2256,  ..., -0.8438, -7.1875, -0.3516]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 19:46:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is improving, it improves
When something is enabling, it enables
When something is receiving, it receives
When something is understanding, it understands
When something is providing, it provides
When something is considering, it considers
When something is asking, it asks
When something is representing, it
2024-07-27 19:46:59 root INFO     [order_1_approx] starting weight calculation for When something is receiving, it receives
When something is asking, it asks
When something is considering, it considers
When something is enabling, it enables
When something is understanding, it understands
When something is representing, it represents
When something is improving, it improves
When something is providing, it
2024-07-27 19:46:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 19:49:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1514,  0.0742, -0.0285,  ..., -0.0358, -0.1235, -0.1749],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1748, -6.7500,  0.5645,  ..., -1.0986, -6.9922,  0.3242],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-7.9117e-03,  1.0460e-02, -2.1088e-02,  ..., -3.2482e-03,
         -1.3855e-02,  3.7170e-02],
        [ 2.0752e-02,  1.6220e-02,  1.0284e-02,  ...,  3.0121e-02,
          3.6697e-03,  3.9185e-02],
        [-2.7222e-02,  4.8065e-03,  1.3260e-02,  ..., -2.4429e-02,
         -1.1879e-02, -3.0899e-02],
        ...,
        [ 1.1513e-02,  1.5854e-02,  1.4168e-02,  ...,  1.6510e-02,
         -4.9744e-03, -3.4294e-03],
        [ 1.4938e-02,  5.2567e-03, -2.7542e-03,  ..., -5.2368e-02,
          3.8757e-03, -6.9885e-02],
        [-8.8692e-05,  1.1406e-02, -3.7861e-03,  ..., -1.7456e-02,
         -3.0365e-02,  1.1261e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0703, -6.2695,  0.4219,  ..., -1.1436, -7.9531, -0.0715]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 19:49:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is receiving, it receives
When something is asking, it asks
When something is considering, it considers
When something is enabling, it enables
When something is understanding, it understands
When something is representing, it represents
When something is improving, it improves
When something is providing, it
2024-07-27 19:49:44 root INFO     [order_1_approx] starting weight calculation for When something is representing, it represents
When something is enabling, it enables
When something is asking, it asks
When something is considering, it considers
When something is receiving, it receives
When something is providing, it provides
When something is improving, it improves
When something is understanding, it
2024-07-27 19:49:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 19:52:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-2.5879e-01,  5.3906e-01, -2.8687e-02,  ...,  2.0166e-01,
        -2.4390e-01, -1.3351e-04], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1289, -2.3594,  0.7930,  ..., -0.5620, -5.7930,  1.9531],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0169,  0.0045, -0.0278,  ..., -0.0060, -0.0141,  0.0174],
        [-0.0047,  0.0372, -0.0005,  ..., -0.0078,  0.0069,  0.0245],
        [ 0.0141, -0.0055,  0.0103,  ..., -0.0097, -0.0045, -0.0167],
        ...,
        [ 0.0301,  0.0205,  0.0191,  ...,  0.0353,  0.0037, -0.0083],
        [-0.0152,  0.0035, -0.0184,  ..., -0.0406,  0.0039, -0.0461],
        [-0.0325, -0.0014, -0.0071,  ...,  0.0041, -0.0231,  0.0006]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1055, -2.4219,  1.2852,  ..., -0.7373, -6.0391,  1.6006]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 19:52:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is representing, it represents
When something is enabling, it enables
When something is asking, it asks
When something is considering, it considers
When something is receiving, it receives
When something is providing, it provides
When something is improving, it improves
When something is understanding, it
2024-07-27 19:52:30 root INFO     total operator prediction time: 1303.1440963745117 seconds
2024-07-27 19:52:30 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun - plural_reg
2024-07-27 19:52:30 root INFO     building operator noun - plural_reg
2024-07-27 19:52:30 root INFO     [order_1_approx] starting weight calculation for The plural form of application is applications
The plural form of event is events
The plural form of government is governments
The plural form of member is members
The plural form of friend is friends
The plural form of problem is problems
The plural form of area is areas
The plural form of thing is
2024-07-27 19:52:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 19:55:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1071, -0.0425, -0.0053,  ...,  0.0568, -0.0643,  0.0535],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3516, -3.2148,  1.8438,  ..., -0.1924, -1.6689, -2.4414],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0480, -0.0662,  0.0121,  ...,  0.0217,  0.0342,  0.0195],
        [ 0.0399,  0.0171,  0.0212,  ...,  0.0468, -0.0356, -0.0153],
        [-0.0116,  0.0034,  0.0330,  ..., -0.0245,  0.0015,  0.0293],
        ...,
        [-0.0424,  0.0106, -0.0005,  ..., -0.0015, -0.0004, -0.0127],
        [-0.0239,  0.0494, -0.0481,  ..., -0.0323, -0.0109, -0.0197],
        [ 0.0207, -0.0382, -0.0196,  ...,  0.0247,  0.0199,  0.0563]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7441, -3.9863,  1.9570,  ..., -0.6011, -1.5430, -2.5762]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 19:55:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of application is applications
The plural form of event is events
The plural form of government is governments
The plural form of member is members
The plural form of friend is friends
The plural form of problem is problems
The plural form of area is areas
The plural form of thing is
2024-07-27 19:55:12 root INFO     [order_1_approx] starting weight calculation for The plural form of friend is friends
The plural form of area is areas
The plural form of government is governments
The plural form of thing is things
The plural form of event is events
The plural form of member is members
The plural form of application is applications
The plural form of problem is
2024-07-27 19:55:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 19:57:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3337, -0.0842,  0.0854,  ...,  0.0607, -0.4624,  0.4109],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8682, -2.8438,  0.7007,  ...,  0.0234, -0.2881, -0.5977],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0240, -0.0018,  0.0136,  ...,  0.0003,  0.0027,  0.0119],
        [-0.0054,  0.0132,  0.0021,  ...,  0.0152, -0.0278,  0.0179],
        [ 0.0043,  0.0080,  0.0020,  ..., -0.0132, -0.0120,  0.0183],
        ...,
        [-0.0061,  0.0102,  0.0120,  ...,  0.0329,  0.0046, -0.0135],
        [ 0.0007, -0.0002, -0.0257,  ...,  0.0098,  0.0152, -0.0329],
        [ 0.0177, -0.0128,  0.0129,  ...,  0.0188, -0.0105,  0.0083]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8164, -3.1270,  0.7646,  ...,  0.3176, -0.5293, -0.5557]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 19:57:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of friend is friends
The plural form of area is areas
The plural form of government is governments
The plural form of thing is things
The plural form of event is events
The plural form of member is members
The plural form of application is applications
The plural form of problem is
2024-07-27 19:57:58 root INFO     [order_1_approx] starting weight calculation for The plural form of thing is things
The plural form of member is members
The plural form of problem is problems
The plural form of friend is friends
The plural form of government is governments
The plural form of area is areas
The plural form of application is applications
The plural form of event is
2024-07-27 19:57:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 20:00:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2181,  0.2759,  0.1079,  ..., -0.1211,  0.1077, -0.0510],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2852, -1.5430, -0.0327,  ..., -0.0071, -1.7090, -2.2715],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0382, -0.0178,  0.0127,  ...,  0.0011, -0.0055, -0.0072],
        [-0.0023,  0.0381,  0.0158,  ...,  0.0090, -0.0252,  0.0030],
        [ 0.0015,  0.0059, -0.0104,  ...,  0.0023, -0.0074,  0.0081],
        ...,
        [-0.0046,  0.0015,  0.0048,  ...,  0.0182, -0.0028, -0.0024],
        [ 0.0046,  0.0025, -0.0257,  ..., -0.0108,  0.0184, -0.0105],
        [ 0.0172, -0.0047, -0.0060,  ...,  0.0094, -0.0050,  0.0132]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5884, -1.7588, -0.1854,  ...,  0.2571, -2.0996, -2.3477]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 20:00:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of thing is things
The plural form of member is members
The plural form of problem is problems
The plural form of friend is friends
The plural form of government is governments
The plural form of area is areas
The plural form of application is applications
The plural form of event is
2024-07-27 20:00:43 root INFO     [order_1_approx] starting weight calculation for The plural form of problem is problems
The plural form of government is governments
The plural form of thing is things
The plural form of member is members
The plural form of event is events
The plural form of friend is friends
The plural form of application is applications
The plural form of area is
2024-07-27 20:00:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 20:03:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0220,  0.0149, -0.0956,  ...,  0.3652,  0.0179,  0.1177],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4434e+00, -4.1953e+00,  2.8516e+00,  ..., -2.2227e+00,
         3.0518e-03, -3.1836e+00], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0507, -0.0356, -0.0461,  ...,  0.0159, -0.0240,  0.0145],
        [ 0.0394,  0.0550, -0.0127,  ..., -0.0079, -0.0400, -0.0049],
        [-0.0182,  0.0101,  0.0099,  ...,  0.0323, -0.0102,  0.0380],
        ...,
        [ 0.0011, -0.0003,  0.0224,  ...,  0.0410, -0.0113, -0.0066],
        [ 0.0054, -0.0081, -0.0051,  ...,  0.0295,  0.0375, -0.0554],
        [ 0.0131, -0.0191, -0.0234,  ...,  0.0241, -0.0311,  0.0110]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4219, -4.3438,  2.3242,  ..., -1.9824, -0.4521, -3.2520]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 20:03:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of problem is problems
The plural form of government is governments
The plural form of thing is things
The plural form of member is members
The plural form of event is events
The plural form of friend is friends
The plural form of application is applications
The plural form of area is
2024-07-27 20:03:27 root INFO     [order_1_approx] starting weight calculation for The plural form of event is events
The plural form of thing is things
The plural form of area is areas
The plural form of application is applications
The plural form of government is governments
The plural form of problem is problems
The plural form of member is members
The plural form of friend is
2024-07-27 20:03:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 20:06:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0801,  0.0169,  0.0224,  ...,  0.1301, -0.0717,  0.1328],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8916, -2.3906,  2.5586,  ...,  0.0737, -0.7695, -1.6094],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0062,  0.0174, -0.0058,  ...,  0.0018,  0.0374, -0.0047],
        [-0.0060,  0.0081, -0.0062,  ...,  0.0120, -0.0158, -0.0039],
        [-0.0099, -0.0105, -0.0205,  ...,  0.0065, -0.0108,  0.0388],
        ...,
        [ 0.0098,  0.0150,  0.0161,  ...,  0.0127, -0.0295,  0.0108],
        [-0.0031,  0.0007, -0.0306,  ...,  0.0028,  0.0277, -0.0107],
        [ 0.0162, -0.0148, -0.0276,  ...,  0.0157, -0.0060, -0.0008]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3984, -2.5488,  2.8164,  ..., -0.2654, -0.4280, -1.5537]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 20:06:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of event is events
The plural form of thing is things
The plural form of area is areas
The plural form of application is applications
The plural form of government is governments
The plural form of problem is problems
The plural form of member is members
The plural form of friend is
2024-07-27 20:06:15 root INFO     [order_1_approx] starting weight calculation for The plural form of area is areas
The plural form of event is events
The plural form of friend is friends
The plural form of thing is things
The plural form of application is applications
The plural form of government is governments
The plural form of problem is problems
The plural form of member is
2024-07-27 20:06:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 20:09:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1536, -0.1034, -0.1951,  ...,  0.1980, -0.1912,  0.2007],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8809, -1.5547,  1.2480,  ..., -1.2754,  0.6172, -3.5508],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0392, -0.0253, -0.0610,  ...,  0.0276, -0.0182,  0.0252],
        [ 0.0134,  0.0272,  0.0196,  ...,  0.0035, -0.0543, -0.0094],
        [-0.0051,  0.0090, -0.0266,  ..., -0.0060, -0.0114,  0.0353],
        ...,
        [-0.0087,  0.0359,  0.0370,  ...,  0.0118,  0.0307, -0.0115],
        [-0.0454,  0.0703,  0.0097,  ..., -0.0420,  0.0520, -0.0318],
        [ 0.0210, -0.0260, -0.0314,  ...,  0.0238,  0.0055,  0.0190]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6924, -1.6260,  1.1855,  ..., -1.5068,  0.2710, -3.1914]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 20:09:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of area is areas
The plural form of event is events
The plural form of friend is friends
The plural form of thing is things
The plural form of application is applications
The plural form of government is governments
The plural form of problem is problems
The plural form of member is
2024-07-27 20:09:02 root INFO     [order_1_approx] starting weight calculation for The plural form of event is events
The plural form of friend is friends
The plural form of application is applications
The plural form of member is members
The plural form of area is areas
The plural form of problem is problems
The plural form of thing is things
The plural form of government is
2024-07-27 20:09:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 20:11:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0518,  0.0688,  0.1702,  ...,  0.0453, -0.1749, -0.0865],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6289, -1.7949,  0.8574,  ..., -1.9258, -0.5596, -3.0527],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.8519e-02,  2.6001e-02, -1.0620e-02,  ...,  3.2959e-03,
         -1.3344e-02, -3.3356e-02],
        [-1.2970e-03,  1.6594e-03,  1.1322e-02,  ...,  7.2327e-03,
         -2.4902e-02,  1.4687e-02],
        [-2.1255e-02,  1.0162e-02, -2.3026e-02,  ...,  2.4033e-02,
         -5.2032e-03, -2.8496e-03],
        ...,
        [ 1.5961e-02, -1.2680e-02, -2.7313e-02,  ...,  2.2736e-02,
         -1.1063e-02, -9.8267e-03],
        [-4.3831e-03, -9.8343e-03, -4.7607e-02,  ..., -2.3468e-02,
         -6.0425e-03,  4.5433e-03],
        [ 7.6981e-03,  7.2479e-05, -8.6823e-03,  ...,  5.3596e-03,
          6.2180e-03,  2.4155e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6416, -1.9697,  1.2754,  ..., -1.9541, -0.1226, -2.6504]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 20:11:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of event is events
The plural form of friend is friends
The plural form of application is applications
The plural form of member is members
The plural form of area is areas
The plural form of problem is problems
The plural form of thing is things
The plural form of government is
2024-07-27 20:11:47 root INFO     [order_1_approx] starting weight calculation for The plural form of problem is problems
The plural form of friend is friends
The plural form of government is governments
The plural form of member is members
The plural form of thing is things
The plural form of event is events
The plural form of area is areas
The plural form of application is
2024-07-27 20:11:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 20:14:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0618, -0.0963, -0.0448,  ...,  0.2693, -0.3020,  0.0593],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2031, -2.4297, -0.7524,  ..., -0.6084, -3.4434, -1.6914],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0493, -0.0376, -0.0030,  ...,  0.0384,  0.0394,  0.0126],
        [-0.0007,  0.0239,  0.0191,  ..., -0.0011, -0.0127, -0.0092],
        [-0.0114, -0.0016, -0.0015,  ..., -0.0051,  0.0153,  0.0261],
        ...,
        [ 0.0053,  0.0236, -0.0013,  ...,  0.0410, -0.0079,  0.0068],
        [-0.0211,  0.0315, -0.0278,  ..., -0.0121,  0.0031, -0.0082],
        [ 0.0135, -0.0154,  0.0077,  ...,  0.0108, -0.0054,  0.0208]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3525, -2.6680, -0.3743,  ..., -0.7969, -3.6309, -1.2930]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 20:14:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of problem is problems
The plural form of friend is friends
The plural form of government is governments
The plural form of member is members
The plural form of thing is things
The plural form of event is events
The plural form of area is areas
The plural form of application is
2024-07-27 20:14:32 root INFO     total operator prediction time: 1322.8243505954742 seconds
2024-07-27 20:14:32 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_3pSg - Ved
2024-07-27 20:14:32 root INFO     building operator verb_3pSg - Ved
2024-07-27 20:14:33 root INFO     [order_1_approx] starting weight calculation for When he hears something, something has been heard
When he refers something, something has been referred
When he remains something, something has been remained
When he appears something, something has been appeared
When he occurs something, something has been occurred
When he continues something, something has been continued
When he involves something, something has been involved
When he loses something, something has been
2024-07-27 20:14:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 20:17:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2010,  0.2185, -0.0071,  ...,  0.0021,  0.1157, -0.1141],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1367,  0.0068,  1.3945,  ..., -0.7725,  0.6191, -2.7695],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0141, -0.0247,  0.0193,  ...,  0.0079, -0.0113,  0.0107],
        [-0.0126,  0.0280,  0.0069,  ...,  0.0036, -0.0106, -0.0159],
        [ 0.0089, -0.0059,  0.0188,  ...,  0.0060,  0.0098, -0.0049],
        ...,
        [ 0.0118,  0.0192, -0.0040,  ..., -0.0203, -0.0166,  0.0218],
        [ 0.0020,  0.0118, -0.0067,  ..., -0.0212,  0.0040, -0.0079],
        [-0.0066,  0.0353,  0.0283,  ..., -0.0056, -0.0072, -0.0241]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1055, -0.0655,  1.3174,  ..., -0.3599,  0.6855, -2.7871]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 20:17:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he hears something, something has been heard
When he refers something, something has been referred
When he remains something, something has been remained
When he appears something, something has been appeared
When he occurs something, something has been occurred
When he continues something, something has been continued
When he involves something, something has been involved
When he loses something, something has been
2024-07-27 20:17:19 root INFO     [order_1_approx] starting weight calculation for When he occurs something, something has been occurred
When he remains something, something has been remained
When he involves something, something has been involved
When he continues something, something has been continued
When he hears something, something has been heard
When he loses something, something has been lost
When he appears something, something has been appeared
When he refers something, something has been
2024-07-27 20:17:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 20:20:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3911,  0.1289,  0.0423,  ...,  0.1166, -0.1221, -0.0797],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1660, -0.8462,  1.7012,  ...,  2.5703, -1.6309, -3.0859],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0620, -0.0160, -0.0148,  ..., -0.0136,  0.0463,  0.0134],
        [-0.0549,  0.0341,  0.0134,  ...,  0.0043, -0.0115,  0.0155],
        [ 0.0096, -0.0003, -0.0042,  ..., -0.0134,  0.0085, -0.0239],
        ...,
        [ 0.0445,  0.0105, -0.0109,  ...,  0.0201,  0.0080,  0.0262],
        [ 0.0133,  0.0006, -0.0253,  ..., -0.0208,  0.0143, -0.0159],
        [-0.0162,  0.0206,  0.0149,  ...,  0.0103, -0.0136,  0.0217]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4248, -1.0244,  1.4531,  ...,  2.2871, -1.4258, -2.7168]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 20:20:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he occurs something, something has been occurred
When he remains something, something has been remained
When he involves something, something has been involved
When he continues something, something has been continued
When he hears something, something has been heard
When he loses something, something has been lost
When he appears something, something has been appeared
When he refers something, something has been
2024-07-27 20:20:03 root INFO     [order_1_approx] starting weight calculation for When he involves something, something has been involved
When he refers something, something has been referred
When he occurs something, something has been occurred
When he remains something, something has been remained
When he hears something, something has been heard
When he continues something, something has been continued
When he loses something, something has been lost
When he appears something, something has been
2024-07-27 20:20:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 20:22:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2114,  0.0957, -0.1219,  ...,  0.1171, -0.2771, -0.3643],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4219,  0.9805,  1.5088,  ...,  0.7812, -1.7705,  0.0898],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0281, -0.0090,  0.0045,  ..., -0.0137,  0.0131,  0.0130],
        [-0.0091,  0.0259, -0.0191,  ...,  0.0102,  0.0007,  0.0049],
        [ 0.0377, -0.0055,  0.0338,  ..., -0.0208, -0.0199, -0.0041],
        ...,
        [-0.0023,  0.0341, -0.0051,  ...,  0.0287,  0.0103,  0.0169],
        [ 0.0171, -0.0135, -0.0161,  ...,  0.0105,  0.0378,  0.0005],
        [-0.0229,  0.0093,  0.0041,  ...,  0.0089, -0.0124,  0.0068]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1738,  0.8662,  1.5713,  ...,  0.6602, -1.4346,  0.3967]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 20:22:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he involves something, something has been involved
When he refers something, something has been referred
When he occurs something, something has been occurred
When he remains something, something has been remained
When he hears something, something has been heard
When he continues something, something has been continued
When he loses something, something has been lost
When he appears something, something has been
2024-07-27 20:22:43 root INFO     [order_1_approx] starting weight calculation for When he hears something, something has been heard
When he refers something, something has been referred
When he loses something, something has been lost
When he continues something, something has been continued
When he appears something, something has been appeared
When he involves something, something has been involved
When he remains something, something has been remained
When he occurs something, something has been
2024-07-27 20:22:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 20:25:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3435, -0.0820, -0.0408,  ...,  0.1064, -0.1062, -0.5962],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4526,  0.7100,  1.7383,  ...,  0.0421, -1.1611,  0.3301],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-3.9673e-02, -4.3030e-02,  3.3600e-02,  ...,  1.4793e-02,
          5.7922e-02,  7.9956e-03],
        [-1.1063e-02,  2.3727e-02,  2.3315e-02,  ...,  3.0563e-02,
          1.2093e-02, -8.4076e-03],
        [ 1.2665e-02, -2.9175e-02, -4.0283e-03,  ..., -2.0767e-02,
          3.5267e-03, -1.0757e-02],
        ...,
        [ 6.5689e-03, -5.5275e-03,  3.5217e-02,  ...,  2.1057e-02,
          2.5726e-02,  1.7151e-02],
        [ 1.0239e-02,  9.5673e-03, -7.2479e-03,  ..., -4.6539e-02,
         -2.7252e-02,  6.2790e-03],
        [ 2.2583e-02,  4.0222e-02,  2.8900e-02,  ..., -2.4796e-05,
         -2.9739e-02,  2.7756e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5190, -0.0112,  1.4727,  ..., -0.5742, -0.7764,  0.3059]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 20:25:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he hears something, something has been heard
When he refers something, something has been referred
When he loses something, something has been lost
When he continues something, something has been continued
When he appears something, something has been appeared
When he involves something, something has been involved
When he remains something, something has been remained
When he occurs something, something has been
2024-07-27 20:25:26 root INFO     [order_1_approx] starting weight calculation for When he occurs something, something has been occurred
When he refers something, something has been referred
When he involves something, something has been involved
When he appears something, something has been appeared
When he continues something, something has been continued
When he remains something, something has been remained
When he loses something, something has been lost
When he hears something, something has been
2024-07-27 20:25:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 20:28:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3140,  0.3855,  0.1624,  ...,  0.0315, -0.0857,  0.1122],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6436, -0.1836,  1.5645,  ...,  0.6865, -4.2109, -2.3906],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0409, -0.0054,  0.0258,  ..., -0.0260,  0.0011,  0.0227],
        [-0.0269,  0.0601,  0.0026,  ...,  0.0058, -0.0242, -0.0244],
        [ 0.0111, -0.0095,  0.0265,  ..., -0.0065,  0.0026, -0.0026],
        ...,
        [ 0.0220,  0.0268, -0.0026,  ..., -0.0131,  0.0073, -0.0056],
        [ 0.0367, -0.0215, -0.0095,  ...,  0.0004,  0.0280, -0.0176],
        [-0.0290,  0.0345,  0.0133,  ...,  0.0049,  0.0150, -0.0092]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2207, -0.4465,  1.6152,  ...,  0.4863, -3.8066, -2.7578]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 20:28:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he occurs something, something has been occurred
When he refers something, something has been referred
When he involves something, something has been involved
When he appears something, something has been appeared
When he continues something, something has been continued
When he remains something, something has been remained
When he loses something, something has been lost
When he hears something, something has been
2024-07-27 20:28:12 root INFO     [order_1_approx] starting weight calculation for When he occurs something, something has been occurred
When he hears something, something has been heard
When he continues something, something has been continued
When he remains something, something has been remained
When he refers something, something has been referred
When he appears something, something has been appeared
When he loses something, something has been lost
When he involves something, something has been
2024-07-27 20:28:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 20:30:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1738, -0.3088, -0.0308,  ...,  0.1492, -0.2050, -0.1587],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9023,  1.6250,  2.5664,  ...,  1.0869,  0.0951, -3.5645],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0047,  0.0168,  0.0078,  ...,  0.0362,  0.0854,  0.0259],
        [-0.0825,  0.0526,  0.0202,  ...,  0.0400, -0.0203, -0.0122],
        [-0.0073, -0.0297, -0.0117,  ..., -0.0007, -0.0359, -0.0473],
        ...,
        [ 0.0359,  0.0522, -0.0421,  ...,  0.0382,  0.0164,  0.0295],
        [-0.0042,  0.0163, -0.0143,  ..., -0.0027, -0.0723, -0.0454],
        [ 0.0389,  0.0656,  0.0364,  ...,  0.0090, -0.0169,  0.0425]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6865,  0.7388,  2.5078,  ..., -0.4336,  0.5459, -2.7227]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 20:30:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he occurs something, something has been occurred
When he hears something, something has been heard
When he continues something, something has been continued
When he remains something, something has been remained
When he refers something, something has been referred
When he appears something, something has been appeared
When he loses something, something has been lost
When he involves something, something has been
2024-07-27 20:30:56 root INFO     [order_1_approx] starting weight calculation for When he occurs something, something has been occurred
When he loses something, something has been lost
When he involves something, something has been involved
When he refers something, something has been referred
When he appears something, something has been appeared
When he hears something, something has been heard
When he continues something, something has been continued
When he remains something, something has been
2024-07-27 20:30:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 20:33:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0386,  0.0756, -0.0491,  ...,  0.0061, -0.1116, -0.0789],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7109, -0.9155,  1.5664,  ..., -2.1191,  0.0762, -2.0469],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0106, -0.0203, -0.0232,  ..., -0.0145,  0.0146,  0.0238],
        [-0.0303,  0.0383,  0.0062,  ...,  0.0122, -0.0043,  0.0056],
        [-0.0084, -0.0033,  0.0191,  ..., -0.0076, -0.0189,  0.0055],
        ...,
        [-0.0015, -0.0137, -0.0003,  ..., -0.0010,  0.0143,  0.0304],
        [ 0.0022, -0.0078, -0.0170,  ..., -0.0005, -0.0026, -0.0129],
        [ 0.0084, -0.0008,  0.0005,  ...,  0.0275, -0.0123,  0.0018]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8770, -1.0898,  1.7871,  ..., -1.9951,  0.0801, -2.0137]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 20:33:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he occurs something, something has been occurred
When he loses something, something has been lost
When he involves something, something has been involved
When he refers something, something has been referred
When he appears something, something has been appeared
When he hears something, something has been heard
When he continues something, something has been continued
When he remains something, something has been
2024-07-27 20:33:39 root INFO     [order_1_approx] starting weight calculation for When he hears something, something has been heard
When he appears something, something has been appeared
When he occurs something, something has been occurred
When he refers something, something has been referred
When he involves something, something has been involved
When he remains something, something has been remained
When he loses something, something has been lost
When he continues something, something has been
2024-07-27 20:33:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 20:36:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1101, -0.1814, -0.0999,  ...,  0.0252, -0.3931,  0.1234],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0156, -0.5342,  2.4199,  ..., -0.7607,  1.2656, -1.8145],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0113, -0.0020, -0.0012,  ...,  0.0046,  0.0225,  0.0192],
        [-0.0220,  0.0308,  0.0080,  ..., -0.0091, -0.0031,  0.0015],
        [ 0.0086, -0.0033,  0.0067,  ..., -0.0166,  0.0060,  0.0032],
        ...,
        [-0.0062,  0.0190,  0.0163,  ...,  0.0237,  0.0120,  0.0089],
        [ 0.0043, -0.0148, -0.0253,  ..., -0.0373, -0.0071, -0.0074],
        [-0.0114, -0.0026,  0.0040,  ..., -0.0172, -0.0243,  0.0161]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0859, -0.3003,  1.9893,  ..., -0.7051,  1.4111, -1.8574]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 20:36:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he hears something, something has been heard
When he appears something, something has been appeared
When he occurs something, something has been occurred
When he refers something, something has been referred
When he involves something, something has been involved
When he remains something, something has been remained
When he loses something, something has been lost
When he continues something, something has been
2024-07-27 20:36:24 root INFO     total operator prediction time: 1311.999295949936 seconds
2024-07-27 20:36:24 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj - superlative
2024-07-27 20:36:24 root INFO     building operator adj - superlative
2024-07-27 20:36:25 root INFO     [order_1_approx] starting weight calculation for If something is the most weird, it is weirdest
If something is the most costly, it is costliest
If something is the most weak, it is weakest
If something is the most vague, it is vaguest
If something is the most dense, it is densest
If something is the most strange, it is strangest
If something is the most clever, it is cleverest
If something is the most rude, it is
2024-07-27 20:36:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 20:39:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1006,  0.1249,  0.0898,  ..., -0.0211,  0.0765, -0.0585],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.0039, -4.6094,  0.7383,  ..., -2.5664, -1.4473, -1.6016],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0117, -0.0198,  0.0098,  ..., -0.0357,  0.0217,  0.0063],
        [ 0.0010, -0.0186,  0.0276,  ..., -0.0259,  0.0029,  0.0284],
        [-0.0286, -0.0002,  0.0354,  ...,  0.0043, -0.0189, -0.0095],
        ...,
        [-0.0067,  0.0095,  0.0046,  ...,  0.0374, -0.0027,  0.0090],
        [-0.0097, -0.0266,  0.0151,  ...,  0.0007,  0.0096, -0.0317],
        [ 0.0051, -0.0089,  0.0161,  ...,  0.0044,  0.0202,  0.0005]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.0098, -4.7344,  0.9097,  ..., -2.5195, -1.5625, -1.4014]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 20:39:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most weird, it is weirdest
If something is the most costly, it is costliest
If something is the most weak, it is weakest
If something is the most vague, it is vaguest
If something is the most dense, it is densest
If something is the most strange, it is strangest
If something is the most clever, it is cleverest
If something is the most rude, it is
2024-07-27 20:39:08 root INFO     [order_1_approx] starting weight calculation for If something is the most rude, it is rudest
If something is the most strange, it is strangest
If something is the most weird, it is weirdest
If something is the most weak, it is weakest
If something is the most vague, it is vaguest
If something is the most dense, it is densest
If something is the most clever, it is cleverest
If something is the most costly, it is
2024-07-27 20:39:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 20:41:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2739,  0.2524, -0.2378,  ...,  0.2534, -0.1772,  0.0862],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.1445, -5.1367, -0.1433,  ..., -2.9258,  0.2207,  1.2324],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0074, -0.0213,  0.0018,  ..., -0.0186, -0.0281,  0.0179],
        [ 0.0050, -0.0031, -0.0021,  ..., -0.0286,  0.0239,  0.0237],
        [ 0.0069, -0.0038,  0.0179,  ...,  0.0112, -0.0181, -0.0105],
        ...,
        [ 0.0173,  0.0166,  0.0048,  ...,  0.0299,  0.0156,  0.0141],
        [ 0.0127,  0.0043, -0.0019,  ...,  0.0009,  0.0114, -0.0250],
        [-0.0180,  0.0016, -0.0069,  ..., -0.0031, -0.0038, -0.0019]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.6230, -4.9688, -0.5029,  ..., -2.8438,  0.0361,  1.3809]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 20:41:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most rude, it is rudest
If something is the most strange, it is strangest
If something is the most weird, it is weirdest
If something is the most weak, it is weakest
If something is the most vague, it is vaguest
If something is the most dense, it is densest
If something is the most clever, it is cleverest
If something is the most costly, it is
2024-07-27 20:41:53 root INFO     [order_1_approx] starting weight calculation for If something is the most clever, it is cleverest
If something is the most weak, it is weakest
If something is the most strange, it is strangest
If something is the most vague, it is vaguest
If something is the most rude, it is rudest
If something is the most weird, it is weirdest
If something is the most costly, it is costliest
If something is the most dense, it is
2024-07-27 20:41:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 20:44:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1101, -0.0701,  0.2310,  ..., -0.0182, -0.1812,  0.2571],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.2656, -3.3574,  0.8354,  ..., -5.3594, -3.5508, -2.6836],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0226, -0.0367,  0.0047,  ...,  0.0178, -0.0031,  0.0162],
        [-0.0125,  0.0312,  0.0087,  ..., -0.0284, -0.0236, -0.0134],
        [-0.0004,  0.0147,  0.0274,  ..., -0.0375, -0.0252,  0.0193],
        ...,
        [-0.0258, -0.0127,  0.0097,  ...,  0.0456, -0.0075, -0.0105],
        [-0.0262, -0.0131, -0.0040,  ...,  0.0289,  0.0512, -0.0511],
        [ 0.0176, -0.0075,  0.0049,  ..., -0.0375, -0.0015,  0.0053]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.7285, -2.9805,  0.8149,  ..., -5.0039, -3.5820, -2.7480]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 20:44:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most clever, it is cleverest
If something is the most weak, it is weakest
If something is the most strange, it is strangest
If something is the most vague, it is vaguest
If something is the most rude, it is rudest
If something is the most weird, it is weirdest
If something is the most costly, it is costliest
If something is the most dense, it is
2024-07-27 20:44:40 root INFO     [order_1_approx] starting weight calculation for If something is the most vague, it is vaguest
If something is the most weird, it is weirdest
If something is the most rude, it is rudest
If something is the most clever, it is cleverest
If something is the most dense, it is densest
If something is the most costly, it is costliest
If something is the most weak, it is weakest
If something is the most strange, it is
2024-07-27 20:44:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 20:47:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1043,  0.0211,  0.0197,  ..., -0.0285, -0.2681,  0.0995],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7129, -4.4258, -2.0469,  ..., -1.3164, -0.7539, -2.6426],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0142, -0.0189,  0.0058,  ..., -0.0125,  0.0047,  0.0109],
        [ 0.0101,  0.0164,  0.0367,  ..., -0.0105, -0.0266,  0.0040],
        [ 0.0058, -0.0408,  0.0225,  ...,  0.0029, -0.0149,  0.0430],
        ...,
        [-0.0054,  0.0261,  0.0167,  ...,  0.0311, -0.0081, -0.0215],
        [ 0.0008,  0.0124,  0.0126,  ...,  0.0108,  0.0350, -0.0459],
        [ 0.0191,  0.0126, -0.0045,  ..., -0.0065, -0.0291, -0.0092]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4551, -4.8516, -2.1309,  ..., -0.8809, -0.5698, -2.7715]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 20:47:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most vague, it is vaguest
If something is the most weird, it is weirdest
If something is the most rude, it is rudest
If something is the most clever, it is cleverest
If something is the most dense, it is densest
If something is the most costly, it is costliest
If something is the most weak, it is weakest
If something is the most strange, it is
2024-07-27 20:47:25 root INFO     [order_1_approx] starting weight calculation for If something is the most dense, it is densest
If something is the most rude, it is rudest
If something is the most vague, it is vaguest
If something is the most weak, it is weakest
If something is the most weird, it is weirdest
If something is the most strange, it is strangest
If something is the most costly, it is costliest
If something is the most clever, it is
2024-07-27 20:47:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 20:50:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0002,  0.0398,  0.1871,  ..., -0.1348, -0.0970, -0.0201],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.9775, -2.1484, -0.3208,  ..., -0.8232, -0.9609,  1.2070],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0305, -0.0123,  0.0308,  ..., -0.0081, -0.0012,  0.0126],
        [-0.0116, -0.0027,  0.0475,  ..., -0.0021,  0.0103,  0.0372],
        [ 0.0005, -0.0079,  0.0367,  ...,  0.0072, -0.0388,  0.0069],
        ...,
        [ 0.0067,  0.0153, -0.0013,  ...,  0.0460,  0.0188, -0.0178],
        [ 0.0103,  0.0047,  0.0003,  ..., -0.0158,  0.0319, -0.0236],
        [ 0.0112, -0.0045, -0.0016,  ...,  0.0194, -0.0058, -0.0121]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.0654, -2.8477, -0.2900,  ...,  0.0615, -1.0859,  1.3623]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 20:50:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most dense, it is densest
If something is the most rude, it is rudest
If something is the most vague, it is vaguest
If something is the most weak, it is weakest
If something is the most weird, it is weirdest
If something is the most strange, it is strangest
If something is the most costly, it is costliest
If something is the most clever, it is
2024-07-27 20:50:13 root INFO     [order_1_approx] starting weight calculation for If something is the most vague, it is vaguest
If something is the most weird, it is weirdest
If something is the most strange, it is strangest
If something is the most rude, it is rudest
If something is the most costly, it is costliest
If something is the most dense, it is densest
If something is the most clever, it is cleverest
If something is the most weak, it is
2024-07-27 20:50:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 20:52:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0201, -0.1707, -0.0663,  ..., -0.1554, -0.1561,  0.0123],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0684, -4.1172, -1.9570,  ..., -4.3750,  2.3828, -4.4570],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0296,  0.0071,  0.0102,  ..., -0.0059,  0.0240,  0.0145],
        [-0.0032, -0.0034,  0.0069,  ...,  0.0005,  0.0052,  0.0129],
        [ 0.0164, -0.0147,  0.0078,  ...,  0.0140, -0.0058, -0.0134],
        ...,
        [-0.0255, -0.0007,  0.0119,  ...,  0.0145, -0.0079, -0.0038],
        [ 0.0202, -0.0116, -0.0262,  ...,  0.0229,  0.0059, -0.0123],
        [ 0.0361, -0.0071, -0.0170,  ...,  0.0332, -0.0058, -0.0307]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2158, -3.7285, -1.9404,  ..., -4.2422,  2.4336, -4.4414]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 20:52:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most vague, it is vaguest
If something is the most weird, it is weirdest
If something is the most strange, it is strangest
If something is the most rude, it is rudest
If something is the most costly, it is costliest
If something is the most dense, it is densest
If something is the most clever, it is cleverest
If something is the most weak, it is
2024-07-27 20:52:59 root INFO     [order_1_approx] starting weight calculation for If something is the most costly, it is costliest
If something is the most clever, it is cleverest
If something is the most vague, it is vaguest
If something is the most weak, it is weakest
If something is the most strange, it is strangest
If something is the most dense, it is densest
If something is the most rude, it is rudest
If something is the most weird, it is
2024-07-27 20:52:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 20:55:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2590, -0.0387,  0.2223,  ...,  0.0526, -0.2329,  0.2551],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6934, -4.6328, -0.9067,  ..., -2.2949, -0.2031, -3.2617],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0148,  0.0096,  0.0026,  ...,  0.0234,  0.0171, -0.0197],
        [ 0.0041,  0.0021,  0.0083,  ...,  0.0026, -0.0348,  0.0266],
        [-0.0008, -0.0331,  0.0057,  ...,  0.0071, -0.0300, -0.0175],
        ...,
        [ 0.0134,  0.0070,  0.0114,  ...,  0.0277, -0.0183, -0.0183],
        [ 0.0131, -0.0115,  0.0176,  ...,  0.0045,  0.0271, -0.0154],
        [-0.0060,  0.0290, -0.0107,  ...,  0.0174, -0.0082, -0.0053]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0098, -4.6445, -1.0908,  ..., -1.8633, -0.0674, -3.3984]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 20:55:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most costly, it is costliest
If something is the most clever, it is cleverest
If something is the most vague, it is vaguest
If something is the most weak, it is weakest
If something is the most strange, it is strangest
If something is the most dense, it is densest
If something is the most rude, it is rudest
If something is the most weird, it is
2024-07-27 20:55:45 root INFO     [order_1_approx] starting weight calculation for If something is the most strange, it is strangest
If something is the most rude, it is rudest
If something is the most weird, it is weirdest
If something is the most weak, it is weakest
If something is the most dense, it is densest
If something is the most costly, it is costliest
If something is the most clever, it is cleverest
If something is the most vague, it is
2024-07-27 20:55:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 20:58:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0109,  0.1381,  0.0526,  ..., -0.0519, -0.1956, -0.1295],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.8359, -3.8066, -0.6143,  ..., -0.3970, -2.8633, -1.0586],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0388, -0.0032,  0.0172,  ..., -0.0150,  0.0053,  0.0056],
        [-0.0002,  0.0141,  0.0084,  ..., -0.0089, -0.0084,  0.0244],
        [-0.0230,  0.0181,  0.0487,  ...,  0.0081, -0.0350,  0.0370],
        ...,
        [ 0.0118,  0.0390,  0.0215,  ...,  0.0714,  0.0066,  0.0057],
        [ 0.0172, -0.0106,  0.0153,  ..., -0.0084,  0.0345, -0.0239],
        [ 0.0026,  0.0241,  0.0041,  ...,  0.0033, -0.0316,  0.0081]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.7773, -4.0781, -0.7378,  ..., -0.4458, -2.5137, -1.5586]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 20:58:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most strange, it is strangest
If something is the most rude, it is rudest
If something is the most weird, it is weirdest
If something is the most weak, it is weakest
If something is the most dense, it is densest
If something is the most costly, it is costliest
If something is the most clever, it is cleverest
If something is the most vague, it is
2024-07-27 20:58:28 root INFO     total operator prediction time: 1323.7884902954102 seconds
2024-07-27 20:58:28 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+er_irreg
2024-07-27 20:58:28 root INFO     building operator verb+er_irreg
2024-07-27 20:58:28 root INFO     [order_1_approx] starting weight calculation for If you teach something, you are a teacher
If you manage something, you are a manager
If you recommend something, you are a recommender
If you choreograph something, you are a choreographer
If you receive something, you are a receiver
If you write something, you are a writer
If you organise something, you are a organiser
If you deliver something, you are a
2024-07-27 20:58:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 21:01:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0927,  0.3115,  0.1670,  ...,  0.0258, -0.3523, -0.1777],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.2656, -4.1680,  2.3340,  ...,  0.4790, -4.5430, -2.7363],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0374,  0.0048,  0.0219,  ...,  0.0233, -0.0103, -0.0052],
        [-0.0243,  0.0206, -0.0047,  ..., -0.0116,  0.0037, -0.0174],
        [ 0.0075, -0.0165,  0.0225,  ...,  0.0128, -0.0013,  0.0100],
        ...,
        [ 0.0216,  0.0155,  0.0138,  ...,  0.0373,  0.0187,  0.0060],
        [ 0.0122, -0.0056,  0.0049,  ..., -0.0380,  0.0099, -0.0122],
        [-0.0052, -0.0006,  0.0017,  ..., -0.0159, -0.0120,  0.0204]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.6445, -4.3750,  2.6289,  ...,  0.4331, -4.2266, -3.0391]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 21:01:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you teach something, you are a teacher
If you manage something, you are a manager
If you recommend something, you are a recommender
If you choreograph something, you are a choreographer
If you receive something, you are a receiver
If you write something, you are a writer
If you organise something, you are a organiser
If you deliver something, you are a
2024-07-27 21:01:16 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you teach something, you are a teacher
If you choreograph something, you are a choreographer
If you write something, you are a writer
If you manage something, you are a manager
If you organise something, you are a organiser
If you recommend something, you are a recommender
If you receive something, you are a
2024-07-27 21:01:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 21:04:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0024,  0.1055, -0.0841,  ..., -0.2349, -0.1210, -0.0816],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7432,  0.2871, -1.7461,  ..., -0.6714, -3.5234, -2.7832],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0145,  0.0226,  0.0088,  ...,  0.0128,  0.0073, -0.0076],
        [-0.0459,  0.0295,  0.0116,  ..., -0.0032,  0.0041, -0.0022],
        [-0.0121,  0.0017,  0.0079,  ..., -0.0165,  0.0134,  0.0066],
        ...,
        [ 0.0431,  0.0174,  0.0104,  ...,  0.0190, -0.0012, -0.0047],
        [ 0.0005,  0.0014, -0.0085,  ..., -0.0217,  0.0240, -0.0018],
        [-0.0077,  0.0185,  0.0006,  ..., -0.0371,  0.0031, -0.0150]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9126,  0.0510, -1.7520,  ..., -0.2537, -3.9004, -3.1094]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 21:04:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you deliver something, you are a deliverer
If you teach something, you are a teacher
If you choreograph something, you are a choreographer
If you write something, you are a writer
If you manage something, you are a manager
If you organise something, you are a organiser
If you recommend something, you are a recommender
If you receive something, you are a
2024-07-27 21:04:03 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you organise something, you are a organiser
If you choreograph something, you are a choreographer
If you manage something, you are a manager
If you teach something, you are a teacher
If you recommend something, you are a recommender
If you receive something, you are a receiver
If you write something, you are a
2024-07-27 21:04:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 21:06:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2328, -0.0702,  0.0717,  ..., -0.1072, -0.0281, -0.1417],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4941, -4.4961,  0.9590,  ...,  0.9561, -5.6328, -1.4395],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0329, -0.0188,  0.0072,  ..., -0.0052,  0.0187,  0.0104],
        [-0.0167,  0.0155,  0.0023,  ...,  0.0008,  0.0018,  0.0039],
        [ 0.0167,  0.0005,  0.0019,  ...,  0.0098,  0.0051,  0.0316],
        ...,
        [ 0.0096,  0.0273, -0.0061,  ...,  0.0176,  0.0036, -0.0201],
        [ 0.0056,  0.0075, -0.0043,  ..., -0.0204,  0.0205,  0.0098],
        [ 0.0028,  0.0176, -0.0046,  ..., -0.0236, -0.0049,  0.0156]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4424, -4.5469,  0.7471,  ...,  0.8359, -5.4297, -1.6367]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 21:06:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you deliver something, you are a deliverer
If you organise something, you are a organiser
If you choreograph something, you are a choreographer
If you manage something, you are a manager
If you teach something, you are a teacher
If you recommend something, you are a recommender
If you receive something, you are a receiver
If you write something, you are a
2024-07-27 21:06:48 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you receive something, you are a receiver
If you manage something, you are a manager
If you recommend something, you are a recommender
If you write something, you are a writer
If you teach something, you are a teacher
If you organise something, you are a organiser
If you choreograph something, you are a
2024-07-27 21:06:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 21:09:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0789,  0.3774, -0.0159,  ..., -0.0897, -0.4272, -0.1492],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4458, -3.5469,  2.6230,  ..., -1.0264, -3.1523, -1.8291],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0236, -0.0120,  0.0177,  ...,  0.0006,  0.0183, -0.0082],
        [-0.0157,  0.0450, -0.0116,  ...,  0.0189,  0.0155, -0.0214],
        [ 0.0055, -0.0128,  0.0158,  ..., -0.0169,  0.0023,  0.0115],
        ...,
        [ 0.0136,  0.0203,  0.0013,  ...,  0.0095,  0.0044, -0.0016],
        [-0.0063,  0.0064, -0.0117,  ..., -0.0171, -0.0023,  0.0026],
        [-0.0206,  0.0121,  0.0216,  ..., -0.0057, -0.0080,  0.0114]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3066, -3.4512,  2.7246,  ..., -1.3018, -2.7773, -1.6543]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 21:09:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you deliver something, you are a deliverer
If you receive something, you are a receiver
If you manage something, you are a manager
If you recommend something, you are a recommender
If you write something, you are a writer
If you teach something, you are a teacher
If you organise something, you are a organiser
If you choreograph something, you are a
2024-07-27 21:09:26 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you receive something, you are a receiver
If you write something, you are a writer
If you recommend something, you are a recommender
If you manage something, you are a manager
If you choreograph something, you are a choreographer
If you teach something, you are a teacher
If you organise something, you are a
2024-07-27 21:09:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 21:12:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0574,  0.3281, -0.0422,  ..., -0.1232, -0.0654, -0.0976],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3330, -3.6621,  1.3076,  ...,  1.1055, -3.2363, -5.4844],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0311,  0.0181, -0.0029,  ...,  0.0001, -0.0039, -0.0159],
        [-0.0219, -0.0115, -0.0033,  ..., -0.0130,  0.0106, -0.0033],
        [ 0.0052,  0.0139,  0.0018,  ..., -0.0026, -0.0088,  0.0142],
        ...,
        [ 0.0205,  0.0250,  0.0119,  ...,  0.0078, -0.0100,  0.0102],
        [-0.0172,  0.0161, -0.0045,  ...,  0.0045,  0.0053, -0.0228],
        [ 0.0077, -0.0011,  0.0180,  ..., -0.0107, -0.0088,  0.0054]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3425, -3.7207,  1.6709,  ...,  0.9214, -2.9375, -5.6406]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 21:12:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you deliver something, you are a deliverer
If you receive something, you are a receiver
If you write something, you are a writer
If you recommend something, you are a recommender
If you manage something, you are a manager
If you choreograph something, you are a choreographer
If you teach something, you are a teacher
If you organise something, you are a
2024-07-27 21:12:07 root INFO     [order_1_approx] starting weight calculation for If you recommend something, you are a recommender
If you deliver something, you are a deliverer
If you receive something, you are a receiver
If you manage something, you are a manager
If you write something, you are a writer
If you organise something, you are a organiser
If you choreograph something, you are a choreographer
If you teach something, you are a
2024-07-27 21:12:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 21:14:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2500,  0.2756,  0.0625,  ...,  0.0765, -0.0906, -0.0524],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0137, -3.3477,  5.3672,  ...,  1.9824, -4.4531, -5.5000],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0144, -0.0003, -0.0029,  ...,  0.0013,  0.0151, -0.0003],
        [-0.0196, -0.0062,  0.0025,  ..., -0.0033,  0.0179, -0.0064],
        [ 0.0066,  0.0236,  0.0052,  ...,  0.0229,  0.0015,  0.0231],
        ...,
        [ 0.0205,  0.0303,  0.0013,  ...,  0.0036, -0.0141,  0.0095],
        [-0.0112,  0.0093,  0.0007,  ...,  0.0092,  0.0074,  0.0142],
        [-0.0047, -0.0052,  0.0255,  ...,  0.0137,  0.0084, -0.0092]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8408, -3.3203,  5.3867,  ...,  1.8926, -4.4180, -5.6211]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 21:14:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you recommend something, you are a recommender
If you deliver something, you are a deliverer
If you receive something, you are a receiver
If you manage something, you are a manager
If you write something, you are a writer
If you organise something, you are a organiser
If you choreograph something, you are a choreographer
If you teach something, you are a
2024-07-27 21:14:50 root INFO     [order_1_approx] starting weight calculation for If you teach something, you are a teacher
If you choreograph something, you are a choreographer
If you write something, you are a writer
If you manage something, you are a manager
If you organise something, you are a organiser
If you deliver something, you are a deliverer
If you receive something, you are a receiver
If you recommend something, you are a
2024-07-27 21:14:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 21:17:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2238,  0.2527,  0.1646,  ...,  0.1379, -0.1362, -0.1218],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2461, -1.7275,  2.0488,  ...,  2.1992, -5.8438, -3.8223],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.5116e-02, -3.4065e-03,  2.4323e-02,  ...,  1.7700e-02,
         -2.6123e-02,  1.9547e-02],
        [-2.2217e-02,  4.0405e-02,  1.0796e-03,  ...,  8.4877e-04,
          1.9623e-02,  3.3340e-03],
        [ 3.0518e-05, -4.6921e-03,  7.4463e-03,  ..., -1.3664e-02,
         -3.9368e-02,  1.1871e-02],
        ...,
        [ 4.3564e-03, -6.2790e-03, -5.7125e-04,  ...,  4.3884e-02,
          1.0071e-03,  1.9287e-02],
        [-1.4832e-02,  1.8433e-02, -1.3443e-02,  ..., -4.4647e-02,
          1.8341e-02, -1.3672e-02],
        [-7.1259e-03,  1.1795e-02, -7.3013e-03,  ..., -3.5461e-02,
         -3.5919e-02, -1.3046e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0938, -1.9150,  2.1953,  ...,  2.5684, -5.6953, -4.2734]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 21:17:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you teach something, you are a teacher
If you choreograph something, you are a choreographer
If you write something, you are a writer
If you manage something, you are a manager
If you organise something, you are a organiser
If you deliver something, you are a deliverer
If you receive something, you are a receiver
If you recommend something, you are a
2024-07-27 21:17:35 root INFO     [order_1_approx] starting weight calculation for If you write something, you are a writer
If you organise something, you are a organiser
If you deliver something, you are a deliverer
If you receive something, you are a receiver
If you teach something, you are a teacher
If you recommend something, you are a recommender
If you choreograph something, you are a choreographer
If you manage something, you are a
2024-07-27 21:17:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 21:20:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1626,  0.3147,  0.0012,  ...,  0.0592, -0.1167, -0.3513],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0508, -2.7930,  2.3633,  ..., -0.4055, -3.7812, -4.4375],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0354,  0.0036,  0.0060,  ..., -0.0120,  0.0071, -0.0123],
        [-0.0052,  0.0230,  0.0059,  ...,  0.0057,  0.0331, -0.0008],
        [-0.0065,  0.0035,  0.0209,  ..., -0.0099, -0.0075,  0.0043],
        ...,
        [ 0.0056,  0.0259,  0.0196,  ...,  0.0190, -0.0004, -0.0027],
        [-0.0328,  0.0065, -0.0045,  ...,  0.0075,  0.0051,  0.0088],
        [ 0.0186, -0.0067,  0.0136,  ..., -0.0260, -0.0151, -0.0204]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3555, -3.1133,  2.5215,  ..., -0.2981, -3.3711, -4.7031]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 21:20:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you write something, you are a writer
If you organise something, you are a organiser
If you deliver something, you are a deliverer
If you receive something, you are a receiver
If you teach something, you are a teacher
If you recommend something, you are a recommender
If you choreograph something, you are a choreographer
If you manage something, you are a
2024-07-27 21:20:20 root INFO     total operator prediction time: 1311.7816333770752 seconds
2024-07-27 21:20:20 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on over+adj_reg
2024-07-27 21:20:20 root INFO     building operator over+adj_reg
2024-07-27 21:20:20 root INFO     [order_1_approx] starting weight calculation for If something is too dressed, it is overdressed
If something is too laid, it is overlaid
If something is too heard, it is overheard
If something is too stretched, it is overstretched
If something is too represented, it is overrepresented
If something is too taken, it is overtaken
If something is too ambitious, it is overambitious
If something is too heated, it is
2024-07-27 21:20:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 21:23:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1891, -0.4277, -0.0498,  ...,  0.0803, -0.4348,  0.1473],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5059, -1.8633,  0.2583,  ..., -0.1084, -1.6250, -2.7832],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0348,  0.0176,  0.0125,  ..., -0.0195, -0.0038,  0.0040],
        [-0.0031,  0.0268,  0.0189,  ...,  0.0044, -0.0124,  0.0137],
        [ 0.0025, -0.0049,  0.0091,  ...,  0.0203,  0.0066, -0.0008],
        ...,
        [-0.0177,  0.0379, -0.0008,  ...,  0.0557,  0.0050, -0.0136],
        [ 0.0293, -0.0111, -0.0189,  ...,  0.0039,  0.0185, -0.0181],
        [-0.0171, -0.0168,  0.0135,  ...,  0.0248, -0.0164,  0.0235]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0605, -1.9404, -0.0215,  ..., -0.1658, -1.8623, -2.6992]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 21:23:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too dressed, it is overdressed
If something is too laid, it is overlaid
If something is too heard, it is overheard
If something is too stretched, it is overstretched
If something is too represented, it is overrepresented
If something is too taken, it is overtaken
If something is too ambitious, it is overambitious
If something is too heated, it is
2024-07-27 21:23:06 root INFO     [order_1_approx] starting weight calculation for If something is too represented, it is overrepresented
If something is too taken, it is overtaken
If something is too ambitious, it is overambitious
If something is too heated, it is overheated
If something is too stretched, it is overstretched
If something is too dressed, it is overdressed
If something is too laid, it is overlaid
If something is too heard, it is
2024-07-27 21:23:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 21:25:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1080, -0.1134, -0.0515,  ..., -0.0947, -0.2175,  0.0918],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9590, -2.4883,  0.2881,  ...,  0.4685, -1.6221, -4.2812],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0355,  0.0207, -0.0070,  ...,  0.0300,  0.0243,  0.0111],
        [-0.0593,  0.0501,  0.0188,  ..., -0.0196, -0.0199, -0.0349],
        [ 0.0271,  0.0212,  0.0388,  ...,  0.0154, -0.0202,  0.0275],
        ...,
        [ 0.0087, -0.0103, -0.0094,  ...,  0.0359,  0.0104,  0.0070],
        [-0.0097, -0.0367, -0.0092,  ..., -0.0397,  0.0422, -0.0050],
        [ 0.0071,  0.0078,  0.0080,  ...,  0.0429, -0.0262,  0.0355]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1953, -2.4414,  0.8022,  ...,  0.5454, -1.7959, -4.2344]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 21:25:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too represented, it is overrepresented
If something is too taken, it is overtaken
If something is too ambitious, it is overambitious
If something is too heated, it is overheated
If something is too stretched, it is overstretched
If something is too dressed, it is overdressed
If something is too laid, it is overlaid
If something is too heard, it is
2024-07-27 21:25:50 root INFO     [order_1_approx] starting weight calculation for If something is too heated, it is overheated
If something is too taken, it is overtaken
If something is too heard, it is overheard
If something is too laid, it is overlaid
If something is too stretched, it is overstretched
If something is too dressed, it is overdressed
If something is too ambitious, it is overambitious
If something is too represented, it is
2024-07-27 21:25:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 21:28:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0753,  0.1456, -0.2163,  ..., -0.1052, -0.2190,  0.0867],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1016, -2.3594,  0.3608,  ..., -0.4319, -1.9023, -3.4355],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0446, -0.0020,  0.0135,  ..., -0.0048, -0.0004,  0.0116],
        [-0.0343,  0.0319,  0.0287,  ..., -0.0034, -0.0021, -0.0103],
        [ 0.0064,  0.0178,  0.0444,  ..., -0.0034, -0.0130,  0.0276],
        ...,
        [ 0.0162, -0.0105, -0.0158,  ...,  0.0271, -0.0401,  0.0209],
        [-0.0064, -0.0114, -0.0080,  ..., -0.0266,  0.0374, -0.0053],
        [-0.0125, -0.0007, -0.0130,  ...,  0.0069, -0.0230,  0.0461]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4160, -2.6816,  0.3044,  ..., -0.4802, -1.6982, -3.5215]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 21:28:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too heated, it is overheated
If something is too taken, it is overtaken
If something is too heard, it is overheard
If something is too laid, it is overlaid
If something is too stretched, it is overstretched
If something is too dressed, it is overdressed
If something is too ambitious, it is overambitious
If something is too represented, it is
2024-07-27 21:28:36 root INFO     [order_1_approx] starting weight calculation for If something is too ambitious, it is overambitious
If something is too dressed, it is overdressed
If something is too heard, it is overheard
If something is too taken, it is overtaken
If something is too represented, it is overrepresented
If something is too stretched, it is overstretched
If something is too heated, it is overheated
If something is too laid, it is
2024-07-27 21:28:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 21:31:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1376,  0.2172,  0.0111,  ..., -0.1151, -0.4990,  0.1270],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0234, -2.9727,  0.6157,  ...,  1.3330, -2.5117, -2.1621],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.4280e-02, -7.7744e-03,  3.8147e-03,  ...,  8.0719e-03,
         -2.3361e-02,  1.1658e-02],
        [-6.8741e-03,  5.1453e-02,  5.1231e-03,  ..., -1.1463e-03,
         -5.1041e-03, -2.0294e-02],
        [ 9.7351e-03,  5.3596e-03,  4.9225e-02,  ..., -1.0162e-02,
         -2.8824e-02, -5.0545e-03],
        ...,
        [ 1.4526e-02,  2.0462e-02,  6.1035e-05,  ...,  4.8920e-02,
          1.6586e-02, -1.7593e-02],
        [-1.1688e-02, -2.3773e-02,  1.6193e-03,  ..., -1.4793e-02,
          7.2449e-02, -7.8278e-03],
        [-5.9738e-03, -1.8219e-02, -1.7490e-03,  ...,  1.8875e-02,
          4.1847e-03,  2.5604e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3867, -3.1758,  0.9927,  ...,  1.5254, -2.7637, -2.1504]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 21:31:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too ambitious, it is overambitious
If something is too dressed, it is overdressed
If something is too heard, it is overheard
If something is too taken, it is overtaken
If something is too represented, it is overrepresented
If something is too stretched, it is overstretched
If something is too heated, it is overheated
If something is too laid, it is
2024-07-27 21:31:21 root INFO     [order_1_approx] starting weight calculation for If something is too stretched, it is overstretched
If something is too ambitious, it is overambitious
If something is too heated, it is overheated
If something is too heard, it is overheard
If something is too taken, it is overtaken
If something is too represented, it is overrepresented
If something is too laid, it is overlaid
If something is too dressed, it is
2024-07-27 21:31:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 21:34:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0894, -0.2505, -0.0707,  ..., -0.1453, -0.3713, -0.0317],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4189, -4.4492, -0.5322,  ...,  1.9785, -4.1406, -2.2422],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0077, -0.0197, -0.0269,  ..., -0.0132,  0.0143, -0.0287],
        [-0.0113,  0.0032,  0.0243,  ..., -0.0068, -0.0105,  0.0099],
        [ 0.0257,  0.0086,  0.0273,  ..., -0.0047,  0.0041,  0.0264],
        ...,
        [ 0.0186,  0.0305,  0.0140,  ...,  0.0447, -0.0070, -0.0124],
        [-0.0090, -0.0079, -0.0079,  ..., -0.0149,  0.0222, -0.0217],
        [-0.0114,  0.0036,  0.0202,  ...,  0.0273, -0.0209,  0.0047]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4160, -4.3359, -0.8916,  ...,  2.1582, -3.5078, -2.3652]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 21:34:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too stretched, it is overstretched
If something is too ambitious, it is overambitious
If something is too heated, it is overheated
If something is too heard, it is overheard
If something is too taken, it is overtaken
If something is too represented, it is overrepresented
If something is too laid, it is overlaid
If something is too dressed, it is
2024-07-27 21:34:04 root INFO     [order_1_approx] starting weight calculation for If something is too heated, it is overheated
If something is too laid, it is overlaid
If something is too ambitious, it is overambitious
If something is too dressed, it is overdressed
If something is too stretched, it is overstretched
If something is too represented, it is overrepresented
If something is too heard, it is overheard
If something is too taken, it is
2024-07-27 21:34:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 21:36:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1433,  0.0585, -0.0251,  ..., -0.0720, -0.2817,  0.1663],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3809, -3.4258, -0.2612,  ...,  0.0061, -1.8984, -2.8535],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0509, -0.0078,  0.0058,  ..., -0.0086,  0.0018,  0.0081],
        [-0.0010,  0.0435,  0.0139,  ...,  0.0134, -0.0261,  0.0017],
        [ 0.0175, -0.0229,  0.0256,  ...,  0.0105,  0.0216, -0.0003],
        ...,
        [ 0.0066, -0.0100, -0.0128,  ...,  0.0408,  0.0113, -0.0087],
        [-0.0362,  0.0113,  0.0017,  ..., -0.0173,  0.0448, -0.0049],
        [ 0.0052, -0.0065, -0.0115,  ...,  0.0018,  0.0052,  0.0215]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3281, -3.7148,  0.4351,  ...,  0.2600, -2.5703, -2.8320]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 21:36:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too heated, it is overheated
If something is too laid, it is overlaid
If something is too ambitious, it is overambitious
If something is too dressed, it is overdressed
If something is too stretched, it is overstretched
If something is too represented, it is overrepresented
If something is too heard, it is overheard
If something is too taken, it is
2024-07-27 21:36:49 root INFO     [order_1_approx] starting weight calculation for If something is too taken, it is overtaken
If something is too heated, it is overheated
If something is too heard, it is overheard
If something is too laid, it is overlaid
If something is too represented, it is overrepresented
If something is too dressed, it is overdressed
If something is too stretched, it is overstretched
If something is too ambitious, it is
2024-07-27 21:36:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 21:39:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1912, -0.0247, -0.2080,  ...,  0.1514, -0.2627,  0.1694],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5645, -3.5508,  0.6733,  ...,  0.5215, -1.7568, -2.5195],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0145, -0.0022,  0.0072,  ..., -0.0117, -0.0113,  0.0010],
        [-0.0042,  0.0200,  0.0194,  ..., -0.0066, -0.0048, -0.0006],
        [ 0.0052,  0.0119,  0.0349,  ...,  0.0047,  0.0156, -0.0041],
        ...,
        [ 0.0166,  0.0225,  0.0115,  ...,  0.0026, -0.0118, -0.0271],
        [ 0.0261,  0.0134,  0.0316,  ...,  0.0130, -0.0007, -0.0034],
        [-0.0086, -0.0036, -0.0163,  ..., -0.0030,  0.0015,  0.0135]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5547, -3.4336,  0.2505,  ...,  0.3330, -1.8320, -2.6113]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 21:39:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too taken, it is overtaken
If something is too heated, it is overheated
If something is too heard, it is overheard
If something is too laid, it is overlaid
If something is too represented, it is overrepresented
If something is too dressed, it is overdressed
If something is too stretched, it is overstretched
If something is too ambitious, it is
2024-07-27 21:39:36 root INFO     [order_1_approx] starting weight calculation for If something is too dressed, it is overdressed
If something is too ambitious, it is overambitious
If something is too heard, it is overheard
If something is too represented, it is overrepresented
If something is too taken, it is overtaken
If something is too laid, it is overlaid
If something is too heated, it is overheated
If something is too stretched, it is
2024-07-27 21:39:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 21:42:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2559, -0.4368,  0.0814,  ...,  0.0424, -0.2301,  0.1641],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2695, -3.8145,  0.3022,  ...,  0.2256,  0.1875, -2.5352],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0283,  0.0138, -0.0078,  ...,  0.0078,  0.0244,  0.0087],
        [ 0.0054,  0.0259,  0.0095,  ..., -0.0056, -0.0086,  0.0020],
        [ 0.0245,  0.0118,  0.0448,  ...,  0.0093,  0.0190, -0.0052],
        ...,
        [ 0.0208,  0.0068,  0.0046,  ...,  0.0353, -0.0044, -0.0053],
        [-0.0144,  0.0014, -0.0064,  ..., -0.0087, -0.0076, -0.0253],
        [-0.0130, -0.0036,  0.0008,  ...,  0.0035, -0.0121,  0.0192]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3242, -3.8887,  0.1958,  ...,  0.1338,  0.2030, -2.5098]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 21:42:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too dressed, it is overdressed
If something is too ambitious, it is overambitious
If something is too heard, it is overheard
If something is too represented, it is overrepresented
If something is too taken, it is overtaken
If something is too laid, it is overlaid
If something is too heated, it is overheated
If something is too stretched, it is
2024-07-27 21:42:22 root INFO     total operator prediction time: 1321.7572693824768 seconds
2024-07-27 21:42:22 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj+ly_reg
2024-07-27 21:42:22 root INFO     building operator adj+ly_reg
2024-07-27 21:42:22 root INFO     [order_1_approx] starting weight calculation for The adjective form of huge is hugely
The adjective form of popular is popularly
The adjective form of similar is similarly
The adjective form of internal is internally
The adjective form of visual is visually
The adjective form of decided is decidedly
The adjective form of political is politically
The adjective form of historical is
2024-07-27 21:42:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 21:45:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1130,  0.0920, -0.1125,  ..., -0.1758, -0.2095,  0.0325],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2683, -1.4971,  0.8228,  ..., -3.7012, -3.1406, -1.9990],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0457, -0.0237,  0.0044,  ...,  0.0107, -0.0110,  0.0296],
        [-0.0070,  0.0413,  0.0043,  ...,  0.0014, -0.0059, -0.0294],
        [ 0.0323, -0.0137,  0.0091,  ...,  0.0174, -0.0327,  0.0318],
        ...,
        [ 0.0345, -0.0005, -0.0518,  ...,  0.0527,  0.0197,  0.0030],
        [-0.0105, -0.0131, -0.0424,  ...,  0.0047,  0.0486, -0.0140],
        [ 0.0194, -0.0039,  0.0179,  ...,  0.0051, -0.0225, -0.0168]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0415, -1.5361,  1.2217,  ..., -3.6738, -3.1094, -2.1016]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 21:45:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of huge is hugely
The adjective form of popular is popularly
The adjective form of similar is similarly
The adjective form of internal is internally
The adjective form of visual is visually
The adjective form of decided is decidedly
The adjective form of political is politically
The adjective form of historical is
2024-07-27 21:45:08 root INFO     [order_1_approx] starting weight calculation for The adjective form of popular is popularly
The adjective form of huge is hugely
The adjective form of political is politically
The adjective form of similar is similarly
The adjective form of decided is decidedly
The adjective form of historical is historically
The adjective form of internal is internally
The adjective form of visual is
2024-07-27 21:45:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 21:47:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0612, -0.0125,  0.0720,  ...,  0.0537, -0.1992, -0.0421],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6260, -3.1758,  0.9888,  ..., -2.1992, -1.4707, -1.3096],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0547, -0.0504, -0.0050,  ..., -0.0170,  0.0113,  0.0384],
        [ 0.0042,  0.0583,  0.0314,  ..., -0.0044, -0.0224, -0.0227],
        [ 0.0518, -0.0328,  0.0435,  ...,  0.0160, -0.0246,  0.0507],
        ...,
        [ 0.0157,  0.0207, -0.0206,  ...,  0.0464, -0.0025, -0.0360],
        [ 0.0112,  0.0202, -0.0679,  ..., -0.0134,  0.0291, -0.0147],
        [-0.0129,  0.0403,  0.0126,  ...,  0.0396, -0.0277, -0.0097]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2507, -3.0156,  0.7622,  ..., -1.5352, -1.7441, -1.5859]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 21:47:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of popular is popularly
The adjective form of huge is hugely
The adjective form of political is politically
The adjective form of similar is similarly
The adjective form of decided is decidedly
The adjective form of historical is historically
The adjective form of internal is internally
The adjective form of visual is
2024-07-27 21:47:55 root INFO     [order_1_approx] starting weight calculation for The adjective form of historical is historically
The adjective form of huge is hugely
The adjective form of internal is internally
The adjective form of visual is visually
The adjective form of political is politically
The adjective form of decided is decidedly
The adjective form of popular is popularly
The adjective form of similar is
2024-07-27 21:47:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 21:50:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0521, -0.3787, -0.0208,  ...,  0.1248, -0.1290,  0.2058],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5913, -0.9131,  1.2285,  ..., -2.3926, -0.0874, -1.3193],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0550, -0.0361, -0.0120,  ...,  0.0260,  0.0657, -0.0043],
        [-0.0403,  0.0336,  0.0163,  ..., -0.0140,  0.0253, -0.0037],
        [ 0.0056,  0.0157,  0.0159,  ..., -0.0237, -0.0295, -0.0034],
        ...,
        [-0.0071,  0.0211,  0.0097,  ...,  0.0636, -0.0370, -0.0002],
        [ 0.0436,  0.0231,  0.0390,  ..., -0.0027, -0.0282, -0.0136],
        [ 0.0054, -0.0017,  0.0096,  ...,  0.0149, -0.0352,  0.0236]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2175, -0.3618,  1.4082,  ..., -2.5078, -0.3137, -1.8154]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 21:50:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of historical is historically
The adjective form of huge is hugely
The adjective form of internal is internally
The adjective form of visual is visually
The adjective form of political is politically
The adjective form of decided is decidedly
The adjective form of popular is popularly
The adjective form of similar is
2024-07-27 21:50:41 root INFO     [order_1_approx] starting weight calculation for The adjective form of similar is similarly
The adjective form of historical is historically
The adjective form of political is politically
The adjective form of internal is internally
The adjective form of visual is visually
The adjective form of popular is popularly
The adjective form of decided is decidedly
The adjective form of huge is
2024-07-27 21:50:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 21:53:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0013, -0.2084,  0.0076,  ...,  0.1562, -0.2119,  0.1423],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5625, -1.8223,  1.2139,  ..., -3.2461, -6.9531, -0.5088],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0788,  0.0212, -0.0054,  ...,  0.0036,  0.0099, -0.0042],
        [-0.0030, -0.0167,  0.0008,  ..., -0.0037, -0.0053,  0.0071],
        [ 0.0271, -0.0261,  0.0311,  ...,  0.0034,  0.0131,  0.0690],
        ...,
        [ 0.0116, -0.0089,  0.0407,  ...,  0.0433,  0.0180, -0.0546],
        [ 0.0198, -0.0394, -0.0152,  ...,  0.0329,  0.0207,  0.0108],
        [-0.0272, -0.0193,  0.0135,  ...,  0.0271, -0.0268,  0.0056]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4990, -2.2051,  1.4980,  ..., -3.0840, -7.4297, -0.4980]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 21:53:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of similar is similarly
The adjective form of historical is historically
The adjective form of political is politically
The adjective form of internal is internally
The adjective form of visual is visually
The adjective form of popular is popularly
The adjective form of decided is decidedly
The adjective form of huge is
2024-07-27 21:53:26 root INFO     [order_1_approx] starting weight calculation for The adjective form of historical is historically
The adjective form of popular is popularly
The adjective form of similar is similarly
The adjective form of political is politically
The adjective form of visual is visually
The adjective form of huge is hugely
The adjective form of decided is decidedly
The adjective form of internal is
2024-07-27 21:53:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 21:56:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1543, -0.1871,  0.0328,  ...,  0.0584, -0.1252,  0.3647],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1858, -0.9185,  1.0938,  ..., -4.0234,  0.4163, -3.5527],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0643, -0.0330, -0.0486,  ...,  0.0152,  0.0070,  0.0399],
        [ 0.0338,  0.0656,  0.0392,  ..., -0.0578,  0.0126, -0.0455],
        [ 0.0676, -0.0377,  0.0380,  ...,  0.0118, -0.0156,  0.0676],
        ...,
        [-0.0345,  0.0368, -0.0076,  ...,  0.0765,  0.0273, -0.0542],
        [ 0.0071, -0.0085, -0.0578,  ...,  0.0206,  0.0257, -0.0365],
        [ 0.0070, -0.0114,  0.0043,  ..., -0.0033, -0.0171,  0.0404]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0161, -0.4788,  1.2490,  ..., -4.1680,  0.7842, -3.8887]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 21:56:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of historical is historically
The adjective form of popular is popularly
The adjective form of similar is similarly
The adjective form of political is politically
The adjective form of visual is visually
The adjective form of huge is hugely
The adjective form of decided is decidedly
The adjective form of internal is
2024-07-27 21:56:11 root INFO     [order_1_approx] starting weight calculation for The adjective form of internal is internally
The adjective form of visual is visually
The adjective form of similar is similarly
The adjective form of political is politically
The adjective form of popular is popularly
The adjective form of huge is hugely
The adjective form of historical is historically
The adjective form of decided is
2024-07-27 21:56:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 21:58:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0426, -0.0285, -0.2261,  ...,  0.0402, -0.3096,  0.2491],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.2773, -4.4141,  2.5742,  ..., -0.4600, -2.9922, -1.3711],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.9429e-02, -1.2627e-02, -4.1260e-02,  ...,  1.4450e-02,
         -2.8419e-04,  2.0233e-02],
        [-2.6947e-02,  2.6947e-02,  4.1107e-02,  ..., -2.1912e-02,
          4.0710e-02, -5.3711e-02],
        [ 3.5858e-02, -1.4282e-02, -2.3174e-03,  ..., -3.3386e-02,
         -2.4200e-02, -1.6479e-02],
        ...,
        [-1.6129e-02,  1.7136e-02,  3.0518e-05,  ...,  5.2246e-02,
          8.5983e-03, -1.7136e-02],
        [-1.9424e-02,  1.0086e-02, -1.9302e-03,  ...,  1.7456e-02,
          2.5848e-02,  1.2489e-02],
        [-2.1347e-02,  3.6392e-03,  3.5736e-02,  ..., -1.8005e-02,
         -6.3629e-03, -2.0862e-04]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.1328, -4.1172,  3.2051,  ..., -0.5146, -3.6445, -2.0215]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 21:58:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of internal is internally
The adjective form of visual is visually
The adjective form of similar is similarly
The adjective form of political is politically
The adjective form of popular is popularly
The adjective form of huge is hugely
The adjective form of historical is historically
The adjective form of decided is
2024-07-27 21:58:57 root INFO     [order_1_approx] starting weight calculation for The adjective form of similar is similarly
The adjective form of huge is hugely
The adjective form of historical is historically
The adjective form of decided is decidedly
The adjective form of popular is popularly
The adjective form of internal is internally
The adjective form of visual is visually
The adjective form of political is
2024-07-27 21:58:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 22:01:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0115,  0.1038,  0.0760,  ...,  0.0440, -0.2656,  0.1539],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7666, -2.5977,  0.7749,  ..., -2.2695, -0.2834,  0.1377],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0075, -0.0040, -0.0116,  ...,  0.0186, -0.0036,  0.0272],
        [-0.0123,  0.0288,  0.0314,  ..., -0.0168,  0.0091, -0.0308],
        [ 0.0229, -0.0172, -0.0031,  ...,  0.0044, -0.0558, -0.0002],
        ...,
        [ 0.0082, -0.0192, -0.0120,  ...,  0.0510, -0.0051,  0.0007],
        [ 0.0104, -0.0178, -0.0303,  ..., -0.0032,  0.0175, -0.0383],
        [-0.0175,  0.0107, -0.0009,  ..., -0.0015, -0.0040, -0.0197]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0410, -2.6309,  0.6431,  ..., -2.2715, -0.2223,  0.0737]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 22:01:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of similar is similarly
The adjective form of huge is hugely
The adjective form of historical is historically
The adjective form of decided is decidedly
The adjective form of popular is popularly
The adjective form of internal is internally
The adjective form of visual is visually
The adjective form of political is
2024-07-27 22:01:44 root INFO     [order_1_approx] starting weight calculation for The adjective form of similar is similarly
The adjective form of political is politically
The adjective form of huge is hugely
The adjective form of visual is visually
The adjective form of internal is internally
The adjective form of historical is historically
The adjective form of decided is decidedly
The adjective form of popular is
2024-07-27 22:01:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 22:04:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1572,  0.0361,  0.1768,  ...,  0.2852, -0.2395,  0.1672],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7100, -2.3027, -1.6338,  ..., -0.5054, -2.3828, -0.7734],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0028, -0.0136,  0.0073,  ..., -0.0213,  0.0469,  0.0289],
        [-0.0099,  0.0123,  0.0081,  ..., -0.0173, -0.0004, -0.0272],
        [ 0.0400, -0.0275,  0.0185,  ..., -0.0360,  0.0003, -0.0057],
        ...,
        [ 0.0515, -0.0031,  0.0146,  ...,  0.1069, -0.0334,  0.0040],
        [ 0.0423, -0.0258,  0.0151,  ...,  0.0081,  0.0041, -0.0257],
        [-0.0111, -0.0168,  0.0175,  ...,  0.0380,  0.0082, -0.0147]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0645, -2.4961, -1.9492,  ..., -0.4319, -2.3086, -1.6348]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 22:04:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of similar is similarly
The adjective form of political is politically
The adjective form of huge is hugely
The adjective form of visual is visually
The adjective form of internal is internally
The adjective form of historical is historically
The adjective form of decided is decidedly
The adjective form of popular is
2024-07-27 22:04:29 root INFO     total operator prediction time: 1327.068523645401 seconds
2024-07-27 22:04:29 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+tion_irreg
2024-07-27 22:04:29 root INFO     building operator verb+tion_irreg
2024-07-27 22:04:29 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To specialize results in specialization
To globalize results in globalization
To imagine results in imagination
To privatize results in privatization
To condense results in condensation
To colonize results in colonization
To deprive results in
2024-07-27 22:04:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 22:07:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2375,  0.2549, -0.1816,  ...,  0.0106, -0.1519, -0.1689],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1699, -2.9688,  2.4648,  ...,  0.6074, -1.5049, -1.7490],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0289,  0.0054, -0.0099,  ..., -0.0300,  0.0118,  0.0174],
        [-0.0148,  0.0242,  0.0052,  ...,  0.0125, -0.0019,  0.0093],
        [-0.0189, -0.0048, -0.0016,  ...,  0.0230,  0.0054,  0.0007],
        ...,
        [ 0.0065, -0.0007,  0.0067,  ...,  0.0234,  0.0230,  0.0134],
        [ 0.0195, -0.0114, -0.0055,  ...,  0.0003,  0.0061, -0.0279],
        [-0.0026, -0.0222,  0.0146,  ...,  0.0125, -0.0026,  0.0230]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1782, -2.6816,  2.3008,  ...,  0.2383, -1.8389, -1.5762]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 22:07:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To characterize results in characterization
To specialize results in specialization
To globalize results in globalization
To imagine results in imagination
To privatize results in privatization
To condense results in condensation
To colonize results in colonization
To deprive results in
2024-07-27 22:07:13 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To globalize results in globalization
To imagine results in imagination
To colonize results in colonization
To condense results in condensation
To deprive results in deprivation
To privatize results in privatization
To specialize results in
2024-07-27 22:07:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 22:09:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0768,  0.1980, -0.1951,  ..., -0.1875, -0.2808, -0.1951],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5664, -1.7266,  1.3242,  ...,  1.2695, -2.2246, -2.7383],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0567, -0.0193,  0.0219,  ..., -0.0085, -0.0097,  0.0049],
        [-0.0353,  0.0470,  0.0098,  ...,  0.0002,  0.0414,  0.0067],
        [-0.0230, -0.0110,  0.0292,  ...,  0.0180, -0.0231, -0.0161],
        ...,
        [-0.0049,  0.0115,  0.0130,  ...,  0.0587, -0.0054, -0.0031],
        [-0.0008, -0.0317,  0.0056,  ...,  0.0257,  0.0320, -0.0075],
        [-0.0071, -0.0029,  0.0070,  ..., -0.0088,  0.0031,  0.0562]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9248, -1.0898,  1.0742,  ...,  1.2842, -2.3906, -2.3809]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 22:09:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To characterize results in characterization
To globalize results in globalization
To imagine results in imagination
To colonize results in colonization
To condense results in condensation
To deprive results in deprivation
To privatize results in privatization
To specialize results in
2024-07-27 22:09:59 root INFO     [order_1_approx] starting weight calculation for To privatize results in privatization
To specialize results in specialization
To deprive results in deprivation
To colonize results in colonization
To imagine results in imagination
To characterize results in characterization
To condense results in condensation
To globalize results in
2024-07-27 22:09:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 22:12:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0464,  0.4138, -0.2769,  ..., -0.1376, -0.1249, -0.1024],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0205, -2.7129,  2.0566,  ..., -0.0112, -2.0742, -1.9150],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0279, -0.0002,  0.0097,  ..., -0.0062, -0.0150,  0.0032],
        [-0.0135,  0.0173,  0.0004,  ...,  0.0251,  0.0096, -0.0011],
        [-0.0147,  0.0063,  0.0047,  ..., -0.0028, -0.0067, -0.0187],
        ...,
        [-0.0093, -0.0011,  0.0012,  ...,  0.0359, -0.0062, -0.0029],
        [-0.0189, -0.0080, -0.0093,  ...,  0.0237,  0.0185,  0.0114],
        [ 0.0069, -0.0045,  0.0071,  ...,  0.0211, -0.0002,  0.0137]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7881, -2.4688,  2.0547,  ..., -0.3567, -2.7539, -1.6602]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 22:12:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To privatize results in privatization
To specialize results in specialization
To deprive results in deprivation
To colonize results in colonization
To imagine results in imagination
To characterize results in characterization
To condense results in condensation
To globalize results in
2024-07-27 22:12:41 root INFO     [order_1_approx] starting weight calculation for To privatize results in privatization
To globalize results in globalization
To deprive results in deprivation
To specialize results in specialization
To condense results in condensation
To characterize results in characterization
To colonize results in colonization
To imagine results in
2024-07-27 22:12:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 22:15:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0794,  0.3369,  0.4111,  ..., -0.1003, -0.2419, -0.0319],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5186, -3.6484,  6.7812,  ...,  3.0156, -1.6465, -0.4531],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0023,  0.0027, -0.0260,  ..., -0.0754, -0.0715, -0.0362],
        [ 0.0180,  0.0587, -0.0017,  ...,  0.0498,  0.0062,  0.0058],
        [-0.0186, -0.0099,  0.0145,  ...,  0.0522, -0.0316,  0.0230],
        ...,
        [ 0.0103,  0.0099,  0.0081,  ...,  0.0679,  0.0150, -0.0042],
        [-0.0064, -0.0025, -0.0001,  ..., -0.0315,  0.0544, -0.0576],
        [ 0.0097,  0.0443, -0.0013,  ...,  0.0453, -0.0439,  0.0097]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 9.7656e-04, -1.3809e+00,  6.4570e+00,  ...,  3.8730e+00,
         -2.4258e+00,  7.9883e-01]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SubBackward0>) 

                    
2024-07-27 22:15:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To privatize results in privatization
To globalize results in globalization
To deprive results in deprivation
To specialize results in specialization
To condense results in condensation
To characterize results in characterization
To colonize results in colonization
To imagine results in
2024-07-27 22:15:27 root INFO     [order_1_approx] starting weight calculation for To imagine results in imagination
To characterize results in characterization
To globalize results in globalization
To specialize results in specialization
To privatize results in privatization
To condense results in condensation
To deprive results in deprivation
To colonize results in
2024-07-27 22:15:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 22:18:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1315,  0.2769, -0.0718,  ..., -0.1423, -0.3257, -0.2625],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.8379, -1.4521,  4.2422,  ...,  0.5112, -0.7422, -2.7617],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0411, -0.0215,  0.0086,  ...,  0.0021,  0.0006,  0.0073],
        [-0.0200,  0.0124,  0.0043,  ...,  0.0099,  0.0101,  0.0081],
        [-0.0021,  0.0066,  0.0189,  ...,  0.0108, -0.0224,  0.0131],
        ...,
        [ 0.0053,  0.0043,  0.0062,  ...,  0.0097, -0.0242,  0.0060],
        [ 0.0025, -0.0015, -0.0077,  ...,  0.0181,  0.0364,  0.0172],
        [-0.0027,  0.0064,  0.0044,  ...,  0.0141, -0.0208,  0.0239]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.3984, -1.2578,  4.6133,  ...,  0.3047, -0.6230, -2.3867]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 22:18:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To imagine results in imagination
To characterize results in characterization
To globalize results in globalization
To specialize results in specialization
To privatize results in privatization
To condense results in condensation
To deprive results in deprivation
To colonize results in
2024-07-27 22:18:12 root INFO     [order_1_approx] starting weight calculation for To colonize results in colonization
To specialize results in specialization
To characterize results in characterization
To condense results in condensation
To deprive results in deprivation
To imagine results in imagination
To globalize results in globalization
To privatize results in
2024-07-27 22:18:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 22:20:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0579,  0.2798, -0.2253,  ..., -0.2483, -0.1877, -0.0519],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.6523, -3.6836,  2.3262,  ..., -2.4297, -0.7158, -2.0586],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0266, -0.0064, -0.0031,  ..., -0.0060, -0.0009,  0.0126],
        [-0.0178,  0.0087, -0.0094,  ...,  0.0077, -0.0028,  0.0073],
        [-0.0240, -0.0009,  0.0089,  ...,  0.0102, -0.0022,  0.0102],
        ...,
        [-0.0014, -0.0100, -0.0012,  ...,  0.0228,  0.0032,  0.0165],
        [ 0.0113, -0.0016, -0.0090,  ..., -0.0032,  0.0227, -0.0014],
        [-0.0008, -0.0061, -0.0003,  ...,  0.0144, -0.0151,  0.0147]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.2500, -3.6543,  2.5684,  ..., -2.5508, -0.9902, -1.9463]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 22:20:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To colonize results in colonization
To specialize results in specialization
To characterize results in characterization
To condense results in condensation
To deprive results in deprivation
To imagine results in imagination
To globalize results in globalization
To privatize results in
2024-07-27 22:20:56 root INFO     [order_1_approx] starting weight calculation for To specialize results in specialization
To globalize results in globalization
To characterize results in characterization
To deprive results in deprivation
To imagine results in imagination
To privatize results in privatization
To colonize results in colonization
To condense results in
2024-07-27 22:20:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 22:23:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0519,  0.0358, -0.0895,  ...,  0.0891, -0.5435,  0.0806],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0684, -3.7891,  3.2109,  ...,  1.0947, -1.1309, -1.0654],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0598, -0.0206, -0.0026,  ...,  0.0011, -0.0108,  0.0258],
        [-0.0246,  0.0325, -0.0034,  ...,  0.0193, -0.0200,  0.0054],
        [-0.0361, -0.0151,  0.0075,  ...,  0.0223,  0.0123, -0.0021],
        ...,
        [-0.0243,  0.0436,  0.0252,  ...,  0.0274, -0.0101,  0.0010],
        [-0.0074, -0.0195, -0.0142,  ..., -0.0105,  0.0326, -0.0275],
        [-0.0078, -0.0083, -0.0008,  ..., -0.0161, -0.0378,  0.0233]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2737, -3.5859,  2.9238,  ...,  1.2236, -1.2578, -1.0898]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 22:23:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To specialize results in specialization
To globalize results in globalization
To characterize results in characterization
To deprive results in deprivation
To imagine results in imagination
To privatize results in privatization
To colonize results in colonization
To condense results in
2024-07-27 22:23:40 root INFO     [order_1_approx] starting weight calculation for To specialize results in specialization
To condense results in condensation
To imagine results in imagination
To privatize results in privatization
To deprive results in deprivation
To colonize results in colonization
To globalize results in globalization
To characterize results in
2024-07-27 22:23:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 22:26:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0474,  0.1418, -0.0715,  ..., -0.1638, -0.4238, -0.2693],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.3652, -2.0352,  4.0195,  ...,  1.5430, -0.9180, -1.5557],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0247,  0.0252, -0.0364,  ..., -0.0646, -0.0091, -0.0157],
        [ 0.0415, -0.0089,  0.0595,  ...,  0.0559,  0.0051,  0.0373],
        [-0.0487,  0.0117, -0.0294,  ..., -0.0161,  0.0059, -0.0259],
        ...,
        [ 0.0237, -0.0233,  0.0273,  ...,  0.0424, -0.0042,  0.0367],
        [ 0.0144, -0.0024, -0.0172,  ...,  0.0085,  0.0202,  0.0222],
        [ 0.0190, -0.0236,  0.0367,  ...,  0.0264, -0.0107,  0.0316]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-3.9043, -0.3418,  3.6836,  ...,  2.4375, -0.9360, -0.9600]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 22:26:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To specialize results in specialization
To condense results in condensation
To imagine results in imagination
To privatize results in privatization
To deprive results in deprivation
To colonize results in colonization
To globalize results in globalization
To characterize results in
2024-07-27 22:26:25 root INFO     total operator prediction time: 1316.5450823307037 seconds
2024-07-27 22:26:25 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+able_reg
2024-07-27 22:26:25 root INFO     building operator verb+able_reg
2024-07-27 22:26:26 root INFO     [order_1_approx] starting weight calculation for If you can manage something, that thing is manageable
If you can write something, that thing is writeable
If you can define something, that thing is definable
If you can imagine something, that thing is imaginable
If you can protect something, that thing is protectable
If you can observe something, that thing is observable
If you can enjoy something, that thing is enjoyable
If you can explain something, that thing is
2024-07-27 22:26:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 22:29:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0388,  0.2264,  0.3545,  ..., -0.1281, -0.1034, -0.2673],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.1875,  0.1484,  3.2012,  ..., -3.2969, -7.6367, -0.2031],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.7673e-03, -1.6617e-02,  5.1117e-04,  ...,  5.0163e-04,
          5.7650e-04,  2.1255e-02],
        [-2.5391e-02,  3.8910e-02, -1.6830e-02,  ..., -2.9205e-02,
         -9.3460e-05, -1.1292e-03],
        [ 2.4887e-02, -1.7334e-02,  1.2421e-02,  ..., -3.0956e-03,
         -2.6245e-03, -7.8659e-03],
        ...,
        [ 3.4119e-02,  1.0269e-02,  4.4632e-04,  ...,  3.2440e-02,
          4.0131e-03, -1.6460e-03],
        [ 2.0065e-02, -6.7444e-03, -3.1982e-02,  ..., -2.1530e-02,
          3.7201e-02,  1.9852e-02],
        [-3.3283e-04, -2.1439e-03, -2.9648e-02,  ...,  5.1842e-03,
          5.1880e-03, -2.0554e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.9609,  0.3965,  3.4727,  ..., -3.5996, -8.0391, -0.1733]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 22:29:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can manage something, that thing is manageable
If you can write something, that thing is writeable
If you can define something, that thing is definable
If you can imagine something, that thing is imaginable
If you can protect something, that thing is protectable
If you can observe something, that thing is observable
If you can enjoy something, that thing is enjoyable
If you can explain something, that thing is
2024-07-27 22:29:06 root INFO     [order_1_approx] starting weight calculation for If you can enjoy something, that thing is enjoyable
If you can protect something, that thing is protectable
If you can write something, that thing is writeable
If you can define something, that thing is definable
If you can observe something, that thing is observable
If you can explain something, that thing is explainable
If you can manage something, that thing is manageable
If you can imagine something, that thing is
2024-07-27 22:29:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 22:31:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0940,  0.1082,  0.7134,  ...,  0.0322, -0.1748, -0.2971],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8560,  0.4192,  2.4180,  ..., -3.5820, -7.2266, -2.0918],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0067,  0.0031, -0.0201,  ..., -0.0008,  0.0121,  0.0020],
        [-0.0046,  0.0063,  0.0172,  ..., -0.0381, -0.0394,  0.0083],
        [ 0.0250, -0.0249,  0.0218,  ...,  0.0243, -0.0218, -0.0012],
        ...,
        [-0.0018, -0.0052,  0.0049,  ...,  0.0329, -0.0084, -0.0109],
        [-0.0040,  0.0061, -0.0110,  ..., -0.0352,  0.0388,  0.0188],
        [-0.0009,  0.0093,  0.0056,  ...,  0.0108, -0.0208,  0.0220]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6338,  0.4976,  2.0488,  ..., -3.2695, -6.8125, -2.4238]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 22:31:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can enjoy something, that thing is enjoyable
If you can protect something, that thing is protectable
If you can write something, that thing is writeable
If you can define something, that thing is definable
If you can observe something, that thing is observable
If you can explain something, that thing is explainable
If you can manage something, that thing is manageable
If you can imagine something, that thing is
2024-07-27 22:31:51 root INFO     [order_1_approx] starting weight calculation for If you can imagine something, that thing is imaginable
If you can manage something, that thing is manageable
If you can write something, that thing is writeable
If you can explain something, that thing is explainable
If you can define something, that thing is definable
If you can observe something, that thing is observable
If you can protect something, that thing is protectable
If you can enjoy something, that thing is
2024-07-27 22:31:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 22:34:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1047,  0.3481,  0.3430,  ..., -0.1160, -0.2773, -0.1034],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.9316, -0.9912, -1.3232,  ..., -1.7109, -8.0312, -2.9023],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0099, -0.0085,  0.0147,  ...,  0.0275, -0.0042,  0.0218],
        [-0.0247,  0.0025,  0.0142,  ..., -0.0096, -0.0090,  0.0005],
        [ 0.0196, -0.0352,  0.0281,  ...,  0.0064, -0.0379, -0.0147],
        ...,
        [ 0.0074, -0.0184,  0.0069,  ...,  0.0250, -0.0011, -0.0196],
        [ 0.0113,  0.0122, -0.0062,  ..., -0.0236,  0.0157,  0.0002],
        [-0.0051, -0.0203,  0.0242,  ..., -0.0098, -0.0501, -0.0118]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.9111, -0.9473, -1.4854,  ..., -1.4551, -7.8672, -3.0527]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 22:34:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can imagine something, that thing is imaginable
If you can manage something, that thing is manageable
If you can write something, that thing is writeable
If you can explain something, that thing is explainable
If you can define something, that thing is definable
If you can observe something, that thing is observable
If you can protect something, that thing is protectable
If you can enjoy something, that thing is
2024-07-27 22:34:38 root INFO     [order_1_approx] starting weight calculation for If you can explain something, that thing is explainable
If you can manage something, that thing is manageable
If you can protect something, that thing is protectable
If you can imagine something, that thing is imaginable
If you can observe something, that thing is observable
If you can enjoy something, that thing is enjoyable
If you can write something, that thing is writeable
If you can define something, that thing is
2024-07-27 22:34:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 22:37:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1036, -0.0634,  0.4897,  ...,  0.1077, -0.1860, -0.3555],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2129, -1.5781,  4.2969,  ..., -2.8398, -8.1797, -2.5391],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0187,  0.0040, -0.0009,  ...,  0.0002,  0.0076,  0.0073],
        [-0.0407,  0.0116,  0.0099,  ..., -0.0292, -0.0424, -0.0177],
        [ 0.0303, -0.0222,  0.0309,  ...,  0.0043,  0.0309, -0.0018],
        ...,
        [ 0.0047,  0.0062,  0.0214,  ...,  0.0133, -0.0027, -0.0132],
        [ 0.0111,  0.0020, -0.0063,  ..., -0.0121,  0.0112,  0.0426],
        [-0.0026,  0.0188,  0.0079,  ..., -0.0331, -0.0115,  0.0130]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1641, -1.5928,  4.1992,  ..., -2.6562, -8.1328, -2.7344]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 22:37:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can explain something, that thing is explainable
If you can manage something, that thing is manageable
If you can protect something, that thing is protectable
If you can imagine something, that thing is imaginable
If you can observe something, that thing is observable
If you can enjoy something, that thing is enjoyable
If you can write something, that thing is writeable
If you can define something, that thing is
2024-07-27 22:37:21 root INFO     [order_1_approx] starting weight calculation for If you can observe something, that thing is observable
If you can define something, that thing is definable
If you can imagine something, that thing is imaginable
If you can enjoy something, that thing is enjoyable
If you can protect something, that thing is protectable
If you can explain something, that thing is explainable
If you can manage something, that thing is manageable
If you can write something, that thing is
2024-07-27 22:37:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 22:40:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1418,  0.0761,  0.0920,  ..., -0.0155,  0.0140, -0.1345],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.4814, -1.3125,  0.6611,  ..., -3.1680, -6.6016,  0.2197],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0241, -0.0244,  0.0069,  ...,  0.0096,  0.0180,  0.0425],
        [ 0.0018,  0.0051, -0.0006,  ..., -0.0124,  0.0094,  0.0179],
        [ 0.0103, -0.0280,  0.0282,  ...,  0.0091, -0.0123,  0.0344],
        ...,
        [ 0.0118,  0.0133,  0.0082,  ...,  0.0336,  0.0076, -0.0080],
        [-0.0013,  0.0121,  0.0048,  ..., -0.0307,  0.0184,  0.0057],
        [ 0.0115, -0.0021,  0.0029,  ..., -0.0089, -0.0094, -0.0086]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.5586, -1.1016,  0.9658,  ..., -2.7520, -6.6680,  0.0542]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 22:40:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can observe something, that thing is observable
If you can define something, that thing is definable
If you can imagine something, that thing is imaginable
If you can enjoy something, that thing is enjoyable
If you can protect something, that thing is protectable
If you can explain something, that thing is explainable
If you can manage something, that thing is manageable
If you can write something, that thing is
2024-07-27 22:40:10 root INFO     [order_1_approx] starting weight calculation for If you can imagine something, that thing is imaginable
If you can define something, that thing is definable
If you can explain something, that thing is explainable
If you can enjoy something, that thing is enjoyable
If you can manage something, that thing is manageable
If you can write something, that thing is writeable
If you can observe something, that thing is observable
If you can protect something, that thing is
2024-07-27 22:40:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 22:42:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0696, -0.0184,  0.0596,  ...,  0.0397, -0.2217, -0.0933],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8799, -3.3535, -1.6738,  ..., -2.7227, -6.3750, -1.9219],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.8015e-02,  2.2949e-02, -1.0696e-02,  ...,  1.7090e-02,
         -2.0828e-03, -1.1616e-03],
        [-1.9165e-02,  1.0620e-02, -3.3474e-04,  ...,  1.9150e-03,
          1.2497e-02,  2.1332e-02],
        [ 8.1940e-03, -2.5650e-02, -8.3923e-05,  ..., -1.9623e-02,
         -7.1106e-03, -2.9388e-02],
        ...,
        [ 4.0802e-02,  2.2430e-02, -1.5411e-03,  ...,  7.5302e-03,
         -1.7487e-02, -3.4790e-02],
        [ 6.7291e-03, -1.8143e-02,  4.7302e-03,  ..., -1.9745e-02,
         -3.3417e-03, -2.8870e-02],
        [ 2.8824e-02, -1.3290e-02,  2.9709e-02,  ..., -1.0956e-02,
         -2.4460e-02, -1.3062e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0991, -2.8887, -1.6865,  ..., -2.4824, -6.1758, -2.3340]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 22:42:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can imagine something, that thing is imaginable
If you can define something, that thing is definable
If you can explain something, that thing is explainable
If you can enjoy something, that thing is enjoyable
If you can manage something, that thing is manageable
If you can write something, that thing is writeable
If you can observe something, that thing is observable
If you can protect something, that thing is
2024-07-27 22:42:54 root INFO     [order_1_approx] starting weight calculation for If you can define something, that thing is definable
If you can write something, that thing is writeable
If you can imagine something, that thing is imaginable
If you can explain something, that thing is explainable
If you can protect something, that thing is protectable
If you can enjoy something, that thing is enjoyable
If you can manage something, that thing is manageable
If you can observe something, that thing is
2024-07-27 22:42:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 22:45:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0662,  0.3386,  0.0826,  ..., -0.0548, -0.1364, -0.2690],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.4805, -1.9912, -0.5107,  ..., -3.9141, -5.3164, -0.9702],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.7059e-02, -1.4885e-02, -1.1658e-02,  ...,  2.8351e-02,
          4.5624e-03,  6.3400e-03],
        [-8.7738e-05,  1.7044e-02, -2.0885e-04,  ..., -2.1332e-02,
         -3.1372e-02, -1.9211e-02],
        [ 7.3700e-03, -1.1154e-02,  7.5035e-03,  ...,  6.4468e-03,
         -1.3702e-02, -1.3084e-03],
        ...,
        [ 2.4155e-02, -4.6120e-03, -1.8005e-02,  ...,  4.4128e-02,
         -1.2619e-02, -3.8086e-02],
        [-8.5068e-03, -2.6627e-02, -1.7670e-02,  ..., -2.5620e-02,
          2.1713e-02, -5.5618e-03],
        [-7.5455e-03,  1.2619e-02,  2.8137e-02,  ...,  1.0490e-02,
         -1.1475e-02,  1.2604e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.3496, -2.2578, -0.9316,  ..., -3.5156, -4.8125, -1.3926]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 22:45:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can define something, that thing is definable
If you can write something, that thing is writeable
If you can imagine something, that thing is imaginable
If you can explain something, that thing is explainable
If you can protect something, that thing is protectable
If you can enjoy something, that thing is enjoyable
If you can manage something, that thing is manageable
If you can observe something, that thing is
2024-07-27 22:45:39 root INFO     [order_1_approx] starting weight calculation for If you can imagine something, that thing is imaginable
If you can enjoy something, that thing is enjoyable
If you can observe something, that thing is observable
If you can define something, that thing is definable
If you can explain something, that thing is explainable
If you can protect something, that thing is protectable
If you can write something, that thing is writeable
If you can manage something, that thing is
2024-07-27 22:45:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 22:48:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0313,  0.3904,  0.1001,  ...,  0.0265, -0.2632, -0.2864],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4111, -1.3652,  0.4639,  ..., -3.2227, -6.4219, -2.9766],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0041,  0.0010,  0.0036,  ..., -0.0038,  0.0097,  0.0059],
        [-0.0047,  0.0315, -0.0166,  ...,  0.0044, -0.0243, -0.0032],
        [-0.0076, -0.0311,  0.0181,  ...,  0.0031,  0.0013, -0.0022],
        ...,
        [ 0.0294, -0.0174,  0.0178,  ...,  0.0348,  0.0092, -0.0110],
        [-0.0166,  0.0021, -0.0095,  ..., -0.0211,  0.0070,  0.0104],
        [ 0.0337, -0.0036,  0.0145,  ..., -0.0384,  0.0009, -0.0151]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6528, -0.8433,  0.5400,  ..., -3.2363, -6.2461, -3.4082]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 22:48:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can imagine something, that thing is imaginable
If you can enjoy something, that thing is enjoyable
If you can observe something, that thing is observable
If you can define something, that thing is definable
If you can explain something, that thing is explainable
If you can protect something, that thing is protectable
If you can write something, that thing is writeable
If you can manage something, that thing is
2024-07-27 22:48:25 root INFO     total operator prediction time: 1319.292775630951 seconds
2024-07-27 22:48:25 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on un+adj_reg
2024-07-27 22:48:25 root INFO     building operator un+adj_reg
2024-07-27 22:48:25 root INFO     [order_1_approx] starting weight calculation for The opposite of resolved is unresolved
The opposite of forgettable is unforgettable
The opposite of used is unused
The opposite of finished is unfinished
The opposite of sustainable is unsustainable
The opposite of changed is unchanged
The opposite of believable is unbelievable
The opposite of reasonable is
2024-07-27 22:48:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 22:51:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0319,  0.0223, -0.0692,  ..., -0.2316, -0.1903,  0.0555],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1191, -2.2969, -0.4053,  ..., -1.6689, -3.1719, -3.6367],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0517, -0.0090, -0.0202,  ...,  0.0246, -0.0118,  0.0045],
        [ 0.0026,  0.0103,  0.0374,  ...,  0.0221, -0.0294,  0.0395],
        [-0.0252, -0.0025,  0.0134,  ...,  0.0031, -0.0237, -0.0040],
        ...,
        [-0.0121,  0.0405,  0.0191,  ...,  0.0087,  0.0208, -0.0401],
        [-0.0121,  0.0292,  0.0131,  ..., -0.0340,  0.0281, -0.0635],
        [-0.0237, -0.0061,  0.0088,  ...,  0.0083, -0.0150,  0.0178]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5898, -2.5977, -0.6943,  ..., -1.3223, -3.3770, -3.8574]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 22:51:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of resolved is unresolved
The opposite of forgettable is unforgettable
The opposite of used is unused
The opposite of finished is unfinished
The opposite of sustainable is unsustainable
The opposite of changed is unchanged
The opposite of believable is unbelievable
The opposite of reasonable is
2024-07-27 22:51:10 root INFO     [order_1_approx] starting weight calculation for The opposite of resolved is unresolved
The opposite of finished is unfinished
The opposite of believable is unbelievable
The opposite of sustainable is unsustainable
The opposite of changed is unchanged
The opposite of reasonable is unreasonable
The opposite of used is unused
The opposite of forgettable is
2024-07-27 22:51:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 22:53:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2456, -0.1450, -0.1411,  ..., -0.1929, -0.2727, -0.0615],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4736, -1.8740, -1.1973,  ..., -1.0166, -5.4102, -3.7129],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0378,  0.0301, -0.0145,  ...,  0.0362,  0.0197,  0.0342],
        [-0.0461,  0.0398,  0.0026,  ..., -0.0058,  0.0116, -0.0182],
        [ 0.0072,  0.0135,  0.0127,  ...,  0.0139, -0.0129,  0.0129],
        ...,
        [ 0.0032, -0.0103,  0.0039,  ..., -0.0124,  0.0181, -0.0032],
        [ 0.0077, -0.0006,  0.0341,  ..., -0.0068,  0.0355,  0.0077],
        [-0.0088,  0.0284, -0.0288,  ...,  0.0240, -0.0068, -0.0081]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5991, -1.9443, -1.2881,  ..., -0.6025, -5.7383, -3.8906]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 22:53:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of resolved is unresolved
The opposite of finished is unfinished
The opposite of believable is unbelievable
The opposite of sustainable is unsustainable
The opposite of changed is unchanged
The opposite of reasonable is unreasonable
The opposite of used is unused
The opposite of forgettable is
2024-07-27 22:53:55 root INFO     [order_1_approx] starting weight calculation for The opposite of sustainable is unsustainable
The opposite of forgettable is unforgettable
The opposite of resolved is unresolved
The opposite of finished is unfinished
The opposite of reasonable is unreasonable
The opposite of changed is unchanged
The opposite of used is unused
The opposite of believable is
2024-07-27 22:53:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 22:56:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2991, -0.0426,  0.0525,  ..., -0.1626, -0.2920,  0.1448],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0879, -3.2031,  1.0664,  ..., -1.7344, -2.1484, -3.1719],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0282, -0.0204, -0.0293,  ...,  0.0314, -0.0158,  0.0361],
        [-0.0261,  0.0145,  0.0160,  ..., -0.0004,  0.0216,  0.0045],
        [-0.0156, -0.0219, -0.0072,  ...,  0.0082, -0.0268, -0.0062],
        ...,
        [-0.0178,  0.0214, -0.0444,  ...,  0.0057,  0.0027,  0.0067],
        [-0.0183,  0.0289,  0.0201,  ..., -0.0056,  0.0040, -0.0086],
        [-0.0424,  0.0274, -0.0248,  ...,  0.0003, -0.0142,  0.0114]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0273, -3.4258,  1.0889,  ..., -1.2646, -1.9482, -3.1699]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 22:56:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of sustainable is unsustainable
The opposite of forgettable is unforgettable
The opposite of resolved is unresolved
The opposite of finished is unfinished
The opposite of reasonable is unreasonable
The opposite of changed is unchanged
The opposite of used is unused
The opposite of believable is
2024-07-27 22:56:41 root INFO     [order_1_approx] starting weight calculation for The opposite of used is unused
The opposite of resolved is unresolved
The opposite of finished is unfinished
The opposite of reasonable is unreasonable
The opposite of believable is unbelievable
The opposite of changed is unchanged
The opposite of forgettable is unforgettable
The opposite of sustainable is
2024-07-27 22:56:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 22:59:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0670, -0.0491, -0.3098,  ..., -0.0720,  0.0474,  0.1479],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0674, -2.9453, -0.1279,  ..., -2.0938, -2.1953, -0.0254],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0204, -0.0086, -0.0133,  ...,  0.0263,  0.0144,  0.0295],
        [-0.0250,  0.0090,  0.0170,  ..., -0.0052,  0.0081,  0.0105],
        [-0.0098, -0.0123, -0.0155,  ...,  0.0105, -0.0238,  0.0087],
        ...,
        [ 0.0370, -0.0198, -0.0124,  ..., -0.0135, -0.0038,  0.0218],
        [-0.0228,  0.0104,  0.0364,  ..., -0.0093,  0.0267, -0.0358],
        [-0.0285,  0.0211, -0.0266,  ..., -0.0270, -0.0224, -0.0219]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8008, -2.6543, -0.0379,  ..., -1.3438, -2.6543,  0.2981]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 22:59:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of used is unused
The opposite of resolved is unresolved
The opposite of finished is unfinished
The opposite of reasonable is unreasonable
The opposite of believable is unbelievable
The opposite of changed is unchanged
The opposite of forgettable is unforgettable
The opposite of sustainable is
2024-07-27 22:59:28 root INFO     [order_1_approx] starting weight calculation for The opposite of reasonable is unreasonable
The opposite of forgettable is unforgettable
The opposite of believable is unbelievable
The opposite of resolved is unresolved
The opposite of sustainable is unsustainable
The opposite of finished is unfinished
The opposite of changed is unchanged
The opposite of used is
2024-07-27 22:59:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 23:02:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1973, -0.1361, -0.0687,  ...,  0.1260, -0.5229,  0.1660],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6396, -3.1875,  0.5386,  ..., -1.8145, -2.5371, -1.5684],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-7.0038e-03, -1.9836e-02,  2.3621e-02,  ...,  3.8635e-02,
         -6.2599e-03,  1.3687e-02],
        [-7.7972e-03,  7.6416e-02,  5.2429e-02,  ...,  2.0905e-02,
         -2.9160e-02,  1.0696e-02],
        [-1.9379e-02, -6.4636e-02,  3.3752e-02,  ...,  4.7455e-02,
         -1.2619e-02,  2.8625e-02],
        ...,
        [ 1.2970e-02,  2.8610e-05,  1.5564e-03,  ...,  8.9874e-03,
         -1.8539e-02,  1.9302e-03],
        [ 3.9551e-02, -3.2013e-02, -1.0193e-02,  ...,  8.6517e-03,
          5.6183e-02,  4.3091e-02],
        [-4.0207e-03,  2.0813e-02, -3.6743e-02,  ...,  4.0649e-02,
          9.5978e-03, -4.0436e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8369, -2.7109,  1.3916,  ..., -1.8242, -4.1250, -0.2637]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 23:02:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of reasonable is unreasonable
The opposite of forgettable is unforgettable
The opposite of believable is unbelievable
The opposite of resolved is unresolved
The opposite of sustainable is unsustainable
The opposite of finished is unfinished
The opposite of changed is unchanged
The opposite of used is
2024-07-27 23:02:16 root INFO     [order_1_approx] starting weight calculation for The opposite of believable is unbelievable
The opposite of sustainable is unsustainable
The opposite of changed is unchanged
The opposite of used is unused
The opposite of reasonable is unreasonable
The opposite of finished is unfinished
The opposite of forgettable is unforgettable
The opposite of resolved is
2024-07-27 23:02:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 23:05:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2461, -0.1819, -0.4165,  ..., -0.1255, -0.2406,  0.0807],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4902, -1.2705,  1.3232,  ..., -0.4126, -1.3477, -0.2949],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0425,  0.0111, -0.0101,  ...,  0.0440, -0.0055,  0.0199],
        [-0.0347,  0.0141,  0.0301,  ..., -0.0149,  0.0119, -0.0172],
        [ 0.0162, -0.0041,  0.0163,  ...,  0.0028, -0.0265,  0.0243],
        ...,
        [ 0.0102, -0.0059, -0.0056,  ...,  0.0354, -0.0214,  0.0029],
        [-0.0207,  0.0182,  0.0583,  ..., -0.0016,  0.0463, -0.0301],
        [ 0.0035, -0.0011,  0.0190,  ..., -0.0030, -0.0081, -0.0158]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6753, -2.4219,  1.8555,  ...,  0.0564, -2.1211, -0.2610]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 23:05:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of believable is unbelievable
The opposite of sustainable is unsustainable
The opposite of changed is unchanged
The opposite of used is unused
The opposite of reasonable is unreasonable
The opposite of finished is unfinished
The opposite of forgettable is unforgettable
The opposite of resolved is
2024-07-27 23:05:03 root INFO     [order_1_approx] starting weight calculation for The opposite of resolved is unresolved
The opposite of reasonable is unreasonable
The opposite of believable is unbelievable
The opposite of used is unused
The opposite of forgettable is unforgettable
The opposite of sustainable is unsustainable
The opposite of changed is unchanged
The opposite of finished is
2024-07-27 23:05:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 23:07:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1367, -0.1274, -0.2468,  ..., -0.0571, -0.1902,  0.2330],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0449, -2.4766,  0.0947,  ...,  0.9673,  0.4990, -1.4512],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.5319e-02, -1.9714e-02, -2.4033e-02,  ...,  3.2166e-02,
          2.6535e-02,  4.4899e-03],
        [-1.3268e-02,  3.8330e-02, -1.1536e-02,  ..., -3.0670e-02,
         -2.6443e-02, -2.0737e-02],
        [ 3.4332e-05, -3.0075e-02,  2.2156e-02,  ..., -8.0948e-03,
          1.9135e-02,  2.4246e-02],
        ...,
        [ 8.9798e-03,  1.9409e-02,  1.7128e-03,  ...,  1.2230e-02,
         -3.2749e-03, -1.7395e-02],
        [ 4.3152e-02,  7.2266e-02,  4.7150e-02,  ..., -5.9509e-02,
         -7.3776e-03, -1.7670e-02],
        [ 1.0651e-02,  2.7504e-03, -2.7206e-02,  ...,  6.4453e-02,
          5.3177e-03,  1.1780e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0850, -2.8340,  0.5654,  ...,  0.7612, -0.4409, -1.1699]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 23:07:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of resolved is unresolved
The opposite of reasonable is unreasonable
The opposite of believable is unbelievable
The opposite of used is unused
The opposite of forgettable is unforgettable
The opposite of sustainable is unsustainable
The opposite of changed is unchanged
The opposite of finished is
2024-07-27 23:07:48 root INFO     [order_1_approx] starting weight calculation for The opposite of sustainable is unsustainable
The opposite of resolved is unresolved
The opposite of finished is unfinished
The opposite of used is unused
The opposite of reasonable is unreasonable
The opposite of forgettable is unforgettable
The opposite of believable is unbelievable
The opposite of changed is
2024-07-27 23:07:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 23:10:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0332, -0.0847, -0.2050,  ..., -0.1688, -0.0413,  0.1840],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5605, -0.7896,  1.0234,  ..., -2.7656, -1.5117, -1.4990],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0729, -0.0043, -0.0093,  ...,  0.0629, -0.0043,  0.0297],
        [-0.0380,  0.0127,  0.0070,  ..., -0.0098, -0.0228, -0.0168],
        [ 0.0359,  0.0139, -0.0115,  ...,  0.0200, -0.0111, -0.0033],
        ...,
        [-0.0098,  0.0044,  0.0020,  ...,  0.0153,  0.0346,  0.0244],
        [ 0.0542, -0.0353,  0.0083,  ..., -0.0083,  0.0269, -0.0292],
        [ 0.0360,  0.0119, -0.0346,  ...,  0.0449, -0.0052, -0.0091]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4688, -1.0801,  1.5869,  ..., -2.8887, -2.7812, -1.5713]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 23:10:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of sustainable is unsustainable
The opposite of resolved is unresolved
The opposite of finished is unfinished
The opposite of used is unused
The opposite of reasonable is unreasonable
The opposite of forgettable is unforgettable
The opposite of believable is unbelievable
The opposite of changed is
2024-07-27 23:10:34 root INFO     total operator prediction time: 1328.7675321102142 seconds
2024-07-27 23:10:34 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on re+verb_reg
2024-07-27 23:10:34 root INFO     building operator re+verb_reg
2024-07-27 23:10:34 root INFO     [order_1_approx] starting weight calculation for To confirm again is to reconfirm
To submit again is to resubmit
To learn again is to relearn
To interpret again is to reinterpret
To assess again is to reassess
To investigate again is to reinvestigate
To cognize again is to recognize
To appoint again is to
2024-07-27 23:10:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 23:13:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1225,  0.3896, -0.1383,  ...,  0.0977, -0.2407, -0.0820],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4561, -5.3867,  2.1836,  ...,  2.0938, -7.4219, -5.3594],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0566, -0.0029,  0.0242,  ..., -0.0117,  0.0021, -0.0081],
        [-0.0010,  0.0122,  0.0109,  ...,  0.0175,  0.0134,  0.0098],
        [-0.0146,  0.0096,  0.0248,  ..., -0.0228, -0.0043, -0.0190],
        ...,
        [ 0.0005, -0.0123,  0.0100,  ...,  0.0396,  0.0022,  0.0212],
        [ 0.0130, -0.0168, -0.0246,  ..., -0.0314,  0.0143, -0.0405],
        [ 0.0079, -0.0323,  0.0051,  ...,  0.0122, -0.0225,  0.0504]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4272, -5.5078,  1.9766,  ...,  2.0234, -7.3750, -5.2812]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 23:13:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To confirm again is to reconfirm
To submit again is to resubmit
To learn again is to relearn
To interpret again is to reinterpret
To assess again is to reassess
To investigate again is to reinvestigate
To cognize again is to recognize
To appoint again is to
2024-07-27 23:13:19 root INFO     [order_1_approx] starting weight calculation for To confirm again is to reconfirm
To appoint again is to reappoint
To submit again is to resubmit
To assess again is to reassess
To interpret again is to reinterpret
To cognize again is to recognize
To investigate again is to reinvestigate
To learn again is to
2024-07-27 23:13:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 23:16:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1165,  0.1621,  0.1323,  ..., -0.0338, -0.3164,  0.0667],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1689, -3.2031,  1.0898,  ...,  3.5859, -4.7070, -5.6133],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0424, -0.0195, -0.0094,  ...,  0.0075,  0.0148,  0.0230],
        [-0.0046,  0.0125, -0.0094,  ...,  0.0024,  0.0200,  0.0164],
        [ 0.0046,  0.0093,  0.0226,  ...,  0.0137, -0.0133, -0.0130],
        ...,
        [ 0.0140, -0.0144, -0.0045,  ...,  0.0158,  0.0081, -0.0114],
        [-0.0086, -0.0098, -0.0068,  ..., -0.0221,  0.0194, -0.0191],
        [ 0.0092, -0.0009, -0.0133,  ...,  0.0028,  0.0139,  0.0145]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1810, -3.4648,  1.2803,  ...,  3.5684, -4.8125, -5.5977]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 23:16:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To confirm again is to reconfirm
To appoint again is to reappoint
To submit again is to resubmit
To assess again is to reassess
To interpret again is to reinterpret
To cognize again is to recognize
To investigate again is to reinvestigate
To learn again is to
2024-07-27 23:16:03 root INFO     [order_1_approx] starting weight calculation for To submit again is to resubmit
To interpret again is to reinterpret
To assess again is to reassess
To appoint again is to reappoint
To confirm again is to reconfirm
To investigate again is to reinvestigate
To learn again is to relearn
To cognize again is to
2024-07-27 23:16:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 23:18:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0895,  0.4517, -0.3169,  ...,  0.0803, -0.1333,  0.1257],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.9629, -1.5449,  2.7852,  ...,  1.6289, -2.0645, -1.3066],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0468, -0.0147,  0.0360,  ...,  0.0098,  0.0025,  0.0022],
        [-0.0013, -0.0101, -0.0179,  ..., -0.0125,  0.0245,  0.0024],
        [-0.0155, -0.0043,  0.0229,  ..., -0.0068, -0.0055, -0.0258],
        ...,
        [ 0.0274, -0.0032, -0.0209,  ...,  0.0540,  0.0059,  0.0438],
        [ 0.0249, -0.0041, -0.0190,  ..., -0.0392,  0.0014, -0.0197],
        [-0.0162,  0.0240,  0.0080,  ...,  0.0336, -0.0172,  0.0097]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.8760, -1.5068,  2.6387,  ...,  2.1523, -2.1738, -1.4609]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 23:18:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To submit again is to resubmit
To interpret again is to reinterpret
To assess again is to reassess
To appoint again is to reappoint
To confirm again is to reconfirm
To investigate again is to reinvestigate
To learn again is to relearn
To cognize again is to
2024-07-27 23:18:49 root INFO     [order_1_approx] starting weight calculation for To learn again is to relearn
To appoint again is to reappoint
To cognize again is to recognize
To assess again is to reassess
To confirm again is to reconfirm
To investigate again is to reinvestigate
To interpret again is to reinterpret
To submit again is to
2024-07-27 23:18:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 23:21:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0864, -0.0115,  0.0701,  ..., -0.0336, -0.3533,  0.2124],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5127, -2.5859, -1.3994,  ...,  0.7871, -3.3711, -3.2129],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0489, -0.0239,  0.0454,  ..., -0.0021,  0.0069,  0.0165],
        [-0.0028,  0.0295, -0.0403,  ...,  0.0173,  0.0057,  0.0020],
        [-0.0081,  0.0146,  0.0224,  ...,  0.0177,  0.0172,  0.0012],
        ...,
        [ 0.0067, -0.0143,  0.0237,  ...,  0.0656,  0.0165,  0.0349],
        [ 0.0107,  0.0159,  0.0172,  ..., -0.0750, -0.0054, -0.0266],
        [-0.0051, -0.0577, -0.0270,  ...,  0.0029, -0.0431,  0.0120]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2520, -2.4844, -0.6812,  ...,  0.7812, -3.6504, -3.6113]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 23:21:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To learn again is to relearn
To appoint again is to reappoint
To cognize again is to recognize
To assess again is to reassess
To confirm again is to reconfirm
To investigate again is to reinvestigate
To interpret again is to reinterpret
To submit again is to
2024-07-27 23:21:33 root INFO     [order_1_approx] starting weight calculation for To cognize again is to recognize
To assess again is to reassess
To confirm again is to reconfirm
To submit again is to resubmit
To interpret again is to reinterpret
To appoint again is to reappoint
To learn again is to relearn
To investigate again is to
2024-07-27 23:21:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 23:24:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0155,  0.2313, -0.0747,  ..., -0.0538, -0.2395, -0.0153],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6470, -2.7031,  0.8311,  ...,  0.5273, -1.1211, -3.8848],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0245, -0.0158,  0.0235,  ...,  0.0026,  0.0474, -0.0213],
        [-0.0160,  0.0029,  0.0117,  ...,  0.0161,  0.0047,  0.0249],
        [ 0.0027,  0.0106,  0.0152,  ..., -0.0069, -0.0030, -0.0309],
        ...,
        [ 0.0080,  0.0135, -0.0135,  ...,  0.0233,  0.0301, -0.0032],
        [-0.0056, -0.0291, -0.0214,  ...,  0.0107, -0.0246,  0.0147],
        [-0.0069, -0.0145,  0.0219,  ..., -0.0062,  0.0118, -0.0065]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5449, -2.6602,  1.1094,  ...,  0.3301, -1.3516, -4.0312]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 23:24:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To cognize again is to recognize
To assess again is to reassess
To confirm again is to reconfirm
To submit again is to resubmit
To interpret again is to reinterpret
To appoint again is to reappoint
To learn again is to relearn
To investigate again is to
2024-07-27 23:24:18 root INFO     [order_1_approx] starting weight calculation for To interpret again is to reinterpret
To cognize again is to recognize
To assess again is to reassess
To learn again is to relearn
To submit again is to resubmit
To investigate again is to reinvestigate
To appoint again is to reappoint
To confirm again is to
2024-07-27 23:24:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 23:27:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0484,  0.2595,  0.0214,  ...,  0.2507, -0.2205,  0.1892],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3950, -3.0879,  1.2529,  ...,  2.9746, -2.6133, -2.1719],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0509, -0.0247,  0.0349,  ..., -0.0168,  0.0201,  0.0166],
        [-0.0232,  0.0327, -0.0147,  ...,  0.0106,  0.0164,  0.0024],
        [-0.0073, -0.0017,  0.0063,  ...,  0.0100, -0.0117, -0.0119],
        ...,
        [ 0.0094,  0.0062,  0.0043,  ...,  0.0330,  0.0096,  0.0010],
        [ 0.0060,  0.0087,  0.0058,  ..., -0.0073, -0.0022, -0.0031],
        [-0.0069,  0.0105,  0.0081,  ..., -0.0268, -0.0231, -0.0021]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5596, -3.2598,  1.6670,  ...,  3.0527, -3.1562, -2.3809]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 23:27:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To interpret again is to reinterpret
To cognize again is to recognize
To assess again is to reassess
To learn again is to relearn
To submit again is to resubmit
To investigate again is to reinvestigate
To appoint again is to reappoint
To confirm again is to
2024-07-27 23:27:02 root INFO     [order_1_approx] starting weight calculation for To learn again is to relearn
To interpret again is to reinterpret
To appoint again is to reappoint
To investigate again is to reinvestigate
To submit again is to resubmit
To confirm again is to reconfirm
To cognize again is to recognize
To assess again is to
2024-07-27 23:27:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 23:29:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0349,  0.1231,  0.0351,  ...,  0.2039, -0.3022, -0.1350],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9038, -2.6914, -0.2783,  ..., -0.2192, -5.6953, -4.8789],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0429, -0.0130,  0.0190,  ..., -0.0111,  0.0122,  0.0062],
        [-0.0079,  0.0220, -0.0079,  ...,  0.0114,  0.0065,  0.0198],
        [-0.0233, -0.0155,  0.0240,  ...,  0.0105,  0.0224, -0.0202],
        ...,
        [-0.0092, -0.0082, -0.0081,  ...,  0.0439,  0.0325, -0.0154],
        [-0.0381, -0.0276, -0.0041,  ...,  0.0097,  0.0226,  0.0004],
        [ 0.0049, -0.0165, -0.0271,  ...,  0.0063, -0.0030,  0.0061]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1836, -2.7305, -0.1233,  ..., -0.2168, -5.8750, -4.7930]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 23:29:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To learn again is to relearn
To interpret again is to reinterpret
To appoint again is to reappoint
To investigate again is to reinvestigate
To submit again is to resubmit
To confirm again is to reconfirm
To cognize again is to recognize
To assess again is to
2024-07-27 23:29:47 root INFO     [order_1_approx] starting weight calculation for To assess again is to reassess
To confirm again is to reconfirm
To appoint again is to reappoint
To learn again is to relearn
To investigate again is to reinvestigate
To submit again is to resubmit
To cognize again is to recognize
To interpret again is to
2024-07-27 23:29:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 23:32:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0690,  0.1981,  0.1003,  ...,  0.1816, -0.1262,  0.1780],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5400, -2.3398,  2.4102,  ...,  0.3843, -3.7832, -3.4922],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0042, -0.0228,  0.0270,  ..., -0.0024,  0.0450,  0.0149],
        [ 0.0159,  0.0412,  0.0109,  ...,  0.0101, -0.0020,  0.0025],
        [-0.0035, -0.0022,  0.0040,  ...,  0.0018, -0.0377, -0.0179],
        ...,
        [ 0.0131, -0.0074,  0.0166,  ...,  0.0254,  0.0206, -0.0234],
        [ 0.0252, -0.0086, -0.0150,  ..., -0.0255,  0.0109, -0.0283],
        [-0.0085, -0.0004,  0.0078,  ..., -0.0174, -0.0018,  0.0115]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3223, -2.7617,  2.9062,  ..., -0.2720, -3.6523, -3.6465]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 23:32:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To assess again is to reassess
To confirm again is to reconfirm
To appoint again is to reappoint
To learn again is to relearn
To investigate again is to reinvestigate
To submit again is to resubmit
To cognize again is to recognize
To interpret again is to
2024-07-27 23:32:32 root INFO     total operator prediction time: 1318.5811245441437 seconds
2024-07-27 23:32:32 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj+ness_reg
2024-07-27 23:32:32 root INFO     building operator adj+ness_reg
2024-07-27 23:32:32 root INFO     [order_1_approx] starting weight calculation for The state of being obvious is obviousness
The state of being random is randomness
The state of being odd is oddness
The state of being sad is sadness
The state of being competitive is competitiveness
The state of being broken is brokenness
The state of being useful is usefulness
The state of being related is
2024-07-27 23:32:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 23:35:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0452, -0.0299, -0.0709,  ..., -0.0649, -0.4102,  0.1101],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4922, -2.1348, -1.2480,  ...,  0.7344, -4.2500, -2.7266],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0062, -0.0028,  0.0117,  ..., -0.0087,  0.0054,  0.0057],
        [-0.0031,  0.0486, -0.0002,  ...,  0.0627, -0.0238,  0.0320],
        [ 0.0011, -0.0068,  0.0347,  ..., -0.0030,  0.0021, -0.0101],
        ...,
        [ 0.0134,  0.0149,  0.0066,  ...,  0.0251,  0.0054, -0.0088],
        [ 0.0107, -0.0240,  0.0037,  ..., -0.0233,  0.0278, -0.0159],
        [ 0.0166,  0.0245, -0.0141,  ...,  0.0276, -0.0367,  0.0555]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2261, -1.9297, -1.5068,  ...,  0.6118, -4.2930, -2.5684]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 23:35:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being obvious is obviousness
The state of being random is randomness
The state of being odd is oddness
The state of being sad is sadness
The state of being competitive is competitiveness
The state of being broken is brokenness
The state of being useful is usefulness
The state of being related is
2024-07-27 23:35:17 root INFO     [order_1_approx] starting weight calculation for The state of being obvious is obviousness
The state of being useful is usefulness
The state of being odd is oddness
The state of being sad is sadness
The state of being related is relatedness
The state of being broken is brokenness
The state of being random is randomness
The state of being competitive is
2024-07-27 23:35:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 23:38:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0995, -0.0732, -0.0526,  ..., -0.0348, -0.4556,  0.0080],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8516, -4.5625, -0.9868,  ..., -2.1719, -1.6387, -0.8721],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0175,  0.0056,  0.0242,  ..., -0.0114, -0.0162,  0.0168],
        [ 0.0052,  0.0134,  0.0101,  ...,  0.0003,  0.0061,  0.0293],
        [ 0.0060, -0.0044,  0.0015,  ..., -0.0077, -0.0093, -0.0055],
        ...,
        [ 0.0211, -0.0169,  0.0082,  ...,  0.0246, -0.0081,  0.0082],
        [ 0.0018,  0.0051, -0.0145,  ..., -0.0024,  0.0172, -0.0231],
        [ 0.0075, -0.0196, -0.0014,  ...,  0.0137, -0.0142,  0.0367]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8613, -4.2891, -0.9805,  ..., -2.3047, -1.8271, -1.1299]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 23:38:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being obvious is obviousness
The state of being useful is usefulness
The state of being odd is oddness
The state of being sad is sadness
The state of being related is relatedness
The state of being broken is brokenness
The state of being random is randomness
The state of being competitive is
2024-07-27 23:38:02 root INFO     [order_1_approx] starting weight calculation for The state of being related is relatedness
The state of being sad is sadness
The state of being competitive is competitiveness
The state of being random is randomness
The state of being obvious is obviousness
The state of being odd is oddness
The state of being useful is usefulness
The state of being broken is
2024-07-27 23:38:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 23:40:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1328,  0.1427, -0.1494,  ..., -0.0796, -0.4312,  0.1089],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0254, -4.3242, -0.9043,  ..., -1.9346, -0.0342, -0.8335],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0018,  0.0144, -0.0045,  ..., -0.0221,  0.0109,  0.0180],
        [ 0.0040, -0.0201,  0.0007,  ...,  0.0188, -0.0059,  0.0220],
        [-0.0130, -0.0374,  0.0018,  ...,  0.0100,  0.0115,  0.0085],
        ...,
        [ 0.0406, -0.0002,  0.0188,  ...,  0.0214, -0.0160,  0.0009],
        [-0.0382,  0.0240, -0.0038,  ..., -0.0409,  0.0532, -0.0388],
        [ 0.0042,  0.0054,  0.0038,  ...,  0.0183,  0.0041,  0.0308]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1523, -4.2500, -0.7524,  ..., -2.0469, -0.3928, -0.8066]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 23:40:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being related is relatedness
The state of being sad is sadness
The state of being competitive is competitiveness
The state of being random is randomness
The state of being obvious is obviousness
The state of being odd is oddness
The state of being useful is usefulness
The state of being broken is
2024-07-27 23:40:49 root INFO     [order_1_approx] starting weight calculation for The state of being sad is sadness
The state of being related is relatedness
The state of being competitive is competitiveness
The state of being broken is brokenness
The state of being random is randomness
The state of being odd is oddness
The state of being useful is usefulness
The state of being obvious is
2024-07-27 23:40:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 23:43:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0231,  0.3162,  0.0054,  ..., -0.2537, -0.7598,  0.1009],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9648, -3.4023, -0.1143,  ..., -2.4121, -4.2031,  1.5352],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.6408e-03,  1.5137e-02, -1.0773e-02,  ...,  3.9337e-02,
         -8.6060e-03,  2.4109e-02],
        [-2.7832e-02,  5.8823e-03, -9.4299e-03,  ..., -2.3407e-02,
         -1.3916e-02, -1.4198e-02],
        [ 9.0866e-03, -3.5156e-02, -2.0630e-02,  ...,  9.4299e-03,
         -2.2614e-02,  1.0559e-02],
        ...,
        [-2.6703e-05,  2.3163e-02,  4.4952e-02,  ...,  1.9913e-02,
         -2.0615e-02,  1.6647e-02],
        [ 2.7252e-02, -7.8278e-03, -3.5591e-03,  ..., -8.2550e-03,
         -8.2970e-04, -1.8814e-02],
        [ 9.6817e-03,  2.2171e-02,  1.4748e-02,  ..., -4.9591e-04,
          9.9564e-04,  7.9269e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0996, -3.5117, -0.6196,  ..., -2.6133, -4.4570,  1.5225]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 23:43:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being sad is sadness
The state of being related is relatedness
The state of being competitive is competitiveness
The state of being broken is brokenness
The state of being random is randomness
The state of being odd is oddness
The state of being useful is usefulness
The state of being obvious is
2024-07-27 23:43:32 root INFO     [order_1_approx] starting weight calculation for The state of being competitive is competitiveness
The state of being broken is brokenness
The state of being sad is sadness
The state of being related is relatedness
The state of being useful is usefulness
The state of being obvious is obviousness
The state of being random is randomness
The state of being odd is
2024-07-27 23:43:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 23:46:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0462,  0.1460,  0.2472,  ..., -0.0666, -0.2025,  0.0664],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9795, -3.0977, -1.6758,  ..., -2.9844, -4.4297, -1.8145],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0218,  0.0120, -0.0285,  ...,  0.0037, -0.0052,  0.0203],
        [-0.0081,  0.0048, -0.0122,  ..., -0.0046, -0.0165,  0.0057],
        [ 0.0027, -0.0185,  0.0226,  ...,  0.0094, -0.0161,  0.0145],
        ...,
        [-0.0132,  0.0180,  0.0462,  ...,  0.0100, -0.0022,  0.0093],
        [-0.0203,  0.0272,  0.0164,  ...,  0.0048,  0.0349, -0.0225],
        [-0.0253, -0.0203, -0.0199,  ...,  0.0154, -0.0079,  0.0151]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6797, -2.8262, -1.8438,  ..., -3.1016, -4.8984, -1.5195]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 23:46:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being competitive is competitiveness
The state of being broken is brokenness
The state of being sad is sadness
The state of being related is relatedness
The state of being useful is usefulness
The state of being obvious is obviousness
The state of being random is randomness
The state of being odd is
2024-07-27 23:46:18 root INFO     [order_1_approx] starting weight calculation for The state of being obvious is obviousness
The state of being useful is usefulness
The state of being broken is brokenness
The state of being competitive is competitiveness
The state of being sad is sadness
The state of being odd is oddness
The state of being related is relatedness
The state of being random is
2024-07-27 23:46:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 23:49:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2487,  0.3672, -0.1214,  ...,  0.0894, -0.3384, -0.0552],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7100, -1.7266, -1.1426,  ..., -1.6191, -3.4453, -4.9219],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0362, -0.0041, -0.0333,  ..., -0.0003, -0.0052,  0.0025],
        [-0.0313, -0.0251,  0.0098,  ...,  0.0179, -0.0034,  0.0160],
        [-0.0043, -0.0037,  0.0323,  ..., -0.0050,  0.0011, -0.0045],
        ...,
        [-0.0150,  0.0158,  0.0387,  ...,  0.0125, -0.0098,  0.0102],
        [-0.0072,  0.0246,  0.0085,  ..., -0.0313,  0.0336, -0.0068],
        [ 0.0100, -0.0066, -0.0265,  ...,  0.0112, -0.0126, -0.0095]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2974, -2.0039, -0.9800,  ..., -2.4492, -3.7695, -4.6211]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 23:49:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being obvious is obviousness
The state of being useful is usefulness
The state of being broken is brokenness
The state of being competitive is competitiveness
The state of being sad is sadness
The state of being odd is oddness
The state of being related is relatedness
The state of being random is
2024-07-27 23:49:03 root INFO     [order_1_approx] starting weight calculation for The state of being competitive is competitiveness
The state of being broken is brokenness
The state of being random is randomness
The state of being related is relatedness
The state of being obvious is obviousness
The state of being odd is oddness
The state of being sad is sadness
The state of being useful is
2024-07-27 23:49:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 23:51:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0034,  0.1213,  0.3496,  ..., -0.1064, -0.4280,  0.0778],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5820, -2.1094, -1.3525,  ..., -1.9043, -4.3945, -2.2871],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0058,  0.0061, -0.0047,  ...,  0.0044, -0.0062,  0.0130],
        [-0.0186,  0.0076, -0.0070,  ...,  0.0175,  0.0112, -0.0027],
        [ 0.0217, -0.0270,  0.0201,  ..., -0.0037, -0.0172, -0.0193],
        ...,
        [ 0.0312,  0.0012,  0.0074,  ...,  0.0285,  0.0139,  0.0020],
        [ 0.0105, -0.0014,  0.0124,  ..., -0.0073,  0.0188, -0.0364],
        [ 0.0199, -0.0004,  0.0167,  ...,  0.0047, -0.0087,  0.0119]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8691, -1.7051, -1.6377,  ..., -1.8369, -4.9141, -2.5840]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 23:51:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being competitive is competitiveness
The state of being broken is brokenness
The state of being random is randomness
The state of being related is relatedness
The state of being obvious is obviousness
The state of being odd is oddness
The state of being sad is sadness
The state of being useful is
2024-07-27 23:51:48 root INFO     [order_1_approx] starting weight calculation for The state of being random is randomness
The state of being odd is oddness
The state of being related is relatedness
The state of being obvious is obviousness
The state of being useful is usefulness
The state of being competitive is competitiveness
The state of being broken is brokenness
The state of being sad is
2024-07-27 23:51:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 23:54:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1064, -0.1439, -0.0557,  ...,  0.0126, -0.3555,  0.3201],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3555, -4.7656, -0.9873,  ..., -6.2070, -2.9297, -3.3242],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0129,  0.0154, -0.0199,  ...,  0.0116,  0.0394,  0.0046],
        [-0.0183,  0.0043,  0.0213,  ..., -0.0345, -0.0461,  0.0009],
        [ 0.0245, -0.0114,  0.0386,  ...,  0.0056, -0.0025, -0.0003],
        ...,
        [-0.0013, -0.0124,  0.0110,  ..., -0.0049, -0.0389,  0.0222],
        [-0.0003,  0.0076, -0.0075,  ...,  0.0172,  0.0505, -0.0051],
        [ 0.0179, -0.0234,  0.0132,  ..., -0.0126, -0.0638,  0.0290]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6934, -5.3594, -1.5645,  ..., -6.4531, -2.5547, -3.7129]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 23:54:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being random is randomness
The state of being odd is oddness
The state of being related is relatedness
The state of being obvious is obviousness
The state of being useful is usefulness
The state of being competitive is competitiveness
The state of being broken is brokenness
The state of being sad is
2024-07-27 23:54:33 root INFO     total operator prediction time: 1320.4813115596771 seconds
2024-07-27 23:54:33 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun+less_reg
2024-07-27 23:54:33 root INFO     building operator noun+less_reg
2024-07-27 23:54:33 root INFO     [order_1_approx] starting weight calculation for Something without gender is genderless
Something without child is childless
Something without mirth is mirthless
Something without law is lawless
Something without heart is heartless
Something without speech is speechless
Something without expression is expressionless
Something without penny is
2024-07-27 23:54:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-27 23:57:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0694, -0.3555, -0.1547,  ..., -0.1351, -0.1542,  0.0183],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6372, -3.5703,  0.2573,  ..., -4.5312, -5.7109, -1.9658],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0314, -0.0261,  0.0278,  ..., -0.0319,  0.0015,  0.0170],
        [ 0.0208, -0.0013,  0.0171,  ...,  0.0012, -0.0201,  0.0032],
        [ 0.0098, -0.0213,  0.0042,  ..., -0.0255,  0.0174,  0.0043],
        ...,
        [ 0.0096, -0.0323,  0.0085,  ..., -0.0106, -0.0018,  0.0066],
        [-0.0222, -0.0017,  0.0353,  ...,  0.0273, -0.0119, -0.0338],
        [-0.0009, -0.0019, -0.0098,  ..., -0.0166,  0.0040,  0.0237]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3535, -3.9238,  0.2771,  ..., -4.9844, -5.3047, -2.2617]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-27 23:57:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without gender is genderless
Something without child is childless
Something without mirth is mirthless
Something without law is lawless
Something without heart is heartless
Something without speech is speechless
Something without expression is expressionless
Something without penny is
2024-07-27 23:57:17 root INFO     [order_1_approx] starting weight calculation for Something without mirth is mirthless
Something without law is lawless
Something without heart is heartless
Something without gender is genderless
Something without penny is penniless
Something without child is childless
Something without speech is speechless
Something without expression is
2024-07-27 23:57:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 00:00:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0873, -0.0629,  0.1161,  ...,  0.1682, -0.0765,  0.0935],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9316, -3.4375,  0.7188,  ..., -2.5879, -1.7305, -1.6426],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0201,  0.0198, -0.0056,  ..., -0.0224, -0.0104,  0.0140],
        [ 0.0033,  0.0450,  0.0038,  ...,  0.0045,  0.0134,  0.0038],
        [-0.0116,  0.0026,  0.0218,  ...,  0.0031,  0.0114, -0.0099],
        ...,
        [ 0.0422,  0.0289,  0.0027,  ..., -0.0026,  0.0251, -0.0213],
        [-0.0552, -0.0199,  0.0086,  ...,  0.0069, -0.0101, -0.0237],
        [ 0.0201, -0.0012, -0.0027,  ...,  0.0232,  0.0102,  0.0356]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7056, -3.5742,  0.7397,  ..., -2.4355, -2.4414, -1.4033]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 00:00:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without mirth is mirthless
Something without law is lawless
Something without heart is heartless
Something without gender is genderless
Something without penny is penniless
Something without child is childless
Something without speech is speechless
Something without expression is
2024-07-28 00:00:01 root INFO     [order_1_approx] starting weight calculation for Something without gender is genderless
Something without mirth is mirthless
Something without child is childless
Something without law is lawless
Something without expression is expressionless
Something without heart is heartless
Something without penny is penniless
Something without speech is
2024-07-28 00:00:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 00:02:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1245, -0.0310,  0.1000,  ...,  0.1049,  0.0691,  0.2245],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0488, -2.7266,  0.1055,  ..., -0.4971, -1.1846, -0.9624],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0266, -0.0041,  0.0156,  ..., -0.0276,  0.0093,  0.0297],
        [ 0.0110,  0.0547,  0.0085,  ...,  0.0081, -0.0114,  0.0081],
        [ 0.0256, -0.0319,  0.0124,  ...,  0.0092,  0.0069, -0.0010],
        ...,
        [-0.0017,  0.0107,  0.0007,  ..., -0.0039,  0.0268, -0.0096],
        [-0.0255, -0.0365,  0.0129,  ..., -0.0231,  0.0140, -0.0293],
        [-0.0136, -0.0210, -0.0111,  ..., -0.0017,  0.0232,  0.0016]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1699, -3.1562, -0.3850,  ..., -0.5664, -1.2295, -1.3711]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 00:02:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without gender is genderless
Something without mirth is mirthless
Something without child is childless
Something without law is lawless
Something without expression is expressionless
Something without heart is heartless
Something without penny is penniless
Something without speech is
2024-07-28 00:02:45 root INFO     [order_1_approx] starting weight calculation for Something without penny is penniless
Something without law is lawless
Something without speech is speechless
Something without expression is expressionless
Something without gender is genderless
Something without heart is heartless
Something without child is childless
Something without mirth is
2024-07-28 00:02:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 00:05:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0459, -0.0060,  0.2795,  ...,  0.1326, -0.4270,  0.1608],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4590, -2.9551, -0.1284,  ..., -1.9287, -4.2266, -1.8096],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0338,  0.0148, -0.0218,  ..., -0.0098,  0.0151,  0.0038],
        [ 0.0326, -0.0340,  0.0495,  ..., -0.0284, -0.0042,  0.0425],
        [-0.0002, -0.0134,  0.0521,  ...,  0.0199, -0.0074, -0.0244],
        ...,
        [ 0.0100,  0.0337,  0.0264,  ...,  0.0031, -0.0043,  0.0047],
        [-0.0081, -0.0042,  0.0061,  ..., -0.0192, -0.0154, -0.0294],
        [ 0.0112, -0.0287,  0.0257,  ...,  0.0249, -0.0243,  0.0353]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6807, -2.6934, -0.6611,  ..., -1.9971, -4.1758, -1.9229]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 00:05:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without penny is penniless
Something without law is lawless
Something without speech is speechless
Something without expression is expressionless
Something without gender is genderless
Something without heart is heartless
Something without child is childless
Something without mirth is
2024-07-28 00:05:31 root INFO     [order_1_approx] starting weight calculation for Something without law is lawless
Something without speech is speechless
Something without expression is expressionless
Something without child is childless
Something without gender is genderless
Something without mirth is mirthless
Something without penny is penniless
Something without heart is
2024-07-28 00:05:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 00:08:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0032, -0.2744, -0.0482,  ..., -0.0955, -0.1360,  0.1738],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8237, -3.9336, -0.1025,  ..., -3.3203, -2.4180, -2.0254],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0277,  0.0270,  0.0376,  ..., -0.0018, -0.0270,  0.0237],
        [-0.0097,  0.0437, -0.0055,  ..., -0.0055, -0.0199,  0.0134],
        [ 0.0144, -0.0178,  0.0524,  ...,  0.0030, -0.0059, -0.0077],
        ...,
        [-0.0060,  0.0308, -0.0068,  ...,  0.0248,  0.0026, -0.0045],
        [-0.0217, -0.0080, -0.0224,  ..., -0.0126,  0.0008, -0.0319],
        [-0.0011,  0.0070, -0.0278,  ...,  0.0252, -0.0121, -0.0023]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6431, -4.4453, -1.0264,  ..., -3.8633, -2.1387, -2.0566]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 00:08:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without law is lawless
Something without speech is speechless
Something without expression is expressionless
Something without child is childless
Something without gender is genderless
Something without mirth is mirthless
Something without penny is penniless
Something without heart is
2024-07-28 00:08:16 root INFO     [order_1_approx] starting weight calculation for Something without gender is genderless
Something without child is childless
Something without mirth is mirthless
Something without speech is speechless
Something without heart is heartless
Something without penny is penniless
Something without expression is expressionless
Something without law is
2024-07-28 00:08:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 00:11:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1768, -0.0216,  0.0178,  ..., -0.1653, -0.1678, -0.0537],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1512, -3.3535,  1.1582,  ..., -0.6909, -0.3047, -1.1367],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0375,  0.0141, -0.0107,  ..., -0.0024, -0.0195, -0.0064],
        [ 0.0240,  0.0077, -0.0079,  ..., -0.0126, -0.0133,  0.0270],
        [-0.0034, -0.0039,  0.0228,  ...,  0.0109,  0.0046, -0.0073],
        ...,
        [ 0.0145,  0.0238,  0.0097,  ..., -0.0197,  0.0200, -0.0130],
        [-0.0540,  0.0228,  0.0093,  ..., -0.0419,  0.0428, -0.0171],
        [ 0.0208,  0.0042,  0.0046,  ..., -0.0104, -0.0108,  0.0048]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2377, -2.9277,  1.3174,  ..., -0.6372, -0.9795, -1.4443]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 00:11:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without gender is genderless
Something without child is childless
Something without mirth is mirthless
Something without speech is speechless
Something without heart is heartless
Something without penny is penniless
Something without expression is expressionless
Something without law is
2024-07-28 00:11:01 root INFO     [order_1_approx] starting weight calculation for Something without mirth is mirthless
Something without penny is penniless
Something without expression is expressionless
Something without heart is heartless
Something without law is lawless
Something without speech is speechless
Something without child is childless
Something without gender is
2024-07-28 00:11:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 00:13:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3711, -0.0403, -0.2559,  ...,  0.0656, -0.1368, -0.1877],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7334, -3.4727, -1.1836,  ..., -1.8838, -3.3809, -2.2285],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.5471e-02, -1.2489e-02, -3.4790e-02,  ...,  4.7684e-06,
          4.4800e-02, -7.3929e-03],
        [ 1.9104e-02,  3.4760e-02,  2.1393e-02,  ..., -8.4457e-03,
          1.1215e-02, -1.0666e-02],
        [ 2.9800e-02, -1.2733e-02,  3.8528e-03,  ..., -2.1072e-02,
         -1.1200e-02, -9.6436e-03],
        ...,
        [ 2.4170e-02,  2.2415e-02, -1.8845e-02,  ..., -1.6937e-02,
         -1.0796e-02, -2.9099e-02],
        [ 8.4534e-03,  7.3967e-03,  2.7695e-02,  ..., -4.0802e-02,
         -4.0512e-03, -1.8738e-02],
        [ 1.0620e-02,  5.0926e-04, -5.8594e-03,  ...,  5.1392e-02,
          1.0803e-02, -2.5215e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5718, -3.6348, -1.3408,  ..., -1.9609, -3.2676, -2.1777]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 00:13:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without mirth is mirthless
Something without penny is penniless
Something without expression is expressionless
Something without heart is heartless
Something without law is lawless
Something without speech is speechless
Something without child is childless
Something without gender is
2024-07-28 00:13:47 root INFO     [order_1_approx] starting weight calculation for Something without expression is expressionless
Something without penny is penniless
Something without gender is genderless
Something without law is lawless
Something without heart is heartless
Something without mirth is mirthless
Something without speech is speechless
Something without child is
2024-07-28 00:13:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 00:16:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1127, -0.2949,  0.0598,  ..., -0.3103, -0.5879,  0.0601],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8628, -1.7578,  1.7725,  ..., -2.3164, -2.2070, -0.1582],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0414, -0.0019,  0.0379,  ..., -0.0008, -0.0078,  0.0288],
        [-0.0044, -0.0133, -0.0100,  ..., -0.0075,  0.0135, -0.0016],
        [ 0.0047, -0.0024,  0.0340,  ..., -0.0134,  0.0016, -0.0291],
        ...,
        [ 0.0131, -0.0102,  0.0102,  ..., -0.0164,  0.0028,  0.0205],
        [-0.0036, -0.0331,  0.0000,  ..., -0.0101, -0.0003, -0.0497],
        [ 0.0004, -0.0128,  0.0124,  ..., -0.0265, -0.0263,  0.0069]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.5000, -1.8564,  1.6768,  ..., -2.4277, -1.7500, -1.0078]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 00:16:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without expression is expressionless
Something without penny is penniless
Something without gender is genderless
Something without law is lawless
Something without heart is heartless
Something without mirth is mirthless
Something without speech is speechless
Something without child is
2024-07-28 00:16:32 root INFO     total operator prediction time: 1319.044471025467 seconds
2024-07-28 00:16:32 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+ment_irreg
2024-07-28 00:16:32 root INFO     building operator verb+ment_irreg
2024-07-28 00:16:32 root INFO     [order_1_approx] starting weight calculation for To reinforce results in a reinforcement
To endorse results in a endorsement
To disagree results in a disagreement
To accomplish results in a accomplishment
To harass results in a harassment
To require results in a requirement
To embarrass results in a embarrassment
To enjoy results in a
2024-07-28 00:16:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 00:19:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0892,  0.2742, -0.0023,  ...,  0.1035, -0.1910, -0.0576],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0977, -1.8320,  0.6484,  ...,  2.4609, -2.0996, -1.4590],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.2367e-02,  4.6463e-03, -2.2324e-02,  ...,  1.2497e-02,
         -2.8725e-03,  4.7607e-03],
        [-4.7836e-03,  2.3071e-02, -3.1250e-02,  ..., -2.3071e-02,
          2.4780e-02,  9.6741e-03],
        [ 3.5004e-02, -7.1487e-03,  1.9867e-02,  ...,  8.5754e-03,
         -2.6703e-02,  2.9831e-03],
        ...,
        [ 7.7896e-03,  1.9867e-02,  7.6332e-03,  ...,  4.9347e-02,
          7.6294e-06, -2.0752e-03],
        [ 9.7656e-04,  1.3115e-02, -6.5727e-03,  ..., -3.0640e-02,
          1.8005e-02, -2.6398e-02],
        [-8.2550e-03, -7.4844e-03, -2.6901e-02,  ...,  2.1637e-02,
         -9.1629e-03,  1.9302e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.5117, -1.6270,  0.9287,  ...,  1.7852, -1.9678, -1.3594]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 00:19:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To reinforce results in a reinforcement
To endorse results in a endorsement
To disagree results in a disagreement
To accomplish results in a accomplishment
To harass results in a harassment
To require results in a requirement
To embarrass results in a embarrassment
To enjoy results in a
2024-07-28 00:19:17 root INFO     [order_1_approx] starting weight calculation for To endorse results in a endorsement
To disagree results in a disagreement
To harass results in a harassment
To enjoy results in a enjoyment
To require results in a requirement
To accomplish results in a accomplishment
To embarrass results in a embarrassment
To reinforce results in a
2024-07-28 00:19:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 00:22:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0105, -0.1161, -0.0110,  ...,  0.0883, -0.2710,  0.1504],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1211, -2.1016,  1.7949,  ...,  3.7402, -1.8633, -3.9160],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0370, -0.0032, -0.0130,  ..., -0.0149, -0.0348,  0.0397],
        [-0.0390,  0.0454, -0.0105,  ..., -0.0204,  0.0580, -0.0202],
        [ 0.0075, -0.0332,  0.0049,  ..., -0.0087, -0.0027,  0.0199],
        ...,
        [ 0.0198, -0.0232,  0.0024,  ...,  0.0359,  0.0019,  0.0292],
        [ 0.0032,  0.0023, -0.0091,  ..., -0.0129,  0.0549, -0.0156],
        [-0.0148, -0.0036, -0.0214,  ..., -0.0008, -0.0169,  0.0194]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1738, -1.9902,  2.1230,  ...,  3.2949, -2.0859, -3.6035]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 00:22:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To endorse results in a endorsement
To disagree results in a disagreement
To harass results in a harassment
To enjoy results in a enjoyment
To require results in a requirement
To accomplish results in a accomplishment
To embarrass results in a embarrassment
To reinforce results in a
2024-07-28 00:22:03 root INFO     [order_1_approx] starting weight calculation for To disagree results in a disagreement
To require results in a requirement
To reinforce results in a reinforcement
To enjoy results in a enjoyment
To harass results in a harassment
To accomplish results in a accomplishment
To endorse results in a endorsement
To embarrass results in a
2024-07-28 00:22:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 00:24:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2559,  0.2944, -0.4248,  ...,  0.1086, -0.3306,  0.3530],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3633, -0.9658,  1.1602,  ...,  1.9883,  2.7129, -2.1562],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0765,  0.0081, -0.0145,  ..., -0.0020, -0.0249,  0.0155],
        [-0.0118,  0.0555,  0.0095,  ..., -0.0127,  0.0102,  0.0130],
        [-0.0225, -0.0193, -0.0065,  ...,  0.0114, -0.0121, -0.0115],
        ...,
        [ 0.0172,  0.0338, -0.0428,  ...,  0.0100,  0.0019, -0.0047],
        [ 0.0142,  0.0020, -0.0227,  ...,  0.0331, -0.0107, -0.0278],
        [-0.0011,  0.0485,  0.0107,  ..., -0.0053, -0.0479,  0.0372]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3008, -1.3418,  1.5488,  ...,  1.9482,  2.7344, -1.7490]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 00:24:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To disagree results in a disagreement
To require results in a requirement
To reinforce results in a reinforcement
To enjoy results in a enjoyment
To harass results in a harassment
To accomplish results in a accomplishment
To endorse results in a endorsement
To embarrass results in a
2024-07-28 00:24:51 root INFO     [order_1_approx] starting weight calculation for To require results in a requirement
To accomplish results in a accomplishment
To enjoy results in a enjoyment
To reinforce results in a reinforcement
To embarrass results in a embarrassment
To disagree results in a disagreement
To endorse results in a endorsement
To harass results in a
2024-07-28 00:24:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 00:27:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1816,  0.0649, -0.2729,  ..., -0.0076, -0.3232, -0.1825],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5469, -3.4688,  0.7261,  ...,  0.4912, -0.3108, -1.8438],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0570,  0.0138,  0.0123,  ..., -0.0174, -0.0185,  0.0089],
        [-0.0171,  0.0431, -0.0163,  ..., -0.0173,  0.0190,  0.0057],
        [-0.0119, -0.0116,  0.0221,  ..., -0.0061, -0.0171, -0.0089],
        ...,
        [ 0.0149,  0.0286, -0.0288,  ...,  0.0421,  0.0004, -0.0241],
        [-0.0036, -0.0480, -0.0005,  ...,  0.0464,  0.0539, -0.0041],
        [ 0.0032,  0.0266, -0.0163,  ..., -0.0054, -0.0422,  0.0229]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4648, -3.7656,  0.7812,  ...,  0.9170, -0.4463, -1.3379]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 00:27:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To require results in a requirement
To accomplish results in a accomplishment
To enjoy results in a enjoyment
To reinforce results in a reinforcement
To embarrass results in a embarrassment
To disagree results in a disagreement
To endorse results in a endorsement
To harass results in a
2024-07-28 00:27:36 root INFO     [order_1_approx] starting weight calculation for To embarrass results in a embarrassment
To endorse results in a endorsement
To accomplish results in a accomplishment
To disagree results in a disagreement
To enjoy results in a enjoyment
To reinforce results in a reinforcement
To harass results in a harassment
To require results in a
2024-07-28 00:27:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 00:30:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1345,  0.1567, -0.0615,  ..., -0.0780, -0.2227, -0.0996],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.0938, -4.0703, -0.7114,  ...,  0.1023, -4.8320, -2.7773],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0063,  0.0768,  0.0024,  ..., -0.0795, -0.0256,  0.0054],
        [ 0.0186, -0.0355, -0.0647,  ...,  0.1373, -0.0103,  0.0475],
        [-0.0283, -0.0099,  0.0433,  ..., -0.0537, -0.0146, -0.0033],
        ...,
        [ 0.0216, -0.0248, -0.0115,  ...,  0.1189,  0.0175,  0.0459],
        [ 0.0007,  0.0031,  0.0345,  ..., -0.0628,  0.0318, -0.0298],
        [ 0.0275, -0.0557, -0.0449,  ...,  0.0806, -0.0468,  0.0717]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2852, -1.2207, -1.3613,  ...,  1.2383, -5.1367, -0.7773]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 00:30:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To embarrass results in a embarrassment
To endorse results in a endorsement
To accomplish results in a accomplishment
To disagree results in a disagreement
To enjoy results in a enjoyment
To reinforce results in a reinforcement
To harass results in a harassment
To require results in a
2024-07-28 00:30:19 root INFO     [order_1_approx] starting weight calculation for To embarrass results in a embarrassment
To accomplish results in a accomplishment
To enjoy results in a enjoyment
To disagree results in a disagreement
To harass results in a harassment
To require results in a requirement
To reinforce results in a reinforcement
To endorse results in a
2024-07-28 00:30:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 00:33:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1887,  0.3396, -0.2076,  ...,  0.1631, -0.1162,  0.1209],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.5156, -3.6895,  0.9136,  ...,  2.2383, -6.1016, -3.5508],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0488,  0.0004,  0.0761,  ..., -0.0035, -0.0572, -0.0564],
        [-0.0514,  0.0086, -0.0801,  ..., -0.0065,  0.0970,  0.0696],
        [ 0.0169, -0.0042,  0.0143,  ..., -0.0115, -0.0207, -0.0186],
        ...,
        [-0.0135,  0.0173, -0.0297,  ...,  0.0266,  0.0127,  0.0258],
        [ 0.0091, -0.0101, -0.0129,  ..., -0.0096,  0.0224,  0.0102],
        [-0.0126, -0.0137, -0.0439,  ...,  0.0067,  0.0026,  0.0231]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.2266, -3.3789,  0.9146,  ...,  2.2559, -5.8906, -3.4805]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 00:33:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To embarrass results in a embarrassment
To accomplish results in a accomplishment
To enjoy results in a enjoyment
To disagree results in a disagreement
To harass results in a harassment
To require results in a requirement
To reinforce results in a reinforcement
To endorse results in a
2024-07-28 00:33:06 root INFO     [order_1_approx] starting weight calculation for To require results in a requirement
To enjoy results in a enjoyment
To endorse results in a endorsement
To harass results in a harassment
To embarrass results in a embarrassment
To disagree results in a disagreement
To reinforce results in a reinforcement
To accomplish results in a
2024-07-28 00:33:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 00:35:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0029,  0.3279,  0.0297,  ...,  0.1842, -0.4795, -0.0701],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4453, -3.8633, -0.7539,  ...,  1.3174, -0.6528, -1.4355],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0406,  0.0406, -0.0511,  ..., -0.0833, -0.0293, -0.0125],
        [ 0.0743,  0.0044,  0.0705,  ...,  0.1299,  0.0770,  0.0218],
        [-0.0049, -0.0341,  0.0197,  ..., -0.0200, -0.0033,  0.0094],
        ...,
        [ 0.0490,  0.0080,  0.0341,  ...,  0.1638,  0.0564,  0.0133],
        [-0.0155,  0.0255, -0.0032,  ..., -0.0366,  0.0016, -0.0183],
        [ 0.0503, -0.0025,  0.0563,  ...,  0.0890, -0.0172,  0.0630]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4863, -3.3887, -0.4275,  ...,  1.5430, -0.8633, -1.6406]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 00:35:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To require results in a requirement
To enjoy results in a enjoyment
To endorse results in a endorsement
To harass results in a harassment
To embarrass results in a embarrassment
To disagree results in a disagreement
To reinforce results in a reinforcement
To accomplish results in a
2024-07-28 00:35:51 root INFO     [order_1_approx] starting weight calculation for To endorse results in a endorsement
To require results in a requirement
To harass results in a harassment
To reinforce results in a reinforcement
To embarrass results in a embarrassment
To enjoy results in a enjoyment
To accomplish results in a accomplishment
To disagree results in a
2024-07-28 00:35:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 00:38:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2766,  0.1367, -0.1169,  ...,  0.2773, -0.1318,  0.1597],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3594, -4.1133,  1.5537,  ...,  0.1990,  1.5820, -0.8916],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0039, -0.0375,  0.0491,  ..., -0.0299,  0.0052, -0.0017],
        [ 0.0751,  0.0711, -0.0823,  ..., -0.0151,  0.0201,  0.0221],
        [-0.0001, -0.0348,  0.0209,  ..., -0.0022,  0.0047,  0.0074],
        ...,
        [ 0.0108,  0.0333, -0.0132,  ...,  0.0326, -0.0061,  0.0181],
        [-0.0136, -0.0067, -0.0158,  ...,  0.0172, -0.0082, -0.0118],
        [ 0.0038,  0.0370, -0.0291,  ...,  0.0135, -0.0540,  0.0438]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5684, -4.0391,  1.3838,  ...,  0.5645,  1.2715, -0.8188]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 00:38:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To endorse results in a endorsement
To require results in a requirement
To harass results in a harassment
To reinforce results in a reinforcement
To embarrass results in a embarrassment
To enjoy results in a enjoyment
To accomplish results in a accomplishment
To disagree results in a
2024-07-28 00:38:36 root INFO     total operator prediction time: 1324.3133220672607 seconds
2024-07-28 00:38:36 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on UK_city - county
2024-07-28 00:38:36 root INFO     building operator UK_city - county
2024-07-28 00:38:36 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of leicester is in the county of midlands
In the United Kingdom, the city of glasgow is in the county of lowlands
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of chichester is in the county of sussex
In the United Kingdom, the city of lancaster is in the county of lancashire
In the United Kingdom, the city of chester is in the county of cheshire
In the United Kingdom, the city of dundee is in the county of lowlands
In the United Kingdom, the city of nottingham is in the county of
2024-07-28 00:38:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 00:42:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0387, -0.0595, -0.3235,  ...,  0.2649, -0.2324,  0.0111],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9697, -5.4492, -0.1509,  ..., -4.7031, -3.2031, -0.8872],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0008,  0.0090,  0.0146,  ..., -0.0046, -0.0159, -0.0028],
        [ 0.0010,  0.0071,  0.0090,  ...,  0.0019,  0.0078, -0.0012],
        [-0.0066,  0.0007,  0.0114,  ...,  0.0056,  0.0058, -0.0161],
        ...,
        [ 0.0049,  0.0023, -0.0103,  ...,  0.0236, -0.0021,  0.0020],
        [ 0.0117, -0.0043,  0.0010,  ..., -0.0087, -0.0122,  0.0007],
        [ 0.0009, -0.0106, -0.0013,  ..., -0.0007, -0.0113, -0.0034]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1348, -5.4727, -0.2302,  ..., -4.4844, -2.5156, -0.8096]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 00:42:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of leicester is in the county of midlands
In the United Kingdom, the city of glasgow is in the county of lowlands
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of chichester is in the county of sussex
In the United Kingdom, the city of lancaster is in the county of lancashire
In the United Kingdom, the city of chester is in the county of cheshire
In the United Kingdom, the city of dundee is in the county of lowlands
In the United Kingdom, the city of nottingham is in the county of
2024-07-28 00:42:11 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of nottingham is in the county of nottinghamshire
In the United Kingdom, the city of chichester is in the county of sussex
In the United Kingdom, the city of leicester is in the county of midlands
In the United Kingdom, the city of glasgow is in the county of lowlands
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of lancaster is in the county of lancashire
In the United Kingdom, the city of dundee is in the county of lowlands
In the United Kingdom, the city of chester is in the county of
2024-07-28 00:42:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 00:45:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0145,  0.1231, -0.1897,  ...,  0.0032, -0.4050, -0.0087],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.5703, -7.2578,  2.2695,  ..., -4.2852, -0.4131, -0.6587],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0239,  0.0156, -0.0204,  ...,  0.0066, -0.0091, -0.0482],
        [-0.0045,  0.0276,  0.0204,  ...,  0.0549, -0.0141, -0.0333],
        [-0.0497,  0.0239, -0.0109,  ...,  0.0524, -0.0029, -0.0451],
        ...,
        [ 0.0218,  0.0226, -0.0064,  ...,  0.0567,  0.0155, -0.0303],
        [ 0.0295, -0.0591, -0.0080,  ..., -0.0387, -0.0061,  0.0210],
        [ 0.0113, -0.0134, -0.0133,  ..., -0.0027, -0.0114, -0.0052]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.2266, -7.0391,  2.8633,  ..., -3.8301, -1.1016, -0.7012]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 00:45:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of nottingham is in the county of nottinghamshire
In the United Kingdom, the city of chichester is in the county of sussex
In the United Kingdom, the city of leicester is in the county of midlands
In the United Kingdom, the city of glasgow is in the county of lowlands
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of lancaster is in the county of lancashire
In the United Kingdom, the city of dundee is in the county of lowlands
In the United Kingdom, the city of chester is in the county of
2024-07-28 00:45:24 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of chichester is in the county of sussex
In the United Kingdom, the city of nottingham is in the county of nottinghamshire
In the United Kingdom, the city of lancaster is in the county of lancashire
In the United Kingdom, the city of chester is in the county of cheshire
In the United Kingdom, the city of glasgow is in the county of lowlands
In the United Kingdom, the city of dundee is in the county of lowlands
In the United Kingdom, the city of leicester is in the county of
2024-07-28 00:45:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 00:48:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1022, -0.0679, -0.2024,  ...,  0.0325, -0.1980,  0.0509],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4004, -5.1758,  1.2275,  ..., -4.6602, -3.2578, -0.8379],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.8708e-03,  6.2485e-03, -9.8343e-03,  ...,  5.1689e-03,
         -2.2278e-02,  3.6926e-03],
        [-1.2314e-02,  8.9264e-03,  1.4992e-03,  ...,  7.0343e-03,
          2.7847e-03, -1.8021e-02],
        [-6.3820e-03,  1.3924e-03,  4.3602e-03,  ...,  8.2016e-03,
          7.6637e-03, -2.5574e-02],
        ...,
        [ 1.3641e-02,  9.6970e-03,  3.3951e-03,  ...,  2.5070e-02,
          1.3847e-03, -2.3651e-02],
        [ 2.3438e-02, -1.4008e-02,  1.2238e-02,  ...,  1.1612e-02,
         -1.2665e-02, -1.4275e-02],
        [-9.1553e-05, -8.7357e-03, -5.8174e-03,  ..., -1.6346e-03,
         -1.2230e-02, -5.3329e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3311, -4.9336,  1.2100,  ..., -4.5938, -3.2637, -0.6035]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 00:48:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of chichester is in the county of sussex
In the United Kingdom, the city of nottingham is in the county of nottinghamshire
In the United Kingdom, the city of lancaster is in the county of lancashire
In the United Kingdom, the city of chester is in the county of cheshire
In the United Kingdom, the city of glasgow is in the county of lowlands
In the United Kingdom, the city of dundee is in the county of lowlands
In the United Kingdom, the city of leicester is in the county of
2024-07-28 00:48:44 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of chichester is in the county of sussex
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of glasgow is in the county of lowlands
In the United Kingdom, the city of chester is in the county of cheshire
In the United Kingdom, the city of leicester is in the county of midlands
In the United Kingdom, the city of nottingham is in the county of nottinghamshire
In the United Kingdom, the city of lancaster is in the county of lancashire
In the United Kingdom, the city of dundee is in the county of
2024-07-28 00:48:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 00:51:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0638, -0.0212, -0.0374,  ...,  0.3374, -0.1080, -0.0844],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4121, -3.9082,  1.3037,  ..., -4.3398, -5.1992, -0.6826],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0006,  0.0060,  0.0181,  ...,  0.0103, -0.0045, -0.0196],
        [-0.0104,  0.0098,  0.0244,  ...,  0.0140, -0.0131, -0.0259],
        [-0.0225,  0.0115,  0.0280,  ...,  0.0052,  0.0011, -0.0247],
        ...,
        [-0.0012,  0.0105, -0.0016,  ...,  0.0080, -0.0043, -0.0245],
        [ 0.0232, -0.0098,  0.0069,  ...,  0.0023,  0.0021,  0.0040],
        [-0.0023, -0.0196, -0.0042,  ..., -0.0037, -0.0135,  0.0239]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0898, -4.0195,  0.6860,  ..., -4.0312, -4.8711, -0.6553]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 00:52:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of chichester is in the county of sussex
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of glasgow is in the county of lowlands
In the United Kingdom, the city of chester is in the county of cheshire
In the United Kingdom, the city of leicester is in the county of midlands
In the United Kingdom, the city of nottingham is in the county of nottinghamshire
In the United Kingdom, the city of lancaster is in the county of lancashire
In the United Kingdom, the city of dundee is in the county of
2024-07-28 00:52:03 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of nottingham is in the county of nottinghamshire
In the United Kingdom, the city of lancaster is in the county of lancashire
In the United Kingdom, the city of leicester is in the county of midlands
In the United Kingdom, the city of dundee is in the county of lowlands
In the United Kingdom, the city of chester is in the county of cheshire
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of glasgow is in the county of lowlands
In the United Kingdom, the city of chichester is in the county of
2024-07-28 00:52:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 00:55:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0121,  0.2073, -0.4976,  ...,  0.2627, -0.1975, -0.1099],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.5977, -6.8906,  1.3896,  ..., -4.0000,  0.1758, -2.2461],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0125, -0.0081, -0.0004,  ..., -0.0042, -0.0023, -0.0388],
        [-0.0180,  0.0104,  0.0151,  ...,  0.0174,  0.0172, -0.0203],
        [-0.0180, -0.0096, -0.0172,  ...,  0.0057,  0.0237, -0.0140],
        ...,
        [ 0.0191, -0.0091, -0.0093,  ...,  0.0180, -0.0004,  0.0046],
        [ 0.0071, -0.0379,  0.0258,  ...,  0.0139,  0.0117, -0.0261],
        [-0.0078, -0.0115, -0.0043,  ..., -0.0139, -0.0047,  0.0156]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.4805, -7.1094,  1.0400,  ..., -3.2168,  0.3188, -2.4727]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 00:55:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of nottingham is in the county of nottinghamshire
In the United Kingdom, the city of lancaster is in the county of lancashire
In the United Kingdom, the city of leicester is in the county of midlands
In the United Kingdom, the city of dundee is in the county of lowlands
In the United Kingdom, the city of chester is in the county of cheshire
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of glasgow is in the county of lowlands
In the United Kingdom, the city of chichester is in the county of
2024-07-28 00:55:22 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of nottingham is in the county of nottinghamshire
In the United Kingdom, the city of chester is in the county of cheshire
In the United Kingdom, the city of leicester is in the county of midlands
In the United Kingdom, the city of glasgow is in the county of lowlands
In the United Kingdom, the city of dundee is in the county of lowlands
In the United Kingdom, the city of chichester is in the county of sussex
In the United Kingdom, the city of lancaster is in the county of lancashire
In the United Kingdom, the city of swansea is in the county of
2024-07-28 00:55:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 00:58:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 2.4414e-04, -4.2908e-02, -4.4653e-01,  ...,  1.9336e-01,
        -2.1362e-01,  1.4111e-01], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.9453, -7.2578,  1.9248,  ..., -3.2969, -1.3379, -0.4971],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0086,  0.0075,  0.0089,  ..., -0.0028, -0.0027, -0.0120],
        [-0.0031,  0.0096,  0.0033,  ...,  0.0008, -0.0035, -0.0006],
        [-0.0262,  0.0005,  0.0061,  ...,  0.0145,  0.0171, -0.0297],
        ...,
        [-0.0022,  0.0025,  0.0001,  ...,  0.0084,  0.0141, -0.0139],
        [ 0.0028,  0.0007,  0.0087,  ..., -0.0038, -0.0160,  0.0070],
        [-0.0043, -0.0148,  0.0027,  ..., -0.0008,  0.0030, -0.0097]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.6562, -7.4414,  1.7021,  ..., -3.3281, -1.2188, -0.3032]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 00:58:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of nottingham is in the county of nottinghamshire
In the United Kingdom, the city of chester is in the county of cheshire
In the United Kingdom, the city of leicester is in the county of midlands
In the United Kingdom, the city of glasgow is in the county of lowlands
In the United Kingdom, the city of dundee is in the county of lowlands
In the United Kingdom, the city of chichester is in the county of sussex
In the United Kingdom, the city of lancaster is in the county of lancashire
In the United Kingdom, the city of swansea is in the county of
2024-07-28 00:58:41 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of chester is in the county of cheshire
In the United Kingdom, the city of nottingham is in the county of nottinghamshire
In the United Kingdom, the city of glasgow is in the county of lowlands
In the United Kingdom, the city of chichester is in the county of sussex
In the United Kingdom, the city of dundee is in the county of lowlands
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of leicester is in the county of midlands
In the United Kingdom, the city of lancaster is in the county of
2024-07-28 00:58:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 01:01:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0352, -0.0082, -0.4512,  ...,  0.0660, -0.4634, -0.1189],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0605, -7.1562,  2.3887,  ..., -6.2852,  2.1152, -0.0400],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.2196e-02,  9.6512e-03, -7.6294e-05,  ..., -1.3870e-02,
          2.2263e-02, -1.1002e-02],
        [-1.0361e-02,  1.6174e-02,  3.0518e-02,  ...,  2.7863e-02,
         -1.7517e-02, -4.5288e-02],
        [-3.6591e-02,  3.6224e-02,  5.6000e-03,  ...,  4.0344e-02,
         -6.0959e-03, -6.9641e-02],
        ...,
        [ 3.2082e-03,  5.4398e-03, -6.8283e-03,  ...,  1.5518e-02,
         -9.2316e-03,  1.2733e-02],
        [-7.1621e-04, -6.1150e-03,  1.9775e-02,  ..., -6.1035e-03,
         -1.5900e-02, -4.0344e-02],
        [-5.3101e-03, -1.2520e-02, -1.5152e-02,  ..., -1.9836e-03,
         -1.2215e-02,  6.0387e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6445, -7.3203,  2.3633,  ..., -6.0195,  2.1172, -0.0710]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 01:01:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of chester is in the county of cheshire
In the United Kingdom, the city of nottingham is in the county of nottinghamshire
In the United Kingdom, the city of glasgow is in the county of lowlands
In the United Kingdom, the city of chichester is in the county of sussex
In the United Kingdom, the city of dundee is in the county of lowlands
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of leicester is in the county of midlands
In the United Kingdom, the city of lancaster is in the county of
2024-07-28 01:01:59 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of leicester is in the county of midlands
In the United Kingdom, the city of lancaster is in the county of lancashire
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of nottingham is in the county of nottinghamshire
In the United Kingdom, the city of chichester is in the county of sussex
In the United Kingdom, the city of chester is in the county of cheshire
In the United Kingdom, the city of dundee is in the county of lowlands
In the United Kingdom, the city of glasgow is in the county of
2024-07-28 01:01:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 01:05:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0168,  0.3176, -0.3071,  ...,  0.2412,  0.0579,  0.0452],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4395, -6.2109,  1.5107,  ..., -6.3945,  0.9531, -2.0371],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0081, -0.0082,  0.0097,  ...,  0.0077, -0.0127, -0.0299],
        [-0.0126,  0.0100,  0.0158,  ...,  0.0367,  0.0059, -0.0250],
        [-0.0250,  0.0096,  0.0223,  ...,  0.0108,  0.0095, -0.0206],
        ...,
        [-0.0045, -0.0110,  0.0104,  ...,  0.0226,  0.0072, -0.0017],
        [ 0.0400, -0.0210,  0.0202,  ..., -0.0101, -0.0122,  0.0012],
        [ 0.0060, -0.0150, -0.0101,  ..., -0.0088, -0.0062,  0.0265]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4004, -5.9453,  1.5225,  ..., -5.8750,  0.5713, -1.9707]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 01:05:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of leicester is in the county of midlands
In the United Kingdom, the city of lancaster is in the county of lancashire
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of nottingham is in the county of nottinghamshire
In the United Kingdom, the city of chichester is in the county of sussex
In the United Kingdom, the city of chester is in the county of cheshire
In the United Kingdom, the city of dundee is in the county of lowlands
In the United Kingdom, the city of glasgow is in the county of
2024-07-28 01:05:21 root INFO     total operator prediction time: 1605.339518547058 seconds
2024-07-28 01:05:21 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on name - nationality
2024-07-28 01:05:21 root INFO     building operator name - nationality
2024-07-28 01:05:21 root INFO     [order_1_approx] starting weight calculation for stalin was soviet
fermi was italian
locke was english
gorbachev was soviet
lennon was english
dickens was english
maxwell was scottish
descartes was
2024-07-28 01:05:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 01:08:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1547,  0.0172, -0.1589,  ..., -0.2544, -0.2021,  0.1858],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.1328, -3.7988,  1.4883,  ..., -5.7109, -1.0137,  0.0088],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0558, -0.0112, -0.0223,  ..., -0.0049, -0.0057, -0.0803],
        [-0.0047,  0.0397,  0.0325,  ..., -0.0155, -0.0225,  0.0366],
        [ 0.0013, -0.0250,  0.0345,  ...,  0.0114,  0.0037, -0.0157],
        ...,
        [ 0.0300,  0.0059,  0.0100,  ...,  0.0068, -0.0290,  0.0505],
        [-0.0137,  0.0130,  0.0006,  ...,  0.0201,  0.0035, -0.0047],
        [-0.0443, -0.0012,  0.0038,  ...,  0.0150, -0.0048,  0.0452]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8359, -2.5273,  0.3887,  ..., -4.3633, -0.4390,  0.6104]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 01:08:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for stalin was soviet
fermi was italian
locke was english
gorbachev was soviet
lennon was english
dickens was english
maxwell was scottish
descartes was
2024-07-28 01:08:02 root INFO     [order_1_approx] starting weight calculation for gorbachev was soviet
locke was english
stalin was soviet
lennon was english
fermi was italian
descartes was french
maxwell was scottish
dickens was
2024-07-28 01:08:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 01:10:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1288,  0.4692, -0.3528,  ..., -0.0273, -0.0305, -0.0145],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2832, -2.2891,  2.1133,  ..., -4.3242,  0.6543, -3.4961],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0202, -0.0093,  0.0164,  ..., -0.0067,  0.0134, -0.0171],
        [ 0.0547,  0.0097,  0.0238,  ...,  0.0026, -0.0254,  0.0058],
        [-0.0449, -0.0213,  0.0394,  ...,  0.0322,  0.0559,  0.0091],
        ...,
        [ 0.0848,  0.0141,  0.0139,  ...,  0.0261, -0.0616,  0.0006],
        [ 0.0123, -0.0162,  0.0294,  ...,  0.0463,  0.0359, -0.0048],
        [ 0.0249,  0.0090,  0.0009,  ..., -0.0083, -0.0438,  0.0310]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7500, -2.0703,  2.2793,  ..., -3.8086,  0.2163, -2.8496]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 01:10:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for gorbachev was soviet
locke was english
stalin was soviet
lennon was english
fermi was italian
descartes was french
maxwell was scottish
dickens was
2024-07-28 01:10:47 root INFO     [order_1_approx] starting weight calculation for dickens was english
descartes was french
stalin was soviet
locke was english
lennon was english
maxwell was scottish
fermi was italian
gorbachev was
2024-07-28 01:10:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 01:13:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1494,  0.1095, -0.2583,  ...,  0.0105, -0.7080,  0.3613],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1621, -2.2285,  0.9141,  ..., -3.8535,  1.7227, -0.4268],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.3386e-02,  1.0895e-02,  1.3618e-02,  ..., -8.8959e-03,
         -2.2308e-02,  1.0979e-02],
        [-1.0880e-02,  1.7212e-02, -2.9907e-03,  ..., -5.2109e-03,
         -6.2675e-03, -4.0398e-03],
        [-1.7624e-02,  8.3008e-03,  3.2837e-02,  ..., -3.9749e-03,
          4.1656e-03, -6.8665e-03],
        ...,
        [-1.6083e-02, -1.5900e-02,  2.0409e-03,  ...,  3.8574e-02,
          8.0872e-03, -1.2939e-02],
        [-1.5106e-02,  3.5667e-03, -6.9046e-03,  ...,  5.5313e-05,
          8.9035e-03, -1.9798e-03],
        [ 1.5182e-03, -5.0583e-03, -6.3400e-03,  ..., -8.2245e-03,
         -1.2444e-02,  3.1830e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7314, -1.7627,  0.5859,  ..., -3.9102,  1.8662,  0.3174]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 01:13:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for dickens was english
descartes was french
stalin was soviet
locke was english
lennon was english
maxwell was scottish
fermi was italian
gorbachev was
2024-07-28 01:13:33 root INFO     [order_1_approx] starting weight calculation for maxwell was scottish
dickens was english
gorbachev was soviet
descartes was french
lennon was english
stalin was soviet
locke was english
fermi was
2024-07-28 01:13:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 01:16:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1053, -0.0557, -0.3848,  ...,  0.0115, -0.2656,  0.4663],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1289, -4.2188, -1.1875,  ..., -2.7109, -0.5361,  0.8901],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0657, -0.0396, -0.0087,  ..., -0.0291,  0.0051, -0.0983],
        [-0.0421,  0.0881,  0.0069,  ...,  0.0243, -0.0008,  0.1070],
        [ 0.0225, -0.0321,  0.0486,  ..., -0.0012,  0.0043, -0.0139],
        ...,
        [-0.0171,  0.0190,  0.0130,  ...,  0.0628,  0.0154,  0.0399],
        [-0.0202, -0.0287, -0.0076,  ...,  0.0372,  0.0320,  0.0095],
        [-0.0479,  0.0362,  0.0361,  ...,  0.0190, -0.0119,  0.0635]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3359, -2.0977, -1.5146,  ..., -2.0586, -0.3062,  1.1514]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 01:16:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for maxwell was scottish
dickens was english
gorbachev was soviet
descartes was french
lennon was english
stalin was soviet
locke was english
fermi was
2024-07-28 01:16:17 root INFO     [order_1_approx] starting weight calculation for maxwell was scottish
locke was english
stalin was soviet
descartes was french
fermi was italian
gorbachev was soviet
dickens was english
lennon was
2024-07-28 01:16:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 01:19:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1675,  0.1078, -0.0885,  ...,  0.0902, -0.1327,  0.2603],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.2656, -3.9922,  0.1270,  ..., -3.0078, -0.0454, -0.8008],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0057,  0.0226, -0.0196,  ...,  0.0060, -0.0076, -0.0118],
        [ 0.0429,  0.0192,  0.0305,  ..., -0.0169,  0.0100,  0.0006],
        [-0.0395, -0.0094,  0.0208,  ..., -0.0141, -0.0056, -0.0017],
        ...,
        [ 0.0130, -0.0173,  0.0476,  ...,  0.0697,  0.0330,  0.0124],
        [-0.0085, -0.0120,  0.0074,  ..., -0.0059, -0.0077, -0.0128],
        [ 0.0052, -0.0350,  0.0076,  ..., -0.0086, -0.0129,  0.0493]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.1797, -4.1250, -0.1185,  ..., -3.0586,  0.0149, -0.8081]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 01:19:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for maxwell was scottish
locke was english
stalin was soviet
descartes was french
fermi was italian
gorbachev was soviet
dickens was english
lennon was
2024-07-28 01:19:03 root INFO     [order_1_approx] starting weight calculation for fermi was italian
dickens was english
locke was english
stalin was soviet
descartes was french
gorbachev was soviet
lennon was english
maxwell was
2024-07-28 01:19:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 01:21:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1302, -0.0615, -0.1165,  ..., -0.1531, -0.1410,  0.2159],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2148, -3.4219, -0.3008,  ..., -3.9492, -1.3369, -1.7051],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0913, -0.0268,  0.0557,  ..., -0.0745, -0.0139, -0.0706],
        [-0.0653,  0.0865, -0.0475,  ...,  0.0300, -0.0366,  0.0715],
        [ 0.0280, -0.0071,  0.0493,  ...,  0.0228,  0.0078,  0.0019],
        ...,
        [ 0.0031, -0.0147, -0.0152,  ..., -0.0180, -0.0338, -0.0205],
        [ 0.0021, -0.0177, -0.0042,  ...,  0.0555,  0.0423, -0.0031],
        [-0.0486,  0.0276, -0.0376,  ..., -0.0181, -0.0442,  0.0983]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9375, -3.2051, -0.7886,  ..., -3.2266, -1.8574, -1.1660]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 01:21:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for fermi was italian
dickens was english
locke was english
stalin was soviet
descartes was french
gorbachev was soviet
lennon was english
maxwell was
2024-07-28 01:21:49 root INFO     [order_1_approx] starting weight calculation for gorbachev was soviet
descartes was french
fermi was italian
dickens was english
stalin was soviet
lennon was english
maxwell was scottish
locke was
2024-07-28 01:21:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 01:24:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0871,  0.1531, -0.3054,  ..., -0.2244, -0.1201,  0.0783],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7207, -2.0000,  1.2852,  ..., -4.8906, -0.1426, -3.7891],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0439,  0.0415, -0.0349,  ..., -0.0047,  0.0148, -0.0554],
        [-0.0132,  0.0181,  0.0475,  ..., -0.0064, -0.0356,  0.0256],
        [-0.0090,  0.0168,  0.0359,  ..., -0.0062,  0.0147, -0.0271],
        ...,
        [ 0.0166, -0.0180, -0.0022,  ...,  0.0557, -0.0399,  0.0481],
        [-0.0084,  0.0012,  0.0010,  ...,  0.0266,  0.0172, -0.0216],
        [-0.0052,  0.0055, -0.0171,  ..., -0.0136, -0.0206,  0.0660]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6465, -1.7227,  1.1611,  ..., -4.3789,  0.0873, -3.2188]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 01:24:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for gorbachev was soviet
descartes was french
fermi was italian
dickens was english
stalin was soviet
lennon was english
maxwell was scottish
locke was
2024-07-28 01:24:35 root INFO     [order_1_approx] starting weight calculation for dickens was english
gorbachev was soviet
locke was english
lennon was english
descartes was french
maxwell was scottish
fermi was italian
stalin was
2024-07-28 01:24:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 01:27:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1656, -0.0395, -0.4644,  ..., -0.0323, -0.2194,  0.2571],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0312, -1.9932, -0.2170,  ..., -4.3281,  0.6963, -0.3020],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.8137e-02,  1.8814e-02, -5.1651e-03,  ...,  1.5793e-02,
         -1.1429e-02, -9.7046e-03],
        [-1.1459e-02,  2.8152e-03,  2.1820e-03,  ...,  4.5776e-05,
          1.5869e-02, -1.0849e-02],
        [-7.2403e-03,  4.0627e-04,  2.7710e-02,  ...,  1.5907e-03,
          2.0966e-02, -5.1575e-03],
        ...,
        [-2.0081e-02,  1.4229e-02,  3.7811e-02,  ...,  2.6627e-02,
         -1.0651e-02, -9.5062e-03],
        [ 9.6130e-03, -9.4910e-03,  3.5858e-03,  ..., -3.5248e-03,
          7.6294e-03,  2.0203e-02],
        [-2.0721e-02,  1.0643e-02, -8.8501e-04,  ..., -2.6062e-02,
         -3.0060e-03,  3.9429e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6406, -1.7520, -0.2500,  ..., -4.9062,  0.9946,  0.4558]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 01:27:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for dickens was english
gorbachev was soviet
locke was english
lennon was english
descartes was french
maxwell was scottish
fermi was italian
stalin was
2024-07-28 01:27:20 root INFO     total operator prediction time: 1318.931500673294 seconds
2024-07-28 01:27:20 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on country - language
2024-07-28 01:27:20 root INFO     building operator country - language
2024-07-28 01:27:20 root INFO     [order_1_approx] starting weight calculation for The country of israel primarily speaks the language of hebrew
The country of jamaica primarily speaks the language of english
The country of iran primarily speaks the language of persian
The country of palestine primarily speaks the language of arabic
The country of nicaragua primarily speaks the language of spanish
The country of australia primarily speaks the language of english
The country of syria primarily speaks the language of arabic
The country of taiwan primarily speaks the language of
2024-07-28 01:27:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 01:30:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0267, -0.1544,  0.1940,  ...,  0.3088, -0.0829,  0.1382],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.8105, -2.1328,  2.1680,  ..., -0.5303, -2.9551, -0.0264],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0052, -0.0186,  0.0086,  ..., -0.0211,  0.0419,  0.0157],
        [-0.0146,  0.0322,  0.0041,  ..., -0.0065, -0.0081,  0.0097],
        [ 0.0053,  0.0243,  0.0221,  ...,  0.0085, -0.0374, -0.0303],
        ...,
        [ 0.0079,  0.0241,  0.0011,  ...,  0.0250, -0.0165, -0.0296],
        [-0.0143, -0.0174,  0.0168,  ..., -0.0099,  0.0288,  0.0183],
        [ 0.0067, -0.0159, -0.0135,  ...,  0.0008,  0.0106,  0.0441]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.3955, -2.1094,  1.6152,  ..., -0.8311, -2.9141,  0.0831]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 01:30:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of israel primarily speaks the language of hebrew
The country of jamaica primarily speaks the language of english
The country of iran primarily speaks the language of persian
The country of palestine primarily speaks the language of arabic
The country of nicaragua primarily speaks the language of spanish
The country of australia primarily speaks the language of english
The country of syria primarily speaks the language of arabic
The country of taiwan primarily speaks the language of
2024-07-28 01:30:07 root INFO     [order_1_approx] starting weight calculation for The country of palestine primarily speaks the language of arabic
The country of taiwan primarily speaks the language of chinese
The country of nicaragua primarily speaks the language of spanish
The country of iran primarily speaks the language of persian
The country of jamaica primarily speaks the language of english
The country of syria primarily speaks the language of arabic
The country of australia primarily speaks the language of english
The country of israel primarily speaks the language of
2024-07-28 01:30:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 01:32:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0968, -0.1015, -0.1324,  ..., -0.0606, -0.4656,  0.3027],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.2344, -4.3672,  0.7139,  ..., -4.5508, -0.3428, -1.9268],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.1962e-02, -1.3313e-03,  3.8147e-03,  ..., -1.5747e-02,
          6.0806e-03,  1.6144e-02],
        [ 1.4473e-02,  5.1346e-03, -2.4338e-03,  ..., -1.0262e-02,
         -8.3466e-03,  1.1322e-02],
        [-1.9226e-02,  1.8524e-02,  2.9694e-02,  ...,  2.9659e-04,
          1.0063e-02, -1.1177e-02],
        ...,
        [-2.3590e-02,  9.6283e-03, -3.6011e-03,  ...,  3.1616e-02,
          1.6754e-02, -2.1759e-02],
        [ 1.6525e-02, -2.4681e-03, -8.3923e-05,  ..., -1.4343e-02,
          1.4984e-02,  1.0910e-02],
        [ 2.3251e-03, -1.0590e-02, -8.6594e-03,  ..., -5.5313e-05,
         -1.1909e-02,  4.1565e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.4316, -3.7539,  0.7622,  ..., -4.3242, -0.4656, -1.8682]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 01:32:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of palestine primarily speaks the language of arabic
The country of taiwan primarily speaks the language of chinese
The country of nicaragua primarily speaks the language of spanish
The country of iran primarily speaks the language of persian
The country of jamaica primarily speaks the language of english
The country of syria primarily speaks the language of arabic
The country of australia primarily speaks the language of english
The country of israel primarily speaks the language of
2024-07-28 01:32:53 root INFO     [order_1_approx] starting weight calculation for The country of australia primarily speaks the language of english
The country of jamaica primarily speaks the language of english
The country of palestine primarily speaks the language of arabic
The country of nicaragua primarily speaks the language of spanish
The country of syria primarily speaks the language of arabic
The country of israel primarily speaks the language of hebrew
The country of taiwan primarily speaks the language of chinese
The country of iran primarily speaks the language of
2024-07-28 01:32:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 01:35:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0987, -0.0187, -0.1863,  ..., -0.2808, -0.4329,  0.2671],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2590, -4.7148, -0.5244,  ..., -0.4038, -1.8145, -2.6523],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0074,  0.0123,  0.0044,  ..., -0.0386,  0.0199,  0.0359],
        [-0.0025,  0.0158,  0.0112,  ..., -0.0110, -0.0089,  0.0120],
        [-0.0238, -0.0185,  0.0476,  ..., -0.0009, -0.0052, -0.0275],
        ...,
        [-0.0004, -0.0035,  0.0050,  ...,  0.0314, -0.0129, -0.0328],
        [-0.0004,  0.0050,  0.0212,  ..., -0.0296,  0.0416,  0.0141],
        [ 0.0059, -0.0038,  0.0051,  ..., -0.0070, -0.0037,  0.0331]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2314, -4.0625, -0.4502,  ..., -0.4475, -1.4395, -2.5156]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 01:35:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of australia primarily speaks the language of english
The country of jamaica primarily speaks the language of english
The country of palestine primarily speaks the language of arabic
The country of nicaragua primarily speaks the language of spanish
The country of syria primarily speaks the language of arabic
The country of israel primarily speaks the language of hebrew
The country of taiwan primarily speaks the language of chinese
The country of iran primarily speaks the language of
2024-07-28 01:35:39 root INFO     [order_1_approx] starting weight calculation for The country of australia primarily speaks the language of english
The country of taiwan primarily speaks the language of chinese
The country of syria primarily speaks the language of arabic
The country of israel primarily speaks the language of hebrew
The country of jamaica primarily speaks the language of english
The country of nicaragua primarily speaks the language of spanish
The country of iran primarily speaks the language of persian
The country of palestine primarily speaks the language of
2024-07-28 01:35:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 01:38:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0476, -0.1301, -0.2839,  ...,  0.1504, -0.3936,  0.0648],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2769, -5.0039,  0.2155,  ..., -2.2891,  0.7354, -0.9482],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0161, -0.0056,  0.0097,  ...,  0.0076,  0.0115,  0.0016],
        [ 0.0282,  0.0159,  0.0105,  ..., -0.0141,  0.0116, -0.0008],
        [-0.0271, -0.0061,  0.0078,  ..., -0.0131,  0.0008, -0.0081],
        ...,
        [-0.0087,  0.0043, -0.0170,  ...,  0.0054, -0.0048, -0.0222],
        [-0.0078, -0.0068,  0.0125,  ...,  0.0043,  0.0065, -0.0001],
        [-0.0041, -0.0045, -0.0028,  ..., -0.0060, -0.0011,  0.0117]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4189, -4.8438, -0.0641,  ..., -2.2734,  0.7090, -0.6670]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 01:38:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of australia primarily speaks the language of english
The country of taiwan primarily speaks the language of chinese
The country of syria primarily speaks the language of arabic
The country of israel primarily speaks the language of hebrew
The country of jamaica primarily speaks the language of english
The country of nicaragua primarily speaks the language of spanish
The country of iran primarily speaks the language of persian
The country of palestine primarily speaks the language of
2024-07-28 01:38:25 root INFO     [order_1_approx] starting weight calculation for The country of taiwan primarily speaks the language of chinese
The country of iran primarily speaks the language of persian
The country of israel primarily speaks the language of hebrew
The country of syria primarily speaks the language of arabic
The country of australia primarily speaks the language of english
The country of jamaica primarily speaks the language of english
The country of palestine primarily speaks the language of arabic
The country of nicaragua primarily speaks the language of
2024-07-28 01:38:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 01:41:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0707, -0.3831, -0.2244,  ...,  0.1842, -0.4956, -0.1956],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3496, -2.1797,  1.3584,  ..., -0.3103, -1.0586, -4.1133],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0188, -0.0195,  0.0101,  ..., -0.0201,  0.0097,  0.0124],
        [ 0.0040,  0.0099,  0.0155,  ..., -0.0031, -0.0075,  0.0106],
        [-0.0203,  0.0193,  0.0048,  ...,  0.0021, -0.0090, -0.0278],
        ...,
        [-0.0077,  0.0149, -0.0193,  ...,  0.0158, -0.0099, -0.0233],
        [ 0.0033, -0.0113,  0.0068,  ..., -0.0045,  0.0220,  0.0045],
        [ 0.0078, -0.0140, -0.0041,  ..., -0.0045, -0.0047,  0.0184]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0364, -2.0723,  0.7646,  ..., -0.6479, -0.9473, -3.7109]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 01:41:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of taiwan primarily speaks the language of chinese
The country of iran primarily speaks the language of persian
The country of israel primarily speaks the language of hebrew
The country of syria primarily speaks the language of arabic
The country of australia primarily speaks the language of english
The country of jamaica primarily speaks the language of english
The country of palestine primarily speaks the language of arabic
The country of nicaragua primarily speaks the language of
2024-07-28 01:41:15 root INFO     [order_1_approx] starting weight calculation for The country of nicaragua primarily speaks the language of spanish
The country of jamaica primarily speaks the language of english
The country of syria primarily speaks the language of arabic
The country of iran primarily speaks the language of persian
The country of palestine primarily speaks the language of arabic
The country of israel primarily speaks the language of hebrew
The country of taiwan primarily speaks the language of chinese
The country of australia primarily speaks the language of
2024-07-28 01:41:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 01:43:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0355,  0.0254, -0.1042,  ...,  0.1936, -0.3789,  0.1246],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1494, -2.0000,  1.6797,  ..., -0.3726, -1.3730, -1.7295],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0228, -0.0213,  0.0123,  ..., -0.0071, -0.0052,  0.0193],
        [ 0.0256, -0.0051,  0.0191,  ..., -0.0014,  0.0058,  0.0091],
        [-0.0234,  0.0148,  0.0068,  ...,  0.0085, -0.0066, -0.0126],
        ...,
        [-0.0222,  0.0145, -0.0086,  ...,  0.0088,  0.0027, -0.0175],
        [ 0.0037,  0.0052,  0.0252,  ...,  0.0103,  0.0175, -0.0073],
        [ 0.0103, -0.0350, -0.0064,  ..., -0.0002, -0.0098,  0.0291]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6152, -1.4824,  1.2314,  ..., -0.8950, -1.4678, -1.2393]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 01:43:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of nicaragua primarily speaks the language of spanish
The country of jamaica primarily speaks the language of english
The country of syria primarily speaks the language of arabic
The country of iran primarily speaks the language of persian
The country of palestine primarily speaks the language of arabic
The country of israel primarily speaks the language of hebrew
The country of taiwan primarily speaks the language of chinese
The country of australia primarily speaks the language of
2024-07-28 01:43:58 root INFO     [order_1_approx] starting weight calculation for The country of taiwan primarily speaks the language of chinese
The country of syria primarily speaks the language of arabic
The country of australia primarily speaks the language of english
The country of iran primarily speaks the language of persian
The country of nicaragua primarily speaks the language of spanish
The country of israel primarily speaks the language of hebrew
The country of palestine primarily speaks the language of arabic
The country of jamaica primarily speaks the language of
2024-07-28 01:43:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 01:46:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2056,  0.0366, -0.3408,  ...,  0.0613, -0.2881, -0.2612],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9336,  0.2988,  1.8379,  ...,  0.6030,  0.8848, -2.4629],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0066, -0.0091,  0.0212,  ..., -0.0038, -0.0023,  0.0252],
        [ 0.0023,  0.0096, -0.0057,  ..., -0.0013,  0.0033, -0.0061],
        [-0.0160,  0.0058,  0.0302,  ..., -0.0122, -0.0039,  0.0002],
        ...,
        [-0.0083,  0.0060, -0.0118,  ...,  0.0030,  0.0047, -0.0358],
        [-0.0106,  0.0070,  0.0098,  ...,  0.0036,  0.0190,  0.0247],
        [ 0.0034, -0.0002, -0.0057,  ..., -0.0048, -0.0050,  0.0086]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1270,  0.3784,  1.7559,  ...,  0.3289,  0.9019, -2.1719]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 01:46:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of taiwan primarily speaks the language of chinese
The country of syria primarily speaks the language of arabic
The country of australia primarily speaks the language of english
The country of iran primarily speaks the language of persian
The country of nicaragua primarily speaks the language of spanish
The country of israel primarily speaks the language of hebrew
The country of palestine primarily speaks the language of arabic
The country of jamaica primarily speaks the language of
2024-07-28 01:46:46 root INFO     [order_1_approx] starting weight calculation for The country of taiwan primarily speaks the language of chinese
The country of jamaica primarily speaks the language of english
The country of nicaragua primarily speaks the language of spanish
The country of palestine primarily speaks the language of arabic
The country of iran primarily speaks the language of persian
The country of australia primarily speaks the language of english
The country of israel primarily speaks the language of hebrew
The country of syria primarily speaks the language of
2024-07-28 01:46:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 01:49:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1840, -0.1121, -0.2124,  ...,  0.0027, -0.4971,  0.2759],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.8086, -4.3594,  0.3691,  ..., -1.4609,  0.7012, -1.5938],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0161, -0.0172,  0.0126,  ..., -0.0284,  0.0077,  0.0317],
        [ 0.0164,  0.0083,  0.0105,  ..., -0.0118,  0.0011,  0.0102],
        [-0.0380,  0.0262,  0.0207,  ...,  0.0051, -0.0123, -0.0342],
        ...,
        [-0.0287,  0.0302, -0.0040,  ...,  0.0403, -0.0047, -0.0299],
        [ 0.0059, -0.0124,  0.0137,  ...,  0.0061,  0.0203, -0.0017],
        [ 0.0044, -0.0258,  0.0038,  ...,  0.0029, -0.0099,  0.0023]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.0723, -3.8457,  0.2661,  ..., -1.3252,  0.8257, -1.7119]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 01:49:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of taiwan primarily speaks the language of chinese
The country of jamaica primarily speaks the language of english
The country of nicaragua primarily speaks the language of spanish
The country of palestine primarily speaks the language of arabic
The country of iran primarily speaks the language of persian
The country of australia primarily speaks the language of english
The country of israel primarily speaks the language of hebrew
The country of syria primarily speaks the language of
2024-07-28 01:49:32 root INFO     total operator prediction time: 1332.1904742717743 seconds
2024-07-28 01:49:32 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - shelter
2024-07-28 01:49:32 root INFO     building operator animal - shelter
2024-07-28 01:49:33 root INFO     [order_1_approx] starting weight calculation for The place wasp lives in is called nest
The place cattle lives in is called barn
The place ant lives in is called anthill
The place herring lives in is called sea
The place hornet lives in is called nest
The place dog lives in is called doghouse
The place chimpanzee lives in is called grove
The place trout lives in is called
2024-07-28 01:49:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 01:52:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2866,  0.1421, -0.2966,  ..., -0.1278, -0.1890, -0.1066],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4141, -4.9102,  1.8633,  ..., -3.0742, -0.6074, -3.3438],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0380, -0.0067, -0.0132,  ...,  0.0032, -0.0165, -0.0042],
        [ 0.0032,  0.0704, -0.0059,  ...,  0.0164, -0.0183, -0.0201],
        [-0.0033, -0.0245,  0.0406,  ..., -0.0143, -0.0150, -0.0261],
        ...,
        [ 0.0241,  0.0308,  0.0276,  ...,  0.0578,  0.0176, -0.0086],
        [ 0.0323, -0.0138,  0.0040,  ...,  0.0019,  0.0349, -0.0065],
        [-0.0224, -0.0174, -0.0027,  ..., -0.0350, -0.0189,  0.0463]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6582, -4.9492,  1.9307,  ..., -3.3633, -0.6172, -2.5918]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 01:52:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place wasp lives in is called nest
The place cattle lives in is called barn
The place ant lives in is called anthill
The place herring lives in is called sea
The place hornet lives in is called nest
The place dog lives in is called doghouse
The place chimpanzee lives in is called grove
The place trout lives in is called
2024-07-28 01:52:20 root INFO     [order_1_approx] starting weight calculation for The place hornet lives in is called nest
The place cattle lives in is called barn
The place trout lives in is called river
The place wasp lives in is called nest
The place ant lives in is called anthill
The place dog lives in is called doghouse
The place chimpanzee lives in is called grove
The place herring lives in is called
2024-07-28 01:52:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 01:55:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1125,  0.0399, -0.3638,  ..., -0.1823, -0.0307, -0.2288],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2695, -5.2109,  1.4561,  ..., -2.8965, -1.0557, -1.3691],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0341,  0.0226,  0.0002,  ...,  0.0328,  0.0144, -0.0212],
        [ 0.0011,  0.0385, -0.0267,  ...,  0.0276, -0.0012, -0.0520],
        [-0.0303,  0.0042,  0.0153,  ..., -0.0311, -0.0190,  0.0184],
        ...,
        [ 0.0384,  0.0327,  0.0446,  ...,  0.0648,  0.0026, -0.0051],
        [-0.0189,  0.0045, -0.0205,  ...,  0.0272,  0.0314,  0.0079],
        [-0.0054, -0.0031, -0.0125,  ...,  0.0106,  0.0110,  0.0344]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6230, -5.1484,  1.5156,  ..., -2.9766, -0.7969, -1.5127]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 01:55:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place hornet lives in is called nest
The place cattle lives in is called barn
The place trout lives in is called river
The place wasp lives in is called nest
The place ant lives in is called anthill
The place dog lives in is called doghouse
The place chimpanzee lives in is called grove
The place herring lives in is called
2024-07-28 01:55:08 root INFO     [order_1_approx] starting weight calculation for The place ant lives in is called anthill
The place dog lives in is called doghouse
The place wasp lives in is called nest
The place herring lives in is called sea
The place hornet lives in is called nest
The place chimpanzee lives in is called grove
The place trout lives in is called river
The place cattle lives in is called
2024-07-28 01:55:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 01:57:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0685, -0.0434, -0.0867,  ..., -0.1063,  0.1895,  0.0770],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5566, -6.7617,  3.3984,  ..., -3.6133,  3.6562, -1.5137],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0388, -0.0146,  0.0026,  ..., -0.0230, -0.0274,  0.0200],
        [-0.0168,  0.0144, -0.0320,  ...,  0.0217, -0.0223, -0.0057],
        [-0.0063, -0.0034,  0.0958,  ..., -0.0217,  0.0223,  0.0000],
        ...,
        [-0.0042,  0.0130, -0.0104,  ...,  0.0392,  0.0064, -0.0018],
        [ 0.0152,  0.0359,  0.0106,  ...,  0.0145,  0.0643, -0.0123],
        [-0.0046, -0.0307, -0.0026,  ..., -0.0195, -0.0103,  0.0323]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5957, -6.0312,  2.6816,  ..., -3.6426,  2.9141, -0.9653]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 01:57:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place ant lives in is called anthill
The place dog lives in is called doghouse
The place wasp lives in is called nest
The place herring lives in is called sea
The place hornet lives in is called nest
The place chimpanzee lives in is called grove
The place trout lives in is called river
The place cattle lives in is called
2024-07-28 01:57:52 root INFO     [order_1_approx] starting weight calculation for The place chimpanzee lives in is called grove
The place cattle lives in is called barn
The place ant lives in is called anthill
The place herring lives in is called sea
The place dog lives in is called doghouse
The place trout lives in is called river
The place hornet lives in is called nest
The place wasp lives in is called
2024-07-28 01:57:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 02:00:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3611, -0.1521,  0.1798,  ...,  0.0562,  0.0222,  0.1030],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.2812, -4.8906,  3.6504,  ..., -2.1816,  0.7490,  1.1240],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0282, -0.0073,  0.0024,  ...,  0.0263, -0.0071, -0.0317],
        [-0.0082,  0.0532,  0.0100,  ...,  0.0429,  0.0148, -0.0316],
        [-0.0153,  0.0289,  0.0260,  ...,  0.0111, -0.0322,  0.0105],
        ...,
        [-0.0096,  0.0265, -0.0051,  ..., -0.0052,  0.0260, -0.0049],
        [-0.0094,  0.0116, -0.0008,  ...,  0.0072, -0.0014,  0.0260],
        [-0.0214, -0.0281, -0.0090,  ...,  0.0086, -0.0479,  0.0201]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.2891, -4.6602,  3.5918,  ..., -1.8730,  0.7612,  1.3848]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 02:00:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place chimpanzee lives in is called grove
The place cattle lives in is called barn
The place ant lives in is called anthill
The place herring lives in is called sea
The place dog lives in is called doghouse
The place trout lives in is called river
The place hornet lives in is called nest
The place wasp lives in is called
2024-07-28 02:00:38 root INFO     [order_1_approx] starting weight calculation for The place wasp lives in is called nest
The place cattle lives in is called barn
The place ant lives in is called anthill
The place dog lives in is called doghouse
The place hornet lives in is called nest
The place trout lives in is called river
The place herring lives in is called sea
The place chimpanzee lives in is called
2024-07-28 02:00:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 02:03:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0314, -0.2996, -0.2233,  ..., -0.2734, -0.3755,  0.2108],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8516, -8.1953,  3.7383,  ..., -1.5986, -0.4868,  1.0615],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.3929e-03, -7.0724e-03, -2.0409e-03,  ...,  1.4257e-03,
         -1.2390e-02,  1.2543e-02],
        [-1.3153e-02,  7.9803e-03, -1.7385e-03,  ..., -2.5082e-03,
         -4.5090e-03, -2.2221e-03],
        [-8.2588e-04,  1.6556e-03,  1.2238e-02,  ...,  3.9625e-04,
         -6.5899e-04, -4.5052e-03],
        ...,
        [-4.7684e-03,  5.4131e-03,  3.2425e-05,  ...,  8.4610e-03,
          3.9024e-03, -9.6436e-03],
        [ 2.2736e-03, -3.3417e-03,  3.2711e-04,  ..., -2.8458e-03,
          9.1019e-03,  2.9106e-03],
        [-6.3934e-03, -8.6975e-03, -1.7376e-03,  ...,  4.2458e-03,
         -6.1035e-03,  8.1711e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9297, -8.2344,  3.7871,  ..., -1.6104, -0.5264,  0.9619]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 02:03:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place wasp lives in is called nest
The place cattle lives in is called barn
The place ant lives in is called anthill
The place dog lives in is called doghouse
The place hornet lives in is called nest
The place trout lives in is called river
The place herring lives in is called sea
The place chimpanzee lives in is called
2024-07-28 02:03:24 root INFO     [order_1_approx] starting weight calculation for The place trout lives in is called river
The place dog lives in is called doghouse
The place wasp lives in is called nest
The place chimpanzee lives in is called grove
The place cattle lives in is called barn
The place hornet lives in is called nest
The place herring lives in is called sea
The place ant lives in is called
2024-07-28 02:03:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 02:06:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0557, -0.0891,  0.0343,  ..., -0.1504, -0.2117, -0.2456],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2393, -6.2891,  1.4150,  ..., -3.2246,  0.9507, -2.2500],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0540, -0.0078,  0.0133,  ...,  0.0290,  0.0070, -0.0064],
        [-0.0315,  0.0166, -0.0204,  ...,  0.0563,  0.0284, -0.0002],
        [-0.0122,  0.0209,  0.0206,  ..., -0.0443, -0.0293,  0.0212],
        ...,
        [-0.0006,  0.0018,  0.0010,  ...,  0.0395,  0.0335,  0.0047],
        [-0.0146, -0.0055,  0.0023,  ...,  0.0171,  0.0204,  0.0269],
        [-0.0240,  0.0020, -0.0046,  ...,  0.0129, -0.0341,  0.0380]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2803, -6.0820,  1.1807,  ..., -2.6680,  1.0391, -2.4160]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 02:06:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place trout lives in is called river
The place dog lives in is called doghouse
The place wasp lives in is called nest
The place chimpanzee lives in is called grove
The place cattle lives in is called barn
The place hornet lives in is called nest
The place herring lives in is called sea
The place ant lives in is called
2024-07-28 02:06:06 root INFO     [order_1_approx] starting weight calculation for The place dog lives in is called doghouse
The place wasp lives in is called nest
The place herring lives in is called sea
The place ant lives in is called anthill
The place trout lives in is called river
The place chimpanzee lives in is called grove
The place cattle lives in is called barn
The place hornet lives in is called
2024-07-28 02:06:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 02:08:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1348, -0.0357,  0.0629,  ...,  0.0208,  0.0155,  0.0467],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9492, -5.2695,  2.3184,  ..., -2.7422, -0.5508, -0.5107],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0430, -0.0059,  0.0095,  ...,  0.0108, -0.0268, -0.0026],
        [-0.0050,  0.0665,  0.0228,  ...,  0.0897,  0.0118,  0.0112],
        [-0.0294,  0.0238,  0.0496,  ..., -0.0066, -0.0036,  0.0133],
        ...,
        [-0.0093, -0.0127,  0.0210,  ...,  0.0387,  0.0083,  0.0164],
        [-0.0136,  0.0129, -0.0155,  ...,  0.0042,  0.0145,  0.0088],
        [-0.0399, -0.0094, -0.0175,  ...,  0.0157, -0.0374,  0.0337]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4609, -5.0820,  2.4512,  ..., -2.1133, -0.7642, -0.1421]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 02:08:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place dog lives in is called doghouse
The place wasp lives in is called nest
The place herring lives in is called sea
The place ant lives in is called anthill
The place trout lives in is called river
The place chimpanzee lives in is called grove
The place cattle lives in is called barn
The place hornet lives in is called
2024-07-28 02:08:51 root INFO     [order_1_approx] starting weight calculation for The place trout lives in is called river
The place wasp lives in is called nest
The place ant lives in is called anthill
The place herring lives in is called sea
The place cattle lives in is called barn
The place hornet lives in is called nest
The place chimpanzee lives in is called grove
The place dog lives in is called
2024-07-28 02:08:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 02:11:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1274,  0.0080, -0.0339,  ...,  0.0187, -0.1475,  0.0317],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3013, -6.4375,  3.9219,  ..., -1.8164,  0.7090,  0.6006],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0363, -0.0206,  0.0186,  ..., -0.0003, -0.0199,  0.0145],
        [-0.0222,  0.0272, -0.0353,  ...,  0.0230,  0.0116,  0.0023],
        [ 0.0067,  0.0023,  0.0243,  ...,  0.0264,  0.0168, -0.0070],
        ...,
        [-0.0086, -0.0062,  0.0396,  ..., -0.0044,  0.0052, -0.0087],
        [-0.0061, -0.0094, -0.0165,  ...,  0.0129,  0.0484,  0.0012],
        [-0.0264, -0.0150,  0.0036,  ...,  0.0170,  0.0082,  0.0275]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2354, -5.7812,  3.8672,  ..., -1.8721,  0.7280,  0.8418]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 02:11:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place trout lives in is called river
The place wasp lives in is called nest
The place ant lives in is called anthill
The place herring lives in is called sea
The place cattle lives in is called barn
The place hornet lives in is called nest
The place chimpanzee lives in is called grove
The place dog lives in is called
2024-07-28 02:11:36 root INFO     total operator prediction time: 1323.205515384674 seconds
2024-07-28 02:11:36 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on male - female
2024-07-28 02:11:36 root INFO     building operator male - female
2024-07-28 02:11:36 root INFO     [order_1_approx] starting weight calculation for A female god is known as a goddess
A female batman is known as a batwoman
A female daddy is known as a mommy
A female duke is known as a duchess
A female sculptor is known as a sculptress
A female stallion is known as a mare
A female buck is known as a doe
A female manager is known as a
2024-07-28 02:11:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 02:14:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0365,  0.2147, -0.0359,  ...,  0.3262, -0.2969, -0.2085],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.0156, -4.2422,  1.7139,  ...,  2.5723, -0.2554, -3.2754],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0515, -0.0172, -0.0003,  ...,  0.0107,  0.0167,  0.0157],
        [-0.0171,  0.0390, -0.0356,  ...,  0.0090,  0.0121, -0.0110],
        [-0.0076,  0.0138,  0.0671,  ..., -0.0399, -0.0365, -0.0014],
        ...,
        [-0.0190,  0.0235, -0.0131,  ...,  0.0405,  0.0091, -0.0263],
        [ 0.0287,  0.0077,  0.0356,  ..., -0.0136,  0.0269, -0.0140],
        [ 0.0049, -0.0169, -0.0471,  ...,  0.0074,  0.0289,  0.0191]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.8203, -4.3320,  1.6289,  ...,  2.5527, -0.7148, -3.2559]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 02:14:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female god is known as a goddess
A female batman is known as a batwoman
A female daddy is known as a mommy
A female duke is known as a duchess
A female sculptor is known as a sculptress
A female stallion is known as a mare
A female buck is known as a doe
A female manager is known as a
2024-07-28 02:14:17 root INFO     [order_1_approx] starting weight calculation for A female sculptor is known as a sculptress
A female stallion is known as a mare
A female buck is known as a doe
A female daddy is known as a mommy
A female duke is known as a duchess
A female god is known as a goddess
A female manager is known as a manageress
A female batman is known as a
2024-07-28 02:14:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 02:16:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1544,  0.2932, -0.0684,  ..., -0.2510, -0.2241,  0.2773],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4531, -4.6406,  2.9727,  ..., -0.9170, -1.4648,  0.1882],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0179, -0.0359,  0.0121,  ...,  0.0215,  0.0096,  0.0359],
        [-0.0096,  0.0276, -0.0058,  ...,  0.0323,  0.0252, -0.0216],
        [ 0.0226,  0.0314,  0.0191,  ..., -0.0225, -0.0203, -0.0283],
        ...,
        [-0.0011,  0.0137, -0.0290,  ...,  0.0605, -0.0170, -0.0038],
        [-0.0047, -0.0028, -0.0092,  ..., -0.0076, -0.0554, -0.0002],
        [-0.0067, -0.0087,  0.0059,  ..., -0.0126,  0.0284,  0.0465]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9746, -4.7305,  2.6543,  ..., -0.9463, -1.8887,  0.4058]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 02:17:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female sculptor is known as a sculptress
A female stallion is known as a mare
A female buck is known as a doe
A female daddy is known as a mommy
A female duke is known as a duchess
A female god is known as a goddess
A female manager is known as a manageress
A female batman is known as a
2024-07-28 02:17:01 root INFO     [order_1_approx] starting weight calculation for A female batman is known as a batwoman
A female god is known as a goddess
A female buck is known as a doe
A female stallion is known as a mare
A female daddy is known as a mommy
A female manager is known as a manageress
A female sculptor is known as a sculptress
A female duke is known as a
2024-07-28 02:17:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 02:19:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1372,  0.4932,  0.0687,  ..., -0.3271, -0.0615,  0.3821],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2905, -1.7686,  1.9004,  ..., -0.3057, -3.4316,  1.9053],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0334,  0.0065,  0.0385,  ..., -0.0540,  0.0171,  0.0116],
        [-0.0331,  0.0509, -0.0165,  ...,  0.0293,  0.0551,  0.0102],
        [ 0.0355, -0.0127,  0.0369,  ..., -0.0158,  0.0216, -0.0073],
        ...,
        [-0.0416,  0.0254, -0.0205,  ...,  0.0591, -0.0141, -0.0215],
        [ 0.0528, -0.0195,  0.0267,  ..., -0.0424,  0.0212,  0.0548],
        [ 0.0137, -0.0088,  0.0234,  ...,  0.0031, -0.0201,  0.0535]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3311, -2.0898,  1.5576,  ..., -0.3130, -3.5352,  1.6562]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 02:19:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female batman is known as a batwoman
A female god is known as a goddess
A female buck is known as a doe
A female stallion is known as a mare
A female daddy is known as a mommy
A female manager is known as a manageress
A female sculptor is known as a sculptress
A female duke is known as a
2024-07-28 02:19:44 root INFO     [order_1_approx] starting weight calculation for A female god is known as a goddess
A female buck is known as a doe
A female duke is known as a duchess
A female batman is known as a batwoman
A female stallion is known as a mare
A female sculptor is known as a sculptress
A female manager is known as a manageress
A female daddy is known as a
2024-07-28 02:19:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 02:22:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1458,  0.0132, -0.1941,  ..., -0.2365, -0.5327,  0.0627],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.3555, -4.3750, -1.7793,  ...,  1.0820, -4.7578, -0.8730],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0687, -0.0429, -0.0174,  ...,  0.0021, -0.0024,  0.0446],
        [ 0.0069,  0.0551, -0.0059,  ...,  0.0183, -0.0211,  0.0148],
        [ 0.0236, -0.0356,  0.0600,  ...,  0.0192, -0.0171,  0.0091],
        ...,
        [ 0.0205, -0.0030,  0.0072,  ...,  0.0085, -0.0306,  0.0016],
        [ 0.0054, -0.0411,  0.0080,  ..., -0.0323,  0.0319,  0.0105],
        [-0.0272, -0.0039,  0.0386,  ...,  0.0047,  0.0338, -0.0267]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.3047, -4.5781, -1.9346,  ...,  1.2285, -4.7109, -1.1504]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 02:22:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female god is known as a goddess
A female buck is known as a doe
A female duke is known as a duchess
A female batman is known as a batwoman
A female stallion is known as a mare
A female sculptor is known as a sculptress
A female manager is known as a manageress
A female daddy is known as a
2024-07-28 02:22:28 root INFO     [order_1_approx] starting weight calculation for A female stallion is known as a mare
A female manager is known as a manageress
A female batman is known as a batwoman
A female daddy is known as a mommy
A female god is known as a goddess
A female sculptor is known as a sculptress
A female duke is known as a duchess
A female buck is known as a
2024-07-28 02:22:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 02:25:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3684,  0.1116,  0.0925,  ..., -0.0806, -0.2463,  0.1199],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1133, -2.7656, -1.2080,  ...,  2.4941, -5.5781,  1.0508],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0133,  0.0103,  0.0230,  ..., -0.0001,  0.0117,  0.0218],
        [-0.0042,  0.0745, -0.0226,  ...,  0.0699,  0.0241,  0.0036],
        [ 0.0078, -0.0153,  0.0185,  ...,  0.0043, -0.0182, -0.0511],
        ...,
        [-0.0299, -0.0073,  0.0062,  ...,  0.0555,  0.0280, -0.0189],
        [-0.0041,  0.0038,  0.0431,  ..., -0.0330,  0.0213,  0.0139],
        [ 0.0076,  0.0171, -0.0513,  ...,  0.0046,  0.0095, -0.0032]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2598, -2.7012, -1.0547,  ...,  2.1680, -5.3164,  1.8574]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 02:25:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female stallion is known as a mare
A female manager is known as a manageress
A female batman is known as a batwoman
A female daddy is known as a mommy
A female god is known as a goddess
A female sculptor is known as a sculptress
A female duke is known as a duchess
A female buck is known as a
2024-07-28 02:25:10 root INFO     [order_1_approx] starting weight calculation for A female batman is known as a batwoman
A female buck is known as a doe
A female daddy is known as a mommy
A female manager is known as a manageress
A female duke is known as a duchess
A female god is known as a goddess
A female stallion is known as a mare
A female sculptor is known as a
2024-07-28 02:25:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 02:27:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3252, -0.1622, -0.2910,  ..., -0.2646, -0.2607,  0.2435],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9590, -5.2930, -0.8633,  ...,  0.4619, -3.2812, -0.2842],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0033,  0.0034,  0.0028,  ...,  0.0221,  0.0130,  0.0228],
        [ 0.0119,  0.0044, -0.0253,  ...,  0.0110,  0.0119, -0.0001],
        [-0.0063,  0.0039,  0.0100,  ...,  0.0049, -0.0181, -0.0122],
        ...,
        [-0.0129,  0.0110,  0.0049,  ...,  0.0139,  0.0182,  0.0046],
        [ 0.0125,  0.0087,  0.0022,  ...,  0.0005,  0.0003, -0.0001],
        [ 0.0030,  0.0188, -0.0122,  ..., -0.0110, -0.0122, -0.0162]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5020, -5.0703, -0.8247,  ...,  0.9819, -3.2773, -0.0355]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 02:27:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female batman is known as a batwoman
A female buck is known as a doe
A female daddy is known as a mommy
A female manager is known as a manageress
A female duke is known as a duchess
A female god is known as a goddess
A female stallion is known as a mare
A female sculptor is known as a
2024-07-28 02:27:54 root INFO     [order_1_approx] starting weight calculation for A female duke is known as a duchess
A female batman is known as a batwoman
A female buck is known as a doe
A female stallion is known as a mare
A female manager is known as a manageress
A female sculptor is known as a sculptress
A female daddy is known as a mommy
A female god is known as a
2024-07-28 02:27:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 02:30:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0138,  0.3396,  0.0875,  ..., -0.0421, -0.2817, -0.1732],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.7539, -6.1172,  0.3452,  ..., -1.1299, -1.0986, -0.1309],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0321, -0.0131,  0.0301,  ...,  0.0043, -0.0128, -0.0120],
        [-0.0298,  0.0363, -0.0198,  ...,  0.0042,  0.0207,  0.0041],
        [-0.0014, -0.0103,  0.0424,  ...,  0.0072, -0.0033, -0.0044],
        ...,
        [-0.0291,  0.0011, -0.0214,  ...,  0.0249,  0.0036, -0.0110],
        [ 0.0339, -0.0076,  0.0219,  ..., -0.0210, -0.0142, -0.0080],
        [ 0.0128,  0.0133, -0.0092,  ..., -0.0280,  0.0159,  0.0059]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.7148, -6.1992,  0.0652,  ..., -0.5625, -1.6787,  0.1172]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 02:30:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female duke is known as a duchess
A female batman is known as a batwoman
A female buck is known as a doe
A female stallion is known as a mare
A female manager is known as a manageress
A female sculptor is known as a sculptress
A female daddy is known as a mommy
A female god is known as a
2024-07-28 02:30:32 root INFO     [order_1_approx] starting weight calculation for A female god is known as a goddess
A female manager is known as a manageress
A female duke is known as a duchess
A female batman is known as a batwoman
A female sculptor is known as a sculptress
A female buck is known as a doe
A female daddy is known as a mommy
A female stallion is known as a
2024-07-28 02:30:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 02:33:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3623, -0.0427, -0.0634,  ...,  0.0545, -0.1428,  0.2159],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4023, -5.5234, -2.0527,  ..., -0.1030, -2.2656,  2.3086],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0247,  0.0058, -0.0318,  ...,  0.0436, -0.0084, -0.0029],
        [-0.0151,  0.0638,  0.0230,  ...,  0.0183,  0.0551, -0.0002],
        [ 0.0201,  0.0392,  0.0746,  ..., -0.0102, -0.0475, -0.0340],
        ...,
        [-0.0290, -0.0097, -0.0359,  ...,  0.0031,  0.0289,  0.0028],
        [-0.0177, -0.0040,  0.0045,  ..., -0.0219, -0.0184,  0.0181],
        [ 0.0412, -0.0251,  0.0225,  ..., -0.0012,  0.0003,  0.0294]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2832, -5.2930, -2.4707,  ...,  0.0061, -2.1816,  2.3398]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 02:33:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female god is known as a goddess
A female manager is known as a manageress
A female duke is known as a duchess
A female batman is known as a batwoman
A female sculptor is known as a sculptress
A female buck is known as a doe
A female daddy is known as a mommy
A female stallion is known as a
2024-07-28 02:33:14 root INFO     total operator prediction time: 1298.0914092063904 seconds
2024-07-28 02:33:14 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on name - occupation
2024-07-28 02:33:14 root INFO     building operator name - occupation
2024-07-28 02:33:14 root INFO     [order_1_approx] starting weight calculation for newton was known for their work as a  scientist
spinoza was known for their work as a  philosopher
wittgenstein was known for their work as a  philosopher
goethe was known for their work as a  poet
moses was known for their work as a  prophet
balzac was known for their work as a  novelist
mozart was known for their work as a  composer
michelangelo was known for their work as a 
2024-07-28 02:33:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 02:35:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3435,  0.1162, -0.3086,  ..., -0.1758, -0.0880,  0.2280],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1445, -8.4062,  2.2793,  ..., -6.1992, -0.0179, -0.0137],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0259,  0.0167,  0.0017,  ..., -0.0082, -0.0096,  0.0123],
        [ 0.0264, -0.0034,  0.0068,  ..., -0.0210, -0.0102,  0.0085],
        [ 0.0160,  0.0035,  0.0143,  ..., -0.0012, -0.0095,  0.0145],
        ...,
        [ 0.0168,  0.0044,  0.0003,  ...,  0.0185, -0.0025, -0.0034],
        [ 0.0116,  0.0006,  0.0089,  ..., -0.0089, -0.0085,  0.0043],
        [-0.0020, -0.0153,  0.0043,  ...,  0.0051, -0.0014,  0.0205]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8477e+00, -7.3906e+00,  2.3418e+00,  ..., -5.6211e+00,
         -2.1973e-03,  1.0492e-01]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SubBackward0>) 

                    
2024-07-28 02:35:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for newton was known for their work as a  scientist
spinoza was known for their work as a  philosopher
wittgenstein was known for their work as a  philosopher
goethe was known for their work as a  poet
moses was known for their work as a  prophet
balzac was known for their work as a  novelist
mozart was known for their work as a  composer
michelangelo was known for their work as a 
2024-07-28 02:35:59 root INFO     [order_1_approx] starting weight calculation for goethe was known for their work as a  poet
mozart was known for their work as a  composer
moses was known for their work as a  prophet
wittgenstein was known for their work as a  philosopher
balzac was known for their work as a  novelist
michelangelo was known for their work as a  sculptor
newton was known for their work as a  scientist
spinoza was known for their work as a 
2024-07-28 02:35:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 02:38:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1093, -0.0668, -0.2908,  ..., -0.1038, -0.0619,  0.1884],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7480, -2.6992,  3.8594,  ..., -6.3477,  0.7324, -3.0234],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0474, -0.0041,  0.0099,  ..., -0.0085, -0.0165,  0.0204],
        [-0.0059,  0.0161,  0.0098,  ..., -0.0194, -0.0139, -0.0029],
        [-0.0037,  0.0065,  0.0415,  ..., -0.0032,  0.0082, -0.0165],
        ...,
        [ 0.0108,  0.0089,  0.0072,  ...,  0.0311, -0.0078,  0.0205],
        [-0.0020,  0.0047,  0.0054,  ...,  0.0136,  0.0205, -0.0297],
        [-0.0026,  0.0112,  0.0032,  ...,  0.0065, -0.0212,  0.0250]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8535, -2.7480,  3.6367,  ..., -5.7773,  0.2930, -2.6250]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 02:38:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for goethe was known for their work as a  poet
mozart was known for their work as a  composer
moses was known for their work as a  prophet
wittgenstein was known for their work as a  philosopher
balzac was known for their work as a  novelist
michelangelo was known for their work as a  sculptor
newton was known for their work as a  scientist
spinoza was known for their work as a 
2024-07-28 02:38:42 root INFO     [order_1_approx] starting weight calculation for goethe was known for their work as a  poet
newton was known for their work as a  scientist
moses was known for their work as a  prophet
mozart was known for their work as a  composer
spinoza was known for their work as a  philosopher
wittgenstein was known for their work as a  philosopher
michelangelo was known for their work as a  sculptor
balzac was known for their work as a 
2024-07-28 02:38:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 02:41:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1009,  0.1162, -0.5259,  ..., -0.1670, -0.1537, -0.0218],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1289, -4.1953,  3.4961,  ..., -3.7422, -1.5205,  0.7773],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0921, -0.0109,  0.0350,  ...,  0.0013, -0.0201,  0.0162],
        [ 0.0352,  0.0133,  0.0037,  ..., -0.0166, -0.0303,  0.0166],
        [-0.0314,  0.0323,  0.0327,  ..., -0.0046,  0.0444, -0.0207],
        ...,
        [ 0.0176,  0.0058, -0.0159,  ...,  0.0891,  0.0036,  0.0033],
        [ 0.0194, -0.0107,  0.0244,  ...,  0.0127,  0.0350,  0.0291],
        [ 0.0027,  0.0273,  0.0111,  ..., -0.0245, -0.0138,  0.0276]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6445, -3.5684,  2.4121,  ..., -4.1797, -1.0957,  0.6841]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 02:41:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for goethe was known for their work as a  poet
newton was known for their work as a  scientist
moses was known for their work as a  prophet
mozart was known for their work as a  composer
spinoza was known for their work as a  philosopher
wittgenstein was known for their work as a  philosopher
michelangelo was known for their work as a  sculptor
balzac was known for their work as a 
2024-07-28 02:41:27 root INFO     [order_1_approx] starting weight calculation for goethe was known for their work as a  poet
newton was known for their work as a  scientist
wittgenstein was known for their work as a  philosopher
balzac was known for their work as a  novelist
spinoza was known for their work as a  philosopher
michelangelo was known for their work as a  sculptor
moses was known for their work as a  prophet
mozart was known for their work as a 
2024-07-28 02:41:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 02:44:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1073,  0.4229, -0.3235,  ..., -0.2074, -0.0131, -0.2429],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6875, -5.4531,  1.8564,  ..., -1.8975,  0.4834,  0.2783],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0307, -0.0132,  0.0045,  ..., -0.0155,  0.0032,  0.0212],
        [ 0.0024,  0.0229, -0.0010,  ..., -0.0056,  0.0119, -0.0048],
        [ 0.0231, -0.0062,  0.0513,  ...,  0.0056, -0.0027,  0.0249],
        ...,
        [-0.0018,  0.0029, -0.0063,  ...,  0.0428,  0.0074,  0.0036],
        [ 0.0096,  0.0105,  0.0053,  ..., -0.0102,  0.0232, -0.0070],
        [-0.0071, -0.0027, -0.0099,  ..., -0.0142, -0.0088, -0.0010]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7480, -5.3398,  2.2500,  ..., -2.2949,  0.3130,  0.2487]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 02:44:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for goethe was known for their work as a  poet
newton was known for their work as a  scientist
wittgenstein was known for their work as a  philosopher
balzac was known for their work as a  novelist
spinoza was known for their work as a  philosopher
michelangelo was known for their work as a  sculptor
moses was known for their work as a  prophet
mozart was known for their work as a 
2024-07-28 02:44:12 root INFO     [order_1_approx] starting weight calculation for spinoza was known for their work as a  philosopher
goethe was known for their work as a  poet
balzac was known for their work as a  novelist
wittgenstein was known for their work as a  philosopher
mozart was known for their work as a  composer
michelangelo was known for their work as a  sculptor
moses was known for their work as a  prophet
newton was known for their work as a 
2024-07-28 02:44:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 02:46:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1196,  0.1309, -0.1340,  ..., -0.2952,  0.0873,  0.2107],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4883, -4.6328,  1.5273,  ..., -7.5938,  0.7324, -1.4248],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0587, -0.0074,  0.0501,  ..., -0.0243,  0.0077,  0.0115],
        [-0.0034,  0.0442, -0.0114,  ...,  0.0103,  0.0033, -0.0121],
        [ 0.0210, -0.0187,  0.0593,  ..., -0.0145, -0.0229,  0.0125],
        ...,
        [ 0.0116,  0.0117,  0.0199,  ...,  0.0335,  0.0060,  0.0048],
        [-0.0253,  0.0016, -0.0254,  ...,  0.0290,  0.0182, -0.0108],
        [ 0.0145, -0.0132,  0.0286,  ..., -0.0034, -0.0070,  0.0538]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8281, -4.6523,  1.2471,  ..., -7.3008,  0.6123, -0.6777]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 02:46:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for spinoza was known for their work as a  philosopher
goethe was known for their work as a  poet
balzac was known for their work as a  novelist
wittgenstein was known for their work as a  philosopher
mozart was known for their work as a  composer
michelangelo was known for their work as a  sculptor
moses was known for their work as a  prophet
newton was known for their work as a 
2024-07-28 02:46:59 root INFO     [order_1_approx] starting weight calculation for spinoza was known for their work as a  philosopher
mozart was known for their work as a  composer
michelangelo was known for their work as a  sculptor
moses was known for their work as a  prophet
balzac was known for their work as a  novelist
newton was known for their work as a  scientist
wittgenstein was known for their work as a  philosopher
goethe was known for their work as a 
2024-07-28 02:46:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 02:49:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0109,  0.3679, -0.0780,  ..., -0.2484,  0.2742, -0.3562],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6455, -6.6602,  4.6133,  ..., -0.6392, -1.4717,  0.2354],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 9.1248e-02,  1.7517e-02,  2.2003e-02,  ...,  5.7144e-03,
         -3.7445e-02, -2.7657e-03],
        [ 4.4617e-02,  3.0670e-02, -4.1275e-03,  ...,  1.9897e-02,
         -9.4604e-04, -3.0880e-03],
        [-2.8896e-04,  6.0921e-03,  6.9397e-02,  ..., -8.7738e-05,
          1.0727e-02,  1.8021e-02],
        ...,
        [-4.8340e-02,  3.6224e-02,  1.8051e-02,  ...,  8.1238e-02,
          2.5848e-02,  3.3325e-02],
        [ 3.7292e-02,  7.1259e-03, -9.3079e-04,  ...,  1.3485e-03,
          2.1912e-02, -2.6245e-02],
        [-2.0813e-02,  1.4610e-02,  6.7863e-03,  ...,  5.5084e-03,
         -6.5041e-03,  6.8726e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8096, -5.8633,  3.8906,  ..., -1.3535, -0.8311,  0.7085]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 02:49:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for spinoza was known for their work as a  philosopher
mozart was known for their work as a  composer
michelangelo was known for their work as a  sculptor
moses was known for their work as a  prophet
balzac was known for their work as a  novelist
newton was known for their work as a  scientist
wittgenstein was known for their work as a  philosopher
goethe was known for their work as a 
2024-07-28 02:49:45 root INFO     [order_1_approx] starting weight calculation for newton was known for their work as a  scientist
mozart was known for their work as a  composer
wittgenstein was known for their work as a  philosopher
balzac was known for their work as a  novelist
goethe was known for their work as a  poet
michelangelo was known for their work as a  sculptor
spinoza was known for their work as a  philosopher
moses was known for their work as a 
2024-07-28 02:49:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 02:52:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1134,  0.1646, -0.1431,  ..., -0.1904, -0.2935,  0.2852],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2300, -5.0977,  1.0889,  ..., -5.9648,  3.3555,  0.0449],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0430,  0.0138,  0.0146,  ..., -0.0121, -0.0245,  0.0192],
        [-0.0155, -0.0021,  0.0098,  ..., -0.0391, -0.0118, -0.0158],
        [ 0.0172, -0.0167,  0.0253,  ...,  0.0036, -0.0006,  0.0161],
        ...,
        [ 0.0208,  0.0161,  0.0400,  ...,  0.0135, -0.0052, -0.0064],
        [ 0.0472,  0.0041, -0.0087,  ...,  0.0099,  0.0388,  0.0101],
        [-0.0219, -0.0043,  0.0053,  ..., -0.0134, -0.0095, -0.0014]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.9175, -4.5000,  0.9541,  ..., -5.9883,  2.9512,  0.3528]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 02:52:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for newton was known for their work as a  scientist
mozart was known for their work as a  composer
wittgenstein was known for their work as a  philosopher
balzac was known for their work as a  novelist
goethe was known for their work as a  poet
michelangelo was known for their work as a  sculptor
spinoza was known for their work as a  philosopher
moses was known for their work as a 
2024-07-28 02:52:26 root INFO     [order_1_approx] starting weight calculation for spinoza was known for their work as a  philosopher
newton was known for their work as a  scientist
balzac was known for their work as a  novelist
mozart was known for their work as a  composer
moses was known for their work as a  prophet
goethe was known for their work as a  poet
michelangelo was known for their work as a  sculptor
wittgenstein was known for their work as a 
2024-07-28 02:52:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 02:55:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1873, -0.3481, -0.3818,  ...,  0.2825,  0.0565,  0.1816],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7295, -4.2617,  2.2539,  ..., -5.2305, -1.0000, -1.8574],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0446, -0.0201,  0.0096,  ..., -0.0170,  0.0016,  0.0152],
        [ 0.0128, -0.0030, -0.0010,  ..., -0.0143,  0.0171,  0.0080],
        [ 0.0160, -0.0010,  0.0203,  ..., -0.0178, -0.0129,  0.0037],
        ...,
        [ 0.0063,  0.0005,  0.0037,  ...,  0.0269,  0.0144,  0.0063],
        [-0.0128,  0.0103,  0.0079,  ...,  0.0171, -0.0078, -0.0027],
        [ 0.0334, -0.0227,  0.0036,  ..., -0.0233, -0.0027,  0.0191]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1973, -4.0273,  2.5488,  ..., -5.2930, -1.0703, -1.3672]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 02:55:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for spinoza was known for their work as a  philosopher
newton was known for their work as a  scientist
balzac was known for their work as a  novelist
mozart was known for their work as a  composer
moses was known for their work as a  prophet
goethe was known for their work as a  poet
michelangelo was known for their work as a  sculptor
wittgenstein was known for their work as a 
2024-07-28 02:55:07 root INFO     total operator prediction time: 1312.8245205879211 seconds
2024-07-28 02:55:07 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on country - capital
2024-07-28 02:55:07 root INFO     building operator country - capital
2024-07-28 02:55:07 root INFO     [order_1_approx] starting weight calculation for The country with bern as its capital is known as switzerland
The country with tbilisi as its capital is known as georgia
The country with hanoi as its capital is known as vietnam
The country with bangkok as its capital is known as thailand
The country with athens as its capital is known as greece
The country with dublin as its capital is known as ireland
The country with islamabad as its capital is known as pakistan
The country with rome as its capital is known as
2024-07-28 02:55:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 02:57:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0845, -0.0555, -0.3984,  ...,  0.1111,  0.0585,  0.0500],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2490, -4.7148, -1.4277,  ..., -1.9717,  2.0430, -3.7852],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0440, -0.0029, -0.0164,  ...,  0.0185, -0.0013,  0.0151],
        [-0.0043,  0.0313,  0.0135,  ..., -0.0134, -0.0298, -0.0209],
        [-0.0059, -0.0025,  0.0516,  ...,  0.0119,  0.0190, -0.0095],
        ...,
        [-0.0153,  0.0049, -0.0073,  ...,  0.0116,  0.0010, -0.0352],
        [ 0.0172, -0.0164,  0.0064,  ...,  0.0188,  0.0006,  0.0077],
        [ 0.0005, -0.0067, -0.0063,  ...,  0.0020, -0.0162, -0.0072]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0225, -4.2969, -1.7324,  ..., -1.6895,  1.9580, -3.8125]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 02:57:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with bern as its capital is known as switzerland
The country with tbilisi as its capital is known as georgia
The country with hanoi as its capital is known as vietnam
The country with bangkok as its capital is known as thailand
The country with athens as its capital is known as greece
The country with dublin as its capital is known as ireland
The country with islamabad as its capital is known as pakistan
The country with rome as its capital is known as
2024-07-28 02:57:54 root INFO     [order_1_approx] starting weight calculation for The country with rome as its capital is known as italy
The country with bangkok as its capital is known as thailand
The country with islamabad as its capital is known as pakistan
The country with bern as its capital is known as switzerland
The country with dublin as its capital is known as ireland
The country with hanoi as its capital is known as vietnam
The country with athens as its capital is known as greece
The country with tbilisi as its capital is known as
2024-07-28 02:57:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 03:00:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0243, -0.1096, -0.4080,  ...,  0.2490, -0.1812, -0.1022],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4805, -5.5273, -1.2715,  ..., -3.2188,  0.4648, -2.9297],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0134,  0.0005, -0.0062,  ...,  0.0216, -0.0155, -0.0038],
        [-0.0053,  0.0140, -0.0073,  ...,  0.0097, -0.0058, -0.0270],
        [-0.0215,  0.0065,  0.0029,  ...,  0.0077, -0.0113, -0.0074],
        ...,
        [ 0.0068,  0.0067, -0.0227,  ...,  0.0168, -0.0080, -0.0130],
        [ 0.0102,  0.0202, -0.0089,  ...,  0.0208,  0.0225,  0.0026],
        [-0.0076, -0.0069, -0.0076,  ...,  0.0085,  0.0127, -0.0007]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1699, -5.5938, -1.4473,  ..., -3.1641,  0.7090, -2.7305]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 03:00:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with rome as its capital is known as italy
The country with bangkok as its capital is known as thailand
The country with islamabad as its capital is known as pakistan
The country with bern as its capital is known as switzerland
The country with dublin as its capital is known as ireland
The country with hanoi as its capital is known as vietnam
The country with athens as its capital is known as greece
The country with tbilisi as its capital is known as
2024-07-28 03:00:40 root INFO     [order_1_approx] starting weight calculation for The country with islamabad as its capital is known as pakistan
The country with dublin as its capital is known as ireland
The country with hanoi as its capital is known as vietnam
The country with tbilisi as its capital is known as georgia
The country with rome as its capital is known as italy
The country with bern as its capital is known as switzerland
The country with athens as its capital is known as greece
The country with bangkok as its capital is known as
2024-07-28 03:00:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 03:03:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0580,  0.0917, -0.3933,  ...,  0.1913, -0.2341, -0.0360],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6772, -4.8516,  1.3057,  ..., -0.4597, -2.2246, -3.6270],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0277, -0.0152,  0.0001,  ...,  0.0030, -0.0095, -0.0053],
        [ 0.0026,  0.0039,  0.0114,  ..., -0.0131, -0.0013, -0.0267],
        [-0.0096,  0.0030,  0.0241,  ...,  0.0056,  0.0161, -0.0114],
        ...,
        [ 0.0074,  0.0092,  0.0160,  ...,  0.0098, -0.0050, -0.0214],
        [ 0.0065, -0.0065, -0.0048,  ..., -0.0014,  0.0017,  0.0057],
        [-0.0026, -0.0226,  0.0063,  ..., -0.0105,  0.0160,  0.0037]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7192, -4.3164,  1.6289,  ..., -0.1492, -2.1602, -3.3945]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 03:03:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with islamabad as its capital is known as pakistan
The country with dublin as its capital is known as ireland
The country with hanoi as its capital is known as vietnam
The country with tbilisi as its capital is known as georgia
The country with rome as its capital is known as italy
The country with bern as its capital is known as switzerland
The country with athens as its capital is known as greece
The country with bangkok as its capital is known as
2024-07-28 03:03:24 root INFO     [order_1_approx] starting weight calculation for The country with hanoi as its capital is known as vietnam
The country with tbilisi as its capital is known as georgia
The country with islamabad as its capital is known as pakistan
The country with rome as its capital is known as italy
The country with bern as its capital is known as switzerland
The country with dublin as its capital is known as ireland
The country with bangkok as its capital is known as thailand
The country with athens as its capital is known as
2024-07-28 03:03:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 03:06:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0230,  0.0826, -0.5767,  ...,  0.0994, -0.0785, -0.2113],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6250, -5.2500, -3.0117,  ...,  0.0273,  1.1982, -2.9980],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0637, -0.0210,  0.0196,  ..., -0.0083,  0.0079, -0.0168],
        [ 0.0027,  0.0244, -0.0089,  ..., -0.0020, -0.0372, -0.0120],
        [-0.0177, -0.0104,  0.0562,  ..., -0.0108,  0.0116, -0.0174],
        ...,
        [-0.0142,  0.0132, -0.0389,  ...,  0.0349,  0.0013, -0.0176],
        [-0.0033, -0.0104, -0.0046,  ..., -0.0050,  0.0195, -0.0009],
        [ 0.0096, -0.0185,  0.0182,  ..., -0.0161,  0.0013, -0.0058]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7109, -5.0469, -2.8750,  ...,  0.0401,  1.1914, -2.4219]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 03:06:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with hanoi as its capital is known as vietnam
The country with tbilisi as its capital is known as georgia
The country with islamabad as its capital is known as pakistan
The country with rome as its capital is known as italy
The country with bern as its capital is known as switzerland
The country with dublin as its capital is known as ireland
The country with bangkok as its capital is known as thailand
The country with athens as its capital is known as
2024-07-28 03:06:13 root INFO     [order_1_approx] starting weight calculation for The country with athens as its capital is known as greece
The country with bangkok as its capital is known as thailand
The country with tbilisi as its capital is known as georgia
The country with rome as its capital is known as italy
The country with hanoi as its capital is known as vietnam
The country with islamabad as its capital is known as pakistan
The country with bern as its capital is known as switzerland
The country with dublin as its capital is known as
2024-07-28 03:06:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 03:08:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1914,  0.0630, -0.5513,  ...,  0.3174, -0.1266, -0.1104],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3652, -5.5703, -1.0918,  ...,  1.7305, -1.4795, -6.9141],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0442, -0.0238,  0.0004,  ...,  0.0215, -0.0074,  0.0138],
        [-0.0204,  0.0426, -0.0248,  ..., -0.0385, -0.0246, -0.0178],
        [-0.0100,  0.0085,  0.0248,  ...,  0.0302,  0.0240, -0.0179],
        ...,
        [ 0.0285,  0.0416,  0.0226,  ...,  0.0469, -0.0141, -0.0344],
        [-0.0176, -0.0013, -0.0317,  ..., -0.0254,  0.0229, -0.0106],
        [-0.0070, -0.0331,  0.0024,  ..., -0.0196,  0.0013,  0.0159]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2109, -5.5781, -1.0840,  ...,  1.8643, -1.9443, -7.0195]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 03:08:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with athens as its capital is known as greece
The country with bangkok as its capital is known as thailand
The country with tbilisi as its capital is known as georgia
The country with rome as its capital is known as italy
The country with hanoi as its capital is known as vietnam
The country with islamabad as its capital is known as pakistan
The country with bern as its capital is known as switzerland
The country with dublin as its capital is known as
2024-07-28 03:08:55 root INFO     [order_1_approx] starting weight calculation for The country with dublin as its capital is known as ireland
The country with tbilisi as its capital is known as georgia
The country with rome as its capital is known as italy
The country with bangkok as its capital is known as thailand
The country with bern as its capital is known as switzerland
The country with athens as its capital is known as greece
The country with hanoi as its capital is known as vietnam
The country with islamabad as its capital is known as
2024-07-28 03:08:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 03:11:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2795, -0.0272, -0.4277,  ...,  0.4028, -0.5732,  0.2571],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6641, -6.8945, -0.3118,  ..., -1.1973, -1.0459, -1.9219],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.0828e-02,  1.1040e-02,  4.9973e-03,  ...,  1.1539e-03,
         -2.9221e-03, -5.5923e-03],
        [ 1.1246e-02,  7.1487e-03, -5.9166e-03,  ..., -1.7624e-02,
         -2.2522e-02, -2.1935e-04],
        [-1.6525e-02,  6.0669e-02,  4.2603e-02,  ..., -3.3379e-06,
          4.9057e-03, -2.1210e-02],
        ...,
        [ 1.8494e-02,  2.1648e-03, -2.1225e-02,  ...,  3.9825e-02,
         -3.8548e-03,  1.1292e-03],
        [ 2.6657e-02, -1.9318e-02,  3.1891e-03,  ..., -7.1373e-03,
          1.3718e-02,  1.5671e-02],
        [ 1.3367e-02,  9.1858e-03,  2.5131e-02,  ...,  8.9722e-03,
         -9.1553e-03,  1.4801e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9883, -6.7539, -0.6621,  ..., -0.8447, -1.1787, -1.9180]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 03:11:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with dublin as its capital is known as ireland
The country with tbilisi as its capital is known as georgia
The country with rome as its capital is known as italy
The country with bangkok as its capital is known as thailand
The country with bern as its capital is known as switzerland
The country with athens as its capital is known as greece
The country with hanoi as its capital is known as vietnam
The country with islamabad as its capital is known as
2024-07-28 03:11:42 root INFO     [order_1_approx] starting weight calculation for The country with athens as its capital is known as greece
The country with tbilisi as its capital is known as georgia
The country with hanoi as its capital is known as vietnam
The country with islamabad as its capital is known as pakistan
The country with dublin as its capital is known as ireland
The country with rome as its capital is known as italy
The country with bangkok as its capital is known as thailand
The country with bern as its capital is known as
2024-07-28 03:11:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 03:14:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0721,  0.3486, -0.0611,  ...,  0.0427, -0.0478, -0.0803],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7598, -6.1328, -1.7461,  ...,  0.1367, -1.4932, -1.6719],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0273, -0.0256,  0.0202,  ...,  0.0338, -0.0237, -0.0464],
        [ 0.0264,  0.0090,  0.0240,  ..., -0.0422, -0.0232, -0.0561],
        [-0.0063,  0.0406,  0.0427,  ...,  0.0082,  0.0098, -0.0184],
        ...,
        [ 0.0177,  0.0168, -0.0012,  ...,  0.0368, -0.0199, -0.0463],
        [ 0.0178,  0.0049,  0.0072,  ...,  0.0347,  0.0312,  0.0278],
        [ 0.0007, -0.0065, -0.0100,  ..., -0.0134, -0.0060,  0.0110]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2559, -5.5273, -1.4629,  ...,  0.4976, -2.0918, -1.7754]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 03:14:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with athens as its capital is known as greece
The country with tbilisi as its capital is known as georgia
The country with hanoi as its capital is known as vietnam
The country with islamabad as its capital is known as pakistan
The country with dublin as its capital is known as ireland
The country with rome as its capital is known as italy
The country with bangkok as its capital is known as thailand
The country with bern as its capital is known as
2024-07-28 03:14:27 root INFO     [order_1_approx] starting weight calculation for The country with dublin as its capital is known as ireland
The country with islamabad as its capital is known as pakistan
The country with athens as its capital is known as greece
The country with bern as its capital is known as switzerland
The country with rome as its capital is known as italy
The country with bangkok as its capital is known as thailand
The country with tbilisi as its capital is known as georgia
The country with hanoi as its capital is known as
2024-07-28 03:14:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 03:17:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0817, -0.1924, -0.2859,  ..., -0.0460, -0.2161,  0.0956],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.1650, -5.6953, -0.1567,  ..., -2.0742, -2.4531, -3.4570],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0244,  0.0076, -0.0105,  ...,  0.0218, -0.0220, -0.0031],
        [-0.0070,  0.0176, -0.0017,  ..., -0.0139, -0.0151, -0.0300],
        [ 0.0005,  0.0064,  0.0322,  ..., -0.0025,  0.0098, -0.0181],
        ...,
        [-0.0005,  0.0016, -0.0150,  ...,  0.0086,  0.0079, -0.0130],
        [ 0.0185,  0.0030, -0.0168,  ..., -0.0053,  0.0020,  0.0037],
        [-0.0079, -0.0180,  0.0032,  ..., -0.0041,  0.0041, -0.0132]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.2920, -5.3398, -0.1036,  ..., -1.9873, -2.3906, -3.4609]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 03:17:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with dublin as its capital is known as ireland
The country with islamabad as its capital is known as pakistan
The country with athens as its capital is known as greece
The country with bern as its capital is known as switzerland
The country with rome as its capital is known as italy
The country with bangkok as its capital is known as thailand
The country with tbilisi as its capital is known as georgia
The country with hanoi as its capital is known as
2024-07-28 03:17:10 root INFO     total operator prediction time: 1323.38743019104 seconds
2024-07-28 03:17:10 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on things - color
2024-07-28 03:17:10 root INFO     building operator things - color
2024-07-28 03:17:10 root INFO     [order_1_approx] starting weight calculation for The grapes is colored black
The cauliflower is colored white
The raven is colored black
The tomato is colored red
The grass is colored green
The cloud is colored white
The blood is colored red
The spinach is colored
2024-07-28 03:17:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 03:19:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1331, -0.2366, -0.3347,  ..., -0.0500, -0.3281,  0.0657],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7012, -4.2578, -1.4902,  ..., -1.1523, -1.1641, -2.8418],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0813,  0.0411, -0.0177,  ..., -0.0256,  0.0194,  0.0123],
        [ 0.0105, -0.0129,  0.0309,  ..., -0.0045,  0.0390, -0.0058],
        [-0.0302, -0.0517,  0.0406,  ...,  0.0262, -0.0201,  0.0172],
        ...,
        [-0.0097, -0.0245, -0.0306,  ...,  0.0739, -0.0063, -0.0025],
        [-0.0311, -0.0023, -0.0083,  ...,  0.0074,  0.0228,  0.0124],
        [-0.0190, -0.0306,  0.0004,  ..., -0.0014, -0.0095,  0.0361]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5801, -4.2617, -1.5820,  ..., -1.0137, -1.2510, -2.9629]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 03:19:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The grapes is colored black
The cauliflower is colored white
The raven is colored black
The tomato is colored red
The grass is colored green
The cloud is colored white
The blood is colored red
The spinach is colored
2024-07-28 03:19:57 root INFO     [order_1_approx] starting weight calculation for The grass is colored green
The tomato is colored red
The raven is colored black
The cloud is colored white
The cauliflower is colored white
The blood is colored red
The spinach is colored green
The grapes is colored
2024-07-28 03:19:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 03:22:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1512, -0.4521, -0.2437,  ..., -0.1278, -0.2090, -0.1371],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9731, -8.0234, -2.0645,  ..., -1.6113, -0.0947, -2.4746],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0558,  0.0116,  0.0113,  ..., -0.0106,  0.0102, -0.0157],
        [-0.0322,  0.0009,  0.0170,  ..., -0.0038, -0.0035, -0.0184],
        [ 0.0125,  0.0045,  0.0193,  ...,  0.0292,  0.0048,  0.0091],
        ...,
        [-0.0153, -0.0030,  0.0064,  ...,  0.0546, -0.0131,  0.0014],
        [ 0.0106,  0.0008, -0.0008,  ..., -0.0004,  0.0236,  0.0076],
        [-0.0126, -0.0115,  0.0025,  ...,  0.0019, -0.0064,  0.0435]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3027, -8.2500, -1.6123,  ..., -1.7393, -0.1140, -2.4375]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 03:22:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The grass is colored green
The tomato is colored red
The raven is colored black
The cloud is colored white
The cauliflower is colored white
The blood is colored red
The spinach is colored green
The grapes is colored
2024-07-28 03:22:42 root INFO     [order_1_approx] starting weight calculation for The cloud is colored white
The raven is colored black
The grapes is colored black
The blood is colored red
The grass is colored green
The tomato is colored red
The spinach is colored green
The cauliflower is colored
2024-07-28 03:22:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 03:25:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1528, -0.0446, -0.1583,  ...,  0.0146, -0.3413,  0.1688],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2354, -5.7656, -0.8315,  ..., -1.1699,  0.6934, -0.2988],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0323,  0.0049,  0.0041,  ..., -0.0210, -0.0057,  0.0181],
        [ 0.0065,  0.0053, -0.0047,  ..., -0.0287, -0.0029,  0.0089],
        [-0.0233,  0.0014,  0.0172,  ...,  0.0150, -0.0036,  0.0006],
        ...,
        [ 0.0055, -0.0136, -0.0057,  ...,  0.0237, -0.0213,  0.0145],
        [-0.0048, -0.0085, -0.0040,  ...,  0.0027,  0.0176,  0.0100],
        [-0.0049, -0.0029,  0.0116,  ...,  0.0049,  0.0041,  0.0288]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1628, -5.6992, -0.6694,  ..., -1.2920,  0.6743, -0.1812]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 03:25:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The cloud is colored white
The raven is colored black
The grapes is colored black
The blood is colored red
The grass is colored green
The tomato is colored red
The spinach is colored green
The cauliflower is colored
2024-07-28 03:25:28 root INFO     [order_1_approx] starting weight calculation for The cauliflower is colored white
The cloud is colored white
The grapes is colored black
The spinach is colored green
The tomato is colored red
The grass is colored green
The raven is colored black
The blood is colored
2024-07-28 03:25:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 03:28:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0020, -0.1153, -0.3677,  ..., -0.0847, -0.5259, -0.1095],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.6035, -9.2969, -2.2676,  ..., -1.9639,  1.8047, -2.3789],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0543,  0.0042,  0.0257,  ...,  0.0221, -0.0087,  0.0029],
        [ 0.0087,  0.0221, -0.0086,  ..., -0.0108, -0.0031, -0.0072],
        [ 0.0096,  0.0061,  0.0095,  ...,  0.0288, -0.0107,  0.0323],
        ...,
        [-0.0080,  0.0157, -0.0107,  ..., -0.0030, -0.0070, -0.0224],
        [-0.0001,  0.0164,  0.0028,  ..., -0.0104,  0.0155,  0.0056],
        [-0.0027, -0.0136,  0.0084,  ..., -0.0005,  0.0079,  0.0242]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.0625, -9.0547, -2.0566,  ..., -2.6582,  1.9150, -2.9004]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 03:28:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The cauliflower is colored white
The cloud is colored white
The grapes is colored black
The spinach is colored green
The tomato is colored red
The grass is colored green
The raven is colored black
The blood is colored
2024-07-28 03:28:14 root INFO     [order_1_approx] starting weight calculation for The cauliflower is colored white
The grass is colored green
The tomato is colored red
The blood is colored red
The grapes is colored black
The cloud is colored white
The spinach is colored green
The raven is colored
2024-07-28 03:28:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 03:30:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1118,  0.0797, -0.2637,  ..., -0.0753, -0.0648,  0.2189],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1465, -3.9180,  2.5039,  ...,  0.4282,  3.2012, -2.5547],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0605,  0.0266,  0.0289,  ..., -0.0165,  0.0092, -0.0172],
        [-0.0051,  0.0259,  0.0675,  ...,  0.0197, -0.0430, -0.0093],
        [-0.0140, -0.0087,  0.0798,  ...,  0.0181, -0.0255,  0.0014],
        ...,
        [ 0.0204,  0.0265,  0.0233,  ...,  0.0692, -0.0171, -0.0307],
        [-0.0073,  0.0125,  0.0008,  ...,  0.0416,  0.0372, -0.0077],
        [ 0.0232, -0.0186, -0.0385,  ..., -0.0319, -0.0392,  0.0530]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0059, -4.8984,  1.6504,  ..., -0.0874,  2.3516, -3.1348]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 03:31:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The cauliflower is colored white
The grass is colored green
The tomato is colored red
The blood is colored red
The grapes is colored black
The cloud is colored white
The spinach is colored green
The raven is colored
2024-07-28 03:31:00 root INFO     [order_1_approx] starting weight calculation for The spinach is colored green
The tomato is colored red
The grapes is colored black
The blood is colored red
The raven is colored black
The grass is colored green
The cauliflower is colored white
The cloud is colored
2024-07-28 03:31:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 03:33:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0903, -0.1147,  0.2029,  ..., -0.1482, -0.2798, -0.0684],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3545, -4.6289,  2.1113,  ..., -2.3047, -0.3516, -1.2461],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0423,  0.0156,  0.0293,  ...,  0.0120, -0.0033,  0.0151],
        [ 0.0050,  0.0187, -0.0075,  ...,  0.0183, -0.0148, -0.0293],
        [ 0.0218,  0.0133,  0.0061,  ...,  0.0002, -0.0304, -0.0057],
        ...,
        [-0.0106, -0.0057,  0.0026,  ...,  0.0476, -0.0003, -0.0223],
        [-0.0226, -0.0085,  0.0019,  ...,  0.0275,  0.0124, -0.0124],
        [ 0.0056, -0.0375,  0.0018,  ...,  0.0059, -0.0169,  0.0294]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3816, -4.4375,  1.7871,  ..., -2.2070, -0.6245, -0.9775]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 03:33:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The spinach is colored green
The tomato is colored red
The grapes is colored black
The blood is colored red
The raven is colored black
The grass is colored green
The cauliflower is colored white
The cloud is colored
2024-07-28 03:33:46 root INFO     [order_1_approx] starting weight calculation for The cauliflower is colored white
The grass is colored green
The spinach is colored green
The raven is colored black
The blood is colored red
The cloud is colored white
The grapes is colored black
The tomato is colored
2024-07-28 03:33:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 03:36:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1497, -0.0892, -0.0729,  ...,  0.1274, -0.3650, -0.0684],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.5742, -8.6875,  0.2725,  ..., -2.2305,  0.4883, -1.6826],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0341,  0.0135,  0.0298,  ..., -0.0323,  0.0001, -0.0148],
        [ 0.0202,  0.0357,  0.0278,  ..., -0.0069,  0.0075, -0.0246],
        [-0.0240,  0.0326,  0.0254,  ...,  0.0574,  0.0098,  0.0010],
        ...,
        [-0.0272, -0.0435, -0.0164,  ...,  0.0861, -0.0300, -0.0011],
        [-0.0141, -0.0095, -0.0368,  ...,  0.0480,  0.0108, -0.0104],
        [-0.0135, -0.0394, -0.0046,  ...,  0.0120, -0.0146,  0.0533]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8760, -8.5234,  0.1185,  ..., -2.4512, -0.0698, -2.4238]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 03:36:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The cauliflower is colored white
The grass is colored green
The spinach is colored green
The raven is colored black
The blood is colored red
The cloud is colored white
The grapes is colored black
The tomato is colored
2024-07-28 03:36:31 root INFO     [order_1_approx] starting weight calculation for The spinach is colored green
The raven is colored black
The grapes is colored black
The cauliflower is colored white
The tomato is colored red
The cloud is colored white
The blood is colored red
The grass is colored
2024-07-28 03:36:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 03:39:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1143,  0.1715, -0.2333,  ..., -0.1381, -0.1256, -0.1382],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7715, -6.6094, -1.8203,  ..., -0.8726,  1.1768, -3.5625],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0603,  0.0130,  0.0068,  ..., -0.0103,  0.0037,  0.0020],
        [ 0.0102,  0.0207, -0.0247,  ...,  0.0054, -0.0113, -0.0440],
        [ 0.0038,  0.0034,  0.0417,  ...,  0.0016,  0.0152,  0.0351],
        ...,
        [ 0.0030, -0.0193,  0.0012,  ...,  0.0297,  0.0035, -0.0120],
        [-0.0033,  0.0020,  0.0321,  ...,  0.0036,  0.0298, -0.0098],
        [-0.0119, -0.0107,  0.0074,  ..., -0.0095,  0.0355,  0.0272]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3496, -6.3359, -1.2051,  ..., -0.8594,  0.9165, -3.7266]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 03:39:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The spinach is colored green
The raven is colored black
The grapes is colored black
The cauliflower is colored white
The tomato is colored red
The cloud is colored white
The blood is colored red
The grass is colored
2024-07-28 03:39:17 root INFO     total operator prediction time: 1327.0185265541077 seconds
2024-07-28 03:39:17 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - sound
2024-07-28 03:39:17 root INFO     building operator animal - sound
2024-07-28 03:39:17 root INFO     [order_1_approx] starting weight calculation for The sound that a ferret makes is called a dook
The sound that a coyote makes is called a howl
The sound that a leopard makes is called a growl
The sound that a tiger makes is called a growl
The sound that a wasp makes is called a buzz
The sound that a moose makes is called a bellow
The sound that a hyena makes is called a laugh
The sound that a pig makes is called a
2024-07-28 03:39:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 03:42:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1227,  0.0267,  0.0350,  ..., -0.0503, -0.1033,  0.1250],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7031, -1.8926,  4.0859,  ..., -2.4434,  0.2109,  2.0391],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0316, -0.0066,  0.0012,  ..., -0.0115, -0.0079, -0.0184],
        [-0.0145,  0.0238, -0.0170,  ..., -0.0393, -0.0129, -0.0307],
        [ 0.0180, -0.0011,  0.0321,  ..., -0.0204, -0.0135,  0.0096],
        ...,
        [ 0.0042, -0.0081, -0.0173,  ...,  0.0128, -0.0112,  0.0068],
        [ 0.0013,  0.0132, -0.0158,  ...,  0.0358,  0.0156,  0.0027],
        [ 0.0019,  0.0081,  0.0098,  ..., -0.0374,  0.0155, -0.0029]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8008, -1.9502,  3.5938,  ..., -2.2910,  0.2756,  1.8770]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 03:42:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a ferret makes is called a dook
The sound that a coyote makes is called a howl
The sound that a leopard makes is called a growl
The sound that a tiger makes is called a growl
The sound that a wasp makes is called a buzz
The sound that a moose makes is called a bellow
The sound that a hyena makes is called a laugh
The sound that a pig makes is called a
2024-07-28 03:42:05 root INFO     [order_1_approx] starting weight calculation for The sound that a coyote makes is called a howl
The sound that a moose makes is called a bellow
The sound that a hyena makes is called a laugh
The sound that a wasp makes is called a buzz
The sound that a tiger makes is called a growl
The sound that a leopard makes is called a growl
The sound that a pig makes is called a oink
The sound that a ferret makes is called a
2024-07-28 03:42:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 03:44:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1469, -0.4697,  0.0110,  ..., -0.0761, -0.3401,  0.0457],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5508, -2.0000,  1.7920,  ..., -1.1396, -0.8687,  0.9082],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0157, -0.0009,  0.0045,  ...,  0.0161, -0.0797,  0.0133],
        [-0.0120,  0.0595, -0.0373,  ...,  0.0213, -0.0095, -0.0290],
        [ 0.0187, -0.0138,  0.0403,  ..., -0.0834, -0.0120, -0.0250],
        ...,
        [-0.0100,  0.0383, -0.0289,  ...,  0.0257, -0.0333, -0.0011],
        [ 0.0209,  0.0021,  0.0037,  ..., -0.0168,  0.0077,  0.0047],
        [ 0.0062, -0.0246, -0.0157,  ...,  0.0172, -0.0107,  0.0258]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7461, -2.0410,  1.7764,  ..., -1.4199, -0.9678,  0.8252]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 03:44:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a coyote makes is called a howl
The sound that a moose makes is called a bellow
The sound that a hyena makes is called a laugh
The sound that a wasp makes is called a buzz
The sound that a tiger makes is called a growl
The sound that a leopard makes is called a growl
The sound that a pig makes is called a oink
The sound that a ferret makes is called a
2024-07-28 03:44:52 root INFO     [order_1_approx] starting weight calculation for The sound that a wasp makes is called a buzz
The sound that a pig makes is called a oink
The sound that a tiger makes is called a growl
The sound that a coyote makes is called a howl
The sound that a leopard makes is called a growl
The sound that a ferret makes is called a dook
The sound that a moose makes is called a bellow
The sound that a hyena makes is called a
2024-07-28 03:44:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 03:47:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1770, -0.1382,  0.0282,  ...,  0.2159, -0.3481,  0.1311],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6729, -4.8359,  3.1406,  ..., -1.0850, -0.8984, -0.3291],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0687,  0.0060,  0.0192,  ...,  0.0086, -0.0257, -0.0213],
        [-0.0162,  0.0225, -0.0199,  ..., -0.0256, -0.0356,  0.0110],
        [ 0.0131,  0.0221,  0.0302,  ..., -0.1019, -0.0068, -0.0083],
        ...,
        [ 0.0260,  0.0166,  0.0217,  ...,  0.0361, -0.0172,  0.0207],
        [ 0.0085, -0.0298, -0.0057,  ..., -0.0093,  0.0272,  0.0059],
        [-0.0088,  0.0084, -0.0257,  ..., -0.0061, -0.0091,  0.0207]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9980, -4.4023,  3.4395,  ..., -1.1299, -0.7212, -0.6553]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 03:47:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a wasp makes is called a buzz
The sound that a pig makes is called a oink
The sound that a tiger makes is called a growl
The sound that a coyote makes is called a howl
The sound that a leopard makes is called a growl
The sound that a ferret makes is called a dook
The sound that a moose makes is called a bellow
The sound that a hyena makes is called a
2024-07-28 03:47:40 root INFO     [order_1_approx] starting weight calculation for The sound that a wasp makes is called a buzz
The sound that a ferret makes is called a dook
The sound that a moose makes is called a bellow
The sound that a hyena makes is called a laugh
The sound that a tiger makes is called a growl
The sound that a pig makes is called a oink
The sound that a coyote makes is called a howl
The sound that a leopard makes is called a
2024-07-28 03:47:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 03:50:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0712,  0.1520, -0.2507,  ..., -0.0394, -0.1902,  0.2196],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2383, -4.9375, -2.6172,  ..., -2.0078, -0.6240,  1.1709],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0279,  0.0033, -0.0045,  ..., -0.0153, -0.0150,  0.0176],
        [-0.0160,  0.0141,  0.0124,  ..., -0.0125,  0.0092, -0.0026],
        [-0.0021, -0.0192, -0.0206,  ..., -0.0283,  0.0167,  0.0222],
        ...,
        [ 0.0121,  0.0184,  0.0026,  ...,  0.0130,  0.0033, -0.0015],
        [ 0.0055, -0.0203, -0.0157,  ...,  0.0034,  0.0144,  0.0138],
        [-0.0044, -0.0080, -0.0258,  ..., -0.0281,  0.0070,  0.0093]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3008, -4.8828, -2.4629,  ..., -2.1387, -0.4570,  0.9980]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 03:50:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a wasp makes is called a buzz
The sound that a ferret makes is called a dook
The sound that a moose makes is called a bellow
The sound that a hyena makes is called a laugh
The sound that a tiger makes is called a growl
The sound that a pig makes is called a oink
The sound that a coyote makes is called a howl
The sound that a leopard makes is called a
2024-07-28 03:50:27 root INFO     [order_1_approx] starting weight calculation for The sound that a leopard makes is called a growl
The sound that a coyote makes is called a howl
The sound that a wasp makes is called a buzz
The sound that a hyena makes is called a laugh
The sound that a pig makes is called a oink
The sound that a ferret makes is called a dook
The sound that a moose makes is called a bellow
The sound that a tiger makes is called a
2024-07-28 03:50:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 03:53:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1299,  0.0761, -0.1138,  ..., -0.0525, -0.1501,  0.1500],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4570, -5.2305, -0.2712,  ..., -2.4043, -0.0488,  0.7832],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0326, -0.0075,  0.0235,  ..., -0.0106, -0.0242,  0.0102],
        [-0.0196,  0.0462, -0.0123,  ..., -0.0132, -0.0194, -0.0396],
        [ 0.0199,  0.0233,  0.0271,  ..., -0.0398,  0.0353,  0.0014],
        ...,
        [ 0.0272,  0.0329, -0.0095,  ...,  0.0279, -0.0158, -0.0245],
        [ 0.0141, -0.0318, -0.0154,  ...,  0.0080,  0.0164,  0.0341],
        [-0.0139,  0.0216, -0.0282,  ..., -0.0053, -0.0213, -0.0069]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5566, -4.9023, -0.4548,  ..., -2.2207,  0.0537,  0.5898]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 03:53:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a leopard makes is called a growl
The sound that a coyote makes is called a howl
The sound that a wasp makes is called a buzz
The sound that a hyena makes is called a laugh
The sound that a pig makes is called a oink
The sound that a ferret makes is called a dook
The sound that a moose makes is called a bellow
The sound that a tiger makes is called a
2024-07-28 03:53:14 root INFO     [order_1_approx] starting weight calculation for The sound that a ferret makes is called a dook
The sound that a hyena makes is called a laugh
The sound that a leopard makes is called a growl
The sound that a moose makes is called a bellow
The sound that a pig makes is called a oink
The sound that a tiger makes is called a growl
The sound that a coyote makes is called a howl
The sound that a wasp makes is called a
2024-07-28 03:53:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 03:55:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0684, -0.0217,  0.2783,  ...,  0.2023,  0.0106,  0.0643],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2461, -2.0762,  3.3066,  ..., -1.3926, -0.2227,  1.9805],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0473, -0.0144, -0.0054,  ..., -0.0110, -0.0349,  0.0074],
        [-0.0353,  0.0580, -0.0282,  ...,  0.0011, -0.0208, -0.0198],
        [ 0.0093,  0.0229,  0.0061,  ...,  0.0050, -0.0305,  0.0151],
        ...,
        [-0.0184,  0.0320,  0.0079,  ...,  0.0260, -0.0394, -0.0401],
        [-0.0238, -0.0048, -0.0032,  ...,  0.0195, -0.0054,  0.0204],
        [ 0.0005,  0.0032,  0.0005,  ..., -0.0068, -0.0127,  0.0190]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8467, -1.9844,  3.0195,  ..., -1.7197, -0.3037,  2.0957]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 03:55:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a ferret makes is called a dook
The sound that a hyena makes is called a laugh
The sound that a leopard makes is called a growl
The sound that a moose makes is called a bellow
The sound that a pig makes is called a oink
The sound that a tiger makes is called a growl
The sound that a coyote makes is called a howl
The sound that a wasp makes is called a
2024-07-28 03:55:54 root INFO     [order_1_approx] starting weight calculation for The sound that a tiger makes is called a growl
The sound that a pig makes is called a oink
The sound that a hyena makes is called a laugh
The sound that a wasp makes is called a buzz
The sound that a moose makes is called a bellow
The sound that a leopard makes is called a growl
The sound that a ferret makes is called a dook
The sound that a coyote makes is called a
2024-07-28 03:55:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 03:58:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0468,  0.1190, -0.2595,  ..., -0.2125, -0.1362,  0.1014],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5283, -6.9219,  0.3750,  ..., -2.9160, -0.5918,  1.9893],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0278,  0.0046,  0.0167,  ..., -0.0340, -0.0048,  0.0139],
        [-0.0106,  0.0087, -0.0150,  ..., -0.0065, -0.0213, -0.0169],
        [ 0.0157, -0.0070,  0.0193,  ..., -0.0426, -0.0090,  0.0183],
        ...,
        [ 0.0042,  0.0276,  0.0038,  ...,  0.0550, -0.0264, -0.0156],
        [ 0.0136, -0.0145, -0.0136,  ...,  0.0140, -0.0046,  0.0150],
        [-0.0057,  0.0008, -0.0248,  ..., -0.0052, -0.0196,  0.0050]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4688, -6.6172,  0.5532,  ..., -3.3047, -0.1404,  1.8408]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 03:58:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a tiger makes is called a growl
The sound that a pig makes is called a oink
The sound that a hyena makes is called a laugh
The sound that a wasp makes is called a buzz
The sound that a moose makes is called a bellow
The sound that a leopard makes is called a growl
The sound that a ferret makes is called a dook
The sound that a coyote makes is called a
2024-07-28 03:58:35 root INFO     [order_1_approx] starting weight calculation for The sound that a coyote makes is called a howl
The sound that a wasp makes is called a buzz
The sound that a leopard makes is called a growl
The sound that a tiger makes is called a growl
The sound that a ferret makes is called a dook
The sound that a hyena makes is called a laugh
The sound that a pig makes is called a oink
The sound that a moose makes is called a
2024-07-28 03:58:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 04:01:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0465,  0.2262,  0.0364,  ..., -0.2257, -0.3501,  0.1902],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4873, -4.4570,  1.7520,  ...,  0.8179, -2.0723,  1.2686],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0142, -0.0283,  0.0099,  ..., -0.0259, -0.0070,  0.0292],
        [-0.0210,  0.0878, -0.0095,  ...,  0.0297, -0.0717, -0.0367],
        [-0.0077,  0.0302,  0.0436,  ...,  0.0238, -0.0414,  0.0301],
        ...,
        [ 0.0168,  0.0457, -0.0242,  ...,  0.0496, -0.0093, -0.0159],
        [ 0.0040, -0.0126,  0.0025,  ...,  0.0259,  0.0178,  0.0243],
        [ 0.0132, -0.0284,  0.0032,  ..., -0.0213, -0.0454,  0.0188]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3645, -4.9336,  1.4141,  ...,  0.8423, -1.0615,  1.1904]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 04:01:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a coyote makes is called a howl
The sound that a wasp makes is called a buzz
The sound that a leopard makes is called a growl
The sound that a tiger makes is called a growl
The sound that a ferret makes is called a dook
The sound that a hyena makes is called a laugh
The sound that a pig makes is called a oink
The sound that a moose makes is called a
2024-07-28 04:01:19 root INFO     total operator prediction time: 1322.2887239456177 seconds
2024-07-28 04:01:19 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - youth
2024-07-28 04:01:19 root INFO     building operator animal - youth
2024-07-28 04:01:20 root INFO     [order_1_approx] starting weight calculation for The offspring of a buffalo is referred to as a calf
The offspring of a butterfly is referred to as a larva
The offspring of a fish is referred to as a fingerling
The offspring of a goat is referred to as a kid
The offspring of a horse is referred to as a foal
The offspring of a fox is referred to as a cub
The offspring of a camel is referred to as a calf
The offspring of a cricket is referred to as a
2024-07-28 04:01:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 04:04:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0870,  0.0540, -0.0095,  ...,  0.0931,  0.1702, -0.0468],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0701, -2.0938,  0.2725,  ...,  0.4062, -1.5322, -0.0791],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0305,  0.0013,  0.0329,  ...,  0.0160,  0.0103,  0.0005],
        [ 0.0079,  0.0156, -0.0140,  ...,  0.0019, -0.0081, -0.0182],
        [ 0.0281,  0.0271,  0.0533,  ..., -0.0081, -0.0092, -0.0175],
        ...,
        [ 0.0045, -0.0248, -0.0240,  ...,  0.0083,  0.0164,  0.0104],
        [ 0.0198,  0.0158, -0.0090,  ...,  0.0587, -0.0195, -0.0302],
        [ 0.0092,  0.0273, -0.0045,  ..., -0.0115,  0.0016,  0.0178]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1393, -1.6035,  0.1052,  ...,  0.8413, -0.7007, -0.0259]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 04:04:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a buffalo is referred to as a calf
The offspring of a butterfly is referred to as a larva
The offspring of a fish is referred to as a fingerling
The offspring of a goat is referred to as a kid
The offspring of a horse is referred to as a foal
The offspring of a fox is referred to as a cub
The offspring of a camel is referred to as a calf
The offspring of a cricket is referred to as a
2024-07-28 04:04:06 root INFO     [order_1_approx] starting weight calculation for The offspring of a camel is referred to as a calf
The offspring of a buffalo is referred to as a calf
The offspring of a fox is referred to as a cub
The offspring of a butterfly is referred to as a larva
The offspring of a horse is referred to as a foal
The offspring of a fish is referred to as a fingerling
The offspring of a cricket is referred to as a larva
The offspring of a goat is referred to as a
2024-07-28 04:04:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 04:06:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0557, -0.1985, -0.0848,  ..., -0.2228, -0.1214,  0.2500],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.9531, -3.0957, -0.3242,  ...,  1.5557, -3.0859, -1.4932],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0179,  0.0044,  0.0242,  ...,  0.0224, -0.0050, -0.0160],
        [-0.0161,  0.0317,  0.0048,  ..., -0.0189, -0.0222, -0.0092],
        [ 0.0154, -0.0076,  0.0144,  ..., -0.0187, -0.0023,  0.0085],
        ...,
        [-0.0035,  0.0157,  0.0030,  ...,  0.0290,  0.0199, -0.0179],
        [ 0.0264,  0.0043,  0.0152,  ..., -0.0146, -0.0036,  0.0219],
        [ 0.0045,  0.0291, -0.0193,  ...,  0.0050, -0.0145,  0.0131]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.5469, -2.6855, -0.6377,  ...,  2.1660, -3.0449, -1.1602]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 04:06:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a camel is referred to as a calf
The offspring of a buffalo is referred to as a calf
The offspring of a fox is referred to as a cub
The offspring of a butterfly is referred to as a larva
The offspring of a horse is referred to as a foal
The offspring of a fish is referred to as a fingerling
The offspring of a cricket is referred to as a larva
The offspring of a goat is referred to as a
2024-07-28 04:06:53 root INFO     [order_1_approx] starting weight calculation for The offspring of a fox is referred to as a cub
The offspring of a buffalo is referred to as a calf
The offspring of a goat is referred to as a kid
The offspring of a horse is referred to as a foal
The offspring of a butterfly is referred to as a larva
The offspring of a cricket is referred to as a larva
The offspring of a camel is referred to as a calf
The offspring of a fish is referred to as a
2024-07-28 04:06:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 04:09:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1711,  0.2150, -0.0755,  ..., -0.1765, -0.1348,  0.0693],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0547, -2.9648, -2.7578,  ..., -0.4219, -4.5312,  0.5234],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0419, -0.0283,  0.0264,  ...,  0.0226, -0.0191, -0.0009],
        [-0.0109,  0.0467, -0.0155,  ..., -0.0107,  0.0110, -0.0322],
        [ 0.0522, -0.0238,  0.0229,  ..., -0.0051,  0.0023,  0.0001],
        ...,
        [-0.0180,  0.0433, -0.0147,  ...,  0.0322, -0.0042, -0.0054],
        [ 0.0008,  0.0202, -0.0167,  ..., -0.0220,  0.0044, -0.0012],
        [ 0.0004, -0.0006,  0.0069,  ...,  0.0023, -0.0120,  0.0382]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6035, -2.6035, -2.8555,  ..., -0.5273, -4.3711,  0.3459]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 04:09:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a fox is referred to as a cub
The offspring of a buffalo is referred to as a calf
The offspring of a goat is referred to as a kid
The offspring of a horse is referred to as a foal
The offspring of a butterfly is referred to as a larva
The offspring of a cricket is referred to as a larva
The offspring of a camel is referred to as a calf
The offspring of a fish is referred to as a
2024-07-28 04:09:39 root INFO     [order_1_approx] starting weight calculation for The offspring of a fox is referred to as a cub
The offspring of a fish is referred to as a fingerling
The offspring of a buffalo is referred to as a calf
The offspring of a cricket is referred to as a larva
The offspring of a camel is referred to as a calf
The offspring of a horse is referred to as a foal
The offspring of a goat is referred to as a kid
The offspring of a butterfly is referred to as a
2024-07-28 04:09:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 04:12:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0925,  0.1649,  0.0906,  ..., -0.3877, -0.1243,  0.0487],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3066, -1.1445, -1.3574,  ...,  2.0957, -1.4307,  1.3516],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.1353e-02, -2.8000e-03,  7.3967e-03,  ..., -7.6294e-06,
          4.9515e-03,  6.0196e-03],
        [-1.1345e-02,  2.0828e-02,  8.1177e-03,  ..., -6.4392e-03,
         -5.0659e-03, -3.0151e-02],
        [-8.5907e-03,  1.7357e-03,  3.2867e-02,  ...,  1.4389e-02,
         -1.8282e-03,  6.0806e-03],
        ...,
        [-1.0536e-02,  1.1169e-02, -2.0325e-02,  ...,  2.3468e-02,
         -3.2616e-04, -2.4811e-02],
        [ 5.3596e-04, -2.4738e-03,  1.6632e-02,  ...,  9.0179e-03,
         -6.2218e-03, -8.2169e-03],
        [ 1.9287e-02,  8.5678e-03,  1.3054e-02,  ..., -2.5101e-03,
          8.6365e-03,  4.6936e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2773, -0.9424, -1.4346,  ...,  2.3438, -0.9697,  1.1865]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 04:12:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a fox is referred to as a cub
The offspring of a fish is referred to as a fingerling
The offspring of a buffalo is referred to as a calf
The offspring of a cricket is referred to as a larva
The offspring of a camel is referred to as a calf
The offspring of a horse is referred to as a foal
The offspring of a goat is referred to as a kid
The offspring of a butterfly is referred to as a
2024-07-28 04:12:22 root INFO     [order_1_approx] starting weight calculation for The offspring of a fox is referred to as a cub
The offspring of a goat is referred to as a kid
The offspring of a buffalo is referred to as a calf
The offspring of a cricket is referred to as a larva
The offspring of a camel is referred to as a calf
The offspring of a butterfly is referred to as a larva
The offspring of a fish is referred to as a fingerling
The offspring of a horse is referred to as a
2024-07-28 04:12:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 04:15:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1411, -0.0161, -0.0220,  ..., -0.0046,  0.0853,  0.1379],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8584, -5.2266, -2.3477,  ...,  2.6973, -1.2686,  2.5605],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0067, -0.0055,  0.0181,  ..., -0.0064, -0.0133,  0.0211],
        [ 0.0074,  0.0078, -0.0085,  ..., -0.0138, -0.0068, -0.0149],
        [ 0.0153,  0.0035,  0.0258,  ..., -0.0099, -0.0235, -0.0078],
        ...,
        [-0.0019,  0.0028, -0.0049,  ...,  0.0082, -0.0098, -0.0069],
        [ 0.0107,  0.0084,  0.0157,  ...,  0.0108,  0.0093,  0.0051],
        [ 0.0157, -0.0123,  0.0036,  ..., -0.0102, -0.0036,  0.0011]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6172, -4.6992, -2.2734,  ...,  3.3555, -1.7891,  2.5566]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 04:15:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a fox is referred to as a cub
The offspring of a goat is referred to as a kid
The offspring of a buffalo is referred to as a calf
The offspring of a cricket is referred to as a larva
The offspring of a camel is referred to as a calf
The offspring of a butterfly is referred to as a larva
The offspring of a fish is referred to as a fingerling
The offspring of a horse is referred to as a
2024-07-28 04:15:09 root INFO     [order_1_approx] starting weight calculation for The offspring of a fox is referred to as a cub
The offspring of a horse is referred to as a foal
The offspring of a camel is referred to as a calf
The offspring of a fish is referred to as a fingerling
The offspring of a goat is referred to as a kid
The offspring of a cricket is referred to as a larva
The offspring of a butterfly is referred to as a larva
The offspring of a buffalo is referred to as a
2024-07-28 04:15:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 04:17:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0559,  0.0291,  0.0281,  ..., -0.1648, -0.2686,  0.1472],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4648, -4.3633, -0.6733,  ...,  1.5703, -1.4434, -0.2861],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.1408e-02, -1.2787e-02,  6.1073e-03,  ..., -6.8359e-03,
          3.2463e-03, -1.3550e-02],
        [ 2.0721e-02,  2.8061e-02,  1.8661e-02,  ..., -4.6661e-02,
         -2.0859e-02, -1.9562e-02],
        [ 2.0203e-02, -5.2643e-03,  4.5990e-02,  ...,  3.1281e-04,
         -2.1271e-02, -1.3771e-03],
        ...,
        [ 1.1444e-05,  2.2934e-02, -4.9629e-03,  ...,  2.3331e-02,
          4.3701e-02, -2.7557e-02],
        [ 5.7831e-03,  1.0674e-02,  4.7119e-02,  ..., -1.3824e-02,
          4.4136e-03,  5.3825e-03],
        [ 9.1553e-03,  7.0038e-03, -1.8616e-02,  ..., -1.3374e-02,
          1.8219e-02,  9.9716e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0586, -4.2852, -0.4399,  ...,  1.8125, -1.7090,  0.0168]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 04:17:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a fox is referred to as a cub
The offspring of a horse is referred to as a foal
The offspring of a camel is referred to as a calf
The offspring of a fish is referred to as a fingerling
The offspring of a goat is referred to as a kid
The offspring of a cricket is referred to as a larva
The offspring of a butterfly is referred to as a larva
The offspring of a buffalo is referred to as a
2024-07-28 04:17:49 root INFO     [order_1_approx] starting weight calculation for The offspring of a fish is referred to as a fingerling
The offspring of a butterfly is referred to as a larva
The offspring of a fox is referred to as a cub
The offspring of a buffalo is referred to as a calf
The offspring of a horse is referred to as a foal
The offspring of a goat is referred to as a kid
The offspring of a cricket is referred to as a larva
The offspring of a camel is referred to as a
2024-07-28 04:17:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 04:20:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0089, -0.1132, -0.2113,  ..., -0.2976, -0.1799,  0.3467],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1484, -1.9102, -0.1836,  ...,  1.1182, -3.0039,  0.7886],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.6448e-02,  4.2610e-03, -1.1307e-02,  ..., -9.5062e-03,
         -2.6031e-02,  5.4855e-03],
        [ 8.4839e-03,  1.6602e-02,  1.6144e-02,  ..., -1.0246e-02,
         -1.0406e-02, -4.4434e-02],
        [ 2.5406e-02,  1.6693e-02,  2.6459e-02,  ..., -1.7914e-02,
         -1.5060e-02, -9.1553e-03],
        ...,
        [ 8.4381e-03,  2.6428e-02, -1.2054e-02,  ...,  4.0558e-02,
          8.5297e-03, -1.1330e-03],
        [ 2.1957e-02, -7.3090e-03, -5.2795e-03,  ...,  5.3406e-05,
         -1.6663e-02,  1.4313e-02],
        [-7.7362e-03,  8.1787e-03, -4.4632e-04,  ..., -7.9498e-03,
          3.8025e-02,  4.3457e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8867, -1.3223, -0.3379,  ...,  1.1514, -2.7402,  0.5244]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 04:20:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a fish is referred to as a fingerling
The offspring of a butterfly is referred to as a larva
The offspring of a fox is referred to as a cub
The offspring of a buffalo is referred to as a calf
The offspring of a horse is referred to as a foal
The offspring of a goat is referred to as a kid
The offspring of a cricket is referred to as a larva
The offspring of a camel is referred to as a
2024-07-28 04:20:32 root INFO     [order_1_approx] starting weight calculation for The offspring of a fish is referred to as a fingerling
The offspring of a cricket is referred to as a larva
The offspring of a goat is referred to as a kid
The offspring of a horse is referred to as a foal
The offspring of a butterfly is referred to as a larva
The offspring of a camel is referred to as a calf
The offspring of a buffalo is referred to as a calf
The offspring of a fox is referred to as a
2024-07-28 04:20:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 04:23:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1902,  0.1459,  0.0055,  ..., -0.1196,  0.1492, -0.0760],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2734, -4.0195, -2.0527,  ...,  1.1758, -2.9629,  2.9199],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0436, -0.0237,  0.0168,  ...,  0.0261, -0.0281,  0.0181],
        [-0.0325,  0.0432, -0.0190,  ...,  0.0020, -0.0293, -0.0300],
        [ 0.0220, -0.0135,  0.0255,  ..., -0.0149, -0.0174, -0.0031],
        ...,
        [-0.0156,  0.0215,  0.0037,  ...,  0.0099,  0.0374, -0.0179],
        [-0.0065, -0.0117,  0.0282,  ...,  0.0220, -0.0011,  0.0006],
        [ 0.0065, -0.0104,  0.0109,  ...,  0.0023, -0.0035,  0.0147]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8984, -3.9824, -1.7109,  ...,  1.7070, -2.8203,  2.4980]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 04:23:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a fish is referred to as a fingerling
The offspring of a cricket is referred to as a larva
The offspring of a goat is referred to as a kid
The offspring of a horse is referred to as a foal
The offspring of a butterfly is referred to as a larva
The offspring of a camel is referred to as a calf
The offspring of a buffalo is referred to as a calf
The offspring of a fox is referred to as a
2024-07-28 04:23:13 root INFO     total operator prediction time: 1313.3355536460876 seconds
2024-07-28 04:23:13 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on synonyms - exact
2024-07-28 04:23:13 root INFO     building operator synonyms - exact
2024-07-28 04:23:13 root INFO     [order_1_approx] starting weight calculation for Another word for phone is telephone
Another word for clothes is clothing
Another word for auto is car
Another word for lady is madam
Another word for monument is memorial
Another word for airplane is aeroplane
Another word for lazy is indolent
Another word for father is
2024-07-28 04:23:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 04:25:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0196,  0.1046, -0.1313,  ..., -0.0271, -0.1564,  0.0854],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1660, -2.3574,  0.0889,  ...,  0.4644, -2.8477, -1.9688],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0313, -0.0285,  0.0251,  ...,  0.0007,  0.0094, -0.0002],
        [-0.0081,  0.0119,  0.0008,  ..., -0.0185,  0.0204,  0.0004],
        [ 0.0111, -0.0225,  0.0487,  ...,  0.0523, -0.0128, -0.0029],
        ...,
        [-0.0406,  0.0189, -0.0063,  ...,  0.0188, -0.0075,  0.0072],
        [-0.0281,  0.0036, -0.0136,  ..., -0.0052, -0.0184, -0.0099],
        [ 0.0008, -0.0056, -0.0255,  ...,  0.0060, -0.0203,  0.0147]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2988, -1.9600,  0.2861,  ...,  0.3369, -2.6035, -1.9980]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 04:25:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for phone is telephone
Another word for clothes is clothing
Another word for auto is car
Another word for lady is madam
Another word for monument is memorial
Another word for airplane is aeroplane
Another word for lazy is indolent
Another word for father is
2024-07-28 04:25:59 root INFO     [order_1_approx] starting weight calculation for Another word for lazy is indolent
Another word for monument is memorial
Another word for airplane is aeroplane
Another word for father is dad
Another word for auto is car
Another word for phone is telephone
Another word for lady is madam
Another word for clothes is
2024-07-28 04:25:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 04:28:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0090, -0.2090, -0.0786,  ...,  0.3220,  0.0176,  0.1388],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5703, -2.9941,  0.5381,  ..., -1.5947, -2.3223, -1.5576],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0507, -0.0205,  0.0274,  ...,  0.0072, -0.0016,  0.0168],
        [ 0.0009,  0.0382, -0.0085,  ...,  0.0026,  0.0105,  0.0002],
        [-0.0075, -0.0232,  0.0405,  ..., -0.0017, -0.0119, -0.0065],
        ...,
        [ 0.0258, -0.0201,  0.0254,  ...,  0.0023, -0.0041, -0.0038],
        [-0.0425,  0.0028, -0.0181,  ...,  0.0251,  0.0630, -0.0285],
        [ 0.0180, -0.0003, -0.0048,  ...,  0.0021, -0.0123, -0.0065]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3711, -2.6133,  0.5957,  ..., -1.2461, -2.3594, -1.1885]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 04:28:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for lazy is indolent
Another word for monument is memorial
Another word for airplane is aeroplane
Another word for father is dad
Another word for auto is car
Another word for phone is telephone
Another word for lady is madam
Another word for clothes is
2024-07-28 04:28:45 root INFO     [order_1_approx] starting weight calculation for Another word for airplane is aeroplane
Another word for phone is telephone
Another word for clothes is clothing
Another word for auto is car
Another word for father is dad
Another word for lazy is indolent
Another word for monument is memorial
Another word for lady is
2024-07-28 04:28:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 04:31:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1249,  0.2832, -0.1230,  ..., -0.1082,  0.0167, -0.1375],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7568, -2.5156, -1.6738,  ..., -1.9277, -3.2969, -1.0137],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0235, -0.0359,  0.0204,  ...,  0.0249, -0.0291,  0.0050],
        [ 0.0098,  0.0348,  0.0078,  ..., -0.0113,  0.0519,  0.0350],
        [ 0.0108, -0.0351,  0.0036,  ...,  0.0304, -0.0184, -0.0020],
        ...,
        [-0.0047,  0.0138,  0.0050,  ...,  0.0116,  0.0182, -0.0095],
        [-0.0138,  0.0208, -0.0022,  ...,  0.0024,  0.0252, -0.0280],
        [-0.0022, -0.0087, -0.0109,  ...,  0.0046, -0.0301, -0.0023]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4268, -2.1289, -1.7002,  ..., -1.1816, -3.6582, -1.1338]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 04:31:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for airplane is aeroplane
Another word for phone is telephone
Another word for clothes is clothing
Another word for auto is car
Another word for father is dad
Another word for lazy is indolent
Another word for monument is memorial
Another word for lady is
2024-07-28 04:31:32 root INFO     [order_1_approx] starting weight calculation for Another word for clothes is clothing
Another word for phone is telephone
Another word for father is dad
Another word for lady is madam
Another word for monument is memorial
Another word for airplane is aeroplane
Another word for lazy is indolent
Another word for auto is
2024-07-28 04:31:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 04:34:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1942,  0.1975, -0.0504,  ..., -0.0974, -0.1037, -0.0053],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0322, -6.2578,  1.9717,  ..., -0.9980, -0.5645,  1.2891],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0527,  0.0051,  0.0273,  ...,  0.0464,  0.0152,  0.0133],
        [-0.0410,  0.0347, -0.0245,  ..., -0.0137,  0.0270, -0.0402],
        [ 0.0242,  0.0174,  0.0492,  ...,  0.0046, -0.0252, -0.0087],
        ...,
        [-0.0327, -0.0228, -0.0038,  ...,  0.0644, -0.0023, -0.0203],
        [-0.0006,  0.0084,  0.0007,  ...,  0.0410,  0.0376, -0.0289],
        [-0.0257, -0.0161, -0.0299,  ..., -0.0068, -0.0123,  0.0613]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.5557, -6.3867,  1.9424,  ..., -0.6396, -0.5308,  0.9639]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 04:34:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for clothes is clothing
Another word for phone is telephone
Another word for father is dad
Another word for lady is madam
Another word for monument is memorial
Another word for airplane is aeroplane
Another word for lazy is indolent
Another word for auto is
2024-07-28 04:34:16 root INFO     [order_1_approx] starting weight calculation for Another word for father is dad
Another word for clothes is clothing
Another word for auto is car
Another word for lazy is indolent
Another word for phone is telephone
Another word for monument is memorial
Another word for lady is madam
Another word for airplane is
2024-07-28 04:34:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 04:37:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0183,  0.0611, -0.1567,  ...,  0.1632, -0.1472,  0.0416],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1250, -3.5781,  3.0703,  ..., -1.2285, -1.5967,  1.3730],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0468, -0.0051,  0.0090,  ...,  0.0160,  0.0187,  0.0073],
        [ 0.0147,  0.0495, -0.0094,  ...,  0.0277,  0.0081,  0.0061],
        [-0.0050,  0.0048,  0.0605,  ..., -0.0071, -0.0127,  0.0179],
        ...,
        [ 0.0045,  0.0065, -0.0017,  ...,  0.0371, -0.0043, -0.0122],
        [-0.0146, -0.0024,  0.0096,  ..., -0.0089,  0.0264,  0.0061],
        [ 0.0036,  0.0119,  0.0040,  ..., -0.0138,  0.0052,  0.0191]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2311, -3.3906,  3.0410,  ..., -1.3281, -1.6504,  1.1318]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 04:37:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for father is dad
Another word for clothes is clothing
Another word for auto is car
Another word for lazy is indolent
Another word for phone is telephone
Another word for monument is memorial
Another word for lady is madam
Another word for airplane is
2024-07-28 04:37:03 root INFO     [order_1_approx] starting weight calculation for Another word for clothes is clothing
Another word for father is dad
Another word for lady is madam
Another word for monument is memorial
Another word for phone is telephone
Another word for auto is car
Another word for airplane is aeroplane
Another word for lazy is
2024-07-28 04:37:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 04:39:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2676, -0.0482,  0.0106,  ..., -0.1278, -0.1622,  0.2983],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7168, -2.2617,  1.3379,  ..., -2.2266, -3.5703, -2.3184],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0456, -0.0127, -0.0093,  ..., -0.0369,  0.0395, -0.0070],
        [ 0.0167,  0.0140,  0.0022,  ..., -0.0358, -0.0090,  0.0260],
        [-0.0044, -0.0108,  0.0331,  ...,  0.0149, -0.0126, -0.0027],
        ...,
        [-0.0098,  0.0169,  0.0211,  ...,  0.0740, -0.0155,  0.0187],
        [ 0.0086,  0.0282,  0.0111,  ...,  0.0193,  0.0003, -0.0516],
        [ 0.0346, -0.0028, -0.0110,  ...,  0.0168,  0.0038,  0.0306]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6299, -1.8145,  1.2139,  ..., -1.6240, -3.4375, -2.0098]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 04:39:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for clothes is clothing
Another word for father is dad
Another word for lady is madam
Another word for monument is memorial
Another word for phone is telephone
Another word for auto is car
Another word for airplane is aeroplane
Another word for lazy is
2024-07-28 04:39:48 root INFO     [order_1_approx] starting weight calculation for Another word for father is dad
Another word for lazy is indolent
Another word for airplane is aeroplane
Another word for lady is madam
Another word for phone is telephone
Another word for auto is car
Another word for clothes is clothing
Another word for monument is
2024-07-28 04:39:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 04:42:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1853,  0.1805,  0.2017,  ...,  0.1267, -0.1841,  0.1394],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.3457, -3.6289,  1.6221,  ...,  0.2988, -3.5176, -1.7822],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0744, -0.0013,  0.0134,  ...,  0.0036, -0.0304,  0.0116],
        [-0.0341,  0.0458,  0.0064,  ..., -0.0269,  0.0469, -0.0464],
        [ 0.0447, -0.0199,  0.0456,  ...,  0.0400, -0.0530,  0.0173],
        ...,
        [ 0.0013, -0.0077,  0.0157,  ...,  0.0516,  0.0414, -0.0645],
        [-0.0453,  0.0225, -0.0135,  ...,  0.0216,  0.0262, -0.0354],
        [-0.0045,  0.0196,  0.0188,  ..., -0.0228,  0.0295,  0.0267]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.3770, -3.6953,  1.4795,  ...,  0.4746, -3.7090, -1.9854]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 04:42:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for father is dad
Another word for lazy is indolent
Another word for airplane is aeroplane
Another word for lady is madam
Another word for phone is telephone
Another word for auto is car
Another word for clothes is clothing
Another word for monument is
2024-07-28 04:42:35 root INFO     [order_1_approx] starting weight calculation for Another word for monument is memorial
Another word for lazy is indolent
Another word for airplane is aeroplane
Another word for auto is car
Another word for lady is madam
Another word for clothes is clothing
Another word for father is dad
Another word for phone is
2024-07-28 04:42:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 04:45:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1555, -0.1779, -0.0862,  ...,  0.1877, -0.0712, -0.3560],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.1094, -4.0195,  1.4609,  ..., -0.8447, -0.3555, -4.5078],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0662, -0.0473,  0.0170,  ...,  0.0033, -0.0105, -0.0099],
        [-0.0118,  0.0464,  0.0039,  ...,  0.0226,  0.0111, -0.0015],
        [-0.0011, -0.0482,  0.0620,  ...,  0.0125, -0.0149,  0.0050],
        ...,
        [ 0.0034, -0.0202,  0.0214,  ...,  0.0258, -0.0314,  0.0027],
        [-0.0113,  0.0109, -0.0012,  ..., -0.0059,  0.0200, -0.0233],
        [-0.0011,  0.0206, -0.0078,  ..., -0.0015, -0.0129,  0.0218]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6289, -4.0742,  1.8662,  ..., -0.3540, -0.5615, -4.2812]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 04:45:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for monument is memorial
Another word for lazy is indolent
Another word for airplane is aeroplane
Another word for auto is car
Another word for lady is madam
Another word for clothes is clothing
Another word for father is dad
Another word for phone is
2024-07-28 04:45:14 root INFO     total operator prediction time: 1321.6425168514252 seconds
2024-07-28 04:45:14 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hypernyms - misc
2024-07-28 04:45:14 root INFO     building operator hypernyms - misc
2024-07-28 04:45:15 root INFO     [order_1_approx] starting weight calculation for The diary falls into the category of journal
The tv falls into the category of device
The cake falls into the category of dessert
The postcard falls into the category of card
The sweater falls into the category of clothes
The pie falls into the category of pastry
The brooch falls into the category of jewelry
The fridge falls into the category of
2024-07-28 04:45:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 04:47:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1202, -0.0413, -0.0179,  ..., -0.0473, -0.4146,  0.0520],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1797, -5.9141,  4.1055,  ..., -2.1562, -2.5586,  0.0088],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0637, -0.0154, -0.0331,  ...,  0.0053, -0.0307, -0.0043],
        [-0.0113,  0.0290,  0.0397,  ..., -0.0098,  0.0072,  0.0020],
        [-0.0022, -0.0086, -0.0149,  ...,  0.0008, -0.0113,  0.0266],
        ...,
        [ 0.0159, -0.0169,  0.0030,  ...,  0.0392, -0.0108, -0.0089],
        [ 0.0093,  0.0136, -0.0197,  ...,  0.0086,  0.0484, -0.0223],
        [ 0.0166,  0.0064, -0.0073,  ..., -0.0304,  0.0409,  0.0352]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-3.0518e-03, -6.0352e+00,  3.9668e+00,  ..., -1.9746e+00,
         -2.0820e+00,  7.7934e-03]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SubBackward0>) 

                    
2024-07-28 04:48:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The diary falls into the category of journal
The tv falls into the category of device
The cake falls into the category of dessert
The postcard falls into the category of card
The sweater falls into the category of clothes
The pie falls into the category of pastry
The brooch falls into the category of jewelry
The fridge falls into the category of
2024-07-28 04:48:01 root INFO     [order_1_approx] starting weight calculation for The cake falls into the category of dessert
The brooch falls into the category of jewelry
The diary falls into the category of journal
The postcard falls into the category of card
The sweater falls into the category of clothes
The tv falls into the category of device
The fridge falls into the category of appliance
The pie falls into the category of
2024-07-28 04:48:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 04:50:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0249, -0.4138,  0.1256,  ..., -0.3687, -0.3936, -0.0706],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1445, -5.9336,  0.0869,  ..., -4.5000, -4.1250,  0.0234],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0209, -0.0176, -0.0252,  ..., -0.0287, -0.0314,  0.0085],
        [ 0.0036,  0.0372,  0.0129,  ..., -0.0222, -0.0276, -0.0088],
        [ 0.0069, -0.0397,  0.0442,  ..., -0.0200, -0.0090,  0.0155],
        ...,
        [ 0.0226,  0.0439,  0.0052,  ...,  0.0592,  0.0106,  0.0042],
        [-0.0150, -0.0151,  0.0074,  ..., -0.0041,  0.0928, -0.0132],
        [-0.0062,  0.0042,  0.0076,  ..., -0.0302,  0.0043,  0.0221]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6562, -5.7539, -0.4253,  ..., -3.9492, -3.8613,  0.1146]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 04:50:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The cake falls into the category of dessert
The brooch falls into the category of jewelry
The diary falls into the category of journal
The postcard falls into the category of card
The sweater falls into the category of clothes
The tv falls into the category of device
The fridge falls into the category of appliance
The pie falls into the category of
2024-07-28 04:50:46 root INFO     [order_1_approx] starting weight calculation for The cake falls into the category of dessert
The postcard falls into the category of card
The brooch falls into the category of jewelry
The fridge falls into the category of appliance
The sweater falls into the category of clothes
The pie falls into the category of pastry
The tv falls into the category of device
The diary falls into the category of
2024-07-28 04:50:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 04:53:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0587,  0.0218, -0.1632,  ..., -0.1678, -0.3484,  0.0867],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7598, -3.2969,  1.7656,  ..., -3.7910, -2.9180,  0.1250],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0237,  0.0025,  0.0186,  ...,  0.0007,  0.0262, -0.0004],
        [-0.0038,  0.0213, -0.0033,  ..., -0.0294, -0.0182,  0.0390],
        [-0.0063, -0.0367,  0.0118,  ...,  0.0175, -0.0225, -0.0023],
        ...,
        [ 0.0270,  0.0187, -0.0108,  ...,  0.0228,  0.0134,  0.0114],
        [-0.0010,  0.0031,  0.0264,  ...,  0.0063,  0.0196, -0.0133],
        [ 0.0189,  0.0008,  0.0076,  ..., -0.0436, -0.0034,  0.0504]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.0078, -3.6211,  1.6250,  ..., -3.4316, -2.7090, -0.2500]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 04:53:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The cake falls into the category of dessert
The postcard falls into the category of card
The brooch falls into the category of jewelry
The fridge falls into the category of appliance
The sweater falls into the category of clothes
The pie falls into the category of pastry
The tv falls into the category of device
The diary falls into the category of
2024-07-28 04:53:30 root INFO     [order_1_approx] starting weight calculation for The cake falls into the category of dessert
The diary falls into the category of journal
The brooch falls into the category of jewelry
The pie falls into the category of pastry
The sweater falls into the category of clothes
The tv falls into the category of device
The fridge falls into the category of appliance
The postcard falls into the category of
2024-07-28 04:53:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 04:56:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2407,  0.0242, -0.0596,  ..., -0.1923, -0.3494, -0.2041],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0071, -2.6836,  0.4038,  ..., -1.6738, -3.8555,  1.5635],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0530, -0.0172,  0.0216,  ...,  0.0087, -0.0158,  0.0088],
        [-0.0100,  0.0362,  0.0122,  ..., -0.0169, -0.0419, -0.0148],
        [ 0.0233,  0.0067,  0.0159,  ...,  0.0485, -0.0361,  0.0131],
        ...,
        [ 0.0404,  0.0177, -0.0078,  ...,  0.0273, -0.0427, -0.0115],
        [ 0.0040, -0.0018,  0.0163,  ..., -0.0218,  0.0692, -0.0051],
        [-0.0075,  0.0047,  0.0065,  ..., -0.0472,  0.0356,  0.0318]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1584, -3.0703,  0.7832,  ..., -1.3105, -3.3203,  1.3057]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 04:56:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The cake falls into the category of dessert
The diary falls into the category of journal
The brooch falls into the category of jewelry
The pie falls into the category of pastry
The sweater falls into the category of clothes
The tv falls into the category of device
The fridge falls into the category of appliance
The postcard falls into the category of
2024-07-28 04:56:12 root INFO     [order_1_approx] starting weight calculation for The pie falls into the category of pastry
The brooch falls into the category of jewelry
The cake falls into the category of dessert
The sweater falls into the category of clothes
The postcard falls into the category of card
The diary falls into the category of journal
The fridge falls into the category of appliance
The tv falls into the category of
2024-07-28 04:56:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 04:58:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1198, -0.2600, -0.0070,  ...,  0.2141, -0.0573, -0.0209],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.2871, -3.2930,  2.4160,  ..., -1.5449, -3.1289, -1.5811],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0346, -0.0760, -0.0423,  ..., -0.0549,  0.0377,  0.0189],
        [-0.0053,  0.0365,  0.0215,  ..., -0.0041,  0.0142,  0.0127],
        [ 0.0138,  0.0297,  0.0033,  ..., -0.0064, -0.0201,  0.0068],
        ...,
        [ 0.0145,  0.0174,  0.0315,  ...,  0.0332, -0.0100, -0.0148],
        [ 0.0128,  0.0015,  0.0079,  ...,  0.0051,  0.0352, -0.0025],
        [-0.0029, -0.0485,  0.0088,  ..., -0.0470,  0.0187,  0.0251]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.7686, -3.5684,  2.6172,  ..., -1.7549, -2.7832, -1.2129]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 04:58:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The pie falls into the category of pastry
The brooch falls into the category of jewelry
The cake falls into the category of dessert
The sweater falls into the category of clothes
The postcard falls into the category of card
The diary falls into the category of journal
The fridge falls into the category of appliance
The tv falls into the category of
2024-07-28 04:58:56 root INFO     [order_1_approx] starting weight calculation for The pie falls into the category of pastry
The diary falls into the category of journal
The tv falls into the category of device
The postcard falls into the category of card
The sweater falls into the category of clothes
The brooch falls into the category of jewelry
The fridge falls into the category of appliance
The cake falls into the category of
2024-07-28 04:58:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 05:01:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0468, -0.0813,  0.0109,  ..., -0.1837, -0.5342, -0.1986],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4980, -5.8750, -0.3999,  ..., -3.7305, -4.0273,  0.9512],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0458, -0.0194, -0.0394,  ..., -0.0077,  0.0025,  0.0203],
        [ 0.0263,  0.0198,  0.0183,  ...,  0.0121, -0.0301,  0.0109],
        [-0.0041,  0.0010,  0.0277,  ..., -0.0166,  0.0059,  0.0156],
        ...,
        [ 0.0208,  0.0188,  0.0172,  ...,  0.0631, -0.0157, -0.0061],
        [ 0.0121, -0.0007,  0.0043,  ...,  0.0068,  0.0621, -0.0026],
        [ 0.0282, -0.0259, -0.0096,  ..., -0.0080,  0.0069,  0.0386]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8262, -5.8047, -0.6172,  ..., -3.3477, -3.6973,  0.6816]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 05:01:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The pie falls into the category of pastry
The diary falls into the category of journal
The tv falls into the category of device
The postcard falls into the category of card
The sweater falls into the category of clothes
The brooch falls into the category of jewelry
The fridge falls into the category of appliance
The cake falls into the category of
2024-07-28 05:01:42 root INFO     [order_1_approx] starting weight calculation for The diary falls into the category of journal
The fridge falls into the category of appliance
The brooch falls into the category of jewelry
The cake falls into the category of dessert
The postcard falls into the category of card
The pie falls into the category of pastry
The tv falls into the category of device
The sweater falls into the category of
2024-07-28 05:01:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 05:04:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1069, -0.2947,  0.1522,  ...,  0.2244, -0.2754, -0.0049],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3086, -5.7812,  0.2302,  ...,  0.1877, -3.2930,  2.6484],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0286,  0.0067, -0.0086,  ...,  0.0069,  0.0279,  0.0243],
        [-0.0172,  0.0264,  0.0298,  ..., -0.0372, -0.0238,  0.0294],
        [-0.0062, -0.0068,  0.0137,  ...,  0.0396, -0.0349, -0.0145],
        ...,
        [ 0.0289, -0.0246, -0.0011,  ...,  0.0341,  0.0032, -0.0047],
        [ 0.0025, -0.0052, -0.0243,  ...,  0.0537,  0.0139, -0.0221],
        [-0.0077,  0.0059,  0.0151,  ..., -0.0333, -0.0058,  0.0137]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2891, -5.6133,  0.7441,  ...,  0.1227, -2.9492,  2.6562]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 05:04:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The diary falls into the category of journal
The fridge falls into the category of appliance
The brooch falls into the category of jewelry
The cake falls into the category of dessert
The postcard falls into the category of card
The pie falls into the category of pastry
The tv falls into the category of device
The sweater falls into the category of
2024-07-28 05:04:27 root INFO     [order_1_approx] starting weight calculation for The diary falls into the category of journal
The postcard falls into the category of card
The fridge falls into the category of appliance
The sweater falls into the category of clothes
The pie falls into the category of pastry
The tv falls into the category of device
The cake falls into the category of dessert
The brooch falls into the category of
2024-07-28 05:04:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 05:07:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0400, -0.0552, -0.0086,  ...,  0.1066,  0.0504,  0.1289],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6758, -7.2656, -4.3828,  ..., -1.2842, -4.9531,  2.6992],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0487, -0.0091,  0.0146,  ..., -0.0177, -0.0175,  0.0314],
        [-0.0071,  0.0289,  0.0017,  ...,  0.0104,  0.0274, -0.0221],
        [ 0.0381, -0.0024, -0.0164,  ...,  0.0333, -0.0462, -0.0017],
        ...,
        [ 0.0222, -0.0231,  0.0024,  ...,  0.0636,  0.0097, -0.0199],
        [-0.0273, -0.0017,  0.0097,  ...,  0.0293,  0.0461, -0.0173],
        [-0.0051, -0.0103, -0.0069,  ..., -0.0132, -0.0134,  0.0478]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1348, -7.0156, -3.5625,  ..., -0.7607, -4.8906,  2.5664]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 05:07:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The diary falls into the category of journal
The postcard falls into the category of card
The fridge falls into the category of appliance
The sweater falls into the category of clothes
The pie falls into the category of pastry
The tv falls into the category of device
The cake falls into the category of dessert
The brooch falls into the category of
2024-07-28 05:07:12 root INFO     total operator prediction time: 1317.8262584209442 seconds
2024-07-28 05:07:12 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - substance
2024-07-28 05:07:12 root INFO     building operator meronyms - substance
2024-07-28 05:07:12 root INFO     [order_1_approx] starting weight calculation for A steel is made up of iron
A roof is made up of shingles
A wig is made up of hair
A house is made up of bricks
A wall is made up of cement
A cloud is made up of vapor
A money is made up of paper
A wire is made up of
2024-07-28 05:07:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 05:09:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0339, -0.0873, -0.2405,  ..., -0.0154,  0.0443,  0.0268],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.4258, -5.1562,  0.0776,  ..., -2.2773,  0.0723, -2.1602],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0338, -0.0403,  0.0388,  ...,  0.0179, -0.0006, -0.0203],
        [-0.0210,  0.0295, -0.0058,  ..., -0.0142,  0.0057,  0.0144],
        [ 0.0113,  0.0111,  0.0296,  ..., -0.0241,  0.0132, -0.0161],
        ...,
        [ 0.0047, -0.0075,  0.0172,  ...,  0.0197,  0.0213, -0.0175],
        [ 0.0209,  0.0328, -0.0155,  ...,  0.0115,  0.0160,  0.0130],
        [-0.0430, -0.0281, -0.0266,  ..., -0.0369,  0.0053,  0.0143]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.6406, -5.3047,  0.0487,  ..., -1.8877,  0.0199, -1.3105]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 05:09:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A steel is made up of iron
A roof is made up of shingles
A wig is made up of hair
A house is made up of bricks
A wall is made up of cement
A cloud is made up of vapor
A money is made up of paper
A wire is made up of
2024-07-28 05:09:59 root INFO     [order_1_approx] starting weight calculation for A steel is made up of iron
A money is made up of paper
A house is made up of bricks
A wire is made up of metal
A roof is made up of shingles
A wig is made up of hair
A cloud is made up of vapor
A wall is made up of
2024-07-28 05:09:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 05:12:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1522, -0.0025,  0.0656,  ...,  0.3181, -0.2000, -0.1730],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6719, -5.6055,  1.1416,  ..., -1.8340, -1.3672,  0.0303],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0196,  0.0025,  0.0145,  ..., -0.0179, -0.0155, -0.0240],
        [ 0.0174,  0.0108,  0.0072,  ...,  0.0034,  0.0054, -0.0035],
        [-0.0102,  0.0136,  0.0106,  ...,  0.0320, -0.0107, -0.0062],
        ...,
        [ 0.0265, -0.0086,  0.0145,  ...,  0.0172, -0.0202, -0.0234],
        [-0.0087,  0.0489, -0.0267,  ...,  0.0273,  0.0098, -0.0145],
        [ 0.0078, -0.0483,  0.0397,  ...,  0.0169,  0.0092,  0.0530]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5527, -5.3867,  1.6465,  ..., -1.6582, -1.5566,  0.0479]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 05:12:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A steel is made up of iron
A money is made up of paper
A house is made up of bricks
A wire is made up of metal
A roof is made up of shingles
A wig is made up of hair
A cloud is made up of vapor
A wall is made up of
2024-07-28 05:12:42 root INFO     [order_1_approx] starting weight calculation for A money is made up of paper
A wig is made up of hair
A steel is made up of iron
A wall is made up of cement
A wire is made up of metal
A cloud is made up of vapor
A roof is made up of shingles
A house is made up of
2024-07-28 05:12:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 05:15:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0008,  0.3335,  0.0031,  ...,  0.0930, -0.3057, -0.2211],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8887, -6.8633,  1.8066,  ..., -1.6973, -1.0576, -1.2734],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0139, -0.0036,  0.0089,  ...,  0.0236,  0.0175, -0.0206],
        [ 0.0192,  0.0031,  0.0255,  ..., -0.0264, -0.0254,  0.0026],
        [-0.0084,  0.0155,  0.0087,  ..., -0.0033,  0.0155, -0.0157],
        ...,
        [-0.0067, -0.0017,  0.0121,  ...,  0.0196, -0.0044, -0.0206],
        [-0.0101,  0.0008, -0.0186,  ...,  0.0109, -0.0086,  0.0125],
        [ 0.0015, -0.0258,  0.0070,  ..., -0.0255, -0.0083,  0.0339]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8750, -6.5078,  1.8301,  ..., -1.6982, -0.9058, -0.9707]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 05:15:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A money is made up of paper
A wig is made up of hair
A steel is made up of iron
A wall is made up of cement
A wire is made up of metal
A cloud is made up of vapor
A roof is made up of shingles
A house is made up of
2024-07-28 05:15:28 root INFO     [order_1_approx] starting weight calculation for A house is made up of bricks
A money is made up of paper
A roof is made up of shingles
A wall is made up of cement
A cloud is made up of vapor
A wig is made up of hair
A wire is made up of metal
A steel is made up of
2024-07-28 05:15:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 05:18:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0966,  0.0004, -0.1980,  ..., -0.0484,  0.1421,  0.0533],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0469, -5.0078,  1.4893,  ..., -4.2227, -0.9678, -0.8750],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.2480e-02, -3.2288e-02,  4.1656e-03,  ..., -1.6068e-02,
         -2.2034e-02, -5.6702e-02],
        [-2.2766e-02,  1.8738e-02, -1.1963e-02,  ..., -2.1378e-02,
          2.3315e-02, -2.8412e-02],
        [ 2.1606e-02,  1.1673e-02,  1.9180e-02,  ...,  2.6443e-02,
          2.7771e-02,  2.3529e-02],
        ...,
        [ 3.1677e-02, -6.2103e-03,  1.0223e-02,  ...,  2.9846e-02,
          3.3875e-02, -4.5258e-02],
        [ 1.1902e-02,  4.5593e-02, -6.5613e-03,  ...,  4.9591e-02,
          6.1035e-05,  3.6297e-03],
        [ 7.8278e-03,  8.9645e-04, -2.8580e-02,  ..., -4.6051e-02,
         -1.9333e-02,  2.6718e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8613, -5.1875,  1.1152,  ..., -3.5117, -1.4492, -0.8086]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 05:18:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A house is made up of bricks
A money is made up of paper
A roof is made up of shingles
A wall is made up of cement
A cloud is made up of vapor
A wig is made up of hair
A wire is made up of metal
A steel is made up of
2024-07-28 05:18:13 root INFO     [order_1_approx] starting weight calculation for A house is made up of bricks
A wall is made up of cement
A wire is made up of metal
A cloud is made up of vapor
A wig is made up of hair
A steel is made up of iron
A money is made up of paper
A roof is made up of
2024-07-28 05:18:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 05:20:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1699, -0.0618,  0.1326,  ..., -0.0502, -0.1213, -0.3179],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.8789, -7.5039,  1.8652,  ..., -1.6602, -0.9062, -2.2734],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0654, -0.0275, -0.0092,  ...,  0.0041,  0.0039,  0.0027],
        [ 0.0258,  0.0282, -0.0288,  ..., -0.0064,  0.0005,  0.0374],
        [-0.0259, -0.0048,  0.0194,  ..., -0.0271, -0.0169, -0.0147],
        ...,
        [ 0.0003,  0.0129,  0.0181,  ...,  0.0573, -0.0106, -0.0173],
        [ 0.0248,  0.0333, -0.0235,  ..., -0.0154,  0.0002,  0.0330],
        [ 0.0179, -0.0391, -0.0089,  ...,  0.0211,  0.0179,  0.0243]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.6953, -7.3789,  2.0625,  ..., -1.6055, -1.3193, -1.6387]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 05:20:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A house is made up of bricks
A wall is made up of cement
A wire is made up of metal
A cloud is made up of vapor
A wig is made up of hair
A steel is made up of iron
A money is made up of paper
A roof is made up of
2024-07-28 05:20:58 root INFO     [order_1_approx] starting weight calculation for A wig is made up of hair
A wire is made up of metal
A steel is made up of iron
A house is made up of bricks
A roof is made up of shingles
A cloud is made up of vapor
A wall is made up of cement
A money is made up of
2024-07-28 05:20:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 05:23:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2450, -0.0446, -0.1390,  ...,  0.0699,  0.0393, -0.1152],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5054, -3.3359, -1.4297,  ..., -4.4727,  0.7749,  0.8398],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0134, -0.0401, -0.0163,  ..., -0.0279,  0.0035, -0.0315],
        [-0.0071,  0.0313, -0.0240,  ..., -0.0026, -0.0179, -0.0198],
        [ 0.0040,  0.0179,  0.0141,  ..., -0.0048,  0.0072, -0.0107],
        ...,
        [ 0.0248, -0.0003,  0.0059,  ...,  0.0280, -0.0001,  0.0039],
        [-0.0273, -0.0090, -0.0133,  ..., -0.0023,  0.0181, -0.0016],
        [ 0.0003, -0.0320,  0.0029,  ...,  0.0028,  0.0028,  0.0005]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3745, -3.3242, -1.2256,  ..., -4.3008,  0.5850,  1.2383]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 05:23:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A wig is made up of hair
A wire is made up of metal
A steel is made up of iron
A house is made up of bricks
A roof is made up of shingles
A cloud is made up of vapor
A wall is made up of cement
A money is made up of
2024-07-28 05:23:45 root INFO     [order_1_approx] starting weight calculation for A steel is made up of iron
A cloud is made up of vapor
A wire is made up of metal
A money is made up of paper
A house is made up of bricks
A roof is made up of shingles
A wall is made up of cement
A wig is made up of
2024-07-28 05:23:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 05:26:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0648,  0.1436, -0.0687,  ...,  0.0294,  0.1417, -0.0895],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0508, -6.1055, -1.6533,  ..., -0.7090, -1.6426,  0.5898],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0836, -0.0381, -0.0112,  ...,  0.0240,  0.0197,  0.0273],
        [-0.0290,  0.0585, -0.0093,  ..., -0.0072,  0.0101, -0.0238],
        [-0.0170, -0.0273,  0.0330,  ..., -0.0009, -0.0207, -0.0154],
        ...,
        [ 0.0172,  0.0005,  0.0113,  ...,  0.0164, -0.0226, -0.0222],
        [-0.0173,  0.0133, -0.0211,  ...,  0.0132,  0.0077, -0.0314],
        [ 0.0036, -0.0484,  0.0313,  ...,  0.0016,  0.0130,  0.0392]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6084, -6.1289, -1.6182,  ..., -0.4294, -1.2490,  0.7266]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 05:26:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A steel is made up of iron
A cloud is made up of vapor
A wire is made up of metal
A money is made up of paper
A house is made up of bricks
A roof is made up of shingles
A wall is made up of cement
A wig is made up of
2024-07-28 05:26:32 root INFO     [order_1_approx] starting weight calculation for A wall is made up of cement
A wig is made up of hair
A steel is made up of iron
A house is made up of bricks
A roof is made up of shingles
A money is made up of paper
A wire is made up of metal
A cloud is made up of
2024-07-28 05:26:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 05:29:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0617,  0.0442,  0.0713,  ..., -0.0717, -0.0040, -0.1650],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7441, -1.3945,  1.6250,  ..., -3.4453,  2.4199, -0.7344],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0510,  0.0137,  0.0086,  ..., -0.0184, -0.0020,  0.0051],
        [-0.0012,  0.0181, -0.0168,  ...,  0.0040,  0.0110,  0.0080],
        [ 0.0093, -0.0116,  0.0132,  ...,  0.0180, -0.0165,  0.0072],
        ...,
        [ 0.0041,  0.0080,  0.0091,  ...,  0.0203, -0.0059,  0.0120],
        [-0.0172,  0.0185, -0.0250,  ...,  0.0433, -0.0077, -0.0493],
        [ 0.0177, -0.0364,  0.0057,  ...,  0.0032, -0.0074,  0.0129]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1465, -1.8477,  1.4453,  ..., -3.3320,  1.7891,  0.1299]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 05:29:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A wall is made up of cement
A wig is made up of hair
A steel is made up of iron
A house is made up of bricks
A roof is made up of shingles
A money is made up of paper
A wire is made up of metal
A cloud is made up of
2024-07-28 05:29:17 root INFO     total operator prediction time: 1324.5804557800293 seconds
2024-07-28 05:29:17 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on synonyms - intensity
2024-07-28 05:29:17 root INFO     building operator synonyms - intensity
2024-07-28 05:29:17 root INFO     [order_1_approx] starting weight calculation for A more intense word for giggle is laugh
A more intense word for sad is desparate
A more intense word for dislike is hate
A more intense word for confused is lost
A more intense word for damp is drenched
A more intense word for angry is furious
A more intense word for nap is sleep
A more intense word for tasty is
2024-07-28 05:29:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 05:31:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1078, -0.0388, -0.1019,  ..., -0.2502, -0.4392,  0.0114],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.3672, -3.7812, -0.9697,  ..., -3.8730, -8.0234, -2.4102],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0043,  0.0147, -0.0068,  ...,  0.0133, -0.0010,  0.0213],
        [ 0.0368,  0.0454,  0.0006,  ...,  0.0026, -0.0346,  0.0118],
        [-0.0133, -0.0131,  0.0327,  ...,  0.0205, -0.0061,  0.0129],
        ...,
        [ 0.0189, -0.0033,  0.0031,  ...,  0.0157, -0.0067, -0.0010],
        [ 0.0273, -0.0363,  0.0274,  ..., -0.0048, -0.0004,  0.0003],
        [-0.0106,  0.0094, -0.0316,  ...,  0.0057,  0.0153,  0.0104]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 6.7305, -3.8867, -1.6396,  ..., -3.5938, -8.4688, -2.0762]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 05:32:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for giggle is laugh
A more intense word for sad is desparate
A more intense word for dislike is hate
A more intense word for confused is lost
A more intense word for damp is drenched
A more intense word for angry is furious
A more intense word for nap is sleep
A more intense word for tasty is
2024-07-28 05:32:01 root INFO     [order_1_approx] starting weight calculation for A more intense word for dislike is hate
A more intense word for nap is sleep
A more intense word for confused is lost
A more intense word for angry is furious
A more intense word for damp is drenched
A more intense word for tasty is delicious
A more intense word for giggle is laugh
A more intense word for sad is
2024-07-28 05:32:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 05:34:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0582, -0.0787, -0.0519,  ...,  0.0510, -0.3582,  0.2056],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0176, -3.2656,  3.3066,  ..., -1.1406, -0.5469, -2.5391],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0329, -0.0156,  0.0065,  ..., -0.0120,  0.0090,  0.0192],
        [-0.0090,  0.0160, -0.0072,  ...,  0.0050, -0.0082, -0.0148],
        [ 0.0048, -0.0154,  0.0381,  ...,  0.0218, -0.0011,  0.0090],
        ...,
        [ 0.0051, -0.0107, -0.0212,  ...,  0.0260, -0.0143, -0.0155],
        [-0.0149, -0.0229, -0.0215,  ...,  0.0202,  0.0320, -0.0312],
        [ 0.0015, -0.0104, -0.0084,  ...,  0.0028, -0.0132, -0.0006]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5156, -2.8516,  2.6836,  ..., -1.1416, -0.2300, -2.5762]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 05:34:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for dislike is hate
A more intense word for nap is sleep
A more intense word for confused is lost
A more intense word for angry is furious
A more intense word for damp is drenched
A more intense word for tasty is delicious
A more intense word for giggle is laugh
A more intense word for sad is
2024-07-28 05:34:45 root INFO     [order_1_approx] starting weight calculation for A more intense word for sad is desparate
A more intense word for damp is drenched
A more intense word for confused is lost
A more intense word for giggle is laugh
A more intense word for tasty is delicious
A more intense word for angry is furious
A more intense word for nap is sleep
A more intense word for dislike is
2024-07-28 05:34:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 05:37:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1211, -0.0643,  0.0245,  ...,  0.0947, -0.0873,  0.4507],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1133, -5.4297,  0.2744,  ..., -1.6914, -3.3242, -2.0684],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0059, -0.0180, -0.0422,  ..., -0.0187,  0.0653,  0.0065],
        [ 0.0332,  0.0174,  0.0568,  ..., -0.0211, -0.0552,  0.0229],
        [-0.0115, -0.0372,  0.0075,  ..., -0.0031, -0.0033, -0.0037],
        ...,
        [ 0.0323,  0.0154,  0.0107,  ...,  0.0232,  0.0214, -0.0217],
        [ 0.0364,  0.0010,  0.0057,  ...,  0.0094, -0.0389, -0.0193],
        [-0.0009, -0.0007, -0.0308,  ..., -0.0132,  0.0179,  0.0056]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4590, -5.5703,  0.3694,  ..., -2.2344, -3.2617, -2.5625]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 05:37:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for sad is desparate
A more intense word for damp is drenched
A more intense word for confused is lost
A more intense word for giggle is laugh
A more intense word for tasty is delicious
A more intense word for angry is furious
A more intense word for nap is sleep
A more intense word for dislike is
2024-07-28 05:37:29 root INFO     [order_1_approx] starting weight calculation for A more intense word for giggle is laugh
A more intense word for damp is drenched
A more intense word for dislike is hate
A more intense word for nap is sleep
A more intense word for angry is furious
A more intense word for tasty is delicious
A more intense word for sad is desparate
A more intense word for confused is
2024-07-28 05:37:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 05:40:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0791,  0.1559, -0.1790,  ...,  0.1034, -0.3789,  0.3552],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.8867, -3.3223,  4.5977,  ..., -1.3613,  0.1113, -1.1221],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0021,  0.0092, -0.0432,  ...,  0.0003,  0.0009, -0.0168],
        [ 0.0214,  0.0353,  0.0256,  ..., -0.0183, -0.0145,  0.0132],
        [-0.0100, -0.0376,  0.0561,  ...,  0.0076, -0.0246,  0.0239],
        ...,
        [ 0.0126,  0.0039,  0.0246,  ...,  0.0433, -0.0382, -0.0161],
        [ 0.0049, -0.0213, -0.0150,  ..., -0.0012,  0.0235, -0.0421],
        [ 0.0116, -0.0371,  0.0135,  ..., -0.0152, -0.0110,  0.0510]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 6.6055, -3.2832,  4.6992,  ..., -1.6328,  0.2866, -1.1338]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 05:40:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for giggle is laugh
A more intense word for damp is drenched
A more intense word for dislike is hate
A more intense word for nap is sleep
A more intense word for angry is furious
A more intense word for tasty is delicious
A more intense word for sad is desparate
A more intense word for confused is
2024-07-28 05:40:13 root INFO     [order_1_approx] starting weight calculation for A more intense word for tasty is delicious
A more intense word for sad is desparate
A more intense word for confused is lost
A more intense word for giggle is laugh
A more intense word for dislike is hate
A more intense word for angry is furious
A more intense word for damp is drenched
A more intense word for nap is
2024-07-28 05:40:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 05:42:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1099, -0.0231,  0.2222,  ...,  0.1267, -0.4534,  0.1361],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2227, -4.3398,  4.7344,  ...,  0.8857, -0.4214, -1.3896],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0188, -0.0407, -0.0298,  ...,  0.0468,  0.0389,  0.0274],
        [-0.0224,  0.0326,  0.0378,  ..., -0.0269, -0.0139, -0.0332],
        [-0.0280, -0.0229, -0.0091,  ..., -0.0031, -0.0254, -0.0347],
        ...,
        [ 0.0281,  0.0508,  0.0503,  ...,  0.0200, -0.0239, -0.0240],
        [ 0.0185, -0.0482,  0.0172,  ...,  0.0536,  0.0057, -0.0091],
        [ 0.0093, -0.0036, -0.0128,  ...,  0.0146,  0.0135,  0.0002]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3276, -4.1172,  5.1836,  ...,  0.6602, -0.7725, -1.4219]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 05:43:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for tasty is delicious
A more intense word for sad is desparate
A more intense word for confused is lost
A more intense word for giggle is laugh
A more intense word for dislike is hate
A more intense word for angry is furious
A more intense word for damp is drenched
A more intense word for nap is
2024-07-28 05:43:00 root INFO     [order_1_approx] starting weight calculation for A more intense word for nap is sleep
A more intense word for angry is furious
A more intense word for giggle is laugh
A more intense word for sad is desparate
A more intense word for confused is lost
A more intense word for tasty is delicious
A more intense word for dislike is hate
A more intense word for damp is
2024-07-28 05:43:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 05:45:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0352, -0.0458, -0.0616,  ...,  0.0129, -0.4463, -0.0167],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.2891, -4.2969, -0.0637,  ..., -1.5010,  0.8652, -3.5215],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0065,  0.0259,  0.0088,  ..., -0.0063, -0.0193, -0.0002],
        [ 0.0218,  0.0333,  0.0258,  ..., -0.0019, -0.0527, -0.0143],
        [-0.0243, -0.0396,  0.0161,  ..., -0.0104,  0.0319,  0.0550],
        ...,
        [ 0.0531,  0.0164,  0.0263,  ...,  0.0407, -0.0101, -0.0543],
        [-0.0324, -0.0085, -0.0080,  ...,  0.0097,  0.0500, -0.0012],
        [ 0.0237, -0.0018,  0.0012,  ..., -0.0133, -0.0009,  0.0225]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 6.0039, -4.3555, -0.4597,  ..., -1.0439,  0.0581, -3.6641]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 05:45:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for nap is sleep
A more intense word for angry is furious
A more intense word for giggle is laugh
A more intense word for sad is desparate
A more intense word for confused is lost
A more intense word for tasty is delicious
A more intense word for dislike is hate
A more intense word for damp is
2024-07-28 05:45:43 root INFO     [order_1_approx] starting weight calculation for A more intense word for damp is drenched
A more intense word for confused is lost
A more intense word for sad is desparate
A more intense word for nap is sleep
A more intense word for dislike is hate
A more intense word for giggle is laugh
A more intense word for tasty is delicious
A more intense word for angry is
2024-07-28 05:45:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 05:48:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1841,  0.1086, -0.2201,  ..., -0.0497, -0.1863,  0.2336],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4902, -6.8438, -0.4937,  ..., -2.8027, -0.9155, -0.4473],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0094,  0.0164,  0.0099,  ..., -0.0045, -0.0106,  0.0129],
        [ 0.0290,  0.0081, -0.0099,  ..., -0.0127, -0.0161, -0.0113],
        [ 0.0031, -0.0017,  0.0206,  ..., -0.0144, -0.0301,  0.0127],
        ...,
        [ 0.0277,  0.0167,  0.0250,  ...,  0.0409, -0.0067, -0.0026],
        [-0.0251, -0.0066, -0.0018,  ...,  0.0147,  0.0446, -0.0348],
        [-0.0105, -0.0045, -0.0166,  ...,  0.0093,  0.0045,  0.0129]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2852, -6.4883, -0.4753,  ..., -2.8145, -0.8867, -0.5708]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 05:48:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for damp is drenched
A more intense word for confused is lost
A more intense word for sad is desparate
A more intense word for nap is sleep
A more intense word for dislike is hate
A more intense word for giggle is laugh
A more intense word for tasty is delicious
A more intense word for angry is
2024-07-28 05:48:27 root INFO     [order_1_approx] starting weight calculation for A more intense word for confused is lost
A more intense word for tasty is delicious
A more intense word for damp is drenched
A more intense word for nap is sleep
A more intense word for sad is desparate
A more intense word for dislike is hate
A more intense word for angry is furious
A more intense word for giggle is
2024-07-28 05:48:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 05:51:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0017, -0.1396, -0.1804,  ..., -0.0011, -0.3821,  0.1401],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4375, -2.9238,  5.9062,  ...,  4.2227, -0.4727, -0.9961],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0295,  0.0045, -0.0082,  ..., -0.0209,  0.0228,  0.0061],
        [-0.0066,  0.0627,  0.0216,  ...,  0.0379, -0.0303,  0.0089],
        [-0.0089, -0.0215,  0.0069,  ...,  0.0063,  0.0174, -0.0019],
        ...,
        [ 0.0232,  0.0023, -0.0111,  ...,  0.0130, -0.0112, -0.0087],
        [-0.0004, -0.0140, -0.0138,  ...,  0.0006,  0.0023,  0.0049],
        [ 0.0044,  0.0082, -0.0185,  ..., -0.0062,  0.0146,  0.0079]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1943, -2.6855,  5.7930,  ...,  3.8438, -0.5347, -0.9897]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 05:51:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for confused is lost
A more intense word for tasty is delicious
A more intense word for damp is drenched
A more intense word for nap is sleep
A more intense word for sad is desparate
A more intense word for dislike is hate
A more intense word for angry is furious
A more intense word for giggle is
2024-07-28 05:51:07 root INFO     total operator prediction time: 1310.7107739448547 seconds
2024-07-28 05:51:07 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hypernyms - animals
2024-07-28 05:51:07 root INFO     building operator hypernyms - animals
2024-07-28 05:51:08 root INFO     [order_1_approx] starting weight calculation for The bee falls into the category of insect
The squirrel falls into the category of rodent
The gibbon falls into the category of primate
The gorilla falls into the category of primate
The mouse falls into the category of rodent
The goat falls into the category of bovid
The goose falls into the category of fowl
The cobra falls into the category of
2024-07-28 05:51:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 05:53:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0094,  0.0775, -0.1949,  ..., -0.0749, -0.2197, -0.0048],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1926, -4.8945,  2.2695,  ..., -1.3965, -3.2812, -0.2307],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.8168e-02, -3.0403e-03, -3.6888e-03,  ..., -1.1269e-02,
          4.1046e-03,  1.1047e-02],
        [-1.7090e-02,  1.6190e-02, -1.4206e-02,  ..., -1.1368e-03,
          1.2154e-02, -3.0289e-03],
        [ 1.9272e-02, -1.1864e-03,  5.7800e-02,  ..., -3.2593e-02,
         -1.3725e-02, -2.7466e-04],
        ...,
        [-6.2866e-03,  1.7090e-02, -8.1100e-03,  ...,  5.1758e-02,
          4.9858e-03, -9.5320e-04],
        [-2.4281e-03,  1.2253e-02, -4.9934e-03,  ...,  5.2605e-03,
          2.3117e-02, -2.1179e-02],
        [ 1.8173e-02,  4.7150e-03, -8.0109e-05,  ..., -2.5299e-02,
          2.4689e-02,  1.5015e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2974, -4.8867,  2.1973,  ..., -1.1133, -3.7285, -0.3784]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 05:53:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The bee falls into the category of insect
The squirrel falls into the category of rodent
The gibbon falls into the category of primate
The gorilla falls into the category of primate
The mouse falls into the category of rodent
The goat falls into the category of bovid
The goose falls into the category of fowl
The cobra falls into the category of
2024-07-28 05:53:52 root INFO     [order_1_approx] starting weight calculation for The gibbon falls into the category of primate
The gorilla falls into the category of primate
The goat falls into the category of bovid
The squirrel falls into the category of rodent
The cobra falls into the category of snake
The mouse falls into the category of rodent
The goose falls into the category of fowl
The bee falls into the category of
2024-07-28 05:53:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 05:56:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2288, -0.0044,  0.0776,  ...,  0.0064, -0.1141, -0.1061],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9507, -4.2461,  1.9814,  ..., -2.6211, -3.8320, -0.2500],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0411, -0.0144, -0.0107,  ..., -0.0093,  0.0017,  0.0066],
        [ 0.0108,  0.0100,  0.0073,  ..., -0.0057,  0.0332,  0.0141],
        [-0.0249,  0.0164,  0.0289,  ...,  0.0107, -0.0550,  0.0096],
        ...,
        [-0.0219,  0.0431, -0.0090,  ...,  0.0340,  0.0045, -0.0147],
        [-0.0308,  0.0253, -0.0020,  ...,  0.0032,  0.0144, -0.0137],
        [ 0.0291, -0.0334,  0.0188,  ..., -0.0255,  0.0053,  0.0290]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0967, -3.6230,  1.1328,  ..., -2.5859, -4.5977,  0.4536]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 05:56:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The gibbon falls into the category of primate
The gorilla falls into the category of primate
The goat falls into the category of bovid
The squirrel falls into the category of rodent
The cobra falls into the category of snake
The mouse falls into the category of rodent
The goose falls into the category of fowl
The bee falls into the category of
2024-07-28 05:56:37 root INFO     [order_1_approx] starting weight calculation for The gibbon falls into the category of primate
The goose falls into the category of fowl
The squirrel falls into the category of rodent
The gorilla falls into the category of primate
The cobra falls into the category of snake
The goat falls into the category of bovid
The bee falls into the category of insect
The mouse falls into the category of
2024-07-28 05:56:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 05:59:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3489, -0.2158, -0.0860,  ...,  0.1083, -0.1636, -0.2068],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.4766, -3.4570,  0.7646,  ..., -3.4707, -5.9609, -0.2798],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0349, -0.0172,  0.0063,  ..., -0.0306, -0.0314,  0.0200],
        [-0.0070,  0.0624,  0.0248,  ..., -0.0095,  0.0207, -0.0145],
        [-0.0071, -0.0210,  0.0465,  ..., -0.0374, -0.0018,  0.0021],
        ...,
        [-0.0202,  0.0063,  0.0146,  ...,  0.0248,  0.0126,  0.0008],
        [-0.0095, -0.0025,  0.0128,  ..., -0.0369,  0.0482, -0.0059],
        [ 0.0209, -0.0072, -0.0067,  ..., -0.0064, -0.0125,  0.0233]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.7490, -3.0527,  0.3279,  ..., -3.2031, -6.3398, -0.2424]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 05:59:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The gibbon falls into the category of primate
The goose falls into the category of fowl
The squirrel falls into the category of rodent
The gorilla falls into the category of primate
The cobra falls into the category of snake
The goat falls into the category of bovid
The bee falls into the category of insect
The mouse falls into the category of
2024-07-28 05:59:24 root INFO     [order_1_approx] starting weight calculation for The mouse falls into the category of rodent
The gorilla falls into the category of primate
The bee falls into the category of insect
The squirrel falls into the category of rodent
The gibbon falls into the category of primate
The goat falls into the category of bovid
The cobra falls into the category of snake
The goose falls into the category of
2024-07-28 05:59:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 06:02:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1755, -0.0403, -0.1371,  ...,  0.1143, -0.0231, -0.0485],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9956, -2.6016,  4.0859,  ..., -1.6680, -8.8438,  1.1396],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0387, -0.0102, -0.0246,  ...,  0.0098, -0.0125, -0.0015],
        [ 0.0042,  0.0153,  0.0035,  ...,  0.0343, -0.0154, -0.0133],
        [-0.0063,  0.0098,  0.0567,  ..., -0.0214, -0.0274, -0.0040],
        ...,
        [ 0.0275, -0.0027,  0.0005,  ...,  0.0207, -0.0125, -0.0128],
        [ 0.0134, -0.0102,  0.0116,  ...,  0.0065,  0.0689, -0.0111],
        [ 0.0236, -0.0303,  0.0161,  ..., -0.0278,  0.0140,  0.0347]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2256, -2.4707,  3.7930,  ..., -1.2842, -9.2969,  1.6172]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 06:02:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The mouse falls into the category of rodent
The gorilla falls into the category of primate
The bee falls into the category of insect
The squirrel falls into the category of rodent
The gibbon falls into the category of primate
The goat falls into the category of bovid
The cobra falls into the category of snake
The goose falls into the category of
2024-07-28 06:02:10 root INFO     [order_1_approx] starting weight calculation for The bee falls into the category of insect
The goat falls into the category of bovid
The squirrel falls into the category of rodent
The gorilla falls into the category of primate
The cobra falls into the category of snake
The mouse falls into the category of rodent
The goose falls into the category of fowl
The gibbon falls into the category of
2024-07-28 06:02:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 06:04:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3679, -0.4502,  0.1538,  ..., -0.1003, -0.4951,  0.1938],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5205, -2.8633,  0.9795,  ..., -3.6914, -6.5938,  0.8760],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0761,  0.0162, -0.0163,  ..., -0.0131,  0.0025,  0.0085],
        [ 0.0089,  0.0146,  0.0078,  ...,  0.0194,  0.0024, -0.0011],
        [ 0.0097,  0.0224,  0.0588,  ...,  0.0006, -0.0218, -0.0069],
        ...,
        [ 0.0263,  0.0207, -0.0013,  ...,  0.0442, -0.0138,  0.0031],
        [-0.0052, -0.0184, -0.0089,  ..., -0.0006,  0.0321, -0.0223],
        [-0.0109,  0.0122,  0.0027,  ...,  0.0238,  0.0052,  0.0419]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3574, -3.0684,  1.4727,  ..., -3.6445, -6.5391,  1.0420]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 06:04:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The bee falls into the category of insect
The goat falls into the category of bovid
The squirrel falls into the category of rodent
The gorilla falls into the category of primate
The cobra falls into the category of snake
The mouse falls into the category of rodent
The goose falls into the category of fowl
The gibbon falls into the category of
2024-07-28 06:04:47 root INFO     [order_1_approx] starting weight calculation for The goat falls into the category of bovid
The goose falls into the category of fowl
The mouse falls into the category of rodent
The gibbon falls into the category of primate
The cobra falls into the category of snake
The squirrel falls into the category of rodent
The bee falls into the category of insect
The gorilla falls into the category of
2024-07-28 06:04:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 06:07:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1833, -0.2578, -0.2798,  ..., -0.0118, -0.3369,  0.0621],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1982, -5.4883,  0.1006,  ..., -3.0859, -7.7852,  1.4775],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0254,  0.0017, -0.0071,  ..., -0.0017,  0.0048,  0.0303],
        [ 0.0275,  0.0026, -0.0090,  ..., -0.0043,  0.0294, -0.0053],
        [ 0.0043, -0.0007,  0.0352,  ..., -0.0352,  0.0017, -0.0193],
        ...,
        [-0.0201,  0.0033, -0.0174,  ...,  0.0315, -0.0077,  0.0042],
        [ 0.0195, -0.0276,  0.0223,  ...,  0.0129,  0.0362, -0.0010],
        [-0.0095, -0.0141, -0.0227,  ..., -0.0011,  0.0172,  0.0226]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8027, -5.2852,  0.2769,  ..., -3.0430, -7.7344,  1.6357]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 06:07:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The goat falls into the category of bovid
The goose falls into the category of fowl
The mouse falls into the category of rodent
The gibbon falls into the category of primate
The cobra falls into the category of snake
The squirrel falls into the category of rodent
The bee falls into the category of insect
The gorilla falls into the category of
2024-07-28 06:07:26 root INFO     [order_1_approx] starting weight calculation for The gorilla falls into the category of primate
The goose falls into the category of fowl
The mouse falls into the category of rodent
The gibbon falls into the category of primate
The cobra falls into the category of snake
The bee falls into the category of insect
The goat falls into the category of bovid
The squirrel falls into the category of
2024-07-28 06:07:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 06:10:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0115, -0.2423, -0.2277,  ..., -0.1477, -0.1760,  0.0052],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1375, -3.3125,  1.7383,  ..., -3.7617, -5.2227, -0.7656],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0051, -0.0062,  0.0079,  ..., -0.0003, -0.0128,  0.0033],
        [ 0.0081,  0.0123,  0.0250,  ...,  0.0084,  0.0088, -0.0069],
        [-0.0045,  0.0132, -0.0002,  ..., -0.0079, -0.0105, -0.0049],
        ...,
        [ 0.0142,  0.0197, -0.0051,  ...,  0.0185,  0.0103, -0.0029],
        [ 0.0049, -0.0106, -0.0099,  ..., -0.0119,  0.0266, -0.0163],
        [-0.0007, -0.0126,  0.0185,  ..., -0.0218,  0.0146,  0.0017]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2627, -3.1582,  1.5928,  ..., -3.9648, -5.2422, -0.5508]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 06:10:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The gorilla falls into the category of primate
The goose falls into the category of fowl
The mouse falls into the category of rodent
The gibbon falls into the category of primate
The cobra falls into the category of snake
The bee falls into the category of insect
The goat falls into the category of bovid
The squirrel falls into the category of
2024-07-28 06:10:09 root INFO     [order_1_approx] starting weight calculation for The goose falls into the category of fowl
The squirrel falls into the category of rodent
The bee falls into the category of insect
The gorilla falls into the category of primate
The gibbon falls into the category of primate
The mouse falls into the category of rodent
The cobra falls into the category of snake
The goat falls into the category of
2024-07-28 06:10:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 06:12:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0704, -0.2878, -0.1991,  ..., -0.0508, -0.1976,  0.1663],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7871, -4.5312,  2.3008,  ..., -0.7207, -6.8516, -1.0938],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0224,  0.0071, -0.0291,  ..., -0.0046,  0.0060, -0.0083],
        [-0.0204,  0.0452,  0.0181,  ...,  0.0077,  0.0320, -0.0035],
        [ 0.0216, -0.0055,  0.0217,  ..., -0.0275, -0.0177,  0.0101],
        ...,
        [ 0.0042,  0.0153, -0.0031,  ...,  0.0348, -0.0126, -0.0112],
        [-0.0103, -0.0116,  0.0166,  ..., -0.0135,  0.0385,  0.0167],
        [ 0.0083, -0.0052,  0.0072,  ..., -0.0108,  0.0071,  0.0491]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4885, -4.2891,  2.0547,  ..., -0.7197, -7.2070, -0.9570]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 06:12:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The goose falls into the category of fowl
The squirrel falls into the category of rodent
The bee falls into the category of insect
The gorilla falls into the category of primate
The gibbon falls into the category of primate
The mouse falls into the category of rodent
The cobra falls into the category of snake
The goat falls into the category of
2024-07-28 06:12:54 root INFO     total operator prediction time: 1306.2503173351288 seconds
2024-07-28 06:12:54 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hyponyms - misc
2024-07-28 06:12:54 root INFO     building operator hyponyms - misc
2024-07-28 06:12:54 root INFO     [order_1_approx] starting weight calculation for A more specific term for a container is bag
A more specific term for a computer is laptop
A more specific term for a gun is rifle
A more specific term for a emotion is anger
A more specific term for a dress is gown
A more specific term for a boat is ferry
A more specific term for a camera is camcorder
A more specific term for a sweater is
2024-07-28 06:12:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 06:15:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0587, -0.2158,  0.1162,  ...,  0.1626, -0.2888,  0.0068],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7939, -5.1562, -0.3877,  ...,  0.5649, -3.0918,  2.1875],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0403,  0.0087, -0.0151,  ...,  0.0358,  0.0269,  0.0262],
        [-0.0164,  0.0430,  0.0166,  ...,  0.0069, -0.0049,  0.0039],
        [ 0.0074, -0.0223,  0.0459,  ...,  0.0212, -0.0038,  0.0032],
        ...,
        [ 0.0376,  0.0340, -0.0262,  ...,  0.0526,  0.0155, -0.0091],
        [ 0.0007,  0.0136,  0.0179,  ...,  0.0102,  0.0452, -0.0246],
        [-0.0227, -0.0052,  0.0008,  ..., -0.0134,  0.0067,  0.0157]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1475, -4.7578, -0.2988,  ...,  0.1763, -2.9434,  2.1973]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 06:15:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a container is bag
A more specific term for a computer is laptop
A more specific term for a gun is rifle
A more specific term for a emotion is anger
A more specific term for a dress is gown
A more specific term for a boat is ferry
A more specific term for a camera is camcorder
A more specific term for a sweater is
2024-07-28 06:15:37 root INFO     [order_1_approx] starting weight calculation for A more specific term for a sweater is turtleneck
A more specific term for a emotion is anger
A more specific term for a boat is ferry
A more specific term for a container is bag
A more specific term for a gun is rifle
A more specific term for a camera is camcorder
A more specific term for a computer is laptop
A more specific term for a dress is
2024-07-28 06:15:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 06:18:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0742, -0.1796, -0.0961,  ...,  0.1648, -0.2051, -0.0171],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2583, -4.3906, -1.8594,  ...,  1.5732, -2.6484,  2.3203],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0296, -0.0641,  0.0346,  ..., -0.0433,  0.0490,  0.0047],
        [ 0.0103,  0.0331,  0.0305,  ...,  0.0060, -0.0230, -0.0060],
        [ 0.0251, -0.0366,  0.0844,  ..., -0.0105, -0.0337,  0.0026],
        ...,
        [-0.0057,  0.0102, -0.0178,  ...,  0.0061,  0.0262, -0.0131],
        [ 0.0280,  0.0044, -0.0137,  ...,  0.0058,  0.0372, -0.0063],
        [ 0.0098, -0.0002,  0.0042,  ...,  0.0090,  0.0069,  0.0019]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1053, -3.8652, -1.7002,  ...,  1.7559, -2.8945,  2.6113]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 06:18:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a sweater is turtleneck
A more specific term for a emotion is anger
A more specific term for a boat is ferry
A more specific term for a container is bag
A more specific term for a gun is rifle
A more specific term for a camera is camcorder
A more specific term for a computer is laptop
A more specific term for a dress is
2024-07-28 06:18:19 root INFO     [order_1_approx] starting weight calculation for A more specific term for a boat is ferry
A more specific term for a dress is gown
A more specific term for a emotion is anger
A more specific term for a sweater is turtleneck
A more specific term for a container is bag
A more specific term for a computer is laptop
A more specific term for a gun is rifle
A more specific term for a camera is
2024-07-28 06:18:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 06:21:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1454, -0.0199, -0.0366,  ..., -0.1409, -0.1215, -0.3237],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.1104, -3.1094,  0.6919,  ..., -0.7676,  1.3076, -1.6445],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.7206e-02, -1.6693e-02, -2.5070e-02,  ..., -2.2781e-02,
         -1.5160e-02,  9.5978e-03],
        [-4.0398e-03,  3.2104e-02,  6.5994e-03,  ..., -1.3565e-02,
          4.4556e-03, -2.2182e-03],
        [ 2.6474e-03,  3.0426e-02,  4.4250e-02,  ..., -1.7365e-02,
          1.3344e-02,  1.2711e-02],
        ...,
        [ 1.3489e-02, -2.2018e-02,  3.1891e-03,  ...,  5.5908e-02,
          1.2070e-02, -4.1275e-03],
        [-1.9043e-02, -1.4458e-02, -1.1932e-02,  ..., -1.6052e-02,
          5.4596e-02, -3.6621e-02],
        [-1.0519e-03,  2.7695e-03, -1.2489e-02,  ..., -6.4850e-05,
         -1.7410e-02,  4.9316e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3887, -2.5703,  0.6553,  ..., -0.8062,  1.6299, -1.2881]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 06:21:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a boat is ferry
A more specific term for a dress is gown
A more specific term for a emotion is anger
A more specific term for a sweater is turtleneck
A more specific term for a container is bag
A more specific term for a computer is laptop
A more specific term for a gun is rifle
A more specific term for a camera is
2024-07-28 06:21:02 root INFO     [order_1_approx] starting weight calculation for A more specific term for a gun is rifle
A more specific term for a camera is camcorder
A more specific term for a computer is laptop
A more specific term for a emotion is anger
A more specific term for a dress is gown
A more specific term for a sweater is turtleneck
A more specific term for a boat is ferry
A more specific term for a container is
2024-07-28 06:21:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 06:23:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3538, -0.1120, -0.0203,  ..., -0.0707, -0.1153, -0.1410],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.3438, -4.7344, -1.1631,  ...,  0.8730,  1.4180, -0.0654],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0328, -0.0215,  0.0105,  ...,  0.0204, -0.0288,  0.0126],
        [-0.0081, -0.0003,  0.0011,  ..., -0.0028, -0.0118,  0.0048],
        [ 0.0012, -0.0018,  0.0413,  ...,  0.0187, -0.0004,  0.0106],
        ...,
        [ 0.0272,  0.0178, -0.0039,  ...,  0.0316, -0.0156,  0.0111],
        [-0.0108,  0.0091, -0.0079,  ..., -0.0208,  0.0357,  0.0167],
        [ 0.0033,  0.0070, -0.0022,  ..., -0.0053, -0.0075,  0.0535]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7402, -4.5352, -0.9653,  ...,  0.8398,  1.3652,  0.3562]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 06:23:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a gun is rifle
A more specific term for a camera is camcorder
A more specific term for a computer is laptop
A more specific term for a emotion is anger
A more specific term for a dress is gown
A more specific term for a sweater is turtleneck
A more specific term for a boat is ferry
A more specific term for a container is
2024-07-28 06:23:45 root INFO     [order_1_approx] starting weight calculation for A more specific term for a computer is laptop
A more specific term for a container is bag
A more specific term for a sweater is turtleneck
A more specific term for a camera is camcorder
A more specific term for a dress is gown
A more specific term for a gun is rifle
A more specific term for a boat is ferry
A more specific term for a emotion is
2024-07-28 06:23:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 06:26:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.4077,  0.1077, -0.0048,  ...,  0.0497, -0.1771,  0.0194],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.2383, -3.3867,  1.1621,  ...,  1.0518, -1.6094, -1.3809],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.7924e-02,  1.5823e-02,  2.1553e-03,  ...,  5.6038e-03,
         -1.9455e-02, -5.5313e-03],
        [-2.1469e-02,  2.0218e-02, -5.7564e-03,  ...,  6.2637e-03,
          8.7433e-03,  2.1301e-02],
        [-2.6413e-02, -1.6846e-02,  2.3941e-02,  ..., -3.4714e-04,
         -2.9465e-02, -3.3813e-02],
        ...,
        [-9.4509e-04,  6.1035e-05, -6.6757e-03,  ...,  2.2583e-02,
         -5.5351e-03, -1.5762e-02],
        [-2.9419e-02, -1.6113e-02, -1.9608e-02,  ..., -8.7967e-03,
          1.3634e-02,  5.7755e-03],
        [ 8.1177e-03, -1.7099e-03, -4.4136e-03,  ..., -9.7580e-03,
         -3.2215e-03, -8.5754e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5273, -3.5742,  1.0195,  ...,  1.2539, -1.9219, -1.2070]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 06:26:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a computer is laptop
A more specific term for a container is bag
A more specific term for a sweater is turtleneck
A more specific term for a camera is camcorder
A more specific term for a dress is gown
A more specific term for a gun is rifle
A more specific term for a boat is ferry
A more specific term for a emotion is
2024-07-28 06:26:28 root INFO     [order_1_approx] starting weight calculation for A more specific term for a container is bag
A more specific term for a sweater is turtleneck
A more specific term for a dress is gown
A more specific term for a camera is camcorder
A more specific term for a gun is rifle
A more specific term for a emotion is anger
A more specific term for a boat is ferry
A more specific term for a computer is
2024-07-28 06:26:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 06:29:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1501, -0.1694,  0.1465,  ...,  0.1168, -0.2236,  0.0320],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0605, -2.9844,  0.3374,  ..., -1.2324, -1.1680, -0.3125],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0401, -0.0157, -0.0102,  ..., -0.0108,  0.0156,  0.0541],
        [ 0.0053,  0.0103,  0.0288,  ...,  0.0171, -0.0185, -0.0207],
        [ 0.0125,  0.0113,  0.0450,  ..., -0.0079,  0.0115,  0.0231],
        ...,
        [-0.0027,  0.0156, -0.0357,  ...,  0.0246,  0.0202, -0.0193],
        [-0.0092, -0.0098, -0.0101,  ..., -0.0123,  0.0233, -0.0138],
        [ 0.0146, -0.0085, -0.0145,  ...,  0.0025, -0.0132,  0.0304]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8481, -2.5703,  0.2925,  ..., -1.0020, -0.8643,  0.1545]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 06:29:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a container is bag
A more specific term for a sweater is turtleneck
A more specific term for a dress is gown
A more specific term for a camera is camcorder
A more specific term for a gun is rifle
A more specific term for a emotion is anger
A more specific term for a boat is ferry
A more specific term for a computer is
2024-07-28 06:29:10 root INFO     [order_1_approx] starting weight calculation for A more specific term for a computer is laptop
A more specific term for a emotion is anger
A more specific term for a dress is gown
A more specific term for a sweater is turtleneck
A more specific term for a camera is camcorder
A more specific term for a gun is rifle
A more specific term for a container is bag
A more specific term for a boat is
2024-07-28 06:29:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 06:31:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0937,  0.0635,  0.0924,  ..., -0.1464, -0.1938,  0.1523],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7739, -5.4961,  0.5747,  ...,  1.1689,  0.0933,  0.9570],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.1931e-02,  6.5041e-03,  2.4185e-03,  ...,  6.8398e-03,
          3.4973e-02,  2.1530e-02],
        [ 7.8888e-03,  4.0344e-02, -1.3084e-02,  ...,  2.8725e-03,
          7.9117e-03,  1.5182e-03],
        [-2.0847e-03,  6.6261e-03,  5.6183e-02,  ...,  3.6240e-05,
         -4.3449e-03,  1.3969e-02],
        ...,
        [ 9.3994e-03,  2.3407e-02,  2.4414e-03,  ...,  4.3793e-02,
          1.9669e-02, -1.9043e-02],
        [ 1.8616e-03, -4.8523e-03,  7.2098e-03,  ..., -2.0340e-02,
          2.2079e-02, -2.7161e-03],
        [-3.8605e-03, -2.3499e-02, -1.0513e-02,  ..., -4.2343e-03,
         -2.3178e-02,  4.4189e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6240, -5.0781,  0.7529,  ...,  1.3008,  0.1956,  1.5830]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 06:31:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a computer is laptop
A more specific term for a emotion is anger
A more specific term for a dress is gown
A more specific term for a sweater is turtleneck
A more specific term for a camera is camcorder
A more specific term for a gun is rifle
A more specific term for a container is bag
A more specific term for a boat is
2024-07-28 06:31:52 root INFO     [order_1_approx] starting weight calculation for A more specific term for a emotion is anger
A more specific term for a boat is ferry
A more specific term for a container is bag
A more specific term for a camera is camcorder
A more specific term for a computer is laptop
A more specific term for a dress is gown
A more specific term for a sweater is turtleneck
A more specific term for a gun is
2024-07-28 06:31:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 06:34:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2935,  0.1614,  0.0113,  ..., -0.1864, -0.1488, -0.1432],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9414, -5.3789,  0.0684,  ..., -0.9521, -1.3271, -0.3613],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0232, -0.0012, -0.0104,  ...,  0.0092,  0.0329, -0.0087],
        [-0.0179,  0.0253, -0.0194,  ...,  0.0140, -0.0009, -0.0235],
        [ 0.0115,  0.0123,  0.0374,  ...,  0.0123,  0.0133,  0.0068],
        ...,
        [ 0.0076,  0.0037, -0.0364,  ...,  0.0330, -0.0153,  0.0191],
        [-0.0131,  0.0090, -0.0267,  ...,  0.0345,  0.0263, -0.0169],
        [ 0.0206, -0.0113,  0.0040,  ..., -0.0219, -0.0220,  0.0474]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8188, -4.5391,  0.1272,  ..., -0.2539, -0.9805,  0.1792]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 06:34:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a emotion is anger
A more specific term for a boat is ferry
A more specific term for a container is bag
A more specific term for a camera is camcorder
A more specific term for a computer is laptop
A more specific term for a dress is gown
A more specific term for a sweater is turtleneck
A more specific term for a gun is
2024-07-28 06:34:37 root INFO     total operator prediction time: 1303.5542299747467 seconds
2024-07-28 06:34:37 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on antonyms - binary
2024-07-28 06:34:37 root INFO     building operator antonyms - binary
2024-07-28 06:34:38 root INFO     [order_1_approx] starting weight calculation for The opposite of front is back
The opposite of out is in
The opposite of beginning is end
The opposite of proceed is retreat
The opposite of inside is outside
The opposite of ahead is behind
The opposite of first is last
The opposite of mortal is
2024-07-28 06:34:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 06:37:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1982, -0.1235, -0.0248,  ..., -0.3806, -0.3262,  0.2274],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2598, -2.5254, -0.3569,  ..., -2.9492, -2.8125, -4.2539],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0145,  0.0110,  0.0316,  ..., -0.0063, -0.0155, -0.0037],
        [ 0.0028,  0.0091, -0.0026,  ...,  0.0212, -0.0057, -0.0168],
        [ 0.0188, -0.0383,  0.0196,  ..., -0.0164, -0.0253, -0.0064],
        ...,
        [ 0.0404, -0.0053,  0.0125,  ..., -0.0323,  0.0020,  0.0084],
        [ 0.0126, -0.0345,  0.0129,  ...,  0.0107, -0.0066,  0.0103],
        [ 0.0336, -0.0233, -0.0173,  ...,  0.0104,  0.0034,  0.0213]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6953, -2.3711, -0.6416,  ..., -2.9531, -3.1875, -4.0547]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 06:37:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of front is back
The opposite of out is in
The opposite of beginning is end
The opposite of proceed is retreat
The opposite of inside is outside
The opposite of ahead is behind
The opposite of first is last
The opposite of mortal is
2024-07-28 06:37:23 root INFO     [order_1_approx] starting weight calculation for The opposite of first is last
The opposite of inside is outside
The opposite of mortal is immortal
The opposite of ahead is behind
The opposite of front is back
The opposite of out is in
The opposite of proceed is retreat
The opposite of beginning is
2024-07-28 06:37:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 06:40:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0738, -0.0281, -0.0262,  ..., -0.0479, -0.3113,  0.0328],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3887, -3.1484, -1.3125,  ...,  0.8076, -0.8672, -2.1504],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0223, -0.0203, -0.0429,  ...,  0.0252,  0.0120,  0.0184],
        [-0.0015,  0.0303,  0.0271,  ...,  0.0067, -0.0024,  0.0032],
        [-0.0061, -0.0171,  0.0114,  ...,  0.0005, -0.0049, -0.0075],
        ...,
        [ 0.0292,  0.0188,  0.0262,  ...,  0.0123, -0.0545, -0.0161],
        [ 0.0123,  0.0164,  0.0211,  ...,  0.0022,  0.0657,  0.0013],
        [-0.0038, -0.0018, -0.0027,  ...,  0.0190,  0.0096,  0.0435]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2402, -3.1719, -1.1709,  ...,  0.9082, -0.5181, -1.9297]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 06:40:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of first is last
The opposite of inside is outside
The opposite of mortal is immortal
The opposite of ahead is behind
The opposite of front is back
The opposite of out is in
The opposite of proceed is retreat
The opposite of beginning is
2024-07-28 06:40:07 root INFO     [order_1_approx] starting weight calculation for The opposite of out is in
The opposite of mortal is immortal
The opposite of beginning is end
The opposite of front is back
The opposite of first is last
The opposite of proceed is retreat
The opposite of inside is outside
The opposite of ahead is
2024-07-28 06:40:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 06:42:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2122, -0.0751, -0.0568,  ...,  0.0357, -0.1980,  0.1444],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9434, -3.2617,  0.9775,  ..., -4.2188, -0.7627, -3.0156],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0508, -0.0375, -0.0502,  ...,  0.0116,  0.0126,  0.0488],
        [-0.0337,  0.0756,  0.0443,  ...,  0.0034,  0.0269, -0.0253],
        [-0.0102, -0.0140, -0.0273,  ...,  0.0221, -0.0535,  0.0373],
        ...,
        [ 0.0009,  0.0085, -0.0298,  ..., -0.0246,  0.0597, -0.0360],
        [ 0.0133, -0.0050,  0.0158,  ...,  0.0447,  0.0926, -0.0546],
        [-0.0017, -0.0106,  0.0126,  ...,  0.0119,  0.0090,  0.0053]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7939, -3.0586,  0.9956,  ..., -3.3789, -0.7988, -2.5664]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 06:42:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of out is in
The opposite of mortal is immortal
The opposite of beginning is end
The opposite of front is back
The opposite of first is last
The opposite of proceed is retreat
The opposite of inside is outside
The opposite of ahead is
2024-07-28 06:42:52 root INFO     [order_1_approx] starting weight calculation for The opposite of first is last
The opposite of beginning is end
The opposite of inside is outside
The opposite of mortal is immortal
The opposite of ahead is behind
The opposite of proceed is retreat
The opposite of out is in
The opposite of front is
2024-07-28 06:42:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 06:45:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1056, -0.1067, -0.0801,  ..., -0.0439, -0.0052,  0.1163],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0273, -2.7031,  1.5127,  ..., -1.0859, -0.2109, -0.9673],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0073, -0.0068, -0.0135,  ...,  0.0237,  0.0137,  0.0149],
        [ 0.0458,  0.0301,  0.0312,  ..., -0.0114,  0.0015, -0.0080],
        [ 0.0143, -0.0261, -0.0177,  ...,  0.0290, -0.0223,  0.0346],
        ...,
        [ 0.0140,  0.0103,  0.0170,  ...,  0.0167,  0.0210,  0.0096],
        [ 0.0145,  0.0079, -0.0058,  ..., -0.0058,  0.0681,  0.0013],
        [ 0.0007, -0.0048, -0.0159,  ...,  0.0146,  0.0403,  0.0453]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.2607, -2.6406,  1.4902,  ..., -0.8296, -0.3826, -0.8125]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 06:45:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of first is last
The opposite of beginning is end
The opposite of inside is outside
The opposite of mortal is immortal
The opposite of ahead is behind
The opposite of proceed is retreat
The opposite of out is in
The opposite of front is
2024-07-28 06:45:36 root INFO     [order_1_approx] starting weight calculation for The opposite of mortal is immortal
The opposite of beginning is end
The opposite of inside is outside
The opposite of proceed is retreat
The opposite of front is back
The opposite of ahead is behind
The opposite of first is last
The opposite of out is
2024-07-28 06:45:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 06:48:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1503, -0.0447,  0.0690,  ..., -0.0560, -0.0851,  0.0701],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9023, -3.6797,  1.2930,  ..., -1.1953, -0.9336, -3.6445],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0132,  0.0220, -0.0280,  ...,  0.0361,  0.0801,  0.0164],
        [ 0.0089, -0.0041, -0.0232,  ...,  0.0417,  0.0249,  0.0068],
        [-0.0361, -0.0823, -0.0514,  ...,  0.0230, -0.0258,  0.0416],
        ...,
        [ 0.0244, -0.0162, -0.0092,  ..., -0.0124,  0.0447, -0.0632],
        [ 0.0648, -0.0116,  0.0094,  ...,  0.0645,  0.0015, -0.0066],
        [ 0.0275,  0.0113,  0.0178,  ...,  0.0241,  0.0215,  0.0100]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9663, -4.0508,  0.5508,  ..., -1.6543, -0.0254, -3.2891]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 06:48:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of mortal is immortal
The opposite of beginning is end
The opposite of inside is outside
The opposite of proceed is retreat
The opposite of front is back
The opposite of ahead is behind
The opposite of first is last
The opposite of out is
2024-07-28 06:48:21 root INFO     [order_1_approx] starting weight calculation for The opposite of front is back
The opposite of beginning is end
The opposite of inside is outside
The opposite of out is in
The opposite of proceed is retreat
The opposite of ahead is behind
The opposite of mortal is immortal
The opposite of first is
2024-07-28 06:48:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 06:51:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0188, -0.0415, -0.1058,  ..., -0.2871, -0.1233,  0.0743],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9805, -2.2891, -0.5195,  ..., -0.3384, -0.8560, -3.1855],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-5.2414e-03, -4.2877e-02, -4.0398e-03,  ...,  8.4991e-03,
          3.6346e-02, -2.8412e-02],
        [ 2.0493e-02,  3.4729e-02, -2.3590e-02,  ...,  8.8501e-03,
         -1.9531e-02,  2.7084e-02],
        [ 1.7395e-02, -3.5034e-02, -1.7349e-02,  ...,  3.8574e-02,
          4.4861e-03,  1.6846e-02],
        ...,
        [ 3.0243e-02,  2.1881e-02, -1.2993e-02,  ...,  1.5625e-02,
          1.5839e-02,  1.0185e-02],
        [ 2.7161e-02,  4.3488e-04,  3.8147e-05,  ...,  2.2369e-02,
          3.6987e-02, -2.4643e-02],
        [ 1.9165e-02, -2.3529e-02, -2.0508e-02,  ...,  1.4328e-02,
          1.8448e-02,  4.5105e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5410, -2.4629, -0.3271,  ...,  0.1226, -0.7090, -3.4258]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 06:51:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of front is back
The opposite of beginning is end
The opposite of inside is outside
The opposite of out is in
The opposite of proceed is retreat
The opposite of ahead is behind
The opposite of mortal is immortal
The opposite of first is
2024-07-28 06:51:06 root INFO     [order_1_approx] starting weight calculation for The opposite of inside is outside
The opposite of ahead is behind
The opposite of first is last
The opposite of beginning is end
The opposite of front is back
The opposite of mortal is immortal
The opposite of out is in
The opposite of proceed is
2024-07-28 06:51:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 06:53:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2976, -0.2739, -0.1909,  ..., -0.1113, -0.4585,  0.4563],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2148, -4.0664,  1.9512,  ...,  1.2148, -3.5762, -3.6172],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0115, -0.0313, -0.0231,  ...,  0.0586,  0.0558, -0.0058],
        [-0.0404,  0.0190, -0.0069,  ...,  0.0830,  0.0332,  0.0085],
        [-0.0417,  0.0199,  0.0042,  ..., -0.0196,  0.0238, -0.0227],
        ...,
        [-0.0043,  0.0305, -0.0029,  ...,  0.0573,  0.0225, -0.0373],
        [ 0.0170, -0.0139,  0.0211,  ..., -0.0325,  0.0348, -0.0008],
        [ 0.0318, -0.0026, -0.0181,  ...,  0.0507, -0.0020,  0.0432]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6660, -4.2656,  1.6748,  ...,  0.7490, -3.6074, -3.5293]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 06:53:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of inside is outside
The opposite of ahead is behind
The opposite of first is last
The opposite of beginning is end
The opposite of front is back
The opposite of mortal is immortal
The opposite of out is in
The opposite of proceed is
2024-07-28 06:53:51 root INFO     [order_1_approx] starting weight calculation for The opposite of first is last
The opposite of beginning is end
The opposite of proceed is retreat
The opposite of out is in
The opposite of ahead is behind
The opposite of mortal is immortal
The opposite of front is back
The opposite of inside is
2024-07-28 06:53:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 06:56:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0210, -0.3118,  0.0283,  ..., -0.1857,  0.0764,  0.1107],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6914, -3.4277,  2.7695,  ..., -1.2891,  3.4785, -1.7871],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0226,  0.0111, -0.0501,  ..., -0.0073,  0.0726,  0.0151],
        [ 0.0069,  0.0029,  0.0088,  ...,  0.0412, -0.0200,  0.0029],
        [-0.0395, -0.0177,  0.0043,  ...,  0.0130,  0.0257,  0.0329],
        ...,
        [ 0.0227,  0.0264,  0.0049,  ...,  0.0044,  0.0014, -0.0052],
        [-0.0109, -0.0261,  0.0177,  ..., -0.0133,  0.0352,  0.0065],
        [ 0.0171, -0.0098, -0.0080,  ...,  0.0455,  0.0098,  0.0526]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0645, -3.5938,  2.8223,  ..., -1.3281,  3.1602, -1.4600]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 06:56:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of first is last
The opposite of beginning is end
The opposite of proceed is retreat
The opposite of out is in
The opposite of ahead is behind
The opposite of mortal is immortal
The opposite of front is back
The opposite of inside is
2024-07-28 06:56:36 root INFO     total operator prediction time: 1318.8194029331207 seconds
2024-07-28 06:56:36 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - member
2024-07-28 06:56:36 root INFO     building operator meronyms - member
2024-07-28 06:56:36 root INFO     [order_1_approx] starting weight calculation for A parishioner is a member of a parish
A page is a member of a book
A state is a member of a country
A photo is a member of a album
A college is a member of a university
A listener is a member of a audience
A cat is a member of a clowder
A book is a member of a
2024-07-28 06:56:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 06:59:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0580, -0.0851, -0.1864,  ..., -0.0033, -0.0878, -0.2676],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7695, -4.4023,  0.4185,  ..., -0.8271, -2.4648, -3.4805],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0225, -0.0067, -0.0040,  ...,  0.0054, -0.0019,  0.0530],
        [-0.0024,  0.0320,  0.0350,  ...,  0.0002,  0.0246, -0.0042],
        [ 0.0031, -0.0179,  0.0205,  ..., -0.0296,  0.0031,  0.0268],
        ...,
        [ 0.0114, -0.0032, -0.0105,  ...,  0.0334, -0.0067, -0.0328],
        [-0.0021, -0.0049, -0.0075,  ..., -0.0079,  0.0138, -0.0037],
        [ 0.0246,  0.0146,  0.0236,  ..., -0.0272, -0.0127,  0.0186]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0938, -3.8398,  0.6641,  ..., -0.6919, -2.7695, -2.2344]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 06:59:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A parishioner is a member of a parish
A page is a member of a book
A state is a member of a country
A photo is a member of a album
A college is a member of a university
A listener is a member of a audience
A cat is a member of a clowder
A book is a member of a
2024-07-28 06:59:24 root INFO     [order_1_approx] starting weight calculation for A photo is a member of a album
A college is a member of a university
A listener is a member of a audience
A page is a member of a book
A state is a member of a country
A cat is a member of a clowder
A book is a member of a library
A parishioner is a member of a
2024-07-28 06:59:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 07:02:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0980,  0.0629, -0.4314,  ...,  0.1098, -0.1350,  0.0583],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1426, -5.8594,  4.2852,  ..., -2.6758,  1.4629, -0.0918],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0111, -0.0096, -0.0161,  ...,  0.0204,  0.0080, -0.0025],
        [ 0.0119,  0.0034,  0.0264,  ...,  0.0033, -0.0113,  0.0050],
        [-0.0040, -0.0117,  0.0005,  ..., -0.0043,  0.0018, -0.0023],
        ...,
        [ 0.0203,  0.0093,  0.0126,  ...,  0.0105, -0.0183,  0.0026],
        [-0.0182,  0.0009, -0.0293,  ..., -0.0084,  0.0157, -0.0244],
        [ 0.0019, -0.0114,  0.0070,  ..., -0.0021, -0.0096,  0.0330]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3105, -5.4180,  4.3008,  ..., -2.6211,  1.2021,  0.2827]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 07:02:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A photo is a member of a album
A college is a member of a university
A listener is a member of a audience
A page is a member of a book
A state is a member of a country
A cat is a member of a clowder
A book is a member of a library
A parishioner is a member of a
2024-07-28 07:02:10 root INFO     [order_1_approx] starting weight calculation for A parishioner is a member of a parish
A photo is a member of a album
A page is a member of a book
A book is a member of a library
A college is a member of a university
A state is a member of a country
A cat is a member of a clowder
A listener is a member of a
2024-07-28 07:02:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 07:04:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0067, -0.0616, -0.2729,  ...,  0.1890,  0.2649, -0.0363],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0996, -4.3477,  3.0254,  ...,  1.8203, -2.8965, -2.1426],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0716, -0.0433,  0.0161,  ...,  0.0370, -0.0157,  0.0407],
        [-0.0298,  0.0365,  0.0551,  ...,  0.0109, -0.0100, -0.0660],
        [ 0.0051, -0.0379,  0.0180,  ...,  0.0038, -0.0199,  0.0324],
        ...,
        [ 0.0023,  0.0437,  0.0211,  ...,  0.0482,  0.0123, -0.0007],
        [ 0.0060,  0.0111, -0.0382,  ..., -0.0200,  0.0136,  0.0224],
        [ 0.0110,  0.0016, -0.0371,  ...,  0.0068,  0.0155,  0.0430]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2490, -3.6660,  3.4395,  ...,  1.2441, -2.5645, -1.6270]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 07:04:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A parishioner is a member of a parish
A photo is a member of a album
A page is a member of a book
A book is a member of a library
A college is a member of a university
A state is a member of a country
A cat is a member of a clowder
A listener is a member of a
2024-07-28 07:04:56 root INFO     [order_1_approx] starting weight calculation for A college is a member of a university
A listener is a member of a audience
A parishioner is a member of a parish
A book is a member of a library
A cat is a member of a clowder
A page is a member of a book
A state is a member of a country
A photo is a member of a
2024-07-28 07:04:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 07:07:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2576, -0.0006, -0.0909,  ..., -0.1203, -0.1565, -0.1298],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9883, -0.2656,  3.3047,  ..., -2.5020, -0.0464,  0.0186],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0363, -0.0212,  0.0199,  ...,  0.0124,  0.0034,  0.0155],
        [-0.0348,  0.0683,  0.0030,  ...,  0.0635, -0.0333, -0.0141],
        [ 0.0215, -0.0015,  0.0325,  ..., -0.0062,  0.0042,  0.0273],
        ...,
        [ 0.0473, -0.0343,  0.0170,  ...,  0.0384, -0.0467, -0.0276],
        [-0.0027,  0.0229, -0.0343,  ..., -0.0321,  0.0119, -0.0080],
        [-0.0222,  0.0071, -0.0009,  ..., -0.0113,  0.0130,  0.0184]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2705, -0.3857,  3.5332,  ..., -1.5449, -0.2559, -0.1216]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 07:07:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A college is a member of a university
A listener is a member of a audience
A parishioner is a member of a parish
A book is a member of a library
A cat is a member of a clowder
A page is a member of a book
A state is a member of a country
A photo is a member of a
2024-07-28 07:07:42 root INFO     [order_1_approx] starting weight calculation for A book is a member of a library
A parishioner is a member of a parish
A listener is a member of a audience
A cat is a member of a clowder
A state is a member of a country
A photo is a member of a album
A college is a member of a university
A page is a member of a
2024-07-28 07:07:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 07:10:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1180,  0.1467, -0.0960,  ..., -0.0118, -0.3813, -0.0573],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5234, -1.9395,  1.7041,  ..., -1.4160, -1.7715, -0.7373],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0724, -0.0378,  0.0341,  ...,  0.0018,  0.0089,  0.0267],
        [-0.0206,  0.0992,  0.0191,  ...,  0.0026, -0.0326, -0.0321],
        [ 0.0193,  0.0022,  0.0458,  ...,  0.0140, -0.0296, -0.0026],
        ...,
        [ 0.0418,  0.0392,  0.0223,  ...,  0.0617, -0.0135, -0.0620],
        [ 0.0109,  0.0133, -0.0099,  ..., -0.0255,  0.0475, -0.0434],
        [-0.0324,  0.0342,  0.0242,  ..., -0.0261, -0.0109,  0.0140]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1875, -1.4219,  1.3135,  ..., -1.3154, -1.5039, -0.2285]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 07:10:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A book is a member of a library
A parishioner is a member of a parish
A listener is a member of a audience
A cat is a member of a clowder
A state is a member of a country
A photo is a member of a album
A college is a member of a university
A page is a member of a
2024-07-28 07:10:26 root INFO     [order_1_approx] starting weight calculation for A cat is a member of a clowder
A listener is a member of a audience
A parishioner is a member of a parish
A college is a member of a university
A book is a member of a library
A page is a member of a book
A photo is a member of a album
A state is a member of a
2024-07-28 07:10:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 07:13:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0012,  0.1462, -0.2512,  ..., -0.0756,  0.2408,  0.0485],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1216, -4.4297,  3.7676,  ..., -3.8711,  2.6074, -3.5508],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0350, -0.0487, -0.0069,  ..., -0.0273, -0.0148,  0.0003],
        [-0.0258,  0.0410, -0.0068,  ...,  0.0311,  0.0162, -0.0125],
        [ 0.0078,  0.0047, -0.0050,  ...,  0.0061, -0.0260,  0.0161],
        ...,
        [-0.0018,  0.0381, -0.0102,  ...,  0.0298,  0.0188, -0.0213],
        [ 0.0257,  0.0112, -0.0171,  ...,  0.0115,  0.0197, -0.0019],
        [-0.0129, -0.0377,  0.0021,  ..., -0.0270, -0.0025,  0.0211]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1489, -4.3945,  3.7129,  ..., -3.9160,  2.3398, -2.7520]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 07:13:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A cat is a member of a clowder
A listener is a member of a audience
A parishioner is a member of a parish
A college is a member of a university
A book is a member of a library
A page is a member of a book
A photo is a member of a album
A state is a member of a
2024-07-28 07:13:11 root INFO     [order_1_approx] starting weight calculation for A cat is a member of a clowder
A listener is a member of a audience
A photo is a member of a album
A state is a member of a country
A book is a member of a library
A parishioner is a member of a parish
A page is a member of a book
A college is a member of a
2024-07-28 07:13:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 07:15:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0324,  0.1050, -0.2253,  ...,  0.0784, -0.1207,  0.0035],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4375, -4.4297,  3.7539,  ..., -1.7168,  1.2910, -0.7227],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1234, -0.0585, -0.0068,  ..., -0.0220, -0.0248,  0.0110],
        [-0.0053,  0.0202,  0.0187,  ..., -0.0121, -0.0357, -0.0270],
        [-0.0045, -0.0082,  0.0704,  ..., -0.0381, -0.0192,  0.0149],
        ...,
        [ 0.0307,  0.0233, -0.0329,  ...,  0.0433,  0.0115, -0.0494],
        [ 0.0057, -0.0056, -0.0065,  ..., -0.0114,  0.0397,  0.0010],
        [ 0.0054, -0.0463, -0.0226,  ..., -0.0116, -0.0051,  0.0348]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3647, -3.6172,  3.9492,  ..., -1.9014,  1.4434, -0.1660]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 07:15:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A cat is a member of a clowder
A listener is a member of a audience
A photo is a member of a album
A state is a member of a country
A book is a member of a library
A parishioner is a member of a parish
A page is a member of a book
A college is a member of a
2024-07-28 07:15:54 root INFO     [order_1_approx] starting weight calculation for A state is a member of a country
A listener is a member of a audience
A parishioner is a member of a parish
A book is a member of a library
A photo is a member of a album
A page is a member of a book
A college is a member of a university
A cat is a member of a
2024-07-28 07:15:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 07:18:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2432, -0.0527,  0.1063,  ..., -0.0576,  0.1331,  0.0371],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2773, -3.8887,  3.3105,  ..., -2.4551, -0.3633, -0.8203],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0495, -0.0165, -0.0205,  ..., -0.0076, -0.0219,  0.0143],
        [-0.0188,  0.0456,  0.0375,  ...,  0.0229,  0.0194,  0.0032],
        [ 0.0060, -0.0216,  0.0443,  ..., -0.0114,  0.0105,  0.0039],
        ...,
        [ 0.0083, -0.0069,  0.0087,  ...,  0.0483,  0.0046, -0.0099],
        [ 0.0578,  0.0367,  0.0045,  ...,  0.0285,  0.0104, -0.0196],
        [-0.0063, -0.0327,  0.0013,  ..., -0.0465,  0.0132,  0.0636]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2969, -3.8145,  3.1445,  ..., -2.4609, -0.8389, -0.3318]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 07:18:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A state is a member of a country
A listener is a member of a audience
A parishioner is a member of a parish
A book is a member of a library
A photo is a member of a album
A page is a member of a book
A college is a member of a university
A cat is a member of a
2024-07-28 07:18:39 root INFO     total operator prediction time: 1322.9713516235352 seconds
2024-07-28 07:18:39 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun - plural_irreg
2024-07-28 07:18:39 root INFO     building operator noun - plural_irreg
2024-07-28 07:18:39 root INFO     [order_1_approx] starting weight calculation for The plural form of army is armies
The plural form of century is centuries
The plural form of city is cities
The plural form of woman is women
The plural form of business is businesses
The plural form of activity is activities
The plural form of safety is safeties
The plural form of economy is
2024-07-28 07:18:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 07:21:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0899,  0.2373, -0.2263,  ..., -0.1583, -0.0559,  0.0654],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7656, -0.9238, -1.4502,  ..., -2.0371, -2.7461, -2.5312],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0401, -0.0010, -0.0119,  ...,  0.0193,  0.0304,  0.0007],
        [-0.0034,  0.0613,  0.0331,  ..., -0.0069, -0.0469,  0.0063],
        [-0.0357, -0.0136,  0.0197,  ..., -0.0392, -0.0229,  0.0056],
        ...,
        [ 0.0058,  0.0290,  0.0066,  ...,  0.0177,  0.0125, -0.0212],
        [-0.0250, -0.0249, -0.0352,  ...,  0.0053,  0.0158,  0.0197],
        [ 0.0174,  0.0048, -0.0146,  ...,  0.0496, -0.0179,  0.0089]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7856, -1.2578, -1.3428,  ..., -2.2344, -2.9531, -2.6270]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 07:21:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of army is armies
The plural form of century is centuries
The plural form of city is cities
The plural form of woman is women
The plural form of business is businesses
The plural form of activity is activities
The plural form of safety is safeties
The plural form of economy is
2024-07-28 07:21:26 root INFO     [order_1_approx] starting weight calculation for The plural form of activity is activities
The plural form of army is armies
The plural form of century is centuries
The plural form of safety is safeties
The plural form of woman is women
The plural form of economy is economies
The plural form of business is businesses
The plural form of city is
2024-07-28 07:21:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 07:24:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0782,  0.1460, -0.1991,  ..., -0.0502, -0.2505,  0.0460],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.2256, -5.8906,  1.4736,  ..., -1.5586,  1.6875, -1.1768],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0269, -0.0197, -0.0362,  ...,  0.0015, -0.0078,  0.0187],
        [ 0.0029,  0.0417, -0.0088,  ...,  0.0046,  0.0087,  0.0126],
        [ 0.0111, -0.0045, -0.0088,  ...,  0.0332, -0.0231,  0.0457],
        ...,
        [-0.0056,  0.0131,  0.0268,  ...,  0.0193,  0.0092, -0.0101],
        [ 0.0107, -0.0322, -0.0314,  ...,  0.0238, -0.0148, -0.0155],
        [-0.0043, -0.0128, -0.0175,  ..., -0.0066,  0.0003,  0.0047]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6221, -5.6875,  1.5889,  ..., -1.9434,  1.9756, -1.1826]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 07:24:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of activity is activities
The plural form of army is armies
The plural form of century is centuries
The plural form of safety is safeties
The plural form of woman is women
The plural form of economy is economies
The plural form of business is businesses
The plural form of city is
2024-07-28 07:24:12 root INFO     [order_1_approx] starting weight calculation for The plural form of century is centuries
The plural form of economy is economies
The plural form of city is cities
The plural form of business is businesses
The plural form of woman is women
The plural form of army is armies
The plural form of activity is activities
The plural form of safety is
2024-07-28 07:24:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 07:26:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0483, -0.1542, -0.1552,  ...,  0.2007, -0.0591,  0.1279],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5078, -1.0068,  0.1770,  ..., -0.5479, -3.4609, -2.9512],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0309, -0.0312, -0.0431,  ...,  0.0147, -0.0028, -0.0334],
        [-0.0131,  0.0410,  0.0189,  ..., -0.0253, -0.0273,  0.0192],
        [-0.0103,  0.0182,  0.0321,  ...,  0.0337, -0.0079, -0.0136],
        ...,
        [ 0.0006,  0.0143, -0.0127,  ...,  0.0143,  0.0150,  0.0040],
        [-0.0101,  0.0041,  0.0186,  ...,  0.0132,  0.0074, -0.0118],
        [ 0.0245, -0.0025,  0.0086,  ...,  0.0792, -0.0025,  0.0046]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7441, -1.8242,  0.5879,  ..., -0.7837, -4.2344, -2.7812]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 07:26:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of century is centuries
The plural form of economy is economies
The plural form of city is cities
The plural form of business is businesses
The plural form of woman is women
The plural form of army is armies
The plural form of activity is activities
The plural form of safety is
2024-07-28 07:26:58 root INFO     [order_1_approx] starting weight calculation for The plural form of activity is activities
The plural form of safety is safeties
The plural form of city is cities
The plural form of century is centuries
The plural form of woman is women
The plural form of economy is economies
The plural form of business is businesses
The plural form of army is
2024-07-28 07:26:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 07:29:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0690,  0.0978, -0.0151,  ..., -0.1152, -0.0192,  0.2073],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8955, -5.3594,  1.9062,  ..., -1.5527, -0.8076, -2.5156],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0334,  0.0061, -0.0276,  ...,  0.0029, -0.0085, -0.0266],
        [-0.0090,  0.0372, -0.0141,  ...,  0.0041, -0.0156, -0.0010],
        [-0.0028, -0.0130, -0.0029,  ..., -0.0062, -0.0064,  0.0123],
        ...,
        [-0.0283,  0.0314,  0.0355,  ...,  0.0141,  0.0084, -0.0070],
        [ 0.0231, -0.0287, -0.0264,  ...,  0.0134, -0.0253, -0.0020],
        [ 0.0009, -0.0114,  0.0062,  ...,  0.0331, -0.0323,  0.0089]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4900, -5.1016,  1.3633,  ..., -1.6133, -0.1836, -2.0957]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 07:29:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of activity is activities
The plural form of safety is safeties
The plural form of city is cities
The plural form of century is centuries
The plural form of woman is women
The plural form of economy is economies
The plural form of business is businesses
The plural form of army is
2024-07-28 07:29:45 root INFO     [order_1_approx] starting weight calculation for The plural form of safety is safeties
The plural form of woman is women
The plural form of business is businesses
The plural form of activity is activities
The plural form of economy is economies
The plural form of army is armies
The plural form of city is cities
The plural form of century is
2024-07-28 07:29:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 07:32:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1131, -0.1331,  0.0649,  ..., -0.1331, -0.2125,  0.2144],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1924, -2.1133,  2.2754,  ..., -3.6895, -0.8130, -1.2588],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0396, -0.0285, -0.0007,  ...,  0.0026, -0.0394, -0.0294],
        [-0.0103,  0.0632,  0.0211,  ...,  0.0069,  0.0034, -0.0177],
        [ 0.0066, -0.0339, -0.0101,  ...,  0.0171, -0.0664,  0.0447],
        ...,
        [-0.0062,  0.0384,  0.0097,  ...,  0.0440,  0.0301,  0.0022],
        [ 0.0009,  0.0201,  0.0069,  ..., -0.0040,  0.0195, -0.0133],
        [ 0.0037, -0.0201, -0.0044,  ...,  0.0371, -0.0239,  0.0420]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0216, -2.6621,  2.6074,  ..., -3.7832, -0.6294, -0.5317]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 07:32:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of safety is safeties
The plural form of woman is women
The plural form of business is businesses
The plural form of activity is activities
The plural form of economy is economies
The plural form of army is armies
The plural form of city is cities
The plural form of century is
2024-07-28 07:32:31 root INFO     [order_1_approx] starting weight calculation for The plural form of business is businesses
The plural form of city is cities
The plural form of century is centuries
The plural form of army is armies
The plural form of safety is safeties
The plural form of activity is activities
The plural form of economy is economies
The plural form of woman is
2024-07-28 07:32:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 07:35:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0587, -0.0260, -0.0045,  ...,  0.0891, -0.1781,  0.0515],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6602, -4.8906,  2.4453,  ..., -0.6982, -1.3516, -0.1455],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0135, -0.0191,  0.0086,  ...,  0.0148,  0.0177,  0.0098],
        [ 0.0083,  0.0241,  0.0117,  ...,  0.0189,  0.0022,  0.0039],
        [ 0.0108,  0.0308, -0.0144,  ...,  0.0496, -0.0161,  0.0507],
        ...,
        [-0.0202,  0.0054,  0.0073,  ...,  0.0294, -0.0419, -0.0150],
        [ 0.0226,  0.0178, -0.0281,  ...,  0.0075,  0.0176,  0.0341],
        [-0.0077, -0.0002, -0.0094,  ...,  0.0211, -0.0097,  0.0257]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4121, -4.8516,  2.3945,  ..., -0.9316, -1.0977, -0.2786]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 07:35:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of business is businesses
The plural form of city is cities
The plural form of century is centuries
The plural form of army is armies
The plural form of safety is safeties
The plural form of activity is activities
The plural form of economy is economies
The plural form of woman is
2024-07-28 07:35:16 root INFO     [order_1_approx] starting weight calculation for The plural form of century is centuries
The plural form of army is armies
The plural form of woman is women
The plural form of city is cities
The plural form of economy is economies
The plural form of safety is safeties
The plural form of activity is activities
The plural form of business is
2024-07-28 07:35:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 07:37:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1099,  0.2559,  0.2380,  ...,  0.1926, -0.1595, -0.1624],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9492, -2.3867, -1.0791,  ...,  0.1816,  0.5483, -2.0664],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0012,  0.0062, -0.0150,  ...,  0.0079, -0.0102,  0.0044],
        [-0.0111,  0.0005,  0.0025,  ...,  0.0106, -0.0145,  0.0061],
        [-0.0029, -0.0256, -0.0057,  ...,  0.0123,  0.0052,  0.0265],
        ...,
        [ 0.0045,  0.0191,  0.0121,  ...,  0.0069,  0.0038, -0.0161],
        [-0.0129, -0.0443, -0.0263,  ...,  0.0141, -0.0007,  0.0139],
        [ 0.0126, -0.0290, -0.0005,  ...,  0.0166,  0.0060,  0.0346]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7676, -2.5215, -1.0850,  ...,  0.2224,  0.4922, -1.7695]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 07:37:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of century is centuries
The plural form of army is armies
The plural form of woman is women
The plural form of city is cities
The plural form of economy is economies
The plural form of safety is safeties
The plural form of activity is activities
The plural form of business is
2024-07-28 07:37:59 root INFO     [order_1_approx] starting weight calculation for The plural form of business is businesses
The plural form of century is centuries
The plural form of woman is women
The plural form of economy is economies
The plural form of safety is safeties
The plural form of city is cities
The plural form of army is armies
The plural form of activity is
2024-07-28 07:37:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 07:40:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0026, -0.0718, -0.1171,  ...,  0.0101, -0.4229,  0.0042],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1079, -1.4141,  1.4258,  ..., -0.4214, -0.4453, -2.0938],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0151,  0.0130,  0.0170,  ...,  0.0410, -0.0032,  0.0238],
        [-0.0262,  0.0320,  0.0124,  ...,  0.0109, -0.0375, -0.0103],
        [-0.0168, -0.0071,  0.0073,  ..., -0.0016,  0.0104,  0.0386],
        ...,
        [ 0.0051,  0.0074, -0.0374,  ...,  0.0206, -0.0078, -0.0474],
        [ 0.0392,  0.0170, -0.0488,  ..., -0.0182, -0.0022, -0.0566],
        [ 0.0274, -0.0020, -0.0039,  ...,  0.0243,  0.0008,  0.0248]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2832, -2.0410,  1.6016,  ..., -0.4678, -0.6104, -1.7686]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 07:40:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of business is businesses
The plural form of century is centuries
The plural form of woman is women
The plural form of economy is economies
The plural form of safety is safeties
The plural form of city is cities
The plural form of army is armies
The plural form of activity is
2024-07-28 07:40:42 root INFO     total operator prediction time: 1322.667291879654 seconds
2024-07-28 07:40:42 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on Ving - verb_inf
2024-07-28 07:40:42 root INFO     building operator Ving - verb_inf
2024-07-28 07:40:42 root INFO     [order_1_approx] starting weight calculation for applying is the active form of apply
receiving is the active form of receive
improving is the active form of improve
happening is the active form of happen
promoting is the active form of promote
adding is the active form of add
believing is the active form of believe
allowing is the active form of
2024-07-28 07:40:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 07:43:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1085,  0.0991,  0.1271,  ..., -0.1556, -0.0515, -0.0350],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3555, -5.3594, -1.7217,  ...,  1.7354, -2.2441, -0.8223],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0349, -0.0047, -0.0220,  ...,  0.0078, -0.0047,  0.0116],
        [-0.0002,  0.0251, -0.0127,  ...,  0.0132, -0.0066,  0.0018],
        [-0.0020,  0.0046, -0.0003,  ...,  0.0058, -0.0121, -0.0089],
        ...,
        [-0.0032, -0.0099,  0.0071,  ...,  0.0198,  0.0030,  0.0022],
        [ 0.0195, -0.0008,  0.0073,  ..., -0.0068,  0.0169, -0.0089],
        [-0.0090,  0.0129, -0.0012,  ..., -0.0122,  0.0081,  0.0154]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4414, -5.4844, -1.7695,  ...,  1.7285, -1.9424, -0.9971]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 07:43:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for applying is the active form of apply
receiving is the active form of receive
improving is the active form of improve
happening is the active form of happen
promoting is the active form of promote
adding is the active form of add
believing is the active form of believe
allowing is the active form of
2024-07-28 07:43:27 root INFO     [order_1_approx] starting weight calculation for applying is the active form of apply
receiving is the active form of receive
improving is the active form of improve
happening is the active form of happen
promoting is the active form of promote
believing is the active form of believe
allowing is the active form of allow
adding is the active form of
2024-07-28 07:43:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 07:46:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0792, -0.2800,  0.0906,  ...,  0.1575, -0.2773, -0.0816],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5625, -2.2578, -1.6016,  ...,  2.9902, -3.4609, -1.6934],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0529, -0.0063,  0.0137,  ..., -0.0093, -0.0171,  0.0129],
        [-0.0171,  0.0594,  0.0233,  ..., -0.0478, -0.0335, -0.0237],
        [ 0.0052, -0.0069,  0.0308,  ..., -0.0109, -0.0089, -0.0020],
        ...,
        [ 0.0056,  0.0362, -0.0007,  ...,  0.0014, -0.0126, -0.0054],
        [-0.0042, -0.0416,  0.0338,  ...,  0.0375,  0.0210, -0.0096],
        [ 0.0041,  0.0070, -0.0007,  ..., -0.0401, -0.0233,  0.0339]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2539, -2.8770, -1.9648,  ...,  2.6387, -2.8633, -2.0234]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 07:46:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for applying is the active form of apply
receiving is the active form of receive
improving is the active form of improve
happening is the active form of happen
promoting is the active form of promote
believing is the active form of believe
allowing is the active form of allow
adding is the active form of
2024-07-28 07:46:13 root INFO     [order_1_approx] starting weight calculation for adding is the active form of add
believing is the active form of believe
allowing is the active form of allow
happening is the active form of happen
applying is the active form of apply
improving is the active form of improve
receiving is the active form of receive
promoting is the active form of
2024-07-28 07:46:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 07:48:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1201,  0.2451, -0.0046,  ..., -0.0217,  0.0004, -0.0421],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3164, -4.1445, -0.6431,  ...,  2.6836, -2.7930, -2.3418],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.9917e-02,  4.5967e-03,  8.5068e-03,  ..., -9.6283e-03,
         -2.7145e-02,  6.6605e-03],
        [ 3.7994e-03,  2.8198e-02, -9.8228e-04,  ...,  1.2596e-02,
          7.1754e-03,  1.5671e-02],
        [ 8.1635e-04, -4.7302e-03,  1.4946e-02,  ...,  4.9248e-03,
         -7.6294e-05,  3.6049e-03],
        ...,
        [ 1.7136e-02, -1.0956e-02, -2.0370e-03,  ...,  2.8320e-02,
         -2.0493e-02, -2.0966e-02],
        [ 1.4977e-02,  7.7400e-03,  9.8419e-04,  ...,  1.2825e-02,
          4.7821e-02,  1.4175e-02],
        [ 1.5121e-02,  1.7593e-02, -9.3231e-03,  ..., -7.1869e-03,
         -2.0161e-03,  2.7237e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3516, -4.1289, -0.8491,  ...,  2.5840, -3.0664, -2.5762]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 07:48:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for adding is the active form of add
believing is the active form of believe
allowing is the active form of allow
happening is the active form of happen
applying is the active form of apply
improving is the active form of improve
receiving is the active form of receive
promoting is the active form of
2024-07-28 07:48:58 root INFO     [order_1_approx] starting weight calculation for promoting is the active form of promote
applying is the active form of apply
improving is the active form of improve
adding is the active form of add
allowing is the active form of allow
receiving is the active form of receive
happening is the active form of happen
believing is the active form of
2024-07-28 07:48:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 07:51:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0347,  0.2446,  0.1582,  ..., -0.0363, -0.3311,  0.1672],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7539, -5.5547,  1.2207,  ...,  1.7988, -1.5449, -2.7363],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0032, -0.0046, -0.0090,  ..., -0.0002, -0.0068, -0.0035],
        [ 0.0078,  0.0113,  0.0069,  ...,  0.0008, -0.0019,  0.0114],
        [-0.0154, -0.0150,  0.0166,  ..., -0.0062, -0.0169, -0.0073],
        ...,
        [ 0.0168,  0.0032,  0.0053,  ..., -0.0001,  0.0035, -0.0002],
        [-0.0045, -0.0133,  0.0138,  ...,  0.0079,  0.0238, -0.0069],
        [ 0.0194, -0.0006,  0.0013,  ...,  0.0019, -0.0046,  0.0108]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0938, -5.8320,  1.3232,  ...,  1.5693, -1.6914, -2.8770]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 07:51:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for promoting is the active form of promote
applying is the active form of apply
improving is the active form of improve
adding is the active form of add
allowing is the active form of allow
receiving is the active form of receive
happening is the active form of happen
believing is the active form of
2024-07-28 07:51:44 root INFO     [order_1_approx] starting weight calculation for allowing is the active form of allow
happening is the active form of happen
improving is the active form of improve
believing is the active form of believe
promoting is the active form of promote
adding is the active form of add
applying is the active form of apply
receiving is the active form of
2024-07-28 07:51:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 07:54:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0653,  0.0930, -0.0382,  ..., -0.1765,  0.0096, -0.0195],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.3857, -3.1152, -1.9219,  ...,  0.2051, -0.2568, -3.6816],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0206, -0.0126,  0.0086,  ...,  0.0076, -0.0111,  0.0112],
        [-0.0236,  0.0117,  0.0058,  ..., -0.0070, -0.0126,  0.0266],
        [-0.0018, -0.0148,  0.0203,  ..., -0.0108, -0.0056, -0.0084],
        ...,
        [ 0.0119,  0.0167, -0.0141,  ...,  0.0276, -0.0061,  0.0042],
        [ 0.0078, -0.0237,  0.0042,  ..., -0.0118,  0.0267, -0.0108],
        [-0.0013,  0.0127,  0.0008,  ..., -0.0043, -0.0143,  0.0163]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7705, -3.4688, -1.8340,  ..., -0.0432, -0.3530, -3.8223]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 07:54:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for allowing is the active form of allow
happening is the active form of happen
improving is the active form of improve
believing is the active form of believe
promoting is the active form of promote
adding is the active form of add
applying is the active form of apply
receiving is the active form of
2024-07-28 07:54:30 root INFO     [order_1_approx] starting weight calculation for improving is the active form of improve
allowing is the active form of allow
applying is the active form of apply
adding is the active form of add
believing is the active form of believe
receiving is the active form of receive
promoting is the active form of promote
happening is the active form of
2024-07-28 07:54:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 07:57:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0862,  0.1731,  0.1825,  ..., -0.0244, -0.1375, -0.3142],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4160, -3.9238,  1.0508,  ...,  2.0684, -2.2305, -0.3623],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.2705e-02,  1.5350e-02, -3.9043e-03,  ..., -6.6147e-03,
         -4.3411e-03,  5.1422e-03],
        [-5.7220e-06,  1.4915e-03, -1.4053e-02,  ...,  5.5389e-03,
          4.0245e-03,  9.5291e-03],
        [ 1.5717e-03,  4.7989e-03,  8.2779e-04,  ...,  5.7697e-04,
         -6.3515e-03, -2.6550e-02],
        ...,
        [ 1.2917e-02,  2.4414e-03, -1.8616e-03,  ...,  7.3738e-03,
         -2.7252e-02, -2.7802e-02],
        [-7.7515e-03, -2.3407e-02, -1.9684e-03,  ...,  3.6907e-03,
          3.7048e-02,  4.0192e-02],
        [-1.4114e-04,  9.7961e-03,  2.6951e-03,  ...,  4.2305e-03,
         -1.8330e-03,  6.9714e-04]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4443, -4.0430,  1.0186,  ...,  2.0547, -2.2598, -0.4297]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 07:57:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for improving is the active form of improve
allowing is the active form of allow
applying is the active form of apply
adding is the active form of add
believing is the active form of believe
receiving is the active form of receive
promoting is the active form of promote
happening is the active form of
2024-07-28 07:57:16 root INFO     [order_1_approx] starting weight calculation for allowing is the active form of allow
adding is the active form of add
improving is the active form of improve
receiving is the active form of receive
happening is the active form of happen
believing is the active form of believe
promoting is the active form of promote
applying is the active form of
2024-07-28 07:57:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 08:00:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2201, -0.0493,  0.3169,  ..., -0.0079, -0.2013,  0.0052],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2598, -3.5938, -0.9912,  ...,  3.0977, -2.6074, -2.6875],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0299, -0.0139,  0.0145,  ..., -0.0031,  0.0034,  0.0047],
        [-0.0125,  0.0124,  0.0248,  ..., -0.0011, -0.0460,  0.0120],
        [-0.0143,  0.0055,  0.0304,  ..., -0.0003,  0.0094,  0.0129],
        ...,
        [ 0.0145,  0.0026, -0.0009,  ...,  0.0275, -0.0269, -0.0062],
        [ 0.0043,  0.0015,  0.0149,  ..., -0.0082,  0.0182,  0.0203],
        [ 0.0158,  0.0115, -0.0072,  ..., -0.0197, -0.0211,  0.0261]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0486, -4.2188, -0.7578,  ...,  3.0312, -2.7129, -2.7969]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 08:00:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for allowing is the active form of allow
adding is the active form of add
improving is the active form of improve
receiving is the active form of receive
happening is the active form of happen
believing is the active form of believe
promoting is the active form of promote
applying is the active form of
2024-07-28 08:00:03 root INFO     [order_1_approx] starting weight calculation for allowing is the active form of allow
believing is the active form of believe
applying is the active form of apply
happening is the active form of happen
adding is the active form of add
receiving is the active form of receive
promoting is the active form of promote
improving is the active form of
2024-07-28 08:00:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 08:02:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0818,  0.1725,  0.0499,  ..., -0.0565, -0.1309,  0.1119],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1992, -3.8906, -0.8105,  ...,  3.3164, -0.9575, -2.7422],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0169, -0.0113, -0.0028,  ..., -0.0162, -0.0157,  0.0051],
        [-0.0099,  0.0093,  0.0071,  ...,  0.0047,  0.0008,  0.0083],
        [ 0.0029, -0.0003,  0.0067,  ..., -0.0020,  0.0038, -0.0007],
        ...,
        [ 0.0035, -0.0081, -0.0079,  ...,  0.0229, -0.0046, -0.0058],
        [ 0.0135, -0.0048,  0.0181,  ...,  0.0080,  0.0222,  0.0101],
        [ 0.0024,  0.0108, -0.0005,  ...,  0.0064, -0.0072,  0.0198]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1855, -3.9160, -0.9053,  ...,  3.1875, -1.5117, -2.8496]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 08:02:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for allowing is the active form of allow
believing is the active form of believe
applying is the active form of apply
happening is the active form of happen
adding is the active form of add
receiving is the active form of receive
promoting is the active form of promote
improving is the active form of
2024-07-28 08:02:48 root INFO     total operator prediction time: 1326.3993151187897 seconds
2024-07-28 08:02:48 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_Ving - Ved
2024-07-28 08:02:48 root INFO     building operator verb_Ving - Ved
2024-07-28 08:02:48 root INFO     [order_1_approx] starting weight calculation for After something is requiring, it has required
After something is existing, it has existed
After something is developing, it has developed
After something is publishing, it has published
After something is introducing, it has introduced
After something is deciding, it has decided
After something is establishing, it has established
After something is operating, it has
2024-07-28 08:02:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 08:05:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0735,  0.1736, -0.0411,  ...,  0.0966, -0.2006, -0.1521],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9912,  0.2363,  0.9106,  ..., -3.3867, -1.7139,  0.0215],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0112,  0.0017, -0.0090,  ..., -0.0105,  0.0195,  0.0073],
        [-0.0192,  0.0275, -0.0233,  ..., -0.0043, -0.0016,  0.0114],
        [ 0.0048,  0.0128, -0.0027,  ...,  0.0094,  0.0101, -0.0010],
        ...,
        [ 0.0036,  0.0186, -0.0170,  ...,  0.0165,  0.0099, -0.0060],
        [ 0.0102, -0.0098, -0.0032,  ...,  0.0117,  0.0141, -0.0002],
        [ 0.0170, -0.0133,  0.0071,  ...,  0.0110, -0.0207,  0.0177]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8677,  1.2666,  1.0078,  ..., -2.7305, -2.0898,  0.3062]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 08:05:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is requiring, it has required
After something is existing, it has existed
After something is developing, it has developed
After something is publishing, it has published
After something is introducing, it has introduced
After something is deciding, it has decided
After something is establishing, it has established
After something is operating, it has
2024-07-28 08:05:31 root INFO     [order_1_approx] starting weight calculation for After something is requiring, it has required
After something is introducing, it has introduced
After something is establishing, it has established
After something is publishing, it has published
After something is developing, it has developed
After something is operating, it has operated
After something is existing, it has existed
After something is deciding, it has
2024-07-28 08:05:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 08:08:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0502,  0.2130, -0.0853,  ...,  0.0505, -0.2195, -0.1004],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8047, -1.5391,  2.4258,  ..., -1.2949, -2.3008,  0.8086],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0136, -0.0206, -0.0360,  ..., -0.0163,  0.0051, -0.0033],
        [-0.0228,  0.0002,  0.0295,  ..., -0.0093,  0.0065, -0.0123],
        [ 0.0127,  0.0007, -0.0138,  ..., -0.0086, -0.0036, -0.0129],
        ...,
        [ 0.0058,  0.0240,  0.0138,  ...,  0.0198,  0.0011,  0.0094],
        [ 0.0117,  0.0066, -0.0007,  ..., -0.0313, -0.0121, -0.0222],
        [ 0.0051, -0.0075,  0.0104,  ..., -0.0151, -0.0378, -0.0063]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5000, -1.9844,  2.5332,  ..., -1.3672, -2.5586,  0.7334]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 08:08:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is requiring, it has required
After something is introducing, it has introduced
After something is establishing, it has established
After something is publishing, it has published
After something is developing, it has developed
After something is operating, it has operated
After something is existing, it has existed
After something is deciding, it has
2024-07-28 08:08:17 root INFO     [order_1_approx] starting weight calculation for After something is deciding, it has decided
After something is establishing, it has established
After something is existing, it has existed
After something is introducing, it has introduced
After something is operating, it has operated
After something is developing, it has developed
After something is requiring, it has required
After something is publishing, it has
2024-07-28 08:08:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 08:11:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1680,  0.1173,  0.1750,  ...,  0.1559, -0.0554,  0.0586],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0918, -1.7656,  1.2324,  ..., -2.7402, -1.6523,  1.3672],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0270, -0.0008, -0.0151,  ...,  0.0046,  0.0231,  0.0164],
        [-0.0454,  0.0094, -0.0052,  ..., -0.0088, -0.0145, -0.0156],
        [ 0.0195, -0.0239,  0.0194,  ...,  0.0185, -0.0098, -0.0031],
        ...,
        [ 0.0035,  0.0411,  0.0053,  ...,  0.0284,  0.0079,  0.0068],
        [ 0.0040, -0.0013, -0.0122,  ..., -0.0115,  0.0128, -0.0104],
        [ 0.0371,  0.0239, -0.0060,  ..., -0.0196, -0.0462, -0.0311]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6328, -1.7100,  1.6768,  ..., -2.8496, -1.7256,  1.1035]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 08:11:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is deciding, it has decided
After something is establishing, it has established
After something is existing, it has existed
After something is introducing, it has introduced
After something is operating, it has operated
After something is developing, it has developed
After something is requiring, it has required
After something is publishing, it has
2024-07-28 08:11:03 root INFO     [order_1_approx] starting weight calculation for After something is operating, it has operated
After something is publishing, it has published
After something is requiring, it has required
After something is developing, it has developed
After something is establishing, it has established
After something is existing, it has existed
After something is deciding, it has decided
After something is introducing, it has
2024-07-28 08:11:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 08:13:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0230,  0.0723,  0.1135,  ...,  0.1092, -0.0495,  0.1256],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4463,  0.3066,  2.9551,  ..., -0.9609, -2.9258, -0.2266],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0201,  0.0033,  0.0017,  ..., -0.0029, -0.0068, -0.0005],
        [-0.0412,  0.0072, -0.0033,  ...,  0.0050,  0.0124, -0.0026],
        [ 0.0198, -0.0004, -0.0141,  ..., -0.0097,  0.0073, -0.0313],
        ...,
        [ 0.0243,  0.0018, -0.0001,  ...,  0.0236, -0.0122,  0.0207],
        [ 0.0285,  0.0160, -0.0131,  ..., -0.0112,  0.0187,  0.0024],
        [ 0.0016,  0.0175, -0.0009,  ..., -0.0020, -0.0130,  0.0149]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6143,  0.0188,  3.2520,  ..., -1.0703, -2.9062, -0.4741]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 08:13:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is operating, it has operated
After something is publishing, it has published
After something is requiring, it has required
After something is developing, it has developed
After something is establishing, it has established
After something is existing, it has existed
After something is deciding, it has decided
After something is introducing, it has
2024-07-28 08:13:48 root INFO     [order_1_approx] starting weight calculation for After something is deciding, it has decided
After something is publishing, it has published
After something is operating, it has operated
After something is introducing, it has introduced
After something is establishing, it has established
After something is developing, it has developed
After something is requiring, it has required
After something is existing, it has
2024-07-28 08:13:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 08:16:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0359,  0.2983, -0.1310,  ..., -0.0797, -0.2378, -0.3030],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9902,  0.6187,  0.4741,  ..., -1.8301, -1.7754, -1.2109],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0312,  0.0186, -0.0278,  ..., -0.0029,  0.0292,  0.0090],
        [-0.0149,  0.0208, -0.0092,  ...,  0.0042,  0.0002, -0.0416],
        [ 0.0194, -0.0078,  0.0038,  ..., -0.0335, -0.0040, -0.0110],
        ...,
        [ 0.0117,  0.0242, -0.0169,  ...,  0.0208, -0.0294, -0.0139],
        [ 0.0196, -0.0060,  0.0163,  ..., -0.0004,  0.0408, -0.0027],
        [-0.0010, -0.0111,  0.0168,  ...,  0.0190, -0.0305, -0.0152]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3926,  0.3813,  0.6318,  ..., -1.2617, -1.7861, -1.5264]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 08:16:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is deciding, it has decided
After something is publishing, it has published
After something is operating, it has operated
After something is introducing, it has introduced
After something is establishing, it has established
After something is developing, it has developed
After something is requiring, it has required
After something is existing, it has
2024-07-28 08:16:33 root INFO     [order_1_approx] starting weight calculation for After something is existing, it has existed
After something is requiring, it has required
After something is introducing, it has introduced
After something is operating, it has operated
After something is publishing, it has published
After something is developing, it has developed
After something is deciding, it has decided
After something is establishing, it has
2024-07-28 08:16:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 08:19:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0743,  0.0630, -0.2051,  ...,  0.0385, -0.1920,  0.0642],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1387,  0.0000,  1.0928,  ..., -1.3867, -0.7070, -0.6973],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0217, -0.0045, -0.0306,  ...,  0.0135, -0.0029, -0.0040],
        [ 0.0006,  0.0256, -0.0048,  ...,  0.0206,  0.0030,  0.0089],
        [-0.0038,  0.0175,  0.0025,  ...,  0.0106,  0.0011,  0.0032],
        ...,
        [ 0.0029,  0.0078, -0.0166,  ...,  0.0042, -0.0035,  0.0027],
        [-0.0078,  0.0178,  0.0230,  ..., -0.0092,  0.0110, -0.0047],
        [ 0.0014,  0.0144,  0.0094,  ...,  0.0006, -0.0234,  0.0003]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5039, -0.0066,  1.3613,  ..., -1.4570, -0.8086, -0.9302]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 08:19:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is existing, it has existed
After something is requiring, it has required
After something is introducing, it has introduced
After something is operating, it has operated
After something is publishing, it has published
After something is developing, it has developed
After something is deciding, it has decided
After something is establishing, it has
2024-07-28 08:19:18 root INFO     [order_1_approx] starting weight calculation for After something is introducing, it has introduced
After something is establishing, it has established
After something is deciding, it has decided
After something is operating, it has operated
After something is requiring, it has required
After something is publishing, it has published
After something is existing, it has existed
After something is developing, it has
2024-07-28 08:19:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 08:22:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2183,  0.0101,  0.0323,  ...,  0.0987, -0.1191, -0.1843],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6836, -0.8247,  3.0117,  ..., -2.8047, -1.7295, -1.3945],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.1667e-03,  1.4565e-02, -1.3397e-02,  ..., -1.0727e-02,
          8.8425e-03, -7.6294e-06],
        [-4.4739e-02,  4.3701e-02, -6.6376e-03,  ...,  2.9266e-02,
          6.8741e-03, -1.3733e-04],
        [-1.6279e-03,  1.4076e-03, -1.6861e-03,  ..., -4.0466e-02,
         -1.8120e-03, -3.4058e-02],
        ...,
        [ 2.4078e-02,  2.7771e-02,  1.1703e-02,  ...,  2.2903e-02,
         -2.7008e-03,  1.6296e-02],
        [ 2.9068e-03, -1.6907e-02,  1.8036e-02,  ..., -2.4673e-02,
         -3.6812e-04,  8.6517e-03],
        [ 2.0752e-03, -1.9547e-02,  1.4214e-02,  ...,  2.6764e-02,
         -2.3514e-02,  4.7874e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4980, -0.2241,  2.5391,  ..., -2.8789, -1.8311, -1.5303]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 08:22:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is introducing, it has introduced
After something is establishing, it has established
After something is deciding, it has decided
After something is operating, it has operated
After something is requiring, it has required
After something is publishing, it has published
After something is existing, it has existed
After something is developing, it has
2024-07-28 08:22:04 root INFO     [order_1_approx] starting weight calculation for After something is establishing, it has established
After something is deciding, it has decided
After something is operating, it has operated
After something is developing, it has developed
After something is existing, it has existed
After something is introducing, it has introduced
After something is publishing, it has published
After something is requiring, it has
2024-07-28 08:22:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 08:24:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2495,  0.1603, -0.1628,  ..., -0.0551, -0.2588,  0.0938],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0967,  0.0889,  1.7109,  ..., -2.0000, -2.5527, -1.1006],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0102,  0.0364, -0.0052,  ..., -0.0118, -0.0063,  0.0231],
        [-0.0607,  0.0260, -0.0549,  ..., -0.0282,  0.0001, -0.0182],
        [ 0.0035,  0.0016, -0.0093,  ..., -0.0119, -0.0271, -0.0265],
        ...,
        [ 0.0132,  0.0289, -0.0197,  ...,  0.0275, -0.0111, -0.0008],
        [ 0.0175,  0.0016,  0.0385,  ...,  0.0088,  0.0432, -0.0044],
        [-0.0005,  0.0146,  0.0134,  ...,  0.0010, -0.0117, -0.0177]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6807, -0.6562,  2.1660,  ..., -1.4688, -1.9434, -1.2832]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 08:24:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is establishing, it has established
After something is deciding, it has decided
After something is operating, it has operated
After something is developing, it has developed
After something is existing, it has existed
After something is introducing, it has introduced
After something is publishing, it has published
After something is requiring, it has
2024-07-28 08:24:50 root INFO     total operator prediction time: 1322.0017852783203 seconds
2024-07-28 08:24:50 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_inf - Ved
2024-07-28 08:24:50 root INFO     building operator verb_inf - Ved
2024-07-28 08:24:50 root INFO     [order_1_approx] starting weight calculation for If the present form is decide, the past form is decided
If the present form is require, the past form is required
If the present form is apply, the past form is applied
If the present form is create, the past form is created
If the present form is establish, the past form is established
If the present form is become, the past form is became
If the present form is introduce, the past form is introduced
If the present form is lose, the past form is
2024-07-28 08:24:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 08:27:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0432,  0.1552,  0.1372,  ..., -0.1567, -0.1670,  0.1483],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1094, -1.4561, -0.2319,  ..., -0.1250, -0.3828, -1.6152],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.9133e-02, -5.8365e-03,  4.3976e-02,  ...,  1.0551e-02,
         -2.0050e-02, -1.9501e-02],
        [-1.7303e-02,  4.6539e-02,  9.8877e-03,  ..., -1.0033e-02,
         -2.3079e-03, -2.1042e-02],
        [ 3.3493e-03, -4.1122e-03,  7.1335e-03,  ..., -2.3041e-02,
         -3.3951e-03,  8.7738e-05],
        ...,
        [ 4.1428e-03, -2.9633e-02, -9.5367e-04,  ...,  1.6373e-02,
          1.0132e-02,  1.3916e-02],
        [ 3.2806e-04,  1.4343e-02, -4.4136e-03,  ..., -1.8585e-02,
          4.3030e-02, -8.4839e-03],
        [ 8.2092e-03,  3.8330e-02, -4.8447e-03,  ..., -3.2471e-02,
         -1.0239e-02, -1.1124e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1908, -1.5469, -0.4419,  ..., -0.0248, -0.3008, -1.5537]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 08:27:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is decide, the past form is decided
If the present form is require, the past form is required
If the present form is apply, the past form is applied
If the present form is create, the past form is created
If the present form is establish, the past form is established
If the present form is become, the past form is became
If the present form is introduce, the past form is introduced
If the present form is lose, the past form is
2024-07-28 08:27:34 root INFO     [order_1_approx] starting weight calculation for If the present form is establish, the past form is established
If the present form is become, the past form is became
If the present form is create, the past form is created
If the present form is lose, the past form is lost
If the present form is apply, the past form is applied
If the present form is introduce, the past form is introduced
If the present form is require, the past form is required
If the present form is decide, the past form is
2024-07-28 08:27:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 08:30:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1089,  0.1783, -0.0335,  ..., -0.0032, -0.2448, -0.0306],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4785, -2.8340,  2.2812,  ..., -1.2949, -2.3164, -0.5928],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0061,  0.0101, -0.0125,  ..., -0.0349,  0.0178, -0.0165],
        [ 0.0043,  0.0019, -0.0084,  ...,  0.0092, -0.0305, -0.0220],
        [-0.0096,  0.0052, -0.0071,  ..., -0.0326, -0.0098, -0.0186],
        ...,
        [-0.0066, -0.0040,  0.0065,  ...,  0.0249,  0.0127, -0.0002],
        [ 0.0088, -0.0089,  0.0034,  ..., -0.0005,  0.0212, -0.0047],
        [ 0.0013, -0.0136, -0.0075,  ...,  0.0026, -0.0320, -0.0224]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5938, -2.9902,  2.1777,  ..., -1.3213, -1.8525, -0.9175]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 08:30:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is establish, the past form is established
If the present form is become, the past form is became
If the present form is create, the past form is created
If the present form is lose, the past form is lost
If the present form is apply, the past form is applied
If the present form is introduce, the past form is introduced
If the present form is require, the past form is required
If the present form is decide, the past form is
2024-07-28 08:30:20 root INFO     [order_1_approx] starting weight calculation for If the present form is introduce, the past form is introduced
If the present form is apply, the past form is applied
If the present form is become, the past form is became
If the present form is require, the past form is required
If the present form is decide, the past form is decided
If the present form is create, the past form is created
If the present form is lose, the past form is lost
If the present form is establish, the past form is
2024-07-28 08:30:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 08:33:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0107,  0.0625, -0.0688,  ..., -0.0435, -0.3955,  0.2019],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 7.3926e-01, -1.4648e-03,  1.7139e-01,  ..., -2.8418e-01,
        -1.1865e+00, -2.5664e+00], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0102,  0.0021, -0.0141,  ..., -0.0027, -0.0074,  0.0251],
        [-0.0164,  0.0247, -0.0155,  ...,  0.0163, -0.0161, -0.0229],
        [ 0.0172,  0.0090,  0.0098,  ..., -0.0243, -0.0180, -0.0191],
        ...,
        [ 0.0201,  0.0013, -0.0127,  ...,  0.0278,  0.0088,  0.0124],
        [-0.0226, -0.0278, -0.0062,  ...,  0.0189,  0.0281, -0.0437],
        [ 0.0084, -0.0036,  0.0028,  ...,  0.0030, -0.0205,  0.0026]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9517, -0.2524,  0.0375,  ..., -0.5347, -0.6558, -2.2930]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 08:33:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is introduce, the past form is introduced
If the present form is apply, the past form is applied
If the present form is become, the past form is became
If the present form is require, the past form is required
If the present form is decide, the past form is decided
If the present form is create, the past form is created
If the present form is lose, the past form is lost
If the present form is establish, the past form is
2024-07-28 08:33:07 root INFO     [order_1_approx] starting weight calculation for If the present form is establish, the past form is established
If the present form is lose, the past form is lost
If the present form is become, the past form is became
If the present form is create, the past form is created
If the present form is decide, the past form is decided
If the present form is apply, the past form is applied
If the present form is introduce, the past form is introduced
If the present form is require, the past form is
2024-07-28 08:33:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 08:35:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0707, -0.0478, -0.2087,  ..., -0.0078, -0.3945,  0.2546],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.0898,  0.0417,  0.6035,  ..., -1.3301, -3.2695, -1.5107],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0063,  0.0125,  0.0138,  ..., -0.0130, -0.0144,  0.0139],
        [-0.0217,  0.0320, -0.0119,  ..., -0.0123, -0.0273, -0.0095],
        [-0.0003, -0.0073,  0.0154,  ..., -0.0423, -0.0288, -0.0064],
        ...,
        [ 0.0005,  0.0080,  0.0102,  ...,  0.0334,  0.0203, -0.0078],
        [ 0.0262, -0.0215, -0.0112,  ..., -0.0138,  0.0346,  0.0005],
        [ 0.0116, -0.0059,  0.0035,  ..., -0.0174,  0.0048, -0.0045]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.3926, -0.3313,  0.8740,  ..., -1.3154, -2.8594, -1.3330]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 08:35:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is establish, the past form is established
If the present form is lose, the past form is lost
If the present form is become, the past form is became
If the present form is create, the past form is created
If the present form is decide, the past form is decided
If the present form is apply, the past form is applied
If the present form is introduce, the past form is introduced
If the present form is require, the past form is
2024-07-28 08:35:52 root INFO     [order_1_approx] starting weight calculation for If the present form is decide, the past form is decided
If the present form is introduce, the past form is introduced
If the present form is require, the past form is required
If the present form is establish, the past form is established
If the present form is create, the past form is created
If the present form is lose, the past form is lost
If the present form is apply, the past form is applied
If the present form is become, the past form is
2024-07-28 08:35:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 08:38:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0181,  0.2264,  0.3799,  ..., -0.1113, -0.4346,  0.2240],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3008,  0.0793,  1.2637,  ...,  0.2395,  0.9990, -1.2764],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0109, -0.0002,  0.0195,  ...,  0.0447,  0.0148, -0.0118],
        [-0.0131,  0.0275,  0.0176,  ..., -0.0218, -0.0373, -0.0267],
        [-0.0033,  0.0012,  0.0186,  ..., -0.0342,  0.0010, -0.0184],
        ...,
        [-0.0081,  0.0121, -0.0172,  ...,  0.0529,  0.0220, -0.0237],
        [ 0.0104,  0.0226, -0.0050,  ..., -0.0071,  0.0217, -0.0086],
        [-0.0031,  0.0101,  0.0219,  ..., -0.0056, -0.0114,  0.0002]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5156, -0.1821,  0.4966,  ...,  0.0265,  0.9146, -1.3262]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 08:38:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is decide, the past form is decided
If the present form is introduce, the past form is introduced
If the present form is require, the past form is required
If the present form is establish, the past form is established
If the present form is create, the past form is created
If the present form is lose, the past form is lost
If the present form is apply, the past form is applied
If the present form is become, the past form is
2024-07-28 08:38:38 root INFO     [order_1_approx] starting weight calculation for If the present form is become, the past form is became
If the present form is create, the past form is created
If the present form is require, the past form is required
If the present form is apply, the past form is applied
If the present form is establish, the past form is established
If the present form is lose, the past form is lost
If the present form is decide, the past form is decided
If the present form is introduce, the past form is
2024-07-28 08:38:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 08:41:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1836, -0.0417,  0.3757,  ..., -0.0859, -0.1165,  0.1852],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5244,  1.0586,  2.5977,  ...,  0.5942, -2.6719, -0.9180],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.1475e-02, -2.5730e-03,  9.9411e-03,  ..., -7.2632e-03,
         -4.3011e-04, -1.0788e-02],
        [-6.1035e-05,  3.4149e-02,  5.8365e-03,  ...,  1.9165e-02,
         -3.0960e-02,  3.0556e-03],
        [ 6.7558e-03, -2.2736e-03, -1.2138e-02,  ..., -8.9645e-03,
         -6.5460e-03, -4.0932e-03],
        ...,
        [-1.8066e-02, -1.3023e-02,  1.3901e-02,  ...,  4.5532e-02,
          2.1927e-02, -7.4310e-03],
        [ 4.8706e-02,  1.1459e-02, -8.5144e-03,  ..., -1.0231e-02,
          2.0874e-02, -1.4816e-02],
        [ 4.1565e-02,  1.5656e-02,  2.7176e-02,  ..., -8.8806e-03,
         -2.5925e-02, -2.7981e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8516,  0.4448,  3.0508,  ...,  0.1548, -2.2285, -1.3438]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 08:41:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is become, the past form is became
If the present form is create, the past form is created
If the present form is require, the past form is required
If the present form is apply, the past form is applied
If the present form is establish, the past form is established
If the present form is lose, the past form is lost
If the present form is decide, the past form is decided
If the present form is introduce, the past form is
2024-07-28 08:41:25 root INFO     [order_1_approx] starting weight calculation for If the present form is require, the past form is required
If the present form is establish, the past form is established
If the present form is introduce, the past form is introduced
If the present form is lose, the past form is lost
If the present form is become, the past form is became
If the present form is create, the past form is created
If the present form is decide, the past form is decided
If the present form is apply, the past form is
2024-07-28 08:41:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 08:44:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1353, -0.0777,  0.2080,  ...,  0.0283, -0.4211,  0.0328],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2529, -1.0928, -1.4043,  ...,  0.0812, -2.8281, -1.2246],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0150, -0.0052,  0.0211,  ..., -0.0018,  0.0192, -0.0116],
        [-0.0112,  0.0082, -0.0021,  ...,  0.0086, -0.0249, -0.0054],
        [ 0.0036, -0.0182, -0.0026,  ..., -0.0193, -0.0277,  0.0032],
        ...,
        [-0.0030,  0.0020,  0.0106,  ...,  0.0336,  0.0066,  0.0056],
        [-0.0055, -0.0150,  0.0352,  ..., -0.0214,  0.0223, -0.0081],
        [ 0.0311, -0.0199, -0.0254,  ..., -0.0079, -0.0294, -0.0048]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5107, -1.6670, -1.1758,  ...,  0.2563, -3.0645, -1.6982]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 08:44:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is require, the past form is required
If the present form is establish, the past form is established
If the present form is introduce, the past form is introduced
If the present form is lose, the past form is lost
If the present form is become, the past form is became
If the present form is create, the past form is created
If the present form is decide, the past form is decided
If the present form is apply, the past form is
2024-07-28 08:44:07 root INFO     [order_1_approx] starting weight calculation for If the present form is lose, the past form is lost
If the present form is decide, the past form is decided
If the present form is apply, the past form is applied
If the present form is require, the past form is required
If the present form is introduce, the past form is introduced
If the present form is become, the past form is became
If the present form is establish, the past form is established
If the present form is create, the past form is
2024-07-28 08:44:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 08:46:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0840,  0.1405,  0.0581,  ...,  0.0561, -0.3037,  0.1102],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.2363, -1.8154,  1.3965,  ..., -0.8042, -1.6875,  0.4668],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0226, -0.0265, -0.0217,  ..., -0.0085, -0.0187, -0.0082],
        [ 0.0073,  0.0388,  0.0076,  ...,  0.0212, -0.0060, -0.0120],
        [ 0.0050,  0.0044,  0.0042,  ..., -0.0122, -0.0233, -0.0256],
        ...,
        [ 0.0180, -0.0045,  0.0057,  ...,  0.0155,  0.0243, -0.0031],
        [ 0.0213,  0.0119, -0.0104,  ..., -0.0202,  0.0321,  0.0091],
        [ 0.0031, -0.0014,  0.0109,  ..., -0.0021, -0.0075,  0.0211]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.4902, -1.4092,  1.0312,  ..., -1.0449, -1.5088,  0.5962]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 08:46:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is lose, the past form is lost
If the present form is decide, the past form is decided
If the present form is apply, the past form is applied
If the present form is require, the past form is required
If the present form is introduce, the past form is introduced
If the present form is become, the past form is became
If the present form is establish, the past form is established
If the present form is create, the past form is
2024-07-28 08:46:51 root INFO     total operator prediction time: 1321.113597869873 seconds
2024-07-28 08:46:51 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_inf - 3pSg
2024-07-28 08:46:51 root INFO     building operator verb_inf - 3pSg
2024-07-28 08:46:52 root INFO     [order_1_approx] starting weight calculation for I ensure, he ensures
I explain, he explains
I represent, he represents
I operate, he operates
I develop, he develops
I accept, he accepts
I tell, he tells
I identify, he
2024-07-28 08:46:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 08:49:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1826, -0.0943, -0.1274,  ...,  0.2664, -0.2700, -0.0069],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2852, -2.0391,  2.9395,  ..., -0.7529, -7.5703,  0.5547],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0110,  0.0568, -0.0313,  ...,  0.0414, -0.0038, -0.0332],
        [-0.0152, -0.0089,  0.0122,  ..., -0.0270,  0.0179, -0.0084],
        [ 0.0076, -0.0219,  0.0269,  ..., -0.0223, -0.0298,  0.0249],
        ...,
        [-0.0121,  0.0093,  0.0168,  ...,  0.0116,  0.0215,  0.0032],
        [ 0.0506, -0.0641,  0.0023,  ..., -0.0526, -0.0011, -0.0059],
        [ 0.0153,  0.0088,  0.0111,  ..., -0.0109, -0.0253,  0.0026]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4199, -2.5664,  3.0781,  ..., -0.0576, -9.0078, -0.0757]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 08:49:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I ensure, he ensures
I explain, he explains
I represent, he represents
I operate, he operates
I develop, he develops
I accept, he accepts
I tell, he tells
I identify, he
2024-07-28 08:49:35 root INFO     [order_1_approx] starting weight calculation for I accept, he accepts
I develop, he develops
I operate, he operates
I ensure, he ensures
I tell, he tells
I identify, he identifies
I explain, he explains
I represent, he
2024-07-28 08:49:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 08:52:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0482,  0.3896, -0.1631,  ..., -0.0810, -0.0812, -0.2463],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4463, -3.5098,  1.2734,  ..., -1.0674, -6.5781, -0.0117],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0166,  0.0148, -0.0017,  ...,  0.0190,  0.0073,  0.0147],
        [-0.0221, -0.0125,  0.0104,  ..., -0.0326,  0.0299, -0.0337],
        [-0.0045,  0.0030,  0.0306,  ..., -0.0174,  0.0103,  0.0210],
        ...,
        [-0.0192,  0.0133, -0.0088,  ..., -0.0068, -0.0173,  0.0053],
        [ 0.0250, -0.0414, -0.0092,  ..., -0.0418,  0.0354, -0.0333],
        [-0.0027, -0.0235, -0.0054,  ..., -0.0092,  0.0033, -0.0016]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0959, -4.0078,  0.9092,  ..., -0.6782, -7.5625, -0.1299]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 08:52:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I accept, he accepts
I develop, he develops
I operate, he operates
I ensure, he ensures
I tell, he tells
I identify, he identifies
I explain, he explains
I represent, he
2024-07-28 08:52:19 root INFO     [order_1_approx] starting weight calculation for I ensure, he ensures
I identify, he identifies
I tell, he tells
I accept, he accepts
I represent, he represents
I develop, he develops
I explain, he explains
I operate, he
2024-07-28 08:52:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 08:55:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0564,  0.2343, -0.2407,  ..., -0.2067, -0.3271, -0.1669],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0117, -4.3750,  1.1055,  ..., -1.5264, -5.7969,  0.4219],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0057,  0.0122,  0.0137,  ...,  0.0232, -0.0056,  0.0313],
        [-0.0067,  0.0034, -0.0040,  ..., -0.0167,  0.0276, -0.0108],
        [-0.0076,  0.0194,  0.0227,  ...,  0.0007, -0.0127,  0.0018],
        ...,
        [ 0.0051, -0.0229, -0.0068,  ...,  0.0038,  0.0091,  0.0251],
        [ 0.0095, -0.0360,  0.0168,  ..., -0.0404, -0.0005, -0.0334],
        [ 0.0130, -0.0173,  0.0131,  ..., -0.0291, -0.0165,  0.0020]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.2578, -4.5352,  1.2412,  ..., -1.0117, -6.6875, -0.0786]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 08:55:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I ensure, he ensures
I identify, he identifies
I tell, he tells
I accept, he accepts
I represent, he represents
I develop, he develops
I explain, he explains
I operate, he
2024-07-28 08:55:04 root INFO     [order_1_approx] starting weight calculation for I represent, he represents
I identify, he identifies
I develop, he develops
I explain, he explains
I accept, he accepts
I ensure, he ensures
I operate, he operates
I tell, he
2024-07-28 08:55:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 08:57:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3564,  0.2190,  0.0029,  ..., -0.0387, -0.1405, -0.1189],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([  2.4453,  -2.5879,   2.1406,  ...,   1.7930, -10.5781,  -1.1523],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0161, -0.0042,  0.0015,  ...,  0.0146, -0.0080,  0.0231],
        [-0.0208,  0.0249, -0.0163,  ..., -0.0055,  0.0292, -0.0005],
        [-0.0023,  0.0196,  0.0242,  ...,  0.0169,  0.0208,  0.0483],
        ...,
        [ 0.0022,  0.0104, -0.0031,  ...,  0.0187,  0.0231,  0.0213],
        [-0.0120, -0.0062,  0.0096,  ..., -0.0084,  0.0122,  0.0211],
        [ 0.0269, -0.0103, -0.0161,  ..., -0.0133, -0.0179,  0.0217]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[  2.3867,  -2.4238,   1.8057,  ...,   1.8369, -10.6484,  -1.3574]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 08:57:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I represent, he represents
I identify, he identifies
I develop, he develops
I explain, he explains
I accept, he accepts
I ensure, he ensures
I operate, he operates
I tell, he
2024-07-28 08:57:48 root INFO     [order_1_approx] starting weight calculation for I operate, he operates
I develop, he develops
I identify, he identifies
I ensure, he ensures
I accept, he accepts
I represent, he represents
I tell, he tells
I explain, he
2024-07-28 08:57:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 09:00:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0981,  0.3340,  0.0228,  ..., -0.1561, -0.1968, -0.0782],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7617, -3.2617,  1.5527,  ...,  0.6963, -6.3633,  1.3496],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0048, -0.0056, -0.0001,  ...,  0.0081, -0.0194,  0.0244],
        [-0.0305,  0.0287,  0.0089,  ..., -0.0344,  0.0214,  0.0073],
        [ 0.0087,  0.0074, -0.0189,  ..., -0.0236, -0.0015, -0.0104],
        ...,
        [-0.0029, -0.0023,  0.0162,  ...,  0.0225, -0.0030, -0.0120],
        [ 0.0228, -0.0092, -0.0118,  ..., -0.0346,  0.0026,  0.0047],
        [ 0.0309,  0.0123,  0.0149,  ..., -0.0163,  0.0072,  0.0019]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7793, -3.2207,  1.6484,  ...,  1.4199, -7.1055,  0.9331]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 09:00:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I operate, he operates
I develop, he develops
I identify, he identifies
I ensure, he ensures
I accept, he accepts
I represent, he represents
I tell, he tells
I explain, he
2024-07-28 09:00:34 root INFO     [order_1_approx] starting weight calculation for I tell, he tells
I explain, he explains
I accept, he accepts
I represent, he represents
I identify, he identifies
I ensure, he ensures
I operate, he operates
I develop, he
2024-07-28 09:00:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 09:03:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1127,  0.3521,  0.1144,  ..., -0.1294, -0.2729, -0.0130],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.2852, -4.5703,  1.0449,  ..., -0.6323, -8.5234, -1.3779],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.2062e-02,  9.3765e-03,  1.1894e-02,  ...,  2.1957e-02,
         -1.0422e-02,  1.8433e-02],
        [-1.0788e-02,  2.5574e-02, -6.3019e-03,  ..., -1.6556e-02,
          3.3569e-02, -1.9775e-02],
        [ 1.6708e-03,  5.9624e-03,  5.3978e-03,  ...,  8.1329e-03,
         -2.0538e-02,  3.3447e-02],
        ...,
        [ 2.1835e-02, -1.8982e-02,  8.6899e-03,  ...,  2.0447e-02,
         -3.3188e-03,  2.8564e-02],
        [-8.5449e-03, -7.6233e-02, -1.1772e-02,  ..., -4.0344e-02,
          1.4130e-02, -1.6205e-02],
        [ 1.6193e-03, -8.9111e-03,  5.7297e-03,  ..., -3.6011e-03,
          7.5569e-03, -1.3351e-05]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9844, -4.8672,  1.1875,  ..., -0.3828, -8.5781, -1.7100]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 09:03:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I tell, he tells
I explain, he explains
I accept, he accepts
I represent, he represents
I identify, he identifies
I ensure, he ensures
I operate, he operates
I develop, he
2024-07-28 09:03:19 root INFO     [order_1_approx] starting weight calculation for I explain, he explains
I identify, he identifies
I represent, he represents
I operate, he operates
I tell, he tells
I ensure, he ensures
I develop, he develops
I accept, he
2024-07-28 09:03:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 09:06:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1028,  0.4463, -0.1353,  ..., -0.0226, -0.3281,  0.0055],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.9453, -3.1680, -1.5586,  ..., -0.0342, -9.6250,  0.1699],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0006,  0.0086,  0.0131,  ...,  0.0250, -0.0152,  0.0251],
        [-0.0077,  0.0127, -0.0214,  ...,  0.0058,  0.0206,  0.0072],
        [-0.0088,  0.0145,  0.0043,  ..., -0.0264,  0.0072, -0.0049],
        ...,
        [ 0.0019,  0.0117,  0.0092,  ...,  0.0186,  0.0062, -0.0030],
        [-0.0210, -0.0086,  0.0014,  ..., -0.0467,  0.0493, -0.0298],
        [ 0.0023, -0.0089, -0.0052,  ...,  0.0058, -0.0155,  0.0144]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.6406, -3.0410, -1.7207,  ...,  0.2065, -9.9375,  0.0435]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 09:06:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I explain, he explains
I identify, he identifies
I represent, he represents
I operate, he operates
I tell, he tells
I ensure, he ensures
I develop, he develops
I accept, he
2024-07-28 09:06:04 root INFO     [order_1_approx] starting weight calculation for I operate, he operates
I explain, he explains
I identify, he identifies
I tell, he tells
I develop, he develops
I accept, he accepts
I represent, he represents
I ensure, he
2024-07-28 09:06:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 09:08:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0062,  0.3145, -0.2617,  ...,  0.0724, -0.3203, -0.1281],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4082, -2.6367, -0.6992,  ...,  0.1663, -8.3438, -0.6836],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0059,  0.0071,  0.0123,  ...,  0.0243, -0.0116, -0.0083],
        [-0.0143,  0.0045,  0.0258,  ..., -0.0333,  0.0407,  0.0168],
        [-0.0119,  0.0181, -0.0040,  ...,  0.0087, -0.0279,  0.0000],
        ...,
        [ 0.0122, -0.0194,  0.0226,  ..., -0.0120,  0.0071,  0.0349],
        [ 0.0330, -0.0277,  0.0312,  ..., -0.0348,  0.0149,  0.0310],
        [ 0.0359,  0.0280,  0.0518,  ..., -0.0069, -0.0415,  0.0234]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0742, -3.3848, -1.0449,  ...,  0.0186, -9.3203, -1.1904]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 09:08:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I operate, he operates
I explain, he explains
I identify, he identifies
I tell, he tells
I develop, he develops
I accept, he accepts
I represent, he represents
I ensure, he
2024-07-28 09:08:48 root INFO     total operator prediction time: 1316.8338873386383 seconds
2024-07-28 09:08:48 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_Ving - 3pSg
2024-07-28 09:08:48 root INFO     building operator verb_Ving - 3pSg
2024-07-28 09:08:48 root INFO     [order_1_approx] starting weight calculation for When something is performing, it performs
When something is providing, it provides
When something is reducing, it reduces
When something is containing, it contains
When something is referring, it refers
When something is depending, it depends
When something is asking, it asks
When something is creating, it
2024-07-28 09:08:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 09:11:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0089,  0.2379, -0.0579,  ...,  0.0620,  0.0547, -0.2385],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8354, -3.7871,  1.5469,  ...,  0.5850, -6.5547,  0.1016],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0388,  0.0139,  0.0075,  ...,  0.0193,  0.0034,  0.0077],
        [ 0.0039,  0.0500,  0.0032,  ...,  0.0047, -0.0034, -0.0207],
        [-0.0034, -0.0214,  0.0241,  ...,  0.0073, -0.0008, -0.0039],
        ...,
        [ 0.0256,  0.0246,  0.0301,  ...,  0.0177, -0.0108, -0.0009],
        [ 0.0085,  0.0004, -0.0142,  ..., -0.0255,  0.0274, -0.0222],
        [-0.0191,  0.0003, -0.0022,  ..., -0.0175, -0.0106,  0.0127]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1963, -3.5605,  1.4404,  ...,  0.5488, -7.6250, -0.0621]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 09:11:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is performing, it performs
When something is providing, it provides
When something is reducing, it reduces
When something is containing, it contains
When something is referring, it refers
When something is depending, it depends
When something is asking, it asks
When something is creating, it
2024-07-28 09:11:33 root INFO     [order_1_approx] starting weight calculation for When something is containing, it contains
When something is depending, it depends
When something is performing, it performs
When something is creating, it creates
When something is referring, it refers
When something is reducing, it reduces
When something is providing, it provides
When something is asking, it
2024-07-28 09:11:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 09:14:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0891,  0.1986, -0.1340,  ...,  0.1515, -0.0209, -0.3350],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3086, -3.0586, -1.2021,  ...,  0.8242, -5.5273, -0.3398],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0213, -0.0126,  0.0086,  ...,  0.0048,  0.0002,  0.0117],
        [-0.0022,  0.0434,  0.0065,  ...,  0.0281, -0.0134,  0.0002],
        [ 0.0058,  0.0034,  0.0342,  ...,  0.0159,  0.0142, -0.0220],
        ...,
        [ 0.0052,  0.0086,  0.0227,  ...,  0.0277, -0.0139, -0.0006],
        [-0.0130,  0.0149, -0.0331,  ..., -0.0296,  0.0140, -0.0074],
        [-0.0279,  0.0058,  0.0165,  ..., -0.0180, -0.0139,  0.0031]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6836, -3.0273, -1.0498,  ...,  1.1094, -5.6055, -0.4648]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 09:14:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is containing, it contains
When something is depending, it depends
When something is performing, it performs
When something is creating, it creates
When something is referring, it refers
When something is reducing, it reduces
When something is providing, it provides
When something is asking, it
2024-07-28 09:14:17 root INFO     [order_1_approx] starting weight calculation for When something is providing, it provides
When something is creating, it creates
When something is asking, it asks
When something is reducing, it reduces
When something is depending, it depends
When something is performing, it performs
When something is referring, it refers
When something is containing, it
2024-07-28 09:14:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 09:17:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0011, -0.0703, -0.0800,  ...,  0.0352, -0.3555, -0.2825],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9033, -2.5488,  1.1836,  ..., -1.8457, -4.3281, -2.1641],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0404,  0.0296, -0.0014,  ...,  0.0123, -0.0206,  0.0275],
        [-0.0222,  0.0541,  0.0141,  ..., -0.0051, -0.0089,  0.0184],
        [-0.0022, -0.0178,  0.0118,  ..., -0.0439,  0.0049, -0.0367],
        ...,
        [-0.0019,  0.0298,  0.0256,  ...,  0.0161,  0.0068, -0.0012],
        [ 0.0306, -0.0435, -0.0429,  ..., -0.0219,  0.0188, -0.0303],
        [ 0.0266,  0.0078,  0.0049,  ..., -0.0142, -0.0424, -0.0233]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8618, -2.8184,  1.2764,  ..., -2.0938, -3.4512, -2.2422]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 09:17:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is providing, it provides
When something is creating, it creates
When something is asking, it asks
When something is reducing, it reduces
When something is depending, it depends
When something is performing, it performs
When something is referring, it refers
When something is containing, it
2024-07-28 09:17:01 root INFO     [order_1_approx] starting weight calculation for When something is referring, it refers
When something is performing, it performs
When something is providing, it provides
When something is reducing, it reduces
When something is creating, it creates
When something is asking, it asks
When something is containing, it contains
When something is depending, it
2024-07-28 09:17:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 09:19:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1661,  0.1122, -0.0677,  ..., -0.1592, -0.1147,  0.1361],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.2578, -0.5400,  1.9434,  ..., -1.5801, -5.2344, -0.2227],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0145,  0.0441, -0.0417,  ..., -0.0088, -0.0057, -0.0173],
        [-0.0126,  0.0468, -0.0327,  ...,  0.0424, -0.0127,  0.0363],
        [-0.0004,  0.0322,  0.0245,  ..., -0.0247, -0.0230, -0.0053],
        ...,
        [ 0.0265,  0.0029,  0.0306,  ...,  0.0170,  0.0040,  0.0072],
        [ 0.0284, -0.0203,  0.0457,  ..., -0.0353,  0.0219,  0.0129],
        [-0.0036, -0.0039,  0.0163,  ..., -0.0077, -0.0362,  0.0324]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.2461, -1.1562,  1.9189,  ..., -1.2178, -4.4258, -0.5708]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 09:19:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is referring, it refers
When something is performing, it performs
When something is providing, it provides
When something is reducing, it reduces
When something is creating, it creates
When something is asking, it asks
When something is containing, it contains
When something is depending, it
2024-07-28 09:19:47 root INFO     [order_1_approx] starting weight calculation for When something is performing, it performs
When something is containing, it contains
When something is providing, it provides
When something is depending, it depends
When something is reducing, it reduces
When something is creating, it creates
When something is asking, it asks
When something is referring, it
2024-07-28 09:19:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 09:22:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2524,  0.0598, -0.0674,  ...,  0.0771, -0.1815, -0.1295],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2866, -4.1445,  1.9580,  ...,  1.7168, -5.8242, -1.5049],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0391,  0.0053,  0.0009,  ...,  0.0144,  0.0236,  0.0032],
        [-0.0171,  0.0527,  0.0403,  ..., -0.0181, -0.0224,  0.0017],
        [-0.0187, -0.0164,  0.0384,  ..., -0.0312, -0.0082, -0.0130],
        ...,
        [ 0.0225,  0.0182,  0.0153,  ...,  0.0598, -0.0036,  0.0224],
        [ 0.0169, -0.0262,  0.0082,  ..., -0.0497,  0.0222, -0.0366],
        [ 0.0086,  0.0123,  0.0168,  ..., -0.0272, -0.0226,  0.0241]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3181, -4.2266,  1.7188,  ...,  1.8213, -5.4805, -1.9082]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 09:22:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is performing, it performs
When something is containing, it contains
When something is providing, it provides
When something is depending, it depends
When something is reducing, it reduces
When something is creating, it creates
When something is asking, it asks
When something is referring, it
2024-07-28 09:22:31 root INFO     [order_1_approx] starting weight calculation for When something is depending, it depends
When something is containing, it contains
When something is creating, it creates
When something is asking, it asks
When something is performing, it performs
When something is reducing, it reduces
When something is referring, it refers
When something is providing, it
2024-07-28 09:22:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 09:25:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1175,  0.0543,  0.0064,  ..., -0.0261, -0.0698, -0.1741],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8838, -6.0547,  0.2715,  ..., -0.6240, -6.9141, -0.2871],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0144,  0.0103,  0.0055,  ..., -0.0167,  0.0097,  0.0205],
        [ 0.0168,  0.0192,  0.0426,  ...,  0.0334, -0.0201,  0.0378],
        [-0.0211, -0.0067,  0.0203,  ..., -0.0104, -0.0061, -0.0259],
        ...,
        [ 0.0044,  0.0084,  0.0248,  ...,  0.0479, -0.0028,  0.0087],
        [ 0.0039, -0.0155, -0.0312,  ..., -0.0457,  0.0291, -0.0519],
        [ 0.0022, -0.0110,  0.0014,  ..., -0.0374, -0.0206,  0.0174]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3848, -5.4180,  0.4438,  ..., -0.6118, -6.9453, -0.8228]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 09:25:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is depending, it depends
When something is containing, it contains
When something is creating, it creates
When something is asking, it asks
When something is performing, it performs
When something is reducing, it reduces
When something is referring, it refers
When something is providing, it
2024-07-28 09:25:15 root INFO     [order_1_approx] starting weight calculation for When something is containing, it contains
When something is creating, it creates
When something is asking, it asks
When something is depending, it depends
When something is referring, it refers
When something is providing, it provides
When something is performing, it performs
When something is reducing, it
2024-07-28 09:25:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 09:27:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1189,  0.0117, -0.0989,  ..., -0.0143,  0.0594, -0.0695],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8496, -1.9980,  0.0645,  ..., -2.9219, -6.0508, -4.1328],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0486,  0.0006,  0.0212,  ...,  0.0311,  0.0022,  0.0358],
        [ 0.0089,  0.0518, -0.0014,  ...,  0.0312, -0.0130,  0.0232],
        [-0.0306, -0.0038,  0.0139,  ..., -0.0063,  0.0042, -0.0183],
        ...,
        [ 0.0513,  0.0035, -0.0018,  ...,  0.0096, -0.0385,  0.0005],
        [-0.0138, -0.0231, -0.0055,  ..., -0.0366,  0.0451, -0.0577],
        [-0.0165,  0.0293, -0.0012,  ..., -0.0072, -0.0273,  0.0122]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8159, -1.5264,  0.2123,  ..., -2.5898, -6.1797, -4.2617]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 09:27:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is containing, it contains
When something is creating, it creates
When something is asking, it asks
When something is depending, it depends
When something is referring, it refers
When something is providing, it provides
When something is performing, it performs
When something is reducing, it
2024-07-28 09:27:59 root INFO     [order_1_approx] starting weight calculation for When something is referring, it refers
When something is reducing, it reduces
When something is creating, it creates
When something is asking, it asks
When something is depending, it depends
When something is providing, it provides
When something is containing, it contains
When something is performing, it
2024-07-28 09:27:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 09:30:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1049,  0.1938, -0.0400,  ..., -0.0734, -0.0737, -0.1469],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0605, -4.8750,  1.1016,  ..., -0.6177, -6.2773, -2.7539],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0128,  0.0130,  0.0028,  ..., -0.0039,  0.0159,  0.0066],
        [ 0.0024,  0.0434, -0.0083,  ...,  0.0484,  0.0236,  0.0076],
        [-0.0402,  0.0329, -0.0225,  ..., -0.0215,  0.0135,  0.0092],
        ...,
        [ 0.0064,  0.0123,  0.0023,  ...,  0.0378,  0.0029,  0.0094],
        [ 0.0034, -0.0082,  0.0110,  ..., -0.0222,  0.0110, -0.0230],
        [ 0.0024,  0.0081, -0.0023,  ...,  0.0067, -0.0172, -0.0115]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7822, -3.8633,  1.0830,  ..., -0.9990, -6.3008, -3.0156]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 09:30:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is referring, it refers
When something is reducing, it reduces
When something is creating, it creates
When something is asking, it asks
When something is depending, it depends
When something is providing, it provides
When something is containing, it contains
When something is performing, it
2024-07-28 09:30:44 root INFO     total operator prediction time: 1315.5587167739868 seconds
2024-07-28 09:30:44 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun - plural_reg
2024-07-28 09:30:44 root INFO     building operator noun - plural_reg
2024-07-28 09:30:44 root INFO     [order_1_approx] starting weight calculation for The plural form of product is products
The plural form of event is events
The plural form of office is offices
The plural form of difference is differences
The plural form of week is weeks
The plural form of website is websites
The plural form of year is years
The plural form of area is
2024-07-28 09:30:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 09:33:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0908, -0.0280, -0.0170,  ...,  0.3472, -0.0038,  0.0372],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2910, -3.9121,  2.4980,  ..., -1.9648,  0.4448, -2.8047],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0634, -0.0302, -0.0369,  ...,  0.0137, -0.0265, -0.0016],
        [ 0.0353,  0.0466, -0.0150,  ..., -0.0102, -0.0298, -0.0041],
        [-0.0353,  0.0079,  0.0299,  ...,  0.0275,  0.0004,  0.0282],
        ...,
        [-0.0003, -0.0111,  0.0183,  ...,  0.0331, -0.0203,  0.0118],
        [ 0.0147, -0.0139, -0.0073,  ...,  0.0275,  0.0206, -0.0524],
        [ 0.0269, -0.0086,  0.0021,  ...,  0.0317, -0.0403,  0.0117]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5068, -4.4180,  2.4609,  ..., -2.2402,  0.0872, -2.8477]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 09:33:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of product is products
The plural form of event is events
The plural form of office is offices
The plural form of difference is differences
The plural form of week is weeks
The plural form of website is websites
The plural form of year is years
The plural form of area is
2024-07-28 09:33:30 root INFO     [order_1_approx] starting weight calculation for The plural form of office is offices
The plural form of product is products
The plural form of website is websites
The plural form of year is years
The plural form of event is events
The plural form of week is weeks
The plural form of area is areas
The plural form of difference is
2024-07-28 09:33:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 09:36:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0393, -0.2107,  0.1970,  ..., -0.0204,  0.1062,  0.2178],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1582, -0.5347,  3.7461,  ..., -3.5039, -3.0801, -2.1641],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0731, -0.0198,  0.0164,  ...,  0.0394, -0.0253,  0.0340],
        [-0.0049,  0.0399,  0.0137,  ...,  0.0147,  0.0174,  0.0045],
        [-0.0183, -0.0092,  0.0302,  ..., -0.0099, -0.0100,  0.0306],
        ...,
        [-0.0089,  0.0068,  0.0251,  ...,  0.0191,  0.0001,  0.0126],
        [-0.0082, -0.0201, -0.0343,  ..., -0.0355, -0.0016, -0.0461],
        [ 0.0373,  0.0016, -0.0067,  ...,  0.0465, -0.0221,  0.0410]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8242, -1.0957,  3.1934,  ..., -3.9961, -3.5332, -1.7754]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 09:36:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of office is offices
The plural form of product is products
The plural form of website is websites
The plural form of year is years
The plural form of event is events
The plural form of week is weeks
The plural form of area is areas
The plural form of difference is
2024-07-28 09:36:11 root INFO     [order_1_approx] starting weight calculation for The plural form of area is areas
The plural form of difference is differences
The plural form of website is websites
The plural form of product is products
The plural form of event is events
The plural form of year is years
The plural form of week is weeks
The plural form of office is
2024-07-28 09:36:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 09:38:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0204,  0.0139, -0.0360,  ...,  0.1531, -0.1641, -0.1032],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8926, -3.3242,  1.5088,  ..., -0.3696,  0.4417, -1.2598],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.4992e-02, -1.0345e-02, -1.8112e-02,  ..., -8.6823e-03,
          2.0462e-02,  2.8992e-02],
        [ 9.0408e-03,  1.1620e-02, -1.5327e-02,  ..., -8.2855e-03,
         -2.0569e-02, -2.8725e-03],
        [-1.6518e-03,  1.9073e-05, -4.1046e-03,  ..., -2.6417e-03,
         -8.9645e-04,  8.7280e-03],
        ...,
        [ 2.1915e-03, -5.6763e-03,  1.7441e-02,  ...,  1.4557e-02,
         -1.6373e-02,  2.8488e-02],
        [-1.7410e-02, -8.9188e-03, -2.5574e-02,  ...,  9.1248e-03,
          8.2169e-03, -3.1738e-03],
        [-5.8250e-03, -6.5498e-03, -6.8665e-03,  ...,  2.3819e-02,
         -2.2903e-02,  1.7792e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5967, -3.4863,  1.2793,  ..., -0.9990,  0.6719, -0.8887]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 09:38:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of area is areas
The plural form of difference is differences
The plural form of website is websites
The plural form of product is products
The plural form of event is events
The plural form of year is years
The plural form of week is weeks
The plural form of office is
2024-07-28 09:38:57 root INFO     [order_1_approx] starting weight calculation for The plural form of year is years
The plural form of office is offices
The plural form of difference is differences
The plural form of website is websites
The plural form of week is weeks
The plural form of area is areas
The plural form of product is products
The plural form of event is
2024-07-28 09:38:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 09:41:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1104,  0.2766,  0.1775,  ..., -0.1946, -0.0327, -0.2039],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-5.7080e-01, -1.6787e+00, -4.8828e-04,  ...,  2.5024e-02,
        -1.5449e+00, -2.5273e+00], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0294, -0.0061,  0.0104,  ...,  0.0042,  0.0003, -0.0016],
        [-0.0017,  0.0285,  0.0113,  ...,  0.0029, -0.0210,  0.0033],
        [-0.0031,  0.0114, -0.0094,  ..., -0.0046,  0.0078,  0.0081],
        ...,
        [-0.0027,  0.0058,  0.0062,  ...,  0.0184, -0.0006,  0.0007],
        [-0.0118, -0.0100, -0.0189,  ..., -0.0029,  0.0284, -0.0033],
        [ 0.0128, -0.0043, -0.0054,  ...,  0.0110,  0.0046,  0.0084]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1885, -1.8057,  0.1813,  ...,  0.1805, -1.4424, -2.4746]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 09:41:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of year is years
The plural form of office is offices
The plural form of difference is differences
The plural form of website is websites
The plural form of week is weeks
The plural form of area is areas
The plural form of product is products
The plural form of event is
2024-07-28 09:41:42 root INFO     [order_1_approx] starting weight calculation for The plural form of product is products
The plural form of event is events
The plural form of area is areas
The plural form of difference is differences
The plural form of year is years
The plural form of office is offices
The plural form of week is weeks
The plural form of website is
2024-07-28 09:41:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 09:44:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1887, -0.0042,  0.0336,  ...,  0.0956, -0.1351,  0.1381],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2324, -2.9727,  1.3418,  ...,  0.6035, -0.6865, -0.8516],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0101, -0.0391,  0.0079,  ...,  0.0214, -0.0003,  0.0257],
        [-0.0199,  0.0316,  0.0178,  ...,  0.0036, -0.0287, -0.0082],
        [ 0.0314,  0.0041, -0.0004,  ..., -0.0043,  0.0068,  0.0328],
        ...,
        [-0.0061, -0.0058,  0.0657,  ...,  0.0216, -0.0288,  0.0150],
        [ 0.0263, -0.0126, -0.0387,  ...,  0.0078,  0.0190,  0.0127],
        [ 0.0107, -0.0012,  0.0145,  ...,  0.0056, -0.0268,  0.0040]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8052, -3.3691,  1.4346,  ...,  0.6963, -0.3159, -0.4915]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 09:44:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of product is products
The plural form of event is events
The plural form of area is areas
The plural form of difference is differences
The plural form of year is years
The plural form of office is offices
The plural form of week is weeks
The plural form of website is
2024-07-28 09:44:28 root INFO     [order_1_approx] starting weight calculation for The plural form of area is areas
The plural form of office is offices
The plural form of difference is differences
The plural form of event is events
The plural form of product is products
The plural form of week is weeks
The plural form of website is websites
The plural form of year is
2024-07-28 09:44:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 09:47:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2139,  0.0946,  0.0630,  ..., -0.1523, -0.2690,  0.0767],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2090, -4.8594,  2.1250,  ..., -1.9639, -0.4482, -4.1094],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0302,  0.0008,  0.0183,  ..., -0.0055, -0.0250, -0.0024],
        [ 0.0004,  0.0228, -0.0087,  ..., -0.0087, -0.0198, -0.0143],
        [ 0.0124,  0.0054,  0.0132,  ...,  0.0057, -0.0164,  0.0284],
        ...,
        [-0.0256,  0.0276,  0.0054,  ...,  0.0216,  0.0158,  0.0002],
        [-0.0075,  0.0047, -0.0164,  ...,  0.0310,  0.0202,  0.0022],
        [-0.0036, -0.0168, -0.0293,  ...,  0.0036, -0.0225,  0.0033]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1689, -4.9336,  1.9668,  ..., -1.9668, -0.3855, -3.8438]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 09:47:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of area is areas
The plural form of office is offices
The plural form of difference is differences
The plural form of event is events
The plural form of product is products
The plural form of week is weeks
The plural form of website is websites
The plural form of year is
2024-07-28 09:47:13 root INFO     [order_1_approx] starting weight calculation for The plural form of year is years
The plural form of area is areas
The plural form of difference is differences
The plural form of website is websites
The plural form of office is offices
The plural form of event is events
The plural form of product is products
The plural form of week is
2024-07-28 09:47:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 09:49:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3667,  0.0577,  0.2979,  ...,  0.0347, -0.2456,  0.1674],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2832, -4.3203,  0.2095,  ..., -0.6465,  0.7129, -1.7852],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0072,  0.0162, -0.0205,  ...,  0.0144,  0.0009,  0.0123],
        [ 0.0066,  0.0139, -0.0173,  ..., -0.0143, -0.0074, -0.0284],
        [-0.0047, -0.0018,  0.0075,  ..., -0.0032, -0.0036,  0.0600],
        ...,
        [-0.0045,  0.0085,  0.0191,  ...,  0.0194, -0.0285,  0.0059],
        [ 0.0014, -0.0238, -0.0263,  ...,  0.0322,  0.0234, -0.0177],
        [ 0.0036, -0.0154, -0.0030,  ...,  0.0098, -0.0154, -0.0025]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2080, -4.2109,  0.5664,  ..., -0.7085,  0.7529, -1.3906]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 09:49:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of year is years
The plural form of area is areas
The plural form of difference is differences
The plural form of website is websites
The plural form of office is offices
The plural form of event is events
The plural form of product is products
The plural form of week is
2024-07-28 09:49:57 root INFO     [order_1_approx] starting weight calculation for The plural form of website is websites
The plural form of year is years
The plural form of area is areas
The plural form of event is events
The plural form of office is offices
The plural form of difference is differences
The plural form of week is weeks
The plural form of product is
2024-07-28 09:49:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 09:52:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1005, -0.1725,  0.1017,  ..., -0.0471, -0.1271, -0.0059],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4419, -3.6875,  0.4155,  ..., -1.2539, -0.9302, -0.7617],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0352, -0.0285, -0.0089,  ..., -0.0026,  0.0205,  0.0172],
        [ 0.0169,  0.0251,  0.0204,  ..., -0.0070, -0.0293,  0.0028],
        [ 0.0110,  0.0233,  0.0035,  ...,  0.0155,  0.0303,  0.0109],
        ...,
        [-0.0024, -0.0135,  0.0313,  ...,  0.0139,  0.0010,  0.0161],
        [-0.0251,  0.0034, -0.0195,  ...,  0.0075,  0.0330, -0.0246],
        [-0.0188, -0.0174, -0.0156,  ...,  0.0045, -0.0220,  0.0324]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0908, -3.7637,  1.1504,  ..., -1.1953, -0.7065, -1.2207]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 09:52:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of website is websites
The plural form of year is years
The plural form of area is areas
The plural form of event is events
The plural form of office is offices
The plural form of difference is differences
The plural form of week is weeks
The plural form of product is
2024-07-28 09:52:42 root INFO     total operator prediction time: 1317.8908333778381 seconds
2024-07-28 09:52:42 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_3pSg - Ved
2024-07-28 09:52:42 root INFO     building operator verb_3pSg - Ved
2024-07-28 09:52:42 root INFO     [order_1_approx] starting weight calculation for When he requires something, something has been required
When he suggests something, something has been suggested
When he occurs something, something has been occurred
When he involves something, something has been involved
When he replaces something, something has been replaced
When he receives something, something has been received
When he hears something, something has been heard
When he asks something, something has been
2024-07-28 09:52:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 09:55:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1018,  0.2142, -0.0089,  ...,  0.0505, -0.2139, -0.3525],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3496, -1.2949,  0.2812,  ...,  1.3457, -3.8633, -0.5215],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0211,  0.0018,  0.0077,  ..., -0.0260,  0.0247,  0.0077],
        [ 0.0073,  0.0095, -0.0064,  ...,  0.0211, -0.0207,  0.0074],
        [ 0.0064, -0.0207,  0.0199,  ...,  0.0107, -0.0110,  0.0096],
        ...,
        [-0.0015,  0.0212,  0.0021,  ...,  0.0065,  0.0108, -0.0027],
        [ 0.0084,  0.0041, -0.0147,  ..., -0.0126,  0.0029, -0.0158],
        [-0.0068,  0.0059,  0.0296,  ..., -0.0109, -0.0071, -0.0186]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4922, -1.6387,  0.3794,  ...,  1.4912, -4.1328, -0.5024]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 09:55:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he requires something, something has been required
When he suggests something, something has been suggested
When he occurs something, something has been occurred
When he involves something, something has been involved
When he replaces something, something has been replaced
When he receives something, something has been received
When he hears something, something has been heard
When he asks something, something has been
2024-07-28 09:55:25 root INFO     [order_1_approx] starting weight calculation for When he receives something, something has been received
When he asks something, something has been asked
When he suggests something, something has been suggested
When he requires something, something has been required
When he replaces something, something has been replaced
When he involves something, something has been involved
When he occurs something, something has been occurred
When he hears something, something has been
2024-07-28 09:55:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 09:58:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3071,  0.2910,  0.1478,  ...,  0.0704, -0.1823,  0.1448],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2109,  1.2402,  2.0508,  ...,  1.1387, -5.2266, -3.0312],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0238,  0.0030,  0.0099,  ..., -0.0040,  0.0076,  0.0113],
        [-0.0146,  0.0405,  0.0168,  ...,  0.0083, -0.0056, -0.0111],
        [ 0.0155,  0.0004,  0.0042,  ...,  0.0104,  0.0046, -0.0105],
        ...,
        [ 0.0154,  0.0101,  0.0030,  ..., -0.0031,  0.0015,  0.0013],
        [ 0.0091, -0.0259, -0.0170,  ...,  0.0064,  0.0161, -0.0009],
        [-0.0375,  0.0325,  0.0081,  ...,  0.0052,  0.0245, -0.0133]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6460,  1.1289,  2.1777,  ...,  1.2393, -4.7344, -3.4688]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 09:58:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he receives something, something has been received
When he asks something, something has been asked
When he suggests something, something has been suggested
When he requires something, something has been required
When he replaces something, something has been replaced
When he involves something, something has been involved
When he occurs something, something has been occurred
When he hears something, something has been
2024-07-28 09:58:10 root INFO     [order_1_approx] starting weight calculation for When he suggests something, something has been suggested
When he occurs something, something has been occurred
When he requires something, something has been required
When he involves something, something has been involved
When he asks something, something has been asked
When he replaces something, something has been replaced
When he hears something, something has been heard
When he receives something, something has been
2024-07-28 09:58:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 10:00:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0850,  0.2307, -0.0688,  ..., -0.0769, -0.2013, -0.1326],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2480,  0.2002, -0.0522,  ..., -1.7793, -2.9395, -2.0723],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0159, -0.0139,  0.0110,  ..., -0.0014,  0.0233,  0.0707],
        [-0.0480,  0.0206, -0.0012,  ...,  0.0036, -0.0131, -0.0137],
        [ 0.0359,  0.0011, -0.0235,  ..., -0.0304, -0.0095, -0.0375],
        ...,
        [ 0.0275, -0.0051,  0.0158,  ...,  0.0141,  0.0302,  0.0287],
        [ 0.0239, -0.0022,  0.0007,  ..., -0.0268,  0.0232, -0.0183],
        [ 0.0003, -0.0123,  0.0003,  ..., -0.0052,  0.0120, -0.0087]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0840,  0.1260, -0.0808,  ..., -1.7861, -3.3066, -2.1758]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 10:00:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he suggests something, something has been suggested
When he occurs something, something has been occurred
When he requires something, something has been required
When he involves something, something has been involved
When he asks something, something has been asked
When he replaces something, something has been replaced
When he hears something, something has been heard
When he receives something, something has been
2024-07-28 10:00:54 root INFO     [order_1_approx] starting weight calculation for When he replaces something, something has been replaced
When he asks something, something has been asked
When he occurs something, something has been occurred
When he involves something, something has been involved
When he suggests something, something has been suggested
When he receives something, something has been received
When he hears something, something has been heard
When he requires something, something has been
2024-07-28 10:00:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 10:03:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1473, -0.0020, -0.0989,  ...,  0.1091, -0.0792, -0.2146],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7002,  1.1934,  1.7285,  ..., -1.0703, -4.0391, -1.9814],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0018, -0.0082,  0.0315,  ...,  0.0527,  0.0916, -0.0112],
        [-0.0406,  0.0297, -0.0073,  ..., -0.0189, -0.0111, -0.0002],
        [ 0.0136,  0.0135, -0.0105,  ..., -0.0447, -0.0375, -0.0033],
        ...,
        [-0.0065, -0.0256,  0.0248,  ...,  0.0385,  0.0614,  0.0386],
        [ 0.0224, -0.0067, -0.0128,  ..., -0.0419, -0.0498, -0.0097],
        [-0.0205,  0.0088,  0.0161,  ..., -0.0233, -0.0334,  0.0274]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3838,  0.7500,  1.3848,  ..., -1.4717, -3.8555, -1.8994]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 10:03:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he replaces something, something has been replaced
When he asks something, something has been asked
When he occurs something, something has been occurred
When he involves something, something has been involved
When he suggests something, something has been suggested
When he receives something, something has been received
When he hears something, something has been heard
When he requires something, something has been
2024-07-28 10:03:39 root INFO     [order_1_approx] starting weight calculation for When he requires something, something has been required
When he involves something, something has been involved
When he hears something, something has been heard
When he receives something, something has been received
When he replaces something, something has been replaced
When he occurs something, something has been occurred
When he asks something, something has been asked
When he suggests something, something has been
2024-07-28 10:03:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 10:06:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0096,  0.2288,  0.2324,  ...,  0.2468, -0.2000, -0.0985],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 7.7422,  0.1943, -0.3135,  ...,  2.8379, -2.2344, -2.3789],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0480, -0.0063, -0.0077,  ..., -0.0125, -0.0177, -0.0171],
        [ 0.0025,  0.0352, -0.0050,  ...,  0.0193,  0.0202, -0.0037],
        [ 0.0043,  0.0012, -0.0056,  ...,  0.0013,  0.0104,  0.0088],
        ...,
        [-0.0004,  0.0272,  0.0026,  ...,  0.0255,  0.0209,  0.0022],
        [-0.0120, -0.0112, -0.0130,  ..., -0.0583, -0.0180, -0.0094],
        [ 0.0041,  0.0123,  0.0236,  ..., -0.0258, -0.0085,  0.0026]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 7.0156,  0.0458, -0.1503,  ...,  2.4707, -2.1035, -2.5293]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 10:06:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he requires something, something has been required
When he involves something, something has been involved
When he hears something, something has been heard
When he receives something, something has been received
When he replaces something, something has been replaced
When he occurs something, something has been occurred
When he asks something, something has been asked
When he suggests something, something has been
2024-07-28 10:06:25 root INFO     [order_1_approx] starting weight calculation for When he receives something, something has been received
When he hears something, something has been heard
When he suggests something, something has been suggested
When he requires something, something has been required
When he occurs something, something has been occurred
When he asks something, something has been asked
When he replaces something, something has been replaced
When he involves something, something has been
2024-07-28 10:06:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 10:09:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1146, -0.2268, -0.0746,  ...,  0.1604, -0.2500, -0.1633],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4473,  1.5664,  2.8906,  ...,  1.1299,  0.6377, -3.9727],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0323,  0.0002, -0.0172,  ...,  0.0015,  0.0063,  0.0188],
        [-0.0659,  0.0438,  0.0371,  ...,  0.0364, -0.0281, -0.0456],
        [-0.0007, -0.0160, -0.0017,  ...,  0.0021, -0.0046, -0.0175],
        ...,
        [ 0.0532,  0.0507, -0.0478,  ...,  0.0307,  0.0481,  0.0362],
        [-0.0076,  0.0062, -0.0221,  ...,  0.0281, -0.0428, -0.0298],
        [-0.0043,  0.0565,  0.0133,  ...,  0.0582, -0.0101,  0.0037]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4771,  0.9360,  2.5410,  ...,  0.8018,  0.4133, -4.1445]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 10:09:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he receives something, something has been received
When he hears something, something has been heard
When he suggests something, something has been suggested
When he requires something, something has been required
When he occurs something, something has been occurred
When he asks something, something has been asked
When he replaces something, something has been replaced
When he involves something, something has been
2024-07-28 10:09:10 root INFO     [order_1_approx] starting weight calculation for When he asks something, something has been asked
When he occurs something, something has been occurred
When he involves something, something has been involved
When he receives something, something has been received
When he suggests something, something has been suggested
When he requires something, something has been required
When he hears something, something has been heard
When he replaces something, something has been
2024-07-28 10:09:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 10:11:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0310,  0.0471, -0.2634,  ...,  0.0999, -0.1583,  0.1473],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7539, -0.1132,  0.3838,  ...,  0.5273, -1.9219, -0.5938],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0321,  0.0068, -0.0033,  ...,  0.0100,  0.0190,  0.0502],
        [-0.0156,  0.0012, -0.0079,  ..., -0.0086, -0.0388,  0.0229],
        [ 0.0323,  0.0095, -0.0216,  ..., -0.0257,  0.0137, -0.0184],
        ...,
        [ 0.0240,  0.0089,  0.0053,  ...,  0.0212, -0.0011,  0.0305],
        [ 0.0177,  0.0006, -0.0006,  ..., -0.0119,  0.0006, -0.0064],
        [ 0.0224, -0.0053,  0.0105,  ..., -0.0029, -0.0180,  0.0011]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3252, -0.4116,  0.4551,  ...,  0.2537, -2.0254, -0.4895]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 10:11:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he asks something, something has been asked
When he occurs something, something has been occurred
When he involves something, something has been involved
When he receives something, something has been received
When he suggests something, something has been suggested
When he requires something, something has been required
When he hears something, something has been heard
When he replaces something, something has been
2024-07-28 10:11:56 root INFO     [order_1_approx] starting weight calculation for When he receives something, something has been received
When he suggests something, something has been suggested
When he requires something, something has been required
When he involves something, something has been involved
When he asks something, something has been asked
When he hears something, something has been heard
When he replaces something, something has been replaced
When he occurs something, something has been
2024-07-28 10:11:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 10:14:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3633,  0.1526, -0.0392,  ...,  0.0286, -0.0597, -0.5347],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3872,  1.6973,  2.4473,  ..., -0.3433, -1.4688,  2.1289],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0294, -0.0037,  0.0301,  ..., -0.0090,  0.0308,  0.0248],
        [-0.0262,  0.0292, -0.0094,  ...,  0.0104,  0.0052, -0.0052],
        [ 0.0054, -0.0372, -0.0153,  ..., -0.0095, -0.0035,  0.0018],
        ...,
        [ 0.0118, -0.0091,  0.0405,  ...,  0.0054,  0.0222,  0.0302],
        [ 0.0195, -0.0119, -0.0223,  ..., -0.0336,  0.0009, -0.0157],
        [ 0.0043,  0.0397,  0.0201,  ...,  0.0089,  0.0022,  0.0352]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6211,  0.9565,  2.5039,  ..., -0.4197, -1.4541,  2.1719]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 10:14:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he receives something, something has been received
When he suggests something, something has been suggested
When he requires something, something has been required
When he involves something, something has been involved
When he asks something, something has been asked
When he hears something, something has been heard
When he replaces something, something has been replaced
When he occurs something, something has been
2024-07-28 10:14:41 root INFO     total operator prediction time: 1319.633502960205 seconds
2024-07-28 10:14:41 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj - superlative
2024-07-28 10:14:41 root INFO     building operator adj - superlative
2024-07-28 10:14:42 root INFO     [order_1_approx] starting weight calculation for If something is the most tiny, it is tiniest
If something is the most tasty, it is tastiest
If something is the most weird, it is weirdest
If something is the most cute, it is cutest
If something is the most strange, it is strangest
If something is the most clever, it is cleverest
If something is the most pure, it is purest
If something is the most happy, it is
2024-07-28 10:14:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 10:17:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1362, -0.0409, -0.2445,  ..., -0.0657, -0.3008, -0.0783],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1104, -3.3789,  0.1299,  ...,  0.1299, -1.9229, -1.3643],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0069, -0.0177,  0.0117,  ...,  0.0096,  0.0429,  0.0262],
        [-0.0109,  0.0095,  0.0140,  ...,  0.0041,  0.0040,  0.0131],
        [ 0.0008, -0.0395,  0.0192,  ...,  0.0135, -0.0216,  0.0098],
        ...,
        [ 0.0064, -0.0061, -0.0088,  ...,  0.0220,  0.0080, -0.0159],
        [ 0.0076,  0.0058,  0.0201,  ..., -0.0065,  0.0084, -0.0254],
        [ 0.0010, -0.0187,  0.0073,  ...,  0.0282,  0.0013,  0.0041]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1628, -3.4824, -0.1113,  ...,  0.5132, -1.8398, -1.3955]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 10:17:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most tiny, it is tiniest
If something is the most tasty, it is tastiest
If something is the most weird, it is weirdest
If something is the most cute, it is cutest
If something is the most strange, it is strangest
If something is the most clever, it is cleverest
If something is the most pure, it is purest
If something is the most happy, it is
2024-07-28 10:17:26 root INFO     [order_1_approx] starting weight calculation for If something is the most tiny, it is tiniest
If something is the most weird, it is weirdest
If something is the most happy, it is happiest
If something is the most clever, it is cleverest
If something is the most tasty, it is tastiest
If something is the most cute, it is cutest
If something is the most pure, it is purest
If something is the most strange, it is
2024-07-28 10:17:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 10:20:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0815,  0.1095, -0.0225,  ..., -0.0424, -0.1804, -0.0236],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0156, -4.5742, -2.1738,  ..., -1.6465, -0.8623, -2.2539],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0017, -0.0213, -0.0137,  ..., -0.0184,  0.0008,  0.0207],
        [ 0.0121,  0.0034,  0.0201,  ..., -0.0045, -0.0155,  0.0137],
        [-0.0024, -0.0247,  0.0076,  ...,  0.0099, -0.0222,  0.0153],
        ...,
        [-0.0287,  0.0143,  0.0276,  ...,  0.0171,  0.0070, -0.0185],
        [ 0.0040,  0.0106,  0.0135,  ...,  0.0113,  0.0157, -0.0309],
        [ 0.0191,  0.0134, -0.0023,  ...,  0.0093, -0.0245, -0.0134]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7344, -4.6250, -2.1445,  ..., -1.6338, -0.5869, -2.2461]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 10:20:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most tiny, it is tiniest
If something is the most weird, it is weirdest
If something is the most happy, it is happiest
If something is the most clever, it is cleverest
If something is the most tasty, it is tastiest
If something is the most cute, it is cutest
If something is the most pure, it is purest
If something is the most strange, it is
2024-07-28 10:20:11 root INFO     [order_1_approx] starting weight calculation for If something is the most cute, it is cutest
If something is the most strange, it is strangest
If something is the most weird, it is weirdest
If something is the most happy, it is happiest
If something is the most tasty, it is tastiest
If something is the most clever, it is cleverest
If something is the most pure, it is purest
If something is the most tiny, it is
2024-07-28 10:20:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 10:22:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1692, -0.1372, -0.1760,  ..., -0.0714, -0.0644, -0.2429],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.5977,  0.1360, -1.2070,  ..., -4.0625, -2.2422, -1.1611],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0181, -0.0387, -0.0104,  ..., -0.0048,  0.0041,  0.0236],
        [ 0.0171,  0.0360,  0.0021,  ..., -0.0038, -0.0035,  0.0057],
        [ 0.0251,  0.0046,  0.0035,  ..., -0.0208, -0.0475, -0.0066],
        ...,
        [-0.0260,  0.0049, -0.0187,  ...,  0.0382, -0.0079, -0.0141],
        [ 0.0367, -0.0218, -0.0046,  ...,  0.0240,  0.0343, -0.0028],
        [-0.0002,  0.0345,  0.0163,  ...,  0.0071,  0.0003, -0.0014]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.8818,  0.6982, -1.0049,  ..., -3.5469, -1.9111, -1.1455]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 10:22:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most cute, it is cutest
If something is the most strange, it is strangest
If something is the most weird, it is weirdest
If something is the most happy, it is happiest
If something is the most tasty, it is tastiest
If something is the most clever, it is cleverest
If something is the most pure, it is purest
If something is the most tiny, it is
2024-07-28 10:22:53 root INFO     [order_1_approx] starting weight calculation for If something is the most happy, it is happiest
If something is the most tiny, it is tiniest
If something is the most clever, it is cleverest
If something is the most strange, it is strangest
If something is the most cute, it is cutest
If something is the most tasty, it is tastiest
If something is the most weird, it is weirdest
If something is the most pure, it is
2024-07-28 10:22:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 10:25:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0233,  0.1121,  0.1274,  ..., -0.1176, -0.2849, -0.1121],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4707, -3.9141, -2.4629,  ..., -2.4180, -1.1934, -2.3906],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 8.8654e-03, -2.0065e-03,  2.7695e-02,  ..., -2.6520e-02,
         -3.1738e-03, -4.8904e-03],
        [ 4.8103e-03,  7.4043e-03,  2.3239e-02,  ..., -2.3636e-02,
          1.5259e-05,  1.4221e-02],
        [-1.4343e-03, -1.5587e-02,  7.6103e-03,  ...,  2.3712e-02,
         -1.7731e-02,  3.2349e-03],
        ...,
        [ 1.4160e-02,  6.7215e-03, -9.1248e-03,  ...,  7.9346e-04,
          1.0864e-02, -2.6093e-02],
        [ 1.5717e-02, -1.0513e-02, -9.2545e-03,  ...,  5.9891e-03,
          1.8330e-03, -2.7756e-02],
        [-4.9973e-03, -1.5020e-03, -4.9210e-03,  ...,  6.1264e-03,
         -1.4481e-02, -3.8910e-04]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7109, -3.8945, -2.4590,  ..., -2.6484, -1.2402, -2.1211]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 10:25:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most happy, it is happiest
If something is the most tiny, it is tiniest
If something is the most clever, it is cleverest
If something is the most strange, it is strangest
If something is the most cute, it is cutest
If something is the most tasty, it is tastiest
If something is the most weird, it is weirdest
If something is the most pure, it is
2024-07-28 10:25:36 root INFO     [order_1_approx] starting weight calculation for If something is the most strange, it is strangest
If something is the most clever, it is cleverest
If something is the most happy, it is happiest
If something is the most tiny, it is tiniest
If something is the most pure, it is purest
If something is the most tasty, it is tastiest
If something is the most cute, it is cutest
If something is the most weird, it is
2024-07-28 10:25:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 10:28:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1097,  0.0311,  0.2252,  ...,  0.0783, -0.2412,  0.1722],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1621, -5.2031, -1.0244,  ..., -2.5723, -0.4492, -2.5254],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0047, -0.0078,  0.0085,  ..., -0.0257, -0.0071, -0.0166],
        [ 0.0421, -0.0058,  0.0334,  ...,  0.0049, -0.0458,  0.0154],
        [-0.0146, -0.0267,  0.0032,  ..., -0.0277, -0.0247,  0.0028],
        ...,
        [-0.0013, -0.0035, -0.0016,  ...,  0.0313, -0.0083, -0.0151],
        [ 0.0099,  0.0066,  0.0016,  ...,  0.0095,  0.0227, -0.0140],
        [ 0.0149,  0.0332, -0.0067,  ...,  0.0257,  0.0063, -0.0218]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5322, -5.3711, -1.2061,  ..., -2.2949, -0.2910, -2.4199]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 10:28:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most strange, it is strangest
If something is the most clever, it is cleverest
If something is the most happy, it is happiest
If something is the most tiny, it is tiniest
If something is the most pure, it is purest
If something is the most tasty, it is tastiest
If something is the most cute, it is cutest
If something is the most weird, it is
2024-07-28 10:28:21 root INFO     [order_1_approx] starting weight calculation for If something is the most pure, it is purest
If something is the most strange, it is strangest
If something is the most happy, it is happiest
If something is the most cute, it is cutest
If something is the most tiny, it is tiniest
If something is the most tasty, it is tastiest
If something is the most weird, it is weirdest
If something is the most clever, it is
2024-07-28 10:28:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 10:31:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0642,  0.0657,  0.2266,  ..., -0.1730, -0.1011, -0.0909],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.2900, -2.1680, -0.0508,  ..., -2.2031, -0.9072,  1.5674],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0184,  0.0053,  0.0130,  ...,  0.0022,  0.0025,  0.0026],
        [-0.0161, -0.0072,  0.0358,  ...,  0.0042, -0.0015,  0.0291],
        [-0.0071, -0.0200,  0.0354,  ...,  0.0073, -0.0233, -0.0073],
        ...,
        [-0.0035,  0.0046,  0.0022,  ...,  0.0136,  0.0186, -0.0022],
        [ 0.0053,  0.0079,  0.0106,  ..., -0.0223,  0.0240, -0.0205],
        [ 0.0170, -0.0065, -0.0073,  ...,  0.0306, -0.0007, -0.0197]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1348, -2.5410, -0.1632,  ..., -1.5869, -0.9946,  1.4502]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 10:31:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most pure, it is purest
If something is the most strange, it is strangest
If something is the most happy, it is happiest
If something is the most cute, it is cutest
If something is the most tiny, it is tiniest
If something is the most tasty, it is tastiest
If something is the most weird, it is weirdest
If something is the most clever, it is
2024-07-28 10:31:05 root INFO     [order_1_approx] starting weight calculation for If something is the most pure, it is purest
If something is the most weird, it is weirdest
If something is the most happy, it is happiest
If something is the most tiny, it is tiniest
If something is the most cute, it is cutest
If something is the most clever, it is cleverest
If something is the most strange, it is strangest
If something is the most tasty, it is
2024-07-28 10:31:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 10:33:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0898,  0.0188, -0.0694,  ..., -0.2329, -0.4155, -0.4062],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0371, -5.2852, -2.6562,  ..., -1.2607, -6.8359, -2.0859],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0065, -0.0161,  0.0089,  ..., -0.0052,  0.0049,  0.0194],
        [-0.0116,  0.0138, -0.0015,  ..., -0.0077, -0.0116,  0.0160],
        [-0.0034, -0.0209,  0.0097,  ..., -0.0026, -0.0196, -0.0105],
        ...,
        [ 0.0127,  0.0196,  0.0118,  ...,  0.0107,  0.0141, -0.0096],
        [ 0.0049, -0.0050,  0.0149,  ...,  0.0033, -0.0144,  0.0015],
        [-0.0025,  0.0251, -0.0055,  ...,  0.0041, -0.0102,  0.0002]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0645, -5.3867, -2.8574,  ..., -0.9634, -6.6211, -1.9951]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 10:33:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most pure, it is purest
If something is the most weird, it is weirdest
If something is the most happy, it is happiest
If something is the most tiny, it is tiniest
If something is the most cute, it is cutest
If something is the most clever, it is cleverest
If something is the most strange, it is strangest
If something is the most tasty, it is
2024-07-28 10:33:54 root INFO     [order_1_approx] starting weight calculation for If something is the most pure, it is purest
If something is the most happy, it is happiest
If something is the most strange, it is strangest
If something is the most weird, it is weirdest
If something is the most tiny, it is tiniest
If something is the most tasty, it is tastiest
If something is the most clever, it is cleverest
If something is the most cute, it is
2024-07-28 10:33:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 10:36:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1792,  0.1116,  0.1836,  ..., -0.1389, -0.2610, -0.0089],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.8281, -1.9717, -1.5557,  ..., -1.7158,  0.4219,  2.1777],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0015, -0.0228,  0.0190,  ...,  0.0036,  0.0211,  0.0295],
        [ 0.0123,  0.0210,  0.0140,  ...,  0.0016, -0.0163,  0.0199],
        [ 0.0233, -0.0062,  0.0156,  ..., -0.0013, -0.0381, -0.0348],
        ...,
        [-0.0180,  0.0228,  0.0337,  ...,  0.0325,  0.0140, -0.0211],
        [ 0.0135, -0.0224, -0.0005,  ..., -0.0336, -0.0219, -0.0151],
        [ 0.0028,  0.0068,  0.0039,  ...,  0.0161, -0.0338,  0.0013]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.6777, -2.4570, -1.8320,  ..., -1.7559,  0.3765,  1.7793]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 10:36:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most pure, it is purest
If something is the most happy, it is happiest
If something is the most strange, it is strangest
If something is the most weird, it is weirdest
If something is the most tiny, it is tiniest
If something is the most tasty, it is tastiest
If something is the most clever, it is cleverest
If something is the most cute, it is
2024-07-28 10:36:40 root INFO     total operator prediction time: 1318.2175257205963 seconds
2024-07-28 10:36:40 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+er_irreg
2024-07-28 10:36:40 root INFO     building operator verb+er_irreg
2024-07-28 10:36:40 root INFO     [order_1_approx] starting weight calculation for If you achieve something, you are a achiever
If you discover something, you are a discoverer
If you subscribe something, you are a subscriber
If you mourn something, you are a mourner
If you lose something, you are a loser
If you manage something, you are a manager
If you examine something, you are a examiner
If you borrow something, you are a
2024-07-28 10:36:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 10:39:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0846,  0.0521,  0.1350,  ..., -0.1624,  0.2493, -0.2637],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5371, -1.9824, -0.1448,  ..., -1.5840, -1.7617, -4.0586],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.3895e-02, -1.2184e-02,  4.8447e-04,  ...,  3.3905e-02,
          3.4821e-02,  1.6495e-02],
        [-4.1016e-02,  4.2603e-02,  9.5596e-03,  ..., -1.4977e-02,
         -8.4763e-03, -2.5604e-02],
        [-1.2482e-02, -1.9302e-02,  3.5767e-02,  ..., -9.5673e-03,
          7.2289e-03,  2.2720e-02],
        ...,
        [ 2.1057e-02,  5.0812e-03, -1.4084e-02,  ...,  1.1948e-02,
         -9.1553e-05, -1.3512e-02],
        [-1.3504e-03, -1.7975e-02, -1.6022e-02,  ..., -1.0139e-02,
          1.9493e-03, -7.0343e-03],
        [-1.3580e-02,  2.1072e-02,  1.1971e-02,  ..., -2.4643e-02,
         -1.1635e-02, -7.4310e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0684, -1.6973, -0.4722,  ..., -2.0938, -1.5332, -4.7891]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 10:39:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you achieve something, you are a achiever
If you discover something, you are a discoverer
If you subscribe something, you are a subscriber
If you mourn something, you are a mourner
If you lose something, you are a loser
If you manage something, you are a manager
If you examine something, you are a examiner
If you borrow something, you are a
2024-07-28 10:39:23 root INFO     [order_1_approx] starting weight calculation for If you subscribe something, you are a subscriber
If you lose something, you are a loser
If you achieve something, you are a achiever
If you borrow something, you are a borrower
If you mourn something, you are a mourner
If you examine something, you are a examiner
If you manage something, you are a manager
If you discover something, you are a
2024-07-28 10:39:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 10:42:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0582,  0.2544,  0.0253,  ..., -0.1697, -0.2949, -0.1055],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0527, -3.3438,  1.6387,  ...,  0.1978, -4.0156, -0.4785],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0127,  0.0030, -0.0014,  ...,  0.0208,  0.0329,  0.0013],
        [-0.0265,  0.0043,  0.0240,  ..., -0.0035, -0.0003,  0.0084],
        [ 0.0092, -0.0049,  0.0066,  ..., -0.0052, -0.0117, -0.0233],
        ...,
        [ 0.0272,  0.0220,  0.0243,  ...,  0.0120, -0.0063, -0.0093],
        [ 0.0264, -0.0099, -0.0147,  ..., -0.0112,  0.0201,  0.0105],
        [ 0.0099,  0.0154,  0.0124,  ...,  0.0008, -0.0474, -0.0021]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7686, -3.3691,  1.1523,  ...,  0.2078, -3.7500, -0.7949]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 10:42:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you subscribe something, you are a subscriber
If you lose something, you are a loser
If you achieve something, you are a achiever
If you borrow something, you are a borrower
If you mourn something, you are a mourner
If you examine something, you are a examiner
If you manage something, you are a manager
If you discover something, you are a
2024-07-28 10:42:09 root INFO     [order_1_approx] starting weight calculation for If you discover something, you are a discoverer
If you examine something, you are a examiner
If you achieve something, you are a achiever
If you subscribe something, you are a subscriber
If you manage something, you are a manager
If you borrow something, you are a borrower
If you mourn something, you are a mourner
If you lose something, you are a
2024-07-28 10:42:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 10:44:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1219,  0.1335,  0.1312,  ..., -0.0643,  0.1233, -0.1223],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9854, -1.2012,  0.2476,  ..., -0.6548, -2.2422,  0.8330],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-1.6815e-02, -2.9434e-02,  2.1210e-02,  ...,  3.0029e-02,
          1.3672e-02,  8.3771e-03],
        [-2.0966e-02,  2.5665e-02,  7.3700e-03,  ..., -4.7264e-03,
         -2.7046e-03, -5.1231e-03],
        [-9.9030e-03,  1.6052e-02,  3.4302e-02,  ..., -1.4542e-02,
          2.0126e-02,  1.3992e-02],
        ...,
        [ 3.6713e-02, -9.6359e-03, -1.9043e-02,  ..., -2.1400e-03,
         -2.0523e-02, -3.2425e-03],
        [ 9.1553e-05,  1.7151e-02, -2.3865e-02,  ..., -1.1925e-02,
         -2.4338e-02, -2.4933e-02],
        [-3.6926e-03,  3.5278e-02,  1.4587e-02,  ..., -1.4908e-02,
         -8.5754e-03, -2.0844e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9863, -1.3584,  0.3381,  ..., -0.5098, -2.5508,  0.8354]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 10:44:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you discover something, you are a discoverer
If you examine something, you are a examiner
If you achieve something, you are a achiever
If you subscribe something, you are a subscriber
If you manage something, you are a manager
If you borrow something, you are a borrower
If you mourn something, you are a mourner
If you lose something, you are a
2024-07-28 10:44:51 root INFO     [order_1_approx] starting weight calculation for If you borrow something, you are a borrower
If you lose something, you are a loser
If you discover something, you are a discoverer
If you mourn something, you are a mourner
If you subscribe something, you are a subscriber
If you manage something, you are a manager
If you examine something, you are a examiner
If you achieve something, you are a
2024-07-28 10:44:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 10:47:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1342,  0.3647, -0.0115,  ...,  0.1063, -0.1965, -0.0825],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7344, -0.6938, -1.2969,  ...,  0.6455, -4.8438, -2.7109],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0035, -0.0094, -0.0172,  ...,  0.0294,  0.0084, -0.0174],
        [-0.0429,  0.0318,  0.0201,  ..., -0.0255, -0.0242,  0.0024],
        [ 0.0253,  0.0074, -0.0092,  ...,  0.0244, -0.0083,  0.0216],
        ...,
        [ 0.0229,  0.0347, -0.0083,  ...,  0.0063,  0.0072, -0.0023],
        [ 0.0061,  0.0369, -0.0150,  ...,  0.0107,  0.0042,  0.0088],
        [ 0.0100,  0.0062, -0.0240,  ...,  0.0041, -0.0087,  0.0014]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8418, -0.8203, -1.1064,  ...,  0.7769, -4.1367, -2.8652]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 10:47:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you borrow something, you are a borrower
If you lose something, you are a loser
If you discover something, you are a discoverer
If you mourn something, you are a mourner
If you subscribe something, you are a subscriber
If you manage something, you are a manager
If you examine something, you are a examiner
If you achieve something, you are a
2024-07-28 10:47:28 root INFO     [order_1_approx] starting weight calculation for If you lose something, you are a loser
If you subscribe something, you are a subscriber
If you borrow something, you are a borrower
If you discover something, you are a discoverer
If you achieve something, you are a achiever
If you manage something, you are a manager
If you examine something, you are a examiner
If you mourn something, you are a
2024-07-28 10:47:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 10:50:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0371,  0.3499,  0.0524,  ..., -0.1137, -0.2433, -0.0118],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4980, -2.5625,  0.2993,  ..., -1.9141, -1.8867,  0.0488],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0102, -0.0364,  0.0242,  ...,  0.0051,  0.0285, -0.0080],
        [-0.0168,  0.0235,  0.0193,  ...,  0.0166, -0.0046,  0.0102],
        [ 0.0162,  0.0029,  0.0301,  ..., -0.0043,  0.0167, -0.0267],
        ...,
        [ 0.0285,  0.0227,  0.0382,  ..., -0.0059, -0.0032, -0.0035],
        [ 0.0087, -0.0271, -0.0190,  ..., -0.0269,  0.0009, -0.0397],
        [ 0.0009,  0.0380,  0.0016,  ..., -0.0068, -0.0024, -0.0022]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5430, -2.8047,  0.2452,  ..., -2.0898, -1.6904, -0.0234]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 10:50:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you lose something, you are a loser
If you subscribe something, you are a subscriber
If you borrow something, you are a borrower
If you discover something, you are a discoverer
If you achieve something, you are a achiever
If you manage something, you are a manager
If you examine something, you are a examiner
If you mourn something, you are a
2024-07-28 10:50:09 root INFO     [order_1_approx] starting weight calculation for If you manage something, you are a manager
If you mourn something, you are a mourner
If you lose something, you are a loser
If you examine something, you are a examiner
If you achieve something, you are a achiever
If you discover something, you are a discoverer
If you borrow something, you are a borrower
If you subscribe something, you are a
2024-07-28 10:50:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 10:52:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0605, -0.0475, -0.1274,  ...,  0.1055, -0.0771, -0.0015],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3750, -2.3008,  0.9233,  ...,  0.8633, -1.1016, -4.3242],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0544, -0.0015, -0.0032,  ...,  0.0378,  0.0197,  0.0171],
        [-0.0150,  0.0350,  0.0088,  ..., -0.0072, -0.0364, -0.0054],
        [ 0.0177, -0.0083,  0.0155,  ..., -0.0086, -0.0332, -0.0058],
        ...,
        [ 0.0372,  0.0543,  0.0027,  ...,  0.0266,  0.0131, -0.0073],
        [ 0.0091, -0.0214,  0.0151,  ..., -0.0049, -0.0096, -0.0139],
        [ 0.0057, -0.0121,  0.0213,  ..., -0.0477, -0.0358,  0.0018]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6543, -2.3066,  1.1094,  ...,  0.8896, -1.1475, -4.6680]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 10:52:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you manage something, you are a manager
If you mourn something, you are a mourner
If you lose something, you are a loser
If you examine something, you are a examiner
If you achieve something, you are a achiever
If you discover something, you are a discoverer
If you borrow something, you are a borrower
If you subscribe something, you are a
2024-07-28 10:52:51 root INFO     [order_1_approx] starting weight calculation for If you subscribe something, you are a subscriber
If you lose something, you are a loser
If you manage something, you are a manager
If you mourn something, you are a mourner
If you borrow something, you are a borrower
If you achieve something, you are a achiever
If you discover something, you are a discoverer
If you examine something, you are a
2024-07-28 10:52:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 10:55:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0652, -0.0528,  0.1287,  ..., -0.0685,  0.0486, -0.1016],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8418, -2.0000, -0.4453,  ..., -2.6406, -2.7344, -5.4062],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.0863e-02, -1.6693e-02, -3.4885e-03,  ...,  2.5375e-02,
          1.8646e-02, -7.8583e-03],
        [-2.0416e-02,  3.1372e-02,  3.6957e-02,  ..., -4.4327e-03,
          5.0964e-03, -6.1798e-03],
        [-1.3351e-02,  1.5015e-02,  6.8665e-05,  ...,  2.2614e-02,
          2.3193e-02,  1.5823e-02],
        ...,
        [ 1.1475e-02,  1.8616e-02, -3.7746e-03,  ...,  3.0884e-02,
          1.7380e-02,  5.8517e-03],
        [-1.6800e-02, -2.6779e-03, -4.6349e-03,  ..., -3.2837e-02,
         -1.8021e-02,  4.6234e-03],
        [-9.0637e-03,  7.8087e-03, -6.9351e-03,  ...,  2.6550e-02,
         -9.2163e-03,  1.6663e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6348, -2.3164, -0.1843,  ..., -2.4727, -2.6074, -5.3867]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 10:55:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you subscribe something, you are a subscriber
If you lose something, you are a loser
If you manage something, you are a manager
If you mourn something, you are a mourner
If you borrow something, you are a borrower
If you achieve something, you are a achiever
If you discover something, you are a discoverer
If you examine something, you are a
2024-07-28 10:55:36 root INFO     [order_1_approx] starting weight calculation for If you lose something, you are a loser
If you mourn something, you are a mourner
If you subscribe something, you are a subscriber
If you discover something, you are a discoverer
If you examine something, you are a examiner
If you borrow something, you are a borrower
If you achieve something, you are a achiever
If you manage something, you are a
2024-07-28 10:55:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 10:58:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1321,  0.4148,  0.1158,  ...,  0.0315,  0.0115, -0.3032],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5391, -2.3809,  1.7344,  ..., -1.2773, -3.9570, -4.2109],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0157, -0.0060,  0.0012,  ...,  0.0003,  0.0108, -0.0113],
        [ 0.0139,  0.0210, -0.0005,  ..., -0.0280,  0.0101, -0.0052],
        [-0.0257, -0.0138,  0.0224,  ..., -0.0075, -0.0047,  0.0076],
        ...,
        [ 0.0284,  0.0207,  0.0088,  ...,  0.0404, -0.0022,  0.0044],
        [-0.0331,  0.0136, -0.0063,  ...,  0.0018,  0.0170,  0.0229],
        [ 0.0247, -0.0124,  0.0098,  ..., -0.0383, -0.0233, -0.0150]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9023, -2.6719,  1.9082,  ..., -1.1357, -3.6934, -4.6875]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 10:58:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you lose something, you are a loser
If you mourn something, you are a mourner
If you subscribe something, you are a subscriber
If you discover something, you are a discoverer
If you examine something, you are a examiner
If you borrow something, you are a borrower
If you achieve something, you are a achiever
If you manage something, you are a
2024-07-28 10:58:17 root INFO     total operator prediction time: 1297.2201609611511 seconds
2024-07-28 10:58:17 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on over+adj_reg
2024-07-28 10:58:17 root INFO     building operator over+adj_reg
2024-07-28 10:58:17 root INFO     [order_1_approx] starting weight calculation for If something is too dressed, it is overdressed
If something is too stretched, it is overstretched
If something is too arching, it is overarching
If something is too optimistic, it is overoptimistic
If something is too saturated, it is oversaturated
If something is too heard, it is overheard
If something is too sized, it is oversized
If something is too ambitious, it is
2024-07-28 10:58:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 11:01:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1188, -0.1307, -0.2358,  ...,  0.1465, -0.2166,  0.0582],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5781, -3.6621,  0.1079,  ...,  0.7319, -2.5098, -2.6289],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0049,  0.0010,  0.0091,  ..., -0.0090,  0.0043, -0.0067],
        [-0.0127,  0.0140,  0.0054,  ..., -0.0051, -0.0113,  0.0076],
        [ 0.0006,  0.0097,  0.0252,  ..., -0.0064,  0.0187, -0.0128],
        ...,
        [ 0.0116,  0.0163, -0.0041,  ...,  0.0050, -0.0062, -0.0115],
        [ 0.0289,  0.0087,  0.0203,  ...,  0.0185,  0.0007, -0.0110],
        [-0.0091, -0.0080, -0.0160,  ...,  0.0033, -0.0062,  0.0162]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6309, -3.3320, -0.0555,  ...,  0.6069, -2.6582, -2.4688]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 11:01:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too dressed, it is overdressed
If something is too stretched, it is overstretched
If something is too arching, it is overarching
If something is too optimistic, it is overoptimistic
If something is too saturated, it is oversaturated
If something is too heard, it is overheard
If something is too sized, it is oversized
If something is too ambitious, it is
2024-07-28 11:01:01 root INFO     [order_1_approx] starting weight calculation for If something is too dressed, it is overdressed
If something is too ambitious, it is overambitious
If something is too optimistic, it is overoptimistic
If something is too arching, it is overarching
If something is too heard, it is overheard
If something is too stretched, it is overstretched
If something is too sized, it is oversized
If something is too saturated, it is
2024-07-28 11:01:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 11:03:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1245, -0.2175,  0.1780,  ...,  0.4114, -0.3899,  0.0663],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8477, -2.8398, -0.6665,  ..., -1.2188, -2.7930, -0.9375],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0575, -0.0118, -0.0231,  ..., -0.0201, -0.0382,  0.0204],
        [ 0.0141,  0.0375,  0.0088,  ..., -0.0123, -0.0252, -0.0069],
        [ 0.0103, -0.0035,  0.0138,  ..., -0.0157, -0.0221,  0.0208],
        ...,
        [ 0.0058,  0.0041, -0.0139,  ...,  0.0601, -0.0042, -0.0046],
        [-0.0234, -0.0272, -0.0013,  ..., -0.0017,  0.0292, -0.0166],
        [-0.0091,  0.0042,  0.0138,  ...,  0.0116, -0.0193,  0.0232]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1582, -2.9824, -0.5454,  ..., -1.4854, -2.9961, -1.2969]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 11:03:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too dressed, it is overdressed
If something is too ambitious, it is overambitious
If something is too optimistic, it is overoptimistic
If something is too arching, it is overarching
If something is too heard, it is overheard
If something is too stretched, it is overstretched
If something is too sized, it is oversized
If something is too saturated, it is
2024-07-28 11:03:48 root INFO     [order_1_approx] starting weight calculation for If something is too ambitious, it is overambitious
If something is too optimistic, it is overoptimistic
If something is too sized, it is oversized
If something is too saturated, it is oversaturated
If something is too heard, it is overheard
If something is too arching, it is overarching
If something is too stretched, it is overstretched
If something is too dressed, it is
2024-07-28 11:03:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 11:06:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1202, -0.2791, -0.0785,  ..., -0.0488, -0.4167, -0.1049],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1289, -4.5859, -0.8687,  ...,  2.2285, -4.7891, -2.6934],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0176, -0.0203, -0.0268,  ..., -0.0094,  0.0090, -0.0141],
        [-0.0092,  0.0201, -0.0016,  ..., -0.0074, -0.0103,  0.0077],
        [ 0.0323,  0.0191,  0.0259,  ...,  0.0064, -0.0023,  0.0092],
        ...,
        [ 0.0093,  0.0185,  0.0119,  ...,  0.0645,  0.0071, -0.0202],
        [ 0.0113,  0.0026, -0.0117,  ..., -0.0075,  0.0254, -0.0117],
        [-0.0080, -0.0007,  0.0097,  ...,  0.0241, -0.0037,  0.0079]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0128, -4.3789, -0.9893,  ...,  2.3945, -4.3711, -2.7461]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 11:06:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too ambitious, it is overambitious
If something is too optimistic, it is overoptimistic
If something is too sized, it is oversized
If something is too saturated, it is oversaturated
If something is too heard, it is overheard
If something is too arching, it is overarching
If something is too stretched, it is overstretched
If something is too dressed, it is
2024-07-28 11:06:33 root INFO     [order_1_approx] starting weight calculation for If something is too arching, it is overarching
If something is too saturated, it is oversaturated
If something is too heard, it is overheard
If something is too ambitious, it is overambitious
If something is too stretched, it is overstretched
If something is too dressed, it is overdressed
If something is too sized, it is oversized
If something is too optimistic, it is
2024-07-28 11:06:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 11:09:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0720, -0.1936,  0.0026,  ...,  0.1581, -0.1462,  0.1873],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9707, -3.8379,  0.6875,  ...,  0.5103, -1.5596, -2.0332],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0395,  0.0073, -0.0058,  ...,  0.0050, -0.0092,  0.0062],
        [-0.0178,  0.0242,  0.0101,  ..., -0.0146,  0.0028, -0.0083],
        [ 0.0138, -0.0002,  0.0291,  ...,  0.0039, -0.0233, -0.0028],
        ...,
        [ 0.0020,  0.0014, -0.0110,  ...,  0.0488, -0.0150,  0.0169],
        [ 0.0190, -0.0091,  0.0328,  ..., -0.0065,  0.0190, -0.0168],
        [-0.0261, -0.0097, -0.0004,  ...,  0.0079, -0.0175,  0.0251]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1934, -3.7695,  0.6289,  ...,  0.1765, -1.4414, -2.0840]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 11:09:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too arching, it is overarching
If something is too saturated, it is oversaturated
If something is too heard, it is overheard
If something is too ambitious, it is overambitious
If something is too stretched, it is overstretched
If something is too dressed, it is overdressed
If something is too sized, it is oversized
If something is too optimistic, it is
2024-07-28 11:09:17 root INFO     [order_1_approx] starting weight calculation for If something is too arching, it is overarching
If something is too saturated, it is oversaturated
If something is too sized, it is oversized
If something is too optimistic, it is overoptimistic
If something is too ambitious, it is overambitious
If something is too heard, it is overheard
If something is too dressed, it is overdressed
If something is too stretched, it is
2024-07-28 11:09:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 11:12:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1753, -0.5420,  0.0083,  ...,  0.0095, -0.2109,  0.1146],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1055, -3.8652,  0.7837,  ...,  0.3333, -0.5820, -2.8477],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0254,  0.0144, -0.0146,  ...,  0.0053,  0.0208,  0.0192],
        [ 0.0059,  0.0302,  0.0078,  ..., -0.0081, -0.0163,  0.0091],
        [ 0.0212,  0.0109,  0.0458,  ..., -0.0037,  0.0068, -0.0052],
        ...,
        [ 0.0254, -0.0034, -0.0031,  ...,  0.0463, -0.0013, -0.0014],
        [ 0.0018,  0.0024,  0.0026,  ..., -0.0059,  0.0021, -0.0280],
        [-0.0119,  0.0045, -0.0079,  ..., -0.0021, -0.0146,  0.0172]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3613, -4.0391,  0.6821,  ...,  0.5312, -0.6514, -2.8262]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 11:12:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too arching, it is overarching
If something is too saturated, it is oversaturated
If something is too sized, it is oversized
If something is too optimistic, it is overoptimistic
If something is too ambitious, it is overambitious
If something is too heard, it is overheard
If something is too dressed, it is overdressed
If something is too stretched, it is
2024-07-28 11:12:06 root INFO     [order_1_approx] starting weight calculation for If something is too stretched, it is overstretched
If something is too dressed, it is overdressed
If something is too arching, it is overarching
If something is too optimistic, it is overoptimistic
If something is too heard, it is overheard
If something is too saturated, it is oversaturated
If something is too ambitious, it is overambitious
If something is too sized, it is
2024-07-28 11:12:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 11:14:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1071, -0.3311, -0.3416,  ...,  0.1450, -0.1873, -0.1810],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3770, -3.7207, -1.2393,  ...,  0.1755, -3.4062, -0.3672],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0510, -0.0327, -0.0007,  ..., -0.0108,  0.0040, -0.0262],
        [ 0.0047,  0.0649,  0.0271,  ...,  0.0120, -0.0113,  0.0099],
        [ 0.0232,  0.0017,  0.0362,  ..., -0.0055,  0.0031,  0.0163],
        ...,
        [ 0.0243, -0.0178, -0.0045,  ...,  0.0714, -0.0014,  0.0236],
        [ 0.0255,  0.0017,  0.0047,  ...,  0.0002,  0.0479, -0.0242],
        [-0.0053,  0.0121,  0.0269,  ..., -0.0012, -0.0173,  0.0515]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2529, -3.5176, -1.1045,  ...,  0.4487, -3.6172, -0.2705]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 11:14:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too stretched, it is overstretched
If something is too dressed, it is overdressed
If something is too arching, it is overarching
If something is too optimistic, it is overoptimistic
If something is too heard, it is overheard
If something is too saturated, it is oversaturated
If something is too ambitious, it is overambitious
If something is too sized, it is
2024-07-28 11:14:54 root INFO     [order_1_approx] starting weight calculation for If something is too saturated, it is oversaturated
If something is too optimistic, it is overoptimistic
If something is too sized, it is oversized
If something is too dressed, it is overdressed
If something is too heard, it is overheard
If something is too ambitious, it is overambitious
If something is too stretched, it is overstretched
If something is too arching, it is
2024-07-28 11:14:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 11:17:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0924, -0.3384,  0.1062,  ...,  0.0195, -0.3948, -0.3643],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5625, -3.8398,  2.8457,  ...,  0.8711, -1.7520, -3.3203],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0453,  0.0169, -0.0153,  ...,  0.0095,  0.0003,  0.0165],
        [-0.0215,  0.0650,  0.0079,  ...,  0.0025, -0.0163,  0.0181],
        [-0.0215,  0.0170,  0.0272,  ..., -0.0057, -0.0247, -0.0131],
        ...,
        [-0.0092,  0.0203,  0.0158,  ...,  0.0386, -0.0183,  0.0005],
        [ 0.0296, -0.0093,  0.0392,  ..., -0.0243,  0.0508, -0.0311],
        [-0.0404,  0.0063, -0.0149,  ...,  0.0216, -0.0304,  0.0383]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8857, -4.3516,  2.1680,  ...,  0.9507, -2.0352, -3.2852]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 11:17:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too saturated, it is oversaturated
If something is too optimistic, it is overoptimistic
If something is too sized, it is oversized
If something is too dressed, it is overdressed
If something is too heard, it is overheard
If something is too ambitious, it is overambitious
If something is too stretched, it is overstretched
If something is too arching, it is
2024-07-28 11:17:35 root INFO     [order_1_approx] starting weight calculation for If something is too optimistic, it is overoptimistic
If something is too stretched, it is overstretched
If something is too ambitious, it is overambitious
If something is too dressed, it is overdressed
If something is too sized, it is oversized
If something is too saturated, it is oversaturated
If something is too arching, it is overarching
If something is too heard, it is
2024-07-28 11:17:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 11:20:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1636, -0.1274, -0.0145,  ..., -0.0861, -0.2900,  0.0779],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1582, -2.5195,  1.6191,  ...,  0.6533, -2.9727, -3.8320],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0587, -0.0020,  0.0119,  ...,  0.0213,  0.0174,  0.0294],
        [-0.0524,  0.0565,  0.0141,  ..., -0.0100,  0.0224, -0.0393],
        [ 0.0110,  0.0182,  0.0575,  ...,  0.0005, -0.0392,  0.0258],
        ...,
        [ 0.0117, -0.0252,  0.0134,  ...,  0.0507, -0.0011,  0.0148],
        [-0.0048, -0.0519, -0.0155,  ..., -0.0010,  0.0179,  0.0101],
        [-0.0029,  0.0043,  0.0235,  ...,  0.0172, -0.0233,  0.0158]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1895, -2.2852,  2.2305,  ...,  0.8911, -2.7793, -3.3652]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 11:20:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too optimistic, it is overoptimistic
If something is too stretched, it is overstretched
If something is too ambitious, it is overambitious
If something is too dressed, it is overdressed
If something is too sized, it is oversized
If something is too saturated, it is oversaturated
If something is too arching, it is overarching
If something is too heard, it is
2024-07-28 11:20:16 root INFO     total operator prediction time: 1319.042376756668 seconds
2024-07-28 11:20:16 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj+ly_reg
2024-07-28 11:20:16 root INFO     building operator adj+ly_reg
2024-07-28 11:20:16 root INFO     [order_1_approx] starting weight calculation for The adjective form of virtual is virtually
The adjective form of similar is similarly
The adjective form of additional is additionally
The adjective form of apparent is apparently
The adjective form of serious is seriously
The adjective form of rare is rarely
The adjective form of beautiful is beautifully
The adjective form of visual is
2024-07-28 11:20:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 11:23:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0779, -0.0911,  0.0996,  ...,  0.0187, -0.2264, -0.0988],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8457, -3.2734,  1.4082,  ..., -1.9404, -1.0498, -1.9443],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0561, -0.0723,  0.0308,  ..., -0.0304,  0.0024,  0.0279],
        [ 0.0366,  0.0140,  0.0175,  ...,  0.0128, -0.0128, -0.0061],
        [ 0.0214, -0.0253,  0.0267,  ..., -0.0040, -0.0230,  0.0253],
        ...,
        [ 0.0225,  0.0225, -0.0311,  ...,  0.0598, -0.0085, -0.0245],
        [-0.0011,  0.0659, -0.0377,  ...,  0.0202,  0.0110, -0.0317],
        [ 0.0089,  0.0176, -0.0059,  ...,  0.0487, -0.0172,  0.0065]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2129, -2.4375,  1.4043,  ..., -1.8105, -1.7041, -2.2031]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 11:23:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of virtual is virtually
The adjective form of similar is similarly
The adjective form of additional is additionally
The adjective form of apparent is apparently
The adjective form of serious is seriously
The adjective form of rare is rarely
The adjective form of beautiful is beautifully
The adjective form of visual is
2024-07-28 11:23:02 root INFO     [order_1_approx] starting weight calculation for The adjective form of apparent is apparently
The adjective form of additional is additionally
The adjective form of visual is visually
The adjective form of serious is seriously
The adjective form of beautiful is beautifully
The adjective form of similar is similarly
The adjective form of virtual is virtually
The adjective form of rare is
2024-07-28 11:23:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 11:25:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1150, -0.0809, -0.2197,  ..., -0.1848,  0.0134, -0.1078],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.7539, -3.1035,  0.0986,  ..., -4.3516, -3.7852, -5.3750],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0530,  0.0162,  0.0264,  ...,  0.0327,  0.0075,  0.0161],
        [-0.0029,  0.0042,  0.0618,  ...,  0.0372,  0.0094, -0.0072],
        [ 0.0196, -0.0324,  0.0499,  ..., -0.0167, -0.0093,  0.0497],
        ...,
        [ 0.0514,  0.0117,  0.0245,  ...,  0.0748,  0.0070, -0.0572],
        [ 0.0105,  0.0026, -0.0111,  ..., -0.0131,  0.0178, -0.0283],
        [ 0.0247,  0.0101,  0.0184,  ..., -0.0022, -0.0089, -0.0067]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-3.2109, -4.1523, -0.1403,  ..., -4.6836, -3.6855, -5.9805]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 11:25:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of apparent is apparently
The adjective form of additional is additionally
The adjective form of visual is visually
The adjective form of serious is seriously
The adjective form of beautiful is beautifully
The adjective form of similar is similarly
The adjective form of virtual is virtually
The adjective form of rare is
2024-07-28 11:25:50 root INFO     [order_1_approx] starting weight calculation for The adjective form of beautiful is beautifully
The adjective form of similar is similarly
The adjective form of additional is additionally
The adjective form of virtual is virtually
The adjective form of visual is visually
The adjective form of rare is rarely
The adjective form of serious is seriously
The adjective form of apparent is
2024-07-28 11:25:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 11:28:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3706,  0.1295,  0.0132,  ..., -0.0063, -0.4922,  0.1334],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7178, -2.2129, -0.6641,  ...,  0.4834, -1.5156, -0.5635],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0960,  0.0169,  0.0017,  ...,  0.0192, -0.0420,  0.0540],
        [-0.0030,  0.0163, -0.0186,  ...,  0.0088, -0.0021, -0.0352],
        [ 0.0361, -0.0067,  0.0865,  ...,  0.0019, -0.0149,  0.0315],
        ...,
        [ 0.0014, -0.0060,  0.0355,  ...,  0.0568, -0.0142,  0.0259],
        [ 0.0366, -0.0095, -0.0079,  ..., -0.0175,  0.0288, -0.0046],
        [-0.0218,  0.0204, -0.0025,  ...,  0.0173, -0.0227, -0.0293]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8867, -1.9199, -0.3447,  ...,  1.1055, -1.8125, -0.8389]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 11:28:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of beautiful is beautifully
The adjective form of similar is similarly
The adjective form of additional is additionally
The adjective form of virtual is virtually
The adjective form of visual is visually
The adjective form of rare is rarely
The adjective form of serious is seriously
The adjective form of apparent is
2024-07-28 11:28:39 root INFO     [order_1_approx] starting weight calculation for The adjective form of beautiful is beautifully
The adjective form of serious is seriously
The adjective form of apparent is apparently
The adjective form of virtual is virtually
The adjective form of rare is rarely
The adjective form of visual is visually
The adjective form of additional is additionally
The adjective form of similar is
2024-07-28 11:28:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 11:31:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0509, -0.2593,  0.0491,  ...,  0.0434, -0.1531,  0.1393],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3223, -1.2969,  1.0166,  ..., -1.6523,  0.8687, -1.7109],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0048,  0.0050,  0.0111,  ..., -0.0092,  0.0275, -0.0188],
        [-0.0127,  0.0323,  0.0323,  ..., -0.0284,  0.0208, -0.0117],
        [ 0.0049,  0.0085,  0.0124,  ..., -0.0234, -0.0299, -0.0168],
        ...,
        [ 0.0152, -0.0038,  0.0131,  ...,  0.1071, -0.0504, -0.0145],
        [ 0.0301,  0.0114, -0.0026,  ...,  0.0107, -0.0210, -0.0291],
        [ 0.0373,  0.0028, -0.0151,  ...,  0.0178, -0.0088,  0.0322]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7827, -1.2793,  1.0449,  ..., -1.4170,  0.5811, -1.7451]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 11:31:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of beautiful is beautifully
The adjective form of serious is seriously
The adjective form of apparent is apparently
The adjective form of virtual is virtually
The adjective form of rare is rarely
The adjective form of visual is visually
The adjective form of additional is additionally
The adjective form of similar is
2024-07-28 11:31:25 root INFO     [order_1_approx] starting weight calculation for The adjective form of rare is rarely
The adjective form of apparent is apparently
The adjective form of similar is similarly
The adjective form of serious is seriously
The adjective form of virtual is virtually
The adjective form of beautiful is beautifully
The adjective form of visual is visually
The adjective form of additional is
2024-07-28 11:31:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 11:34:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1404, -0.1038, -0.2029,  ..., -0.0627, -0.3525,  0.1154],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6030, -3.1680, -0.9141,  ...,  1.2803, -1.7324, -1.9590],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0190, -0.0362,  0.0069,  ...,  0.0046,  0.0443,  0.0704],
        [-0.0025, -0.0233,  0.0189,  ..., -0.0169,  0.0256,  0.0009],
        [ 0.0197, -0.0077,  0.0323,  ...,  0.0026, -0.0096,  0.0234],
        ...,
        [-0.0301,  0.0018, -0.0003,  ...,  0.0250, -0.0339, -0.0835],
        [ 0.0671,  0.0055,  0.0080,  ...,  0.0028,  0.0704, -0.0320],
        [ 0.0177, -0.0154,  0.0017,  ..., -0.0306, -0.0317,  0.0006]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6914, -2.4375, -0.9985,  ...,  0.8501, -1.4580, -2.1055]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 11:34:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of rare is rarely
The adjective form of apparent is apparently
The adjective form of similar is similarly
The adjective form of serious is seriously
The adjective form of virtual is virtually
The adjective form of beautiful is beautifully
The adjective form of visual is visually
The adjective form of additional is
2024-07-28 11:34:13 root INFO     [order_1_approx] starting weight calculation for The adjective form of visual is visually
The adjective form of additional is additionally
The adjective form of similar is similarly
The adjective form of serious is seriously
The adjective form of rare is rarely
The adjective form of virtual is virtually
The adjective form of apparent is apparently
The adjective form of beautiful is
2024-07-28 11:34:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 11:36:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1987,  0.1068,  0.0037,  ...,  0.1171, -0.2358,  0.0685],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7598, -1.8184, -0.9609,  ...,  1.0508, -3.4062, -2.6230],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0838, -0.0224,  0.0254,  ...,  0.0255, -0.0039,  0.0673],
        [-0.0766,  0.0160,  0.0303,  ..., -0.0432,  0.0016, -0.0422],
        [ 0.0386, -0.0138,  0.0407,  ..., -0.0031, -0.0054,  0.0436],
        ...,
        [ 0.0251, -0.0178,  0.0017,  ...,  0.0469,  0.0167, -0.0653],
        [ 0.0810, -0.0046,  0.0045,  ...,  0.0219,  0.0505,  0.0104],
        [ 0.0077, -0.0093, -0.0075,  ...,  0.0339, -0.0406,  0.0099]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3389, -1.4785, -1.1943,  ...,  1.0674, -4.1875, -3.0664]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 11:37:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of visual is visually
The adjective form of additional is additionally
The adjective form of similar is similarly
The adjective form of serious is seriously
The adjective form of rare is rarely
The adjective form of virtual is virtually
The adjective form of apparent is apparently
The adjective form of beautiful is
2024-07-28 11:37:00 root INFO     [order_1_approx] starting weight calculation for The adjective form of similar is similarly
The adjective form of visual is visually
The adjective form of beautiful is beautifully
The adjective form of additional is additionally
The adjective form of apparent is apparently
The adjective form of rare is rarely
The adjective form of serious is seriously
The adjective form of virtual is
2024-07-28 11:37:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 11:39:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1134, -0.1104,  0.1921,  ..., -0.0579, -0.1321,  0.3728],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1182, -4.0352, -0.4238,  ..., -3.0586, -0.2939, -0.3008],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0410, -0.0446,  0.0037,  ...,  0.0047,  0.0509,  0.0197],
        [ 0.0129,  0.0320,  0.0343,  ..., -0.0260,  0.0089, -0.0256],
        [ 0.0191, -0.0221,  0.0508,  ..., -0.0101, -0.0283,  0.0233],
        ...,
        [ 0.0119,  0.0266,  0.0075,  ...,  0.0364, -0.0122, -0.0348],
        [ 0.0232,  0.0248, -0.0502,  ...,  0.0056,  0.0240, -0.0205],
        [ 0.0026,  0.0477,  0.0241,  ..., -0.0120, -0.0336,  0.0042]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9404, -3.8086, -0.7461,  ..., -2.7559, -0.3691, -0.5942]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 11:39:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of similar is similarly
The adjective form of visual is visually
The adjective form of beautiful is beautifully
The adjective form of additional is additionally
The adjective form of apparent is apparently
The adjective form of rare is rarely
The adjective form of serious is seriously
The adjective form of virtual is
2024-07-28 11:39:48 root INFO     [order_1_approx] starting weight calculation for The adjective form of additional is additionally
The adjective form of similar is similarly
The adjective form of virtual is virtually
The adjective form of visual is visually
The adjective form of beautiful is beautifully
The adjective form of apparent is apparently
The adjective form of rare is rarely
The adjective form of serious is
2024-07-28 11:39:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 11:42:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0715, -0.1649, -0.2959,  ..., -0.0670, -0.4705,  0.2881],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7266, -2.1113, -0.8057,  ..., -2.4922,  0.0469, -4.4102],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.0222e-02,  2.0828e-02,  2.6947e-02,  ..., -1.0170e-02,
          1.2474e-03, -4.0131e-03],
        [-4.7684e-06,  3.3966e-02,  3.3081e-02,  ..., -3.2288e-02,
         -5.4169e-04,  3.7575e-03],
        [ 1.7075e-02,  2.3376e-02,  2.3155e-03,  ..., -1.6693e-02,
         -8.6746e-03,  2.7161e-02],
        ...,
        [ 1.9318e-02, -1.8631e-02,  1.4862e-02,  ...,  7.2754e-02,
          1.3016e-02,  1.0864e-02],
        [-2.9831e-03, -3.1952e-02,  1.2016e-03,  ...,  1.7502e-02,
          4.3945e-02, -3.3447e-02],
        [ 2.5070e-02, -2.3956e-03,  1.8570e-02,  ...,  4.6051e-02,
         -4.9515e-03,  1.1932e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7881, -2.0156, -0.4905,  ..., -3.0430, -0.7969, -4.5273]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 11:42:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of additional is additionally
The adjective form of similar is similarly
The adjective form of virtual is virtually
The adjective form of visual is visually
The adjective form of beautiful is beautifully
The adjective form of apparent is apparently
The adjective form of rare is rarely
The adjective form of serious is
2024-07-28 11:42:35 root INFO     total operator prediction time: 1338.6905722618103 seconds
2024-07-28 11:42:35 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+tion_irreg
2024-07-28 11:42:35 root INFO     building operator verb+tion_irreg
2024-07-28 11:42:35 root INFO     [order_1_approx] starting weight calculation for To oblige results in obligation
To degrade results in degradation
To reorganize results in reorganization
To install results in installation
To improvize results in improvization
To configure results in configuration
To customize results in customization
To realize results in
2024-07-28 11:42:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 11:45:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1296,  0.1229, -0.1938,  ...,  0.1897, -0.2124,  0.2651],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.2793, -4.8125,  1.6406,  ...,  2.4258, -1.9844, -0.4150],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0596, -0.0030,  0.0223,  ..., -0.0456, -0.0301,  0.0152],
        [ 0.0659,  0.0444,  0.0144,  ...,  0.0102, -0.0103, -0.0006],
        [ 0.0112, -0.0270,  0.0367,  ...,  0.0333, -0.0092,  0.0320],
        ...,
        [-0.0041, -0.0044, -0.0062,  ...,  0.0834,  0.0478, -0.0338],
        [-0.0209,  0.0193,  0.0121,  ..., -0.0398,  0.0121, -0.0329],
        [ 0.0178, -0.0080, -0.0040,  ...,  0.0334, -0.0306,  0.0397]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8467, -3.5918,  2.1387,  ...,  1.9590, -3.5586,  0.6504]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 11:45:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To oblige results in obligation
To degrade results in degradation
To reorganize results in reorganization
To install results in installation
To improvize results in improvization
To configure results in configuration
To customize results in customization
To realize results in
2024-07-28 11:45:19 root INFO     [order_1_approx] starting weight calculation for To improvize results in improvization
To degrade results in degradation
To realize results in realization
To reorganize results in reorganization
To customize results in customization
To install results in installation
To configure results in configuration
To oblige results in
2024-07-28 11:45:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 11:48:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0404,  0.6035, -0.2578,  ...,  0.0273, -0.4746, -0.0543],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6611, -6.2852,  1.3965,  ...,  3.3828, -2.5527, -0.7109],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0465,  0.0110, -0.0121,  ..., -0.0196, -0.0167,  0.0242],
        [-0.0377,  0.0220, -0.0247,  ...,  0.0084, -0.0247,  0.0039],
        [-0.0260, -0.0267, -0.0141,  ...,  0.0104,  0.0237,  0.0028],
        ...,
        [-0.0040,  0.0101,  0.0119,  ...,  0.0321,  0.0134,  0.0265],
        [ 0.0338, -0.0278,  0.0059,  ...,  0.0064,  0.0250, -0.0150],
        [-0.0078,  0.0316,  0.0335,  ...,  0.0104, -0.0136,  0.0428]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6802, -6.2500,  1.6201,  ...,  3.0801, -2.7441, -0.8911]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 11:48:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To improvize results in improvization
To degrade results in degradation
To realize results in realization
To reorganize results in reorganization
To customize results in customization
To install results in installation
To configure results in configuration
To oblige results in
2024-07-28 11:48:04 root INFO     [order_1_approx] starting weight calculation for To oblige results in obligation
To configure results in configuration
To improvize results in improvization
To realize results in realization
To install results in installation
To reorganize results in reorganization
To customize results in customization
To degrade results in
2024-07-28 11:48:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 11:50:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0547,  0.2488, -0.2123,  ...,  0.0467, -0.1947, -0.1194],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0605, -3.1250, -0.1621,  ..., -1.0303, -1.5762, -3.5156],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0488,  0.0134,  0.0119,  ..., -0.0332,  0.0147, -0.0034],
        [-0.0299,  0.0583, -0.0120,  ...,  0.0233,  0.0229, -0.0085],
        [ 0.0115,  0.0143, -0.0053,  ...,  0.0021, -0.0064,  0.0268],
        ...,
        [ 0.0154,  0.0538,  0.0112,  ...,  0.0386, -0.0161, -0.0009],
        [-0.0046,  0.0092,  0.0224,  ..., -0.0117,  0.0467, -0.0032],
        [-0.0010, -0.0052, -0.0011,  ...,  0.0103, -0.0445,  0.0581]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.3242, -3.3984, -0.2617,  ..., -0.6250, -1.7842, -3.1172]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 11:50:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To oblige results in obligation
To configure results in configuration
To improvize results in improvization
To realize results in realization
To install results in installation
To reorganize results in reorganization
To customize results in customization
To degrade results in
2024-07-28 11:50:49 root INFO     [order_1_approx] starting weight calculation for To configure results in configuration
To improvize results in improvization
To reorganize results in reorganization
To realize results in realization
To oblige results in obligation
To customize results in customization
To degrade results in degradation
To install results in
2024-07-28 11:50:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 11:53:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1760, -0.0466,  0.1036,  ...,  0.2339, -0.0383, -0.0312],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4141, -4.6953,  2.3984,  ...,  1.8926, -3.8770, -2.0938],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0373, -0.0066,  0.0181,  ...,  0.0332,  0.0337,  0.0477],
        [-0.0318, -0.0066,  0.0114,  ...,  0.0195,  0.0337,  0.0115],
        [ 0.0177, -0.0179,  0.0198,  ...,  0.0061, -0.0093,  0.0139],
        ...,
        [ 0.0168,  0.0165, -0.0114,  ...,  0.0370, -0.0177, -0.0081],
        [-0.0008,  0.0089, -0.0209,  ...,  0.0061,  0.0303,  0.0012],
        [-0.0105,  0.0132, -0.0018,  ...,  0.0320, -0.0269,  0.0223]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5566, -4.2148,  2.3730,  ...,  1.3096, -3.7070, -2.5898]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 11:53:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To configure results in configuration
To improvize results in improvization
To reorganize results in reorganization
To realize results in realization
To oblige results in obligation
To customize results in customization
To degrade results in degradation
To install results in
2024-07-28 11:53:34 root INFO     [order_1_approx] starting weight calculation for To install results in installation
To degrade results in degradation
To realize results in realization
To configure results in configuration
To improvize results in improvization
To customize results in customization
To oblige results in obligation
To reorganize results in
2024-07-28 11:53:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 11:56:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1304,  0.0374, -0.1974,  ...,  0.0437, -0.2094, -0.0981],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0771, -3.4727,  1.6523,  ...,  0.9473, -0.5879, -4.5469],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0228, -0.0061,  0.0040,  ...,  0.0032, -0.0113,  0.0054],
        [-0.0129,  0.0109,  0.0078,  ...,  0.0069, -0.0068,  0.0121],
        [-0.0028,  0.0043, -0.0165,  ...,  0.0160, -0.0078, -0.0073],
        ...,
        [ 0.0056, -0.0002, -0.0023,  ...,  0.0209, -0.0042, -0.0021],
        [-0.0135, -0.0009,  0.0005,  ...,  0.0104,  0.0229, -0.0128],
        [-0.0004, -0.0018,  0.0116,  ...,  0.0058,  0.0114,  0.0235]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.0000, -2.8418,  2.2344,  ...,  0.4966, -0.8691, -4.5430]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 11:56:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To install results in installation
To degrade results in degradation
To realize results in realization
To configure results in configuration
To improvize results in improvization
To customize results in customization
To oblige results in obligation
To reorganize results in
2024-07-28 11:56:19 root INFO     [order_1_approx] starting weight calculation for To degrade results in degradation
To reorganize results in reorganization
To realize results in realization
To improvize results in improvization
To install results in installation
To customize results in customization
To oblige results in obligation
To configure results in
2024-07-28 11:56:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 11:59:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1134,  0.0760, -0.2157,  ...,  0.1270,  0.0162, -0.2177],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6465, -4.1016,  3.2539,  ...,  2.8633, -1.9062, -1.4863],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0060,  0.0117,  0.0077,  ...,  0.0018,  0.0167,  0.0304],
        [-0.0134,  0.0262,  0.0131,  ..., -0.0127,  0.0232, -0.0054],
        [ 0.0074, -0.0175,  0.0125,  ...,  0.0081, -0.0034,  0.0109],
        ...,
        [ 0.0412,  0.0131, -0.0196,  ...,  0.0117, -0.0037, -0.0202],
        [-0.0177,  0.0124, -0.0315,  ..., -0.0182, -0.0123, -0.0256],
        [ 0.0232, -0.0013,  0.0058,  ...,  0.0218, -0.0583,  0.0213]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1240, -4.1914,  3.2988,  ...,  2.6367, -1.9736, -1.5723]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 11:59:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To degrade results in degradation
To reorganize results in reorganization
To realize results in realization
To improvize results in improvization
To install results in installation
To customize results in customization
To oblige results in obligation
To configure results in
2024-07-28 11:59:04 root INFO     [order_1_approx] starting weight calculation for To realize results in realization
To configure results in configuration
To degrade results in degradation
To oblige results in obligation
To reorganize results in reorganization
To install results in installation
To improvize results in improvization
To customize results in
2024-07-28 11:59:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 12:01:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2306, -0.1357, -0.0977,  ...,  0.0157, -0.1406,  0.1705],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0762, -3.7168,  1.0146,  ...,  0.2957, -1.9590, -0.8447],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0320,  0.0027,  0.0136,  ..., -0.0072, -0.0120,  0.0210],
        [-0.0186,  0.0386, -0.0104,  ...,  0.0129,  0.0594,  0.0252],
        [-0.0113, -0.0061,  0.0228,  ...,  0.0039, -0.0298, -0.0171],
        ...,
        [-0.0044, -0.0008, -0.0037,  ...,  0.0362,  0.0333,  0.0078],
        [ 0.0254, -0.0040, -0.0071,  ...,  0.0125,  0.0100,  0.0052],
        [ 0.0110, -0.0105,  0.0121,  ...,  0.0040, -0.0224,  0.0220]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7021, -3.1406,  0.9468,  ...,  0.6992, -2.5781, -0.4729]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 12:01:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To realize results in realization
To configure results in configuration
To degrade results in degradation
To oblige results in obligation
To reorganize results in reorganization
To install results in installation
To improvize results in improvization
To customize results in
2024-07-28 12:01:49 root INFO     [order_1_approx] starting weight calculation for To reorganize results in reorganization
To degrade results in degradation
To realize results in realization
To oblige results in obligation
To configure results in configuration
To install results in installation
To customize results in customization
To improvize results in
2024-07-28 12:01:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 12:04:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0715,  0.2076, -0.2307,  ..., -0.2166, -0.2419, -0.0062],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4023, -3.4629,  0.9326,  ...,  3.3496, -1.5557, -3.0195],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0590,  0.0141, -0.0170,  ..., -0.0303, -0.0238,  0.0185],
        [-0.0585,  0.0332,  0.0149,  ...,  0.0252,  0.0107,  0.0035],
        [-0.0157, -0.0008,  0.0117,  ...,  0.0212,  0.0121,  0.0086],
        ...,
        [-0.0171,  0.0099,  0.0061,  ...,  0.0548, -0.0029, -0.0104],
        [ 0.0034,  0.0027, -0.0180,  ..., -0.0007,  0.0737,  0.0108],
        [ 0.0034,  0.0043,  0.0185,  ..., -0.0008,  0.0046,  0.0287]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6611, -2.1953,  0.5732,  ...,  3.7500, -1.7490, -2.5391]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 12:04:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To reorganize results in reorganization
To degrade results in degradation
To realize results in realization
To oblige results in obligation
To configure results in configuration
To install results in installation
To customize results in customization
To improvize results in
2024-07-28 12:04:33 root INFO     total operator prediction time: 1318.5498485565186 seconds
2024-07-28 12:04:33 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+able_reg
2024-07-28 12:04:33 root INFO     building operator verb+able_reg
2024-07-28 12:04:33 root INFO     [order_1_approx] starting weight calculation for If you can expand something, that thing is expandable
If you can vary something, that thing is variable
If you can replace something, that thing is replaceable
If you can adapt something, that thing is adaptable
If you can sustain something, that thing is sustainable
If you can avoid something, that thing is avoidable
If you can observe something, that thing is observable
If you can accept something, that thing is
2024-07-28 12:04:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 12:07:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0536,  0.4517,  0.2400,  ...,  0.1621, -0.2319,  0.0356],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7734,  1.6572, -1.9199,  ..., -2.7305, -7.8672, -0.8389],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0274,  0.0028, -0.0051,  ...,  0.0119,  0.0164,  0.0058],
        [-0.0096,  0.0285, -0.0121,  ..., -0.0013, -0.0165, -0.0162],
        [-0.0071, -0.0272,  0.0169,  ..., -0.0120, -0.0209,  0.0111],
        ...,
        [ 0.0096,  0.0206,  0.0063,  ...,  0.0229,  0.0135, -0.0320],
        [-0.0026,  0.0188, -0.0091,  ..., -0.0314,  0.0201,  0.0348],
        [-0.0117, -0.0120, -0.0039,  ..., -0.0091, -0.0042, -0.0107]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6387,  1.4141, -1.4668,  ..., -2.5391, -7.8984, -1.0205]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 12:07:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can expand something, that thing is expandable
If you can vary something, that thing is variable
If you can replace something, that thing is replaceable
If you can adapt something, that thing is adaptable
If you can sustain something, that thing is sustainable
If you can avoid something, that thing is avoidable
If you can observe something, that thing is observable
If you can accept something, that thing is
2024-07-28 12:07:19 root INFO     [order_1_approx] starting weight calculation for If you can sustain something, that thing is sustainable
If you can replace something, that thing is replaceable
If you can avoid something, that thing is avoidable
If you can vary something, that thing is variable
If you can observe something, that thing is observable
If you can adapt something, that thing is adaptable
If you can accept something, that thing is acceptable
If you can expand something, that thing is
2024-07-28 12:07:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 12:10:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1769, -0.0328, -0.1094,  ...,  0.0835, -0.2278, -0.0051],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0107,  0.7217, -0.1514,  ..., -2.6289, -7.2188, -3.3477],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0247, -0.0001, -0.0208,  ...,  0.0244,  0.0117,  0.0128],
        [-0.0077,  0.0548,  0.0061,  ..., -0.0145, -0.0433, -0.0131],
        [ 0.0493, -0.0313,  0.0245,  ...,  0.0013, -0.0018, -0.0107],
        ...,
        [ 0.0144,  0.0015,  0.0074,  ...,  0.0323,  0.0100,  0.0013],
        [ 0.0115,  0.0011, -0.0127,  ..., -0.0286,  0.0248,  0.0070],
        [ 0.0235, -0.0042,  0.0076,  ...,  0.0075, -0.0105,  0.0269]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0398,  0.7056,  0.2708,  ..., -3.0488, -7.1484, -3.4492]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 12:10:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can sustain something, that thing is sustainable
If you can replace something, that thing is replaceable
If you can avoid something, that thing is avoidable
If you can vary something, that thing is variable
If you can observe something, that thing is observable
If you can adapt something, that thing is adaptable
If you can accept something, that thing is acceptable
If you can expand something, that thing is
2024-07-28 12:10:02 root INFO     [order_1_approx] starting weight calculation for If you can adapt something, that thing is adaptable
If you can vary something, that thing is variable
If you can replace something, that thing is replaceable
If you can observe something, that thing is observable
If you can expand something, that thing is expandable
If you can avoid something, that thing is avoidable
If you can accept something, that thing is acceptable
If you can sustain something, that thing is
2024-07-28 12:10:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 12:12:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2175,  0.3000,  0.2771,  ...,  0.0600, -0.0958, -0.1489],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8008, -1.2539, -2.2500,  ..., -3.9453, -5.4531, -1.7031],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.8524e-02,  5.2872e-03, -9.4223e-03,  ...,  9.5367e-05,
          1.7731e-02,  3.0918e-03],
        [-8.3084e-03,  1.8570e-02,  3.0098e-03,  ..., -7.4615e-03,
         -4.2305e-03, -6.3705e-03],
        [ 1.4328e-02, -1.2253e-02,  1.5701e-02,  ..., -1.1284e-02,
         -4.0054e-03, -1.3916e-02],
        ...,
        [ 3.5210e-03,  3.2883e-03,  9.6741e-03,  ...,  1.0452e-03,
         -1.2749e-02, -9.3613e-03],
        [ 1.0796e-02,  9.3536e-03, -1.7776e-03,  ..., -1.4610e-02,
         -7.0877e-03, -2.2697e-04],
        [ 2.4300e-03,  8.8959e-03,  7.4081e-03,  ...,  3.3951e-04,
         -1.8372e-02, -7.2784e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6348, -1.3145, -2.1934,  ..., -3.9805, -5.3555, -1.7441]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 12:12:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can adapt something, that thing is adaptable
If you can vary something, that thing is variable
If you can replace something, that thing is replaceable
If you can observe something, that thing is observable
If you can expand something, that thing is expandable
If you can avoid something, that thing is avoidable
If you can accept something, that thing is acceptable
If you can sustain something, that thing is
2024-07-28 12:12:46 root INFO     [order_1_approx] starting weight calculation for If you can expand something, that thing is expandable
If you can observe something, that thing is observable
If you can sustain something, that thing is sustainable
If you can vary something, that thing is variable
If you can replace something, that thing is replaceable
If you can accept something, that thing is acceptable
If you can adapt something, that thing is adaptable
If you can avoid something, that thing is
2024-07-28 12:12:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 12:15:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1743,  0.1990,  0.0868,  ..., -0.1182,  0.1511,  0.0017],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5098,  0.8525, -2.8457,  ..., -0.8521, -6.6328, -1.2598],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0255,  0.0115, -0.0059,  ...,  0.0455,  0.0051,  0.0074],
        [ 0.0157,  0.0319,  0.0159,  ..., -0.0255,  0.0053,  0.0077],
        [ 0.0502, -0.0370,  0.0143,  ...,  0.0010, -0.0099,  0.0085],
        ...,
        [ 0.0081,  0.0067,  0.0081,  ...,  0.0099, -0.0317, -0.0070],
        [-0.0176, -0.0245, -0.0132,  ..., -0.0364,  0.0180, -0.0020],
        [-0.0148, -0.0114, -0.0066,  ..., -0.0185, -0.0205, -0.0234]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5552,  0.9238, -2.4961,  ..., -1.0283, -6.6758, -1.7578]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 12:15:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can expand something, that thing is expandable
If you can observe something, that thing is observable
If you can sustain something, that thing is sustainable
If you can vary something, that thing is variable
If you can replace something, that thing is replaceable
If you can accept something, that thing is acceptable
If you can adapt something, that thing is adaptable
If you can avoid something, that thing is
2024-07-28 12:15:33 root INFO     [order_1_approx] starting weight calculation for If you can observe something, that thing is observable
If you can accept something, that thing is acceptable
If you can adapt something, that thing is adaptable
If you can vary something, that thing is variable
If you can avoid something, that thing is avoidable
If you can sustain something, that thing is sustainable
If you can expand something, that thing is expandable
If you can replace something, that thing is
2024-07-28 12:15:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 12:18:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0474, -0.1048, -0.1072,  ..., -0.0486, -0.1434, -0.1221],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.0996,  1.0146, -1.1855,  ..., -4.4297, -5.8398, -0.1992],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0179,  0.0042, -0.0009,  ...,  0.0095,  0.0258,  0.0504],
        [ 0.0051,  0.0265,  0.0262,  ..., -0.0233, -0.0282,  0.0006],
        [ 0.0322, -0.0045,  0.0131,  ...,  0.0120, -0.0092, -0.0016],
        ...,
        [ 0.0094, -0.0085,  0.0217,  ...,  0.0260, -0.0229,  0.0099],
        [-0.0010, -0.0148, -0.0220,  ..., -0.0626,  0.0410, -0.0242],
        [ 0.0084, -0.0306, -0.0019,  ..., -0.0111, -0.0228,  0.0141]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.8320,  1.1631, -0.8193,  ..., -4.5234, -5.7617, -0.4653]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 12:18:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can observe something, that thing is observable
If you can accept something, that thing is acceptable
If you can adapt something, that thing is adaptable
If you can vary something, that thing is variable
If you can avoid something, that thing is avoidable
If you can sustain something, that thing is sustainable
If you can expand something, that thing is expandable
If you can replace something, that thing is
2024-07-28 12:18:17 root INFO     [order_1_approx] starting weight calculation for If you can sustain something, that thing is sustainable
If you can accept something, that thing is acceptable
If you can avoid something, that thing is avoidable
If you can expand something, that thing is expandable
If you can vary something, that thing is variable
If you can observe something, that thing is observable
If you can replace something, that thing is replaceable
If you can adapt something, that thing is
2024-07-28 12:18:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 12:21:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1974,  0.3992,  0.0306,  ..., -0.0887, -0.0194,  0.0924],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3105,  0.6787, -2.7422,  ..., -1.1729, -8.8984, -0.5195],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0093,  0.0191, -0.0038,  ...,  0.0130,  0.0101,  0.0099],
        [-0.0151,  0.0318,  0.0079,  ...,  0.0061, -0.0222,  0.0254],
        [-0.0003, -0.0199, -0.0179,  ...,  0.0024,  0.0227, -0.0031],
        ...,
        [ 0.0116,  0.0048,  0.0070,  ...,  0.0330,  0.0127, -0.0141],
        [ 0.0253,  0.0289, -0.0136,  ..., -0.0157,  0.0387, -0.0167],
        [ 0.0091,  0.0012, -0.0023,  ...,  0.0043, -0.0303, -0.0088]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3555,  0.6494, -2.3320,  ..., -1.2676, -9.0156, -1.0039]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 12:21:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can sustain something, that thing is sustainable
If you can accept something, that thing is acceptable
If you can avoid something, that thing is avoidable
If you can expand something, that thing is expandable
If you can vary something, that thing is variable
If you can observe something, that thing is observable
If you can replace something, that thing is replaceable
If you can adapt something, that thing is
2024-07-28 12:21:02 root INFO     [order_1_approx] starting weight calculation for If you can replace something, that thing is replaceable
If you can adapt something, that thing is adaptable
If you can avoid something, that thing is avoidable
If you can sustain something, that thing is sustainable
If you can accept something, that thing is acceptable
If you can expand something, that thing is expandable
If you can observe something, that thing is observable
If you can vary something, that thing is
2024-07-28 12:21:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 12:23:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0281,  0.0452, -0.0428,  ...,  0.0405, -0.3325,  0.0647],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1213, -0.0376, -1.4648,  ..., -2.8281, -5.6406, -2.2969],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0263,  0.0458, -0.0034,  ..., -0.0411,  0.0206,  0.0021],
        [-0.0242,  0.0642,  0.0083,  ...,  0.0194,  0.0080, -0.0102],
        [ 0.0016, -0.0165,  0.0005,  ..., -0.0132,  0.0192, -0.0135],
        ...,
        [ 0.0144,  0.0203,  0.0069,  ...,  0.0356,  0.0147,  0.0004],
        [ 0.0313, -0.0033, -0.0001,  ..., -0.0210,  0.0150,  0.0033],
        [-0.0250,  0.0040,  0.0186,  ...,  0.0023, -0.0238, -0.0132]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1523, -0.3157, -1.2080,  ..., -3.0234, -5.6914, -2.5586]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 12:23:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can replace something, that thing is replaceable
If you can adapt something, that thing is adaptable
If you can avoid something, that thing is avoidable
If you can sustain something, that thing is sustainable
If you can accept something, that thing is acceptable
If you can expand something, that thing is expandable
If you can observe something, that thing is observable
If you can vary something, that thing is
2024-07-28 12:23:49 root INFO     [order_1_approx] starting weight calculation for If you can expand something, that thing is expandable
If you can replace something, that thing is replaceable
If you can adapt something, that thing is adaptable
If you can sustain something, that thing is sustainable
If you can vary something, that thing is variable
If you can avoid something, that thing is avoidable
If you can accept something, that thing is acceptable
If you can observe something, that thing is
2024-07-28 12:23:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 12:26:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0801,  0.3606,  0.2400,  ...,  0.0133, -0.0635, -0.2434],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.2441, -0.2664, -0.6211,  ..., -4.0430, -6.7109,  0.1006],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0464, -0.0133,  0.0020,  ...,  0.0109, -0.0058,  0.0272],
        [-0.0104,  0.0296, -0.0023,  ..., -0.0179, -0.0072, -0.0240],
        [-0.0018, -0.0037,  0.0126,  ...,  0.0077, -0.0137,  0.0006],
        ...,
        [ 0.0164,  0.0105, -0.0152,  ...,  0.0349,  0.0049, -0.0027],
        [ 0.0081, -0.0110, -0.0057,  ..., -0.0301,  0.0225,  0.0029],
        [-0.0030,  0.0072,  0.0113,  ...,  0.0061, -0.0088,  0.0009]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.5059, -0.1134, -0.4976,  ..., -3.5742, -6.6328, -0.5283]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 12:26:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can expand something, that thing is expandable
If you can replace something, that thing is replaceable
If you can adapt something, that thing is adaptable
If you can sustain something, that thing is sustainable
If you can vary something, that thing is variable
If you can avoid something, that thing is avoidable
If you can accept something, that thing is acceptable
If you can observe something, that thing is
2024-07-28 12:26:31 root INFO     total operator prediction time: 1317.990062713623 seconds
2024-07-28 12:26:31 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on un+adj_reg
2024-07-28 12:26:31 root INFO     building operator un+adj_reg
2024-07-28 12:26:31 root INFO     [order_1_approx] starting weight calculation for The opposite of wanted is unwanted
The opposite of published is unpublished
The opposite of comfortable is uncomfortable
The opposite of expected is unexpected
The opposite of restricted is unrestricted
The opposite of acceptable is unacceptable
The opposite of available is unavailable
The opposite of desirable is
2024-07-28 12:26:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 12:29:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0236,  0.1603,  0.0683,  ...,  0.0218, -0.1801,  0.0919],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0918, -4.2031,  0.0137,  ..., -0.2761, -3.9844, -3.7188],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.7283e-02, -1.2589e-02, -8.9874e-03,  ...,  2.6443e-02,
         -1.7105e-02,  1.0605e-02],
        [-2.4811e-02,  1.5793e-02, -4.0680e-02,  ..., -8.7509e-03,
         -2.9510e-02, -1.0460e-02],
        [-6.6299e-03,  1.1368e-02,  1.3672e-02,  ..., -1.4572e-02,
          2.4460e-02, -1.7258e-02],
        ...,
        [ 3.7766e-04,  1.9073e-02,  9.9182e-03,  ..., -1.6129e-02,
          2.3041e-03, -3.6469e-02],
        [-1.1177e-02, -2.1515e-03,  3.2501e-02,  ...,  9.9182e-05,
          2.4506e-02, -3.6804e-02],
        [-3.8544e-02,  7.4120e-03, -2.2629e-02,  ...,  1.0178e-02,
         -1.6693e-02,  3.4515e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3110, -3.6543, -0.1884,  ..., -0.0718, -3.7344, -3.2578]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 12:29:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of wanted is unwanted
The opposite of published is unpublished
The opposite of comfortable is uncomfortable
The opposite of expected is unexpected
The opposite of restricted is unrestricted
The opposite of acceptable is unacceptable
The opposite of available is unavailable
The opposite of desirable is
2024-07-28 12:29:12 root INFO     [order_1_approx] starting weight calculation for The opposite of available is unavailable
The opposite of restricted is unrestricted
The opposite of published is unpublished
The opposite of comfortable is uncomfortable
The opposite of wanted is unwanted
The opposite of expected is unexpected
The opposite of desirable is undesirable
The opposite of acceptable is
2024-07-28 12:29:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 12:31:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2051,  0.1788,  0.0993,  ...,  0.0459, -0.3848,  0.2112],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7939e+00, -2.5664e+00,  7.1973e-01,  ...,  2.1973e-03,
        -2.8184e+00, -2.0332e+00], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0253, -0.0348, -0.0155,  ...,  0.0308,  0.0095,  0.0302],
        [-0.0259,  0.0024, -0.0070,  ..., -0.0291, -0.0058,  0.0118],
        [-0.0176, -0.0078, -0.0156,  ...,  0.0250,  0.0082,  0.0102],
        ...,
        [ 0.0045,  0.0341,  0.0130,  ...,  0.0188,  0.0053, -0.0379],
        [-0.0117,  0.0150,  0.0047,  ...,  0.0282,  0.0121, -0.0136],
        [-0.0256,  0.0335, -0.0114,  ..., -0.0146, -0.0243,  0.0215]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9214, -3.4766,  0.5835,  ...,  0.7324, -2.7656, -1.3799]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 12:31:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of available is unavailable
The opposite of restricted is unrestricted
The opposite of published is unpublished
The opposite of comfortable is uncomfortable
The opposite of wanted is unwanted
The opposite of expected is unexpected
The opposite of desirable is undesirable
The opposite of acceptable is
2024-07-28 12:31:56 root INFO     [order_1_approx] starting weight calculation for The opposite of desirable is undesirable
The opposite of wanted is unwanted
The opposite of acceptable is unacceptable
The opposite of comfortable is uncomfortable
The opposite of expected is unexpected
The opposite of restricted is unrestricted
The opposite of published is unpublished
The opposite of available is
2024-07-28 12:31:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 12:34:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1046, -0.0841, -0.0325,  ...,  0.0200, -0.2537,  0.0041],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9399, -2.8223,  1.1602,  ..., -0.9331, -1.0303, -0.0400],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0446, -0.0301,  0.0061,  ...,  0.0513, -0.0027,  0.0402],
        [ 0.0180,  0.0481,  0.0024,  ...,  0.0158, -0.0262, -0.0028],
        [-0.0213,  0.0093,  0.0264,  ..., -0.0136,  0.0008, -0.0501],
        ...,
        [-0.0080,  0.0204, -0.0294,  ...,  0.0094,  0.0328, -0.0057],
        [-0.0374, -0.0017,  0.0053,  ..., -0.0026,  0.0212, -0.0606],
        [-0.0464,  0.0274, -0.0155,  ...,  0.0079, -0.0146,  0.0063]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1836, -3.2480,  1.7012,  ..., -0.9917, -2.0352,  0.3892]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 12:34:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of desirable is undesirable
The opposite of wanted is unwanted
The opposite of acceptable is unacceptable
The opposite of comfortable is uncomfortable
The opposite of expected is unexpected
The opposite of restricted is unrestricted
The opposite of published is unpublished
The opposite of available is
2024-07-28 12:34:39 root INFO     [order_1_approx] starting weight calculation for The opposite of published is unpublished
The opposite of acceptable is unacceptable
The opposite of desirable is undesirable
The opposite of available is unavailable
The opposite of restricted is unrestricted
The opposite of wanted is unwanted
The opposite of comfortable is uncomfortable
The opposite of expected is
2024-07-28 12:34:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 12:37:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1906,  0.1083, -0.0712,  ..., -0.2678, -0.3989, -0.0694],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.2188, -0.2334, -1.2334,  ..., -0.8643, -0.6499, -3.2344],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0003,  0.0137, -0.0067,  ...,  0.0221, -0.0397,  0.0566],
        [-0.0252,  0.0078, -0.0163,  ..., -0.0135,  0.0069, -0.0236],
        [-0.0083, -0.0032,  0.0117,  ...,  0.0336,  0.0255, -0.0169],
        ...,
        [-0.0008,  0.0332,  0.0003,  ...,  0.0229,  0.0146, -0.0166],
        [ 0.0116,  0.0298,  0.0367,  ...,  0.0125,  0.0257, -0.0118],
        [ 0.0287,  0.0007, -0.0282,  ...,  0.0363, -0.0123,  0.0417]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.2305, -0.8203, -1.0244,  ..., -1.0986, -1.0967, -2.9258]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 12:37:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of published is unpublished
The opposite of acceptable is unacceptable
The opposite of desirable is undesirable
The opposite of available is unavailable
The opposite of restricted is unrestricted
The opposite of wanted is unwanted
The opposite of comfortable is uncomfortable
The opposite of expected is
2024-07-28 12:37:26 root INFO     [order_1_approx] starting weight calculation for The opposite of desirable is undesirable
The opposite of restricted is unrestricted
The opposite of published is unpublished
The opposite of acceptable is unacceptable
The opposite of expected is unexpected
The opposite of available is unavailable
The opposite of comfortable is uncomfortable
The opposite of wanted is
2024-07-28 12:37:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 12:40:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2683, -0.0181, -0.2130,  ...,  0.0232, -0.1686,  0.1869],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8359, -2.2520, -0.1309,  ...,  0.2517, -1.8105, -1.8125],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0359, -0.0114,  0.0013,  ...,  0.0128, -0.0172,  0.0009],
        [-0.0330,  0.0467, -0.0138,  ...,  0.0251, -0.0398,  0.0422],
        [-0.0036,  0.0149,  0.0143,  ...,  0.0352,  0.0120, -0.0131],
        ...,
        [-0.0232,  0.0158, -0.0002,  ..., -0.0097,  0.0393,  0.0108],
        [ 0.0401, -0.0223,  0.0010,  ...,  0.0175,  0.0576, -0.0455],
        [-0.0337,  0.0130, -0.0363,  ...,  0.0392,  0.0633,  0.0433]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6426, -3.0039,  0.1265,  ..., -0.1262, -2.4062, -1.3506]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 12:40:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of desirable is undesirable
The opposite of restricted is unrestricted
The opposite of published is unpublished
The opposite of acceptable is unacceptable
The opposite of expected is unexpected
The opposite of available is unavailable
The opposite of comfortable is uncomfortable
The opposite of wanted is
2024-07-28 12:40:10 root INFO     [order_1_approx] starting weight calculation for The opposite of available is unavailable
The opposite of desirable is undesirable
The opposite of restricted is unrestricted
The opposite of acceptable is unacceptable
The opposite of published is unpublished
The opposite of wanted is unwanted
The opposite of expected is unexpected
The opposite of comfortable is
2024-07-28 12:40:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 12:42:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2169, -0.2095,  0.0778,  ..., -0.2002, -0.3975,  0.3855],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3965, -0.8350,  1.0410,  ..., -1.5420,  0.3418,  0.9551],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0576,  0.0060,  0.0034,  ...,  0.0228, -0.0172,  0.0252],
        [-0.0317,  0.0382,  0.0030,  ..., -0.0215, -0.0125, -0.0106],
        [ 0.0112, -0.0039,  0.0004,  ...,  0.0339, -0.0215,  0.0067],
        ...,
        [ 0.0375,  0.0241, -0.0053,  ...,  0.0161, -0.0070, -0.0294],
        [-0.0174,  0.0100,  0.0166,  ..., -0.0224,  0.0257, -0.0057],
        [-0.0392, -0.0066, -0.0439,  ...,  0.0192, -0.0260,  0.0260]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7656, -0.6641,  0.7837,  ..., -1.7295, -0.3369,  1.3301]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 12:42:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of available is unavailable
The opposite of desirable is undesirable
The opposite of restricted is unrestricted
The opposite of acceptable is unacceptable
The opposite of published is unpublished
The opposite of wanted is unwanted
The opposite of expected is unexpected
The opposite of comfortable is
2024-07-28 12:42:55 root INFO     [order_1_approx] starting weight calculation for The opposite of desirable is undesirable
The opposite of wanted is unwanted
The opposite of acceptable is unacceptable
The opposite of expected is unexpected
The opposite of comfortable is uncomfortable
The opposite of published is unpublished
The opposite of available is unavailable
The opposite of restricted is
2024-07-28 12:42:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 12:45:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1149, -0.0222, -0.3472,  ..., -0.0779, -0.1127,  0.1461],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1670,  0.1571,  1.7168,  ...,  0.9194, -1.6582, -0.7676],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0063,  0.0143, -0.0211,  ...,  0.0196,  0.0027,  0.0374],
        [-0.0288,  0.0306,  0.0132,  ..., -0.0449, -0.0119, -0.0242],
        [ 0.0286, -0.0139, -0.0080,  ..., -0.0055, -0.0160, -0.0537],
        ...,
        [ 0.0229,  0.0546,  0.0145,  ...,  0.0015, -0.0008, -0.0107],
        [ 0.0443, -0.0589,  0.0032,  ...,  0.0090, -0.0192, -0.0094],
        [-0.0115,  0.0063, -0.0138,  ...,  0.0148, -0.0136, -0.0022]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7578, -0.3350,  2.6035,  ...,  0.3447, -1.6172, -0.5894]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 12:45:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of desirable is undesirable
The opposite of wanted is unwanted
The opposite of acceptable is unacceptable
The opposite of expected is unexpected
The opposite of comfortable is uncomfortable
The opposite of published is unpublished
The opposite of available is unavailable
The opposite of restricted is
2024-07-28 12:45:40 root INFO     [order_1_approx] starting weight calculation for The opposite of acceptable is unacceptable
The opposite of comfortable is uncomfortable
The opposite of wanted is unwanted
The opposite of available is unavailable
The opposite of expected is unexpected
The opposite of desirable is undesirable
The opposite of restricted is unrestricted
The opposite of published is
2024-07-28 12:45:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 12:48:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1892,  0.0250,  0.0760,  ..., -0.0515, -0.2063,  0.2053],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8340, -1.6553,  0.8213,  ..., -1.5225, -1.6504,  2.1504],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0283, -0.0116,  0.0225,  ...,  0.0451,  0.0128,  0.0363],
        [-0.0122,  0.0463,  0.0131,  ..., -0.0156,  0.0051,  0.0251],
        [ 0.0073, -0.0374,  0.0013,  ..., -0.0154, -0.0038, -0.0433],
        ...,
        [ 0.0284,  0.0204,  0.0029,  ...,  0.0092,  0.0007,  0.0300],
        [-0.0016,  0.0114, -0.0069,  ..., -0.0030,  0.0444, -0.0060],
        [-0.0151,  0.0324, -0.0638,  ...,  0.0250, -0.0149, -0.0619]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5156, -1.5889,  1.4785,  ..., -1.3516, -2.2949,  2.2539]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 12:48:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of acceptable is unacceptable
The opposite of comfortable is uncomfortable
The opposite of wanted is unwanted
The opposite of available is unavailable
The opposite of expected is unexpected
The opposite of desirable is undesirable
The opposite of restricted is unrestricted
The opposite of published is
2024-07-28 12:48:22 root INFO     total operator prediction time: 1310.5190222263336 seconds
2024-07-28 12:48:22 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on re+verb_reg
2024-07-28 12:48:22 root INFO     building operator re+verb_reg
2024-07-28 12:48:22 root INFO     [order_1_approx] starting weight calculation for To emerge again is to reemerge
To engage again is to reengage
To install again is to reinstall
To evaluate again is to reevaluate
To generate again is to regenerate
To calculate again is to recalculate
To occur again is to reoccur
To create again is to
2024-07-28 12:48:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 12:51:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0178,  0.2166,  0.0857,  ...,  0.0768, -0.2042,  0.1089],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.5049, -2.9180,  1.1055,  ...,  3.1367, -3.8027, -1.7246],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0308, -0.0201,  0.0186,  ...,  0.0168,  0.0074,  0.0275],
        [ 0.0065,  0.0132,  0.0095,  ...,  0.0271,  0.0048,  0.0064],
        [ 0.0034, -0.0025,  0.0116,  ..., -0.0064,  0.0046, -0.0400],
        ...,
        [-0.0129, -0.0057, -0.0023,  ...,  0.0216,  0.0152, -0.0174],
        [ 0.0036,  0.0327, -0.0136,  ..., -0.0269,  0.0054, -0.0290],
        [ 0.0050,  0.0072, -0.0063,  ..., -0.0297, -0.0296,  0.0071]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.4287, -2.8379,  1.5391,  ...,  3.4199, -4.1836, -1.5400]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 12:51:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To emerge again is to reemerge
To engage again is to reengage
To install again is to reinstall
To evaluate again is to reevaluate
To generate again is to regenerate
To calculate again is to recalculate
To occur again is to reoccur
To create again is to
2024-07-28 12:51:08 root INFO     [order_1_approx] starting weight calculation for To calculate again is to recalculate
To generate again is to regenerate
To occur again is to reoccur
To install again is to reinstall
To engage again is to reengage
To create again is to recreate
To evaluate again is to reevaluate
To emerge again is to
2024-07-28 12:51:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 12:53:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0161,  0.1897, -0.1106,  ...,  0.1801, -0.1545,  0.1370],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4495, -0.6548, -1.2715,  ...,  3.0781, -3.8418, -3.2871],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0165, -0.0102,  0.0175,  ..., -0.0101, -0.0020, -0.0092],
        [-0.0140,  0.0127, -0.0033,  ...,  0.0074,  0.0044, -0.0015],
        [-0.0033,  0.0219,  0.0004,  ...,  0.0103,  0.0086, -0.0114],
        ...,
        [-0.0180,  0.0084,  0.0129,  ...,  0.0244,  0.0151, -0.0136],
        [-0.0204,  0.0029, -0.0173,  ..., -0.0397, -0.0180, -0.0283],
        [-0.0116, -0.0198,  0.0118,  ..., -0.0029,  0.0040,  0.0096]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6641, -0.4971, -1.4248,  ...,  2.9023, -4.1328, -3.4766]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 12:53:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To calculate again is to recalculate
To generate again is to regenerate
To occur again is to reoccur
To install again is to reinstall
To engage again is to reengage
To create again is to recreate
To evaluate again is to reevaluate
To emerge again is to
2024-07-28 12:53:56 root INFO     [order_1_approx] starting weight calculation for To create again is to recreate
To calculate again is to recalculate
To emerge again is to reemerge
To install again is to reinstall
To evaluate again is to reevaluate
To engage again is to reengage
To occur again is to reoccur
To generate again is to
2024-07-28 12:53:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 12:56:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0682,  0.3184,  0.1105,  ...,  0.1567, -0.1971, -0.0564],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8008, -0.1060, -0.8877,  ...,  2.7754, -2.6895, -3.7227],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0193, -0.0285,  0.0316,  ..., -0.0173,  0.0019,  0.0047],
        [ 0.0092,  0.0262, -0.0063,  ...,  0.0194, -0.0043, -0.0041],
        [ 0.0082, -0.0156,  0.0279,  ..., -0.0104,  0.0068, -0.0109],
        ...,
        [ 0.0076, -0.0149,  0.0039,  ...,  0.0421, -0.0028, -0.0027],
        [ 0.0116,  0.0195, -0.0320,  ...,  0.0035, -0.0101, -0.0073],
        [-0.0130, -0.0165, -0.0150,  ..., -0.0059, -0.0345,  0.0154]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5352, -0.0737, -0.4963,  ...,  2.6602, -3.0098, -3.7500]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 12:56:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To create again is to recreate
To calculate again is to recalculate
To emerge again is to reemerge
To install again is to reinstall
To evaluate again is to reevaluate
To engage again is to reengage
To occur again is to reoccur
To generate again is to
2024-07-28 12:56:43 root INFO     [order_1_approx] starting weight calculation for To create again is to recreate
To occur again is to reoccur
To engage again is to reengage
To emerge again is to reemerge
To calculate again is to recalculate
To install again is to reinstall
To generate again is to regenerate
To evaluate again is to
2024-07-28 12:56:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 12:59:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1163,  0.2185, -0.0849,  ...,  0.1055, -0.1741, -0.0460],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-9.7363e-01, -5.9473e-01, -3.9062e-03,  ..., -3.0176e-01,
        -3.4102e+00, -5.4609e+00], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0334, -0.0089,  0.0360,  ..., -0.0009,  0.0197,  0.0175],
        [ 0.0086,  0.0158, -0.0011,  ...,  0.0141,  0.0062,  0.0176],
        [-0.0141,  0.0081,  0.0036,  ...,  0.0067, -0.0070, -0.0218],
        ...,
        [-0.0003,  0.0093,  0.0038,  ...,  0.0386,  0.0323, -0.0132],
        [-0.0313, -0.0107,  0.0092,  ...,  0.0078,  0.0219,  0.0156],
        [ 0.0023, -0.0018,  0.0204,  ...,  0.0028, -0.0072,  0.0123]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5830, -0.4902,  0.2649,  ..., -0.3618, -3.9922, -5.0312]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 12:59:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To create again is to recreate
To occur again is to reoccur
To engage again is to reengage
To emerge again is to reemerge
To calculate again is to recalculate
To install again is to reinstall
To generate again is to regenerate
To evaluate again is to
2024-07-28 12:59:29 root INFO     [order_1_approx] starting weight calculation for To install again is to reinstall
To create again is to recreate
To engage again is to reengage
To emerge again is to reemerge
To generate again is to regenerate
To occur again is to reoccur
To evaluate again is to reevaluate
To calculate again is to
2024-07-28 12:59:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 13:02:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2581,  0.2496,  0.1716,  ..., -0.1646, -0.3955,  0.0279],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.5859,  0.0553,  2.1191,  ...,  0.8193, -2.5508, -2.4375],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0518, -0.0262,  0.0045,  ...,  0.0142,  0.0272,  0.0283],
        [-0.0007,  0.0304, -0.0093,  ...,  0.0148,  0.0065, -0.0114],
        [-0.0145,  0.0375,  0.0332,  ..., -0.0074, -0.0159, -0.0503],
        ...,
        [ 0.0237,  0.0133,  0.0265,  ...,  0.0349, -0.0097, -0.0101],
        [-0.0124, -0.0224, -0.0094,  ..., -0.0301, -0.0096,  0.0032],
        [-0.0167,  0.0054, -0.0086,  ..., -0.0103, -0.0182,  0.0067]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.2480,  0.1560,  1.9180,  ...,  0.8809, -2.7832, -2.7656]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 13:02:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To install again is to reinstall
To create again is to recreate
To engage again is to reengage
To emerge again is to reemerge
To generate again is to regenerate
To occur again is to reoccur
To evaluate again is to reevaluate
To calculate again is to
2024-07-28 13:02:15 root INFO     [order_1_approx] starting weight calculation for To occur again is to reoccur
To generate again is to regenerate
To emerge again is to reemerge
To calculate again is to recalculate
To install again is to reinstall
To evaluate again is to reevaluate
To create again is to recreate
To engage again is to
2024-07-28 13:02:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 13:05:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0843,  0.3076, -0.0390,  ...,  0.2871, -0.3352,  0.1462],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.2148, -0.8491,  0.6123,  ...,  2.2754, -1.8916, -5.3438],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.3560e-02,  1.4168e-02, -2.7924e-03,  ...,  1.7548e-03,
          1.5930e-02, -1.0559e-02],
        [-9.5291e-03,  4.6570e-02, -1.6083e-02,  ..., -2.1839e-03,
         -4.5013e-03, -7.9498e-03],
        [-1.5450e-02,  8.3618e-03,  1.0757e-02,  ...,  1.2558e-02,
          4.5776e-05, -2.1851e-02],
        ...,
        [ 1.5808e-02, -2.7504e-03, -7.8583e-03,  ...,  2.9739e-02,
          2.3346e-02, -8.1024e-03],
        [-1.5144e-03,  4.8065e-04,  1.0025e-02,  ..., -1.3611e-02,
         -2.8534e-02, -7.7209e-03],
        [-5.8746e-03, -1.9470e-02, -9.0866e-03,  ...,  7.6866e-03,
          6.7024e-03,  2.8168e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4761, -0.5859,  0.8853,  ...,  2.1250, -2.2090, -4.8750]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 13:05:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To occur again is to reoccur
To generate again is to regenerate
To emerge again is to reemerge
To calculate again is to recalculate
To install again is to reinstall
To evaluate again is to reevaluate
To create again is to recreate
To engage again is to
2024-07-28 13:05:02 root INFO     [order_1_approx] starting weight calculation for To create again is to recreate
To calculate again is to recalculate
To evaluate again is to reevaluate
To emerge again is to reemerge
To occur again is to reoccur
To engage again is to reengage
To generate again is to regenerate
To install again is to
2024-07-28 13:05:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 13:07:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2052,  0.0818,  0.0896,  ...,  0.1627, -0.2147,  0.1366],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.4512, -2.8809,  0.1087,  ...,  1.4609, -3.5547, -4.3984],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0230, -0.0188,  0.0270,  ...,  0.0131,  0.0131,  0.0200],
        [-0.0141,  0.0218, -0.0022,  ...,  0.0176, -0.0030,  0.0077],
        [ 0.0459,  0.0255,  0.0049,  ..., -0.0210, -0.0396, -0.0139],
        ...,
        [ 0.0125,  0.0020, -0.0136,  ...,  0.0275,  0.0008,  0.0053],
        [-0.0145, -0.0164, -0.0108,  ..., -0.0027,  0.0069,  0.0066],
        [-0.0040, -0.0068, -0.0091,  ...,  0.0084, -0.0023,  0.0204]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.6611, -2.8066,  0.0370,  ...,  1.1416, -3.3516, -4.4922]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 13:07:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To create again is to recreate
To calculate again is to recalculate
To evaluate again is to reevaluate
To emerge again is to reemerge
To occur again is to reoccur
To engage again is to reengage
To generate again is to regenerate
To install again is to
2024-07-28 13:07:48 root INFO     [order_1_approx] starting weight calculation for To evaluate again is to reevaluate
To generate again is to regenerate
To calculate again is to recalculate
To create again is to recreate
To install again is to reinstall
To emerge again is to reemerge
To engage again is to reengage
To occur again is to
2024-07-28 13:07:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 13:10:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2935,  0.3005, -0.1085,  ..., -0.1167, -0.2649, -0.2820],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.9121, -1.4590,  0.4326,  ...,  1.2432, -2.0293, -1.8428],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0299,  0.0005,  0.0120,  ..., -0.0172,  0.0083, -0.0015],
        [ 0.0103,  0.0138, -0.0202,  ...,  0.0278, -0.0079, -0.0048],
        [ 0.0042,  0.0015, -0.0179,  ..., -0.0289, -0.0299, -0.0415],
        ...,
        [-0.0144, -0.0152,  0.0145,  ...,  0.0467,  0.0095,  0.0219],
        [ 0.0089, -0.0056,  0.0123,  ..., -0.0488,  0.0035, -0.0167],
        [-0.0036,  0.0049, -0.0081,  ..., -0.0146, -0.0230,  0.0322]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.7109, -1.1367,  0.2059,  ...,  1.2783, -2.1016, -1.5996]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 13:10:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To evaluate again is to reevaluate
To generate again is to regenerate
To calculate again is to recalculate
To create again is to recreate
To install again is to reinstall
To emerge again is to reemerge
To engage again is to reengage
To occur again is to
2024-07-28 13:10:31 root INFO     total operator prediction time: 1328.9914274215698 seconds
2024-07-28 13:10:31 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj+ness_reg
2024-07-28 13:10:31 root INFO     building operator adj+ness_reg
2024-07-28 13:10:31 root INFO     [order_1_approx] starting weight calculation for The state of being hot is hotness
The state of being obvious is obviousness
The state of being pure is pureness
The state of being cheap is cheapness
The state of being innovative is innovativeness
The state of being happy is happiness
The state of being broken is brokenness
The state of being unique is
2024-07-28 13:10:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 13:13:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3254,  0.0604, -0.0380,  ...,  0.1636, -0.2573, -0.0717],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9058, -4.1289, -0.9307,  ..., -2.3262, -4.8711, -0.9189],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0124,  0.0119,  0.0140,  ..., -0.0146, -0.0003,  0.0049],
        [-0.0207,  0.0207,  0.0040,  ..., -0.0066, -0.0008,  0.0071],
        [-0.0083, -0.0076,  0.0199,  ...,  0.0055, -0.0044, -0.0290],
        ...,
        [ 0.0065,  0.0247,  0.0202,  ...,  0.0215,  0.0087,  0.0160],
        [ 0.0043, -0.0006,  0.0026,  ...,  0.0113,  0.0116, -0.0105],
        [-0.0065,  0.0241, -0.0185,  ...,  0.0103,  0.0070,  0.0305]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8301, -4.1133, -0.9487,  ..., -1.9941, -5.6094, -1.0537]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 13:13:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being hot is hotness
The state of being obvious is obviousness
The state of being pure is pureness
The state of being cheap is cheapness
The state of being innovative is innovativeness
The state of being happy is happiness
The state of being broken is brokenness
The state of being unique is
2024-07-28 13:13:15 root INFO     [order_1_approx] starting weight calculation for The state of being innovative is innovativeness
The state of being pure is pureness
The state of being obvious is obviousness
The state of being happy is happiness
The state of being unique is uniqueness
The state of being broken is brokenness
The state of being cheap is cheapness
The state of being hot is
2024-07-28 13:13:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 13:16:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1144, -0.0134,  0.1418,  ..., -0.0170, -0.2563, -0.0948],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.9727, -2.7891, -0.1240,  ..., -3.8711, -5.9297, -0.6235],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0253,  0.0129,  0.0086,  ..., -0.0606, -0.0145,  0.0308],
        [-0.0080,  0.0029,  0.0141,  ..., -0.0341,  0.0030,  0.0108],
        [-0.0096,  0.0049,  0.0269,  ...,  0.0069, -0.0026,  0.0138],
        ...,
        [ 0.0362, -0.0161,  0.0178,  ...,  0.0305,  0.0152, -0.0054],
        [ 0.0227, -0.0293, -0.0171,  ..., -0.0081,  0.0372, -0.0146],
        [ 0.0047, -0.0075, -0.0321,  ...,  0.0213, -0.0030,  0.0376]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.0098, -2.6484, -0.4368,  ..., -4.4531, -6.3359, -0.7554]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 13:16:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being innovative is innovativeness
The state of being pure is pureness
The state of being obvious is obviousness
The state of being happy is happiness
The state of being unique is uniqueness
The state of being broken is brokenness
The state of being cheap is cheapness
The state of being hot is
2024-07-28 13:16:01 root INFO     [order_1_approx] starting weight calculation for The state of being unique is uniqueness
The state of being cheap is cheapness
The state of being broken is brokenness
The state of being innovative is innovativeness
The state of being hot is hotness
The state of being pure is pureness
The state of being obvious is obviousness
The state of being happy is
2024-07-28 13:16:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 13:18:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0265, -0.0622, -0.1519,  ..., -0.2139, -0.3765,  0.0546],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3223, -0.3018,  0.8975,  ..., -2.5352, -4.9375, -2.2910],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.9144e-02,  1.6968e-02,  1.8967e-02,  ..., -1.4191e-02,
         -3.5095e-04,  4.8637e-03],
        [-2.9358e-02,  9.3460e-03,  5.4741e-03,  ...,  1.2337e-02,
         -1.5640e-02,  1.3046e-02],
        [-1.0765e-02, -2.4033e-02,  1.4923e-02,  ...,  2.9259e-03,
         -1.6205e-02, -1.5244e-02],
        ...,
        [-3.0518e-05, -1.1505e-02, -1.2112e-03,  ...,  3.1982e-02,
         -2.6001e-02, -2.3254e-02],
        [-1.2024e-02, -1.7395e-02,  1.5327e-02,  ..., -2.0889e-02,
          5.0842e-02, -1.5228e-02],
        [ 1.6495e-02,  6.9618e-04, -3.2471e-02,  ...,  3.5034e-02,
         -4.1290e-02,  3.2440e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3818, -0.5039,  0.9307,  ..., -2.2422, -4.8320, -2.7461]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 13:18:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being unique is uniqueness
The state of being cheap is cheapness
The state of being broken is brokenness
The state of being innovative is innovativeness
The state of being hot is hotness
The state of being pure is pureness
The state of being obvious is obviousness
The state of being happy is
2024-07-28 13:18:47 root INFO     [order_1_approx] starting weight calculation for The state of being cheap is cheapness
The state of being innovative is innovativeness
The state of being obvious is obviousness
The state of being hot is hotness
The state of being pure is pureness
The state of being happy is happiness
The state of being unique is uniqueness
The state of being broken is
2024-07-28 13:18:47 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 13:21:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1818,  0.1648, -0.0571,  ..., -0.0984, -0.3521,  0.0717],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9619, -5.3516, -0.8301,  ..., -2.5566,  0.3323, -0.2515],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.7090e-02,  1.4931e-02, -5.8517e-03,  ..., -1.4343e-02,
          1.8402e-02,  1.7715e-02],
        [ 1.9745e-02, -2.8259e-02, -1.7426e-02,  ...,  3.1097e-02,
         -1.9073e-04,  2.3041e-02],
        [ 2.3346e-03, -3.2867e-02, -8.9569e-03,  ..., -6.3896e-04,
          3.7422e-03, -2.8992e-03],
        ...,
        [ 5.4718e-02, -1.1383e-02,  9.4376e-03,  ...,  2.9694e-02,
         -1.6205e-02, -4.4708e-03],
        [-5.3955e-02,  2.0294e-02,  2.3743e-02,  ..., -6.3354e-02,
          3.1219e-02, -5.5206e-02],
        [ 2.2690e-02, -2.2888e-05, -1.1826e-02,  ...,  3.8513e-02,
          1.0536e-02,  3.5736e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1270, -5.0195, -0.5020,  ..., -2.6309, -0.0999, -0.3384]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 13:21:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being cheap is cheapness
The state of being innovative is innovativeness
The state of being obvious is obviousness
The state of being hot is hotness
The state of being pure is pureness
The state of being happy is happiness
The state of being unique is uniqueness
The state of being broken is
2024-07-28 13:21:33 root INFO     [order_1_approx] starting weight calculation for The state of being innovative is innovativeness
The state of being happy is happiness
The state of being unique is uniqueness
The state of being broken is brokenness
The state of being hot is hotness
The state of being obvious is obviousness
The state of being cheap is cheapness
The state of being pure is
2024-07-28 13:21:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 13:24:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1671, -0.0673,  0.2805,  ..., -0.2312, -0.2715,  0.0812],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8750, -2.8887, -1.7461,  ..., -3.2812, -3.9062, -3.3359],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0439, -0.0086, -0.0110,  ..., -0.0380, -0.0088, -0.0003],
        [-0.0049,  0.0191,  0.0237,  ..., -0.0031,  0.0103,  0.0328],
        [ 0.0081, -0.0069,  0.0298,  ...,  0.0491, -0.0227,  0.0142],
        ...,
        [ 0.0250,  0.0038,  0.0055,  ..., -0.0165, -0.0046,  0.0086],
        [ 0.0116, -0.0408, -0.0150,  ...,  0.0150,  0.0360, -0.0081],
        [ 0.0011, -0.0036, -0.0095,  ...,  0.0258, -0.0018,  0.0540]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8672, -3.1152, -2.1230,  ..., -3.7695, -4.1523, -3.1797]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 13:24:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being innovative is innovativeness
The state of being happy is happiness
The state of being unique is uniqueness
The state of being broken is brokenness
The state of being hot is hotness
The state of being obvious is obviousness
The state of being cheap is cheapness
The state of being pure is
2024-07-28 13:24:19 root INFO     [order_1_approx] starting weight calculation for The state of being obvious is obviousness
The state of being innovative is innovativeness
The state of being unique is uniqueness
The state of being happy is happiness
The state of being broken is brokenness
The state of being pure is pureness
The state of being hot is hotness
The state of being cheap is
2024-07-28 13:24:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 13:27:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2568, -0.0927, -0.0106,  ...,  0.0361, -0.1896,  0.0208],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0420, -0.3271, -1.9004,  ..., -4.0820, -6.1406, -2.0430],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.3203e-02, -1.2115e-02,  1.1948e-02,  ..., -3.8025e-02,
         -1.5671e-02,  2.4063e-02],
        [-1.7334e-02, -7.2594e-03,  1.4023e-02,  ...,  1.1063e-02,
          1.6129e-02,  1.6205e-02],
        [ 3.4332e-05,  1.0826e-02,  2.0905e-02,  ...,  1.1948e-02,
         -1.7838e-02,  1.3237e-03],
        ...,
        [ 1.6800e-02, -8.6899e-03,  8.1329e-03,  ...,  1.9684e-02,
          2.1286e-02,  1.1185e-02],
        [ 2.1988e-02, -9.6512e-03,  1.6495e-02,  ..., -2.8381e-02,
         -2.4414e-02, -1.7700e-03],
        [-1.5488e-02, -5.0583e-03, -5.3680e-02,  ...,  3.4424e-02,
          4.8950e-02,  1.6205e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1680, -0.6904, -2.2266,  ..., -4.3438, -6.6055, -2.3770]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 13:27:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being obvious is obviousness
The state of being innovative is innovativeness
The state of being unique is uniqueness
The state of being happy is happiness
The state of being broken is brokenness
The state of being pure is pureness
The state of being hot is hotness
The state of being cheap is
2024-07-28 13:27:01 root INFO     [order_1_approx] starting weight calculation for The state of being unique is uniqueness
The state of being hot is hotness
The state of being innovative is innovativeness
The state of being cheap is cheapness
The state of being pure is pureness
The state of being happy is happiness
The state of being broken is brokenness
The state of being obvious is
2024-07-28 13:27:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 13:29:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0586,  0.2231, -0.0436,  ..., -0.1466, -0.6855,  0.0833],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1680, -4.2891, -0.9551,  ..., -3.1816, -4.6953,  0.9951],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0300,  0.0041, -0.0172,  ...,  0.0357, -0.0141,  0.0271],
        [-0.0068,  0.0256, -0.0223,  ..., -0.0210, -0.0090,  0.0018],
        [-0.0049, -0.0230,  0.0007,  ...,  0.0301, -0.0219,  0.0093],
        ...,
        [ 0.0261,  0.0053,  0.0407,  ...,  0.0285, -0.0085,  0.0252],
        [ 0.0104, -0.0141,  0.0029,  ..., -0.0081, -0.0048, -0.0283],
        [ 0.0040,  0.0248,  0.0076,  ...,  0.0026,  0.0058,  0.0054]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2617, -4.5000, -1.2637,  ..., -3.4258, -4.8867,  1.0225]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 13:29:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being unique is uniqueness
The state of being hot is hotness
The state of being innovative is innovativeness
The state of being cheap is cheapness
The state of being pure is pureness
The state of being happy is happiness
The state of being broken is brokenness
The state of being obvious is
2024-07-28 13:29:48 root INFO     [order_1_approx] starting weight calculation for The state of being pure is pureness
The state of being cheap is cheapness
The state of being broken is brokenness
The state of being hot is hotness
The state of being happy is happiness
The state of being unique is uniqueness
The state of being obvious is obviousness
The state of being innovative is
2024-07-28 13:29:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 13:32:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1843,  0.1316,  0.0085,  ..., -0.0347, -0.2275, -0.1246],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1367, -3.6172, -0.4346,  ...,  0.8745, -1.1094, -2.7539],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0105,  0.0036,  0.0059,  ...,  0.0004,  0.0023,  0.0138],
        [-0.0065,  0.0089,  0.0066,  ...,  0.0010, -0.0081,  0.0073],
        [ 0.0010, -0.0277,  0.0108,  ...,  0.0092,  0.0021, -0.0190],
        ...,
        [ 0.0068, -0.0032,  0.0067,  ...,  0.0108,  0.0094,  0.0196],
        [ 0.0001,  0.0128,  0.0012,  ..., -0.0093,  0.0084, -0.0110],
        [ 0.0005, -0.0112, -0.0035,  ...,  0.0043, -0.0161,  0.0144]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3447, -3.3711, -0.5479,  ...,  0.9233, -1.2803, -2.8359]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 13:32:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being pure is pureness
The state of being cheap is cheapness
The state of being broken is brokenness
The state of being hot is hotness
The state of being happy is happiness
The state of being unique is uniqueness
The state of being obvious is obviousness
The state of being innovative is
2024-07-28 13:32:31 root INFO     total operator prediction time: 1320.1660034656525 seconds
2024-07-28 13:32:31 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun+less_reg
2024-07-28 13:32:31 root INFO     building operator noun+less_reg
2024-07-28 13:32:31 root INFO     [order_1_approx] starting weight calculation for Something without speech is speechless
Something without odor is odorless
Something without expression is expressionless
Something without tooth is toothless
Something without remorse is remorseless
Something without ruth is ruthless
Something without faith is faithless
Something without breath is
2024-07-28 13:32:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 13:35:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1898, -0.3062, -0.0760,  ..., -0.3721, -0.1005,  0.0413],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5098, -4.4844,  1.4961,  ..., -2.5625, -2.5508, -1.4082],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0324, -0.0178,  0.0165,  ...,  0.0027,  0.0309,  0.0314],
        [ 0.0053,  0.0409, -0.0035,  ...,  0.0132, -0.0094, -0.0173],
        [ 0.0014, -0.0482,  0.0287,  ..., -0.0269, -0.0219,  0.0071],
        ...,
        [-0.0078,  0.0298, -0.0213,  ..., -0.0041, -0.0036, -0.0422],
        [-0.0020,  0.0070,  0.0069,  ..., -0.0253, -0.0093, -0.0215],
        [-0.0046, -0.0185, -0.0374,  ...,  0.0209, -0.0071,  0.0148]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2090, -3.7930,  0.8047,  ..., -2.3438, -2.5547, -2.3125]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 13:35:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without speech is speechless
Something without odor is odorless
Something without expression is expressionless
Something without tooth is toothless
Something without remorse is remorseless
Something without ruth is ruthless
Something without faith is faithless
Something without breath is
2024-07-28 13:35:12 root INFO     [order_1_approx] starting weight calculation for Something without expression is expressionless
Something without breath is breathless
Something without faith is faithless
Something without ruth is ruthless
Something without odor is odorless
Something without remorse is remorseless
Something without speech is speechless
Something without tooth is
2024-07-28 13:35:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 13:37:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1173, -0.2035,  0.1976,  ..., -0.2297,  0.0389,  0.0450],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4014, -3.2500, -1.4678,  ..., -0.4360, -5.8242, -1.6553],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0265, -0.0084,  0.0869,  ..., -0.0235,  0.0162,  0.0408],
        [ 0.0379, -0.0032,  0.0088,  ..., -0.0114, -0.0041,  0.0301],
        [ 0.0269, -0.0202,  0.0230,  ..., -0.0057, -0.0100,  0.0325],
        ...,
        [ 0.0232,  0.0265, -0.0065,  ...,  0.0438,  0.0089, -0.0208],
        [-0.0128, -0.0092, -0.0410,  ...,  0.0275, -0.0323, -0.0559],
        [-0.0098, -0.0122,  0.0151,  ...,  0.0328, -0.0094,  0.0132]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3496, -3.2637, -1.6543,  ..., -0.3096, -4.7422, -2.2129]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 13:37:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without expression is expressionless
Something without breath is breathless
Something without faith is faithless
Something without ruth is ruthless
Something without odor is odorless
Something without remorse is remorseless
Something without speech is speechless
Something without tooth is
2024-07-28 13:37:55 root INFO     [order_1_approx] starting weight calculation for Something without odor is odorless
Something without expression is expressionless
Something without remorse is remorseless
Something without tooth is toothless
Something without faith is faithless
Something without ruth is ruthless
Something without breath is breathless
Something without speech is
2024-07-28 13:37:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 13:40:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0455, -0.0801,  0.2059,  ...,  0.1129,  0.1365,  0.1982],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.9746, -1.9824,  0.3887,  ..., -0.0566, -1.2832, -0.1562],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0455, -0.0095,  0.0316,  ..., -0.0408,  0.0257,  0.0518],
        [ 0.0078,  0.0485, -0.0100,  ...,  0.0224, -0.0023, -0.0063],
        [ 0.0144, -0.0192,  0.0204,  ...,  0.0066, -0.0078,  0.0019],
        ...,
        [-0.0038, -0.0047,  0.0131,  ..., -0.0027,  0.0220, -0.0249],
        [-0.0277, -0.0261,  0.0126,  ..., -0.0063,  0.0214, -0.0352],
        [-0.0071, -0.0033, -0.0042,  ...,  0.0017,  0.0120,  0.0156]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2559, -2.1035,  0.4451,  ..., -0.2534, -1.0000, -0.7314]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 13:40:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without odor is odorless
Something without expression is expressionless
Something without remorse is remorseless
Something without tooth is toothless
Something without faith is faithless
Something without ruth is ruthless
Something without breath is breathless
Something without speech is
2024-07-28 13:40:38 root INFO     [order_1_approx] starting weight calculation for Something without odor is odorless
Something without speech is speechless
Something without tooth is toothless
Something without breath is breathless
Something without faith is faithless
Something without ruth is ruthless
Something without remorse is remorseless
Something without expression is
2024-07-28 13:40:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 13:43:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0112, -0.0850,  0.1937,  ...,  0.1617, -0.0219, -0.0197],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1074, -2.5000,  1.9033,  ..., -2.4961, -2.1328, -1.8789],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0432,  0.0198,  0.0071,  ..., -0.0077, -0.0042,  0.0357],
        [ 0.0041,  0.0492, -0.0012,  ...,  0.0066,  0.0142, -0.0117],
        [-0.0164,  0.0069,  0.0403,  ..., -0.0179,  0.0289, -0.0394],
        ...,
        [ 0.0179,  0.0431,  0.0081,  ..., -0.0001,  0.0289, -0.0354],
        [-0.0333, -0.0111, -0.0103,  ..., -0.0140, -0.0141, -0.0178],
        [ 0.0185, -0.0239, -0.0179,  ...,  0.0380, -0.0021,  0.0386]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1182, -2.6035,  2.3809,  ..., -2.0098, -2.1914, -2.4160]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 13:43:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without odor is odorless
Something without speech is speechless
Something without tooth is toothless
Something without breath is breathless
Something without faith is faithless
Something without ruth is ruthless
Something without remorse is remorseless
Something without expression is
2024-07-28 13:43:23 root INFO     [order_1_approx] starting weight calculation for Something without speech is speechless
Something without expression is expressionless
Something without odor is odorless
Something without faith is faithless
Something without breath is breathless
Something without tooth is toothless
Something without ruth is ruthless
Something without remorse is
2024-07-28 13:43:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 13:46:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0999,  0.0708,  0.0573,  ...,  0.0180, -0.1843,  0.2336],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0781, -2.8184,  0.9829,  ..., -3.4688, -1.3066, -1.5244],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 8.9951e-03, -1.3855e-02,  5.9967e-03,  ..., -4.3945e-03,
         -3.8700e-03,  2.2156e-02],
        [ 2.1606e-02,  3.6049e-03,  2.6550e-02,  ..., -7.1869e-03,
         -3.1090e-03,  6.2790e-03],
        [-4.2877e-03,  2.5757e-02,  1.5900e-02,  ..., -1.6281e-02,
         -8.1062e-05, -5.6458e-04],
        ...,
        [ 2.2690e-02,  2.2598e-02,  1.5656e-02,  ..., -1.7715e-02,
          4.0741e-03,  9.8724e-03],
        [-2.0264e-02,  1.7090e-02,  3.3569e-03,  ..., -8.3694e-03,
         -1.4435e-02, -2.7985e-02],
        [ 1.1444e-05, -5.5084e-03,  1.7410e-02,  ...,  2.3270e-02,
         -1.0056e-02,  3.4943e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8867, -2.7344,  0.6860,  ..., -3.5312, -1.2051, -1.5801]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 13:46:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without speech is speechless
Something without expression is expressionless
Something without odor is odorless
Something without faith is faithless
Something without breath is breathless
Something without tooth is toothless
Something without ruth is ruthless
Something without remorse is
2024-07-28 13:46:08 root INFO     [order_1_approx] starting weight calculation for Something without speech is speechless
Something without remorse is remorseless
Something without odor is odorless
Something without tooth is toothless
Something without breath is breathless
Something without faith is faithless
Something without expression is expressionless
Something without ruth is
2024-07-28 13:46:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 13:48:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1385,  0.0075,  0.2607,  ..., -0.2732, -0.0131,  0.0358],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2246, -3.1426, -1.3340,  ..., -1.7676, -0.5996, -1.5371],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0297, -0.0212,  0.0146,  ..., -0.0129,  0.0004,  0.0261],
        [ 0.0126, -0.0070,  0.0141,  ..., -0.0265, -0.0026,  0.0106],
        [ 0.0186, -0.0014,  0.0342,  ..., -0.0088, -0.0142, -0.0108],
        ...,
        [ 0.0143,  0.0100,  0.0040,  ...,  0.0192,  0.0017, -0.0110],
        [-0.0267,  0.0208, -0.0028,  ...,  0.0226,  0.0205, -0.0191],
        [ 0.0090, -0.0172, -0.0062,  ..., -0.0024, -0.0150,  0.0252]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3848, -3.3027, -1.3984,  ..., -1.7588, -0.7373, -1.9941]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 13:48:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without speech is speechless
Something without remorse is remorseless
Something without odor is odorless
Something without tooth is toothless
Something without breath is breathless
Something without faith is faithless
Something without expression is expressionless
Something without ruth is
2024-07-28 13:48:50 root INFO     [order_1_approx] starting weight calculation for Something without breath is breathless
Something without remorse is remorseless
Something without ruth is ruthless
Something without speech is speechless
Something without expression is expressionless
Something without odor is odorless
Something without tooth is toothless
Something without faith is
2024-07-28 13:48:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 13:51:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1262, -0.0250,  0.1215,  ..., -0.0853, -0.2039,  0.5039],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.3047, -3.1875,  0.6768,  ...,  0.0237, -3.6445, -0.7363],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0188, -0.0120,  0.0161,  ..., -0.0260, -0.0066,  0.0184],
        [ 0.0107,  0.0330, -0.0036,  ...,  0.0086,  0.0020, -0.0229],
        [ 0.0223, -0.0008,  0.0355,  ...,  0.0028, -0.0064, -0.0013],
        ...,
        [ 0.0083,  0.0282, -0.0049,  ...,  0.0121,  0.0098, -0.0215],
        [-0.0270,  0.0265,  0.0019,  ..., -0.0051,  0.0139, -0.0204],
        [ 0.0343, -0.0062,  0.0095,  ...,  0.0098, -0.0230,  0.0232]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.7148, -2.8867,  0.0371,  ..., -0.0391, -4.3398, -1.6631]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 13:51:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without breath is breathless
Something without remorse is remorseless
Something without ruth is ruthless
Something without speech is speechless
Something without expression is expressionless
Something without odor is odorless
Something without tooth is toothless
Something without faith is
2024-07-28 13:51:34 root INFO     [order_1_approx] starting weight calculation for Something without breath is breathless
Something without expression is expressionless
Something without faith is faithless
Something without ruth is ruthless
Something without speech is speechless
Something without tooth is toothless
Something without remorse is remorseless
Something without odor is
2024-07-28 13:51:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 13:54:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1086, -0.2729,  0.0593,  ..., -0.4189, -0.0551, -0.0994],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2227, -3.8555, -0.5156,  ..., -3.7539, -6.3203, -0.9912],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0472, -0.0113,  0.0381,  ..., -0.0030,  0.0155,  0.0237],
        [-0.0046,  0.0278, -0.0128,  ..., -0.0274, -0.0065,  0.0092],
        [ 0.0290, -0.0171,  0.0522,  ..., -0.0076, -0.0220,  0.0064],
        ...,
        [ 0.0224,  0.0179,  0.0017,  ...,  0.0298,  0.0011, -0.0016],
        [ 0.0152, -0.0190, -0.0003,  ...,  0.0264,  0.0262, -0.0163],
        [-0.0053, -0.0211, -0.0151,  ...,  0.0258, -0.0082,  0.0040]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2344, -3.8027,  0.1523,  ..., -4.0234, -6.3633, -1.1104]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 13:54:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without breath is breathless
Something without expression is expressionless
Something without faith is faithless
Something without ruth is ruthless
Something without speech is speechless
Something without tooth is toothless
Something without remorse is remorseless
Something without odor is
2024-07-28 13:54:18 root INFO     total operator prediction time: 1307.4061381816864 seconds
2024-07-28 13:54:18 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+ment_irreg
2024-07-28 13:54:18 root INFO     building operator verb+ment_irreg
2024-07-28 13:54:18 root INFO     [order_1_approx] starting weight calculation for To develop results in a development
To appoint results in a appointment
To enroll results in a enrollment
To involve results in a involvement
To accomplish results in a accomplishment
To impair results in a impairment
To disappoint results in a disappointment
To embarrass results in a
2024-07-28 13:54:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 13:57:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1888,  0.2810, -0.2646,  ...,  0.0582, -0.2864,  0.3232],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2148, -0.5254,  0.0293,  ...,  1.5605,  2.6367, -2.6738],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.9185e-02, -4.4556e-03, -6.8321e-03,  ..., -3.6285e-02,
          2.0569e-02,  1.7487e-02],
        [-1.2413e-02,  5.1849e-02, -6.9237e-04,  ...,  1.7883e-02,
         -8.7204e-03,  1.0010e-02],
        [-2.4445e-02, -2.1713e-02, -6.0959e-03,  ...,  2.1790e-02,
         -2.0340e-02, -7.7057e-03],
        ...,
        [ 1.4183e-02,  2.5681e-02, -8.8348e-03,  ...,  2.1820e-02,
         -1.3855e-02, -7.6904e-03],
        [-1.3016e-02,  4.4098e-03, -4.9438e-03,  ...,  5.8556e-04,
         -1.7548e-04, -1.4915e-02],
        [-5.7220e-05,  6.8054e-03, -3.1261e-03,  ...,  2.4689e-02,
         -2.2720e-02,  2.6642e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4805, -0.2524,  0.5083,  ...,  1.8311,  2.4473, -2.5801]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 13:57:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To develop results in a development
To appoint results in a appointment
To enroll results in a enrollment
To involve results in a involvement
To accomplish results in a accomplishment
To impair results in a impairment
To disappoint results in a disappointment
To embarrass results in a
2024-07-28 13:57:03 root INFO     [order_1_approx] starting weight calculation for To accomplish results in a accomplishment
To enroll results in a enrollment
To disappoint results in a disappointment
To appoint results in a appointment
To develop results in a development
To embarrass results in a embarrassment
To involve results in a involvement
To impair results in a
2024-07-28 13:57:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 13:59:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1210,  0.2312, -0.1256,  ...,  0.0452, -0.1852,  0.1086],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.7891, -2.5195, -0.9062,  ..., -0.3025,  0.5645, -3.1406],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0748,  0.0341,  0.0704,  ..., -0.0369, -0.0469, -0.0016],
        [-0.0852,  0.0463, -0.0667,  ...,  0.0422,  0.1027,  0.0061],
        [ 0.0159, -0.0251,  0.0219,  ...,  0.0030,  0.0088, -0.0267],
        ...,
        [-0.0260,  0.0224, -0.0527,  ...,  0.0526,  0.0677, -0.0196],
        [-0.0172, -0.0347, -0.0049,  ...,  0.0178,  0.0521, -0.0056],
        [-0.0082, -0.0045, -0.0067,  ...,  0.0040, -0.0494,  0.0185]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.5820, -3.0449, -0.6992,  ..., -0.4336, -0.0142, -2.8477]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 13:59:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To accomplish results in a accomplishment
To enroll results in a enrollment
To disappoint results in a disappointment
To appoint results in a appointment
To develop results in a development
To embarrass results in a embarrassment
To involve results in a involvement
To impair results in a
2024-07-28 13:59:49 root INFO     [order_1_approx] starting weight calculation for To develop results in a development
To appoint results in a appointment
To disappoint results in a disappointment
To involve results in a involvement
To embarrass results in a embarrassment
To accomplish results in a accomplishment
To impair results in a impairment
To enroll results in a
2024-07-28 13:59:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 14:02:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1802,  0.2627, -0.0898,  ...,  0.0521, -0.0718, -0.3066],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3760, -1.9531, -1.0693,  ...,  1.0244, -0.8652, -5.2617],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.6499e-02, -1.3809e-03,  1.6098e-02,  ..., -2.1011e-02,
          2.5696e-02,  9.3536e-03],
        [-2.1301e-02,  2.0538e-02,  1.9493e-03,  ...,  1.9226e-03,
          4.6143e-02, -9.6893e-03],
        [-1.2917e-02, -2.2308e-02,  2.8244e-02,  ...,  2.9678e-03,
          8.5220e-03, -2.7283e-02],
        ...,
        [ 1.7014e-02,  1.4069e-02, -7.7820e-03,  ...,  4.2023e-02,
          1.4420e-02, -9.1400e-03],
        [ 9.9487e-03,  2.4128e-03,  3.1616e-02,  ..., -9.8228e-05,
          3.4180e-02,  1.4336e-02],
        [-2.8809e-02, -2.0813e-02, -7.5989e-03,  ..., -1.2497e-02,
         -1.1497e-02,  4.5776e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6958, -1.6445, -0.8638,  ...,  0.7266, -1.0186, -5.6016]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 14:02:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To develop results in a development
To appoint results in a appointment
To disappoint results in a disappointment
To involve results in a involvement
To embarrass results in a embarrassment
To accomplish results in a accomplishment
To impair results in a impairment
To enroll results in a
2024-07-28 14:02:33 root INFO     [order_1_approx] starting weight calculation for To develop results in a development
To disappoint results in a disappointment
To embarrass results in a embarrassment
To impair results in a impairment
To enroll results in a enrollment
To appoint results in a appointment
To involve results in a involvement
To accomplish results in a
2024-07-28 14:02:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 14:05:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0439,  0.3352,  0.0395,  ...,  0.1606, -0.4319, -0.0426],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0371, -2.2773, -1.1201,  ...,  1.1865,  0.2551, -0.5557],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-9.9182e-05,  6.3553e-03,  7.5531e-03,  ...,  3.4119e-02,
          4.8645e-02, -4.8218e-03],
        [-1.5869e-02,  6.9946e-02,  4.2496e-03,  ...,  8.8043e-03,
          3.8849e-02, -1.2314e-02],
        [ 1.9043e-02, -4.5135e-02,  3.2257e-02,  ..., -1.8066e-02,
          1.8311e-04,  9.1476e-03],
        ...,
        [ 1.6998e-02,  4.0436e-02, -1.3153e-02,  ...,  8.5449e-02,
          5.1422e-02, -3.0075e-02],
        [ 2.3590e-02,  1.1841e-02,  1.8234e-02,  ..., -1.3016e-02,
         -2.0523e-03,  3.2043e-04],
        [-5.7831e-03,  1.9623e-02,  1.5396e-02,  ...,  1.6968e-02,
         -4.5471e-02,  3.7933e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0020, -1.5176, -0.9893,  ...,  1.2920,  0.3413, -0.4448]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 14:05:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To develop results in a development
To disappoint results in a disappointment
To embarrass results in a embarrassment
To impair results in a impairment
To enroll results in a enrollment
To appoint results in a appointment
To involve results in a involvement
To accomplish results in a
2024-07-28 14:05:20 root INFO     [order_1_approx] starting weight calculation for To develop results in a development
To disappoint results in a disappointment
To embarrass results in a embarrassment
To impair results in a impairment
To enroll results in a enrollment
To accomplish results in a accomplishment
To involve results in a involvement
To appoint results in a
2024-07-28 14:05:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 14:08:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1642,  0.5225, -0.0516,  ...,  0.1433, -0.1921, -0.2053],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1934, -2.7539,  0.3188,  ...,  2.9805, -1.5127, -1.6904],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0396, -0.0270, -0.0004,  ..., -0.0391,  0.0352, -0.0046],
        [-0.0611,  0.0518, -0.0244,  ...,  0.0501,  0.0458,  0.0357],
        [ 0.0066, -0.0288, -0.0088,  ..., -0.0108, -0.0084, -0.0220],
        ...,
        [-0.0054,  0.0425, -0.0041,  ...,  0.0284,  0.0250,  0.0328],
        [ 0.0208, -0.0188, -0.0087,  ..., -0.0108, -0.0065, -0.0197],
        [ 0.0117,  0.0134, -0.0164,  ...,  0.0550, -0.0393,  0.0412]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0674, -1.7930,  0.0945,  ...,  2.6289, -1.7822, -1.5596]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 14:08:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To develop results in a development
To disappoint results in a disappointment
To embarrass results in a embarrassment
To impair results in a impairment
To enroll results in a enrollment
To accomplish results in a accomplishment
To involve results in a involvement
To appoint results in a
2024-07-28 14:08:04 root INFO     [order_1_approx] starting weight calculation for To embarrass results in a embarrassment
To develop results in a development
To accomplish results in a accomplishment
To impair results in a impairment
To enroll results in a enrollment
To involve results in a involvement
To appoint results in a appointment
To disappoint results in a
2024-07-28 14:08:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 14:10:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0814,  0.5483, -0.2949,  ...,  0.0202, -0.2979, -0.0443],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4590, -3.3008,  0.2363,  ...,  1.0146,  2.2695, -1.7051],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0084,  0.0224, -0.0280,  ...,  0.0236, -0.0005,  0.0033],
        [-0.0050,  0.0334,  0.0258,  ...,  0.0304,  0.0223,  0.0137],
        [ 0.0337, -0.0461, -0.0404,  ..., -0.0141, -0.0170,  0.0047],
        ...,
        [ 0.0285,  0.0129, -0.0105,  ...,  0.0329,  0.0132,  0.0186],
        [ 0.0211, -0.0145,  0.0338,  ...,  0.0119, -0.0204, -0.0294],
        [-0.0051,  0.0199, -0.0009,  ...,  0.0056, -0.0737, -0.0171]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3965, -3.3301,  0.2144,  ...,  0.8271,  1.9219, -1.8311]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 14:10:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To embarrass results in a embarrassment
To develop results in a development
To accomplish results in a accomplishment
To impair results in a impairment
To enroll results in a enrollment
To involve results in a involvement
To appoint results in a appointment
To disappoint results in a
2024-07-28 14:10:49 root INFO     [order_1_approx] starting weight calculation for To impair results in a impairment
To embarrass results in a embarrassment
To appoint results in a appointment
To accomplish results in a accomplishment
To enroll results in a enrollment
To disappoint results in a disappointment
To develop results in a development
To involve results in a
2024-07-28 14:10:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 14:13:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1403,  0.1207, -0.0739,  ...,  0.2261, -0.3794, -0.0759],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7354, -3.1719,  1.4678,  ...,  2.2520,  0.3994, -4.4297],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0640, -0.0415, -0.0342,  ...,  0.0925,  0.0741,  0.0812],
        [-0.0414,  0.0573, -0.0005,  ..., -0.0054,  0.0410,  0.0097],
        [ 0.0054, -0.0407, -0.0158,  ...,  0.0013, -0.0011, -0.0356],
        ...,
        [ 0.0609,  0.0167, -0.0069,  ..., -0.0061,  0.0024,  0.0402],
        [-0.0078,  0.0285,  0.0337,  ..., -0.0182, -0.0607, -0.0498],
        [ 0.0464,  0.0302,  0.0466,  ..., -0.0342, -0.0981,  0.0117]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2578, -2.4883,  0.8569,  ...,  2.0605,  0.2905, -3.7031]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 14:13:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To impair results in a impairment
To embarrass results in a embarrassment
To appoint results in a appointment
To accomplish results in a accomplishment
To enroll results in a enrollment
To disappoint results in a disappointment
To develop results in a development
To involve results in a
2024-07-28 14:13:35 root INFO     [order_1_approx] starting weight calculation for To appoint results in a appointment
To involve results in a involvement
To accomplish results in a accomplishment
To enroll results in a enrollment
To disappoint results in a disappointment
To embarrass results in a embarrassment
To impair results in a impairment
To develop results in a
2024-07-28 14:13:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 14:16:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1069,  0.3369,  0.2510,  ..., -0.0158, -0.2456, -0.0842],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0859, -4.9688,  0.8848,  ...,  3.3145, -2.5586, -2.7715],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0253,  0.0049, -0.0022,  ..., -0.0034,  0.0060, -0.0055],
        [-0.0266,  0.0396,  0.0121,  ...,  0.0385,  0.0756,  0.0361],
        [ 0.0138, -0.0154, -0.0014,  ...,  0.0230,  0.0230,  0.0223],
        ...,
        [ 0.0163, -0.0029,  0.0363,  ...,  0.0411,  0.0062,  0.0013],
        [-0.0041, -0.0228, -0.0086,  ..., -0.0230,  0.0356, -0.0068],
        [ 0.0099, -0.0236, -0.0075,  ...,  0.0212, -0.0533,  0.0311]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3438, -4.7734,  0.8550,  ...,  2.7227, -2.7559, -2.6191]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 14:16:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To appoint results in a appointment
To involve results in a involvement
To accomplish results in a accomplishment
To enroll results in a enrollment
To disappoint results in a disappointment
To embarrass results in a embarrassment
To impair results in a impairment
To develop results in a
2024-07-28 14:16:19 root INFO     total operator prediction time: 1320.822172164917 seconds
2024-07-28 14:16:19 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on UK_city - county
2024-07-28 14:16:19 root INFO     building operator UK_city - county
2024-07-28 14:16:19 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of salisbury is in the county of wiltshire
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of brighton is in the county of sussex
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of oxford is in the county of oxfordshire
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of sheffield is in the county of
2024-07-28 14:16:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 14:19:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0894, -0.1031, -0.2432,  ...,  0.1074,  0.0655,  0.1312],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0762, -4.2891,  0.9575,  ..., -2.3027,  0.0728,  0.8750],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0098,  0.0126,  0.0150,  ..., -0.0029, -0.0050, -0.0031],
        [-0.0015,  0.0081, -0.0063,  ..., -0.0033, -0.0081,  0.0022],
        [-0.0276,  0.0140,  0.0091,  ...,  0.0103, -0.0018, -0.0351],
        ...,
        [-0.0007,  0.0132, -0.0033,  ...,  0.0140,  0.0104, -0.0125],
        [ 0.0151,  0.0068,  0.0036,  ...,  0.0073, -0.0279,  0.0052],
        [-0.0195, -0.0095, -0.0067,  ..., -0.0035, -0.0061, -0.0177]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8320, -4.3086,  1.0117,  ..., -2.3047,  0.2793,  0.9814]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 14:19:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of salisbury is in the county of wiltshire
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of brighton is in the county of sussex
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of oxford is in the county of oxfordshire
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of sheffield is in the county of
2024-07-28 14:19:54 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of salisbury is in the county of wiltshire
In the United Kingdom, the city of sheffield is in the county of yorkshire
In the United Kingdom, the city of oxford is in the county of oxfordshire
In the United Kingdom, the city of brighton is in the county of sussex
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of belfast is in the county of
2024-07-28 14:19:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 14:23:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1238,  0.1050, -0.5146,  ...,  0.2349, -0.3232,  0.2089],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.1172, -5.0234,  1.6113,  ..., -2.3477, -0.5176, -1.3975],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0179,  0.0170,  0.0092,  ...,  0.0121, -0.0127, -0.0190],
        [ 0.0073,  0.0009,  0.0142,  ...,  0.0027, -0.0105, -0.0021],
        [-0.0226,  0.0067,  0.0031,  ...,  0.0034,  0.0168, -0.0219],
        ...,
        [-0.0164,  0.0086, -0.0069,  ...,  0.0187, -0.0048, -0.0257],
        [ 0.0124, -0.0104,  0.0122,  ...,  0.0191, -0.0084,  0.0092],
        [-0.0017, -0.0167,  0.0091,  ..., -0.0049,  0.0111,  0.0067]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 6.0195, -5.0195,  1.4902,  ..., -2.4121, -0.3149, -1.2695]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 14:23:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of salisbury is in the county of wiltshire
In the United Kingdom, the city of sheffield is in the county of yorkshire
In the United Kingdom, the city of oxford is in the county of oxfordshire
In the United Kingdom, the city of brighton is in the county of sussex
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of belfast is in the county of
2024-07-28 14:23:07 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of brighton is in the county of sussex
In the United Kingdom, the city of oxford is in the county of oxfordshire
In the United Kingdom, the city of salisbury is in the county of wiltshire
In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of sheffield is in the county of yorkshire
In the United Kingdom, the city of swansea is in the county of
2024-07-28 14:23:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 14:26:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0201, -0.0408, -0.4250,  ...,  0.1434, -0.2173,  0.1072],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6562, -4.1719, -0.1177,  ..., -2.4551, -1.4980,  1.5996],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0078,  0.0112,  0.0141,  ..., -0.0064, -0.0047, -0.0089],
        [ 0.0021,  0.0208,  0.0010,  ...,  0.0065, -0.0061,  0.0038],
        [-0.0363,  0.0081, -0.0024,  ...,  0.0081,  0.0265, -0.0367],
        ...,
        [ 0.0005,  0.0033, -0.0060,  ...,  0.0074,  0.0224, -0.0218],
        [ 0.0063, -0.0082,  0.0208,  ...,  0.0038, -0.0334,  0.0208],
        [-0.0166, -0.0082, -0.0016,  ..., -0.0099,  0.0145, -0.0126]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3613, -4.3711, -0.3364,  ..., -2.3770, -1.2979,  1.4932]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 14:26:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of brighton is in the county of sussex
In the United Kingdom, the city of oxford is in the county of oxfordshire
In the United Kingdom, the city of salisbury is in the county of wiltshire
In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of sheffield is in the county of yorkshire
In the United Kingdom, the city of swansea is in the county of
2024-07-28 14:26:30 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of brighton is in the county of sussex
In the United Kingdom, the city of oxford is in the county of oxfordshire
In the United Kingdom, the city of sheffield is in the county of yorkshire
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of salisbury is in the county of
2024-07-28 14:26:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 14:29:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0596, -0.0221, -0.2118,  ..., -0.0090, -0.3867, -0.0085],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5820, -3.4375, -0.1377,  ..., -0.6074, -0.8760, -1.7061],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0192,  0.0054,  0.0133,  ..., -0.0040, -0.0171, -0.0169],
        [-0.0017,  0.0119,  0.0094,  ...,  0.0296, -0.0155, -0.0055],
        [-0.0469,  0.0002,  0.0137,  ...,  0.0148,  0.0245, -0.0455],
        ...,
        [-0.0050,  0.0020, -0.0193,  ...,  0.0310,  0.0132, -0.0147],
        [ 0.0265, -0.0213,  0.0063,  ...,  0.0018, -0.0362,  0.0345],
        [-0.0130,  0.0044, -0.0155,  ...,  0.0003,  0.0249, -0.0061]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3047, -3.4277, -0.4116,  ..., -0.5078, -0.3320, -1.9033]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 14:29:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of brighton is in the county of sussex
In the United Kingdom, the city of oxford is in the county of oxfordshire
In the United Kingdom, the city of sheffield is in the county of yorkshire
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of salisbury is in the county of
2024-07-28 14:29:45 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of oxford is in the county of oxfordshire
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of sheffield is in the county of yorkshire
In the United Kingdom, the city of salisbury is in the county of wiltshire
In the United Kingdom, the city of brighton is in the county of
2024-07-28 14:29:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 14:33:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4131,  0.0938, -0.0416,  ...,  0.4417, -0.2084,  0.0121],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9082, -3.3711, -0.5854,  ..., -2.4922,  1.5371, -0.4331],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0026,  0.0108,  0.0211,  ..., -0.0234, -0.0096, -0.0252],
        [-0.0102,  0.0258,  0.0175,  ...,  0.0229, -0.0114, -0.0197],
        [-0.0112, -0.0064,  0.0120,  ...,  0.0382,  0.0014, -0.0135],
        ...,
        [ 0.0100,  0.0107, -0.0095,  ...,  0.0107, -0.0077, -0.0042],
        [ 0.0049, -0.0088,  0.0075,  ...,  0.0300, -0.0011,  0.0103],
        [-0.0024, -0.0017, -0.0009,  ..., -0.0143,  0.0002,  0.0044]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6846, -3.3633, -0.6958,  ..., -2.3848,  1.7822, -0.2749]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 14:33:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of oxford is in the county of oxfordshire
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of sheffield is in the county of yorkshire
In the United Kingdom, the city of salisbury is in the county of wiltshire
In the United Kingdom, the city of brighton is in the county of
2024-07-28 14:33:03 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of brighton is in the county of sussex
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of salisbury is in the county of wiltshire
In the United Kingdom, the city of sheffield is in the county of yorkshire
In the United Kingdom, the city of oxford is in the county of
2024-07-28 14:33:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 14:36:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0421,  0.1877, -0.0952,  ...,  0.0524, -0.0662, -0.1824],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.3281, -4.4023, -1.1094,  ..., -0.6309, -0.3633, -2.8223],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0042,  0.0139,  0.0261,  ..., -0.0073, -0.0174,  0.0088],
        [-0.0105,  0.0157,  0.0134,  ...,  0.0097, -0.0240, -0.0088],
        [-0.0167,  0.0037, -0.0049,  ..., -0.0046,  0.0011,  0.0051],
        ...,
        [ 0.0035,  0.0030, -0.0065,  ...,  0.0293,  0.0143, -0.0230],
        [ 0.0152, -0.0341,  0.0067,  ..., -0.0124, -0.0183,  0.0104],
        [-0.0039,  0.0135, -0.0076,  ..., -0.0044, -0.0243,  0.0032]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.3164, -4.1680, -1.6230,  ..., -0.5020, -0.2150, -3.1973]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 14:36:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of brighton is in the county of sussex
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of salisbury is in the county of wiltshire
In the United Kingdom, the city of sheffield is in the county of yorkshire
In the United Kingdom, the city of oxford is in the county of
2024-07-28 14:36:20 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of oxford is in the county of oxfordshire
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of sheffield is in the county of yorkshire
In the United Kingdom, the city of brighton is in the county of sussex
In the United Kingdom, the city of salisbury is in the county of wiltshire
In the United Kingdom, the city of carlisle is in the county of
2024-07-28 14:36:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 14:39:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1641,  0.0767, -0.3499,  ..., -0.0894, -0.4385,  0.3289],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3574, -2.5547,  1.1641,  ..., -4.9766,  1.3242,  0.5107],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0228,  0.0078,  0.0292,  ..., -0.0032, -0.0041, -0.0064],
        [-0.0025,  0.0150,  0.0124,  ...,  0.0326,  0.0004, -0.0466],
        [-0.0370, -0.0033,  0.0087,  ...,  0.0184,  0.0128, -0.0282],
        ...,
        [ 0.0053,  0.0008, -0.0167,  ...,  0.0441,  0.0204, -0.0280],
        [ 0.0206, -0.0098, -0.0084,  ..., -0.0103, -0.0414,  0.0571],
        [ 0.0214, -0.0195, -0.0061,  ..., -0.0084,  0.0169, -0.0146]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2159, -3.0117,  1.0342,  ..., -4.9297,  1.7012,  0.5142]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 14:39:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of oxford is in the county of oxfordshire
In the United Kingdom, the city of preston is in the county of lancashire
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of sheffield is in the county of yorkshire
In the United Kingdom, the city of brighton is in the county of sussex
In the United Kingdom, the city of salisbury is in the county of wiltshire
In the United Kingdom, the city of carlisle is in the county of
2024-07-28 14:39:43 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of brighton is in the county of sussex
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of oxford is in the county of oxfordshire
In the United Kingdom, the city of salisbury is in the county of wiltshire
In the United Kingdom, the city of sheffield is in the county of yorkshire
In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of preston is in the county of
2024-07-28 14:39:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 14:43:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0475,  0.1812, -0.3213,  ...,  0.3149, -0.2136,  0.0098],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2148, -4.2422,  1.2793,  ..., -1.9473,  0.9463, -1.5684],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0191,  0.0049, -0.0012,  ..., -0.0074, -0.0065, -0.0198],
        [ 0.0164,  0.0318,  0.0051,  ...,  0.0247,  0.0014,  0.0021],
        [-0.0141,  0.0325,  0.0037,  ...,  0.0445,  0.0028, -0.0405],
        ...,
        [ 0.0007,  0.0174, -0.0060,  ...,  0.0571, -0.0269, -0.0636],
        [ 0.0145, -0.0227, -0.0030,  ..., -0.0069, -0.0215, -0.0032],
        [ 0.0259, -0.0166, -0.0113,  ...,  0.0092, -0.0359, -0.0362]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2383, -4.2734,  1.4629,  ..., -1.6279,  0.9971, -1.3213]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 14:43:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of brighton is in the county of sussex
In the United Kingdom, the city of belfast is in the county of antrim
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of oxford is in the county of oxfordshire
In the United Kingdom, the city of salisbury is in the county of wiltshire
In the United Kingdom, the city of sheffield is in the county of yorkshire
In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of preston is in the county of
2024-07-28 14:43:03 root INFO     total operator prediction time: 1603.6768071651459 seconds
2024-07-28 14:43:03 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on name - nationality
2024-07-28 14:43:03 root INFO     building operator name - nationality
2024-07-28 14:43:03 root INFO     [order_1_approx] starting weight calculation for mozart was german
confucius was chinese
raphael was italian
wagner was german
aristotle was greek
dickens was english
truman was american
leibniz was
2024-07-28 14:43:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 14:45:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1893,  0.2101, -0.2773,  ..., -0.2023,  0.0311,  0.1409],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5107, -4.2344,  1.0244,  ..., -2.7422, -1.2979, -0.5391],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0570, -0.0112, -0.0187,  ..., -0.0386, -0.0089, -0.0056],
        [ 0.0225,  0.0579,  0.0282,  ...,  0.0138, -0.0087,  0.0013],
        [ 0.0159, -0.0097,  0.0524,  ..., -0.0018, -0.0168,  0.0282],
        ...,
        [ 0.0291,  0.0028, -0.0075,  ...,  0.0475, -0.0218,  0.0309],
        [-0.0131,  0.0051,  0.0018,  ...,  0.0092,  0.0201,  0.0017],
        [-0.0110, -0.0006,  0.0190,  ..., -0.0003, -0.0094,  0.0534]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6230, -4.0312,  0.6519,  ..., -2.4297, -1.1953, -0.9775]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 14:45:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for mozart was german
confucius was chinese
raphael was italian
wagner was german
aristotle was greek
dickens was english
truman was american
leibniz was
2024-07-28 14:45:50 root INFO     [order_1_approx] starting weight calculation for leibniz was german
truman was american
wagner was german
confucius was chinese
aristotle was greek
raphael was italian
dickens was english
mozart was
2024-07-28 14:45:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 14:48:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1503,  0.2546, -0.3547,  ..., -0.2754, -0.0497, -0.1106],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3672, -4.3359,  1.2422,  ..., -2.2031, -1.4590, -0.7119],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0132,  0.0305, -0.0405,  ..., -0.0003,  0.0149, -0.1187],
        [-0.0011,  0.0208,  0.0535,  ..., -0.0273,  0.0056,  0.0862],
        [-0.0273, -0.0048,  0.0470,  ...,  0.0015, -0.0107, -0.0017],
        ...,
        [ 0.0215, -0.0065,  0.0204,  ...,  0.0157, -0.0287,  0.0576],
        [ 0.0016,  0.0082,  0.0053,  ...,  0.0410,  0.0223,  0.0011],
        [-0.0045, -0.0394,  0.0208,  ..., -0.0089, -0.0193,  0.1193]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5371, -4.4453,  0.7705,  ..., -1.9980, -1.2393, -0.7231]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 14:48:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for leibniz was german
truman was american
wagner was german
confucius was chinese
aristotle was greek
raphael was italian
dickens was english
mozart was
2024-07-28 14:48:33 root INFO     [order_1_approx] starting weight calculation for wagner was german
dickens was english
truman was american
mozart was german
leibniz was german
raphael was italian
aristotle was greek
confucius was
2024-07-28 14:48:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 14:51:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0768,  0.0573, -0.6738,  ..., -0.1176, -0.2954, -0.1073],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8545, -0.9482,  1.7500,  ..., -4.7031,  0.3555,  0.7920],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.8574e-02,  4.1351e-03, -6.3057e-03,  ..., -6.5613e-03,
         -5.5847e-02,  2.3376e-02],
        [ 7.4043e-03,  1.0551e-02,  7.7744e-03,  ..., -9.9182e-05,
          8.6212e-03, -1.2299e-02],
        [-1.5572e-02, -2.7962e-03,  3.7415e-02,  ...,  2.7893e-02,
         -8.5297e-03, -2.1591e-02],
        ...,
        [ 3.5156e-02,  4.1809e-03, -7.1411e-03,  ...,  1.2985e-02,
         -1.7471e-02,  2.3071e-02],
        [-6.3019e-03,  1.0872e-02, -4.2343e-03,  ...,  6.5498e-03,
          2.1759e-02, -3.8544e-02],
        [-2.6352e-02, -1.1215e-02,  1.9897e-02,  ..., -2.3670e-03,
         -1.9501e-02,  3.2990e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4453, -0.9561,  1.5967,  ..., -4.5625,  0.2717,  1.0947]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 14:51:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for wagner was german
dickens was english
truman was american
mozart was german
leibniz was german
raphael was italian
aristotle was greek
confucius was
2024-07-28 14:51:18 root INFO     [order_1_approx] starting weight calculation for mozart was german
dickens was english
leibniz was german
wagner was german
truman was american
raphael was italian
confucius was chinese
aristotle was
2024-07-28 14:51:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 14:54:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3318,  0.0473, -0.4756,  ..., -0.3198, -0.2198,  0.1492],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0488, -4.7812, -0.8188,  ..., -4.1953, -0.8574, -0.7905],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0510, -0.0170, -0.0167,  ..., -0.0109, -0.0233, -0.0196],
        [ 0.0031,  0.0007,  0.0208,  ..., -0.0041, -0.0278,  0.0464],
        [-0.0142, -0.0040,  0.0290,  ...,  0.0048, -0.0027, -0.0057],
        ...,
        [ 0.0536, -0.0052,  0.0113,  ...,  0.0215, -0.0323,  0.0271],
        [-0.0009,  0.0042, -0.0008,  ..., -0.0032,  0.0172, -0.0248],
        [-0.0408, -0.0017,  0.0284,  ..., -0.0246, -0.0126,  0.0693]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1582, -4.3906, -1.1973,  ..., -3.4707, -1.1621, -0.4680]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 14:54:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for mozart was german
dickens was english
leibniz was german
wagner was german
truman was american
raphael was italian
confucius was chinese
aristotle was
2024-07-28 14:54:03 root INFO     [order_1_approx] starting weight calculation for leibniz was german
wagner was german
aristotle was greek
mozart was german
confucius was chinese
truman was american
dickens was english
raphael was
2024-07-28 14:54:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 14:56:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3975, -0.0757, -0.1388,  ..., -0.1775, -0.0575,  0.0492],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.5156, -4.7891,  1.9951,  ..., -4.5234, -1.0195, -1.5068],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0422,  0.0038, -0.0211,  ..., -0.0034, -0.0260, -0.0139],
        [ 0.0349,  0.0029,  0.0430,  ..., -0.0387, -0.0442,  0.0074],
        [-0.0170, -0.0123,  0.0396,  ...,  0.0133,  0.0039, -0.0095],
        ...,
        [ 0.0587,  0.0043, -0.0010,  ...,  0.0479, -0.0095,  0.0075],
        [ 0.0138, -0.0244,  0.0188,  ..., -0.0463,  0.0117, -0.0056],
        [ 0.0053, -0.0049, -0.0310,  ..., -0.0259, -0.0290,  0.0898]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.8906, -4.0000,  1.7188,  ..., -3.9277, -1.2520, -1.1084]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 14:56:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for leibniz was german
wagner was german
aristotle was greek
mozart was german
confucius was chinese
truman was american
dickens was english
raphael was
2024-07-28 14:56:48 root INFO     [order_1_approx] starting weight calculation for confucius was chinese
leibniz was german
raphael was italian
dickens was english
mozart was german
wagner was german
aristotle was greek
truman was
2024-07-28 14:56:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 14:59:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1808,  0.2515, -0.3049,  ...,  0.0905, -0.1823,  0.2040],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7891, -2.3281,  1.0156,  ..., -3.2949,  2.3320, -1.1436],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0374, -0.0042,  0.0135,  ..., -0.0179, -0.0227, -0.0020],
        [-0.0455,  0.0477,  0.0001,  ..., -0.0151,  0.0083, -0.0299],
        [-0.0061, -0.0089,  0.0370,  ..., -0.0020, -0.0147,  0.0211],
        ...,
        [ 0.0103,  0.0054, -0.0067,  ...,  0.0465, -0.0213,  0.0020],
        [ 0.0021,  0.0007, -0.0084,  ...,  0.0045, -0.0039,  0.0175],
        [-0.0179,  0.0212, -0.0025,  ...,  0.0125, -0.0154,  0.0194]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0703, -2.2656,  0.7139,  ..., -3.3613,  2.0938, -0.4702]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 14:59:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for confucius was chinese
leibniz was german
raphael was italian
dickens was english
mozart was german
wagner was german
aristotle was greek
truman was
2024-07-28 14:59:33 root INFO     [order_1_approx] starting weight calculation for aristotle was greek
truman was american
raphael was italian
mozart was german
confucius was chinese
leibniz was german
dickens was english
wagner was
2024-07-28 14:59:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 15:02:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2732,  0.4263, -0.0558,  ...,  0.2322,  0.0341,  0.1340],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3125, -5.6211,  0.4502,  ..., -2.4434, -1.7578, -1.1768],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0162, -0.0149, -0.0513,  ..., -0.0170, -0.0408, -0.0834],
        [ 0.0497,  0.0314,  0.0359,  ...,  0.0248,  0.0425,  0.0085],
        [-0.0422,  0.0215,  0.0575,  ...,  0.0140,  0.0190, -0.0300],
        ...,
        [ 0.0259,  0.0230,  0.0302,  ...,  0.0372, -0.0074,  0.0549],
        [ 0.0556,  0.0071,  0.0393,  ...,  0.0187,  0.0174,  0.0046],
        [ 0.0227,  0.0075,  0.0241,  ...,  0.0109,  0.0142,  0.0936]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3105, -5.8555, -0.0190,  ..., -2.4473, -1.9775, -0.6616]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 15:02:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for aristotle was greek
truman was american
raphael was italian
mozart was german
confucius was chinese
leibniz was german
dickens was english
wagner was
2024-07-28 15:02:18 root INFO     [order_1_approx] starting weight calculation for wagner was german
mozart was german
truman was american
aristotle was greek
leibniz was german
raphael was italian
confucius was chinese
dickens was
2024-07-28 15:02:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 15:05:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0757,  0.4460, -0.2632,  ...,  0.0980, -0.0107, -0.0117],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1875, -2.1816,  1.4678,  ..., -3.9180,  0.6162, -3.9023],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0635,  0.0023,  0.0245,  ..., -0.0279, -0.0443, -0.0250],
        [-0.0119,  0.0082,  0.0181,  ...,  0.0277,  0.0698,  0.0294],
        [-0.0271, -0.0045,  0.0512,  ...,  0.0286,  0.0327,  0.0221],
        ...,
        [ 0.0560,  0.0328,  0.0231,  ...,  0.0450, -0.0150,  0.0286],
        [-0.0029, -0.0141,  0.0186,  ...,  0.0088, -0.0197, -0.0082],
        [ 0.0175,  0.0249, -0.0006,  ...,  0.0274,  0.0383,  0.0776]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2910, -2.1797,  1.6836,  ..., -3.4805,  0.3706, -3.3496]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 15:05:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for wagner was german
mozart was german
truman was american
aristotle was greek
leibniz was german
raphael was italian
confucius was chinese
dickens was
2024-07-28 15:05:03 root INFO     total operator prediction time: 1320.5981216430664 seconds
2024-07-28 15:05:03 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on country - language
2024-07-28 15:05:03 root INFO     building operator country - language
2024-07-28 15:05:04 root INFO     [order_1_approx] starting weight calculation for The country of mexico primarily speaks the language of spanish
The country of palestine primarily speaks the language of arabic
The country of syria primarily speaks the language of arabic
The country of australia primarily speaks the language of english
The country of guatemala primarily speaks the language of spanish
The country of nicaragua primarily speaks the language of spanish
The country of haiti primarily speaks the language of creole
The country of austria primarily speaks the language of
2024-07-28 15:05:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 15:07:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1765,  0.0150, -0.2981,  ...,  0.1296, -0.1379,  0.0167],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2477, -6.9844,  0.3931,  ..., -0.4229, -0.5654, -1.9023],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0232, -0.0146, -0.0107,  ..., -0.0177,  0.0183,  0.0152],
        [ 0.0234,  0.0264, -0.0082,  ..., -0.0052,  0.0100, -0.0083],
        [-0.0039, -0.0030,  0.0301,  ...,  0.0055, -0.0069,  0.0058],
        ...,
        [-0.0159,  0.0009, -0.0154,  ...,  0.0192, -0.0106, -0.0262],
        [ 0.0038,  0.0007,  0.0052,  ...,  0.0124,  0.0208,  0.0136],
        [ 0.0149, -0.0147, -0.0083,  ..., -0.0044, -0.0116,  0.0194]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0516, -6.5430,  0.5410,  ..., -0.4597, -0.5884, -1.8584]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 15:07:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of mexico primarily speaks the language of spanish
The country of palestine primarily speaks the language of arabic
The country of syria primarily speaks the language of arabic
The country of australia primarily speaks the language of english
The country of guatemala primarily speaks the language of spanish
The country of nicaragua primarily speaks the language of spanish
The country of haiti primarily speaks the language of creole
The country of austria primarily speaks the language of
2024-07-28 15:07:50 root INFO     [order_1_approx] starting weight calculation for The country of palestine primarily speaks the language of arabic
The country of austria primarily speaks the language of german
The country of mexico primarily speaks the language of spanish
The country of syria primarily speaks the language of arabic
The country of haiti primarily speaks the language of creole
The country of australia primarily speaks the language of english
The country of guatemala primarily speaks the language of spanish
The country of nicaragua primarily speaks the language of
2024-07-28 15:07:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 15:10:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0397, -0.2969, -0.0833,  ...,  0.1719, -0.5674, -0.0795],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.2930, -2.5430,  0.6338,  ..., -0.1453, -0.9277, -4.0039],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0111,  0.0007,  0.0029,  ..., -0.0113,  0.0093, -0.0058],
        [ 0.0031,  0.0036,  0.0143,  ..., -0.0045, -0.0105,  0.0083],
        [-0.0068,  0.0033,  0.0166,  ..., -0.0047, -0.0028, -0.0160],
        ...,
        [-0.0092,  0.0042, -0.0163,  ...,  0.0116, -0.0021, -0.0141],
        [ 0.0056, -0.0084,  0.0158,  ...,  0.0034,  0.0049, -0.0074],
        [-0.0016, -0.0084, -0.0053,  ...,  0.0013, -0.0057,  0.0115]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.2021, -2.3867,  0.5205,  ..., -0.4399, -0.8145, -3.9531]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 15:10:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of palestine primarily speaks the language of arabic
The country of austria primarily speaks the language of german
The country of mexico primarily speaks the language of spanish
The country of syria primarily speaks the language of arabic
The country of haiti primarily speaks the language of creole
The country of australia primarily speaks the language of english
The country of guatemala primarily speaks the language of spanish
The country of nicaragua primarily speaks the language of
2024-07-28 15:10:34 root INFO     [order_1_approx] starting weight calculation for The country of palestine primarily speaks the language of arabic
The country of haiti primarily speaks the language of creole
The country of nicaragua primarily speaks the language of spanish
The country of mexico primarily speaks the language of spanish
The country of syria primarily speaks the language of arabic
The country of guatemala primarily speaks the language of spanish
The country of austria primarily speaks the language of german
The country of australia primarily speaks the language of
2024-07-28 15:10:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 15:13:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0004,  0.0760, -0.1144,  ...,  0.1671, -0.2681,  0.1570],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3018, -2.9531,  1.0342,  ...,  0.2056, -0.8320, -2.3887],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0010, -0.0301, -0.0003,  ..., -0.0018,  0.0041,  0.0143],
        [ 0.0098,  0.0245,  0.0075,  ...,  0.0013,  0.0003, -0.0067],
        [ 0.0046,  0.0123,  0.0340,  ...,  0.0095, -0.0067, -0.0085],
        ...,
        [-0.0074,  0.0155, -0.0012,  ...,  0.0103,  0.0099, -0.0095],
        [-0.0014, -0.0006,  0.0252,  ...,  0.0120,  0.0164,  0.0005],
        [-0.0027, -0.0268, -0.0139,  ...,  0.0023, -0.0188,  0.0210]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7305, -2.9492,  0.7793,  ..., -0.1460, -0.7485, -2.0371]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 15:13:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of palestine primarily speaks the language of arabic
The country of haiti primarily speaks the language of creole
The country of nicaragua primarily speaks the language of spanish
The country of mexico primarily speaks the language of spanish
The country of syria primarily speaks the language of arabic
The country of guatemala primarily speaks the language of spanish
The country of austria primarily speaks the language of german
The country of australia primarily speaks the language of
2024-07-28 15:13:24 root INFO     [order_1_approx] starting weight calculation for The country of mexico primarily speaks the language of spanish
The country of guatemala primarily speaks the language of spanish
The country of nicaragua primarily speaks the language of spanish
The country of haiti primarily speaks the language of creole
The country of palestine primarily speaks the language of arabic
The country of austria primarily speaks the language of german
The country of australia primarily speaks the language of english
The country of syria primarily speaks the language of
2024-07-28 15:13:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 15:16:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2703, -0.2167, -0.3025,  ...,  0.0476, -0.4863,  0.1616],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.2188, -4.5938,  0.3083,  ..., -2.1191,  1.1484, -2.1836],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.9831e-02, -2.9068e-02,  2.0676e-02,  ..., -5.3375e-02,
          3.4332e-04,  4.5654e-02],
        [ 2.3895e-02,  5.9509e-04,  1.5343e-02,  ..., -2.4445e-02,
          2.3766e-03,  2.5116e-02],
        [-3.3539e-02,  2.6306e-02,  2.5040e-02,  ..., -4.8676e-03,
         -1.0109e-03, -4.1901e-02],
        ...,
        [-1.8738e-02,  4.2908e-02, -1.3992e-02,  ...,  7.5928e-02,
          9.3002e-03, -4.0802e-02],
        [ 4.9591e-05, -9.4604e-03,  2.0645e-02,  ..., -4.9057e-03,
          1.4313e-02, -2.1210e-03],
        [-5.4026e-04, -1.8768e-02,  7.2250e-03,  ...,  9.0179e-03,
         -4.5815e-03,  1.7471e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.4629, -4.0391, -0.1636,  ..., -2.3750,  1.2354, -2.2969]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 15:16:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of mexico primarily speaks the language of spanish
The country of guatemala primarily speaks the language of spanish
The country of nicaragua primarily speaks the language of spanish
The country of haiti primarily speaks the language of creole
The country of palestine primarily speaks the language of arabic
The country of austria primarily speaks the language of german
The country of australia primarily speaks the language of english
The country of syria primarily speaks the language of
2024-07-28 15:16:12 root INFO     [order_1_approx] starting weight calculation for The country of australia primarily speaks the language of english
The country of mexico primarily speaks the language of spanish
The country of palestine primarily speaks the language of arabic
The country of nicaragua primarily speaks the language of spanish
The country of guatemala primarily speaks the language of spanish
The country of syria primarily speaks the language of arabic
The country of austria primarily speaks the language of german
The country of haiti primarily speaks the language of
2024-07-28 15:16:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 15:18:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.5879,  0.0868, -0.3716,  ..., -0.0461, -0.2122, -0.0610],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9907, -1.8359,  1.3535,  ..., -1.4668,  0.9531, -0.3760],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0049,  0.0043,  0.0181,  ..., -0.0235,  0.0187,  0.0190],
        [ 0.0188,  0.0248,  0.0066,  ..., -0.0021, -0.0043, -0.0143],
        [ 0.0035, -0.0273,  0.0248,  ..., -0.0188,  0.0063, -0.0172],
        ...,
        [-0.0302,  0.0054,  0.0070,  ...,  0.0090, -0.0200, -0.0207],
        [-0.0177,  0.0078, -0.0080,  ...,  0.0010,  0.0344,  0.0306],
        [ 0.0239,  0.0032,  0.0048,  ..., -0.0079,  0.0048,  0.0140]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4819, -1.4873,  1.3672,  ..., -1.6543,  1.1279, -0.3533]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 15:18:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of australia primarily speaks the language of english
The country of mexico primarily speaks the language of spanish
The country of palestine primarily speaks the language of arabic
The country of nicaragua primarily speaks the language of spanish
The country of guatemala primarily speaks the language of spanish
The country of syria primarily speaks the language of arabic
The country of austria primarily speaks the language of german
The country of haiti primarily speaks the language of
2024-07-28 15:18:57 root INFO     [order_1_approx] starting weight calculation for The country of palestine primarily speaks the language of arabic
The country of austria primarily speaks the language of german
The country of australia primarily speaks the language of english
The country of nicaragua primarily speaks the language of spanish
The country of haiti primarily speaks the language of creole
The country of syria primarily speaks the language of arabic
The country of guatemala primarily speaks the language of spanish
The country of mexico primarily speaks the language of
2024-07-28 15:18:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 15:21:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1168,  0.3459, -0.1450,  ...,  0.2042, -0.1831, -0.0736],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8862, -2.8418,  0.5884,  ...,  0.3621, -0.6523, -2.9883],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0230, -0.0017,  0.0105,  ..., -0.0189,  0.0157,  0.0072],
        [ 0.0119,  0.0198,  0.0021,  ..., -0.0066, -0.0169,  0.0150],
        [-0.0402,  0.0072,  0.0212,  ...,  0.0083,  0.0028, -0.0228],
        ...,
        [-0.0475,  0.0048, -0.0132,  ...,  0.0284, -0.0013, -0.0175],
        [ 0.0078, -0.0086,  0.0142,  ...,  0.0060,  0.0225,  0.0134],
        [ 0.0143,  0.0041,  0.0053,  ...,  0.0022, -0.0091,  0.0024]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1211, -2.7383,  0.3306,  ...,  0.2571, -0.7407, -2.7480]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 15:21:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of palestine primarily speaks the language of arabic
The country of austria primarily speaks the language of german
The country of australia primarily speaks the language of english
The country of nicaragua primarily speaks the language of spanish
The country of haiti primarily speaks the language of creole
The country of syria primarily speaks the language of arabic
The country of guatemala primarily speaks the language of spanish
The country of mexico primarily speaks the language of
2024-07-28 15:21:44 root INFO     [order_1_approx] starting weight calculation for The country of mexico primarily speaks the language of spanish
The country of nicaragua primarily speaks the language of spanish
The country of syria primarily speaks the language of arabic
The country of haiti primarily speaks the language of creole
The country of austria primarily speaks the language of german
The country of guatemala primarily speaks the language of spanish
The country of australia primarily speaks the language of english
The country of palestine primarily speaks the language of
2024-07-28 15:21:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 15:24:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0291, -0.2494, -0.3193,  ...,  0.1970, -0.3696,  0.0072],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4023, -4.5547,  0.3235,  ..., -2.6523,  0.6377, -1.0957],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0240, -0.0046,  0.0092,  ..., -0.0002,  0.0118,  0.0041],
        [ 0.0203,  0.0125,  0.0083,  ..., -0.0128,  0.0091,  0.0062],
        [-0.0250, -0.0068,  0.0106,  ..., -0.0098,  0.0027, -0.0148],
        ...,
        [-0.0139,  0.0091, -0.0114,  ...,  0.0116, -0.0051, -0.0190],
        [-0.0065, -0.0035,  0.0071,  ...,  0.0050,  0.0053, -0.0056],
        [-0.0038, -0.0036, -0.0042,  ..., -0.0003, -0.0037,  0.0071]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3845, -4.2305, -0.0312,  ..., -2.7734,  0.5752, -1.0068]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 15:24:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of mexico primarily speaks the language of spanish
The country of nicaragua primarily speaks the language of spanish
The country of syria primarily speaks the language of arabic
The country of haiti primarily speaks the language of creole
The country of austria primarily speaks the language of german
The country of guatemala primarily speaks the language of spanish
The country of australia primarily speaks the language of english
The country of palestine primarily speaks the language of
2024-07-28 15:24:28 root INFO     [order_1_approx] starting weight calculation for The country of nicaragua primarily speaks the language of spanish
The country of syria primarily speaks the language of arabic
The country of palestine primarily speaks the language of arabic
The country of australia primarily speaks the language of english
The country of austria primarily speaks the language of german
The country of haiti primarily speaks the language of creole
The country of mexico primarily speaks the language of spanish
The country of guatemala primarily speaks the language of
2024-07-28 15:24:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 15:27:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0161, -0.2974, -0.3618,  ..., -0.0016, -0.5884, -0.0117],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7339, -1.3955,  0.6411,  ..., -0.7593, -1.6084, -4.6328],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0275, -0.0055,  0.0041,  ..., -0.0126,  0.0190,  0.0050],
        [-0.0089,  0.0038,  0.0133,  ..., -0.0034, -0.0100,  0.0114],
        [-0.0269, -0.0028,  0.0154,  ..., -0.0185,  0.0066, -0.0112],
        ...,
        [-0.0193,  0.0119, -0.0152,  ...,  0.0168,  0.0007, -0.0240],
        [ 0.0109, -0.0004,  0.0025,  ...,  0.0004,  0.0202,  0.0047],
        [ 0.0130, -0.0056, -0.0048,  ..., -0.0003, -0.0105,  0.0106]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5786, -1.2266,  0.4907,  ..., -1.0029, -1.5645, -4.4492]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 15:27:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of nicaragua primarily speaks the language of spanish
The country of syria primarily speaks the language of arabic
The country of palestine primarily speaks the language of arabic
The country of australia primarily speaks the language of english
The country of austria primarily speaks the language of german
The country of haiti primarily speaks the language of creole
The country of mexico primarily speaks the language of spanish
The country of guatemala primarily speaks the language of
2024-07-28 15:27:15 root INFO     total operator prediction time: 1331.5800378322601 seconds
2024-07-28 15:27:15 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - shelter
2024-07-28 15:27:15 root INFO     building operator animal - shelter
2024-07-28 15:27:15 root INFO     [order_1_approx] starting weight calculation for The place horse lives in is called stable
The place hamster lives in is called nest
The place seal lives in is called den
The place whale lives in is called sea
The place snake lives in is called nest
The place dolphin lives in is called sea
The place hippopotamus lives in is called river
The place lion lives in is called
2024-07-28 15:27:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 15:29:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1017,  0.1771, -0.1724,  ...,  0.0701, -0.0917, -0.0739],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([  7.1016, -12.5703,   1.7686,  ...,  -1.9062,   0.7207,  -3.6641],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0277, -0.0141,  0.0145,  ...,  0.0038,  0.0018,  0.0108],
        [ 0.0095,  0.0068, -0.0192,  ..., -0.0061, -0.0216,  0.0013],
        [-0.0350,  0.0045,  0.0296,  ...,  0.0097, -0.0009, -0.0010],
        ...,
        [-0.0101, -0.0014, -0.0090,  ...,  0.0242,  0.0224,  0.0030],
        [-0.0086, -0.0116, -0.0035,  ...,  0.0408,  0.0306, -0.0048],
        [ 0.0126, -0.0194,  0.0003,  ..., -0.0451, -0.0257,  0.0399]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[  6.2500, -11.7578,   1.7354,  ...,  -1.6719,   0.8779,  -3.6055]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 15:29:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place horse lives in is called stable
The place hamster lives in is called nest
The place seal lives in is called den
The place whale lives in is called sea
The place snake lives in is called nest
The place dolphin lives in is called sea
The place hippopotamus lives in is called river
The place lion lives in is called
2024-07-28 15:29:58 root INFO     [order_1_approx] starting weight calculation for The place hippopotamus lives in is called river
The place whale lives in is called sea
The place snake lives in is called nest
The place hamster lives in is called nest
The place dolphin lives in is called sea
The place horse lives in is called stable
The place lion lives in is called den
The place seal lives in is called
2024-07-28 15:29:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 15:32:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2944, -0.0038, -0.3530,  ..., -0.2311, -0.0725, -0.0179],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0898, -9.7969, -2.0547,  ..., -1.8271, -0.9521,  0.4150],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0098,  0.0131,  0.0516,  ..., -0.0266,  0.0100,  0.0074],
        [-0.0218,  0.0289,  0.0102,  ..., -0.0033, -0.0158, -0.0214],
        [ 0.0392, -0.0169, -0.0170,  ..., -0.0003, -0.0116, -0.0282],
        ...,
        [-0.0136,  0.0040,  0.0324,  ...,  0.0567,  0.0371,  0.0107],
        [ 0.0334, -0.0141, -0.0638,  ...,  0.0303,  0.0060, -0.0411],
        [-0.0621, -0.0307,  0.0839,  ..., -0.0064,  0.0026,  0.0596]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9062, -9.9609, -1.9893,  ..., -1.6045, -1.0098, -0.4678]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 15:32:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place hippopotamus lives in is called river
The place whale lives in is called sea
The place snake lives in is called nest
The place hamster lives in is called nest
The place dolphin lives in is called sea
The place horse lives in is called stable
The place lion lives in is called den
The place seal lives in is called
2024-07-28 15:32:42 root INFO     [order_1_approx] starting weight calculation for The place lion lives in is called den
The place hippopotamus lives in is called river
The place snake lives in is called nest
The place seal lives in is called den
The place whale lives in is called sea
The place horse lives in is called stable
The place hamster lives in is called nest
The place dolphin lives in is called
2024-07-28 15:32:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 15:35:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2351, -0.0739, -0.2524,  ..., -0.3218, -0.1335,  0.0796],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9971, -8.9531, -0.1641,  ..., -2.0586,  0.7388,  0.2559],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0061, -0.0117,  0.0112,  ..., -0.0055, -0.0050,  0.0078],
        [ 0.0031, -0.0051, -0.0028,  ..., -0.0243, -0.0068,  0.0254],
        [-0.0061, -0.0007,  0.0098,  ...,  0.0062, -0.0057,  0.0002],
        ...,
        [-0.0111,  0.0074, -0.0054,  ...,  0.0035,  0.0063, -0.0010],
        [-0.0014, -0.0039,  0.0050,  ...,  0.0023, -0.0060,  0.0084],
        [-0.0056, -0.0151,  0.0037,  ..., -0.0084, -0.0012,  0.0103]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3154, -8.6797, -0.1443,  ..., -1.9951,  0.6016,  0.3616]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 15:35:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place lion lives in is called den
The place hippopotamus lives in is called river
The place snake lives in is called nest
The place seal lives in is called den
The place whale lives in is called sea
The place horse lives in is called stable
The place hamster lives in is called nest
The place dolphin lives in is called
2024-07-28 15:35:26 root INFO     [order_1_approx] starting weight calculation for The place lion lives in is called den
The place dolphin lives in is called sea
The place hippopotamus lives in is called river
The place whale lives in is called sea
The place horse lives in is called stable
The place seal lives in is called den
The place hamster lives in is called nest
The place snake lives in is called
2024-07-28 15:35:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 15:38:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0687,  0.1781, -0.1053,  ..., -0.1710, -0.0421, -0.0143],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0039, -7.5938,  2.3516,  ..., -0.4189,  0.1826, -0.9556],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0568, -0.0163,  0.0110,  ...,  0.0285, -0.0025, -0.0060],
        [-0.0155,  0.0089,  0.0144,  ..., -0.0357,  0.0068,  0.0061],
        [-0.0042,  0.0094,  0.0745,  ..., -0.0250, -0.0010,  0.0285],
        ...,
        [-0.0178,  0.0221,  0.0069,  ...,  0.0197,  0.0179,  0.0030],
        [ 0.0092, -0.0037, -0.0181,  ...,  0.0205,  0.0315,  0.0073],
        [-0.0229,  0.0064,  0.0044,  ..., -0.0272, -0.0097,  0.0532]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4668, -7.3438,  1.8037,  ..., -0.6304, -0.0876, -0.9941]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 15:38:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place lion lives in is called den
The place dolphin lives in is called sea
The place hippopotamus lives in is called river
The place whale lives in is called sea
The place horse lives in is called stable
The place seal lives in is called den
The place hamster lives in is called nest
The place snake lives in is called
2024-07-28 15:38:09 root INFO     [order_1_approx] starting weight calculation for The place dolphin lives in is called sea
The place snake lives in is called nest
The place horse lives in is called stable
The place whale lives in is called sea
The place lion lives in is called den
The place seal lives in is called den
The place hamster lives in is called nest
The place hippopotamus lives in is called
2024-07-28 15:38:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 15:40:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0632, -0.1758,  0.0432,  ..., -0.1355, -0.0964, -0.0061],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1758, -6.7656,  0.1313,  ..., -3.1836,  0.8496, -0.3193],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0110, -0.0117,  0.0082,  ..., -0.0014,  0.0152,  0.0151],
        [ 0.0074, -0.0069,  0.0109,  ..., -0.0159, -0.0291,  0.0326],
        [-0.0196,  0.0113, -0.0036,  ...,  0.0024,  0.0037, -0.0160],
        ...,
        [ 0.0007, -0.0014, -0.0013,  ...,  0.0001,  0.0087, -0.0007],
        [-0.0086,  0.0092,  0.0024,  ...,  0.0133,  0.0033, -0.0145],
        [-0.0038, -0.0295,  0.0059,  ..., -0.0074, -0.0207,  0.0365]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.4492, -6.3477, -0.0508,  ..., -3.1621,  0.5273, -0.0581]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 15:40:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place dolphin lives in is called sea
The place snake lives in is called nest
The place horse lives in is called stable
The place whale lives in is called sea
The place lion lives in is called den
The place seal lives in is called den
The place hamster lives in is called nest
The place hippopotamus lives in is called
2024-07-28 15:40:53 root INFO     [order_1_approx] starting weight calculation for The place hamster lives in is called nest
The place snake lives in is called nest
The place horse lives in is called stable
The place seal lives in is called den
The place dolphin lives in is called sea
The place lion lives in is called den
The place hippopotamus lives in is called river
The place whale lives in is called
2024-07-28 15:40:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 15:43:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1628, -0.0320, -0.1257,  ..., -0.2615, -0.1384, -0.1561],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4004, -8.2109,  0.6670,  ..., -2.0371,  0.2031, -1.2891],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0089, -0.0056,  0.0035,  ...,  0.0028, -0.0087, -0.0193],
        [-0.0015,  0.0135, -0.0118,  ...,  0.0187,  0.0071, -0.0075],
        [-0.0053,  0.0013,  0.0191,  ..., -0.0175,  0.0013, -0.0121],
        ...,
        [ 0.0047,  0.0159, -0.0091,  ...,  0.0403, -0.0009,  0.0049],
        [ 0.0065,  0.0179, -0.0023,  ...,  0.0022, -0.0124, -0.0069],
        [-0.0105, -0.0270, -0.0006,  ..., -0.0071,  0.0087,  0.0278]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4189, -7.8320,  0.6729,  ..., -2.0020, -0.0476, -1.4043]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 15:43:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place hamster lives in is called nest
The place snake lives in is called nest
The place horse lives in is called stable
The place seal lives in is called den
The place dolphin lives in is called sea
The place lion lives in is called den
The place hippopotamus lives in is called river
The place whale lives in is called
2024-07-28 15:43:37 root INFO     [order_1_approx] starting weight calculation for The place snake lives in is called nest
The place hippopotamus lives in is called river
The place horse lives in is called stable
The place lion lives in is called den
The place dolphin lives in is called sea
The place whale lives in is called sea
The place seal lives in is called den
The place hamster lives in is called
2024-07-28 15:43:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 15:46:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1753, -0.2983,  0.1987,  ..., -0.0547, -0.1722,  0.1084],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2217, -5.3906,  1.7070,  ..., -0.0747, -2.4336,  2.4551],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0676, -0.0271, -0.0213,  ...,  0.0453, -0.0894,  0.0002],
        [-0.0143,  0.0645,  0.0086,  ...,  0.0019,  0.0031, -0.0258],
        [-0.0036,  0.0091,  0.0046,  ...,  0.0049, -0.0248, -0.0066],
        ...,
        [-0.0158, -0.0011, -0.0085,  ...,  0.0473,  0.0190, -0.0037],
        [ 0.0177,  0.0444,  0.0141,  ...,  0.0397,  0.0367, -0.0060],
        [-0.0027,  0.0024, -0.0026,  ..., -0.0035,  0.0177,  0.0702]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6035, -5.0430,  2.0566,  ...,  0.1218, -2.5840,  2.0859]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 15:46:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place snake lives in is called nest
The place hippopotamus lives in is called river
The place horse lives in is called stable
The place lion lives in is called den
The place dolphin lives in is called sea
The place whale lives in is called sea
The place seal lives in is called den
The place hamster lives in is called
2024-07-28 15:46:17 root INFO     [order_1_approx] starting weight calculation for The place seal lives in is called den
The place snake lives in is called nest
The place hamster lives in is called nest
The place whale lives in is called sea
The place lion lives in is called den
The place dolphin lives in is called sea
The place hippopotamus lives in is called river
The place horse lives in is called
2024-07-28 15:46:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 15:48:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0852, -0.0396, -0.0157,  ..., -0.0746,  0.1130,  0.1401],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6738, -8.2578,  3.2422,  ...,  0.2559, -0.0615, -1.8047],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0262, -0.0182, -0.0003,  ...,  0.0073, -0.0263,  0.0176],
        [-0.0099,  0.0273,  0.0013,  ..., -0.0020,  0.0009,  0.0146],
        [ 0.0017,  0.0150,  0.0411,  ..., -0.0265,  0.0052, -0.0120],
        ...,
        [-0.0168,  0.0276,  0.0224,  ...,  0.0128,  0.0175,  0.0051],
        [ 0.0190, -0.0003, -0.0078,  ..., -0.0069,  0.0560,  0.0113],
        [ 0.0012,  0.0041,  0.0148,  ..., -0.0139, -0.0014,  0.0109]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9443, -7.8203,  2.2988,  ..., -0.3740, -0.6182, -1.7109]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 15:48:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place seal lives in is called den
The place snake lives in is called nest
The place hamster lives in is called nest
The place whale lives in is called sea
The place lion lives in is called den
The place dolphin lives in is called sea
The place hippopotamus lives in is called river
The place horse lives in is called
2024-07-28 15:48:56 root INFO     total operator prediction time: 1301.0783534049988 seconds
2024-07-28 15:48:56 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on male - female
2024-07-28 15:48:56 root INFO     building operator male - female
2024-07-28 15:48:56 root INFO     [order_1_approx] starting weight calculation for A female stallion is known as a mare
A female webmaster is known as a webmistress
A female headmaster is known as a headmistress
A female gentleman is known as a lady
A female murderer is known as a murderess
A female boar is known as a sow
A female brother is known as a sister
A female emperor is known as a
2024-07-28 15:48:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 15:51:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.4180,  0.0586,  0.0413,  ..., -0.1842, -0.2532,  0.2695],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0137, -3.4219,  1.1191,  ..., -1.7334, -3.5039, -0.9683],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.7109e-02, -4.4250e-02,  2.4521e-02,  ..., -2.8885e-02,
         -8.3771e-03,  3.1433e-02],
        [-2.9861e-02,  6.2683e-02, -3.0327e-03,  ...,  4.1473e-02,
          1.1391e-02, -6.0120e-03],
        [-9.6130e-03, -6.6338e-03,  2.9053e-02,  ...,  1.0139e-02,
         -8.7738e-05, -3.7766e-04],
        ...,
        [-3.4729e-02,  3.2654e-02, -2.4353e-02,  ...,  5.1727e-02,
          1.1803e-02,  4.0894e-03],
        [ 2.2614e-02, -5.2002e-02, -7.0000e-03,  ..., -2.7679e-02,
          1.1566e-02, -1.0025e-02],
        [ 2.9694e-02, -1.8341e-02,  7.3471e-03,  ..., -2.4002e-02,
          1.6968e-02,  2.4738e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8311, -3.1016,  0.9902,  ..., -1.6045, -3.6484, -1.0615]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 15:51:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female stallion is known as a mare
A female webmaster is known as a webmistress
A female headmaster is known as a headmistress
A female gentleman is known as a lady
A female murderer is known as a murderess
A female boar is known as a sow
A female brother is known as a sister
A female emperor is known as a
2024-07-28 15:51:37 root INFO     [order_1_approx] starting weight calculation for A female emperor is known as a empress
A female gentleman is known as a lady
A female webmaster is known as a webmistress
A female headmaster is known as a headmistress
A female boar is known as a sow
A female stallion is known as a mare
A female brother is known as a sister
A female murderer is known as a
2024-07-28 15:51:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 15:54:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3696, -0.0754, -0.1519,  ..., -0.0560, -0.1671, -0.2336],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4238, -3.3398, -0.9917,  ..., -0.8232, -2.8867, -0.0056],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0268, -0.0201,  0.0090,  ...,  0.0101,  0.0084,  0.0222],
        [-0.0068,  0.0344, -0.0187,  ...,  0.0099,  0.0095, -0.0105],
        [ 0.0148, -0.0095,  0.0111,  ...,  0.0011, -0.0051,  0.0051],
        ...,
        [-0.0118,  0.0083, -0.0141,  ...,  0.0042,  0.0099,  0.0026],
        [-0.0031,  0.0008, -0.0070,  ...,  0.0072, -0.0044, -0.0199],
        [-0.0015,  0.0115, -0.0112,  ..., -0.0032,  0.0119,  0.0148]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5234, -3.4531, -0.9160,  ..., -0.8330, -2.9746,  0.2367]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 15:54:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female emperor is known as a empress
A female gentleman is known as a lady
A female webmaster is known as a webmistress
A female headmaster is known as a headmistress
A female boar is known as a sow
A female stallion is known as a mare
A female brother is known as a sister
A female murderer is known as a
2024-07-28 15:54:21 root INFO     [order_1_approx] starting weight calculation for A female murderer is known as a murderess
A female stallion is known as a mare
A female gentleman is known as a lady
A female boar is known as a sow
A female emperor is known as a empress
A female brother is known as a sister
A female webmaster is known as a webmistress
A female headmaster is known as a
2024-07-28 15:54:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 15:57:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2200,  0.2393, -0.1182,  ..., -0.0645, -0.3596,  0.0909],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.9727, -3.8184, -1.0869,  ...,  0.2466, -5.0273, -0.9077],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0357, -0.0176,  0.0346,  ...,  0.0411,  0.0068, -0.0083],
        [-0.0068,  0.0126, -0.0020,  ..., -0.0381, -0.0118,  0.0227],
        [ 0.0085,  0.0010,  0.0264,  ..., -0.0330, -0.0331,  0.0003],
        ...,
        [ 0.0020,  0.0173,  0.0259,  ...,  0.0029,  0.0111, -0.0055],
        [ 0.0171, -0.0252,  0.0410,  ..., -0.0264, -0.0043, -0.0152],
        [ 0.0017, -0.0031, -0.0050,  ..., -0.0085,  0.0155,  0.0028]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.0625, -3.8164, -1.0049,  ...,  0.3394, -5.0352, -0.5303]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 15:57:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female murderer is known as a murderess
A female stallion is known as a mare
A female gentleman is known as a lady
A female boar is known as a sow
A female emperor is known as a empress
A female brother is known as a sister
A female webmaster is known as a webmistress
A female headmaster is known as a
2024-07-28 15:57:05 root INFO     [order_1_approx] starting weight calculation for A female murderer is known as a murderess
A female webmaster is known as a webmistress
A female emperor is known as a empress
A female gentleman is known as a lady
A female brother is known as a sister
A female boar is known as a sow
A female headmaster is known as a headmistress
A female stallion is known as a
2024-07-28 15:57:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 15:59:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3176, -0.0688, -0.0378,  ..., -0.0078, -0.1580,  0.2927],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1055, -4.4023, -2.6211,  ..., -0.3621, -1.9932,  2.6133],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0353,  0.0069, -0.0094,  ...,  0.0429, -0.0052,  0.0048],
        [-0.0158,  0.0555,  0.0026,  ...,  0.0118,  0.0465, -0.0218],
        [ 0.0092,  0.0312,  0.0784,  ...,  0.0161, -0.0358, -0.0281],
        ...,
        [-0.0266, -0.0122, -0.0391,  ...,  0.0230, -0.0047, -0.0017],
        [-0.0239,  0.0051,  0.0217,  ..., -0.0351, -0.0199,  0.0122],
        [ 0.0466, -0.0265,  0.0034,  ...,  0.0186, -0.0186,  0.0295]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9980, -4.3398, -2.7305,  ..., -0.4316, -2.1113,  3.0215]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 15:59:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female murderer is known as a murderess
A female webmaster is known as a webmistress
A female emperor is known as a empress
A female gentleman is known as a lady
A female brother is known as a sister
A female boar is known as a sow
A female headmaster is known as a headmistress
A female stallion is known as a
2024-07-28 15:59:50 root INFO     [order_1_approx] starting weight calculation for A female gentleman is known as a lady
A female murderer is known as a murderess
A female webmaster is known as a webmistress
A female stallion is known as a mare
A female emperor is known as a empress
A female boar is known as a sow
A female headmaster is known as a headmistress
A female brother is known as a
2024-07-28 15:59:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 16:02:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2891,  0.1373,  0.0670,  ..., -0.1083, -0.1815,  0.0174],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.5664, -2.3340, -2.7188,  ...,  0.3079, -1.5742, -0.1311],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0241,  0.0031,  0.0202,  ...,  0.0264, -0.0361,  0.0325],
        [ 0.0178,  0.0170,  0.0274,  ...,  0.0423,  0.0548, -0.0022],
        [ 0.0311, -0.0596,  0.0405,  ..., -0.0331,  0.0211, -0.0051],
        ...,
        [-0.0363,  0.0456, -0.0136,  ...,  0.0778,  0.0223, -0.0100],
        [-0.0513,  0.0311,  0.0310,  ...,  0.0224, -0.0528, -0.0086],
        [ 0.0629, -0.0528, -0.0059,  ...,  0.0045,  0.0753, -0.0058]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3633, -2.2930, -2.8828,  ..., -0.3274, -3.3516,  0.7744]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 16:02:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female gentleman is known as a lady
A female murderer is known as a murderess
A female webmaster is known as a webmistress
A female stallion is known as a mare
A female emperor is known as a empress
A female boar is known as a sow
A female headmaster is known as a headmistress
A female brother is known as a
2024-07-28 16:02:35 root INFO     [order_1_approx] starting weight calculation for A female brother is known as a sister
A female headmaster is known as a headmistress
A female boar is known as a sow
A female emperor is known as a empress
A female murderer is known as a murderess
A female webmaster is known as a webmistress
A female stallion is known as a mare
A female gentleman is known as a
2024-07-28 16:02:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 16:05:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3916,  0.1516, -0.2227,  ..., -0.1465, -0.1230,  0.0771],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0859,  0.5386, -3.5664,  ...,  0.5811, -4.5352, -0.9688],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0149,  0.0047,  0.0232,  ..., -0.0469, -0.0087,  0.0327],
        [-0.0047,  0.0759, -0.0107,  ...,  0.1305,  0.0067,  0.0239],
        [ 0.0284, -0.0627,  0.0270,  ..., -0.0422,  0.0444, -0.0586],
        ...,
        [-0.0161,  0.0488,  0.0251,  ...,  0.0471, -0.0070,  0.0192],
        [ 0.0127, -0.0006,  0.0172,  ..., -0.0174, -0.0016, -0.0243],
        [ 0.0323,  0.0370, -0.0025,  ...,  0.0226,  0.0010, -0.0018]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3418, -0.9536, -2.7227,  ..., -1.0850, -5.1680, -0.7500]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 16:05:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female brother is known as a sister
A female headmaster is known as a headmistress
A female boar is known as a sow
A female emperor is known as a empress
A female murderer is known as a murderess
A female webmaster is known as a webmistress
A female stallion is known as a mare
A female gentleman is known as a
2024-07-28 16:05:20 root INFO     [order_1_approx] starting weight calculation for A female emperor is known as a empress
A female stallion is known as a mare
A female brother is known as a sister
A female boar is known as a sow
A female headmaster is known as a headmistress
A female gentleman is known as a lady
A female murderer is known as a murderess
A female webmaster is known as a
2024-07-28 16:05:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 16:08:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2708, -0.0390, -0.1442,  ..., -0.0269, -0.2441,  0.1217],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.4414, -4.6172, -0.4182,  ..., -0.1479, -1.2793,  0.5723],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0334, -0.0153, -0.0190,  ...,  0.0071, -0.0069,  0.0172],
        [-0.0331,  0.0269, -0.0054,  ..., -0.0172, -0.0068,  0.0008],
        [-0.0170, -0.0217,  0.0535,  ..., -0.0454,  0.0134,  0.0074],
        ...,
        [ 0.0264,  0.0168,  0.0158,  ...,  0.0153, -0.0118, -0.0142],
        [ 0.0002,  0.0155, -0.0109,  ..., -0.0299,  0.0097, -0.0306],
        [-0.0053, -0.0262, -0.0009,  ...,  0.0148,  0.0112,  0.0263]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.3555, -4.9922,  0.0173,  ..., -0.4927, -1.5596,  0.6826]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 16:08:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female emperor is known as a empress
A female stallion is known as a mare
A female brother is known as a sister
A female boar is known as a sow
A female headmaster is known as a headmistress
A female gentleman is known as a lady
A female murderer is known as a murderess
A female webmaster is known as a
2024-07-28 16:08:03 root INFO     [order_1_approx] starting weight calculation for A female headmaster is known as a headmistress
A female gentleman is known as a lady
A female murderer is known as a murderess
A female emperor is known as a empress
A female brother is known as a sister
A female webmaster is known as a webmistress
A female stallion is known as a mare
A female boar is known as a
2024-07-28 16:08:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 16:10:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.3213, -0.0092,  0.0728,  ...,  0.1007, -0.1377,  0.1058],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0312, -3.8477, -1.1406,  ..., -1.5469, -1.4756,  0.8369],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0088, -0.0113,  0.0044,  ...,  0.0563,  0.0168,  0.0051],
        [-0.0253,  0.0676, -0.0025,  ..., -0.0175,  0.0316, -0.0533],
        [ 0.0346,  0.0016,  0.0354,  ...,  0.0141, -0.0081, -0.0155],
        ...,
        [-0.0157, -0.0098, -0.0409,  ...,  0.0507,  0.0177,  0.0110],
        [ 0.0043,  0.0427,  0.0154,  ...,  0.0053,  0.0252,  0.0091],
        [ 0.0899,  0.0008, -0.0164,  ...,  0.0004, -0.0060,  0.0161]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9355, -4.1172, -1.3447,  ..., -1.3955, -1.2344,  0.9521]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 16:10:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female headmaster is known as a headmistress
A female gentleman is known as a lady
A female murderer is known as a murderess
A female emperor is known as a empress
A female brother is known as a sister
A female webmaster is known as a webmistress
A female stallion is known as a mare
A female boar is known as a
2024-07-28 16:10:47 root INFO     total operator prediction time: 1311.3849885463715 seconds
2024-07-28 16:10:47 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on name - occupation
2024-07-28 16:10:47 root INFO     building operator name - occupation
2024-07-28 16:10:48 root INFO     [order_1_approx] starting weight calculation for rembrandt was known for their work as a  painter
depp was known for their work as a  actor
hawking was known for their work as a  physicist
plato was known for their work as a  philosopher
dickens was known for their work as a  novelist
lincoln was known for their work as a  president
marx was known for their work as a  philosopher
edison was known for their work as a 
2024-07-28 16:10:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 16:13:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1951,  0.5757, -0.3206,  ..., -0.1948, -0.0011,  0.0133],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7227, -3.8555,  1.1982,  ..., -2.1055,  0.4336, -1.6816],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0182, -0.0030, -0.0089,  ...,  0.0175,  0.0014,  0.0113],
        [ 0.0033,  0.0370, -0.0203,  ...,  0.0016,  0.0094,  0.0027],
        [-0.0240, -0.0118,  0.0252,  ...,  0.0170, -0.0051,  0.0086],
        ...,
        [-0.0142,  0.0218, -0.0309,  ...,  0.0595, -0.0040,  0.0073],
        [ 0.0254,  0.0036,  0.0031,  ...,  0.0347,  0.0350,  0.0164],
        [-0.0118,  0.0109, -0.0111,  ..., -0.0079, -0.0030,  0.0391]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0195, -3.8418,  1.6172,  ..., -1.5938,  0.1816, -1.1719]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 16:13:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for rembrandt was known for their work as a  painter
depp was known for their work as a  actor
hawking was known for their work as a  physicist
plato was known for their work as a  philosopher
dickens was known for their work as a  novelist
lincoln was known for their work as a  president
marx was known for their work as a  philosopher
edison was known for their work as a 
2024-07-28 16:13:29 root INFO     [order_1_approx] starting weight calculation for edison was known for their work as a  inventor
plato was known for their work as a  philosopher
rembrandt was known for their work as a  painter
dickens was known for their work as a  novelist
marx was known for their work as a  philosopher
lincoln was known for their work as a  president
hawking was known for their work as a  physicist
depp was known for their work as a 
2024-07-28 16:13:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 16:16:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1117,  0.1545,  0.0591,  ...,  0.2472, -0.3950,  0.0229],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1289, -2.8477,  1.4941,  ..., -3.5352,  0.9453, -0.0068],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0562,  0.0184,  0.0362,  ..., -0.0075,  0.0227, -0.0073],
        [ 0.0249,  0.0347, -0.0047,  ...,  0.0112, -0.0066,  0.0243],
        [ 0.0268, -0.0132,  0.0767,  ..., -0.0017, -0.0062, -0.0012],
        ...,
        [ 0.0277,  0.0366,  0.0171,  ...,  0.0792, -0.0468,  0.0264],
        [ 0.0018,  0.0158,  0.0180,  ..., -0.0130,  0.0134,  0.0036],
        [-0.0201, -0.0169, -0.0200,  ..., -0.0287, -0.0063,  0.0225]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7891, -2.7695,  1.5146,  ..., -3.1719,  0.7988,  0.3120]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 16:16:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for edison was known for their work as a  inventor
plato was known for their work as a  philosopher
rembrandt was known for their work as a  painter
dickens was known for their work as a  novelist
marx was known for their work as a  philosopher
lincoln was known for their work as a  president
hawking was known for their work as a  physicist
depp was known for their work as a 
2024-07-28 16:16:14 root INFO     [order_1_approx] starting weight calculation for rembrandt was known for their work as a  painter
edison was known for their work as a  inventor
depp was known for their work as a  actor
dickens was known for their work as a  novelist
plato was known for their work as a  philosopher
marx was known for their work as a  philosopher
lincoln was known for their work as a  president
hawking was known for their work as a 
2024-07-28 16:16:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 16:18:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1192, -0.0479, -0.3706,  ...,  0.0361,  0.0061,  0.3792],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8516, -3.5938,  3.4688,  ..., -6.2148, -0.5742, -0.6211],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0536, -0.0224,  0.0205,  ..., -0.0006, -0.0094,  0.0163],
        [ 0.0218,  0.0404, -0.0020,  ..., -0.0183, -0.0063,  0.0036],
        [ 0.0017, -0.0096,  0.0513,  ..., -0.0198, -0.0009,  0.0074],
        ...,
        [ 0.0259, -0.0102,  0.0078,  ...,  0.0487, -0.0137,  0.0075],
        [ 0.0237, -0.0080, -0.0054,  ...,  0.0256,  0.0167, -0.0036],
        [-0.0127,  0.0167,  0.0042,  ..., -0.0141, -0.0103,  0.0308]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1543, -3.7227,  3.5391,  ..., -6.0117, -0.4966, -0.6274]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 16:18:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for rembrandt was known for their work as a  painter
edison was known for their work as a  inventor
depp was known for their work as a  actor
dickens was known for their work as a  novelist
plato was known for their work as a  philosopher
marx was known for their work as a  philosopher
lincoln was known for their work as a  president
hawking was known for their work as a 
2024-07-28 16:18:58 root INFO     [order_1_approx] starting weight calculation for marx was known for their work as a  philosopher
depp was known for their work as a  actor
hawking was known for their work as a  physicist
rembrandt was known for their work as a  painter
lincoln was known for their work as a  president
edison was known for their work as a  inventor
dickens was known for their work as a  novelist
plato was known for their work as a 
2024-07-28 16:18:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 16:21:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1008, -0.1098, -0.7466,  ..., -0.0317,  0.1436,  0.1437],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1846, -5.6562,  1.8125,  ..., -7.0586, -0.2881, -0.8618],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0901, -0.0550,  0.0323,  ..., -0.0073, -0.0024,  0.0154],
        [ 0.0167,  0.0070,  0.0108,  ..., -0.0010, -0.0271, -0.0011],
        [ 0.0050, -0.0137,  0.0444,  ..., -0.0072,  0.0313,  0.0256],
        ...,
        [ 0.0422, -0.0053,  0.0171,  ...,  0.0395,  0.0271, -0.0107],
        [-0.0400,  0.0631, -0.0133,  ...,  0.0352,  0.0006, -0.0250],
        [ 0.0237,  0.0168, -0.0044,  ..., -0.0134, -0.0196,  0.0267]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7876, -5.5156,  1.8115,  ..., -7.2227,  0.1052, -0.4270]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 16:21:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for marx was known for their work as a  philosopher
depp was known for their work as a  actor
hawking was known for their work as a  physicist
rembrandt was known for their work as a  painter
lincoln was known for their work as a  president
edison was known for their work as a  inventor
dickens was known for their work as a  novelist
plato was known for their work as a 
2024-07-28 16:21:43 root INFO     [order_1_approx] starting weight calculation for lincoln was known for their work as a  president
depp was known for their work as a  actor
hawking was known for their work as a  physicist
dickens was known for their work as a  novelist
plato was known for their work as a  philosopher
edison was known for their work as a  inventor
marx was known for their work as a  philosopher
rembrandt was known for their work as a 
2024-07-28 16:21:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 16:24:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2477,  0.0931, -0.4966,  ..., -0.4087,  0.0634, -0.2175],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1816, -6.1367,  1.0361,  ..., -7.7148, -1.8174, -2.9141],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0189, -0.0085,  0.0157,  ...,  0.0072, -0.0089,  0.0084],
        [ 0.0205,  0.0038,  0.0154,  ..., -0.0023, -0.0133,  0.0119],
        [ 0.0115, -0.0040,  0.0231,  ..., -0.0037, -0.0085,  0.0108],
        ...,
        [ 0.0242, -0.0115,  0.0051,  ...,  0.0205, -0.0062,  0.0015],
        [ 0.0136, -0.0123,  0.0097,  ...,  0.0069,  0.0037,  0.0058],
        [ 0.0088, -0.0005, -0.0075,  ..., -0.0080, -0.0096,  0.0204]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2598, -5.8008,  1.4375,  ..., -7.2969, -1.8965, -2.5938]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 16:24:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for lincoln was known for their work as a  president
depp was known for their work as a  actor
hawking was known for their work as a  physicist
dickens was known for their work as a  novelist
plato was known for their work as a  philosopher
edison was known for their work as a  inventor
marx was known for their work as a  philosopher
rembrandt was known for their work as a 
2024-07-28 16:24:27 root INFO     [order_1_approx] starting weight calculation for rembrandt was known for their work as a  painter
hawking was known for their work as a  physicist
depp was known for their work as a  actor
edison was known for their work as a  inventor
dickens was known for their work as a  novelist
plato was known for their work as a  philosopher
marx was known for their work as a  philosopher
lincoln was known for their work as a 
2024-07-28 16:24:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 16:27:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0069,  0.0800, -0.3997,  ..., -0.1372,  0.0208, -0.0118],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1680, -3.7930,  2.6758,  ..., -3.1641,  1.0332, -1.6592],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0278,  0.0041,  0.0293,  ...,  0.0056, -0.0198,  0.0168],
        [ 0.0148,  0.0326, -0.0097,  ..., -0.0153,  0.0117,  0.0100],
        [ 0.0246, -0.0069,  0.0457,  ..., -0.0098, -0.0076, -0.0077],
        ...,
        [ 0.0193,  0.0177,  0.0052,  ...,  0.0570,  0.0043, -0.0090],
        [-0.0065,  0.0072, -0.0158,  ...,  0.0030, -0.0022, -0.0004],
        [-0.0056, -0.0015, -0.0062,  ..., -0.0026,  0.0040,  0.0370]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0605, -3.6953,  2.5156,  ..., -3.2773,  1.2422, -0.9399]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 16:27:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for rembrandt was known for their work as a  painter
hawking was known for their work as a  physicist
depp was known for their work as a  actor
edison was known for their work as a  inventor
dickens was known for their work as a  novelist
plato was known for their work as a  philosopher
marx was known for their work as a  philosopher
lincoln was known for their work as a 
2024-07-28 16:27:12 root INFO     [order_1_approx] starting weight calculation for lincoln was known for their work as a  president
plato was known for their work as a  philosopher
hawking was known for their work as a  physicist
depp was known for their work as a  actor
edison was known for their work as a  inventor
marx was known for their work as a  philosopher
rembrandt was known for their work as a  painter
dickens was known for their work as a 
2024-07-28 16:27:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 16:29:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0461,  0.4871, -0.2520,  ...,  0.0923,  0.0198,  0.0151],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8633, -5.3047,  4.1641,  ..., -4.9141,  0.1605, -1.4189],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0492,  0.0028,  0.0019,  ...,  0.0094,  0.0030, -0.0070],
        [ 0.0331,  0.0212, -0.0115,  ..., -0.0034, -0.0217, -0.0061],
        [-0.0191, -0.0089,  0.0507,  ...,  0.0245,  0.0435,  0.0180],
        ...,
        [ 0.0496,  0.0112,  0.0103,  ...,  0.0305, -0.0002, -0.0323],
        [ 0.0113, -0.0061,  0.0168,  ...,  0.0052,  0.0238,  0.0052],
        [-0.0110,  0.0092, -0.0126,  ...,  0.0195, -0.0002,  0.0321]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9023, -5.0898,  3.3555,  ..., -4.9336,  0.2593, -1.7451]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 16:29:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for lincoln was known for their work as a  president
plato was known for their work as a  philosopher
hawking was known for their work as a  physicist
depp was known for their work as a  actor
edison was known for their work as a  inventor
marx was known for their work as a  philosopher
rembrandt was known for their work as a  painter
dickens was known for their work as a 
2024-07-28 16:29:57 root INFO     [order_1_approx] starting weight calculation for hawking was known for their work as a  physicist
dickens was known for their work as a  novelist
plato was known for their work as a  philosopher
edison was known for their work as a  inventor
depp was known for their work as a  actor
rembrandt was known for their work as a  painter
lincoln was known for their work as a  president
marx was known for their work as a 
2024-07-28 16:29:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 16:32:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([0.0228, 0.1127, 0.0525,  ..., 0.2001, 0.1957, 0.2988], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5215, -7.8672,  3.7578,  ..., -6.0117,  1.2461, -3.6172],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0638, -0.0193, -0.0092,  ..., -0.0078, -0.0251, -0.0019],
        [ 0.0384,  0.0191,  0.0359,  ..., -0.0313, -0.0269, -0.0011],
        [ 0.0085, -0.0142,  0.0190,  ...,  0.0137,  0.0107, -0.0171],
        ...,
        [ 0.0206,  0.0029,  0.0351,  ...,  0.0490,  0.0073,  0.0204],
        [ 0.0116,  0.0114,  0.0084,  ...,  0.0186, -0.0101,  0.0011],
        [-0.0194,  0.0194,  0.0244,  ..., -0.0047,  0.0181,  0.0267]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5029, -7.8125,  3.6992,  ..., -6.0117,  0.9727, -3.4199]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 16:32:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for hawking was known for their work as a  physicist
dickens was known for their work as a  novelist
plato was known for their work as a  philosopher
edison was known for their work as a  inventor
depp was known for their work as a  actor
rembrandt was known for their work as a  painter
lincoln was known for their work as a  president
marx was known for their work as a 
2024-07-28 16:32:43 root INFO     total operator prediction time: 1315.8594136238098 seconds
2024-07-28 16:32:43 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on country - capital
2024-07-28 16:32:43 root INFO     building operator country - capital
2024-07-28 16:32:44 root INFO     [order_1_approx] starting weight calculation for The country with dhaka as its capital is known as bangladesh
The country with warsaw as its capital is known as poland
The country with jakarta as its capital is known as indonesia
The country with abuja as its capital is known as nigeria
The country with sofia as its capital is known as bulgaria
The country with ottawa as its capital is known as canada
The country with hanoi as its capital is known as vietnam
The country with london as its capital is known as
2024-07-28 16:32:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 16:35:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0065, -0.1049, -0.1914,  ...,  0.1070,  0.2595, -0.0085],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6816, -6.1172, -1.5078,  ..., -3.6914,  0.8208, -5.7812],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0251, -0.0250, -0.0048,  ...,  0.0226,  0.0102,  0.0092],
        [-0.0095,  0.0258, -0.0088,  ..., -0.0070, -0.0041, -0.0256],
        [ 0.0019, -0.0103,  0.0414,  ..., -0.0020,  0.0418,  0.0111],
        ...,
        [-0.0287,  0.0150, -0.0057,  ...,  0.0184, -0.0033, -0.0306],
        [ 0.0098,  0.0023,  0.0185,  ..., -0.0134,  0.0016,  0.0042],
        [-0.0059, -0.0136,  0.0001,  ..., -0.0047, -0.0151, -0.0034]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5508, -5.7422, -1.6777,  ..., -3.5312,  0.7271, -5.4570]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 16:35:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with dhaka as its capital is known as bangladesh
The country with warsaw as its capital is known as poland
The country with jakarta as its capital is known as indonesia
The country with abuja as its capital is known as nigeria
The country with sofia as its capital is known as bulgaria
The country with ottawa as its capital is known as canada
The country with hanoi as its capital is known as vietnam
The country with london as its capital is known as
2024-07-28 16:35:27 root INFO     [order_1_approx] starting weight calculation for The country with warsaw as its capital is known as poland
The country with london as its capital is known as england
The country with ottawa as its capital is known as canada
The country with hanoi as its capital is known as vietnam
The country with sofia as its capital is known as bulgaria
The country with jakarta as its capital is known as indonesia
The country with abuja as its capital is known as nigeria
The country with dhaka as its capital is known as
2024-07-28 16:35:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 16:38:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.3098, -0.1608, -0.6494,  ...,  0.0886, -0.3657, -0.0534],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5317, -4.9531, -0.2991,  ..., -1.8320, -0.3979, -5.0391],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0164, -0.0081,  0.0096,  ...,  0.0116, -0.0070, -0.0066],
        [-0.0228,  0.0251, -0.0088,  ..., -0.0057, -0.0149, -0.0199],
        [-0.0212, -0.0161,  0.0521,  ..., -0.0126,  0.0263, -0.0408],
        ...,
        [-0.0058,  0.0300, -0.0150,  ...,  0.0228, -0.0044, -0.0015],
        [ 0.0037,  0.0272,  0.0085,  ..., -0.0124,  0.0126,  0.0060],
        [-0.0162,  0.0004, -0.0027,  ...,  0.0051,  0.0033, -0.0008]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5220, -5.0469,  0.1221,  ..., -1.7070, -0.3428, -4.6914]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 16:38:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with warsaw as its capital is known as poland
The country with london as its capital is known as england
The country with ottawa as its capital is known as canada
The country with hanoi as its capital is known as vietnam
The country with sofia as its capital is known as bulgaria
The country with jakarta as its capital is known as indonesia
The country with abuja as its capital is known as nigeria
The country with dhaka as its capital is known as
2024-07-28 16:38:12 root INFO     [order_1_approx] starting weight calculation for The country with dhaka as its capital is known as bangladesh
The country with jakarta as its capital is known as indonesia
The country with abuja as its capital is known as nigeria
The country with ottawa as its capital is known as canada
The country with sofia as its capital is known as bulgaria
The country with london as its capital is known as england
The country with hanoi as its capital is known as vietnam
The country with warsaw as its capital is known as
2024-07-28 16:38:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 16:40:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1193, -0.1309, -0.4351,  ...,  0.1344, -0.1548, -0.2517],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6250, -7.4062, -1.7812,  ..., -1.0576,  1.3809, -4.4141],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.2512e-02,  6.9122e-03,  7.9575e-03,  ...,  1.7334e-02,
         -1.1124e-02, -6.5384e-03],
        [ 1.5137e-02,  2.2247e-02,  1.3382e-02,  ..., -1.9897e-02,
         -1.4992e-02,  1.3809e-02],
        [-4.1687e-02,  3.6194e-02,  1.2207e-02,  ..., -3.9444e-03,
         -4.3869e-05, -1.4900e-02],
        ...,
        [ 8.2703e-03,  3.0899e-02,  1.1284e-02,  ...,  4.4891e-02,
         -1.0117e-02,  1.6336e-03],
        [ 1.1681e-02, -6.0730e-03, -9.9716e-03,  ..., -3.6979e-04,
          1.6891e-02, -1.2222e-02],
        [-1.6724e-02,  3.7804e-03, -3.3779e-03,  ...,  2.9526e-03,
         -1.0017e-02,  3.0766e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7246, -7.0977, -2.0156,  ..., -0.9497,  1.2812, -4.1094]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 16:40:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with dhaka as its capital is known as bangladesh
The country with jakarta as its capital is known as indonesia
The country with abuja as its capital is known as nigeria
The country with ottawa as its capital is known as canada
The country with sofia as its capital is known as bulgaria
The country with london as its capital is known as england
The country with hanoi as its capital is known as vietnam
The country with warsaw as its capital is known as
2024-07-28 16:40:55 root INFO     [order_1_approx] starting weight calculation for The country with jakarta as its capital is known as indonesia
The country with hanoi as its capital is known as vietnam
The country with dhaka as its capital is known as bangladesh
The country with abuja as its capital is known as nigeria
The country with warsaw as its capital is known as poland
The country with london as its capital is known as england
The country with ottawa as its capital is known as canada
The country with sofia as its capital is known as
2024-07-28 16:40:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 16:43:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0509, -0.2573, -0.9160,  ...,  0.2761,  0.0948,  0.0204],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0176, -4.9688, -0.9473,  ..., -0.1071,  0.7002, -4.6562],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0030, -0.0238, -0.0203,  ...,  0.0118, -0.0101,  0.0130],
        [ 0.0020,  0.0088,  0.0065,  ..., -0.0021, -0.0041, -0.0048],
        [ 0.0078,  0.0268,  0.0480,  ..., -0.0013, -0.0227, -0.0201],
        ...,
        [-0.0073,  0.0171, -0.0007,  ...,  0.0325, -0.0148, -0.0178],
        [ 0.0147, -0.0099, -0.0145,  ..., -0.0117,  0.0455,  0.0035],
        [-0.0157, -0.0166, -0.0101,  ...,  0.0034,  0.0230,  0.0288]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8535, -5.0117, -1.1475,  ..., -0.1293,  0.9321, -4.3906]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 16:43:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with jakarta as its capital is known as indonesia
The country with hanoi as its capital is known as vietnam
The country with dhaka as its capital is known as bangladesh
The country with abuja as its capital is known as nigeria
The country with warsaw as its capital is known as poland
The country with london as its capital is known as england
The country with ottawa as its capital is known as canada
The country with sofia as its capital is known as
2024-07-28 16:43:40 root INFO     [order_1_approx] starting weight calculation for The country with jakarta as its capital is known as indonesia
The country with hanoi as its capital is known as vietnam
The country with london as its capital is known as england
The country with warsaw as its capital is known as poland
The country with sofia as its capital is known as bulgaria
The country with dhaka as its capital is known as bangladesh
The country with ottawa as its capital is known as canada
The country with abuja as its capital is known as
2024-07-28 16:43:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 16:46:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0317,  0.0121, -0.2417,  ...,  0.1208, -0.3640,  0.2056],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2012, -4.1797, -1.4229,  ..., -1.2910, -0.4160, -2.1367],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 4.6631e-02, -3.9490e-02, -6.8741e-03,  ...,  9.1858e-03,
         -1.5373e-02,  1.4725e-02],
        [-8.3923e-03,  4.1504e-02,  2.1667e-02,  ..., -1.6403e-02,
         -2.7237e-02, -4.2725e-02],
        [-1.6998e-02,  3.2257e-02,  3.3081e-02,  ...,  3.8109e-03,
          8.2245e-03, -3.5004e-02],
        ...,
        [ 5.1231e-03,  8.5144e-03, -8.7891e-03,  ...,  1.2123e-02,
         -1.9226e-02, -1.5503e-02],
        [ 2.5330e-02, -5.5237e-03, -2.2476e-02,  ...,  2.7008e-02,
          3.3203e-02, -7.6981e-03],
        [-4.2114e-03, -1.5312e-02,  8.1024e-03,  ...,  2.2491e-02,
         -3.8147e-05,  2.8610e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4121, -4.5625, -2.0293,  ..., -1.6240, -0.4404, -1.9570]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 16:46:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with jakarta as its capital is known as indonesia
The country with hanoi as its capital is known as vietnam
The country with london as its capital is known as england
The country with warsaw as its capital is known as poland
The country with sofia as its capital is known as bulgaria
The country with dhaka as its capital is known as bangladesh
The country with ottawa as its capital is known as canada
The country with abuja as its capital is known as
2024-07-28 16:46:24 root INFO     [order_1_approx] starting weight calculation for The country with jakarta as its capital is known as indonesia
The country with abuja as its capital is known as nigeria
The country with warsaw as its capital is known as poland
The country with ottawa as its capital is known as canada
The country with london as its capital is known as england
The country with dhaka as its capital is known as bangladesh
The country with sofia as its capital is known as bulgaria
The country with hanoi as its capital is known as
2024-07-28 16:46:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 16:49:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0622, -0.1953, -0.3083,  ..., -0.0897, -0.1948,  0.0995],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-5.5762e-01, -6.0625e+00,  9.1553e-04,  ..., -1.9824e+00,
        -2.3223e+00, -3.4141e+00], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0121,  0.0100, -0.0074,  ...,  0.0204, -0.0176, -0.0130],
        [-0.0047,  0.0105, -0.0015,  ..., -0.0164, -0.0166, -0.0283],
        [ 0.0029,  0.0051,  0.0319,  ..., -0.0084,  0.0071, -0.0087],
        ...,
        [ 0.0117, -0.0077, -0.0165,  ...,  0.0053,  0.0028, -0.0113],
        [ 0.0137, -0.0045, -0.0152,  ..., -0.0184,  0.0047,  0.0075],
        [-0.0062, -0.0148, -0.0008,  ..., -0.0067,  0.0028, -0.0113]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7461, -5.5625,  0.1262,  ..., -1.9043, -2.3320, -3.3008]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 16:49:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with jakarta as its capital is known as indonesia
The country with abuja as its capital is known as nigeria
The country with warsaw as its capital is known as poland
The country with ottawa as its capital is known as canada
The country with london as its capital is known as england
The country with dhaka as its capital is known as bangladesh
The country with sofia as its capital is known as bulgaria
The country with hanoi as its capital is known as
2024-07-28 16:49:09 root INFO     [order_1_approx] starting weight calculation for The country with dhaka as its capital is known as bangladesh
The country with sofia as its capital is known as bulgaria
The country with warsaw as its capital is known as poland
The country with hanoi as its capital is known as vietnam
The country with abuja as its capital is known as nigeria
The country with ottawa as its capital is known as canada
The country with london as its capital is known as england
The country with jakarta as its capital is known as
2024-07-28 16:49:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 16:51:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2529, -0.0056, -0.6318,  ...,  0.1675, -0.3843,  0.0085],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8828, -5.8438, -0.6772,  ..., -1.5898, -1.7988, -4.3359],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.5706e-02,  1.4465e-02,  6.8665e-05,  ...,  1.6479e-03,
         -1.0620e-02, -2.0035e-02],
        [ 7.2327e-03,  1.4877e-02, -7.8125e-03,  ..., -2.3315e-02,
          2.6054e-03, -1.7944e-02],
        [-1.4305e-04, -4.0398e-03,  4.3854e-02,  ..., -1.1047e-02,
          5.7106e-03, -4.9820e-03],
        ...,
        [ 6.8054e-03,  2.0004e-02,  6.6528e-03,  ...,  2.0355e-02,
          7.6103e-03, -2.0355e-02],
        [ 1.1009e-02,  1.9855e-03, -1.6739e-02,  ...,  7.1945e-03,
          1.0742e-02,  6.8626e-03],
        [ 8.7433e-03, -4.0512e-03,  1.4353e-03,  ..., -1.1276e-02,
         -1.0681e-03,  1.4198e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7832, -5.7227, -0.7290,  ..., -1.2988, -1.8867, -4.1016]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 16:51:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with dhaka as its capital is known as bangladesh
The country with sofia as its capital is known as bulgaria
The country with warsaw as its capital is known as poland
The country with hanoi as its capital is known as vietnam
The country with abuja as its capital is known as nigeria
The country with ottawa as its capital is known as canada
The country with london as its capital is known as england
The country with jakarta as its capital is known as
2024-07-28 16:51:53 root INFO     [order_1_approx] starting weight calculation for The country with london as its capital is known as england
The country with abuja as its capital is known as nigeria
The country with sofia as its capital is known as bulgaria
The country with dhaka as its capital is known as bangladesh
The country with warsaw as its capital is known as poland
The country with jakarta as its capital is known as indonesia
The country with hanoi as its capital is known as vietnam
The country with ottawa as its capital is known as
2024-07-28 16:51:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 16:54:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1583, -0.0168, -0.3354,  ...,  0.0408, -0.0853,  0.0889],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1875, -6.8203,  0.9351,  ..., -0.9209,  1.8193, -1.4395],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0045, -0.0023,  0.0055,  ...,  0.0142, -0.0176,  0.0202],
        [-0.0126,  0.0199,  0.0139,  ..., -0.0192, -0.0086, -0.0212],
        [-0.0128,  0.0249,  0.0575,  ..., -0.0100,  0.0454, -0.0104],
        ...,
        [ 0.0018,  0.0192, -0.0368,  ...,  0.0286, -0.0038, -0.0222],
        [ 0.0163, -0.0028,  0.0131,  ..., -0.0196,  0.0406,  0.0006],
        [-0.0007,  0.0060,  0.0143,  ...,  0.0099, -0.0106,  0.0111]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0458, -6.4180,  0.4902,  ..., -0.7734,  1.6416, -1.0352]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 16:54:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with london as its capital is known as england
The country with abuja as its capital is known as nigeria
The country with sofia as its capital is known as bulgaria
The country with dhaka as its capital is known as bangladesh
The country with warsaw as its capital is known as poland
The country with jakarta as its capital is known as indonesia
The country with hanoi as its capital is known as vietnam
The country with ottawa as its capital is known as
2024-07-28 16:54:38 root INFO     total operator prediction time: 1314.5907485485077 seconds
2024-07-28 16:54:38 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on things - color
2024-07-28 16:54:38 root INFO     building operator things - color
2024-07-28 16:54:38 root INFO     [order_1_approx] starting weight calculation for The blood is colored red
The grass is colored green
The sugar is colored white
The paper is colored white
The cloud is colored white
The milk is colored white
The coal is colored black
The frog is colored
2024-07-28 16:54:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 16:57:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1404,  0.0757,  0.1635,  ..., -0.3853, -0.2922,  0.2793],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6567, -2.3340,  1.2227,  ...,  0.3213, -0.2588,  0.8730],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0643,  0.0088,  0.0287,  ..., -0.0233,  0.0216,  0.0074],
        [-0.0093,  0.0583,  0.0098,  ...,  0.0047, -0.0145, -0.0493],
        [-0.0135,  0.0327,  0.0365,  ...,  0.0268, -0.0234,  0.0138],
        ...,
        [-0.0328,  0.0151, -0.0028,  ...,  0.0757,  0.0142, -0.0241],
        [-0.0038,  0.0164,  0.0370,  ...,  0.0429,  0.0263, -0.0273],
        [ 0.0063, -0.0201,  0.0121,  ..., -0.0337,  0.0142,  0.0523]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2776, -2.2656,  1.4658,  ...,  0.4805, -0.2993,  0.3953]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 16:57:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The blood is colored red
The grass is colored green
The sugar is colored white
The paper is colored white
The cloud is colored white
The milk is colored white
The coal is colored black
The frog is colored
2024-07-28 16:57:24 root INFO     [order_1_approx] starting weight calculation for The milk is colored white
The paper is colored white
The frog is colored green
The cloud is colored white
The sugar is colored white
The coal is colored black
The blood is colored red
The grass is colored
2024-07-28 16:57:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 17:00:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0878,  0.1929, -0.1547,  ..., -0.0771, -0.0898, -0.1652],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9985, -6.5781, -2.5352,  ..., -1.5254,  0.3662, -3.6055],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0755,  0.0086,  0.0053,  ..., -0.0124,  0.0188,  0.0143],
        [ 0.0043,  0.0173, -0.0228,  ..., -0.0147, -0.0006, -0.0385],
        [ 0.0054,  0.0008,  0.0394,  ..., -0.0028,  0.0052,  0.0354],
        ...,
        [-0.0031, -0.0149,  0.0066,  ...,  0.0258,  0.0103, -0.0084],
        [-0.0218,  0.0027,  0.0331,  ...,  0.0219,  0.0121, -0.0070],
        [-0.0168, -0.0212, -0.0014,  ..., -0.0169,  0.0335,  0.0320]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6289, -6.4922, -1.9512,  ..., -1.4121, -0.0793, -3.6934]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 17:00:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The milk is colored white
The paper is colored white
The frog is colored green
The cloud is colored white
The sugar is colored white
The coal is colored black
The blood is colored red
The grass is colored
2024-07-28 17:00:10 root INFO     [order_1_approx] starting weight calculation for The blood is colored red
The frog is colored green
The paper is colored white
The grass is colored green
The sugar is colored white
The coal is colored black
The milk is colored white
The cloud is colored
2024-07-28 17:00:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 17:02:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1672, -0.0942,  0.2157,  ..., -0.1001, -0.3008, -0.0076],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.1816, -4.2266,  1.9570,  ..., -2.1953, -0.4609, -1.4385],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0520,  0.0151,  0.0294,  ...,  0.0106, -0.0144,  0.0187],
        [ 0.0082,  0.0186, -0.0015,  ...,  0.0115, -0.0132, -0.0295],
        [ 0.0160,  0.0119,  0.0182,  ..., -0.0101, -0.0280,  0.0079],
        ...,
        [-0.0060,  0.0019,  0.0097,  ...,  0.0494, -0.0095, -0.0074],
        [-0.0195, -0.0156, -0.0035,  ...,  0.0384,  0.0195, -0.0373],
        [-0.0082, -0.0193,  0.0047,  ...,  0.0035, -0.0156,  0.0314]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8740, -3.8750,  1.5840,  ..., -2.0195, -0.9102, -0.9824]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 17:02:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The blood is colored red
The frog is colored green
The paper is colored white
The grass is colored green
The sugar is colored white
The coal is colored black
The milk is colored white
The cloud is colored
2024-07-28 17:02:57 root INFO     [order_1_approx] starting weight calculation for The grass is colored green
The sugar is colored white
The coal is colored black
The paper is colored white
The milk is colored white
The frog is colored green
The cloud is colored white
The blood is colored
2024-07-28 17:02:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 17:05:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0159, -0.1489, -0.3643,  ..., -0.1340, -0.3159, -0.0926],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.2275, -9.5469, -1.3672,  ..., -2.9062,  0.9316, -3.0469],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.7312e-02, -1.2875e-05,  3.2990e-02,  ...,  1.8234e-03,
         -1.9562e-02,  1.1993e-02],
        [ 2.6276e-02,  7.6599e-03, -1.8906e-02,  ..., -2.0920e-02,
         -5.3291e-03, -3.2349e-03],
        [ 7.8735e-03,  9.0179e-03,  2.8992e-02,  ...,  4.4861e-02,
         -1.2375e-02,  2.2705e-02],
        ...,
        [ 5.6152e-03, -5.7449e-03, -1.7349e-02,  ...,  1.5488e-03,
         -2.0180e-03, -1.3672e-02],
        [-1.5388e-02,  3.8849e-02,  1.0612e-02,  ..., -8.1177e-03,
          2.0340e-02,  3.2978e-03],
        [-1.1986e-02, -1.6632e-02, -1.1597e-02,  ..., -1.6205e-02,
         -1.8692e-03,  7.0763e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.9082, -9.2031, -1.5225,  ..., -3.3438,  1.0137, -2.8965]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 17:05:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The grass is colored green
The sugar is colored white
The coal is colored black
The paper is colored white
The milk is colored white
The frog is colored green
The cloud is colored white
The blood is colored
2024-07-28 17:05:43 root INFO     [order_1_approx] starting weight calculation for The coal is colored black
The paper is colored white
The milk is colored white
The grass is colored green
The blood is colored red
The cloud is colored white
The frog is colored green
The sugar is colored
2024-07-28 17:05:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 17:08:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2344, -0.2056, -0.2136,  ...,  0.0602, -0.1888, -0.2159],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.9014, -5.8828,  1.5264,  ..., -2.5352, -1.7842, -1.2754],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0417,  0.0147,  0.0235,  ..., -0.0320,  0.0122,  0.0466],
        [-0.0188,  0.0521,  0.0043,  ..., -0.0184, -0.0023, -0.0154],
        [ 0.0015, -0.0071,  0.0289,  ..., -0.0002, -0.0102, -0.0074],
        ...,
        [ 0.0025, -0.0262, -0.0055,  ...,  0.0439,  0.0005, -0.0305],
        [-0.0359, -0.0003,  0.0109,  ...,  0.0345,  0.0362, -0.0180],
        [-0.0118, -0.0367, -0.0020,  ...,  0.0040,  0.0112,  0.0103]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.9058, -5.9609,  1.6582,  ..., -2.5527, -1.6104, -1.2490]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 17:08:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The coal is colored black
The paper is colored white
The milk is colored white
The grass is colored green
The blood is colored red
The cloud is colored white
The frog is colored green
The sugar is colored
2024-07-28 17:08:30 root INFO     [order_1_approx] starting weight calculation for The coal is colored black
The grass is colored green
The sugar is colored white
The blood is colored red
The frog is colored green
The paper is colored white
The cloud is colored white
The milk is colored
2024-07-28 17:08:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 17:11:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0171, -0.3511, -0.1538,  ...,  0.0932, -0.2625,  0.0372],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8838, -3.2930,  0.8418,  ..., -1.8340,  0.2439, -1.7236],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0663,  0.0337,  0.0336,  ..., -0.0149,  0.0191,  0.0343],
        [-0.0166,  0.0468, -0.0087,  ..., -0.0268, -0.0100, -0.0229],
        [ 0.0053,  0.0072,  0.0250,  ...,  0.0453, -0.0045, -0.0035],
        ...,
        [-0.0042, -0.0061, -0.0027,  ...,  0.0421, -0.0207, -0.0201],
        [-0.0013,  0.0043, -0.0070,  ...,  0.0435,  0.0221, -0.0115],
        [-0.0222, -0.0140,  0.0325,  ..., -0.0114, -0.0034,  0.0620]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2886, -3.6660,  0.6553,  ..., -1.7578,  0.0139, -1.4219]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 17:11:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The coal is colored black
The grass is colored green
The sugar is colored white
The blood is colored red
The frog is colored green
The paper is colored white
The cloud is colored white
The milk is colored
2024-07-28 17:11:16 root INFO     [order_1_approx] starting weight calculation for The blood is colored red
The sugar is colored white
The paper is colored white
The cloud is colored white
The grass is colored green
The milk is colored white
The frog is colored green
The coal is colored
2024-07-28 17:11:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 17:14:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2947, -0.1409, -0.2260,  ..., -0.2546,  0.0873,  0.3638],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2051, -6.3242, -0.6519,  ..., -4.5664,  0.7144, -4.9453],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0660,  0.0071,  0.0258,  ...,  0.0120,  0.0289,  0.0120],
        [ 0.0146,  0.0068, -0.0048,  ..., -0.0137,  0.0047, -0.0091],
        [-0.0028,  0.0031,  0.0289,  ...,  0.0220, -0.0147, -0.0110],
        ...,
        [-0.0011,  0.0043,  0.0101,  ...,  0.0381,  0.0232, -0.0226],
        [-0.0137,  0.0025,  0.0098,  ...,  0.0227,  0.0187, -0.0272],
        [ 0.0042, -0.0239, -0.0287,  ..., -0.0150,  0.0208,  0.0117]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0253, -6.1172, -0.7520,  ..., -4.2812,  0.6538, -4.6758]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 17:14:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The blood is colored red
The sugar is colored white
The paper is colored white
The cloud is colored white
The grass is colored green
The milk is colored white
The frog is colored green
The coal is colored
2024-07-28 17:14:03 root INFO     [order_1_approx] starting weight calculation for The grass is colored green
The cloud is colored white
The coal is colored black
The sugar is colored white
The blood is colored red
The frog is colored green
The milk is colored white
The paper is colored
2024-07-28 17:14:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 17:16:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2590,  0.0369, -0.3054,  ...,  0.1130, -0.4092,  0.2524],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.3613, -4.9922,  0.7812,  ..., -2.0078, -1.1992,  1.0820],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0577,  0.0200,  0.0323,  ..., -0.0148, -0.0167,  0.0256],
        [ 0.0015,  0.0304, -0.0150,  ..., -0.0192,  0.0019, -0.0292],
        [-0.0046,  0.0036,  0.0186,  ...,  0.0184, -0.0181, -0.0165],
        ...,
        [ 0.0084, -0.0056,  0.0119,  ...,  0.0205, -0.0081,  0.0057],
        [-0.0051, -0.0233,  0.0082,  ...,  0.0100,  0.0077, -0.0143],
        [-0.0080,  0.0131,  0.0047,  ...,  0.0047,  0.0070,  0.0304]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.1855, -4.9336,  0.9761,  ..., -1.8555, -1.0869,  0.6606]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 17:16:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The grass is colored green
The cloud is colored white
The coal is colored black
The sugar is colored white
The blood is colored red
The frog is colored green
The milk is colored white
The paper is colored
2024-07-28 17:16:49 root INFO     total operator prediction time: 1331.4526407718658 seconds
2024-07-28 17:16:49 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - sound
2024-07-28 17:16:49 root INFO     building operator animal - sound
2024-07-28 17:16:50 root INFO     [order_1_approx] starting weight calculation for The sound that a snake makes is called a hiss
The sound that a cricket makes is called a chirp
The sound that a songbird makes is called a chirrup
The sound that a deer makes is called a bellow
The sound that a hound makes is called a bark
The sound that a raven makes is called a caw
The sound that a cattle makes is called a moo
The sound that a wasp makes is called a
2024-07-28 17:16:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 17:19:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0659, -0.0494,  0.2490,  ...,  0.1721, -0.0360,  0.0994],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2168, -2.3398,  2.1074,  ..., -0.3047, -0.5996,  1.9766],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0365, -0.0073, -0.0165,  ..., -0.0022, -0.0405, -0.0029],
        [-0.0252,  0.0426, -0.0154,  ..., -0.0186, -0.0195, -0.0104],
        [-0.0039,  0.0164,  0.0121,  ..., -0.0110, -0.0118,  0.0082],
        ...,
        [-0.0256,  0.0185,  0.0056,  ...,  0.0294, -0.0282, -0.0339],
        [-0.0093, -0.0115,  0.0137,  ...,  0.0078, -0.0009,  0.0137],
        [-0.0007,  0.0133, -0.0084,  ..., -0.0114, -0.0153,  0.0079]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0039, -2.5605,  1.6484,  ..., -0.6812, -1.1094,  1.6406]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 17:19:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a snake makes is called a hiss
The sound that a cricket makes is called a chirp
The sound that a songbird makes is called a chirrup
The sound that a deer makes is called a bellow
The sound that a hound makes is called a bark
The sound that a raven makes is called a caw
The sound that a cattle makes is called a moo
The sound that a wasp makes is called a
2024-07-28 17:19:34 root INFO     [order_1_approx] starting weight calculation for The sound that a songbird makes is called a chirrup
The sound that a wasp makes is called a buzz
The sound that a hound makes is called a bark
The sound that a raven makes is called a caw
The sound that a deer makes is called a bellow
The sound that a cattle makes is called a moo
The sound that a cricket makes is called a chirp
The sound that a snake makes is called a
2024-07-28 17:19:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 17:22:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1101,  0.1997, -0.0758,  ..., -0.2600, -0.1342,  0.2422],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2148, -1.4688,  1.1924,  ...,  0.5894, -1.4141,  2.3086],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0216,  0.0075, -0.0113,  ..., -0.0051, -0.0036,  0.0128],
        [-0.0201,  0.0363, -0.0054,  ..., -0.0274, -0.0265, -0.0287],
        [ 0.0228, -0.0082,  0.0512,  ..., -0.0256, -0.0187,  0.0064],
        ...,
        [-0.0242,  0.0215, -0.0199,  ...,  0.0597, -0.0225, -0.0481],
        [-0.0019, -0.0029, -0.0112,  ...,  0.0140,  0.0297, -0.0058],
        [ 0.0130,  0.0108, -0.0289,  ...,  0.0083,  0.0003,  0.0161]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2568, -1.6270,  0.8750,  ...,  0.6665, -1.2637,  2.2422]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 17:22:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a songbird makes is called a chirrup
The sound that a wasp makes is called a buzz
The sound that a hound makes is called a bark
The sound that a raven makes is called a caw
The sound that a deer makes is called a bellow
The sound that a cattle makes is called a moo
The sound that a cricket makes is called a chirp
The sound that a snake makes is called a
2024-07-28 17:22:19 root INFO     [order_1_approx] starting weight calculation for The sound that a wasp makes is called a buzz
The sound that a hound makes is called a bark
The sound that a songbird makes is called a chirrup
The sound that a deer makes is called a bellow
The sound that a cattle makes is called a moo
The sound that a snake makes is called a hiss
The sound that a cricket makes is called a chirp
The sound that a raven makes is called a
2024-07-28 17:22:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 17:25:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0950,  0.0213, -0.3040,  ..., -0.0640, -0.1088,  0.1877],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9082, -3.9062,  0.7441,  ..., -1.8535,  0.0430,  2.2871],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0418,  0.0201, -0.0201,  ..., -0.0113, -0.0491, -0.0296],
        [-0.0316,  0.0395,  0.0037,  ...,  0.0114,  0.0165, -0.0115],
        [ 0.0116, -0.0284,  0.0282,  ..., -0.0316, -0.0107, -0.0378],
        ...,
        [-0.0175,  0.0281, -0.0091,  ...,  0.0588, -0.0131, -0.0266],
        [-0.0065, -0.0177, -0.0245,  ...,  0.0341,  0.0241, -0.0174],
        [-0.0009, -0.0075, -0.0091,  ..., -0.0252, -0.0337,  0.0074]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3535, -3.5371,  0.3491,  ..., -1.9863, -0.4517,  1.8848]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 17:25:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a wasp makes is called a buzz
The sound that a hound makes is called a bark
The sound that a songbird makes is called a chirrup
The sound that a deer makes is called a bellow
The sound that a cattle makes is called a moo
The sound that a snake makes is called a hiss
The sound that a cricket makes is called a chirp
The sound that a raven makes is called a
2024-07-28 17:25:06 root INFO     [order_1_approx] starting weight calculation for The sound that a hound makes is called a bark
The sound that a deer makes is called a bellow
The sound that a cattle makes is called a moo
The sound that a snake makes is called a hiss
The sound that a raven makes is called a caw
The sound that a wasp makes is called a buzz
The sound that a cricket makes is called a chirp
The sound that a songbird makes is called a
2024-07-28 17:25:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
2024-07-28 17:27:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0701,  0.0870,  0.1040,  ..., -0.0302,  0.0976, -0.0872],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4268, -3.7227,  2.1055,  ...,  0.9814, -1.1816, -1.3818],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0141,  0.0016,  0.0009,  ..., -0.0026, -0.0251,  0.0056],
        [-0.0106,  0.0154,  0.0070,  ...,  0.0030,  0.0179,  0.0050],
        [-0.0053, -0.0103,  0.0284,  ..., -0.0071, -0.0013,  0.0115],
        ...,
        [-0.0022,  0.0139, -0.0067,  ...,  0.0219,  0.0024, -0.0060],
        [-0.0028,  0.0098, -0.0055,  ...,  0.0072,  0.0052, -0.0027],
        [-0.0098, -0.0091, -0.0019,  ..., -0.0210,  0.0089,  0.0193]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6953, -3.6543,  2.3359,  ...,  0.8086, -1.3105, -1.3750]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-28 17:27:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a hound makes is called a bark
The sound that a deer makes is called a bellow
The sound that a cattle makes is called a moo
The sound that a snake makes is called a hiss
The sound that a raven makes is called a caw
The sound that a wasp makes is called a buzz
The sound that a cricket makes is called a chirp
The sound that a songbird makes is called a
2024-07-28 17:27:51 root INFO     [order_1_approx] starting weight calculation for The sound that a songbird makes is called a chirrup
The sound that a cattle makes is called a moo
The sound that a wasp makes is called a buzz
The sound that a cricket makes is called a chirp
The sound that a raven makes is called a caw
The sound that a snake makes is called a hiss
The sound that a hound makes is called a bark
The sound that a deer makes is called a
2024-07-28 17:27:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.8
